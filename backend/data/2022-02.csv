"uuid","repository link","title","author","contributor","publication year","abstract","subject topic","language","publication type","publisher","isbn","issn","patent","patent status","bibliographic note","access restriction","embargo date","faculty","department","research group","programme","project","coordinates"
"uuid:a22b77cc-2cc6-41a6-8044-40d04e1ff281","http://resolver.tudelft.nl/uuid:a22b77cc-2cc6-41a6-8044-40d04e1ff281","Development of a Software for the Failure Modes and Effects Analysis and Reliability Analysis of Satellite Power Generation Systems","Martelli, Davide (TU Delft Aerospace Engineering)","Uludag, M.S. (mentor); Delft University of Technology (degree granting institution)","2022","Cost and lifetime requirements are two of the key drivers for the development of complex systems for modern space missions. As a consequence, system reliability is a factor of primary concern, requiring appropriate analyses. A closely related topic is the study of the effects induced by failures to which the system may be subjected, necessary to identify criticalities and weaknesses within the system. Mitigation strategies may then be derived and implemented. The aforementioned activities are laborious, intensive and a significant number of iterations are needed to achieve a system design that fully complies with the dependability requirements. This research aims to perform an FMEA and reliability analysis of satellite solar arrays by developing a flexible modeling software for the simulation of the performance of any PVA configuration, able to provide a reliability assessment. These activities require the implementation of two different models: an electrical model and a reliability model.<br/>As far as the FMEA is concerned, two types of analysis may be performed to study the effects of the failure modes. A static analysis comprises the investigation of the variations experienced by the characteristic curves of the solar array due to failures, while a dynamic analysis studies the response of the Solar Array Regulator (SAR). The outcome depends on the type of analysis performed: for the former, the characteristic curves of the healthy and faulty system are plotted. Then, the performance variations corresponding to the three main operating points (open-circuit, short-circuit, maximum power) are calculated. This allows characterizing the effects of the failures of the solar array. Furthermore, a severity classification of the failure modes is retrieved. The response of the solar array regulator is instead investigated through the dynamic analysis, where a load is connected to the solar array. Based on the wave-forms obtained, the correct implementation of the SAR may be verified and the sizing of other elements of the Electrical Power Subsystem (EPS) may be derived.<br/>The reliability analysis, besides providing an accurate estimation of the system reliability, is also used to calculate the probability of occurrence of failures. From this, a probability classification is determined, leading to a criticality assessment of the failure modes for the selected PVA configuration. This allows highlighting weaknesses in the system and acting accordingly with the implementation of mitigation measures. Furthermore, through the sensitivity analysis, recommendations for reliability improvement may be derived.<br/>The classification of the effects of the failure modes provides relevant insights about the synthesis of a reliable system, drawing attention to those components whose failure induces the most concerning performance degradation. Furthermore, the outcome of the research is a robust starting point for the development and analysis of a full EPS.","EPS system modelling; FMEA; FMECA; Reliability analysis; PVA; Space Solar Arrays","en","master thesis","","","","","","","","2024-02-28","","","","Aerospace Engineering","",""
"uuid:e10f0030-5107-4db4-be65-743d55007be0","http://resolver.tudelft.nl/uuid:e10f0030-5107-4db4-be65-743d55007be0","Estimation of Drift in Localization Microscopy: A State Space Modelling Approach","Srivastava, Akshat (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Delft Center for Systems and Control)","Smith, C.S. (mentor); Verhaegen, M.H.G. (mentor); Kok, M. (graduation committee); Cnossen, J.P. (graduation committee); Delft University of Technology (degree granting institution)","2022","Single Molecule Localization Microscopy (SMLM) has enabled researchers to breakthrough the diffraction limit and obtain nanometer resolution images of macromolecular structures. But due to the time involved in obtaining ample data for proper image, the technique is venerable to many problem including fluctuations due to thermal gradients from surrounding which cause the frames to drift. SMLM relies on the stochastic blinking of fluorophore probes. Thus drift in SMLM could be explicitly modelled as a stochastic state space process. These models could be used to perform drift correction. Two state space models are proposed relying on different properties of SMLM.<br/><br/>The first model utilizes shifting of underlying image structure. The state space model for this property is constructed using shift matrices. A system identification method along with image reconstruction method is also derived to form the drift compensation algorithm for this model. This algorithm is further developed to provide adequate performance within low computational time. The second model relies on the position of emitter molecules and utilizes linking or pairing of fluorophore probes in succeeding frame to obtain the output data. Drift compensation algorithm for this model is constructed using Prediction Error Methods (PEM) and Kalman (RTS) smoother. The drift correction algorithm for these two models are also bench-marked with existing algorithms to obtain insight into performance. Furthermore, other properties of these algorithms are explored using simulation dataset and recommendation are provided for improvement and further research.","Localization microscopy; stochastic modelling; State Space Model; Single Molecule Localization Microscopy","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:ab721f52-f6b3-4dfc-b646-21fb91adabc8","http://resolver.tudelft.nl/uuid:ab721f52-f6b3-4dfc-b646-21fb91adabc8","Experimental Study of Shock Wave/Boundary-Layer Interactions over Fluttering Panels","Aditya, Abhyuday (TU Delft Aerospace Engineering)","Schrijer, F.F.J. (mentor); van Oudheusden, B.W. (mentor); Bulut, J. (mentor); Avallone, F. (graduation committee); Baars, W.J. (graduation committee); Delft University of Technology (degree granting institution)","2022","Supersonic flows cause thin panels to flutter, which is characterized by high-amplitude self-sustained oscillations, increasing the risk of fatigue failure. Flutter is known to be exacerbated when a shock wave impinges on the panel, creating a shock wave/boundary-layer interaction (SWBLI) which promotes separation of flow and leads to increased aerodynamic and thermal loading on the panel. This novel fluid-structure interaction (FSI), known as shock-induced panel flutter, poses a risk to the structural integrity of components used in high-speed aerial vehicles, such as rocket nozzles and supersonic engine inlets.<br/><br/>Due to the complex coupled interaction between flow and structural dynamics in flutter, experiments provide a better option to investigate the underlying physical mechanisms, rather than computational studies, which usually have to compromise between computational cost and resultant accuracy. The ST-15 supersonic wind tunnel facility at TU Delft is employed to conduct experimental measurements of shock-induced panel flutter, using high-speed Schlieren imaging to capture flow structures and stereographic Digital Image Correlation (DIC) to record panel displacements in separate campaigns. Tests are done at Mach 2 with fully-clamped thin panels, and the flutter response is excited using different shock strengths and impingement locations.<br/><br/>In both campaigns, accelerometers are used to measure spurious vibrations around the wind tunnel test section. This helps reveal the existence of external vibrations inherent to the facility, which are also found to drive the frequency of the panel flutter: at 760-770 Hz without an impinging shock, and 605-640 Hz with an impinging shock. The latter frequency is detected in both - shock motion and panel displacements – which establishes coupling between flow and structure despite measurements being non-simultaneous. Changing the shock impingement location does not have a significant effect on the degree of flow separation caused over the thin fluttering panel, which is always higher than the separation on a rigid plate at the same shock strength, thus proving that fluttering panels are not viable means of shock-induced separation control. A stronger impinging shock produces increased shock-induced flow separation but results in less energetic panel flutter, which is attributed to the higher post-shock pressure rise suppressing the panel. Flutter is found to be most energetic, and consequently, the panel is most susceptible to fatigue failure, when the shock impinges at 60% of the panel length.","Panel Flutter; SWBLI; Fluid Structure Interaction; Schlieren; Digital Image Correlation","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:25c3ff8c-c4e3-4d1c-b0e7-c1796680cef9","http://resolver.tudelft.nl/uuid:25c3ff8c-c4e3-4d1c-b0e7-c1796680cef9","Optimization approach for calcined clay and slag based geopolymer mortar – an experimental investigation for 3DCP","Boudouan, Youssra (TU Delft Civil Engineering and Geosciences)","Ye, G. (graduation committee); Dong, H. (mentor); Delft University of Technology (degree granting institution)","2022","After water, concrete is the most used substance on the planet. Approximately three tonnes of concrete is produced per person annually (Gagg, 2014). Traditionally, large amounts of Ordinary Portland Cement (OPC) are needed for the production of concrete. The production of OPC is very energy intensive and therefore a major generator of carbon dioxide, which is considered to be a potent greenhouse gas. High CO2-emissions are caused by calcination of limestone and combustion of fossil fuel during an energy intensive production process. <br/>To reduce the CO2-emissions caused by the concrete manufacturing, there is a growing interest in alternative and low CO2-binders. A great example of alternative binders are alkali-activated materials (AAMs), often referred to as geopolymers. Alkali-activated materials are inorganic polymers acting as the binder agent in concrete, often containing by-products from the industry such as fly ash and blast furnace slag (Davidovits, 1989). Unlike OPC, AAMs are synthesized by activation of an aluminosilicate source (fly ash, slag, metakaolin) with alkaline activators. AAMs have attracted a lot of attention in the industry because of its superior mechanical properties, excellent resistance to sulphate attack, low creep and low drying shrinkage compared to OPC. <br/>Besides sustainability, the total amount of costs is also a relevant factor for the construction industry. 3D-printing of concrete removes the need for formwork and enables the industry to create complex shapes as well as optimization of material use. It also provides an opportunity for an automated building process with a minimal amount of labour and material wastage. Combining the use of alkali-activated materials (AAMs) in an innovative and automated 3D-printing process may therefore offer many advantages for the construction industry...<br","calcined clay; slag; geopolymer concrete; optimization; AAM","en","master thesis","","","","","","","","","","","","Civil Engineering","",""
"uuid:99e42d4a-7ca1-493c-bfa4-f481fc75952a","http://resolver.tudelft.nl/uuid:99e42d4a-7ca1-493c-bfa4-f481fc75952a","Export costs and service conditions in times of a global container shortage: A case study at Heineken Netherlands Supply","Nanninga, Michiel (TU Delft Civil Engineering and Geosciences)","Vleugel, J (mentor); Beelaerts van Blokland, W.W.A. (mentor); Negenborn, R.R. (mentor); Delft University of Technology (degree granting institution)","2022","Covid-19, the Suez canal blockade and a decreasing amount of larger shipping companies have changed the container shipping industry. A power shift from the exporter towards the shipping companies is occurring, paired with capacity constraints and surging container transportation prices indicating a global container shortage. Exporters of large volume mainly experience this with contract negotiations and are left with a choice for higher prices or less flexibility in contractual service conditions whilst striving to become more sustainable. This study answers the following research question: ‘How should large exporters like HNS weigh off transportation costs, flexibility in service conditions and environmental effects for contractual agreements in times of a global container shortage?’. This study poses several designs through the DMADE methodology to anticipate the aforementioned changes. It does so by modelling several designs based on contract variables, a modal shift and a production division based on geographical locations of breweries for Heineken Netherlands Supply. The study found that higher standard tariffs for container transportation should be preferred above less flexibility. Next to that a modal shift towards road transport is advised if the service conditions in contractual agreements become less flexible.","Export; Container shortage; Detention and demurrage; HNS; case study","en","master thesis","","","","","","","","2024-03-15","","","","Transport, Infrastructure and Logistics","",""
"uuid:3ad68dbd-3444-4e01-94a2-d28044b0ba3f","http://resolver.tudelft.nl/uuid:3ad68dbd-3444-4e01-94a2-d28044b0ba3f","Web3: A Decentralized Societal Infrastructure for Identity, Trust, Money, and Data","Bambacht, Joost (TU Delft Electrical Engineering, Mathematics and Computer Science)","Pouwelse, J.A. (mentor); Delft University of Technology (degree granting institution)","2022","A movement for a more transparent and decentralized Internet is globally attracting more attention. People are becoming more privacy-aware of their online identities and data. The Internet is constantly evolving. Web2 focused on companies that provide services in exchange for personal user data. Web3 commits to user-centricity using decentralization and zero-server architectures. The current digital society demands a global change to empower citizens and take back control. Citizens are locked into big- tech for personal data storage and their for-profit digital identity. Protection of data has proven to be essential, especially due to increased home Internet traffic during the COVID pandemic. Citizens do not possess their own travel documents. The Euro- pean Commission aims to transition this governmental property towards self-sovereign identity, introducing many new opportunities. Citizens are locked into banks with non- portable IBAN accounts and unsustainable legacy banking infrastructures. Migration to all-digital low-fraud infrastructures and healthier competitive ecosystems is essential.<br/>The overall challenge is to return the power to citizens and users again. The transi- tion to a more decentralized Internet is the first crucial step in the realization of user- centricity. This thesis presents the first exploratory study that integrates governmental- issued travel documents into a (decentralized) societal infrastructure. These self-sovereign identities form the authentic base to a private and secure transfer of money and data, and can effectively provide trust in authenticity that is currently missing in online con- versations. A fully operational zero-server infrastructure that incorporates all our re- quirements has been developed for Android using the P2P network overlay IPv8 (Tribler, 2021), and a personalized blockchain called TrustChain (Otte et al., 2020). It contributes to a reformed tech and financial sector that is more efficient and effective in serving the wider economy, and more resistant to bad behavior of all kinds. Creating such an in- frastructure that is decentralized and anti-fragile is deemed crucial for the future.","","en","master thesis","","","","","","","","","","","","","",""
"uuid:e36cda38-7e19-424a-a1c3-57953e781b0c","http://resolver.tudelft.nl/uuid:e36cda38-7e19-424a-a1c3-57953e781b0c","Oil-Water Flushing of Pipelines: Performing and analysing experiments on a 1:12 diameter scale, to study flushing dynamics and to increase future flushing efficiency","Klaassens, Vincent (TU Delft Mechanical, Maritime and Materials Engineering)","Henkes, R.A.W.M. (mentor); Van Nimwegen, Dries (graduation committee); Delft University of Technology (degree granting institution)","2022","Due to the energy transition, an increasing number of oil pipelines will be decommissioned in the foreseeable future. As a part of the decommissioning process, the oil needs to be flushed from the pipelines. Some models to predict the required water velocity to flush oil from pipelines are available, but these are limited in accuracy, and data to validate these models are lacking. The aim of this MSc research project is to gain a better understanding of the oil flushing process in pipelines using water, and to provide validation data for the existing models. Thereto lab experiments were carried out in the flow loop of TNO in Rijswijk. The length of the pipe is almost 6 m and the diameter is 56 mm. The experiments are performed by filling the experimental pipe section with oil and subsequently flushing it using four pipe volumes of water. The first set of experiments, for a pipe inclination of 0° to - 5°, was performed with superficial flushing velocities ranging from 0.05 m/s to 1.5 m/s, for two different types of oil. Data were collected using a mass flow meter system and a video capturing system. These data were subsequently analysed using the software tool MATLAB. The first set of experiments was also modelled in the multi-phase flow modelling tool OLGA. A second set of experiments was performed to find the transition point between stratified and mixed flow, which is relevant for the flushing efficiency, by varying the inclination in a range of 0° to -90° relative to the horizontal plane, using a superficial water velocity of 0.1 m/s. In addition to the mass flow measurements, data were collected with a video system during all sets of experiments, and subsequently processed to determine the phase distribution throughout the pipe during, and after the flushing process. It was established that the flushing efficiency is proportional to the superficial water velocity. For both types of oil, for inclinations between 0° and -5°, a superficial water velocity of 0.35 m/s suffices to flush all oil when flushing four pipe volumes of water. For all considered inclinations and pipe geometries and for both oil types, the bulk (≥ 95%) of the oil is removed from the pipe for a flushing velocity of 0.25 m/s. In a horizontal orientation, the lighter and less viscous Fuchs Renolin DTA7 oil is flushed more efficiently from the pipe compared to the Mobil Velocite No.10 oil. This effect diminishes for downward inclined orientations and is reversed for an inclination of -5°. In OLGA it is possible to easily vary for example the geometry of the pipeline and show the effect on the two-phase flow. Discrepancies were found, however, when the flow was evaluated around the 0° inclination angle. Small deviations from this angle of inclination gave significantly different results. For the 0° to 90° range of inclinations, and a superficial velocity of 0.1 m/s, the transition zone between stratified flow and mixed flow was established to be in a range of 7.5° to 20° relative to the horizontal plane. Either decreasing or increasing the inclination angle from this point is beneficial to the flushing process. Apart from the increased understanding of the flushing process summarised above, the data collected on the flushing process under various sets of conditions can be used to validate models for predicting oil flushing processes.","Flushing; Oil-water; pipelines","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Energy, Flow and Process Technology","",""
"uuid:da2b082f-ad62-4b54-b3d1-23b79248a5bd","http://resolver.tudelft.nl/uuid:da2b082f-ad62-4b54-b3d1-23b79248a5bd","Damage assessment of highly-loaded low-speed roller bearings with acoustic emission monitoring: A full-scale laboratory evaluation","Thakoerdajal, Nitesh (TU Delft Mechanical, Maritime and Materials Engineering)","Pahlavan, L. (mentor); Scheeren, B. (mentor); Smit, A. (mentor); Walters, C.L. (graduation committee); Sietsma, J. (graduation committee); Delft University of Technology (degree granting institution)","2022","Highly-loaded low-speed roller bearings are frequently used in equipment offshore e.g. slew bearings in crane, sheave bearings and FPSO turret bearings. Reducing maintenance costs, increasing productivity, ensuring safety of people and structural integrity and longevity assurance of equipment can be achieved by the condition monitoring of highly-loaded low-speed roller bearings.<br/><br/>Currently, very limited research is performed in the field of condition monitoring with acoustic emission (AE) monitoring for highly-loaded low-speed (&lt;10 rpm) bearings with naturally developed damage. Acoustic emission monitoring has shown promising results in early stage and real time identification of defects according to literature. Furthermore, contamination of wear particles in lubricant shows an increase in AE activity according to literature.<br/><br/>In this research, the applicability of AE monitoring for damage assessment of highly-loaded low-speed roller bearings is investigated in a full scale duration test. Furthermore, the influence of contaminated lubricant with steel particles is investigated in the contamination test to study the feasibility of real-time detection of contaminated lubricant during operations and as a supporting technique for wear debris analysis in lubricant.<br/><br/>From the results, an increase in AE activity expressed in hit-rates is observed for a wide frequency band of 40 - 580 kHz during the duration test where the basic rating lifetime (L10) is consumed from 40% to 50%. Wear development in the bearing is observed during visual inspection and has been quantified with lubrication analysis.<br/>A safety limit and a limit if the bearing is at risk for the AE activity has been defined with the results of the baseline and duration test. This research suggests that AE monitoring can be applied on highly-loaded low-speed bearings to assess the damage for representative operational conditions.<br/><br/>From the results of the lubricant contamination test, an increased AE activity with respect to higher lubricant contamination levels were observed. Furthermore, with a proper choice of the SNR-level, there is no masking effect of acoustic emission signals due to contaminated lubricant. The results of the contamination tests, indicates the possibility of detecting contaminated lubricant with AE monitoring.","Acoustic Emission; Condition monitoring; Predictive Maintenance; Highly-loaded; Low-speed; Bearing; Contamination; Structural Health Monitoring (SHM)","en","master thesis","","","","","","","","2024-02-28","","","","Offshore and Dredging Engineering | Structural analysis and design","",""
"uuid:3f287ebd-7389-4235-b8b4-73c7859d9aff","http://resolver.tudelft.nl/uuid:3f287ebd-7389-4235-b8b4-73c7859d9aff","Catalyzing collaboration for the future of food: A service proposition to accelerate sustainable innovation in the food value chain","Nguyen, Ynhi (TU Delft Industrial Design Engineering)","Mooij, S.C. (graduation committee); Bluemink, R.G.H. (mentor); Delft University of Technology (degree granting institution)","2022","As the world’s population is constantly growing, there is increased pressure on agricultural food value chains to deliver sustainable food production, distribution, and consumption, forcing core stakeholders in the food value chain (FVC) to change to meet those needs. One of the most significant barriers is a lack of collaboration, which risks staying in a dynamic of incremental innovation, whereas increasing sustainability requires radical innovations and innovative design. A positive chain interdependence can be the key to accelerating sustainable innovation. However, due to the complexity of chain configurations and collaboration models, a lack of interdependence among FVC stakeholders is observed. A holistic chain approach is missing in academic literature to solve that. Furthermore, there is ignorance of stakeholder motives and roles to collaborate. Hence, the first part of this thesis is to solve this literature gap by researching the drivers, barriers, and roles of stakeholders in the FVC collaborating for sustainable transformation. The research results in several outcomes, whereas the lack of trust, leadership and a conservative mindset are the most significant barriers. This project is conducted in close collaboration with Accenture, which wants to position itself in the agri-food industry as a stronger partner, accelerator, and orchestrator for sustainable transitions and innovation ecosystems. Therefore, the overall research question is: How can Accenture accelerate sustainable innovation through stakeholder collaboration in the food value chain? The found barriers are amended into needs where Accenture can play upon to bridge the gap from the research into a potential service the company can offer to the FVC. The final concept is designed for Accenture’s Food of the Future (FotF) capability, which has overlapping ambitions and interests as this thesis aims. The challenge lies in the explore phase, where core stakeholders find it difficult to anticipate their role, incentive, and vision before collaborating with others. Hence, the final deliverable is a service proposition for Accenture that helps the company to get insights into the core stakeholders' values and needs to guide them towards a future-oriented mindset. The designed proposition consists of several elements and is based on the existing participatory backcasting framework and the FutureEquity method of Van Berlo. A blueprint shows three phases: explore, envision, and engage, focusing on the interplay between Accenture and the targeted stakeholder. A redesigned toolkit guides the consultants in creating new content and future scenarios that catalyses the thought process of the stakeholder by exposing the possibilities and dead ends of sustainable innovation on the supported platform. The core stakeholder gets the chance to react, whereas Accenture uses that data to create engagement and traction for a potential innovation ecosystem. Lastly, a roadmap presents the required steps to implement the service successfully into the company. The steps consist of laying down a proper foundation, then launching it for current clients (B2B), whereafter the service becomes a separate entity that reaches core stakeholders (B2B2C). Combining all elements creates a unique proposition for Accenture to catalyse existing and potential FVC clients in the agri-food industry to accelerate sustainable innovation.<br/><br","Sustainable innovation; Food Industry; Future scenarios; multi-stakeholder; Corporate Innovation; Collaboration; service approach","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:a38b4cae-fe24-434c-94cf-76ee57cc2639","http://resolver.tudelft.nl/uuid:a38b4cae-fe24-434c-94cf-76ee57cc2639","On the surface interaction between Cylindrotheca fusiformis and aerospace aluminum alloys","Zalman, Sèra (TU Delft Aerospace Engineering)","Garcia, Santiago J. (mentor); Nijemeisland, M. (graduation committee); Rans, C.D. (graduation committee); Brussaard, Corina (graduation committee); Delft University of Technology (degree granting institution)","2022","Microbes, and the biofilms they form on surfaces, generally have a negative impact on performance. Well­-known examples are the increase of drag in ships and pipes, and the accelerated corrosion of metallic structures known as MIC. Among microbes, diatoms form a large unicellular algae group known to play a relevant role in the first stages of biofilm formation. Diatoms are well-­known for their species­-dependent silica exoskeletons, but they also produce, as other microbes, extracellular polymeric substances (EPSs) that may offer opportunities for the development of novel bio­based surface treatments. In this work we studied the interaction between a marine diatom species named Cylindrotheca fusiformis and aerospace aluminum alloys as a first step towards novel surface protection treatments of aircraft structures.<br/><br/>Two routes were followed to study the interaction of C. fusiformis with aluminum alloys after studying diatom population growth. The first route focused on the biofilm formation on aluminum 99.5%, AA20204-­T3 and AA7075­-T6 to study the effect of surface composition. The effect of the surface preparation (degreased vs. polished) was then studied with AA2024­T3 substrates. The second route focused on the study of diatoms’ motility on aluminum 99.5% and AA2024-­T3 with various surface pretreatments. In this work, a number of characterization techniques such as FTIR, SEM/EDS, Raman spectroscopy and image correlation techniques were used.<br/><br/>It was found that C. fusiformis forms well­-adherent biofilms on all aluminum substrates, independently of the surface composition and surface pre­treatment. Nevertheless, the biofilms appeared to be most homogeneous on AA7075­T6, while the EPS layer was more homogeneous on aluminum 99.5%<br/>and AA2024­T3. The motility studies showed that C. fusiformis lowers its surface motility rapidly when on aluminum 99.5% until cells stop being motile. On AA2024­T3, cells maintain their motility for longer periods of time. The motility dependency on surface chemistry is hypothesized to come from speciation dependent aluminum toxicity. Post­mortem chemical analysis of the exposed surfaces showed traces of organic material in the form of proteins and carbohydrates attributed to displacement trails. The results confirm that monocultures of C. fusiformis are able to generate biofilms on aerospace aluminum alloys and release water­ insoluble organic matter on the surface. The promising results here obtained pave the way for more dedicated research to understand the relationships between surface chemistry and topology, and diatom motility and biofilm formation and composition.","bio-based material; diatoms; aluminum coating","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:b4f4f48c-7719-48fc-97c1-909dbedef340","http://resolver.tudelft.nl/uuid:b4f4f48c-7719-48fc-97c1-909dbedef340","Techno-economic evaluation of energy markets for demand response and congestion management in future decentralized energy systems","Leal Jauregui, Pedro (TU Delft Electrical Engineering, Mathematics and Computer Science)","Chandra Mouli, G.R. (mentor); Vermeer, W.W.M. (graduation committee); Delft University of Technology (degree granting institution)","2022","In the context of the energy transition, the energy sector is experiencing a paradigm shift towards electrification in a decentralized model, where renewable energy sources are becoming the protagonists. However, such shift comes with several challenges. In particular for this thesis, the intermittency of renewable energy sources coupled with increased load demand and generation from small scale prosumers is expected to increase grid congestion at a distribution level.<br/>The main purpose of this thesis is to investigate and evaluate the techno-economic feasibility of novel market mechanisms that incentivize demand response from prosumers for congestion management. The focus of this work is on market-based mechanisms that use economic signals to stir prosumers' demand response. The mechanisms investigated are: 1) hard constraint that physically limits prosumers, 2) capacity subscription, 3) peak tariff, and 4) dynamic tariff; these are capacity mechanisms that limit the peak drawing and feeding power from prosumers. Moreover, the day ahead, intraday and frequency containment reserve (FCR) markets are incorporated to the capacity mechanisms to evaluate their compatibility in the context of the Dutch power markets.<br/>The advent of smart energy systems enables prosumers to become active participants in the market and aid in the grid's management. Thus, the approach of this thesis is to simulate prosumers' response to economic signals and evaluate the effects in a low voltage test feeder. To achieve this, the work develops on an existing smart charging algorithm that optimizes the components of the smart energy system. The system is composed of a multi port converter that incorporates a PV maximum power point tracking device (MPPT), a bidirectional EV charger, and a bidirectional battery energy storage (BES) charger; additionally, the grid is connected to a heat pump and load from appliances, which are non-flexible. The distribution network is IEEE's European low voltage test feeder, which is comprised of 55 households.<br/>The techno-economic feasibility evaluation is done by benchamarking the capacity mechanisms against an energy tariff in two scenarios: winter, and summer. The benchmark results indicate that aligning prosumers with only an energy tariff leads to congestion in the feeder. In response, all capacity mechanisms evaluated were effective at managing congestion if properly designed, although, some restrict prosumers more than others. The hard constraint made prosumers lose the most load, and the total cost incurred by the prosumers in the feeder was greatest with the capacity subscription. The peak tariff had the lowest cost of lost load, and the least overall costs, consequently, the peak tariff was chosen to incorporate the day ahead, intraday and FCR markets to it. The incorporation of day ahead and intraday markets decreased the exposure to imbalance costs under the assumption that new forecasts with better accuracy were available one time step (15 min) before delivery. <br/>The incorporation of FCR increased the exposure to imbalance costs due to deviations from the day ahead schedule. Furthermore, FCR with the peak tariff showed conflicting incentives, i.e., the peak tariff reduces the amount of reserved power for balancing regulation, else if full available power is reserved congestion increases. The results of this thesis point towards the potential that prosumers' demand response will have in shaping future decentralized energy systems, however, the market mechanisms in place need to be properly designed to ensure economic feasibility and resolve conflicting incentives between markets such as balancing and local congestion management.","Demand Response; Smart Grid; Capacity Mechanism; Energy Market; Optimization Algorithm","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:4ac5c33f-efa4-47d3-b06e-d49110016890","http://resolver.tudelft.nl/uuid:4ac5c33f-efa4-47d3-b06e-d49110016890","Digital Soil Mapping based on PDFs of Cone Penetration Tests and Vibro Cores using Image Processing and Machine Learning","Ordeman, Sam (TU Delft Mechanical, Maritime and Materials Engineering)","van Rhee, C. (mentor); Talmon, A.M. (mentor); Soleymani Shishvan, M. (mentor); Nuttall, Jonathan (mentor); Pisano, F. (graduation committee); Delft University of Technology (degree granting institution)","2022","Digital Soil Mapping (DSM) of soil types in geotechnical project areas is a top priority. These maps are often used in decision making and can have significant consequences related to costs and risks. Usually, these maps are generated by digital soil models that interpolate soil types at known locations. In practice, conventional spatial interpolation techniques are still often used for DSM of soil types, such as inverse distance weighting and kriging. However, conventional models are not well suited for predicting or interpolating soil types because of their inability to deal with categorical data properly. Besides, the design of the conventional models does not allow for incorporating the abundance of meaningful covariate information that is available nowadays. The flexibility of machine learning algorithms vanquish both problems and has become increasingly popular for DSM of soil properties in recent years. The results of machine learning techniques for DSM of soil properties are promising and generally outperform conventional models. However, few studies have used machine learning for DSM of soil types and is therefore still a relatively unknown field. Moreover, at the time of writing, there are no studies that use sequence models for DSM of soil properties or types. Hence, the author proposes to introduce a new method for DSM of soil types, namely a Long Short-Term Memory (LSTM) network. The intuition behind this introduction is that the spatial correlation can be captured in sequences and can improve soil type prediction. <br/><br/>Real project data from a cable burial project is used to evaluate and compare the performance of the conventional interpolation methods triangulation and kriging, the machine learning models random forest and XGBoost, and the newly proposed deep learning model LSTM. The project data consist of 757 vibro cores (VC), 718 cone penetration test (CPT), bathymetry data and sub-bottom profilers. The geotechnical data, i.e. VCs and CPTs, is received on separate PDF pages that require to be digitized first. This thesis describes a simple yet precise manner to extract this data from the PDFs. The VCs and CPTs are provided with a soil type interpretation and can be used directly for developing the models. The data is split into a training set to develop/train the models and a test set for evaluation. Ultimately, the best performing model is used to build a 3D stratigraphic soil model for the project area with associated prediction accuracies.<br/><br/>All state-of-the-art techniques outperform the conventional models and especially in predicting minority classes. The best performing model is random forest with an overall accuracy of 85.44\% and is comparable to the performance of XGBoost of 85.11\%. LSTM network achieved a slightly lower accuracy of 84.27\%. The results show that LSTM is suitable for DSM of soil types and has considerable potential for improvement as only a few possibilities of the model have been examined.","Digital Soil Mapping; Machine Learning; Deep Learning; Spatial Interpolation; Image Processing; LSTM; Random Forest; XGBoost; Kriging; Trenching","en","master thesis","","","","","","","","2024-02-28","","","","Offshore and Dredging Engineering","",""
"uuid:24ecc498-4e3c-4c3f-8382-9d8c34778afb","http://resolver.tudelft.nl/uuid:24ecc498-4e3c-4c3f-8382-9d8c34778afb","Developing a method to include flood defenses explicitly in flood hazard maps based on limited available information","Jilesen, Vince (TU Delft Civil Engineering & Geosciences)","Jonkman, Sebastiaan N. (mentor); Ragno, E. (mentor); Hoes, O.A.C. (mentor); van Ledden, Mathijs (mentor); Delft University of Technology (degree granting institution)","2022","Flooding is one of the most damaging natural disasters worldwide, and presents a signi_cant risk for a large amount of the global population. For the development of ood disaster management strategies, policy makers make use of ood hazard maps to inform investment strategies to reduce risk. In many current ood hazard mapping methods, the role of embankments is either implicit or completely unaccounted for. However, these defense systems can play a key role in both the _nal extent of the inundation as well as in the development of the inundation. Limitations in available data are often the reason for the lack of explicit implementation of embankments. The goal of this study is the development of a method that can explicitly include the e_ects of ood defenses in a ood hazard map based on limited available data. Next, this has been tested for a low-lying riverine area and the Tisa river basin in Serbia was selected as a case study area for this purpose. First, an idealized approach has been followed to better understand the model behavior using settings resembling this river. Finally, the method has been applied with a more realistic river schematization. <br/>To develop a method for a more explicit inclusion of ood defenses, an understanding of the di_erent current approaches has been generated based on a literature review. On the scale of global ood maps, the failure probabilities of ood defenses are not used. Only with post-processing, certain areas are considered protected by removing inundation from the maps. Many studies of ood hazard mapping use the so-called bathtub approximation. Hereby is assumed that the complete oodplain will ood and that the inundation depth is found by extrapolating the water surface level outside of the embankments to the area inside of the embankments. The inuences of the ood defenses on the inundation are not included. Regional ood hazard maps are still made without ood defenses in many cases. While the improved resolution allows for more detailed maps, the lack of available data still limits the implementation of ood defenses. Flood mapping methods exist that include failure probabilities for ood defenses but these require large amounts of data that is not available everywhere. <br/>An idealized model based on the Tisa river characteristics is used to test a ood mapping method which includes explicitly the presence and potential failure of embankments. Based upon data on the river geometry, hydraulics as well as land-use in the oodplains, a model schematization has been set up with the SOBEK software. The embankments were simpli_ed to a crown height for the purpose of overow and an estimated failure probability. The breaching of the levee is simulated according to the Verheij-vdKnaap breach growth model. The estimation of the failure probabilities was based on historical failure rates of a comparable ood defense system along the Elbe River. The levees were schematized into segments based on the maximum breach width of the breaching model…<br","Flood Defence; flood hazard management","en","master thesis","","","","","","","","","","","","Civil Engineering | Hydraulic Engineering","",""
"uuid:68fe1326-36b2-4eec-b11b-2f3915d1aa07","http://resolver.tudelft.nl/uuid:68fe1326-36b2-4eec-b11b-2f3915d1aa07","Feasibility study for Dechlorination of mixed plastic waste streams","Versteeg, Kyle (TU Delft Mechanical, Maritime and Materials Engineering)","de Jong, W. (mentor); Delft University of Technology (degree granting institution)","2022","This report explored the feasibility of dechlorination of mixed plastic waste systems using a low-temperature pyrolysis process. Decomposition of plastics into chlorides is of interest due to the damage these can pose to both the process system, products, and the environment. Therefore, dechlorination of mixed plastics waste streams is essential to remove detrimental chlorides before entering the processing stage. Relevant literature presents that chloride is found in PVC in plastic mixtures, which decomposes two stages; a dechlorination step below 330 0C and then a thermal decomposition of the hydrocarbon chain. This is due to the weaker C-Cl binding energy present in the molecule. Hydrochloride gas is produced from PVC as a result of dechlorination at temperatures below 300 0C. DKR 350 is a plastic mixture that is studied in this report, and this plastic waste stream can contain approximately 0.2-5% PVC. The process of dechlorination of plastic wastes is investigated in this report. As a result of understanding the parameters required to remove chlorides from a mixed plastic waste stream, an experimental setup was created to examine the viability of the process. The results were analysed and compared with relevant literature on PVC degradation to assess its efficiency. Overall, the methodology established by this report was unsuccessful in producing a practical result. However, the viability of the dechlorination process in mixed plastics wastes has been shown as a result of the 84.9% conversion of chlorides in the plastic from the initial mixture to other sources. As a result of this positive indication of the viability of the process, further testing was recommended based on lessons learned from the current report. Further, an improved test setup was suggested based on several recommendations explored as a result of findings from the experimental.","","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Process and Energy Technology","",""
"uuid:cbdfa26a-0eb9-4cbf-81fa-2fe6cbbcfe0b","http://resolver.tudelft.nl/uuid:cbdfa26a-0eb9-4cbf-81fa-2fe6cbbcfe0b","Long-Term Collaboration Process During the Lifecycle of Circular Building Components for Housing Retrofit: Mapping the collaboration process for the case of circular extension","Voglis, Stefanos (TU Delft Civil Engineering and Geosciences)","Jonkers, H.M. (mentor); van Stijn, A. (mentor); van Bortel, G.A. (graduation committee); Luoma, Tuuli (graduation committee); Delft University of Technology (degree granting institution)","2022","Nowadays, the built environment of the Netherlands is making the transition from the linear to circular economy to meet the goals set by the European Union and the Dutch government of 50% circular economy by 2030. However, there is limited knowledge in the built environment for circular economy projects. In order to generate knowledge on the topic, organisations partner up to complete a project. One of the most important aspects of such partnerships between a variety of partners is collaboration. Successful collaboration between partners is crucial for the partnerships to succeed. However, the built environment is a highly fragmented sector which inhibits collaboration. Furthermore, it is unclear how the long term collaboration process would look like in the context of the circular retrofits. The REHAB project is such a case of partnership between organisations, which develops two circular components for housing retrofits, the circular skin and circular extension. This research develops three process maps to understand if it is possible to create a feasible and useful long-term collaboration process for the development and implementation of the circular extension product.<br/>In order to identify the existing knowledge gap in the academia, a literature review was conducted by analysing circular economy projects, circular economy products and by identifying differences between the practices. Comparing the findings, the gap was identified on the end part of the project lifecycle.<br/>To fit the innovative characteristic of the research, the “Research through Design” (Rtd) methodology is chosen, where possible future scenarios in the form of design variants are simulated. During the first step of RtD (analysis), the design parameters and requirements were identified, as well as the main key factors of collaboration in the context of circularity. This identification happened through a literature review and informal interviews with partners of the circular extension. This determined the parameters of the design variants and the requirements that the design variants have to fulfil. During the next step (synthesis), the three variants were identified and the long term collaboration process variants were designed. Based on this information, three design variants were developed (traditional, balanced, innovative). The third step (simulation) involved presenting the design variants to partners of the circular extension in a semi-structured interview format. The answers of the interviews were analysed in order to derive learnings, where the goal was to evaluate the feasibility and usability of the long-term collaboration process design variants. During the last step (validation) the researcher employed the help of former fellow students that have conducted similar researches using RtD to guarantee the scientific validity of the research. <br/>The analysis of the answers collected during the interviews showed clearly that the balanced design variant is the most feasible collaboration process currently and the innovative as the most promising variant for the future. The traditional design variant was deemed not feasible. Furthermore, trust and communication are the core characteristics of a long term collaboration. Another conclusion is that the most important design parameter for the long term collaboration process is the business model, since both client and contractor are highly interested in the financial incentives. The most important lesson derived by the answers of the partners suggest that currently it is still too early to establish a clear collaboration process path for the stakeholders that will take place in ten to twenty years. The research provides valuable information to stakeholders of the circular extension on how to improve circularity through establishing successful collaboration and the steps to guide the collaboration. Moreover, the research provides a good base for future researches to be conducted on the topic of long term collaboration strategy. The difference being that a strategy can be more adaptive for future partners than the rigid guides of a process. Furthermore, it is concluded that countries with high regulated housing sector can adapt to circular economy practices and create successful collaboration easier than countries with a free market.<br","Collaboration; Circular Economy; Built Environment; Long-Term; Circular building components","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:ef44ea11-a9b4-415d-97be-51d38380a3a5","http://resolver.tudelft.nl/uuid:ef44ea11-a9b4-415d-97be-51d38380a3a5","An experimental study on flared folding wingtips: Effects of wing stiffness, aeroelastic tailoring and hinge release threshold on gust load alleviation performance","Carrillo Córcoles, Xavier (TU Delft Aerospace Engineering)","Sodja, J. (mentor); Mertens, C. (mentor); Sciacchitano, A. (mentor); van Oudheusden, B.W. (mentor); De Breuker, R. (mentor); Delft University of Technology (degree granting institution)","2022","The flared folding wingtip (FFWT) is a concept presented by Airbus to increase the aerodynamic efficiency and provide a means of load alleviation. A gate-to-gate demonstration of this concept has already been presented with the AlbatrossONE, a scaled aircraft featuring the FFWT concept. In this demonstration, the aircraft fold the wingtips during taxiing to fulfil gate requirements and extends it before take-off for improved efficiency. In addition, they can be released during flight to provide load alleviation and reduce the roll rate reduction caused by the increase in the wingspan. The objective of this thesis is to further study the FFWT concept.<br/><br/>An aeroelastic wind tunnel experiment to identify the influence of the wing stiffness and hinge release threshold on the gust load alleviation performance of a folding wingtip design is presented in this study. Five models with different stiffness and tailoring properties are tested and the wing root bending moment at different conditions is compared to the response with locked hinge conditions to assess the impact on the gust load alleviation capabilities of the folding wingtip. <br/><br/>The results show that the structural properties do not have an important impact on the peak load alleviation but the hinge release threshold and timing do. Releasing with the correct timing can reduce significantly the peak loads. However, the dynamics of the system are affected by this release: the flutter speed is decreased and, although the performance can improve, load oscillations increase, which can be considered detrimental for reasons such as fatigue.","aeroelasticity; folding wingtip; gust load alleviation","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:e03948bf-f6b2-487b-9414-d214824cd930","http://resolver.tudelft.nl/uuid:e03948bf-f6b2-487b-9414-d214824cd930","Control analysis of an active inference controller for a skid-steer mobile robot: An analysis on the performance of the active inference controller focusing on convergence time","van der Meer, Bob (TU Delft Mechanical, Maritime and Materials Engineering)","Wisse, M. (mentor); Vatsyayan, A. (mentor); Delft University of Technology (degree granting institution)","2022","Active Inference control is a novel control method based on the free energy principle, which combines action, perception and learning [1][2]. The first Active Inference controller showed promising results on a 7-DOF robot arm for a pick and placing task, however it took nearly six seconds to converge which is too slow [2]. This thesis aims to reduce the convergence time of an Active Inference controller. Therefore an Active Inference controller that is used to control the velocity of a Jackal robot was developed. It was compared to the standard differential drive Controller and it was found that the standard controller outperformed the Active Inference controller on both rise and settling time. A state space model was derived to obtain a better understanding of the Active Inference controller, for this model the robot was modelled as a point mass. This assumption was confirmed by a step response test of the robot, placing it both on the box and on the ground. It was found that both behaved similar, and thus the wheel ground interactions and internal dynamics of the robot did not affect the convergence time. The state space model was used to find three methods to reduce the convergence time of the Active Inference controller. As a first method the update frequency of the entire controller was increased, for the second method only the update frequency of the inner belief update loop was increased. The last method used an increased update frequency of the belief update loop and the parameters of the system were tuned. The methods were tested using step response tests and a square wave test, first in a simulated Gazebo environment and later with the actual robot. It was found that the third method reduced the converging time of the Active Inference controller, and reduced it from 0.88s to 0.51s. The improved controller was also tested against the differential drive controller outperformed it. It was found that due to the increased update frequency the tuning parameters could be changed to a wider range of values, this resulted in a shorter convergence time.","Active Inference; Skid-Steer Mobile robot; Active inference control; Convergence time","en","master thesis","","","","","","","","","","","","Mechanical Engineering","",""
"uuid:468e1b32-dd42-4190-83cb-206c78ea3191","http://resolver.tudelft.nl/uuid:468e1b32-dd42-4190-83cb-206c78ea3191","Comparing sEMG to estimated muscle force for the thumb muscles in the Delft Hand and Wrist model in OpenSim","Greveling, Stan (TU Delft Mechanical, Maritime and Materials Engineering)","Mugge, W. (mentor); Geelen, J.E. (graduation committee); Delft University of Technology (degree granting institution)","2022","The Delft Hand and Wrist model is a recently created musculoskeletal model in the OpenSim environment. The current model lacks a validation of the thumb muscles. Therefore, the main goal of this work is to perform a quantitative trend validation by analyzing the correlation between experimentally measured muscle activity data and muscle forces estimated by the model from markerless motion capture data. The original model is reduced to a minimal model containing only the thumb muscles. A second model is created by changing optimal muscle fiber length, maximum isometric force and tendon slack length parameter values in the minimal model to values reported in literature to evaluate the effects of these adjustments on the estimated muscle force. An experiment is conducted in which participants are instructed to perform repetitive thumb motions while muscle activity and 2D kinematic data is captured. 3D kinematics are obtained through the machine learning toolboxes DeepLabCut and Anipose. Muscle forces are estimated through inverse dynamic static optimization in OpenSim. The results showed that the correlation between the estimated muscle forces and experimentally measured muscle activity data for both the minimal model and the adjusted model was very low to moderate, meaning both models yield unrealistic muscle force estimations. In contrast, the measured muscle activity and kinematic data show expected results thus are captured correctly, which is useful for reference in future work. <br/>There is room for improvement of the Delft Hand and Wrist model. Nevertheless, this work provides suggestions for the optimization of the current model and paves the way towards muscle force estimation and quantitative validation using experimentally measured muscle activity data for the Delft Hand and Wrist model in OpenSim.","Inverse Dynamics; Muscle Force Estimation; Musculoskeletal Model; OpenSim; Static Optimization; Surface EMG; Thumb Kinematics; Thumb Muscles; Validation","en","master thesis","","","","","","","","","","","","","",""
"uuid:6996ab9f-cc04-4ef7-92e5-4f9399afaf4f","http://resolver.tudelft.nl/uuid:6996ab9f-cc04-4ef7-92e5-4f9399afaf4f","Reducing the environmental impact of syringes in the Intensive Care Unit","Honkoop, Margot (TU Delft Industrial Design Engineering; TU Delft Sustainable Design Engineering)","Balkenende, A.R. (mentor); Albayrak, A. (graduation committee); Hunfeld, Nicole (graduation committee); Delft University of Technology (degree granting institution)","2022","This graduation project focused on reducing the environmental impact of syringes on the Intensive Care Unit (ICU) of Erasmus University Medical Centre (MC) by designing solutions based on circular economy.<br/><br/>The ICU of Erasmus MC produces an excessive amount of waste and initiated the transition towards a circular ICU. Syringes and their packaging are defined as an impact hotspot product at the ICU, due to the product properties, extensive use (24 per patient per day), and the fact that it is a single-use disposable product. The underlying problem of the high environmental impact of syringes is the current linear life cycle. This needs to be transformed into a more circular system by design, to limit the amount of waste and to reduce the use of natural resources.<br/><br/>The goal of this project was therefore to redesign the syringes, their packaging and their use, according to circular design strategies suitable for medical products, to decrease the environmental impact. The use of syringes should remain convenient and safe for the healthcare staff and patients.<br/><br/>Research was executed to understand the context. This consisted of literature, user and product research. Furthermore, a waste audit and a life cycle analysis were performed. It showed that decreasing the impact of syringes is not only about the product itself. Manufacturing, preparing, using and disposing of all contribute to the environmental impact of the syringe. Various possible interventions were derived from this research.<br/>Firstly, adapting the infection prevention protocol and behaviour of the staff could lead to a decrease in unused disposed syringes.<br/>Secondly, separating infectious waste from general hospital waste properly could result in opportunities for recycling.<br/>Thirdly, the syringe itself can be redesigned to reduce the impact by changing the material to a sustainable alternative and redesigning the shape for (partial) reuse.<br/>Lastly, the impact of the filling process could be reduced. It was concluded from research that prefilled sterilised syringes (PFSS) are more environmentally friendly than manually filled syringes because they are produced in large batches and, therefore, have fewer by-products per syringe. However, a life cycle analysis of the filling process of PFSS showed various impact hotspots in this filling process, such as the sterilisation phase, materials used, and left-over medication.<br/><br/>The final design is a process optimisation for batch-produced PFSS, based on circular strategies such as reduce, reuse, rethink and repurpose. Interventions include: eliminating the first sterilisation phase, reduce left-over medication and change from steam to gamma sterilisation. The proposed interventions have been evaluated by discussion.<br/><br/>In the end, the environmental impact of syringes is reduced by optimising the filling process, which resulted in decreasing the amount of waste, material, energy and water usage, while remaining safe and without increasing the workload of the staff of the ICU.","syringe; Circulair economy; Intensive Care Unit","en","master thesis","","","","","","","","","","","","Integrated Product Design | Medisign","",""
"uuid:6644f3b4-818c-40a6-8927-e66ead02d4d2","http://resolver.tudelft.nl/uuid:6644f3b4-818c-40a6-8927-e66ead02d4d2","Data driven modeling of junction flows","Vigner, Geneviève (TU Delft Aerospace Engineering)","Dwight, R.P. (mentor); Delft University of Technology (degree granting institution)","2022","A wall resolved LES simulation of the Anti-Fairing wing/body junction introduced by Belligoli et al. [6] to reduce interference drag is performed. The LES mesh is composed of 61.7 million cells with a C-fitted grid around the wing . The simulation is performed using the pimple solver of Open- Foam 4 with a time and space varying inlet boundary condition obtained thanks to a precursor. This simulation will be used to assess the impact of the Anti-Fairing by comparing the result to the wall resolved baseline case of Alberts [2] and to serve as a training data for data driven techniques applied to junctions flows. Using the wall resolved LES we apply the data driven algorithm method Sparse Regression of Turbulent Stress Anisotropy (SpaRTA) developed by Schmelzer et al. [38] in the case of junction flows. It is shown that the first step of the method, namely the k-corrective frozen RANS, is able to produce corrective fields to the Reynolds tensor and the turbulent kinetic energy equations in this case. The corrective fields once added in a k-omega SST simulation make it possible to obtain the exact location, strength and shape of the main horseshoe vortex. The upstream boundary layer is also subject to corrections indicating RANS-LES mismatch in the inflow. Mutual Information (MI) is calculated to identify the relevant tensors, physical features and invariants that correlate with the junction flow data. Finally, algebraic models for the corrective fields are obtained. They are compared to the true values of these fields. It is possible to see that the performance of SpARTA models is good upstream of the wing. However, models found and tested in the vicinity of the wing, where the separation and horseshoe vortex are located, are not fully able to capture the relevant corrections. Additional constraints or steps to the ones performed in the time of this study may be necessary in order to use SpaRTA to generate models giving improved predictions compared to classic RANS turbulence models.","LES; Junction flows; Data-Driven","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:bc45f804-6cd8-4a6b-ae2f-8bd59c9b316b","http://resolver.tudelft.nl/uuid:bc45f804-6cd8-4a6b-ae2f-8bd59c9b316b","MD-Honeypot-SSH: Gathering Threat Intelligence Data during the SSH Handshake","de Jonge, Bart (TU Delft Electrical Engineering, Mathematics and Computer Science)","Verwer, S.E. (mentor); Delft University of Technology (degree granting institution)","2022","With the amount of network connected devices every increasing, and many of them running the Secure Shell (SSH) protocol to facilitate remote management, research into SSH attacks is more important than ever. SSH honeypots can be used to act like vulnerable systems while gathering valuable data on the attacker and its methods in the meantime. The SSH handshake is a currently undervalued asset in these honeypots as a lot of data is already exchanged in this early part of the protocol. In this thesis we propose the MD-Honeypot-SSH framework that can be used to gather threat intelligence research data on the SSH handshake. We show the design choices made in the development of the framework and consider which data is useful to collect in the SSH handshake for future research. As part of the framework we modify an existing OpenSSH implementation to allow us to log any relevant branching decisions made in the server. We then use this logging data to create state machines of the server behaviour while handling a specific connection. We use these state machines to compare different connections and show, as a proof of concept, that we can group these connections based on the used client. The main contribution of this thesis is to provide the MD-Honeypot-SSH framework as a tool to future research, and we provide some recommendations for future research directions.","SSH; Honeypot; Threat Intelligence; SSH Honeypot","en","master thesis","","","","","","","","","","","","Computer Science | Cyber Security","",""
"uuid:dd13952c-bead-4721-ad40-885f51de94af","http://resolver.tudelft.nl/uuid:dd13952c-bead-4721-ad40-885f51de94af","Unraveling Flashback Phenomena of Turbulent premixed Hydrogen-Natural Gas-Air Flames","Willems, Gersom (TU Delft Mechanical, Maritime and Materials Engineering)","Klein, S.A. (mentor); Tummers, M.J. (mentor); Roekaerts, D.J.E.M. (graduation committee); Altenburg, L.A. (graduation committee); Delft University of Technology (degree granting institution)","2022","The growing energy demand and climate change poses a need for alternative energy generation in terms of renewable resources. Renewable energy resources are characterised by their intermittent behaviour. A backup power supply is required that can deliver electricity when the supply from the renewables is not sufficient. Gas turbines operating with hydrogen is an attractive option, since hydrogen combustion has zero carbon emissions and can be used as an energy storage when the supply of renewable energy sources are abundant. However, hydrogen combustion poses several challenges. A hydrogen flame has a higher flame temperature than natural gas, leading to more NO&#x1d465; production. To<br/>reduce these NO&#x1d465; emissions, gas turbines operate in lean premixed conditions. This creates a risk of flame flashback, in particular boundary layer flashback, which can lead to severe damage to the gas turbine. <br/>Recent research performed on boundary layer flashback revealed that two flame configurations, i.e. unconfined and confined, showed fundamentally different flashback phenomena. Unconfined flame flashback refers to the situation where an initially stable flame anchored at the burner rim eventually moves into burner tube. When a flame is partially of completely surrounded by walls and propagates and then starts propagation along the wall, it is called confined flame flashback. Previous studies have focused on one of the two flashback processes at a time. However, the transient flashback process between unconfined and confined flame flashback is not well understood. Research has shown that hydrogen is much more prone to flashback compared to natural gas. This has been attributed to the difference in flame speed between natural gas and hydrogen, but the exact reason for the difference in flashback behaviour between natural gas flames and hydrogen flames has yet to be found. <br/>In this study, a quartz Bunsen burner is used to investigate the flashback phenomena of turbulent premixed hydrogen-natural gas-air flames. To gain more insight in the flashback phenomena, three experiments have been performed. First, flashback maps are obtained to determine the flashback limits of the quartz Bunsen burner. Secondly, the influence of a flame on the flow was investigated using turbulent statistics. Finally, both unconfined and confined flashback are visualised, thereby capturing the transient flashback process between these two configurations. This has been done for a stoichiometric natural gas flame and a lean hydrogen flame. Laser diagnostics like Particle Image Velocimetry (PIV) and Miescattering are used to obtain the turbulent flow statistics and to visualize the instantaneous flashback process. The results show that regions with negative velocity fluctuations in the unburned mixture are the predominant physical mechanism for the start of unconfined flashback and for the transient flashback process of the flame propagating into the burner. However, the start of a flashback event depends on the combination of several parameters: the bulk velocity, the position of the flame front before it interacts with a region with negative velocity fluctuations, the magnitude of the negative velocity fluctuations and whether a region with positive velocity fluctuations is absent after interaction of the flame with the region consisting of negative fluctuations. So, unconfined flashback is rather a statistical phenomena, where the chance of the occurrence of a flashback event is increasing for a decreasing bulk flow velocity. Experiments showed that the transient process between unconfined and confined flashback is very short and fast. After a distance of approximately 5 mm upstream of the burner rim, a backflow region starts to develop in front of the flame, which denotes the start of confined flashback. The time needed for a natural gas flame propagating upstream from the burner rim to reach a confined configuration is approximately 17 ms and only 5.6 ms for the hydrogen flame. The suggested physical mechanisms leading from unconfined flashback to confined flashback are the convex shape of the flame towards the reactants during upstream flame propagation and the reduced cross-sectional flow area of the burned gases at the flame tip. Due to the created backflow in front of the flame and the abovementioned mechanisms, the upstream flame propagation is strongly enhanced, which explains why the flashback propensity for confined flames is much higher than for unconfined flames. The experiments showed that the hydrogen flame propagates closer to the wall than the natural gas flame, indicating higher backpressure effects. The hydrogen flame is thermaldiffusive unstable and the convex shape of the flame tip during flashback strongly enhances the local flame speed and thus the upstream propagation velocity. In contrast, the hydrodynamic instability encountered in the natural gas flame only retards the flow in front of the flame tip, but does not affect the flame speed. This might explain the difference in flashback behaviour between natural gas and hydrogen flames.","Hydrogen combustion; Flame flashback; Turbulent Flow; Premixed Bunsen flame","en","master thesis","","","","","","","","","","","","","",""
"uuid:3e95b60a-7477-41c9-abd0-2a032a97bcca","http://resolver.tudelft.nl/uuid:3e95b60a-7477-41c9-abd0-2a032a97bcca","Studies on the evaporation induced acoustic emissions from 3D-printed bio-inspired microfluidic vessels","Bieling, Thijs (TU Delft Mechanical, Maritime and Materials Engineering)","Dutta, S. (graduation committee); Verbiest, G.J. (mentor); Delft University of Technology (degree granting institution)","2022","Evaporation can induce acoustic emissions in microfluidic devices. The origin of these emissions and their damping remains elusive. This thesis studies acoustic emissions from 3D printed microfluidic tubes mimicking xylem vessels in plants. We show the time and frequency domain signature of these emissions. From these signatures, we identify three types of acoustic pulses. While the source of the first type remains elusive, the second type originates from our evaporative membrane and the third from slower events like microcracking. By varying the vessel's geometry, we observe that its frequency shifts down with increasing vessel radius and length for the second pulse type. We confirmed this behaviour using numerical simulations of the vessel. These findings provide new insights into evaporation induced acoustic emissions from microfluidic devices and, due to their similar morphology, xylem vessels in plants.","microfluidics; acoustics; 3D printing; evaporation; ultrasound","en","master thesis","","","","","","","","2024-02-25","","","","Mechanical Engineering","Plantenna",""
"uuid:4ef50596-46e7-452e-bae2-4148474cc25a","http://resolver.tudelft.nl/uuid:4ef50596-46e7-452e-bae2-4148474cc25a","Twist morphing concept based on buckling-driven technologies","Pereira, Andres (TU Delft Aerospace Engineering)","Bisagni, C. (mentor); Delft University of Technology (degree granting institution)","2022","A novel twist morphing concept is explored, that exploits the buckling instabilities of slender spar webs integrated into a wing structure to control the twisting response to external loads. The main novelty of the concept is in controlling the effective shear stiffness of the post-buckled slender spar webs through external variable constraints acting on the out-of-plane buckling deformations. A methodology for the design and analysis of these novel morphing structures is proposed and implemented in the design of a wing box structure of promising twist morphing capabilities. The overall design process is structured into a multilevel process of increased complexity. In the first level, the morphing structure is simplified to a wing box with slender spar webs. With the objective of maximizing the morphing twists that can be achieved under the action of an external quasi-static torque, the wing box design space is explored in terms of its cross-sectional dimensions and the material assigned to the slender spar webs. In the second level, the morphing structure is expanded to include both the wing box and the external devices required to implement the adaptive constraints acting on the slender spar webs' out-of-plane buckling deformations. At this level, the objective is to design adaptive constraining devices that maximize the twist morphing capabilities, for which the influence of the constraining devices over the twisting response and their effectiveness in restraining the slender spar webs' buckling deformations become the main concerns. After an extensive design process, a design solution for the adaptive constraining devices is proposed, for which thorough analyses on the twist morphing capabilities are performed. In addition, the sensitivity of the twist morphing capabilities to the slender spar webs' geometrical imperfections is investigated.","Morphing Wing; Twist Morphing; Buckling; Bilateral Constraints; Finite Element Analysis; Composite","en","master thesis","","","","","","","","","","","","Aerospace Engineering | Structures and Materials","",""
"uuid:931e9831-c93b-422e-ada1-8229b9fc9233","http://resolver.tudelft.nl/uuid:931e9831-c93b-422e-ada1-8229b9fc9233","A robust material for the production of microfluidic liquid-liquid extraction chips: Evaluation of a robust ALD coating to reduce irradiation-induced surface modifications on polymers and quartz for the usage of microfluidic liquid-liquid extraction chips","de Jong, Rémy (TU Delft Mechanical, Maritime and Materials Engineering)","Santoso, A. (mentor); van Ommen, J.R. (mentor); de Kruijff, R.M. (mentor); Picken, S.J. (graduation committee); Delft University of Technology (degree granting institution)","2022","Microfluidic extraction is a promising alternative for existing extraction methods of radioisotopes due to the high surface-to-volume ratio. When assessing the compatibility of microfluidic material with the extraction system, there are three critical aspects—compatibility with organic solvents, compatibility with the radiochemistry, and, most importantly, the resistance to radiation-induced damage. Resistance to radiation-induced damage includes the primary reactions of the radiation with the matter, such as bond cleavage and the indirect damage caused by radiation due to free radicals. On the other hand, polymers are an interesting alternative as they are cheap and suitable for producing microfluidic chips. Therefore, in this experimental study, multiple interactions with polymers and quartz caused by radiation are assessed. In general, most radiation-induced modifications can be traced back to changes taking place in the structure of the material. Some of the changes have been attributed to the scission of the polymer chains, promotion of cross-linkages, breaking of covalent bonds, formation of carbon clusters, and liberation of volatile products. However, these materials must not lose their mechanical and chemical properties to maintain a well-functioning microfluidic extraction system. Atomic layer deposition (ALD) is an interesting surface modification method due to its self-limiting nature and atomic precision control. With ALD, it is possible to deposit a nano-scale layer of metal oxide that reduces surface-induced damage without changing much of its bulk properties. Furthermore, with ALD, it is possible to change the wettability of the material to make them suited for microfluidic liquid-liquid extraction. This study showed that a 40nm T iO2 thin-film was able to stabilize the surface modifications during high flux electron irradiation. A similar pattern is found between the samples coated with VALD as radiation-induced surface activation is achieved. Briding oxygen that usually is present on the surface gets replaced by carboxyl groups and increases the surface energy to increase the hydrophilicity of the surface. Furthermore, polycarbonate, quartz, and high-density polyethylene showed impressive radiation resistance up to 5MGy as Young’s modulus showed no significant difference. With this study, it is possible to use nano-coating to stabilize the radiation-induced surface activation and can be helpful for surface modifications in multiple fields.","Microfluidic chip; Polymers; Quartz; Gamma radiation; Electron irradiation","en","master thesis","","","","","","","","2025-02-25","","","","","",""
"uuid:24de067e-a713-433c-914d-4f4abfe0bb0c","http://resolver.tudelft.nl/uuid:24de067e-a713-433c-914d-4f4abfe0bb0c","How coordination of production and warehouse decisions affects the product flow between factories and warehouses for manufacturing firms: Mathematical models and a case study at Kraft Heinz","Busser, Bas (TU Delft Technology, Policy and Management; TU Delft Transport and Logistics)","Fazi, S. (mentor); Tavasszy, Lorant (graduation committee); Arslan, A.M. (graduation committee); Strijers, P. (graduation committee); Delft University of Technology (degree granting institution)","2022","In practice manufacturing companies have insufficient coordination and synchronisation between production planning and warehousing teams. The lack of coordination regarding production and warehousing decisions in the ordering strategy may result in unforeseen capacity issues at the warehouse due to misalignment between production plans and warehouse availability. These unforeseen issues can result in additional costs due to production line closure or last-minute stock reallocations. For this reason, it is relevant to study the effects of increasing interdepartmental coordination between production and warehousing departments on product flows between factories and warehouses in the supply chain of a manufacturing company. This thesis’ aim is to analyse the effects of coordinating the production scheduling department with the warehouse management department, against the most common practical case where the two entities hardly communicate. To this end, two optimization models are developed representing the warehouse and factory operations within a supply chain. The first model consists of a multi-period multiproduct lot size and warehouse optimization model for the decision on warehouse capacities while minimizing warehousing costs. The second model is a parallel non-identical machine scheduling model for the optimization of production schedules and the simultaneous minimization of the production costs. We compare the outcomes of the two models against a model where both decisions are integrated. The modelling decisions are taken in a setting with deterministic demand over time. An extensive sensitivity analysis aims to provide managerial guidelines for practitioners, to weigh which department can have greater impact on the total cost. Also, the integrated model can quantify the benefits of coordinating the production and warehouse departments. A case study at Kraft Heinz, a popular brand in the food industry, is used to provide a practical setting.","Optimisation modelling; Supply Chain; Manufacturing","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:0f18069d-41c0-47e1-8e85-72a2a82531d3","http://resolver.tudelft.nl/uuid:0f18069d-41c0-47e1-8e85-72a2a82531d3","Efficient Estimation of the Expected Shortfall: In a Nested Simulation Framework","van Wijngaarden, Maarten (TU Delft Electrical Engineering, Mathematics and Computer Science)","Papapantoleon, A. (mentor); Bierkens, G.N.J.C. (graduation committee); Delft University of Technology (degree granting institution)","2022","We analyze three different methods that can approximate the expected shortfall of a financial portfolio in a nested simulation. In this simulation process, the outer simulation generates risk scenarios, and the inner simulation approximates the value of the financial portfolio under each risk scenario. The first method is the most standard one, and therefore we call it ’the standard Monte Carlo method’. This method uses the same amount of computational cost for each inner simulation. The second method adapts the computational cost of the inner simulation to the output of the outer simulation. Therefore, we call it ’the adaptive sampling method’. This technique has already been proven to work more efficiently than the standard Monte Carlo method. The third method is called ’the multilevel Monte Carlo method’ (MLMC) and is based on the technique that has been introduced by Giles. This method approximates the expected shortfall multiple times and with different levels of accuracy. These estimators are used to give an accurate overall approximation of the expected shortfall. To the best of our knowledge, it has never been examined how efficiently the expected shortfall can be approximated in this manner by the MLMC method. This thesis will thoroughly explain how each method can be applied in a nested simulation to approximate the expected shortfall. In addition, an analysis is given on how to ensure that each method is used as efficiently as possible in the nested simulation. We also perform a numerical experiment in which we simulate a simplified version of a financial portfolio using stochastic processes. With the help of the numerical experiment, we examine which method is most efficient to approximate the expected shortfall.","Expected shortfall; Financial portfolio; Nested simulation; Outer simulation; Inner simulation; Adaptive sampling; Multilevel Monte Carlo method","en","master thesis","","","","","","","","","","","","Applied Mathematics | Financial Engineering","",""
"uuid:9197083c-b007-490d-b90b-400f1385ea36","http://resolver.tudelft.nl/uuid:9197083c-b007-490d-b90b-400f1385ea36","Flow processes forcing the development of the scour hole Beerenplaat in the Rhine-Meuse delta","van Duuren, Karsten (TU Delft Civil Engineering and Geosciences)","Blom, A. (graduation committee); Hofland, B. (graduation committee); Sloff, C.J. (mentor); Stancanelli, L.M. (graduation committee); Delft University of Technology (degree granting institution)","2022","The Rhine-Meuse delta is characterized by the presence of many scour holes. Koopmans (2017) showed that these scour holes have very different growth rates, even if they are located within the same river branch. Most likely this is caused by either the heterogeneous subsoil, the presence of hydraulic structures, the geometry of the river or anthropogenic influences. Therefore, Koopmans (2017) advises to individually study scour holes in the delta since the local variations in conditions cause different shapes, sizes and growth rates, making every scour hole unique. One of these is the scour hole Beerenplaat, which is located at the confluence/bifurcation of the Oude Maas and the Spui. It is a large scour hole which recently gained much more attention due to the construction of a pilot nourishment by Rijkswaterstaat.<br/><br/>This thesis investigates the morphological development of the river bottom at the scour hole Beerenplaat and the location of the pilot nourishment, by analyzing measurements taken with Multibeam Echosounder. Due to the lack of knowledge on the composition of the heterogenous subsoil, it is tried to understand the observed morphological development based on the hydraulic conditions. At the scour hole Beerenplaat, the hydraulic conditions are characterized by two types of flow processes. The first type of flow process is caused by the confluence/bifurcation Oude Maas and Spui. With the help of Acoustic Doppler Current Profiler (ADCP) measurements and the output of a Delft3D model, the flow field at the confluence/bifurcation was investigated for four scenarios: peak ebb flow, flow changing from ebb to flood, peak flood flow and flow changing from flood to ebb. These scenarios are each paired with different flow features such as flow accelerations, flow stagnation and additional turbulence. It is expected that the second type of flow processes at the scour hole Beerenplaat are the 3D flow processes, which are flow contraction, a (curved) recirculation zone and the horseshoe vortex. Again, the output of the Delft3D model and the ADCP measurements are used to investigate them. Unfortunately, the limitations of both the measurement and the model and the use of an incorrect geometry of the scour hole Beerenplaat, made it not possible to succeed in this. Based on the actual profile of the scour hole, it is expected that the (curved) recirculation zone develops at the steep slope of the scour hole Beerenplaat during ebb flow. <br/><br/>By computing bed shear stresses and using literature, it was investigated how these flow processes attack the river bed during ebb flow, indicating areas vulnerable to scour. It was found that these areas were no match with the observed morphological development. Due to the incorrect geometry of the scour hole in the model, it was not possible to include the hydraulic forcing during flood flow. Most probably, it should be included to describe the expansion of the scour hole and growth towards the Spui. Despite, this research has given better understanding of the flow processes occurring at the scour hole Beerenplaat are shaped and affected by the tide.","Scour hole; Beerenplaat; Bi-directional confluence; Flow processes; Rhine-Meuse delta; Heterogenous subsoil; 3D flow processes; Pilot nourishment","en","master thesis","","","","","","","","","","","","Civil Engineering | Hydraulic Engineering","",""
"uuid:98b4f465-1b26-48d8-90d7-53f773095f36","http://resolver.tudelft.nl/uuid:98b4f465-1b26-48d8-90d7-53f773095f36","Assessment and Optimisation of Target Acquisition using SAR Seekers on Manoeuvrable Re-Entry Vehicles","Olberts, Ernst (TU Delft Aerospace Engineering)","Naeije, M.C. (graduation committee); Halswijk, Wouter (mentor); Heiligers, M.J.C. (graduation committee); Delft University of Technology (degree granting institution)","2022","In this thesis, the achievable performance and limitations of a Synthetic Aperture Radar (SAR) seeker on an Anti-Ship Ballistic Missile (ASBM) for a set of parameters has been investigated. This was achieved by modelling the dynamics of an ASBM and the constraints related to the acquisition requirements of a maritime surface target in the ""Generation and Improvement Algorithm for Nonlinear Trajectories"" (GIANT) optimisation tool provided by TNO. The angular velocities of the ASBM were set as the control variables for the optimal control problem where the objectives were set to the minimisation and maximisation of the exposure time and vertical end velocity of the missile and the minimisation of the required time for creating one SAR image by the SAR seeker. <br/><br/>Three experiments were carried out to investigate the influences for different initial conditions and resolution constraints on the optimised trajectory. In the first experiment, the trajectory was optimised for initial reentry conditions that are representative for typical ASBMs. The target was placed at the location that would match the uncorrected ballistic flight impact location of the ASBM. This allowed to compare and visualise the optimised manoeuvres of the ASBM relative to its ballistic flight trajectory. In the second experiment, the target was placed at the same location, but the initial re-entry conditions were optimised by GIANT, that provided the optimal trajectory. In the last experiment, the constraints related to the resolution of the target were lowered to analyse the maximum performance of the system. <br/><br/>The experiments show that a larger initial squint angle of the re-entry position of the ASBM improves the overall performance. This is because a larger squint angle allowed the missile to obtain a larger seeker look angle during the SAR phase while performing minimal manoeuvres during the re-entry phase. This permitted the dwell time of the SAR seeker and the exposure time of the missile to be as short as possible, while the missile’s vertical end velocity could be maximised. It was also shown that a ground range and crossrange resolution of 1.60 m could be achieved for an average dwell time of 0.1170 s. For better resolutions, the bandwidth of the SAR seeker appeared to be the limiting factor of the system for the chosen set of parameters.","Synthetic Aperture Radar; SAR; ASBM; Re-entry vehicle; Optimisation; Target Detection","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:8f40561a-80be-4047-9760-63ab27207ffc","http://resolver.tudelft.nl/uuid:8f40561a-80be-4047-9760-63ab27207ffc","Reduce model unfairness with maximal-correlation-based fairness optimization","Huang, Wenxuan (TU Delft Electrical Engineering, Mathematics and Computer Science)","Loog, M. (mentor); van Gemert, J.C. (graduation committee); Lofi, C. (graduation committee); Delft University of Technology (degree granting institution)","2022","Supervised machine learning is a growing assistive framework for professional decision-making. Yet bias that causes unfair discrimination has already been presented in the datasets. This research proposes a method to reduce model unfairness during the machine learning training process without altering the sample value or the prediction value. Using an objective function that identifies the biased feature with maximal correlation estimation, the method selects samples to train the updated classifier model. The quality of the sample selection determines the extent of unfairness reduction. With an adequate sample size, we demonstrate that the method is valid in reducing model unfairness without severely sacrificing classification accuracy. We tested our method on multiple benchmark datasets with demographic parity and feature independence as the notions for a statistically fair classification model.","Machine Learning; Fairness Optimization; Maximal Correlation; Demographic Parity","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:bb0f5794-889e-449f-9498-0f9f23561d97","http://resolver.tudelft.nl/uuid:bb0f5794-889e-449f-9498-0f9f23561d97","Surrogate modelling framework for probabilistic assessment of slope stability of dikes on heterogeneous soils","Kamphuis, Arian (TU Delft Civil Engineering and Geosciences)","Aguilar Lopez, J.P. (mentor); van der Meij, Raymond (graduation committee); Vardon, P.J. (graduation committee); van den Eijnden, A.P. (graduation committee); Delft University of Technology (degree granting institution)","2022","Climatic conditions in uence peak discharges in rivers and change sea levels; therefore, attention to the safety of dikes is of ever growing importance. Macro instability is one of the dike failure mechanisms that can inundate the hinterland. Soil heterogeneity plays an important role in assessing dike safety, especially for slope stability, because it is a major source of uncertainty. To assess a dike network for safety, numerical simulations for a full probabilistic analysis can be computationally expensive. Therefore, this study investigates how to build a state-of-the-art data-driven framework from a numerical model to predict the safety margins from the macro stability of dikes. Inputs and outputs of tens of thousands D-Stability simulations were used to create a training dataset. The most relevant features were selected based on global sensitivity analysis and the representation of soil heterogeneity in the framework. The maximisation of Shannon's information entropy and the generation of the training dataset was achieved by employing a smart sampling strategy for the input parameters. The sampling strategy consists of a Latin hypercube optimised uncorrelated uniform distributed dataset combined with a correlated dataset for optimal training eciency. The uncertainty due to soil heterogeneity is represented by a Gaussian random eld with a trend. This trend is commonly determined from a geotechnical cone penetration test. With a CPT, it also is possible to nd the vertical scale of uctuation, which is parametrised by the correlation length of the uctuations in soil strength. The second-order Markov correlation function is used to represent the correlation of the random elds. The Gaussian random eld is later mapped onto 16 stacked horizontal layers to model the heterogeneous soil properties. The surrogate model consists of an ensemble of thirteen machine learning models. The most important model is a multi-layer perceptron feed forward articial neural network. The other models are histogram based gradient boosting regression trees. Random search and Bayesian optimisation are used as hyperparametrisation techniques to optimise the prediction capability is of the individual ML algorithms. Weights for each model are determined based on optimisation for error reduction for maximum performance. The surrogate predicts the factor of safety (FOS) as well as the coordinates of the slop failure circles and line of depth from the Uplift-Van method. The surrogate model ensemble that predicted FOS is quite accurate with respect to the numerical FOS of D-Stability, and yet the prediction of the failure plane is still slightly worse. A case study was used to demonstrate the performance of the framework. Despite the uncertainty of the subsoil, due to the soil heterogeneity, the surrogate was able to accurately predict the failure probability. However, the prediction of the far end circle coordinates showed lower performance due to propagating errors. Concluding, application of the framework is possible for dike reinforcement optimisation, risk-based dike safety assessment, length effect, and effcient Monte Carlo simulations.","Surrogate modelling; Soil heterogeneity; Slope stability; Dike stability; D-Stability; Machine learning; Neural network","en","master thesis","","","","","","","","","","","","Civil Engineering | Hydraulic Structures","",""
"uuid:1ec395e4-2827-4779-a1e6-93e06691cb6e","http://resolver.tudelft.nl/uuid:1ec395e4-2827-4779-a1e6-93e06691cb6e","A sensitivity study on the natural frequency of high-rise structures in the Netherlands","Tempelman, Koen (TU Delft Civil Engineering and Geosciences)","Tsouvalas, A. (mentor); Sánchez Gómez, S. (mentor); Lagendijk, Paul (mentor); Bronkhorst, Okke (mentor); Delft University of Technology (degree granting institution)","2022","As the world's population keeps increasing and the rate of urbanizations increases, The rate at which high-rise structures are being built is skyrocketing. In the Netherlands, this is no different. It is expected that the amount of high-rise structures taller than 70 meters will more than double in the coming 20 years. As these structures become taller and more slender, they also become more susceptible to wind-induced excitations. Where once the design of a structure was predominantly governed by the Ultimate Limit State (ULS) design criteria, for tall structures, the Serviceability Limit State (SLS) design criteria becomes as, if not more, important. Therefore, the accurate prediction of the dynamic characteristics are becoming increasingly important. One of these dynamic characteristics is the natural frequency, also called the eigen frequency, of the structure. <br/><br/>The natural frequency is a parameter which is largely influenced by the mass and the stiffness of the structure. One would think that after the completion of structure, that the magnitudes of parameters can be determined with a high level of certainty, and that the natural frequency can be calculated accurately, but this is not the case. When comparing the measured natural frequencies of several high-rise structures in the Netherlands, to their natural frequencies determined in the design phases, an underestimation of between 20\% to 50\% was seen. Although the likelihood that these underestimations will lead to structural failure are small, it does lead to larger design forces and higher peak accelerations, which are used in determining occupant comfort in the structures. The aim of this research is to find the reasons for the discrepancies between the measured and the calculated natural frequencies. <br/><br/>A literature study was performed to determine what the most common methods of determining the natural frequency are during the design phase. There are three main methods which are used throughout different stages of the design phase to approximate the natural frequencies. At the start of the design phase, when structural parameters have not yet been determined, the natural frequency is approximated using empirical formulae. These formulae mostly only depend on 1 or 2 spatial parameters. <br/>As the design progresses and the structural parameters are specified, dynamic beam theory can be used to determine the natural frequency. These calculations take the stiffness of the super- and substructure, and the mass of the structure, into account. As the design nears completion, the structure is modelled in a FE software package. The natural frequency can then be calculated by the software to give a final impression of the natural frequency.<br/><br/>The main parameters influencing the natural frequency of a system are the stiffness and the mass. This is no different for high-rise structures, but how do these parameters affect the natural frequency, and which of these parameters has the greatest effect on the natural frequency? A sensitivity study, looking at 5 existing high-rise structures in the Netherlands, was performed. Each structure was represented by 5 different beam models. One structural parameter was added to each subsequent beam model as to be able to quantify the influence of the added parameter. Lower and upper bounds were determined for each structural parameter. By varying these parameters and calculating the natural frequencies, the effect this variation has on the natural frequency can be determined. It was found that there are 3 parameters which have significant influence on the natural frequencies, namely, the superstructure stiffness, the superstructure density and the rotational stiffness of the foundation. <br/>For all cases with a flexible foundation, the measured natural frequencies could not be reached, even after determining the natural frequencies using the extreme parameter combination, the natural frequencies were still underestimated. The analyses were done for both uniform beam models and multibeam models. The general trend was that the multibeam model produced higher frequencies. This is due to more of the overall stiffness and mass of the structure being situated in the bottom sections of the structure. Using a multibeam can lead to an increase in natural frequency of up to 15\%. Although the natural frequencies were increased, they were still nowhere near the measured natural frequencies. <br/><br/>The underestimation of the natural frequencies using the beams models, led to the question if there are other factors which are not yet taken into account when determining the natural frequencies. In the calculation of the stiffness of the new Erasmus Medical Centre (NEMC), it was assumed that the beams, columns, non-structural elements and the low-rise structure have a negligible influence on the stiffness of the structure. The underestimation in the natural frequencies, led to the conclusion that the stiffness of the structure is underestimated. A complete model of the NEMC was modelled using the SCIA Engineer software. All the structural systems were added to the model. Modal analyses, including different combinations of structural systems and parameter magnitudes, were performed. It was found that for the NEMC the assumption that the beams and columns have a negligible contribution to the natural frequency, was correct. The main contributors to the stiffness of the superstructure were the outer tube and the central cores. The partition walls were added to the model using low stiffness wall elements, by added the walls, the natural frequency was increased by 8.5\%. Assumptions were made to include the influence of the low-rise structure. The determined natural frequency was increased past the measured natural frequency, however, this result might not be realistic. <br/><br/>The final conclusion of the thesis is that the stiffness of the superstructure is underestimated. This leads to the conclusion that there are certain elements which provide the structure with extra stiffness, which is not yet taken into account. At the end of the thesis several recommendations are made as to determine where this extra stiffness comes from.","High-rise structures; Tall buildings; Free vibration; Natural frequency; FEM; Dynamic beam theory; wind; underestimation; parameter uncertainty","en","master thesis","","","","","","","","","","","","Civil Engineering | Structural Engineering | Structural Mechanics","",""
"uuid:1e3f4a48-50b5-4e7d-9907-6f052fcc3216","http://resolver.tudelft.nl/uuid:1e3f4a48-50b5-4e7d-9907-6f052fcc3216","Properties of Node Reliability Polynomials","Yu, Hanshu (TU Delft Electrical Engineering, Mathematics and Computer Science)","Kooij, Robert (mentor); Sun, P. (graduation committee); Delft University of Technology (degree granting institution)","2022","We are living in a connected world and failures can occur anywhere at any time probabilistically. In this thesis, we consider networked systems whose links are perfectly reliable and nodes are subject to failure. The probability of a network subjecting to failure to remain connected is named the node reliability of a graph. The node reliability naturally gives rise to a polynomial in the node operational probability $p$. We call this polynomial node reliability polynomial. The research aims to explore the properties of the node reliability polynomial.<br/><br/>Python tools were developed to compute the exact solutions of node reliability polynomial by enumerating all possible connected sets in graphs. Monte-Carlo simulation software in Python was also developed for approximate solutions of graphs that are too large for enumeration. We took advantage of the developed Python tools to investigate the combinatorics aspect of graphs.<br/><br/>The most important result is that we provide a construction method based on the lexicographic product of graphs such that the node reliability polynomials of two graphs, with the same number of nodes and links, can have an arbitrary number of intersection points. In addition, we have discovered that a fully-joint graph’s connected sets are composed by the addition of the connected sets of all partitions along with the connected sets of the complete multi-partite graph that corresponds to the full interconnection between partitions. Later, we propose a conjecture that complete bipartite graphs that are $\kappa$-optimal in their class are node reliability optimal in their class. Last but not least, by enumeration of all non-isomorphic graphs of the order less than 10, we have discovered the minimum orders of graph pairs that their node reliability polynomials intersect one, two, and three times. The performance of the crude Monte-Carlo simulation in simulating node reliability polynomial is discussed as well.","","en","master thesis","","","","","","","","","","","","Electrical Engineering | Wireless Communication and Sensing","",""
"uuid:c3ee72cc-2a41-41bc-8e41-8521b2df06c5","http://resolver.tudelft.nl/uuid:c3ee72cc-2a41-41bc-8e41-8521b2df06c5","Numerical and Experimental Investigation of a Hall Thruster Operating with Air","Ciolini, Matteo (TU Delft Aerospace Engineering)","Cervone, A. (mentor); Misuri, T. (mentor); Giannetti, V. (mentor); Ferrato, E. (mentor); Guo, J. (graduation committee); Naeije, M.C. (graduation committee); Delft University of Technology (degree granting institution)","2022","The plasma behaviour in an air-propelled Hall thruster (SITAEL HT5k) is investigated by means of numerical modelling and experimental measurements. The air plasma employed (nitrogen/oxygen mixture) is firstly chemically characterized, identifying the most relevant species produced: four neutrals (N<sub>2</sub>, N, O<sub>2</sub>, O), four positive ions (N<sub>2</sub><sup>+</sup>, N<sup>+</sup>, O<sub>2</sub><sup>+</sup>, O<sup>+</sup>) and electrons. Then, it is explored the kinetic theory of ion-ion streaming instabilities in the presheath, relevant to electropositive multispecies plasmas, extending it to the four-ions case under study. These results are used to adapt a non-stationary 1D fully fluid Hall thruster model to operation with an air plasma. Calibration with an experimental discharge current signal confirms the physical validity of the formulation in reproducing breathing mode oscillations, even in multispecies plasmas. The experimental data also consist of fast-diving triple Langmuir probe measurements, which are used to validate the model, showing reasonable accuracy of the spatio-temporal distributions of the plasma properties.","electric propulsion; hall effect thruster; plasma; alternative propellants; plasma kinetic theory; numerical modeling; plasma diagnostics; experimental investigation","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:d85381a4-afe0-49c7-bc5a-cc8768f7390a","http://resolver.tudelft.nl/uuid:d85381a4-afe0-49c7-bc5a-cc8768f7390a","Entrepreneurship in Africa: Improving Lives through Clean Energy and Clean Cooking: Discovering the barriers and drivers for entrepreneurs in the SSA Clean energy sector","Faessen, Pieke (TU Delft Technology, Policy and Management)","Kamp, L.M. (mentor); Kroesen, J.O. (graduation committee); Delft University of Technology (degree granting institution)","2022","In Sub-Saharan Africa (SSA) energy poverty is a widely spread challenge and access to energy is a key imperative for economic development. With the exponential population growth in the region the pressure on the energy that is available grows and the numbers on energy poverty rise. In an effort to promote change, Sustainable Development Goal (SDG) 7, set by the United Nations (UN), encourages to make access to affordable, reliable, sustainable, and modern energy possible for all. With the global agenda on sustainable energy access and the energy market gap in SSA, entrepreneurs are seeing opportunities. Both local and international entrepreneurs are finding their way in the SSA energy sector.<br/><br/>The 2021 status update from the UN on SDG 7 shows the progress regarding the development of energy access for all is not on track for many countries in SSA. With the time ticking on the SDGs timeline (goals should be achieved by 2030) more research should be done into investigating why entrepreneurs seem to be unable to reach substantial progress with regards to providing sustainable energy. This research aimed to discover the drivers and challenges local and international entrepreneurs are facing in their mission of brining sustainable energy to countries in SSA.","entrepreneurship; SSA; sub-Saharan Africa; SDG7; Sustainable development goals; clean energy; green energy; clean cooking","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:4996432b-2064-40d4-be4b-2f6ca76d089d","http://resolver.tudelft.nl/uuid:4996432b-2064-40d4-be4b-2f6ca76d089d","Powering the Rijksrederij fleet with green methanol fuel cells","Pluijlaar, Dion (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Ship Design, Production and Operations)","van Biert, L. (mentor); Verheijen, Loek (mentor); Visser, K. (graduation committee); Geertsma, R.D. (graduation committee); Delft University of Technology (degree granting institution)","2022","This research was performed with the goal of giving insight if the Rijksrederij is able to operate part of their fleet on renewable methanol and fuel cells, in order to work towards their goal of operating with net zero CO2 emissions by 2030. This prompted a research question that focussed on both the renewable methanol supply and the technical implementation on board of some of the ships operated by the Rijksrederij.<br/>First, multiple possible pathways for renewably producing methanol were considered. Three main pathways were identified: two of which using waste biomass, one using recycled CO2 from on-board carbon capture. Green hydrogen could be provided using excess wind energy from Rijkswaterstaat’s own wind parks. In a later stage, it was found that a combination of biomass derived CO2 and recycled CO2 would be most beneficial to use in the methanol production process, by hydrogenating the CO2 with the beforementioned green hydrogen. However, this process resulted in net well-to-tank CO2 emissions.<br/>To gain insight in all necessary components, a literature study was performed on maritime fuel cell systems and methanol reformers. Next, a model based on these systems was constructed that could be used in two ways: to aid in selecting specific systems and tank dimensions to be installed on board of ships, and to calculate tank-to-propeller CO2 emissions on both trip basis and yearly. Three different Rijksrederij ships were analysed using this model, and the spatial system integration on board was considered. In order to recycle the CO2 to produce green methanol, an on-board carbon capture system was needed and also modelled. The model is parametric in a way that allows for other ship types and fuel cell related systems to be used as input. In the end, the tank-to-propeller emissions for the three ship types were calculated, and these findings could be extended towards a larger part of the Rijksrederij fleet in order to calculate the entire well-to-propeller emissions of this fleet.<br/>It was found that there were net positive emissions stemming from two sources: the aforementioned methanol production related emissions, and the slip stemming from uncaptured CO2 on board. Since not 100% of all CO2 could be captured on board, this also results in a gap in available CO2 for methanol production. In this sense, the production CO2 gap and the net well-to-tank emissions go hand in hand, and eliminating the net emissions (by capturing CO2 elsewhere, or improving the capture rate) also reduces the production gap. To achieve this, more research will be necessary.<br","Methanol; Fuel cells; On-board carbon capture","en","master thesis","","","","","","","","","","","","Marine Technology | Marine Engineering","",""
"uuid:6221029b-8b6e-44df-8765-425ee9722849","http://resolver.tudelft.nl/uuid:6221029b-8b6e-44df-8765-425ee9722849","River Bed Response to Sea Level Rise","Scherpbier, Mieke (TU Delft Civil Engineering and Geosciences)","Blom, A. (mentor); Ylla Arbos, C. (mentor); Schielen, R.M.J. (graduation committee); Rutten, M.M. (graduation committee); Delft University of Technology (degree granting institution)","2022","Climate change is causing the global sea level to rise. Research and discussion of the effects of sea level rise are often focused along coastlines. However, the effects of higher water level and changing morphodynamics can reach far inland via rivers. This study uses a one-dimensional numerical model to analyze bed level response to sea level rise. The model simulates 100 years of steady sea level rise on a 1000 km long, fixed width channel. Sea level rise creates a backwater curve which grows in the upstream and vertical directions. The transient response of the channel bed is an aggradation wave the grows in the upstream and vertical directions. We studied different cases which vary in sediment flux, flow discharge, grain size, and rate of sea level rise and found changes in the rate of growth of the aggradation in both directions. All runs start in an equilibrium state and run for 100 years.<br/><br/>This study finds a close relationship between the equilibrium slope and depth of the channel and the shape of the backwater curve. This relationship drives the aggradation patterns. For example, for the same amount of sea level rise, a flat, deep channel has a longer backwater curve with a smaller relative increase in depth than that of a steeper, shallower channel. The backwater curve drives the aggradation patters, such that the flat, deep channel then has aggradation over a longer reach, and a smaller increase in bed level than the steeper shallower channel.<br/><br/>With the cases modeled in this study, three general trends in aggradation rates emerge: (1) an aggradation mound that grows quickly upstream, with slower increase in bed level as found in flatter, deeper channels; (2) a faster increase in bed level with slower upstream growth, found in cases with steeper slope and shallower depths; and (3) faster growth in both bed level and upstream direction caused by an increased rate of sea level rise.<br/><br/>Since natural channels are often complex with multiple sources of discharge inputs, a tributary case is also<br/>included. Starting from equilibrium state and applying sea level rise to the downstream boundary, the model<br/>shows aggradation waves in the regions downstream and upstream of the confluence, starting from the downstream boundary and the confluence. There is also degradation just downstream of the confluence. The scour hole grows at first, in depth and the downstream direction then reduces. The aggradation moving upstream intersects with the degradation moving downstream and fills in the scour hole. In some cases, we see the scour fills in within the 100 year time frame, resulting in a net increase in bed level. In a tributary system, the risk of scour is greatest for tributaries with high flow discharge or low sediment flux.<br/><br/>The transient response of the bed level to sea level rise is aggradation. As the water level continues to rise, the bed level is expected to do the same, but at a lower rate. In this study, the nominal rate of sea level rise is 10 mm/yr. The fastest rate of bed level rise in the model results is less than 6mm/yr, creating an ever increasing water depth. This is beneficial for shipping and navigation in the channel, which would not require dredging of the aggradated material. However, the reduction in bankfull volume with rising water levels is dangerous for flood control.<br","River morphodynamics; Sea level rise; Climate change; backwater effects","en","master thesis","","","","","","","","","","","","Civil Engineering | Hydraulic Engineering","",""
"uuid:6d981687-fd82-4b20-881b-25d0e4b0e86e","http://resolver.tudelft.nl/uuid:6d981687-fd82-4b20-881b-25d0e4b0e86e","An applied uncertainty analysis on the techno-economic valuation of engine wash procedures","Asselman, Bram (TU Delft Aerospace Engineering)","Lourenço Baptista, M. (mentor); Santos, Bruno F. (graduation committee); Delft University of Technology (degree granting institution)","2022","Overall economic assessments (OEAs) can provide a sound basis for decision-making in the areas of investments in new technologies and the application of existent technologies or operating practices. However, due to their long time horizons and complex nature, OEAs often contain many uncertain inputs, making a deterministic simulation insufficient to reflect the true value of the output. In order to incorporate these uncertainties, a systematic and efficient approach for uncertainty analysis is required. This paper sets out such a process, which consists of an iterative Uncertainty Quantification (UQ) based on importance measures for each uncertainty obtained from a Global Sensitivity Analysis (GSA). Methods for UQ and GSA are generally actively researched and well established in theory, but are infrequently applied on actual problems due to the computational and organisational complexity associated with integrative uncertainty assessments. To address this issue, the process is demonstrated on an interdisciplinary problem, namely the economic valuation of Engine Wash (EW) procedures using the cost-benefit tool LYFE. It is concluded that with this iterative uncertainty quantification procedure, the total uncertainty in the output distribution, measured using the 2.5th and 97.5th percentiles and expressed in terms of the Delta Net Present Value, is reduced from $45K - $983K to $78K - $584K. To achieve this reduction, additional modelling was carried out for only the two most important of the six uncertainties, determined using the GSA results, which illustrates the efficient allocation of modelling resources.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:f18e3bb5-e1a5-4fe1-9262-39b3a52fd3e3","http://resolver.tudelft.nl/uuid:f18e3bb5-e1a5-4fe1-9262-39b3a52fd3e3","Playfully teach about patterns of collective behaviour through an interactive design","Tan, Tessa (TU Delft Industrial Design Engineering)","van der Helm, A.J.C. (mentor); van Assen, J.J.R. (graduation committee); Delft University of Technology (degree granting institution)","2022","Collective behaviour can be seen everywhere. It is the phenomenon where many individuals form a group together and act as a whole. These groups are mesmerising to watch, but we can also learn from them. The way these groups behave depend on how the individuals react to their local surroundings. Obtaining knowledge about this concept brings knowledge in different areas like animal groups, human behaviour and complex design systems.<br/>The goal of the project was to make a wide audience aware of collective behaviour, by teaching them in a playful interactive way, through a museum installation. The target group are museum visitors of age 8 and older. The question was what the user experience would look like and how the design would take shape. <br/><br/>The project started with understanding what collective behaviour is, to find out which elements are most important to convey in the design. Designing for a museum context and different technologies that can be used in the installation are explored. This phase concluded with requirements to implement in the museum installation.<br/>In the following phase, the user interaction and the way visitors will manipulate the installation are ideated, and the goal for the user is determined. This phase included brainstorming, ideation by sketching and eventually lead to the design of the installation embodiment.<br/>In the last phase of the project, the final design was determined and detailed: Control the Collective. By interacting with the designed installation, users can manipulate the size of three zones, in which the agents behave in a certain way. These are the zone of repulsion, the zone of orientation and the zone of attraction. Museum visitors can change the size of these zones by sliding disks along a line on the floor and with the use of corresponding buttons. These disks and buttons are placed on top of a circular platform, which users can stand on top of. The size of these zones and the influence on the composition of an individual within the group are visualised on this platform. Simultaneously, on a wall curved around the platform, the accompanying visualisation of the moving group is displayed.<br/>The museum installation was evaluated and validated in Naturalis on user experience and the level of understanding of users. Lastly, recommendations are provided for future research and implementation of the design. <br","collective behaviour; museum installation; interactive design","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:7bf21abc-3d35-4385-8f61-647bc24584f7","http://resolver.tudelft.nl/uuid:7bf21abc-3d35-4385-8f61-647bc24584f7","A systematic tool for the assessment of nature-based solutions to mitigate salt intrusion","Iglesias, Sebastian (TU Delft Civil Engineering and Geosciences)","van Koningsveld, M. (mentor); Aarninkhof, S.G.J. (graduation committee); Hendrickx, G.G. (graduation committee); Bakker, F.P. (graduation committee); Meyer, Han (graduation committee); Delft University of Technology (degree granting institution)","2022","Nature-based initiatives have emerged as potential solutions to problems caused by saltwater intrusion in deltas found globally, but their successful implementation is enabled partly by a multi-stakeholder approach. The latter involves managing several parallel stakeholder objectives, which usually requires quantitative knowledge to understand possible collisions of interests. On that account, the present work developed a systematic approach (referred to as the `comparison tool') to quantitatively compare the objectives of multiple stakeholders interplaying in a delta. As a first approach, the comparison tool is intended to support decision-making to deal with potential conflicts between freshwater supply and port logistics interests. In particular, the present juncture in the Rhine-Meuse Delta in the Netherlands was used to investigate potential trade-offs generated by the nature-based shallowing (or river bed heightening) of the Rotterdam Waterways. The comparison tool is founded on the objective-based assessment of Building with Nature (BwN) solutions. The effects of a BwN solution are assessed separately for each functional requirement and then are related in a combined assessment. The impact assessment for the shallowing of the Rotterdam Waterways required two numerical modelling studies. First, effects on the hydrodynamics and salt transport in a partially-mixed estuary were modelled with the Operationeel Stromingsmodel Rotterdam (OSR), developed by the Port of Rotterdam Authority. Secondly, changes in meso-scale traffic flows over the port network were modelled with the OpenTNSim developed by TU Delft. Afterwards, the effects on freshwater supply and port performance (capacity and efficiency) were quantified separately and then compared. This research delivered a systematic procedure and demonstrated how a combined assessment could be performed in the context of nature-based solutions to mitigate salt intrusion. The most important outcome entails quantitative trade-offs between port efficiency and freshwater supply over a range of bed level increase from 0.0 m to 3.9 m. In general, results showed that the improvement towards the objective of port logistics always goes to the detriment of the freshwater supply objective while increasing bed level. Also, this study found that a collision of interests between the two types of end-users might worsen for a bed level increase over 2 m. Additional results showed that shallowing could be associated with benefits for freshwater supply through a decrease in the duration of water shortages due to a retreat in salt intrusion. The latter holds for specific environmental conditions of low river discharge and mild wind. Also, this study concluded that shallowing could negatively affect port efficiency due to heavier vessel traffic and more burdensome tidal window restrictions, which can result in an exponential growth of vessels average waiting times if the bed level increases over 2 m. Since the freshwater and port sub-systems were simplified, uncertainty in the results was unavoidably accepted. Despite these simplifications, this research demonstrated the main principles in implementing the comparison tool and lays the groundwork for more comprehensive models. In addition, several recommendations for policy-making are proposed, setting a basis for later discussions between freshwater supply and port-related stakeholders in the Rhine-Meuse Delta.","Salt intrusion in estuaries; Nature-based Solutions; River shallowing; Saltwater intrusion in estuaries; Port Logistics; Port efficiency; OpenTNSim model; Operationeel Stromingsmodel Rotterdam (OSR-model); Freshwater supply; Objective-based assessment; Building with Nature solutions; Trade-offs","en","master thesis","","","","","","","","","","","","Civil Engineering | Hydraulic Engineering","SALTISolutions | NWO",""
"uuid:967aaae2-8620-46fc-938e-8c560e1a5d3b","http://resolver.tudelft.nl/uuid:967aaae2-8620-46fc-938e-8c560e1a5d3b","Long-term traffic flow predictions in a transformer-based framework: Capturing temporal and external features, to obtain a traffic flow prediction for the next 24 hours","Petsch, Carmen (TU Delft Mechanical, Maritime and Materials Engineering)","De Schutter, B.H.K. (mentor); Koek, Alexander (graduation committee); Delft University of Technology (degree granting institution)","2022","Traffic flow predictions are an important component in the rising demand for solutions to cope with the increasing pressure on transportation networks. Especially on a long prediction horizon, traffic flow predictions remain challenging due to the complex, nonlinear nature of traffic flow and the influence of both temporal and external features. To incorporate sequential behavior of time series, without being subject to limitations inherent in recurrence-based models, the transformer is increasingly used. However, whether this model is advantageous on long horizons is still unknown. Therefore, in this paper, first, multiple correlation analyses are applied to identify important features in traffic flow. Next, these are incorporated into a generic transformer-based framework, and the adequacy of the transformer on long prediction horizons is investigated based on real data. To test the genericity of the proposed prediction model, all analyses are conducted for two locations, which are subject to different traffic behavior. The first is located on the ring road of Haarlem and is mainly affected by commuter traffic, whereas the second is located on the road to the coast and has more irregular behavior. Results show that the transformer outperforms baseline prediction models on both short and long horizons, especially when the location is subject to irregular behavior. In addition, the inclusion of external features, such as the day of the week, holidays, and temperature, improves the model performance. Moreover, the genericity of the model is highlighted by its applicability to multiple locations.","Traffic flow predictions; Deep learning; Transformer; External features","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:22ee6ff0-af93-42af-ac82-5b8c3d530230","http://resolver.tudelft.nl/uuid:22ee6ff0-af93-42af-ac82-5b8c3d530230","Evaluation of hydrogen sensors and location inside a metering cabinet","van der Goes, Barrie (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Wijk, A.J.M. (mentor); Saadabadi, S.A. (mentor); Lukszo, Z. (graduation committee); Hermkens, R. J. M. (mentor); Delft University of Technology (degree granting institution)","2022","The Hydrogen Heating Studies project in the Green Village at the TU Delft researches the safe application of hydrogen to heat buildings. This study aims to evaluate hydrogen sensor technologies for residential safety, including the determination of the sensor location inside a standard (Dutch) metering cabinet that achieves the fastest response to potentially dangerous leakages of hydrogen gas.<br/>A range of commercially available sensor technologies was assessed to determine their suitability in residential applications. From this analysis on multiple criteria, the thermal conductivity sensors outperformed the other sensor technologies, albeit only by a small margin versus catalytic hydrogen sensors. Furthermore, an experimental study has been carried out by locating seven sensors at different locations inside the metering cabinet. The hydrogen concentrations have been measured in seven different conditions (case studies). It was found that sensors located at the top of the metering cabinet showed the highest concentrations, more specifically, the top-center.<br/>The results of this research also confirmed that the condition of closed ventilation leads to a constant increase of hydrogen concentration in the metering cabinet. This has implications for managing the risks associated with high hydrogen concentration levels because of hydrogen leakage. Air ventilation inside the metering cabinet causes changes in the distribution mechanism, resulting in mixing and distribution of the hydrogen, reducing hydrogen concentrations. With open ventilation, the hydrogen concentration levels to trigger the alarm inside the metering cabinet should be lowered. Based on the results, it is advised to set the alarm to trigger when hydrogen concentration levels reach 5 %LEL. It was also found that, compared to methane, the release of hydrogen gas leads to a more buoyant gas mixture which mixes more easily with the air and rises three times quicker toward the ceiling. Finally, further research on worst-case scenarios is relevant to make specific recommendations for safe and economically feasible residential heating appliances.","hydrogen; leakage; detector; sensor; metering cabinet; location","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:0fbf5a52-bf73-4ad4-9122-8a9156430e4f","http://resolver.tudelft.nl/uuid:0fbf5a52-bf73-4ad4-9122-8a9156430e4f","Hydraulic pressure wave bone drilling: A step towards trajectory controlled drilling in the vertebra","Kaptijn, Guy (TU Delft Mechanical, Maritime and Materials Engineering)","Sakes, A. (graduation committee); de Kater, E.P. (mentor); Delft University of Technology (degree granting institution)","2022","Spinal fusion surgery is applied, amongst other reasons, to correct unwanted curves in a spine hampered by scoliosis. During spinal fusion surgery, holes in the vertebra must be drilled, after which pedicle screws are placed. Traditional drilling only allows for the formation of straight holes. Ill-placed trajectories cannot be course-corrected, leading to repositioning the drill and starting again in the, weakened by the first attempt, vertebra. This thesis aims to develop a drilling method that will allow for the application of trajectory control during operation. This will form the first step towards a new spinal surgical instrument that could be used for course-correcting during spinal drilling or form curved holes applicable for new state-of-the-art alternate bone anchors. <br/> The proof-of-principle instrument designed and fabricated in this thesis consists of an impulse generation part, a bendable tube with a saline medium, and a working head, which will perform the impacts on the bone tissue. The method consists of drilling using the repetitive impact of a solid round tip with a diameter of 4 mm. Through the use of a bendable impulse transmission tube, the instrument allows for the application of steerable drilling. The impulse will be generated by a manual compressed and released compression spring. This impulse will be translated into a hydraulic pressure wave; whereafter it will travel through the liquid medium of the tube, ending at the working head, which translates it into an impact on the target tissue. <br/>The method has been proven to work in every state of curvature of the transmitting tube, ranging from 0 degrees till 90 degrees. Furthermore, almost 20% of the desired impulse output found in this thesis, 0.077 Ns, that would allow for high-speed drilling, 0.3 mm per strike, was reached. A linear increase in impulse output was found, correlating with the linear input increase, suggesting plausible higher impulse output magnitudes could be possible. In the future, the instrument's efficiency should be increased, as a mean efficiency of 3.5% was achieved, caused mainly by leakage of the saline filler and high friction with the mechanisms in the tube. All in all, the method shows great potential to be utilised as a future trajectory controlled bone drilling instrument.","","en","master thesis","","","","","","","","2024-02-24","","","","Mechanical Engineering | BioMechanical Design","",""
"uuid:68acce51-5ab0-4070-aefc-1bfeeb037f21","http://resolver.tudelft.nl/uuid:68acce51-5ab0-4070-aefc-1bfeeb037f21","Model Predictive Control-based Driver Assistance System: Predicting Combined Vehicle and Driver Behaviour during Complex Truck Docking Manoeuvres","Dekker, Abram (TU Delft Mechanical, Maritime and Materials Engineering)","Wahls, S. (mentor); Ferranti, L. (mentor); Ferrari, Riccardo M.G. (graduation committee); Kural, Karel (mentor); Delft University of Technology (degree granting institution)","2022","Due to the continuously increasing volume of road freight transportation, there is a need to aid or automate truck-trailer driving. Truck docking, the process of parking a truck-trailer combination at a loading dock, is one of the most difficult manoeuvres for professional drivers. In this work, we propose a Model Predictive Control (MPC)-based truck docking driver assistance system. The objective of the system is to support the truck driver while parking the vehicle by means of visual instructions. MPC is an advanced control method that can be used to control Multiple-Input and Multiple-Output (MIMO) systems based on a finite horizon optimization. The control structure allows one to formulate a multi-objective control strategy with explicit constraints. This work has been conducted within the scope of the VIsion Supported Truck docking Assistant (VISTA) project and the practical application of the proposed system is to experiment with an MPC-based approach for the VISTA system currently in development. To determine the optimal control action, the proposed MPC-based driver assistant makes use of a kinematic model describing the motion of the vehicle as well as a second-order linear time-invariant model representing the driver’s behaviour. The system is examined by testing four performance categories: path tracking error, robustness, computational speed, and driver acceptance. The performance of the system is tested with professional truck drivers and people without a truck driver’s licence in a Virtual Reality (VR) simulation. The results suggest that the proposed MPC-based driver assistant is able to perform well regarding reference path tracking and is robust against driver errors, with satisfactory computational speed. The feedback and comments from the professional drivers during testing also indicate definite possible advantages of using the system. As of now, the MPC-based solution is preferred over previous concepts of the VISTA system.","Model Predictive Control; Advanced Driver Assistance Systems; Truck-trailers; articulated vehicle","en","master thesis","","","","","","","","2022-09-17","","","","Mechanical Engineering | Systems and Control","",""
"uuid:393d8e74-bcd0-40a9-86d7-3e97116a0f7a","http://resolver.tudelft.nl/uuid:393d8e74-bcd0-40a9-86d7-3e97116a0f7a","Integrating Machine Learning and Computational Physics to Assess Crack Pattern Similarity in Masonry Buildings","Ajithkumar Pillai, Krishna (TU Delft Civil Engineering and Geosciences)","Giardina, Giorgia (mentor); Slobbe, Arthur (mentor); Rózsás, Árpád (mentor); Mehrotra, A.A. (mentor); Rots, J.G. (mentor); Delft University of Technology (degree granting institution)","2022","Cracks in masonry structures are a cause for concern as they signal a potential lack of functionality and/or aesthetics. It thus becomes important to identify the cause of damage in order to mitigate it and to prevent its occurrence in the future. Similarities in crack patterns may correlate to similarities in the damage cause. Currently, the assessment of similarities in crack patterns and their corresponding damage causes is done by masonry experts and structural engineers. This process is often expensive and subjective. The use of a Convolutional Neural Network (CNN) may offer an alternate robust and dependable means to automate the assessment of masonry crack patterns by processing their images. <br/><br/>The main research goal of this MSc thesis is to answer how accurately can the CNN -- fitted to data generated from finite element models -- estimate masonry crack pattern similarities. To develop a neural network that can perform such an automated assessment of masonry crack patterns with a high degree of accuracy, a large number of crack patterns with similarity ratings given by human experts are required. This data is collected in increasing complexity, first from a statistics-based approach by generating synthetic crack patterns from Markov walks. This is followed by a computational physics-based approach, such as the Finite Element Method (FEM), that generates crack patterns on 2D masonry façades subjected to differential settlements and out-of-plane loads. Finally, real-world data is also collected. This data is used to fit and test a convolutional neural network developed by Kleijn (Kleijn, 2022). Continuing along the previous line of research done at TNO (where 12 crack patterns were chosen and developed using the statistics-based approach), this thesis focuses on developing parametric finite element models of 8 out of these 12 Pattern IDs. Additionally, real-world images are also collected from Gouda in The Netherlands. This data is then used to form crack pattern image pairs that can be assessed for their similarities by 28 raters using three similarity label categories: crack pattern similarity label, damage severity label, and the overall similarity label. Using these labels, the raters assessed 2587 image pairs generated from the statistics-based approach, 500 image pairs from the computational physics-based approach, and 50 image pairs from the combination of images from the statistics-based approach, computational physics-based approach, and the real-world cases. <br/><br/>An inter-rater agreement analysis is performed on the similarity assessments using Krippendorff’s alpha measure. Additionally, the agreement of each rater with a chosen standard rater is studied using Lin’s Concordance Correlation Coefficient (CCC). Using Lin’s CCC, the intra-rater agreement is also assessed for the standard rater to see how consistent a rater is with their own annotations. These labelled image pairs are then used to fit and test the regression neural network to evaluate its accuracy in predicting the similarity labels. The neural network is also fitted to and tested with various combinations of labelled data to study its generalisability.<br/><br/>It is found that in all three sets of data, Krippendorff’s alpha is less than 0.80 for all the labels, which indicates an insufficient agreement among the raters. It is also seen that, in general, agreement among the raters increases with their experience level, i.e. the descending order of agreement within the rater group is: industry experts, PhD students, and MSc students. Studying the Lin’s CCC of each rater’s performance compared to that of the standard rater helps to choose the raters who can be considered as reliable as the standard rater. Additionally, the intra-rater agreement analysis of the chosen standard rater shows that the highest self-consistency (agreement) is achieved for the crack pattern similarity label, followed by the overall similarity label and finally the damage severity label, with corresponding Lin's CCC values of 0.96, 0.86 and 0.72, respectively.<br/><br/>The neural network is tasked to predict the similarity level in each similarity rating for each image pair in the test sample. The ground truth of this neural network is established by averaging the similarity ratings given to each image pair by multiple raters. It is found that the neural network is able to achieve a sufficiently high degree of accuracy when fitted to and tested with all the image pairs generated from the computational physics-based approach. The crack pattern similarity label, the damage severity label, and the overall similarity label achieve an accuracy of 87%, 82%, and 69%, respectively. However, the generalisability experiments on the neural network that consist of predicting the similarity of a type of crack pattern image pair that is not included in the fitting data set, show very poor performance with respect to the prediction accuracy of the similarity labels. When the neural network attempts to predict the similarity of Pattern ID or a façade geometry that it did not see in the fitting procedure, it predicts all three labels with an accuracy that varies from 40% to 50%. Additionally, the neural network is also fitted to images generated from the computational physics-based approach and then tested with a pool of image pairs generated from the statistics-based approach, computational physics-based approach, and real-world images. The average accuracy with which the three similarity labels are predicted is even lower, lying between 25% and 40%. <br/><br/>This MSc thesis concludes that the neural network fitted to data generated from the computational physics-based approach and assessed by all the raters is able to predict the crack pattern similarity label, the damage severity label and the overall similarity label with sufficiently high degrees of accuracy. However, the generalisability experiments on the neural network show very poor results. This indicates that in order to achieve a greater prediction accuracy, the neural network may need to be fitted to a considerably larger sample of crack patterns that covers all of the relevant situations. Furthermore, the substantial inter-rater variability in the labelling of crack pattern image pairs suggests that even an ideal neural network architecture may not be able to overcome the inconsistencies in the fitting data.<br","Masonry; Crack pattern; Similarity assessment; Computational physics; Finite element analysis; Krippendorff's alpha; Lin's concordance correlation coefficient; Machine learning","en","master thesis","","","","","","","","","","","","Civil Engineering | Structural Engineering | Structural Mechanics","",""
"uuid:f31da8d4-dacb-4438-b2f6-ee2b2ddc1ea2","http://resolver.tudelft.nl/uuid:f31da8d4-dacb-4438-b2f6-ee2b2ddc1ea2","Life Cycle Fatigue Damage Estimation for Military Off-Road Vehicles","ten Hoopen, Rick (TU Delft Mechanical, Maritime and Materials Engineering)","de Winter, J.C.F. (mentor); van Rijn, H.R. (mentor); Driessen, T. (graduation committee); Shyrokau, B. (graduation committee); Delft University of Technology (degree granting institution)","2022","An important durability question is whether military off-road vehicles can cope with the fatigue damage from extreme random, complex, and non-stationary loads for the design life of up to 30 years. An accurate life cycle fatigue damage estimation is essential for military off-road vehicles as the lives of military personnel can depend on a durable vehicle in future use. In addition, minimizing costly data acquisition time leads to a faster validation of a prototype vehicle, which in turn means the vehicle is taken into service faster. Hence, this study aimed to optimize existing time-domain load extrapolation methods and compare them in fatigue damage to frequency-domain models specifically for military off-road vehicles while minimizing data acquisition time and costs. An error below 5% between the fatigue damage estimations and the validation is deemed satisfactory.<br/><br/>Two time-domain and six frequency-domain fatigue damage models were applied on a varying fraction of the training dataset in a case study using off-road data from the Dutch Army. From 270 km of unique off-road strain measurements two subsets were created, i.e. a training subset of 90 km and a validation subset of 180 km. These measurements represent the actual use in all operating conditions, yet still lack the load cycles from extreme events which rarely occur. All eight models were optimized to fractions of the training set and compared to the fatigue damage of the full training set and validation data.<br/><br/>None of the models performed satisfactory( i.e.&lt;5% error) if less than 36 km or 40% of the training dataset is used. Fatigue damage was underestimated up to 30% compared to the full training dataset. Above 36 km or 40% of the training set the error in fatigue damage estimations stabilizes indicating the training data contains sufficient information regarding rare and exteme loads. Yet, only one time-domain and one frequency-domain model achieved an error below 5% between the estimation on the training data and the validation data.<br/><br/>This shows that for a tail heavy off-road load distribution in the time-domain or wideband PSD in the frequency-domain only a selection of models provide accurate results when the measured signal contains sufficient extreme loads. The results give the Dutch Army a fatigue damage estimation method which provides good accuracy whilst minimizing the required data acquisition. However, it is recommended to expand the model to validate the results for other types of military off-road vehicles, a broad range of material parameters, and user profiles.","Life cycle fatigue; Fatigue damage estimation; Military applications; Off road vehicles","en","master thesis","","","","","","","","","","","","Mechanical Engineering","",""
"uuid:0466e1ed-1a67-469f-aff5-f9eb99a2e23f","http://resolver.tudelft.nl/uuid:0466e1ed-1a67-469f-aff5-f9eb99a2e23f","Financial feasibility of large-scale adaptation strategies for future SLR in northern Europe: NEED vs dike reinforcement","Nota, Hugo (TU Delft Civil Engineering and Geosciences)","Jonkman, Sebastiaan N. (mentor); Ragno, E. (mentor); Rutten, M.M. (graduation committee); Diaz-Loaiza, Andres (graduation committee); Delft University of Technology (degree granting institution)","2022","The effects of climate change are felt all around the world. An increased sea level goes hand in hand with an increased risk of flooding. To combat this, the coastlines must be reinforced to withstand future sea levels. However, repeatedly reinforcing coastlines to keep up with the sea level rise (SLR) could prove extremely costly. An alternative approach would be to shorten the coastline, as the Netherlands did with the Afsluitdijk to enclose the IJsselmeer. Looking at Europe, Groeskamp and Kjellsson (2020) proposed the construction of the Northern European Enclosure Dam (NEED) — a dam that would disconnect the North and Baltic Seas from the Atlantic Ocean. In this way, it would protect fifteen northern European countries against the accelerated global mean SLR (GMSLR), as it simultaneously shortens the coastline that requires reinforcement. This thesis aims to determine whether the NEED (Adaptation Strategy 2) would be a financially favourable adaptation strategy over raising the coastal defences on a country-by-country basis (Adaptation Strategy 1) around the North Sea to combat future GMSLR, and if so, at which GMSLR. <br/><br/>Through the use of the GLOFRIS model framework it was possible to estimate that by 2080 a total of 15,000 km2 would be inundated, affecting 9.5 million people and resulting in damages up to 1 trillion € for all fifteen countries combined. Reinforcing the regional flood protections (Adaptation Strategy 1) is estimated to have a total cost range of 245 to 335 billion € for a 1-metre GMSLR with an increase in costs between 170 and 235 billion € per metre GMSLR. The construction of the NEED (Adaptation Strategy 2), using an earth-fill dam design with 1:6 slopes on either sides, is estimated to be just under 1.1 trillion €, with an increase in costs of 11 billion € per metre GMSLR.<br/><br/>It was found that the NEED flood protection adaptation strategy will eventually become more financially favourable over the regional strategy. Estimated to be more cost-effective beyond 5.15 metres GMSLR, which is associates with construction costs of roughly 1.15 trillion €. This GMSLR for scenario SSP5-RCP8.5 is expected to occur between 2280 and 2660, approximately. However, as the total costs are greatly contingent upon the core material, modifying slope angles of the NEED design will lead to a significant reduction in volume and, hence, costs. For the alternative designs with a 1:4 and 1:5 slope, the total costs are reduced by 17% and 34%, respectively. For these designs, the NEED will already become favourable at 3.35 and 4.25 metres GMSLR, respectively.<br/><br/>Several cost distributions have been created based on the four aspects that have been investigated, namely (i) coastline reinforcement length, (ii) size of inundated area, (iii) population exposed and (iv) economic damages caused by flooding. Together with the extrapolated regional costs per country, it is possible to determine which distribution is the most and least financially favourable for each country and whether contributing to the NEED is even favourable at all from the perspective of each country.<br/><br/>This research scrutinised the costs, effects and consequences of the most extreme scenario that generated the greatest exposure indicator values (i.e. SSP5-RCP8.5 combined with a return period of 1000 years). Through this<br/>assessment, it was possible to estimate the costs associated with both adaptation strategies, and furthermore, to determine at which GMSLR one strategy surpasses the other in financial attractiveness and when this GMSLR can be expected. However, it should be noted that recent studies have shown that, in reality, the most extreme scenario might, unfortunately, turn out to be even more extreme than the most extreme scenario assumed in this thesis. And as the consequences strongly dependent on how climate change will unfold in the future, the costs to combat and the timing of such GMSLR occuring will differ.<br/><br/>The results retrieved from this research provide insight into when the NEED flood protection adaptation strategy will become a better alternative to regional flood protection reinforcement. However, it should be borne in mind that it is not a matter of ‘either-or’, but rather ‘both-and’, as regional dike reinforcement cannot entirely be omitted when deciding to construct the NEED. Instead, a balance must be found in the extent to which regional dike reinforcement is required to protect the countries while the NEED is under construction. So there are plenty of uncertainties and questions that require additional research to fully comprehend all the effects of this massive operation and making it feasible.<br","Flood Risk; Hydraulic Engineering; Hydraulic structures; Inundation maps; Economic damages; Population affected; Dike reinforcement; NEED; Northern European Enclosure Dam; Europe; Floods; SLR; Sea level rise; Flood adaptation strategies; Financial feasibility; global flood risk; GLOFRIS; GLObal Flood Risk with IMAGE Scenarios; FLOPROS; FLOod PROtection Standards; coastline maintenance","en","master thesis","","","","","","","","","","","","Civil Engineering | Hydraulic Engineering","",""
"uuid:8409a9f6-fbf6-4a82-bc84-88a49142b134","http://resolver.tudelft.nl/uuid:8409a9f6-fbf6-4a82-bc84-88a49142b134","Performance of Recirculated PAC for Organic Micropollutant Removal – Development of a Quick Lab Test","Wu, Yuhao (TU Delft Civil Engineering and Geosciences)","Lompe, K.M. (mentor); Rietveld, L.C. (graduation committee); Delft University of Technology (degree granting institution)","2022","Over the last decade, a wide range of organic micropollutants (OMP) has been regularly detected in surface water, groundwater and wastewater treatment plant (WWTP) effluent. These OMPs consist mainly of synthetic organic compounds (SOC) such as pharmaceuticals and pesticides. Although their concentrations in water bodies are usually low, they can cause potential risks to disturbance and affect human as well as environmental health, which has attracted the attention of governments and institutions to search for reliable and simple methods with low cost to remove them. Powdered activated carbon (PAC) adsorption is considered to be an efficient, convenient and cheap method to remove OMPs with low concentrations. However, the adsorption capacity of PAC is not fully used due to a short contact time in the traditional adsorption treatment of dosing PAC into water directly. Therefore, some processes such as the Actiflo Carb or PAC membrane reactors, recirculate PAC in order to increase the contact time. Predicting the performance of older, recirculated PAC is difficult. The objective of this project was to simulate performance of aged PAC using a simple lab-scale experiment. Three different water matrices (tap water, WWTP effluent and diluted WWTP effluent) were used to make the OMPs solutions with 18 selected OMPs of 10 ug/L. PAC was added into the OMPs solutions to make two concentrations of PAC suspension (0.5 g/L and 0.25 g/L). Samples were collected at fixed time intervals. The breakthrough behavior of selected OMPs for aged PAC was then investigated and determined by analyzing the OMPs concentration, UV254 and DOC of samples. The setup was successfully used to record breakthrough curves of 5 different OMPs (Gabapentin, Sulfadimethoxine, Sulfamethoxazole, Metformin and Clofibric acid) and UV254 in 3 different water matrices. Gabapentin was the least adsorbable in tap water and the breakthrough occurred after 10 hours, while in WWTP effluent, Sulfadimethoxine was the least adsorbable OMP with the complete breakthrough time of 14 hours. Propranolol was the most adsorbable compound in both tap water and WWTP effluent. The breakthrough of UV254 was observed later in tap water and WWTP effluent, about 24 hours and 22 hours, respectively. However, parameter DOC can not be used to predicate the breakthrough of OMPs accurately. Model fitting based on the experimental adsorption data was also included.","recirculated powdered activated carbon; organic micropollutants; adsorption; breakthrough curve; model fitting","en","student report","","","","","","","","","","","","Civil Engineering | Environmental Engineering","C53cc5303",""
"uuid:b13f9f20-4241-404f-9c95-7b004790b7ff","http://resolver.tudelft.nl/uuid:b13f9f20-4241-404f-9c95-7b004790b7ff","Virtual bouwteams: a qualitative report on how to implement short-distance virtual teams by focusing on collaboration","Gomez Castillo, Tzitly (TU Delft Civil Engineering and Geosciences)","Chan, P.W.C. (graduation committee); Jalali Sohi, A. (mentor); Wang, T. (graduation committee); Op ‘t Ende, H. (graduation committee); Tegelbeckers, N. (graduation committee); Delft University of Technology (degree granting institution)","2022","The construction industry is shifting towards a more collaborative environment through relational contracts following the early contractor involvement approach. In the Netherlands, one of them is the bouwteam process. The peak of collaboration in bouwteam projects and the construction industry is during the pre-construction phases since there is a higher complexity due to the uncertainty and interdependence of elements. On the other hand, technology innovations opened the way to work across boundaries in a remote way, which is known as virtual teams. Taking both aspects into account, the importance of collaboration through relational contracts and the technological innovations, this research seeks to seize the opportunity to expand the traditional working scope into a virtual or hybrid one in a way that doesn’t jeopardize the performance of projects but rather improves it. Based on the problem definition and objective of the present research, a main research question is defined: How focusing on collaboration improves virtual teams in the bouwteam phase?","Virtual teams; Collaboration; Short-distance; Bouwteams; Bouwteam phase","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:4c3e0618-7b08-48de-99d9-bb2da54384ea","http://resolver.tudelft.nl/uuid:4c3e0618-7b08-48de-99d9-bb2da54384ea","Collection as a service for denim brands and retailers","Jacobs, Anne (TU Delft Industrial Design Engineering)","Price, R.A. (mentor); Hultink, H.J. (graduation committee); Rijken, Peter (graduation committee); Veenhoff, James (graduation committee); Delft University of Technology (degree granting institution)","2022","This thesis aims to find a new collection method for post-consumer denim garments that fits the future context and the needs of ecosystem stakeholders. The thesis is aimed at all who want to work on a circular fashion industry from a business- or ecosystem perspective. The design solution is aimed at brands and retailers.<br/><br/>In a circular economy, denim is recycled at the end-of-life. To scale up recycling, collecting needs scaling up. Now municipalities grant the right to collect garments to collectors. They use textiles containers. The profitability of this business model is decreasing and many garments still end up in the trash.<br/><br/>Stakeholders in the denim industry were interviewed about the barriers, drivers and ideal situation for collecting or working with post-consumer (recycled) denim. The most critical barriers stakeholders mentioned are: clothing is treated as a waste stream; the company’s scale is too small for impact; (fast) fashion is counteractive to circularity; financial barriers; a lack of transparency in the ecosystem; needing to convince consumers to hand in clothes; and uncertainties around legislation. The most important drivers they mentioned are: legislation (the Extended Producer Responsibility) leads to action; financial incentives (from legislation); more attention for sustainability; and growing consumer enthusiasm for sustainability. Consumers often value attributes like a comfortable fit over sustainability when buying garments. There is a need to educate the consumer on topics like handing in clothes. For an ideal situation, industry stakeholders mentioned: collaboration between stakeholders; sustainability is profitable; brands and retailers take care of different steps in the value chain; more transparency. They also asked: should the future be local or global; and should we create closed loops within a brand or the industry? Trends that impact the ecosystem are trends in logistics and legislation.<br/><br/>Brands and retailers will be impacted by the Extended Producer Responsibility (EPR) and will bear responsibility for collecting garments at the end-of-life. Therefore, the design challenge is to facilitate the collection of worn denim for brands and retailers. The thesis studied the case of De Rode Winkel to learn more about jeans collection in stores. This gave insight into the volume composition of the collected jeans. The retailer kept some of the jeans, which led to a decrease in revenue for the sorter. A different approach to the business model was needed. Therefore, the design challenge was redefined to develop the business case of collection as a service.<br/><br/>In the final design, Textiles2Textiles offers collection as a service (CaaS) to denim brands and retailers. The consumer hands in their garment at a store and receives a discount. The service, called the Collecting Collective, takes care of educating the consumer; providing retailers and brands with the means to collect; and sorting the garments and sending them to the right step in the value chain. The service can exist in a system without and with the EPR. At first, the service will be only for denim garments, but will later extend to the collection of all garments.","circular economy; circular textiles; denim; textiles collection; circular fashion; collection as a service","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:42c0cebb-c2ab-43b4-b94c-50aa5d3dc139","http://resolver.tudelft.nl/uuid:42c0cebb-c2ab-43b4-b94c-50aa5d3dc139","Global and local analysis of the mechanical and structural characteristics of carotid atherosclerotic plaques for rupture risk assessment","De Miguel Muñoz, Pablo (TU Delft Mechanical, Maritime and Materials Engineering; Erasmus MC)","Akyildiz, A.C. (mentor); Delft University of Technology (degree granting institution)","2022","The rupture of atherosclerotic plaques present in vital arteries is the main trigger of fatal cardiovascular events, such as heart attacks and strokes. Plaque rupture is a mechanical failure of the fibrous plaque tissue that ensues upon large deformations of the tissue, induced by the blood pressure. Current knowledge on the rupture characteristics of plaque tissue is, however, scarce and limited to global, aggregate tissue properties, although plaque rupture is a local phenomenon. Hence, local mechanical and structural evaluations of the heterogeneous, highly collagenous plaque tissue are required for better understanding the plaque rupture.<br/><br/>To achieve this, a combination of mechanical and structural analyses was performed in this study. The collagen structure of human carotid plaques was imaged by means of Multiphoton microscopy using Second-Harmonic Generation signals (MPM-SHG), and it was characterized in terms of fiber orientation and dispersion. Subsequently, the imaged plaques were subjected to uniaxial tensile tests until rupture to characterize their mechanical response. Apart from the traditional global analysis, the local mechanical response was analyzed through Digital Image Correlation (DIC). This way, the structural heterogeneity of the plaque tissue was assessed and the role of collagen fiber organization in plaque mechanics was investigated locally.<br/><br/>The structural analysis of the plaque tissue samples demonstrated a predominant overall fiber orientation along the circumferential direction of the artery. Yet, high local variability in collagen orientation and dispersion was measured. The global, average mechanical response of the plaques showed a non-linear behavior, typical to many soft biological tissues and the local mechanical analysis demonstrated highly heterogeneous strain distributions in the plaques. Furthermore, regions that were about to rupture, showed higher tensile strains compared to the overall plaque strain, implying the possibility of establishing strain as a predictive metric for rupture. Whereas the global analysis did not yield any important correlation between the overall collagen structural parameters and the global mechanical tissue response, the local analyses indicated that the regional predominant fiber angle might influence the regional strain, and probably the plaque rupture risk.<br/><br/><br","Biomechanics; Atherosclerosis; Plaque rupture; Collagen; Second-Harmonic Generation; Digital Image Correlation","en","master thesis","","","","","","","","2023-02-16","","","","Biomedical Engineering","",""
"uuid:32b6536d-0a4b-47d0-9186-1ed1f79d79ea","http://resolver.tudelft.nl/uuid:32b6536d-0a4b-47d0-9186-1ed1f79d79ea","Extracting and utilising heat from an hydrogen production plant","Hermans, Ewoud (TU Delft Mechanical, Maritime and Materials Engineering)","van Wijk, A.J.M. (mentor); Blom, Wouter (mentor); Delft University of Technology (degree granting institution)","2022","In order to reach the climate goals the use of fossil fuels needs to decrease and green solution need to provide the energy of the future. Wind and solar will probably supply a large fraction of our electrical power need in the future. Because of the nature of these sources the demand for electrical power will not always be balanced with the supply. Industrial companies are responsible for a large portion of the total greenhouse emissions. Some of the emissions are process related, but most are due to the demand for high temperatures in the process. Today fossil fuels like coal and gas are used to achieve these high temperatures. Hydrogen provides a solution for the problems as it can be used as a storage medium and as an energy source to achieve high temperatures. In order to provide the world with sufficient hydrogen needed for the transformation to greener solu­ tions the production of hydrogen needs to increase. Hydrogen can be made from fossil fuels, but to achieve our goals the production of green hydrogen is needed. Green hydrogen is made using green electricity and the electrolysis process. In this thesis the alkaline electrolysis process is reviewed. During the production of hydrogen using the alkaline electrolysis process, a large fraction of the electri­ cal energy is converted to thermal energy. The aim of this research is to gain insight into the possibility of extracting the thermal energy form the process so it can be used in a district heating network. Based on the thermal demand form the heating district and the power supply to the hydrogen plant four case studies are evaluated. Using a pinch analysis, a process flow diagram is designed for each case study after which every design is modelled. Using a heat pump and thermal storage the supply of thermal energy and the demand from the district heating network are balanced in order to reach a high overall efficiency.","hydrogen; Alkaline; heating district","en","master thesis","","","","","","","","2023-02-01","","","","","",""
"uuid:e371413d-ac37-4fc8-aa24-0edd46d00ce0","http://resolver.tudelft.nl/uuid:e371413d-ac37-4fc8-aa24-0edd46d00ce0","Determining the speed of sound in curved bones","Vermeulen, Mark (TU Delft Applied Sciences; TU Delft Electrical Engineering, Mathematics and Computer Science)","Vuik, Cornelis (mentor); Verweij, M.D. (graduation committee); Dubbeldam, J.L.A. (graduation committee); Verschuur, D.J. (graduation committee); Mozaffarzadeh, M. (graduation committee); de Jong, N. (graduation committee); Delft University of Technology (degree granting institution)","2022","Current research on osteoporosis detection and transcranial imaging suggests that it is necessary to find a method to calculate the speed of sound in curved bones. A popular method to find the speed of sound in bones is by the bidirectional axial transmission technique. Currently, this method assumes that the arrival time of the head wave depends linearly on the source-receiver distance. For curved bones this assumption is not valid. The arrival time of the head wave as a function of the source-receiver distance follows a curved trajectory. In this report, we attempt to find an extension to the current method that also works for curved bones, and evaluate how accurate the results of this extended method are.<br/><br/>This extension is based on the semblance method, that quantifies how well a certain trajectory agrees with the received data. In the first part of our project, theoretical trajectories are calculated for flat and semicircular bones. Furthermore, a numerical method is discussed to find these trajectories for arbitrary geometries. Comparing the trajectories corresponding to different velocities using the semblance methods allows for the determination of the speed of sound. <br/><br/>The accuracy of this extended method is evaluated by computer simulations. In these simulations, a Philips P41 Cardiac Sector Probe consisting of 96 elements was used to perform measurements on three different geometries. These geometries consisted of three different single interfaces between water (simulating soft tissue) and bone. The first interface consists of a straight interface between a 2 mm thick layer of water and a 5 mm thick layer of bone (that continues until the bottom edge of the simulation). The second simulation is the same, but the interface is rotated 2 degrees around its midpoint. In the third and fourth simulation, the interface is a semicircle with a 50 mm and 40 mm radius, respectively. The speed of sound in the bone was taken to be 3 mm/&#x1d707;s. The received data was interpolated by a cubic interpolation with a refinement of 4. Both the bidirectional and the extended,<br/>trajectory-based method were applied on the raw and interpolated data.<br/><br/>For the flat interface, the bidirectional method performed slightly better than the trajectory-based method (0.13% and 0.30% error, respectively). The same is true for the tilted interface (0.16% and 0.23% error). Interpolation did not affect the results here. For the 50 mm semicircular interface, the trajectory-based method performed much better than the bidirectional method: it had a 0.10% error compared to a 2% one. This was also true when the interpolation was applied: then the errors were 0.3% and 1.97%. Similar<br/>improvements were seen for the 40 mm radius semicircle. The higher error of the trajectory-based method for the flat and tilted interfaces can be explained by small errors in the additional assumptions that this method makes.<br/><br/>One drawback of the trajectory-based method is that there can be problems interpreting the results. This can be seen in the semblance plots, which plot the semblance coefficient (how well the trajectory fits the data) against the test velocity. For the bidirectional method, these plots clearly have a single biggest peak. For the trajectory-based methods the plot contains multiple large peaks. Furthermore, for the semicircular bone this plot contains a flat peak, which can cause multiple test velocities to have approximately the same semblance. This is a problem, since it means that small changes to the experimental setup can cause big changes in the calculated velocity. Indeed, this can be seen for the trajectory-based method on the 40 mm radius semicircular bone, which has a 1.6% error without interpolation (0.43% with interpolation). Further research could examine solutions to this problem, such as increasing the window size of the semblance method, taking the average velocity over flat peaks, or using an alternative to the semblance method. Finally, we conclude that the trajectory-based method represents an improvement over the bidirectional method when examining curved bones.","head wave; ultrasound; osteoporosis; imaging","en","bachelor thesis","","","","","","","","","","","","Applied Physics","",""
"uuid:f46a58ea-84c4-4d13-8880-0415b2d47c2f","http://resolver.tudelft.nl/uuid:f46a58ea-84c4-4d13-8880-0415b2d47c2f","A goal-oriented adjoint-based optimization approach to model vortex generator flows using smooth source term distributions","Sahu, Sidhartha (TU Delft Aerospace Engineering)","Hulshoff, S.J. (mentor); Delft University of Technology (degree granting institution)","2022","Vortex generators (VGs) are typically about two orders of magnitude smaller than their host component (such as an airplane wing). For this reason, conducting a fully-resolved RANS simulation to isolate their impact on the flow field is computationally expensive. This work presents a goal-oriented adjoint-based approach to model vortex generators using smooth source term distributions to make their simulations tractable.<br/><br/>Several approaches to modelling VGs have been proposed in the past. Phenomenological models such as BAY and jBAY form source term descriptions, while others directly model the vortex or its effects. Recently, a goal-oriented approach to model VGs was introduced. Florentie et al. optimized a set of discrete source terms in a cuboidal domain at the location of the VG, using a fully-resolved solution as a reference. The superior accuracy of the model motivated Dierickx et al. to develop a surrogate model of the optimized source term in order to extend its applicability to any mesh and account for the variability in boundary conditions (Inflow angle and Reynolds number). However, the reduced-order source term produced discretization errors due to the presence of steep gradients.<br/><br/>To overcome the shortcomings associated with the goal-oriented approach and its reduced-order modelling, in this work, a smooth-basis representation of a co-rotating VG array was constructed using a trust-region-based optimization algorithm. The descent direction was obtained from an adjoint system of equations formulated based on an unconstrained optimization problem involving an objective/goal functional and the RANS equations. <br/><br/>The developed framework produced source term distributions that were smooth enough to be resolved on a coarse mesh and accurate enough to generate a good representation of the VG’s effect on the flow field. Specifically, flow parameters such as the Reynolds stress, shape factor and boundary layer profiles corresponding to the fully-resolved simulation were accurately recreated on the coarse mesh. To account for the evolving inflow angle at the VG-surface junction during the flow field calculation, a surrogate model was constructed to vary the source term accordingly. <br/><br/>The developed smooth source term framework brings a new capability to aerodynamic design as, unlike the previous approaches, it can also be used to accurately model arbitrary flow control devices on relatively coarse meshes.","Goal-oriented optimization; Reduced-order model; Vortex Generator Modeling; CFD","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:39114415-f931-49f6-8ce3-9710b714e450","http://resolver.tudelft.nl/uuid:39114415-f931-49f6-8ce3-9710b714e450","Focus on underserved patients: Improving the collection of PROMs within the HIV outpatient clinic of the Amsterdam UMC","Wolterink, Sharda (TU Delft Industrial Design Engineering)","Melles, M. (mentor); Faber, J.S. (graduation committee); van der Valk, Marc (graduation committee); Moody, Kevin (graduation committee); Bedert, Maarten (graduation committee); Delft University of Technology (degree granting institution)","2022","Background:<br/>The HIV outpatient clinic of Amsterdam University Medical Centers (AUMC)is implementing digital patient-reported outcomes measures (PROMS) in routine care to improve the quality of life (QoL) for people living with HIV (PWH). We were asked to design tools to promote the participation of patient groups from Ghana and Nigeria.<br/><br/>Methods:<br/>Two sets of methodologies were used: qualitative research methods informed the development of a ‘patient journey’ and design-thinking methodologies informed the tool development. Participant observation and in-depth semi-structured interviews were conducted to gain insights into patient- and system-related characteristics. Design-thinking methodologies facilitated the transformation of qualitative data into insights that drove design concepts. Three ideation methodologies were used to create four concepts, leading to the final concept.<br/><br/>Results:<br/>Observations of 17 individual consultations (6 female, 11 male) at the HIV outpatient clinic resulted in six recurring themes. These themes were: Personal relationship; Disclosure; Impact of the diagnosis; Health literacy &amp; Health involvement; Communication; No-shows. The observations and additional literature research informed the development of an interview guide. Seven interviews (5 female, 2 male) were conducted with participants from Ghana and Nigeria. The observations and interviews informed the patient journey (PJ). The PJ showed that patients experience stress and anxiety prior to and during their hospital visit but fully trust doctors and nurses. Based on the insights the design challenge was addressed, leading to the following concepts: “Peer support community”; “Wellbeing Diary”; “Waiting Room Inspiration”; “Hospital Roadmap”.<br/><br/>Conclusions:<br/>Amsterdam UMC will adopt the “Wellbeing Diary” which embodies the following characteristics: independence from relying on other organisations or infrastructure for implementation; a visual design that can be used independent of literacy level; and its affordability. The paper diary will provide a low-threshold tool for people to record PROMs-like experiences that will prepare them for their consultations at the outpatient clinic.<br","Medisign; Design for Interaction; Human Centered Design","en","master thesis","","","","","","","","","","","","Design for Interaction | Medisign","",""
"uuid:1202e9bd-cd42-45b3-a300-64524432c9e1","http://resolver.tudelft.nl/uuid:1202e9bd-cd42-45b3-a300-64524432c9e1","Establishing the required lock capacity and configuration in case of canalisation of the river Waal: An exploratory study","Ligtenberg, Jourian (TU Delft Civil Engineering and Geosciences)","van Koningsveld, M. (mentor); Voorendt, M.Z. (graduation committee); Blom, A. (graduation committee); Koedijk, O.C. (graduation committee); Vinke, Frederik R.S. (graduation committee); de Jong, Jurjen (graduation committee); Bolt, Ernst (graduation committee); Delft University of Technology (degree granting institution)","2022","The river Waal is part of an economic important transport-corridor that connects the ports of Antwerp, Rotterdam and Amsterdam to Germany. Ongoing processes such as (1) climate change, (2) large scale river bed erosion and (3) up-scaling of vessels threaten the future navigability of the river. This will lead to massive economic damages as taken in 2018 (Strengs et al., 2020). Canalisation of the river by means of weir-lock complexes is a considered by Rijkswaterstaat to improve inland navigation during periods of low discharge and prevent economic damages. This leads to the primary goal of this study; investigate the required lock capacity to provide smooth and reliable passage of the river Waal now and in the future. <br/><br/>A literature review was conducted to assess the future development of the drivers of the worsening navigation conditions and to gain insight in market- and fleet developments. The developments in the drivers underline the urgency for measures. The development of the fleet navigating on the river Waal is characterised by up-scaling for the past 20 year. This trend is expected to continue the coming years. Future market developments are very uncertain due to the energy transition and the nitrogen crisis, making it very difficult to make accurate projections on future fleet intensities and compositions. Therefore a range of traffic intensities is used to characterise future fleets that encounter the lock complexes. <br/><br/>The number and locations of the lock complexes is investigated by analysing available nautical depths and water levels along the river Waal for several stationary discharges at Lobith. Water levels are set up to a level such that navigation for all vessels (fully loaded) is possible. From a financial perspective it is most attractive to minimise the number of weir-lock complexes, however this is contrary to flood safety aspects on the river Waal. Installation of two weir lock complexes is considered plausible taking into account minimising the number of weir-lock complexes and flood safety. <br/><br/>Vessel traffic simulations are conducted in SIVAK III to investigate the performance of multiple lock configurations in terms of average waiting time and service level. SIVAK III is able to simulate the passage of vessels at an individual level in a network of waterways and locks. A fleet analysis on a representative IVS data set is conducted to provide SIVAK III with fleet intensities, fleet mixes and arrival patterns. <br/><br/>For the upstream (rkm 905) lock complex is recommended to use a lock complex with 4 chambers with dimensions 28.4x305m, but with in mind the option for a 5th chamber in the future. This lock complex is able to handle the current fleet +10% intensity within the considered requirements. A 5th lock chamber of the same size can handle an increased intensity of +30% including strong up-scaling effects. For the downstream lock complex (rkm 941) it is recommended to use a lock complex with 4 chambers and dimensions 25x330m. The lock complex is able to handle the current intensity +30%.<br","Lock Chamber; Inland shipping; Locks; Weirs; SIVAK; Simulation model","en","master thesis","","","","","","","","","","","","Civil Engineering | Hydraulic Engineering","",""
"uuid:ee472a92-c634-47b8-bcee-d828ee29b49e","http://resolver.tudelft.nl/uuid:ee472a92-c634-47b8-bcee-d828ee29b49e","Multi machine approaches for conflict resolution under moving block signalling","Janssens, Mathilde (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Transport Engineering and Logistics)","Reppa, V. (mentor); Quaglietta, E. (mentor); Negenborn, R.R. (graduation committee); Goverde, R.M.P. (graduation committee); Middelkoop, Dick (graduation committee); Delft University of Technology (degree granting institution)","2022","Railway networks are to play an increasingly large role in European transportation. This has boosted the urgency of railway innovations, of which the development of decision support systems for conflict resolution is an important aspect. This research contributes to this development by formulating a suitable mathematical approach for railway networks equipped with moving block signalling systems. Two dispatching actions to reschedule trains are applied, namely retiming and reordering. The designed approach is an extension to an existing method, based on graph theory, that is able to reschedule trains in case of conflict. The novel method uses additional node- and arc types in order to ensure moving block suitability. The new node type enables the possibility to create nodes that are related to trains, rather than infrastructure. The new arc type ensures a continuously safe time interval between two trains in the absence of trackside signals. An optimization problem, with the objective of minimizing the maximum propagated delay, is formulated. Hereafter, the performance is evaluated by a case study in the Rotterdam-The Hague corridor. According to the experimental results, the designed model is able to reduce delay propagation up to 50% for the majority of input situations within 10 seconds of computation time. Overall, the designed method shows promising results, but further research will be necessary to make it applicable in practice.","Railway traffic management; Railway conflict resolution; Alternative graph theory; moving block signalling","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Multi-Machine Engineering","",""
"uuid:aaa06d3d-6cd5-4ad7-a083-65077aa7a3bd","http://resolver.tudelft.nl/uuid:aaa06d3d-6cd5-4ad7-a083-65077aa7a3bd","Differences in the mediolateral control of balance during gait between 2D and 3D bodyweight support systems","Rademaker, Suzanne (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Biomechanical Engineering)","Vallery, H. (mentor); Forbes, P. (mentor); Moore, J.K. (graduation committee); Delft University of Technology (degree granting institution)","2022","Training with bodyweight support (BWS) systems can improve the likelihood of regaining normal locomotor abilities for neurologically impaired patients. It is known that people alter their gait parameters when walking with BWS. However, it is unclear whether 2D (vertical and lateral support) and 3D (only vertical support) BWS systems affect these gait parameters differently. In this study, participants walked overground in both a 2D and a 3D BWS system to investigate the effects of this lateral support. To compare the contribution of the vestibular system between the different BWS systems, participants received galvanic vestibular stimulation (GVS). Motion capture and force plates were used to find the coupling between the GVS stimulus and the mediolateral ground reaction forces and to calculate the gait parameters. Differences in gait parameters were observed between the 2D and the 3D system. Compared to unsupported gait, participants increased their step width variability by ~10% in the 3D system. Contrarily, participants decreased step width variability by more than 15% in the 2D system. Mean step width decreased slightly in only the 3D system. The margin of stability did not change significantly in any condition. The coupling between the GVS signal and mediolateral ground reaction forces decreased in the 2D and 3D systems compared to unsupported gait, but no significant differences were observed between different BWS conditions. These results suggest that 2D and 3D BWS systems influence gait parameters differently and that they influence the contribution of the vestibular system to balance, but no significant differences between the systems can be observed in this aspect.","BWS; GVS; Gait; Rehabilitation","en","master thesis","","","","","","","","","","","","Mechanical Engineering | BioMechanical Design","",""
"uuid:99862608-6a9d-4dc5-9701-80b0576449e2","http://resolver.tudelft.nl/uuid:99862608-6a9d-4dc5-9701-80b0576449e2","Development of a computational thrombus model using finite element software LS-DYNA","Overschie, Serena (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Biomechanical Engineering)","Luraghi, G. (mentor); Gijsen, F.J.H. (graduation committee); Mirzaali, Mohammad J. (graduation committee); Delft University of Technology (degree granting institution)","2022","An acute ischemic stroke is one of the leading causes of death and is caused by a thrombus that occludes a cerebral artery. This thrombus reduces the cerebral blood flow and causes irreversible brain tissue damage. Mechanical thrombectomy is a safe and effective technique to remove the thrombus from the cerebral arteries and restore the brain's blood flow. The mechanical properties of the thrombus highly influence the success rate of mechanical thrombectomy. To investigate the mechanical behavior of the thrombus under different loading conditions, numerical simulations could be performed. The aim of this thesis is to develop an in silico thrombus model to investigate the mechanical behavior of the thrombus under compressive and tensile loading conditions using finite element analysis software LS-DYNA. Experimental data collected from the lab is used to describe the mechanical behavior in the numerical thrombus models.<br/><br/>The building process of the in silico models in this study is organized in three parts. Part one is the cube model, where the material properties and numerical stable settings are investigated. Also, a combination of compression and tension is applied to the cube model to capture both the compressive and tensile forces present during mechanical thrombectomy. Part two includes geometry models that mimic the clot analog samples' geometry used during the experimental compression and tensile tests. Part three includes a clot analog with an initial hole in the middle to understand the fracture behavior of the thrombus. Different approaches to model fracture of the thrombus are investigated. <br/><br/>Three different parts characterize this thesis, and each includes a method, results, and discussion section. The discussion section of each part is dedicated to the decisions that have been made in that specific chapter. A discussion section is also included in the chapter Experiments. The general discussion at the end of this study will include the findings of each model and the comparison with literature. Recommendations for further research are given at the end. <br/><br/>In conclusion, this study provides a framework for modeling the thrombus under tensile and compressive loading, where the thrombus is modeled as a hyperelastic material. Future work is advised to extend and improve the models developed in this study.","Finite Element Analysis; Thrombus mechanics; LS-DYNA","en","master thesis","","","","","","","","","","","","Biomedical Engineering","",""
"uuid:414026ac-b08e-49f3-8aca-1367766161bb","http://resolver.tudelft.nl/uuid:414026ac-b08e-49f3-8aca-1367766161bb","Optimising First-Class Pattern Match Compilation","Hartman, Toine (TU Delft Electrical Engineering, Mathematics and Computer Science)","Smits, J. (mentor); Visser, Eelco (graduation committee); Katsifodimos, A (graduation committee); Delft University of Technology (degree granting institution)","2022","Pattern matching is the act of checking if a value is in the set of values described by a pattern. Many programming languages provide constructs to pattern match on program values. Pattern matching constructs appear in different variants. Stratego, a term rewriting language, features first-class pattern matching, which attempts to match a pattern with a value. If the match is successful, variables in the pattern are bound. If the pattern does not match, the matching expression fails. Using choice and sequence operators, one can build expressions that attempt to match multiple patterns until a match succeeds, evaluating the expression that corresponds to that pattern. This is a common way of branching in Stratego programs. The Stratego compiler handles each match attempt independently, disregarding the context.<br/><br/>In this thesis, we research context-aware compilation of first-class matches, aiming to speed up pattern matching operations without requiring changes to programs. We research the resemblance of Stratego pattern matching with match cases, a pattern matching construct that is ubiquitous in functional-style languages. Previous research shows that match cases can be compiled efficiently by considering all cases together, instead of a single alternative at the time, during compilation. We develop behaviour-preserving translations from first-class matches to match cases and from match cases to decision tree automata. We efficiently represent these automata in Java, the target language of the Stratego compiler. All these changes integrate in the latest upstream version of the Stratego compiler.<br/><br/>We evaluate the performance of our altered compiler and observe an average speed-up of 4x on programs that rely heavily on pattern matching, at the cost of a 20% increase in compilation time and space.","pattern match matching compilation optimisation Stratego decision tree","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:61b8a986-1587-42a1-85d4-842fec7f4411","http://resolver.tudelft.nl/uuid:61b8a986-1587-42a1-85d4-842fec7f4411","Non-Consensus Opinion Models with Byzantine Nodes","Liu, Xinhan (TU Delft Electrical Engineering, Mathematics and Computer Science)","Kooij, Robert (mentor); Dubbeldam, J.L.A. (mentor); Achterberg, M.A. (mentor); Delft University of Technology (degree granting institution)","2022","Opinion dynamics models study how the interaction among people influences the opinion formation process. In most opinion dynamics models, only one opinion could exist in the steady state, which is different from the real-life opinion formation process. In 2009, Shao \emph{et al.} introduced a non-consensus opinion (NCO) model, which allows different opinions to coexist in the steady state. This thesis extends the NCO model by introducing a special type of nodes, Byzantine nodes, to play the role of dishonest people. The Byzantine NCO model is more in line with the real-world opinion formation process because it considers that people who express opinions are not always honest. I build an NCO model simulation algorithm and use this algorithm to perform simulations on three different network models: small-scall graphs, the Erdős–Rényi random graph and the scale-free network. In Byzantine node selection, three different strategies are proposed, according to the degree of the selected nodes. I find a new steady state for the NCO model: the cyclic steady state. The cyclic behaviour of the NCO and Byzantine NCO model is discussed, and some networks with a long cycle period are given. I also introduced a general method to generate networks with extremely long cycle periods. The other properties of the Byzantine NCO model, such as the probability of cyclic behavior, the final opinion distribution and the convergence time are researched. By performing simulations on the network models, I find that the introduction of Byzantine nodes could help the system to reach a steady state with a more balanced opinion ratio. The introduction of Byzantine nodes could decrease the critical threshold of the NCO model and promote the coexistence steady state. A mechanism in which Byzantine nodes influences the convergence time by influencing the steady state is suggested.","complex network; opinion model; Dynamic analysis; Social network","en","master thesis","","","","","","","","","","","","Electrical Engineering | Wireless Communication and Sensing","",""
"uuid:0d7b9b35-12ab-40aa-82bc-e8364bac1da8","http://resolver.tudelft.nl/uuid:0d7b9b35-12ab-40aa-82bc-e8364bac1da8","A capacity-effective scheduling approach for virtual coupling train operations","Miao, Rui (TU Delft Civil Engineering and Geosciences)","Quaglietta, E. (mentor); Bešinović, Nikola (mentor); van den Boom, A.J.J. (mentor); Goverde, R.M.P. (mentor); Delft University of Technology (degree granting institution)","2022","As the demand for the railways is expected to raise in the future, researchers are looking for ways to improve the railway capacity to increase the transport ability. Virtual coupling is a new solution based on the moving block technology, which further shortens train separation from absolute braking distance to relative braking distance. This will also affect the train service schedules for optimal operation under virtual coupling. In this study, a mixed integer quadratic programming method has been proposed to schedule the train services under virtual coupling on a network. Train operation as well as the headway and capacity benefit have been analyzed. In comparison to moving block, virtual coupling will change train operation on shared routes, and the capacity will be improved by different percentages for different timetable patterns and different service braking rates with or without speed limit restrictions.<br","Virtual coupling; Railway timetable; mixed-integer programming","en","master thesis","","","","","","","","","","","","Transport, Infrastructure and Logistics","",""
"uuid:21495d90-89dd-4a33-a1bf-a0f63cc19fa4","http://resolver.tudelft.nl/uuid:21495d90-89dd-4a33-a1bf-a0f63cc19fa4","How can enterprise architects improve their firm's digital innovativeness?","Verbraeken, Joost Verbraeken (TU Delft Technology, Policy and Management; TU Delft Electrical Engineering, Mathematics and Computer Science)","Janssen, M.F.W.H.A. (mentor); Scholten, V.E. (mentor); Delft University of Technology (degree granting institution)","2022","Innovating in the digital domain is almost essential for modern firms to be competitive.<br/>Anno 2021, seven of the ten largest companies worldwide belong to the digital sector compared to only one just twelve years ago.<br/>Digital technologies enable organizations to provide significant additional value that is incredibly scalable to many users, to streamline operations, and to help decision-makers gain valuable insights.<br/><br/>However, creating new and innovative digital technologies is challenging because the competition is intense.<br/>All digital systems within firms, including small experiments that might develop into successful digital innovations, are closely monitored by so-called enterprise architects.<br/>Enterprise architects stipulate the direction of the entire IT landscape, which makes the IT landscape significantly more manageable but perhaps also influences the development of new digital innovations.<br/>Surprisingly, the literature on the influence of enterprise architects on a firm's digital innovativeness is, to the best of the author's knowledge, literally non-existent.<br/><br/>Therefore, this research aims to provide insight into how enterprise architects influence their firm's ability to produce digital innovations.<br/>This is accomplished by measuring for more than 50 firms their digital innovativeness, the extent to which certain Enterprise Architecture (EA)-related factors apply, and the correlation between these data points.<br/>Additionally, the digital innovation readiness of each firm is measured by using several questionnaire items retrieved from prior research and is modeled as a moderating variable in the conceptual model.<br/><br/>The measure for digital innovativeness was found using a literature review and consists of 7 questionnaire items.<br/>The EA-related factors that might influence a firm's digital innovativeness (EA factors) were obtained from three different sources: scientific articles that contain previously identified EA factors, a Best Worst Method prioritization of the factors included in the DyAMM Enterprise Architecture maturity framework, and insights from EA experts.<br/>This approach resulted in the identification of 25 EA factors distributed among six categories: enterprise architecture design, alignment of the To-Be architecture with the business objectives, development of the proper architecture, usage of the architecture, implementation of the architecture, and enterprise architect behavior.<br/><br/>Ten statistically significant correlations were found.<br/>Hiring highly skilled enterprise architects is the highest-correlating factor I found that increases a firm's digital innovativeness.<br/>Other important influencing factors are whether the enterprise architects work in an agile manner, are aware of their role in the context of digital innovation, and actively identify external opportunities for innovation.<br/>Lesser important influencing factors are whether enterprise architects are involved in the strategic discussions, the existence of an open feedback culture, and the presence of a solid EA foundation on top of which it is easy for employees to innovate.<br/><br/>EA experts indicated that all the statistically significant correlations found are probably causal.<br/>Thus, whereas existing literature only hypothesizes that EA factors influence a firm's digital innovativeness, this study provides EA practitioners with the first empirically-grounded guidelines on how to do this.<br/>These findings are important considering the fact that digital innovativeness is often considered a key capability for firms to be competitive in the current rapidly changing markets.<br/><br/>This study empirically shows that an excellent enterprise architect is not only able to design and ensure compliance to an enterprise architecture, but also to behave in a way that stimulates the emergence and development of valuable innovative ideas.<br/><br/>EA experts also indicated for many other EA factors that they would expect these factors to positively influence firms' digital innovativeness, but that more samples are needed to be sufficiently confident in these causal relationships.<br/>Along with several other recommendations for future research, this thesis hopes to also provide a solid starting point for other researchers.","enterprise architecture; digital innovation; pls-sem","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:76b2fb99-0cf9-4fa2-8a1a-441326193fb9","http://resolver.tudelft.nl/uuid:76b2fb99-0cf9-4fa2-8a1a-441326193fb9","Translationally Accelerating Wings in Ground Effect: A Numerical Study","Pathanadka, Chinmaya (TU Delft Mechanical, Maritime and Materials Engineering)","Elsinga, G.E. (mentor); Pourquie, M.J.B.M. (mentor); Overmars, E.F.J. (mentor); Westerweel, J. (graduation committee); van Zuijlen, A.H. (graduation committee); Delft University of Technology (degree granting institution)","2022","Aerodynamics has played a significant role in the industry of motorsports in improving the performance and handling of the race car. Rob Smedley, the former head of vehicle performance at Williams Racing stated that - ""Where teams have problems is when their development or simulation environment – so CFD [Computational Fluid Dynamics] or wind tunnel – doesn’t describe well what happens in reality (although in truth, no-one’s wind tunnel correlates absolutely 100%)"". One of the reasons for this poor correlation could be arising from the fact that, in real life on track scenarios, the race cars undergo accelerating, decelerating, or cornering motion which can have a different influence on the aerodynamics of a race car which is not accounted for in the wind tunnel and simulation environment where a steady constant flow is employed. This research aims to numerically investigate the flow past the front wing of a Formula One car in ground effect subjected to accelerating and decelerating flows to understand the trends in the aerodynamic performance.<br/><br/>A scaling analysis is performed to determine the relevant non-dimensional numbers that influence the flow for translationally accelerating airfoils and two dimensionless numbers are arrived at, namely, the Reynolds number and the Froude number. Numerical investigations are carried out for translationally accelerating wings in ground effect to determine the influence of these dimensionless numbers on the aerodynamic forces.<br/><br/>Transient simulations were performed on a two-dimensional airfoil and a three-dimensional wing in ground effect subjected to translational acceleration and deceleration. The Shear Stress Transport (SST) based on k-ω was employed to model the turbulent flow. The results from the numerical investigations revealed a temporary change in the downforce and the drag force coefficients, as the airfoil (or wing) in ground effect is subjected to translational acceleration (or deceleration). In this study, the mechanisms that contribute to this temporary change in the aerodynamic force coefficients are discussed.<br","Ground effect; Downforce; Vortical Structures; Computational fluid dynamics; Turbulence modelling; Added Mass","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Energy, Flow and Process Technology","",""
"uuid:af6eaed9-906a-4aea-9280-431f0bcb9ceb","http://resolver.tudelft.nl/uuid:af6eaed9-906a-4aea-9280-431f0bcb9ceb","Effect of Flap Position on Propeller-Wing-Flap aerodynamic interaction for Distributed Propulsion Systems: An experimental approach","Lopez Pernas, Pedro (TU Delft Aerospace Engineering)","de Vries, R. (mentor); Veldhuis, L.L.M. (mentor); Sinnige, T. (mentor); Timmer, W.A. (mentor); Delft University of Technology (degree granting institution)","2022","Aviation is responsible for a large part of the emissions due to transportation, which is why, in recent years, a trend towards implementing sustainability in aviation has emerged. In small aircraft, the concept of Leading-Edge Distributed Propulsion (LEDP) can provide aerodynamic advantages to reduce fuel consumption thanks to the ability to increase lift due to the interaction between the slipstream of the propellers and the wing. <br/><br/>Therefore, a wind tunnel experiment is performed to study the aerodynamic interaction in propeller-wing-flap systems when Leading-Edge Distributed Propulsion is used. The objective of this research is to gain insight into the difference in wing loading distribution between the distributed-propeller and single-propeller configurations in the flap retracted case, about the effect of flap position on the lift enhancement in LEDP and about the effect of flap deflection on the wake downstream of the system...","Distributed propulsion; propeller-wing interaction; High lift","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:2be5a336-bf6e-4165-b3f9-6878febdbd6b","http://resolver.tudelft.nl/uuid:2be5a336-bf6e-4165-b3f9-6878febdbd6b","Multi-criteria route optimisation for electric vehicles on long-haul trips using stochastic dynamic programming","den Daas, Jelle (TU Delft Mechanical, Maritime and Materials Engineering)","Dabiri, A. (mentor); Delft University of Technology (degree granting institution)","2022","Stochastic Dynamic Programming (SDP) has shown promising results for sequential decision problems of the route optimisation for an Electric Vehicle (EV) with the presence of stochastic variables in the travel cost. However, in studies, the optimisation problem formulation for EVs has been lacking in detail. For example, possible waiting times at a Charging Station (CS) have been neglected. This thesis uses SDP to formulate a more holistic optimisation problem for EVs moving through a road network where travel speeds and charging station availability are stochastic. The goal is to optimise the travel costs, which consists of, e.g., the journey time and the charging cost, for an EV on long-haul trips.<br/><br/>In this thesis, four simulation-based case studies are conducted: (1) comparison of conventional navigation system with the proposed method; (2) speed optimisation in order to improve the travel costs; (3) charging platform selection in order to improve the travel cost; (4) uncertainty influence on the travel costs. The case studies are conducted to create insight into how the travel costs of an EV can be optimised. In these case studies, the influence of multiple factors has been taken into account and investigated. For example, cabin climate control, which is dependent on the ambient temperature, has a significant influence on the energy consumption of the EV resulting in higher travel costs.<br/><br/>The simulation results have shown interesting results. Compared to a Min algorithm, which uses a strategy to minimise the travel and charging time, the proposed method can find an optimal policy that is in some cases 5% shorter in terms of journey time. It is profitable for certain ambient temperatures and maximum allowable driving speeds in terms of journey time and charging cost to optimise the driving speed below the maximum allowed driving speed on highways. This results in a shorter journey time and saving charging costs. For example, for a maximum speed of 120 (km/h) and an ambient temperature of 20 ◦C, 3% of journey time advantage can be achieved by optimising the driving speed.<br","Stochastic Dynamic Programming; Electric Vehicle; Route Navigation; Charging Station Selection","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:6d1f5084-4bfa-4499-b7e1-50314710046f","http://resolver.tudelft.nl/uuid:6d1f5084-4bfa-4499-b7e1-50314710046f","Qompliance: Declarative Data-Centric Policy Compliance on SQL-based Data Movements","Oudejans, Daan (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Software Technology; TU Delft Distributed Systems)","Rellermeyer, Jan S. (mentor); Pouwelse, J.A. (graduation committee); Katsifodimos, A (graduation committee); Zorin, Anton (graduation committee); Delft University of Technology (degree granting institution)","2022","Data compliance is essential for ensuring that organizations do not run afoul of data protection and privacy legislation. Geographically distributed data is an especially relevant topic because of recent developments in cross-border data protection agreements between the United States and the European Union. We introduce Qompliance, a novel system for automated data-centric compliance evaluation in cloud environments. This approach fills a gap in the research for higher-level data-centric compliance systems with a particular focus on geographically distributed data. Its declarative and extensible policy model allows for defining policies that can govern data movements across borders and is intended to be understandable without explicit knowledge of the governed data by employing a tag-based abstraction layer. The particular challenge is to automate data-centric policy compliance on data movements in a maintainable manner. Qompliance analyzes SQL-defined data movements to extract what data is being addressed and combines this information with additional attributes to match policies in a static manner. Policies can decide whether data movements are allowed and specify requirements on the query and the execution that should be enforced. We provide a qualitative comparison between our approach and related work, and we performed a performance analysis that shows that compliance evaluation can be done in seconds for large sets of policies.","compliance; policy; sql; privacy; geographically distributed data; data movements; access control","en","master thesis","","","","","","","","","","","","Computer Engineering | Distributed Systems","",""
"uuid:908d0f63-df9b-49e2-8b0e-8bc4d21ea78c","http://resolver.tudelft.nl/uuid:908d0f63-df9b-49e2-8b0e-8bc4d21ea78c","Early-Warning-Driven Approach for Network Protection Against Earthquakes","Zaharieva, Nikoleta (TU Delft Electrical Engineering, Mathematics and Computer Science)","Oostenbrink, J. (mentor); Kuipers, F.A. (graduation committee); Liang, K. (graduation committee); Delft University of Technology (degree granting institution)","2022","Natural disasters can significantly disturb communication networks. There are examples of events causing massive connectivity failures in the past, such as the Great East Japan Earthquake. Network protection mechanisms have been developed to cope with the destructive power of natural disasters and mitigate their impact on connections availability, but in terms of accuracy, they are far from perfect.<br/><br/>Some natural disasters are predictable and can be detected hours or even days in advance. In that case, an adequate protection strategy can be applied. Nevertheless, other types of disasters, such as earthquakes, are classified as unpredictable; thus, protecting the network becomes challenging. Fortunately, early warning systems can detect ground motion and provide a few seconds of warning before the shaking is actually felt. In our work, we utilize early warnings and other disaster data to develop a network protection approach against earthquakes, which operates under rigorous time constraints. Our goal is to minimize the number of disrupted connections in the network by rerouting as many connections as possible out of the disaster zone, such that their availability is maximized. At the same time, the sum of the bandwidth of the connections in the network is also maximized. <br/><br/>We create a realistic disaster model using an early warning system and disaster information. We tackle the uncertainties related to unpredictable disasters by introducing the concept of multiple disaster scenarios. We define the problem of finding paths with maximized availability considering the multiple scenarios. The problem is extended further by adding bandwidth constraints. We propose heuristics to solve the formulated problems and provide an SDN implementation. We validate the effectiveness of our solutions by conducting a series of experiments and creating a custom metric to evaluate our results. The results show that our approach improves the availability of the endangered connections; using the proposed multi-scenario strategy is more beneficial than a single scenario. The results also show that our bandwidth algorithm can optimize the bandwidth utilization of the network. Finally, we compare our solution to an exact solution and find out that our results are very close to optimal. This work provides a mechanism for network operators to ensure the protection of critical network communication in the event of a natural disaster and prevent the potential loss of human lives.","Communication Networks; Early warning systems; Natural Disasters; Network Protection; SDN","en","master thesis","","","","","","","","","","","","Computer Engineering","",""
"uuid:36940790-48a4-4d28-bed5-e2522db55229","http://resolver.tudelft.nl/uuid:36940790-48a4-4d28-bed5-e2522db55229","Design of ankle-knee prostheses using predictive simulations","Smit, Nerissa (TU Delft Mechanical, Maritime and Materials Engineering)","Seth, A. (mentor); Geijtenbeek, T. (graduation committee); Smit, G. (graduation committee); Happee, R. (graduation committee); Delft University of Technology (degree granting institution)","2022","There is an increasing need for transfemoral prostheses that provide gait support, stability, safety and comfort. Although there are many prostheses available in different levels of complexity and price, there is still room for improvement. It has been proved that the cost of transport (CoT) for walking is significantly increased for transfemoral amputees with respect to their healthy peers. Assisting push-off is one of the main challenges in prosthesis design. Push-off is normally achieved by plantarflexion of the ankle joint. Prosthesis designs should aim to restore this function in order to lower the amount of energy needed for walking. <br/><br/>This study aims to investigate the effect of prosthesis design on the gait pattern through musculoskeletal modelling and predictive simulations. Two prosthesis designs are modelled for these purposes, after which several variations on these models are made. It is hypothesised that the prosthesis that assists in push-off through ankle plantarflexion, should result in a gait pattern that is closer to a healthy one. It should also decrease the CoT. Furthermore, we aim to evaluate the use of modelling and simulations in the customisation of prostheses.<br/><br/>OpenSim was used to create a total of eight models based on a model with 9 degrees of freedom and 18 muscles: a healthy person, a conventional prosthesis model, two scaled versions of the conventional prosthesis model, the walkMECH prosthesis and three variations on the walkMECH. SCONE was used to find an optimal gait pattern for each of the models through the CMA-ES method. CoT-, gait-, degrees of freedom- and reaction force objectives were minimised. The results were evaluated by comparing the CoT, joint angles, ground reaction forces and muscle activation of each model.<br/><br/>The CoT for the healthy model was found to be higher than reported before, based on both experimental and simulation studies. As a result, we have little confidence in the CoT estimation of our models. This is further exacerbated by the finding of a lower CoT for the conventional prosthesis than for the healthy model, in contrast to earlier reports. The results for most other measures were irregular, making it difficult to draw conclusions from them. It is expected that the predictive optimisations did not reach a global minimum, and that the results are therefore not accurate. Future research should aim to solve this problem. It should also be attempted to find the cause of the difference in CoT between our simulations and those of others.<br/><br/>No conclusions could be drawn from the results. Nonetheless, there is a clear potential for the use of musculoskeletal modelling and predictive simulation in the investigation of the effects of prosthesis design on gait.","Transfemoral amputee; OpenSim; SCONE; Musculoskeletal model; Cost of transport; Gait; Gait analysis","en","master thesis","","","","","","","","","","","","Biomedical Engineering","",""
"uuid:e7e4650b-8085-4254-b946-823674077d62","http://resolver.tudelft.nl/uuid:e7e4650b-8085-4254-b946-823674077d62","A Sustainable Energy Transition Case Study on Aruba","Croes, Gary (TU Delft Technology, Policy and Management)","Quist, J.E. (mentor); Ortt, J.R. (graduation committee); Delft University of Technology (degree granting institution)","2022","This research identifies opportunities to accelerate the SET towards a 100% RE based on Aruba. This thesis is structured in three parts: 1) a literature review to assess the main relevant theories. 2) A conceptual framework combining the Strategic Niche Management and the Multi-level Perspective is developed to analyse and compare case studies of RE technologies (Solar PV Rooftops, Electric Vehicle and Wind Turbines), including the external factors enabling or constraining this SET. 3) Finally, a roadmap is provided to accelerate the SET on the island of Aruba. Data collection is through literature review, desk research and semi-structured interviews with stakeholders in the actors’ group (government, market and society).<br/><br/>The main research question: What is constraining the SET on the island of Aruba, and how can this be accelerated?<br/>To accelerate the SET: at the regime level, the government should introduce an independent entity and an energy policy where the network-related is aligned to support the targets and expectations. At the niche level, utility managers should implement energy storage and intelligent infrastructure to reduce the dependency on fossil fuels and enable demand-side management to create more room for RE penetration. At the landscape level, raising awareness, organise town hall meetings with pilot projects and demonstrations is necessary for society. Due to the limited space and land on the island, environmental impact assessments are required to mitigate the impact during the development process and avoid social resistance. <br/>The education system should be upgraded to create new experiences, knowledge and information for local society. Hence, introducing a technical university is required but generally to change the teaching practice locally. The government’s responsibility is to stimulate more research, create more RE demonstrations, and create funds.<br/>The research conducted by the universities, local and international, could ultimately improve regulatory measures. Utility and RE companies’ managers should consider that new business models will be necessary to survive in the new RE business environment. Other RET should also be explored, primarily because the current RET outcomes are unknown. The SET can be accelerated towards a 100% RE-based island by adopting these measures.<br","SIDS; Sustainable energy transition; Energy transition; Aruba; Renewable energy; Strategic Niche Management; Multi-level perspective","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:e0f8fc5a-6395-4422-aa24-dfd06449ea9d","http://resolver.tudelft.nl/uuid:e0f8fc5a-6395-4422-aa24-dfd06449ea9d","Fission products chemistry and scenario analysis of accident progression at Fukushima-Daiichi nuclear power station: Investigation of the Ba-Sr-Cs-Mo-O system","Grimmon, Fenna (TU Delft Applied Sciences)","Smith, A.L. (mentor); Denkova, A.G. (graduation committee); Konings, R.J.M. (graduation committee); Delft University of Technology (degree granting institution)","2022","The severe accident at the Fukushima-Daiichi Nuclear Power Station in 2011 has shown the necessity to study the impact of the release of hazardous fission products. This work investigates the Ba-Cs-Sr-Mo-O system, which contains some of the most abundantly produced fission products, as well as fission products that carry a great health risk on release. The study of this system is broken up into four subsystems: Ba-Sr-O, Ba-Mo-O, Sr-Mo-O and Ba-Cs-Mo-O. A literature study into the ternary Ba-Sr-O system, including existing thermodynamic models, showed the formation of no stoichiometric ternary compounds due to the mutual miscibility of Ba and Sr. Despite this mutual solubility, a miscibility gap is shown to be present in the solid region of the binary BaO-SrO phase diagram below a certain temperature. Thermogravimetric differential scanning calorimetry (TGDSC) investigations of the BaMoO<sub>4</sub> – MoO<sub>3</sub>, SrMoO<sub>4</sub> – MoO<sub>3</sub> and BaMoO<sub>4</sub> – Cs<sub>2</sub>MoO<sub>4</sub> pseudo-binary systems revealed likely compositions for the eutectic equilibria at 0.792 ≤ x(MoO<sub>3</sub>) ≤ 0.80, 0.806 ≤ x(MoO<sub>3</sub>) ≤ 0.82 and 0.909 ≤ x(Cs<sub>2</sub>MoO<sub>4</sub>) ≤ 0.976, respectively. These measurements also allowed for the development and optimisation of a new thermodynamic model of the BaMoO<sub>4</sub> – Cs<sub>2</sub>MoO<sub>4</sub> system using the CALPHAD (Calculation of Phase Diagram) method. Syntheses of BaMoO<sub>4</sub>, BaMo<sub>3</sub>O<sub>10</sub>, Ba<sub>2</sub>MoO<sub>5</sub> and BaCs<sub>2</sub>(MoO<sub>4</sub>)<sub>2</sub> were successfully completed. A partially successful synthesis method was developed for Ba<sub>3</sub>MoO<sub>6 </sub>that needs further optimisation. The novel synthesis of Ba<sub>2</sub>MoO<sub>5</sub> allowed for solution calorimetry measurements to be performed, leading to the determination of its standard enthalpy of formation Δ<sub>f</sub>H°<sub>m</sub>(298.15K, Ba<sub>2</sub>MoO<sub>5</sub>) = -(2169.0 ± 14.7) kJ/mol. Vapour pressure studies of BaMoO<sub>4</sub> by means of Knudsen EffusionMass Spectrometry (KEMS) gave insight into the composition of the vapour formed above BaMoO<sub>4</sub> after vaporisation. The results showed extensive influence of fragmentation reactions and only a small amount of congruent evaporation, indicated by the high partial pressure of BaO(g) and other binary molecules. A partial reduction of the BaMoO<sub>4</sub> sample to BaMoO<sub>3</sub> could have occurred, but this cannot be confirmed due to the full evaporation of the KEMS sample. Further studies are required to investigate a potential reduction.","Fission product chemistry; Nuclear chemistry; RID; Fukushima accident","en","master thesis","","","","","","","","","","","","Chemical Engineering","",""
"uuid:059faecd-1713-459b-b089-c5ee3aae8ee0","http://resolver.tudelft.nl/uuid:059faecd-1713-459b-b089-c5ee3aae8ee0","Angle-insensitive Human Motion and Posture Recognition Based on 2D FMCW MIMO Radar and Deep Learning Classifiers","Zhao, Yubin (TU Delft Electrical Engineering, Mathematics and Computer Science)","Yarovoy, Alexander (mentor); Fioranelli, F. (graduation committee); Delft University of Technology (degree granting institution)","2022","Nowadays, the aging problem is shaking the root of the healthcare system in many countries, an automatic human activity recognition (HAR) is seen as a promising solution to that problem. In particular, radar-based HAR attracts people’s attention thanks to its respect for privacy and functionality in poor lighting conditions. With a lot of research paying attention to this topic, there is still a lack of conclusive and practical methods. In particular, it is realized that dynamic motions at large aspect angles close to 90◦ or static postures have not been investigated in-depth as a part of the radar-based HAR problem. To extensively investigate this type of problem, we propose to use mm-wave FMCWMIMO radar to obtain accurate information of the human subject. <br/><br/>This thesis work aims to fully exploit the six dimensions of information provided by an imaging radar: range, azimuth, elevation, velocity, power and time. Two complementary data representations- point cloud and spectrogram- are utilized to represent these dimensions of information. A signal processing flow is implemented to generate the desired data representations. A hierarchical pipeline consisting of three cascaded deep learning-based classification modules is proposed to process the input data. Particularly, human orientation classification is achieved through the so-called ""T-Net"" network learning the geometric distribution of point clouds. The positive contribution of each module in the proposed pipeline is validated via an ablation study. The superior performances of the proposed pipeline are also established by comparing with those of the state-of-the-art baselines. The robustness of the proposed pipeline concerning a noisy environment is also discussed. It is also presented that the size","imaging radar; human activity recognition; deep learning","en","master thesis","","","","","","","","","","","","Electrical Engineering","",""
"uuid:fe1f9996-4b2a-4e04-a134-db8e4d5cbaf6","http://resolver.tudelft.nl/uuid:fe1f9996-4b2a-4e04-a134-db8e4d5cbaf6","Node Survivability and Dynamics of the Dutch Municipality Network","Manolopoulos, Ioannis (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Boven, E.F.M. (mentor); Jokic, I. (mentor); Smeitink, E. (graduation committee); Wang, H. (graduation committee); Delft University of Technology (degree granting institution)","2022","This thesis’ research concerns the time-dynamics of a complex geographical network of municipalities, i.e. the Dutch Municipality Network over the period 1830-2019. By analysing 190 years of socioeconomic statistical data and applying contemporary tooling from network science and geographic information systems (GIS), the findings from this research can provide a new approach and supportive methods for policymakers, statistical offices, researchers and businesses (to decide when and where to invest).","GIS; complex network; municipalities; survivability; mergers; municipality network; geographic network; population distribution","en","master thesis","","","","","","","","","","","","Computer Science | Data Science and Technology","",""
"uuid:4d636fdc-18ac-40e6-97c0-63d33fed212a","http://resolver.tudelft.nl/uuid:4d636fdc-18ac-40e6-97c0-63d33fed212a","The Impact of Infrastructure Design on Cycling Safety","van Bentem, Leanne (TU Delft Civil Engineering and Geosciences)","van Wee, G.P. (mentor); Farah, H. (mentor); Annema, J.A. (mentor); Delft University of Technology (degree granting institution)","2022","Increasing concerns about the safety of cyclists request for more research in how infrastructure can be improved to increase cycling safety. Literature in the prediction of bicycle crash risk however is very limited. Also the amount of available (exposure) data was often very limited. The aim of this study was to provide a better understanding of how infrastructural factors contribute to the safety of cyclists and how cycling safety can be improved. By combining rich exposure data from the FietsMonitor of Witteveen+Bos with crash data and infrastructural data, safety performance functions were developed for both road sections and intersections. Negative binomial generalised linear regression modelling (GLM) was used to find the relationships between bicycle crash risk and infrastructural risk factors. Most relationships that were found were as expected. Separate bicycle facilities, the presence of speed humps, closed pavements and an increased bicycle lane width were all found to be related to lower bicycle crash risks. Regarding intersections, the amount of traffic flows crossing the intersection did significantly increase bicycle crash risk. Moreover, the results showed a higher bicycle crash risk for roundabouts compared to other intersection types, which was unexpected. Finally, street light was found to be significantly positively related to bicycle crash risk for both road sections and intersections. As the safety performance functions are incomplete, further research should look into other explanatory infrastructural factors. Furthermore, it is recommended to extend the data to other cities to validate the results.","Cycling safety; Bicycle crashes; Road infrastructure; Safety Performance Function; Crash prediction model; Generalised linear modelling (GLM); Negative binomial","en","master thesis","","","","","","","","","","","","Transport, Infrastructure and Logistics","",""
"uuid:08fbb7f6-64c0-4262-a67a-df20d0a52cde","http://resolver.tudelft.nl/uuid:08fbb7f6-64c0-4262-a67a-df20d0a52cde","Aerodynamic Shape Optimization of a Liquid-Hydrogen-Powered Blended-Wing-Body","Wilod Versprille, Vincent (TU Delft Aerospace Engineering)","Vos, Roelof (mentor); Delft University of Technology (degree granting institution)","2022","While commercial aviation continues to grow, achieving climate goals set for this industry becomes more important. Since no major breakthroughs have been accomplished in the field of conventional kerosene-powered aircraft lately, new concepts and fuels are required. The use of liquid hydrogen as an aircraft propellant is currently considered to be one of the possibilities to accomplish a large reduction in the climate impact of aviation. However, the large volumes required for liquid hydrogen storage impose a challenge in aircraft implementation. The blended-wing-body concept is identified as a potentially suitable platform for integrating these large tanks due to its relatively large internal volume compared to its wetted area. The objective of this research is to attain the optimum aerodynamic shape of a liquid-hydrogen-powered, 150-passenger, medium-range, blended-wing-body. This is done by performing a constrained shape optimization for maximum aerodynamic efficiency. The concept specifications and sizes follow from a kerosene-powered reference aircraft. The aircraft geometry is defined for an inside-out driven design where the cabin and tank are integrated in tandem into the centerbody. The ParaPy platform is used to couple the parameterized geometry to a meshing suite and the aerodynamic analysis methods. The geometry is transformed into an unstructured mesh by using the Salome platform. The aerodynamic analysis of the wave and induced drag consists of using the Euler equations and is computed within the Stanford University Unstructured code. Empirical strip methods provide the viscous drag estimate. Two optimization approaches are employed in this study, both making use of an evolutionary algorithm. Optimizations take place based upon a baseline design and include both geometric and aerodynamic constraints. The dual step approach consists of a 13-variable planform optimization followed by a 49-variable optimization of six two-dimensional profiles that are located along the span. The single step approach includes 50 variables of both the planform and wing profiles. The optimization computations take place at a single cruise condition where the Mach number is 0.78, the lift coefficient is equal to 0.2 and the atmospheric conditions follow from a cruise altitude of 11,000 meters. The dual step and single step optimizations yielded an 8.7% and 7.5% performance increase compared to a baseline. The resulting lift-to-drag ratios of the optimized designs are 20.5 (dual step) and 20.3 (single step). Both optimizations resulted in different shapes. The single step optimization features an aft-positioned outer wing, which has a leading-edge sweep angle of 47-degrees. The dual step optimized design features a more forward-positioned wing with 51-degree leading-edge sweep. Both optimized designs do not display shockwaves and the lift distribution tends to an elliptical shape. The long center chord length of around 37 meters, results in a relatively low centerbody lift coefficient, while a cross-sectional area distribution close to a Sears-Haack body is attained.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:e9e0d15f-c000-46f6-a907-9a52972ab23b","http://resolver.tudelft.nl/uuid:e9e0d15f-c000-46f6-a907-9a52972ab23b","A Baggage as a Service ecosystem for Amsterdam Airport Schiphol: Nudging passengers to use early baggage check-in services to make optimal use of the baggage handling capacity at Schiphol","van Wingerden, Aliex (TU Delft Industrial Design Engineering; TU Delft Design, Organisation and Strategy)","Santema, S.C. (mentor); Bluemink, R.G.H. (graduation committee); Delft University of Technology (degree granting institution)","2022","By 2029, a baggage handling capacity shortage at Amsterdam Airport Schiphol is expected due to the foreseen growth in the aviation industry. Research has shown that the current method of baggage handling already puts pressure on the baggage handling system and its stakeholders, resulting in critical peaks during the day, especially in the holiday season. Schiphol wants to optimize the current baggage handling process with innovative solutions since expanding baggage capacity with implementing new assets is not sustainable due to governmental restrictions. <br/>Research stated that 20% of the check-in baggage must be inserted into the baggage handling system before peak hours to realize the desired spread of baggage handling throughout the day (peak shaving). Schiphol can realize this if the check-in baggage arrives at the airport earlier than in the current situation. Therefore, passengers need to be nudged to change their travel behavior with hold baggage. Commercial baggage pick-up services exist in the market, and such a type of baggage service (BaaS) was the starting point of this research.<br/>The research question stated: How can we build a BaaS ecosystem in order to nudge passengers to use early entry baggage check-in services to make optimal use of the baggage handling capacity at AAS?<br/>Conclusions from this thesis indicate that Schiphol should collaborate with existing commercial baggage pick-up parties to use their infrastructure as part of the ecosystem. Secondly, airlines are the key factor in offering the baggage pick-up service to their passengers since passengers prefer to book the service as part of the travel booking with the airline. The challenge of the project was to design a unique baggage service concept that will be attractive for airlines to offer to their passengers, that will be valuable for passengers to use, and that will realize peak shaving. The challenge included identifying the role of Schiphol in setting up this ecosystem.<br/>A baggage home pick-up service is designed for passengers traveling with hold baggage, called the EASY TRAVEL service. The service is created to attract holiday travelers by responding to the need for convenient traveling without hold baggage to and at Schiphol. The EASY TRAVEL service consists of three features that provide extra value to passengers and help nudge them to use the service; a trustworthy and transparent baggage service, a reward &amp; benefit system and personalized travel advice.<br/>This thesis recommended that Schiphol should take the lead in building the ecosystem by collaborating with the necessary third parties to provide the baggage service. By introducing the EASY TRAVEL service, Schiphol can influence the timing of processing check-in baggage to shave the expected capacity peak. Airlines will be the interface towards their passengers and will offer the EASY TRAVEL service as an additional service on their booking platform. Schiphol will develop an Application Programmed Interface (API) that will serve as an interface tool to support this ecosystem where the backend of the three service features is arranged. This API can be easily integrated by the existing apps of airlines and can be adapted to their own brand, making it attractive for airlines to implement it. <br/>An implementation roadmap is created for Schiphol, which emphasizes starting with a pilot of the EASY TRAVEL service and ecosystem with a few airlines who are interested in participating and one commercial third party. The evaluation and learnings from the pilot will help create a working and proven service that will attract more airlines and third parties to participate and realize the desired peak shaving on a larger scale by 2029.<br","Nudging; Baggage service; Peak shaving","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:37d8fea8-d0c3-45d7-a247-e6c6b834c798","http://resolver.tudelft.nl/uuid:37d8fea8-d0c3-45d7-a247-e6c6b834c798","How can we use Livework's approach to org change for CC for SF?: A tool for Livework to enable organisations to think in sustainable and thriving systems","Priyanka Singh, Priyanka (TU Delft Industrial Design Engineering)","Hultink, H.J. (mentor); Baldassarre, B.R. (graduation committee); Delft University of Technology (degree granting institution)","2022","As sustainability becomes one of the critical topics of our times, organisations seek guidance on feasible and pragmatic ways to implement the same. To reduce the know-do gap, the thesis collaboration between Livework and the Technical University of Delft explores the problem statement: How can we use Livework’s service architecture approach for organisational change for customer-centricity (CC) for Sustainable futures (SF)? Empirical research and semi-structured qualitative interviews focus on two main areas of focus: 1. Livework’s service architecture approach; and 2. Sustainable futures. The results and findings of the interviews with Livework employees, their clients and five sustainability leaders in organisations led to defining a vision for Livework and a set of goals and objectives. To make the vision a reality a roadmap is designed. Turning the vision into action, the tool workshop: organisation as a garden is designed. The workshop imagines an organisation like a garden, where the soil a.k.a the core of the business has to thrive with a network of nurturers and influencers. Using this tool in a collaborative manner with organisations, Livework learns about their mindset, pain points and scope a plan of action to enable them to think in regenerative and thriving systems.","organisational change; Sustainability; Regenerative Design; System Design; Sustainable development","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:666727e3-30dd-4734-9ee2-b0dbfc7b9afb","http://resolver.tudelft.nl/uuid:666727e3-30dd-4734-9ee2-b0dbfc7b9afb","The design of a reef tile for the restoration of flat oyster reefs in the Dutch North Sea","Raspoort, Anne (TU Delft Industrial Design Engineering; TU Delft Human-Centered Design)","van Erp, J. (graduation committee); Willemen, A.M. (mentor); Delft University of Technology (degree granting institution)","2022","Because of human interventions in our seas, like commercial (over)fishing and the introduction of diseases, the presence and biodiversity of natural reefs is declining severely. Reefs provide a habitat for a variety of marine species and are of great value to marine ecosystems. Therefore, it is of importance to recover affected reefs. <br/><br/>Also in the Dutch North Sea, a majority of the reef has disappeared, including reefs of the European flat oyster (Ostrea edulis). Oysters in particular play a key role in reef ecosystems and are therefore the ideal starting point for the recovery of reefs in the Dutch North Sea. <br/><br/>There is no possibility that these oysters will naturally recover: they are not numerous enough to naturally breed and spread. Therefore, there is a need for active restoration. Several methods for restoration exist already, however, these are not proven to be effective and have several drawbacks. <br/><br/>Recently, marine biologists suggested a new method for the restoration of flat oyster reefs, where oyster larvae settle on a small product, which then gets sown in the ocean and naturally form oyster beds. However, this method is theoretical; no such product is developed yet. The goal of this graduation project is to develop this product: from conceptualization to embodiment to preliminary validation in laboratory settings. By the end of the project, the product is ready for field tests and will ultimately enable the restoration of reefs.<br/><br/>Literature review showed no reference model or design guide, as no such products exist yet. Therefore, ideation started with the exploration of basic shapes and their behaviour underwater. These basic shapes were altered in such a way to fit the purpose, whereafter several iterative steps concluded in five final concepts. A practical approach enabled quick iterations. <br/><br/>Simultaneously, exploration of bio-based materials suitable for an application underwater resulted in a material that meets requirements. Two concepts were chosen and made into operational prototypes to test in laboratory settings. These tests, executed in a sediment flume, indicated the performance of the products in water flow. One of the two concepts was more successful in this simulated environment; this product is elaborated.<br/><br/>The final product promotes larvae settlement on the product and allows people to touch the product without touching settled larvae. The product sinks to the sea bottom and stays in place as much as possible, which entails resisting water flow up to 1.9 m/s. The design protects larvae against larger predators and makes sure they stay above the sediment. Finally, the product is large enough for a grown oyster and persists between six months and two years on the seabed, after which the naturally occurring material degrades into biologically safe components.<br/><br/>In conclusion, a product has been designed that can enable the restoration of oyster reefs. With this product, large areas of reef can be restored in an effective and minimally invasive manner. As the indication of performance is only performed in laboratory settings, the advice is to validate in a relevant natural environment to improve knowledge about this product and method. These tests should clarify the performance of the product and the material.","restoration ecology; ecosystem ecology; Ostrea edulis; reef restoration; reef tile","en","master thesis","","","","","","https://vimeo.com/682357271 Video showcase of the project.","","","","","","Integrated Product Design","",""
"uuid:325997ff-14c6-43c7-a1ba-cff891817872","http://resolver.tudelft.nl/uuid:325997ff-14c6-43c7-a1ba-cff891817872","Forecasting Models for Graph Processes: A Study on the Multi-Dimensional Case","van der Hoeven, Jelmer (TU Delft Electrical Engineering, Mathematics and Computer Science)","Leus, G.J.T. (mentor); Natali, A. (mentor); Delft University of Technology (degree granting institution)","2022","In the current Big Data era, large amounts of data are collected from complex systems, such as sensor networks and social networks. The emerging field of graph signal processing (GSP) leverages a network structure (graph) to process signals on an irregular domain. This thesis studies the forecasting of multi-dimensional graph processes, i.e., where each entity in the network carries a multivariate time series. Recent research has proposed to use product graphs to model the dependencies between different variables in multi-dimensional graph processes and employ them in graph-based vector autoregressive models to predict future values. A problem with these product graph-based models is that they can be too restrictive. In this work, it is proposed to combine product graph-based models with multiple one-dimensional models to implement more estimation flexibility. To further increase the degrees of freedom, the use of multiple-input-multiple-output graph filters is also proposed. The proposed models are implemented and tested on synthetic and real-world data sets, which shows an improved forecasting performance compared to state-of-the-art alternatives.<br/><br","Forecasting; Graph signal processing; Multi-dimensional signal processing; product graphs","en","master thesis","","","","","","","","","","","","Electrical Engineering","",""
"uuid:7d9f3f9d-294d-4742-9db2-a4639a191ba0","http://resolver.tudelft.nl/uuid:7d9f3f9d-294d-4742-9db2-a4639a191ba0","Modelling and Optimal Scheduling of Inland Waterway Transport Systems: A Switching Max-Plus-Linear Systems Approach","Pesselse, Mike (TU Delft Mechanical, Maritime and Materials Engineering)","van den Boom, A.J.J. (mentor); Reppa, V. (mentor); Segovia Castillo, P. (mentor); Delft University of Technology (degree granting institution)","2022","Inland waterways form a natural network infrastructure with the capacity for waterborne transport of people and goods for moving freight from seaports to the hinterland. Recently, Inland Waterway Transport (IWT) has been promoted more extensively by the European Union and various governments as it plays a crucial role in reducing road congestion and CO2 emissions from transport. However, the advantages of IWT are not fully exploited due to inefficiencies in the logistics system, such as long waiting times at locks and sub-optimal navigation on waterways. Currently, no scheduling at infrastructures or routing optimisation of the overall waterway network is happening. The scheduling of vessels through a lock is usually performed on a First In First Out basis, providing an opportunity for improvement. Hence, this thesis aims to design a scheduling strategy for generating an optimal plan for sending inland vessels through a waterway network with minimal delays, yielding a significant positive impact on the modal shift towards IWT. <br/>A promising approach to scheduling problems is by using Switching Max-Plus-Linear (SMPL) systems. SMPL systems have proven to be effective in various Discrete-Event Systems and transportation networks. Using SMPL models is convenient since non-linear scheduling problems can be described linearly using Max-Plus operators without compromising on the system dynamics. Moreover, as the SMPL systems can be transformed into Mixed-Integer-Linear-Programming (MILP) problems, it is also possible to use fast optimisers for solving the scheduling problems.<br/>This thesis will show how one can describe IWT systems, consisting of; waterways, vessels and locks, as SMPL systems. The optimal schedule for the inland vessels is determined based on multiple input parameters, including waterway network lay-out, the sailing speeds of vessels and arrival deadlines of the vessels. The scheduler will return the individual vessel routing and overall vessel order in the waterway network. This routing and order selection is defined using binary control variables, turning the IWT scheduling problem into a MILP problem, which will allow finding the solution to large scale IWT scheduling problems in a reasonable computation time. Furthermore, this thesis will show how the goal of minimising the cumulative arrival times of all vessels in a network can be achieved. This is done for different types of waterway network cases, for which the results are shown and analysed.","max-plus algebra; switching max-plus linear system; Optimal control; Scheduling Algorithms; Inland Waterway Transport; Modelling","en","master thesis","","","","","","","","2023-02-19","","","","Mechanical Engineering | Systems and Control","",""
"uuid:56bd5979-858b-4959-bfca-242d1188cda1","http://resolver.tudelft.nl/uuid:56bd5979-858b-4959-bfca-242d1188cda1","Radio-Based Satellite Tracking Systems for the DelfiSpace Program: Phase Interferometry and Time Difference of Arrival","Nachtergaele, Tim (TU Delft Aerospace Engineering; TU Delft Space Engineering)","Speretta, S. (mentor); Root, B.C. (graduation committee); Guo, J. (graduation committee); Delft University of Technology (degree granting institution)","2022","Satellite tracking is used to predict a satellite’s orbit to communicate and perform other key functions. It is commonly performed using large ground-based radars with an accuracy of 1 to 10 km or specialized onboard satellite systems. Ground optical systems are a proliferating technology for satellite tracking, identification, and communications. Such optical systems have a narrow field of view, and to ensure smooth and quick satellite acquisition, the satellite must be tracked with higher accuracy (in the order of 100 m). Hence, to allow for optical ground systems to function smoothly they require satellite tracking systems providing sufficient accuracy which is not common for small satellites.<br/>This work analyses two radio-based methods to provide sufficiently accurate satellite tracking for the next TU Delft satellite to be acquired optically. These methods utilize the innate satellite radio communications subsystem of the satellite without modifications. To optimize the analysis work, the model complexity was gradually built up. The first method analysed is phase interferometry, which based on a first-order model, turned out to be non-viable. The second method investigated is time difference of arrival. Increasingly more sophisticated models were developed to understand its performance and limitations. For example, for Delfi-PQ, by utilizing 25 ground stations in a square configuration with 1000 km baseline and a noise level of 236 ns (71 m), the target satellite in a 500 km circular orbit can be acquired, with at least the required accuracy, for 18% of the area where the satellite can be received by a minimum of 4 ground stations. It is expected that this performance can be improved through future work. Specifically, by utilizing multiple measurements taken at different times, the satellite orbital parameters can be estimated directly.<br/>We conclude time difference of arrival to be a promising method for further research, development, and eventual implementation by TU Delft. The approach and structure of an even more sophisticated model is detailed for future work.<br","Time Difference of Arrival; Satellite tracking; Phase interferometry; TDOA; DTOA","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:df604467-5bf2-4e88-bee1-a09d55d66748","http://resolver.tudelft.nl/uuid:df604467-5bf2-4e88-bee1-a09d55d66748","Learning to estimate the proximity of slip using high-resolution tactile sensing","Boonstra, Dirk-Jan (TU Delft Mechanical, Maritime and Materials Engineering)","Kober, J. (mentor); Wiertlewski, M. (mentor); Luijkx, J.D. (mentor); Kulkarni, P.V. (mentor); Delft University of Technology (degree granting institution)","2022","Tactile sensing provides crucial information about the stability of a grasped object by a robotic gripper. Tactile feedback can be used to predict slip, allowing for timely response to perturbations and to avoid dropping objects. Tactile sensors, included in robotic grippers, measure vibrations, strain or shearing forces which are produced by the movement of the grasped object. With sufficient spatial resolution, tactile sensors can even classify slip or estimate the 3d force displacement field. However, current tactile sensors fail to preemptively detect slippage, requiring fast reaction times during applications in real-time control. Here we show a perception framework that can predict slippage before it occurs by estimating the frictional safety margin. The safety margin indicates the margin to the frictional strength of a grasp, which decreases for reduced friction or increased load force. An accurate safety margin estimate allows for more efficient robot grip force control while providing robustness against object uncertainty and frictional conditions. We developed a high resolution tactile sensor, on which we trained a convolutional neural network to learn the relationship between tactile images and the safety margin. The network’s performance is evaluated on unseen test data, showing robustness to variations in environmental conditions. The results demonstrate that the tactile images contain the information needed to produce accurate safety margin estimates. These estimates can be used for control up to 20% of the minimum required grip force, mimicking human grasping behavior. This approach can drive new grasp control methods and enable robotic grasping of fragile objects in highly dynamic environments. Applications can be found in harvesting, parcel sorting, or improving human-robot interaction.","robotic grasping; grip force control; safety margin estimation; friction","en","master thesis","","","","","","","","","","","","Mechanical Engineering","",""
"uuid:63823e24-85e8-47d3-a585-7f5c6ebb74fb","http://resolver.tudelft.nl/uuid:63823e24-85e8-47d3-a585-7f5c6ebb74fb","The Challenges and Opportunities of a Hydrogen Internal Combustion Engine","Peeters, Erik (TU Delft Aerospace Engineering)","Melkert, J.A. (mentor); Delft University of Technology (degree granting institution)","2022","Converting existing aviation internal combustion engines to run on hydrogen could be a way to make aviation more sustainable. This work is in preparation to actual engine tests, and the goal is therefore to investigate the potential challenges of such a conversion and to assess where the opportunities lie in terms of performance optimization. This is done using a CFD model of an internal combustion engine in ANSYS Forte. Using this model, a form of optimized hydrogen injection is found that increases the power output, while decreasing the NOx emissions. Safe engine operation during testing can be ensured by monitoring the pressure inside the combustion chamber and starting off with low equivalence ratios and retarded spark timings. Further recommendations are made, such as installing injectors in the combustion chamber to facilitate direct injection and replacing the spark plugs for cold-rated ones.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:f3b0792e-fb9f-4e69-b59f-7a477215c642","http://resolver.tudelft.nl/uuid:f3b0792e-fb9f-4e69-b59f-7a477215c642","Ion-Conduction in Solid-State Electrolytes: Investigating the fundamental conduction mechanism in Na3PnS4 (Pn = P, As, Sb) through computation and experiment","Alders, Tim (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Applied Sciences)","Wagemaker, M. (mentor); Smith, A.L. (graduation committee); Braga Groszewicz, P. (graduation committee); Famprikis, T. (graduation committee); Delft University of Technology (degree granting institution)","2022","Recent studies on various solid-state electrolytes showed that while improvements to the ionic conductivity are progressing swiftly, the understanding of the fundamental conduction mechanism is still lagging behind. We attempt to improve this understanding by providing a more complete overview of how different static (structural) and dynamic (lattice-ion interaction) properties relate to the ion diffusion mechanism, by investigating the differences between the Na3PnS4 isostructural compounds (Pn = P, As, Sb). The static bottleneck descriptors previously used in literature, based on the S-atoms coordinating the ion migration pathway, are found to not predict the ionic conductivities accurately. On the dynamic influences, we find that based on the melting points, Born Effective Charges, vibrational frequencies and dissociation energies, it seems that of the Pn-S bonds the P-S bonds are significantly stiffer than the As-S and Sb-S bonds and that based on the differences in electronegativities, Bader Charges and Electron Localization Functions the bonds are least polar for As-S, followed by P-S and Sb-S. The changes in the bond polarity were found to correlate more closely with the observed differences in ionic conductivity than the bond stiffness, and closer inspection of the differences in the bond polarity suggest that the Pn substitution in the PnS4 anions (following the order As  P  Sb) causes a decrease in the Na-S bonding strength through electron transfer from the Na-ions to the S-ions. We quantified the conduction process further by determining the activation barrier with the Nudged Elastic Band method, with which we find that both the ionic conductivities and thus polarity correlate well with the activation barriers. Finally, we find that while the statis bottleneck descriptors are not great predictors of the overall conductivity, they do correlate with the activation volume, indicating an important role for these structural descriptors in studying pressure effects on conductivity.","Batteries; DFT; Ion Conduction; solid-state batteries; solid-state electrolyte; Na3PS4","en","master thesis","","","","","","","","","","","","","",""
"uuid:dc1c6dc1-52a5-4f2e-85cd-b0d2c574172c","http://resolver.tudelft.nl/uuid:dc1c6dc1-52a5-4f2e-85cd-b0d2c574172c","Mitigation Controller: A Multi-Criteria Optimization &amp; Simulations Approach to Keep Construction Projects Within Budget","Khalifé, Ali (TU Delft Civil Engineering & Geosciences)","Wolfert, A.R.M. (graduation committee); Binnekamp, R. (graduation committee); Kammouh, O. (graduation committee); Delft University of Technology (degree granting institution)","2022","The construction and infrastructure industry has witnessed an increase in the need for an optimized mitigation strategy to combat schedule and cost overruns amid the rise in market competitiveness and more strict timelines and budgets. Moreover, projects nowadays are more complex in terms their scope and requirements which ultimately drives more innovative and efficient solutions to enhance project risk mitigation. Typically, Monte Carlo (MC) simulations with different combinations of mitigation measures are performed until a random set of measures is chosen to satisfy the targeted budget. Several attempts aimed at optimizing around different objective functions to obtain more efficient strategies that would demonstrate the dynamics faced on the construction sites(Safaeian et al., 2022). The main flaw of all attempts were the absence of the goal-oriented control behavior of the project manager who would only opt to the optimal mitigation strategy given a risk event and cost overrun. The closest attempt was demonstrated in the objective functions of MitC developed to keep projects within schedule given a set of optimized mitigation strategies (Kammouh et al., 2021). However, the aforementioned tool solely addresses the selection of mitigation measures in the case of project delays affecting a strict delivery date with a trade-off restricted to one criterion: cost. The development in this document demonstrates a tool with broader functionalities that aims at selecting an optimized strategy to keep the project within budget yet with further additional features that extend its usefulness to a multi-criteria approach that involves time delays, environmental impacts as well as noise disturbance. The usefulness of the Mitigation controller for cost is demonstrated using a real case of a construction project in the Netherlands with the analysis performed on the go yielding significant negative impact savings relative to current approaches used to maintain the project’s budget.","risk event; mitigation measure; stochastic budgeting; cost-optimization; probabilistic budgeting","en","master thesis","","","","","","","","2023-03-01","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:6c9417bc-b08b-4ecf-9678-93ee330177e4","http://resolver.tudelft.nl/uuid:6c9417bc-b08b-4ecf-9678-93ee330177e4","United Nations Humanitarian Air Service: Network Optimization: A Tabu Search Approach","YANG, BEIHONG (TU Delft Aerospace Engineering)","Santos, Bruno F. (mentor); Roling, P.C. (graduation committee); Delft University of Technology (degree granting institution)","2022","Network scheduling and fleet assignment are essential tasks for airline operation. In order to generate an optimal flight plan, the flight route and the flight schedule of each aircraft in the fleet requires deliberated consideration and planning. Compared with commercial airlines, which are in pursuit of maximal benefit during the operations, the humanitarian air services have different goals and therefore different strategies are designed. The humanitarian air service dedicates to fulfilling maximal passenger requests by reacting in a relatively short time frame, and the overall cost efficiency needs to be maximised. In this research, the United Nations Humanitarian Service’s (UNHAS) South Sudan mission is taken as the case to study and a metaheuristic method on top of the multi-integer linear programming (MILP) model is designed to solve the optimisation problem. The optimisation process consists of two stages: the tabu search process to assign the flight routes among the fleet, and a variation of a Fleet Size and Mix Vehicle Routing Problem (FSMVRP) model to finally determine the time schedule of each aircraft. The model is able to unlimitedly split the passenger requests and recaptures passenger spillage. It considers much fewer assumptions during the solving process and it provides large flexibility for the planner to manually modify the model based on their purpose. A dynamic balance of aircraft utilisation time regarding the Minimum Guaranteed Hours (MGH) within the fleet is also discussed. The result of this method is compared with the previous study of S.P. Niemansburg, which shows 1% to 11% of cost saved on a single day's operation regarding different levels of passenger spillage.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:ab59f7b6-ba98-4717-991b-18b2c9143f78","http://resolver.tudelft.nl/uuid:ab59f7b6-ba98-4717-991b-18b2c9143f78","Automatic Extraction of Ridge Lines from Digital Elevation Models","van Noppen, Thirza (TU Delft Civil Engineering and Geosciences)","van der Ent, R.J. (mentor); Aguilar Lopez, J.P. (mentor); Rutten, M.M. (mentor); de Graaff, B.J.A. (mentor); Donchyts, G. (mentor); van Dam, A. (mentor); Delft University of Technology (degree granting institution)","2022","Second-order Gaussian kernels have been utilized to develop three algorithms that could automatically extract ridge lines for hydrodynamic modelling. Isotropic second-order Gaussian kernels produce inaccurate lines at crossings and junctions. To avoid the malfunctioning of Second-order Gaussian kernels, one default and two alternative algorithms were developed. The first, default algorithm is based on isotropic kernels and non-maximum suppression. For the first alternative algorithm, isotropic and anisotropic kernels have been applied for the filter process. The third algorithm uses skeletonization instead of non-maximum suppression. A verification was applied to analyzed the performance of the algorithms. The Matthews correlation coefficient (MCC) of the default algorithm and the alternative algorithm that included anisotropic kernels was found to be 0.17. For the algorithm based on skeletonization a value of 0.08 was obtained. Hence it has been concluded that the algorithms that utilized non maximum suppression instead could more accurately detect ridge lines than the model based on skeletonization. However, the latter generated lines that contained less discontinuities. Furthermore this algorithm turned out to be computationally less demanding in comparison to the other two algorithms.","image processing; Ridge detection; DEM-analysis; Second-order Gaussian kernels; Filtering; Hydrodynamic modelling; 1D-2D model; D-Hydro; De Roer; Kernel convolution; Limburg; Inundation; Sub-grid modelling","en","master thesis","","","","","","","","","","","","Civil Engineering | Hydraulic Engineering","TKI project: 'D-HYDRO Suite 1D2D ontwikkelingen'",""
"uuid:a143bc2e-7490-43ce-972e-c67e4a0d73bd","http://resolver.tudelft.nl/uuid:a143bc2e-7490-43ce-972e-c67e4a0d73bd","Tri-Suction Pile Caisson - Analysis of Soil-Structure Interaction","Christantonis, Evangelos (TU Delft Mechanical, Maritime and Materials Engineering)","Metrikine, A. (mentor); Ummels, B.C. (mentor); Rebollo Parada, Juan Antonio (mentor); Delft University of Technology (degree granting institution)","2022","Offshore wind turbines are getting larger and are being installed in ever deeper waters. This requires increasingly stronger yet affordable foundations. The Tri-Suction Pile Caisson (TSPC) is a Wind Turbine Generator (WTG) foundation concept patented by SPT Offshore that requires a smaller amount of structural steel or concrete than a conventional monopile. It can be towed from port to location, and can, thus, be installed by smaller crane vessels. Additionally, it does not require piledriving or noise mitigation measures. Despite its promising potential, unlike its competitors and proven technologies, i.e., the monopile and the Suction Bucket Jacket (SBJ), little is known about the in-place behaviour of the TSPC in sandy or clayey soil types.<br/>This study aims to further existing knowledge regarding the interaction between the three clustered suction piles and the surrounding soil and, subsequently, contribute towards making the TSPC an economically feasible option. To this end, a parametric analysis was conducted using PLAXIS 3D, a Finite Element Modelling (FEM) software, to assess the effect of suction pile centre-to-centre distance, load combination and soil type on the TSPC behaviour under monotonic static loading. <br/>To validate computational results against realistic values, the calculation of the environmental loads acting on the TSPC and the soil constitutive model parameters calibration were made using metocean and geotechnical data from the Aberdeen Offshore Wind Farm (AOWF). <br/>In total, five centre-to-centre distances were considered ranging from 1.2 to 2.0 times the diameter of the suction buckets. Two governing Ultimate Limit State (ULS) load combinations were identified, corresponding to WTG rated wind speed and 50-year storm conditions. Finally, two soil types were addressed, medium-loose sand, modelled by the Hardening Soil Model (HSM) and soft-stiff clay, represented by the NGI-ADP model. The contribution of the above parameters to the mobilization of failure mechanisms, and the evolution of foundation stiffness, was investigated.<br/>Based on this work, it is concluded that the TSPC behaves very similarly to a mono-caisson for the most clustered geometrical configurations, especially in clay, where the formation of an inner soil plug is evident. For larger centre-to-centre distances in sandy soils, the TSPC approaches the behaviour of the SBJ, with the mobilization of axial caisson pair capacity being the main resistance factor against overturning moment loading. With the current knowledge, it is not straightforward to determine which geometrical configuration is the most optimal in terms of structural steel efficiency and installability in sand and clay. Thus, the challenge of the TSPC design optimization remains.<br/>The results of this work, however, can be used to outline the optimization process by providing starting points for normalised centre-to-centre distances in sand and clay, combined with further research on the quantification and normalisation of connection beam costs and rigidity. The investigation of different embedment ratios, accounting for installability, would also contribute to that direction. Finally, the assessment of TSPC behaviour under cyclic and dynamic load is encouraged since it can shed light on a potential strategic advantage against conventional WTG foundations.<br","Offshore Wind Energy; Suction Caisson; Tripod; Soil-Structure Interaction","en","master thesis","","","","","","","","2024-02-09","","","","Offshore and Dredging Engineering","",""
"uuid:d14bd5eb-82ec-4865-a13b-218b0fda3e25","http://resolver.tudelft.nl/uuid:d14bd5eb-82ec-4865-a13b-218b0fda3e25","The Potential of Computer Vision Technologies for the Baggage Handling Ecosystem of Hub Airports: Insights into a value proposition design process by the identification of use cases for a datadriven technology that can lead to a digital transformation of the baggage handling process","van Brakel, Evelien (TU Delft Technology, Policy and Management)","de Reuver, G.A. (mentor); de Bruijne, M.L.C. (graduation committee); Agahari, W. (graduation committee); Plink, Larissa (mentor); Delft University of Technology (degree granting institution)","2022","The growing aviation industry asks for innovative solutions to be able to handle the increasing amount of baggage. An example of such an innovative solution is Computer Vision Technology (CVT), which uses cameras to identify bags using data and artificial intelligence. The value of CVT for the baggage handling ecosystem is currently unknown. Besides this practical knowledge gap, a scientific gap is found as well. The majority of the literature on digital transformations has an organizational viewpoint and does not incorporate established ecosystem perspectives. It is unknown how a value proposition needs to be designed for a data driven technology to lead to a digital transformation of an established ecosystem.<br/><br/>A DSR approach is executed in a situated setting at Schiphol Airport to capture the value proposition of CVT for the baggage handling ecosystem by the identification of use cases. . The results show that the implementation of CVT provides value for Schiphol Airport, the baggage handling system provider, airlines, handlers, passengers, and society. The value proposition of CVT is the automated identification of bags based on visual images that provides thirteen use cases applicable throughout the whole baggage handling process, which leads to more autonomous processes, process improvement, the generation of more (types of) valuable data compared to the current identification techniques and can contribute to the achievement of sustainable goals if it replaces the current identification techniques.<br/><br/>The results not only contribute to the aviation industry, but the insights gained during the research are also valuable for future digital transformations within other established ecosystems. During the research, a lack of ecosystems’ support for the digital transformation was identified, caused by two factors. It was found that certain process choices had a positive influence on these two factors, which inspired the formulation of process guidelines. These guidelines contribute to the digital transformation knowledge base as they provide insights into how to enhance ecosystems support for digital transformations. In this way, it guides future digital transformation processes within established ecosystems. Furthermore, the research provides an approach to get a grip on a complex established ecosystem and a tool to specify data-driven use cases in combination with its implications for the established ecosystem. No tool existed to accommodate that. Therefore, a tool was constructed and used, which provided guidance on the use cases’ specification and could be valuable within future ideation processes of data-driven use cases for established ecosystems.<br","Digital Transformation; Computer Vision Technology; Value Proposition; Hub Airport; Data-driven technology","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:cd550bce-2c08-464e-b1a9-6316cd3446e5","http://resolver.tudelft.nl/uuid:cd550bce-2c08-464e-b1a9-6316cd3446e5","To design a more sustainable disposable diaper without compromising on user experience","Deuring, Evelien (TU Delft Industrial Design Engineering)","Bakker, C.A. (mentor); Balkenende, A.R. (mentor); Meijer, Guus (graduation committee); Delft University of Technology (degree granting institution)","2022","Context<br/><br/>In a society where sustainability is becoming more and more relevant, disposable single use diapers are still used by 95% of parents. Every baby uses approximately 4000 diapers in their first 2,5 years of life. This is close to 160 kilos of material that is used once and then discarded. As the use of disposable diapers only increases with the increasing number of births yearly worldwide, the amount of material needed to sustain the diaper market is enormous. The Future Diaper Project initiated this research with as the main goal to develop a more sustainable disposable diaper. Can disposable diapers be designed to have lower environmental impact, reduced material use and be made renewable? To prevent the design of unusable futuristic designs an extra focus was placed on user experience. Currently disposable diapers can be named as the essence of convenience, low effort and easy disposal. Can a new diaper both be more sustainable while preserving this user experience? This project proposes a new concept to revolutionize the future of the disposable diaper market.<br/><br/>Approach<br/><br/>The main approach of this project lies in the classic double diamond model, consisting of research &amp; analysis (discover), define, conceptualization (develop) and deliver (embodiment and final product). The research and analysis phase allowed the creation of a clear vision, list of requirements and provided a strong foundation for ideation. Through extensive desk research, talking with parents, observation and analysis of impacts through creating a diaper model (Excel) with the material database of Granta Edupack (previously CES). With a clear path ahead created by the analysis, ideation of concepts was started, generating various ideas that could reduce diaper impact. Emphasis lied on embodiment to validate concepts, as well as analyzing impact with the previously created diaper impact model. Implementing low-fidelity prototypes combined with the numerical approach of the model proved to deliver time efficient insights and results.<br/><br/>Results<br/><br/>The result of this project is a user-tested, new diaper system, that potentially reduces the CO₂ emission with 63% and the water use with 18%. The product combines three approaches of making a diaper more sustainable: reusing parts, reducing material use and changing the material composition to biobased materials. The final concept reuses parts of the diaper that most often do not get dirty in use. It combines this with separating day and night capacity of absorbency. The final step taken in this concept is the material composition, which is changed to be almost completely biobased. By being both reusable as well as disposable the diaper stays close to the convenience level parents of today count on, giving them an alternative that is more sustainable without having to compromise on convenience. The end result is a biobased and reusable and disposable diaper system stripped of all unnecessary material, that reduces environmental impact without compromising the user experience.<br","Diaper; Sustainability; Circular; User experience; Material; future diaper; Product design","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:6e6dd8d5-3eab-4d63-a991-acfef0a34343","http://resolver.tudelft.nl/uuid:6e6dd8d5-3eab-4d63-a991-acfef0a34343","Sustainable strategies for consuming on-the-go","de Grefte, Fay (TU Delft Industrial Design Engineering; TU Delft Human-Centered Design)","van Dijk, M.B. (mentor); Kobus, C.B.A. (graduation committee); Delft University of Technology (degree granting institution)","2022","The way we consume when we travel has had a bigger influence on the environment than meets the eye. We see the cups being thrown away, but we do not see the overconsumption, the dodging of responsibility for sustainable production and the food losses. Our quest for convenience has led us to behave in the most environmentally unfriendly way possible.<br/><br/>To contribute to the sustainable development goals of the UN and strive for<br/>a more balanced world, this project created a possible sustainable strategy for consuming on-the-go in 2036. The desired change is constructed using<br/>the ViP-method and Social Practice Theory. In the first part of the report, the current practice is deconstructed and we try to fully understand its impact on the environment. The next chapter uses context factors to make a prediction about the practice of ‘consuming on-the-go’ in 2036. This context is visualised in a future framework. Based on this overview, in combination with the vision of the project, a desired future is presented in the form of a vision statement. By rearranging the social construct of consuming on-the-go out of convenience to one with a motivation of self-care, the practice arguably becomes a more sustainable, and thus desired, one.<br/><br/>An intervention to get from the current practice to a desired one in 2036 could be a product-service system named ‘Tend’. This concept consists of a new system that supports the self-care journey and a digital platform with a product to help actualise your intentions concerning your well-being. The value for the user is added when Tend suggests a consumption that suits your needs at that moment best.<br/><br/>To show how the concept could find its way into reality, a roadmad visualises proposed steps for the service based on the changing context. These parts of implementation are plotted over time and construct a desired final practice<br/>in 2036. Afterwards, an impact analysis compares the old practice to the new one and discusses in what ways Tend leads to less negative impact concerning production and more positive impact concerning health and consumption. This validates the importance of such a transition and shows the value of this projects’ contribution to a more sustainable consumption on-the-go.<br","Sustainability; ViP approach; Consuming on-the-go; Mobility; Future vision","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:3384594a-3abd-492c-b678-de3d231d16c9","http://resolver.tudelft.nl/uuid:3384594a-3abd-492c-b678-de3d231d16c9","Development of a 2D Lidar SLAM algorithm for localization on the building construction site","van Bavel, Henri (TU Delft Mechanical, Maritime and Materials Engineering)","Wahls, S. (mentor); Kok, M. (graduation committee); Delft University of Technology (degree granting institution)","2022","In order to improve the autonomy of construction robots, a Simultaneous Localization and Mapping (SLAM) solution is needed that localizes the robot using solely on-board sensing with sub-5 mm accuracy. As pointed out by the results of the Hilti SLAM Challenge, the state-of-the-art in SLAM currently does not offer a solution that comes close to this requirement. The winning algorithm FAST-LIO2 achieved an accuracy typically around 4-10 cm. When considering the literature, it can be noted that the state-of-the-art SLAM algorithms are designed with generality in mind, and limited attention has been paid to SLAM that focuses on increasing accuracy by targeting a specific scene structure. <br/><br/>In order to improve SLAM accuracy, this thesis proposes a novel 2D Lidar SLAM algorithm focused on indoor environments, hereafter called Ray-SLAM. The algorithm is centered around the assumption that walls are available, which is valid in many cases on the building construction site. Ray-SLAM introduces several novelties which are (1) a sparse map representation to facilitate a joint pose-map optimization scheme, (2) observation-to-map alignment using a non-iterative procedure (contrary to the Iterative Closest Point algorithm) and (3) a stop-and-go strategy to prevent Lidar motion distortion to corrupt the map.<br/><br/>The algorithm was extensively tested using six real-world indoor datasets recorded with the Ouster OS0 Lidar in rooms with various shapes and sizes and with a total trajectory length of 307 m. The motion was constrained to the horizontal plane and a stop-and-go motion pattern was applied. Ground-truth was recorded at static points to evaluate the accuracy. In the majority of the test cases, Ray-SLAM was able to estimate the trajectory successfully. Failure cases led back to either a lack of unoccluded walls in the scene or violated model assumptions about these walls (e.g. incorrect referencing to clutter close to the wall or to a door being opened).<br/><br/>Ray-SLAM's accuracy was compared with two 3D Lidar SLAM algorithms, LOAM and FAST-LIO2 respectively. The compared algorithms solved a harder 6DOF estimation problem, but had access to 64 Lidar scan rings instead of one and (optionally) the IMU. An overall Mean Absolute Error of 5.7 mm is reported by Ray-SLAM in the successful cases, which is 5.0x more accurate than LOAM and 2.4x more accurate than FAST-LIO2. Further research is suggested to improve the robustness of Ray-SLAM and extend it to a full 3D SLAM algorithm.","SLAM; Localization; LiDAR; Optimization; State Estimation; construction robotics","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:65f73194-d045-430b-8112-5b8cf27d7293","http://resolver.tudelft.nl/uuid:65f73194-d045-430b-8112-5b8cf27d7293","The impact of spatial resolution and satellite data type characteristics on Automated Damage Assessment using a Convolutional Neural Network","Verschoor, Fleur (TU Delft Civil Engineering & Geosciences)","Lhermitte, S.L.M. (mentor); Lopez Dekker, F.J. (graduation committee); Lindenbergh, R.C. (graduation committee); Delft University of Technology (degree granting institution)","2022","Satellite data, such as optical and Synthetic Aperture Radar imagery, can provide information about the location and level of destruction caused by natural hazards. This information is essential to optimise the rescue mission logistics by humanitarian aid organisations and save people in need. Currently, many Automatic Damage Assessment (ADA) methods exist, designed explicitly for one data type with corresponding spatial resolution. However, the weather and satellite coverage conditions can hinder rapid and complete data acquisitions after large events. Therefore, it is important to identify the limits and capabilities of novel methodologies testing various data availability scenarios and adjusting them to become robust and widely deployable.<br/>In this research, the Convolutional Neural Network Caladrius of 510 ­ an organisation of the Red Cross Netherlands is selected to perform experiments. Initially, the model was designed to input high-­resolution imagery and based on the Siamese Architecture, including two Inception­-V3 modules fol­lowed by three connected layers. The multiple experiments are based on single­, dual­, and cross­mode scenarios, representing data characteristics with varying resolutions, satellite sources and observation sensor types. The xBD dataset provides pre- and post-­event high­-resolution optical imagery of numer­ous disasters with corresponding validated damage labels of the included buildings. Subsequently, this dataset is replicated in three down­sampled versions and using Sentinel-­2 1C and Sentinel­-1 GRD data. With the use of the Macro F1-­score and the Cohen’s Kappa coefficient the performances are compared and the predictions’ reliability is determined in operational situations. <br/>The results indicate that a lower resolution of the input data has a negative effect on the correct classi­fied buildings. A linear relation does not express the loss in performance, as most damage propertiesare captured between 0.5­ and 2.5-meter. Consequently, this implies that the Sentinel 10­-meter res­olution datasets provide little recognisable features. The Sentinel­-2 1C experiment outperforms the Sentinel­-1 GRD, which equals the output of a random classifier. However, no final conclusion is drawn between the true prediction rate of the model compared to the input data type; optical and SAR im­agery due to the non-­optimal experiment circumstances and limited included datasets. Furthermore,the results from the dual-­mode mapping showcase the importance of identical data characteristics be­tween train and test datasets. Conversely, with the use of the cross-­mode experiments, it is found not essential to match the pre-­ and post­-event resolution imagery. This latter is very promising for the Red Cross and creates flexibility to construct datasets quickly after the disaster has struck.","Deep Learning; Convolutional Neural Network; Satellite Imagery; Optical Data; Synthetic Aperture Radar; Resolution differences; Natural Disaster; Damage assessment; Red Cross; GPU computing; Classification","en","master thesis","","","","","","","","2022-11-17","","","","Geoscience and Remote Sensing","510 - an organisation of the Red Cross Netherlands",""
"uuid:10ce3c80-9fea-4b62-9c77-c0c33971906d","http://resolver.tudelft.nl/uuid:10ce3c80-9fea-4b62-9c77-c0c33971906d","Autonomous Navigation around Asteroids using Convolutional Neural Networks","van der Heijden, Lars (TU Delft Aerospace Engineering; TU Delft Astrodynamics & Space Missions)","Mooij, E. (mentor); Woicke, S. (mentor); Stam, D.M. (graduation committee); van Kampen, E. (graduation committee); Delft University of Technology (degree granting institution)","2022","Missions to small bodies are increasingly gaining interest as they might hold the secrets to our solar system’s origin while some are also posing a threat to life on Earth. The small size and irregular shape result in complex dynamics complicating the close-proximity operations. Furthermore, due to the long round-trip time communication delays of up to 20 minutes can exists, excluding any required computation time on Earth. Currently used approaches either rely on detecting pre-defined landmarks on the target, detecting features and matching them to a database, or tracking craters or unknown features across images (relative navigation). However, these methods rely heavily on a-priori information, suffer from computationally intensive matching steps, or depend on the accuracy of the initial state estimate. <br/><br/>This work investigated the usage of a novel CNN-based pipeline that can be used to autonomously navigate accurately around asteroids. A top-down CNN-based feature detector is developed consisting of an object and keypoint detection network in sequence, which detects n pre-defined keypoints designated on the target’s 3D model using the 3D SIFT algorithm. These 2D detections alongside their 2D-3D correspondences are sent to an Efficient Perspective-n-Point (EPnP) solver that solves the Perspective-n-Points (PnP) problem. The CNN-based feature detector replaces traditional hand-engineered Image Processing (IP) algorithms as it is more robust to illumination conditions and image noise. Furthermore, the use of a CNN facilitates an offline feature selection step and as such avoid the cumbersome and computationally intensive 2D-3D matching step of the detected 2D feature to their location on the 3D model, plaguing traditional approaches. This pose estimation pipeline can be used to navigate around the asteroid up until it covers the full field of view of the camera, and it can be used to(re)-initialize the navigation filter for a relative navigation approach. <br/><br/>The networks have been selected based on their applicability to embedded devices and this resulted in the use of the SSD-MobileNetV2-FPN-Lite as the object detection network and the Lightweight Pose Network (LPN) model as the keypoint detection network. This lightweight CNN-based pipeline has a fraction of the parameters and Floating Point Operations (FLOPs) compared to state-of-the-art deep-learning networks and pipelines. These networks have been trained and evaluated on synthetic datasets created in this work, consisting of 32,352 images with a variety of poses for a distance of 4.5 km to 9 km from the asteroid for different illumination conditions, asteroid orientations, and image corruptions that emulate real sensor artifacts. <br/><br/>The pipeline could achieve a mean and median line-of-sight distance estimate of around 42 m and 30 m, respectively, at a confidence level of 90% for the large relative range, while satisfying the accuracy requirement of a maximum 10% knowledge error for 99.979% of the cases. Furthermore, the pipeline has been proven to be robust against illumination conditions, occlusions, textures, and image corruptions, mimicking effects of real sensors and the space environment. Demonstrating the efficacy of this CNN-based approach for autonomous navigation around asteroids. <br","Applied machine learning; Computer Vision; Convolutional Neural Networks (CNNs); vision-based navigation; Autonomous Navigation; Deep Learning; Asteroids","en","master thesis","","","","","","","","2023-02-17","","","","Aerospace Engineering","",""
"uuid:3ae4c065-bbbc-4472-9915-739f629ea440","http://resolver.tudelft.nl/uuid:3ae4c065-bbbc-4472-9915-739f629ea440","Robot Code of Conduct for Automated Dairy Farming: Steering the Design of Pleasurable, Cohesive and Appropriate Behaviours for Lely Automated Portfolio","Gonzalez Gonzalez, Irene (TU Delft Industrial Design Engineering)","Cila, N. (mentor); Rozendaal, M.C. (graduation committee); Delft University of Technology (degree granting institution)","2022","Robot systems are essentially a new species spreading around us, one that we willingly designed and introduced. Neither a natural species nor a mere human artefact. We have limited information about these smart agents. What do they want, what do you need from us, and how can we find a common ground of understanding to enhance each other through collaboration. Lely took a step into exploring these questions.<br/><br/>As a dutch-based company with a diverse portfolio of robot solutions, Lely thrives to bring dairy farming to the future. They cover many tasks assisting farmers and cows in barns worldwide. These increasingly capable entities are no longer tools but partners so we must take the next step into carefully designing our coexistence and collaboration with these robotic systems.<br/><br/>After extensive literature on Human-Robot Interaction (HRI) and research activities with a variety of stakeholders, I developed a Robot Code of Conduct. This code guides developers into designing robotic systems delivering pleasurable, fitting and cohesive interactions. It provides intermediate-level knowledge on robot behavioural design by carrying the reader through three sets of guidelines differing in abstraction and actionability. <br/><br/>This project contributes to the field of HRI while spreading awareness of its relevance in practice. The document contains many influential factors that are applied and tailored to designing automated solutions in dairy farming. This document sets a direction and gives concrete guidelines to steer the development of the portfolio towards a vision where all Lely systems work and communicate desirably. Where they communicate as one. I obtained positive results from assessing the content and direction of this document with developers and farmers, however, further tests would be necessary for a more precise validation of this Robot Code of Conduct. Future research would be essential to transition from bringing awareness to relevant factors, to defining more recommendations and appropriate solutions.","Human-Robot Interaction; Design Guidelines; Code of Conduct; Expressive Agents","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:15b25b42-e04b-4ff2-a187-773bc170f061","http://resolver.tudelft.nl/uuid:15b25b42-e04b-4ff2-a187-773bc170f061","A theoretical approach towards digital twins: A balance between an empirical and a fundamental model for distribution transformers","van Dijk, Max (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Mathematical Physics)","Lahaye, D.J.P. (mentor); Schuddebeurs, Jeroen (mentor); van Gijzen, M.B. (graduation committee); Delft University of Technology (degree granting institution)","2022","The energy transition will significantly impact distribution transformers as they will have to deal with more load on them, which is also more variable due to renewable energy sources. However, currently, these transformers are often not monitored with sensors. Therefore, the Dutch network operator Stedin asked to investigate the possibilities of a digital twin for distribution transformers without many sensors. This thesis presents two ways to do so: the currently most used but more empirical loading guide and a more analytical method where we solve Maxwell's equations using the finite element method (FEM). Furthermore, the transition to more renewable energy sources and sources that draw instant power from the grid causes the current to get distorted. This distortion can be mathematically analyzed using harmonic functions, and we will consider the impact of these harmonics in both the loading guide and the FEM model. <br/><br/>The loading guide is a method written in slightly different ways in the IEEE and IEC standards that takes the load on a transformer and the ambient temperature around the transformer to determine the hot spot temperature inside the transformer. By saying that the hot spot temperature is the warmest point inside the transformer, we can determine the percentage of loss of life of a transformer for a particular loading pattern. However, the loading guide only considers one set of parameter values for distribution transformers, which can vary widely in rating, location and ventilation household, leading to an over-or underestimation of the temperature, which in both cases can lead to extra costs. Additionally, the impact of harmonics is an empirical addition to the loading guide and only considers the effect on temperature rise and not the losses.<br/><br/>Therefore, we consider the transformer in a finite element approach. We solve Maxwell's equation on a transformer cross-section with the FEM, resulting in a 2D model that can calculate the losses for a particular geometry. This model is made using COMSOL Multiphysics. Furthermore, we calculate the core and winding losses under a harmonic load, resulting in considerably higher losses than without harmonics. <br/><br/>As the FEM model is quick and straightforward to run, it can serve as a first step towards developing a digital twin of distribution transformer, giving a way to determine the losses analytically. With future development, the model can provide better insight into the temperature distribution in the transformer.","Distribution Transformer; Digital Twin; Condition assessment; FEM analysis","en","master thesis","","","","","","","","","","","","","",""
"uuid:fad5e219-c2e8-41ab-ac2b-63a2b089c745","http://resolver.tudelft.nl/uuid:fad5e219-c2e8-41ab-ac2b-63a2b089c745","Experimental and numerical modelling of mode I fracture in tropical hardwoods","Gijzenberg, Kees-Jaap (TU Delft Civil Engineering and Geosciences)","Ravenshorst, G.J.P. (mentor); van de Kuilen, J.W.G. (graduation committee); Esposito, R. (graduation committee); Delft University of Technology (degree granting institution)","2022","The goal of the thesis is to investigate two main questions for the purpose of modelling fractures in timber with a finite element method. The first question is to evaluate the use of digital image correlation during a three point bending test to obtain mean values for tensile strength and fracture energy, and the follow up question is if it is possible to replicate the tests with these mean values. The final result should be a guide to help modelling fractures in timber and how to obtain the necessary data.","Azobé; Azobe; notch; Tropical hardwood; tenon; Fracture energy; Finite Element Method; Finite element analysis; Digital image correlation","en","master thesis","","","","","","","","","","","","Civil Engineering | Structural Engineering","",""
"uuid:b95ba677-16c1-4957-a2d8-d926ac095083","http://resolver.tudelft.nl/uuid:b95ba677-16c1-4957-a2d8-d926ac095083","Lightsail design with neural optimization of topology","Norder, Lucas (TU Delft Mechanical, Maritime and Materials Engineering)","Bessa, M.A. (mentor); Norte, R.A. (graduation committee); Delft University of Technology (degree granting institution)","2022","class=""MsoNormal"" style=""margin-bottom:0cm;line-height:normal;mso-layout-grid-align: none;text-autospace:none"">Conventional Topology Optimization (TO) enables the inverse design of nanophotonic structures by specifying the objective and constraints without a predefined topological concept. Yet, extreme scenarios such as the design of a lightsail pose challenges that require new solutions. Here, a convolutional neural network (CNN) based TO methodology is extended to optimize a two-dimensional photonic crystal used to design a lightsail that aims to reach the nearest star (Alpha Centauri) within 20 years by achieving 20% of the speed of light. The CNN-TO performance is compared to a more conventional method of moving asymptotes (MMA) based TO by optimizing a photonic crystal unit-cell for the 2016 Starshot Initiative parameters. The CNN-TO requires up to 40% fewer iterations than MMA-TO to reach better performance under different operational conditions. The generated design turned out to be easy to fabricate, allowing them to be produced with optical lithography. Additionally, a study regarding the design challenges of the lightsail has been performed, which resulted in an optimization considering the functionality of the sail. Additionally, the study showed the sensitivity of the resulting design to varying objectives and materials. Therefore, underlining the necessity of considering multiple operating conditions (e.g. laser alignment and cooling) within the design process.","lightsail; topology optimization; convolutional neural network; starshot","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Mechatronic System Design (MSD)","",""
"uuid:24b54bb3-a860-4cc7-8bee-93878bda7b50","http://resolver.tudelft.nl/uuid:24b54bb3-a860-4cc7-8bee-93878bda7b50","Explaining the role of dieselgate in the rise of Electric Vehicles","Terwindt, Maurits (TU Delft Civil Engineering and Geosciences)","Negenborn, R.R. (mentor); Beelaerts van Blokland, W.W.A. (mentor); Annema, J.A. (mentor); Delft University of Technology (degree granting institution)","2022","This thesis looks into the link between the Volkswagen emission scandal, or dieselgate, and the strong rise of electric vehicles in the years following that event. In order to investigate this, a framework is build that describes the process of an innovation (the electric vehicle), taking over from an incumbent technology (fossil fuel cars), in measurable factors. This framework combines several theories on these subjects, including innovation diffusion, standard battles, disruptive innovation and radical innovation. The addition of manners to measure the underlying factors is one of the new aspects this thesis brings to both science and society. Through the application of the framework in case study concerning the automotive industry, it was concluded that dieselgate has indeed influenced the rise of electric vehicles, both directly and indirectly through Company Strategy, the reputation of a company, the opinion of consumers on technology, and government regulations and incentives.","Dieselgate; Electric Vehicles; Standard Battle; Innovation Diffusion; 3C-model","en","master thesis","","","","","","","","","","","","Transport, Infrastructure and Logistics","",""
"uuid:762627c5-9901-4c23-a7e4-f6cd791f2fb7","http://resolver.tudelft.nl/uuid:762627c5-9901-4c23-a7e4-f6cd791f2fb7","A critical evaluation of (scatterometer-based) ocean surface wind products over sea","van Cranenburgh, Liselotte (TU Delft Civil Engineering and Geosciences)","Siebesma, A.P. (mentor); Nuijens, Louise (mentor); Delft University of Technology (degree granting institution)","2022","By combining satellite observations and model reanalysis winds, a global data set with higher temporal and spatial resolution ocean surface wind fields can be generated. These superior surface wind fields can have various applications, such as wind forcing of ocean models. The Royal Netherlands Meteorological Institute (KNMI) is responsible for the delivery of two different global data sets of combined surface winds, referred to as IFREMER and ERA5*. IFREMER’s approach focuses on satellite scatterometer observations which are complemented with model reanalysis winds (ERA5). On the other hand, ERA5* is based on ERA5 model reanalysis and corrected with scatterometer observations. The aim of this research is to evaluate global IFREMER and ERA5* surface winds in terms of spatial and temporal characteristics.<br/><br/>In order to validate the surface winds of IFREMER and ERA5*, a reference system of true winds is required. For this, quality-controlled wind observations from an independent Chinese scatterometer Haiyang-2B have been used. This comparison study has been carried out for the year 2019 focusing on zonal wind, meridional wind and wind speed. IFREMER and ERA5* wind fields have been collocated in time and space to HY-2B wind observations using a 6-hour and 1-hour window respectively. This methodology was applied to overcome differences between the data sets in grid definition, wind representation, spatial resolution and temporal resolution.<br/><br/>On a global scale, IFREMER shows larger average and standard deviation of wind differences with respect to HY-2B than ERA5*, specifically in coastal regions and at higher latitudes. The results of this research suggest that the ERA5* wind product generates more accurate surface ocean winds than IFREMER, except for in the tropics, assuming that HY-2B winds represent the true value. Moreover,<br/>at higher wind speeds both global wind products underestimate HY-2B wind, whereby IFREMER already deviates at lower winds than ERA5*. The IFREMER winds showed suspicious satellite tracks and temporal wind inaccuracies, most likely as a result of its 6-hourly resolution. It is recommended that a follow-up investigation is carried out with validation of buoy data in the tropics to investigate the underlying causes of the observed local wind bias.","wind, scatterometer, ocean","en","master thesis","","","","","","","","","","","","Civil Engineering | Environmental Engineering","",""
"uuid:803a83f6-75a4-4016-8427-7fd158a8f09f","http://resolver.tudelft.nl/uuid:803a83f6-75a4-4016-8427-7fd158a8f09f","Robust Bluetooth Low Power Communication","Hendriks, John (TU Delft Electrical Engineering, Mathematics and Computer Science)","de Winkel, J. (mentor); Pawełczak, Przemysław (graduation committee); Delft University of Technology (degree granting institution)","2022","This work presents the first robust connection mode for Bluetooth Low Energy on an energy harvesting sensor.","Bluetooth Low Energy; Energy Harvesting","en","master thesis","","","","","","","","2024-03-31","","","","Computer Engineering | Embedded Software","",""
"uuid:7814e516-e9a9-4633-ab48-b55f5364f7c3","http://resolver.tudelft.nl/uuid:7814e516-e9a9-4633-ab48-b55f5364f7c3","Explaining overthinking in Multi-Scale Dense networks: Why more computation does not always lead to better results","Voorhout, Damian (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Gemert, J.C. (mentor); Liu, X. (graduation committee); Delft University of Technology (degree granting institution)","2022","Traditional convolutional neural networks exhibit an inherent limitation, they can not adapt their computation to the input while some inputs require less computation to arrive at an accurate prediction than others. Early-exiting setups exploit this fact by only spending as much computation as is necessary and subsequently exiting the sample early. In an end-to-end trained convolutional neural network with multiple classifiers, one might expect deeper classifiers to perform better in every circumstance than shallow classifiers; deeper layers make use of the computation done by earlier layers after all. However, this is not always the case and more computation can lead to worse results. This <br/>phenomenon, which has been dubbed overthinking, has been documented in several traditional convolutional neural networks with intermediate classifiers. It has been conjectured that it happens due to later classifiers making use of more complex feature which benefit from a larger receptive field. These later classifiers then claim to discern said features in regions of the image which do not contain them, effectively making the classifiers misclassify images that can be classified correctly by shallow classifiers. However, we have observed overthinking in Multi-Scale Dense networks, an end-to-end hand-tuned network optimized for early-exiting for which the given argument in relation to the receptive field does not hold due to its unique architecture. For this reason, in this thesis we attempt to explain overthinking in Multi-Scale Dense networks. We show that in general there seems to be no connection between what a classifier in a Multi-Scale Dense network learns and the data itself. This in turn suggests that overthinking does not take place due to specialization of the classifiers. Instead, we offer up an alternative theory for overthinking in the form of stochasticity inherent to the training process.","CNN; Early-exiting; Multi-Scale Dense network; Policy network; Adaptive inference","en","master thesis","","","","","","","","","","","","Computer Science | Bioinformatics","",""
"uuid:d0a127c6-c419-4da4-8ee2-a338fb77b282","http://resolver.tudelft.nl/uuid:d0a127c6-c419-4da4-8ee2-a338fb77b282","Retail areas in the city: From a place to buy to a place to be","Voortman, Lieke (TU Delft Industrial Design Engineering)","Keller, A.I. (mentor); Beets, M.F. (graduation committee); Rutten, P. (graduation committee); van de Mosselaar, M. (graduation committee); Delft University of Technology (degree granting institution)","2022","The goal of the project is ‘to make retail areas go from a place to buy to a place to be’. Retail environments have the potential to become a place to be and add value for visitors, the local community and society as a whole. After performing research on various different levels, both quantitative and qualitative and both with consumers and external stakeholders, new consumer vales emerged for retail areas in the city. They were transparency, connection, atmosphere, exploration and authenticity. Exploration and authenticity were chosen as the two core values to form a design direction. A conceptual model was produced to add value to retail areas: in order to create a place to be, a story and an experience are necessary. The story is what brings authenticity to a place, and that can be achieved using storytelling. An experience can be created through multisensory design and can provide the core value of exploration. Using this model, a possible design was created: the story box. This concept provides a multisensory storytelling experience. The story box is a physical cube placed in the street that tells a story through exploration. Users move around the cube to go through the stages of the discovery process: touch, see and hear.The three sides of the cube are assigned with different colors: green, red and blue. Users then can step inside the box and hear the full story. The experience is not just limited to interacting with the cube, it is extended to interacting with the entire street. Both the effect of the authentic stories and the exploring discovery are extended into the street. For the authentic stories, in addition to the large cube, small cubes using the same colors are placed throughout the street at the entrance of shops and stores. Shopowners can participate in the project and adopt a small cube. These small cubes provide the story of the shop or store in audio, once a visitor places its hand inside the cube. For the exploring journey, small colored tiles are placed on the facades throughout the street. The colors coordinate with the colors of the interactions with the cube: touch, see and hear. The small tiles each provide another little discovery journey: green tiles mean there is something nice to touch, red tiles meansthere is something nice to see and blue tiles mean there is something to hear. The final concept gives meaning to retail areas and provides and authentic story in an exploring way. <br/><br","retail; urban design; interaction design","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:6f189a23-6ebf-4c63-84df-c0fcec3ba5e3","http://resolver.tudelft.nl/uuid:6f189a23-6ebf-4c63-84df-c0fcec3ba5e3","Quantification of the development of trunk control in healthy infants using inertial measurement units","Blok, Janneke (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Biomechanical Engineering; TU Delft Delft Center for Systems and Control)","Kok, M. (mentor); Vallery, H. (mentor); Lemus Perez, D.S. (mentor); Horemans, H.L.D. (mentor); van der Kruk, E. (graduation committee); Marchal Crespo, L. (graduation committee); Delft University of Technology (degree granting institution)","2022","Trunk motor control is essential for the proper functioning of the upper extremities and is an important predictor of gait capacity in children with delayed development. Early diagnosis and intervention can potentially increase the trunk motor capabilities in later life. However, current tools used to assess the level of trunk motor control are largely observation-based and lack the sensitivity to change required to accurately monitor progress and effects of therapy in children below the age of 4. To the best of our knowledge, this is the first attempt to use trunk-attached inertial measurement units (IMUs) to differentiate different levels of trunk motor control in this population. We performed experiments with seven children to examine the applicability of the RMS of jerk as an outcome metric for the level of trunk motor control. This study showed that the root mean square (RMS) of jerk decreases for ages up to 24 months, is relatively independent of data segment and length, and shows results similar to a more established method: the centre of pressure (COP) velocity. These findings suggest that the RMS of jerk shows potential as a metric for the differentiation of different trunk motor control levels. However, due to the small sample size, a follow-up study is necessary to verify and validate these results.","trunk control; Inertial Measurement Unit; infants; balance; jerk; IMU","en","master thesis","","","","","","Master of Science in Mechanical Engineering, Systems and Control and Biomedical Engineering","","","","","","Biomedical Engineering","",""
"uuid:def71c0b-51b1-43e3-8a40-d22e0c36cfcb","http://resolver.tudelft.nl/uuid:def71c0b-51b1-43e3-8a40-d22e0c36cfcb","Ultra-Low Power On-Chip Oscillator: A 0.9-V 1.039-MHz 20.51-fJ/cycle oscillator in 28-nm CMOS with rail-to-rail output swing","Demarets, Maël (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Applied Sciences; TU Delft Microelectronics)","Sebastiano, F. (mentor); Villar Piqué, G. (graduation committee); Fan, Q. (graduation committee); Delft University of Technology (degree granting institution)","2022","","Oscillator; Voltage controlled oscillator; Ultra low power; Rail-to-Rail; CMOS","en","master thesis","","","","","","","","2027-02-15","","","","Electrical Engineering","",""
"uuid:1cf2fe45-5839-4c46-8795-a9dbbab93e5a","http://resolver.tudelft.nl/uuid:1cf2fe45-5839-4c46-8795-a9dbbab93e5a","A workability study on floating installation of monopiles using the MUST","Tjaberings, Jorick (TU Delft Technology, Policy and Management; TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Offshore and Dredging Engineering)","Jarquin Laguna, A. (mentor); Miedema, S.A. (graduation committee); Fazi, S. (graduation committee); Delft University of Technology (degree granting institution)","2022","Adapting the size of upending cradles according to the ever-increasing dimensions of offshore wind turbine monopiles is costly and requires structural modifications to the associated Heavy Lift Vessels (HLVs). This study therefore investigates the potential of the Monopile Upending Smart Tool (MUST), which is a platform suspended in the HLV crane, on which a winch is installed. Two grommets of constant length connect the platform with two trunnions attached to the monopile, and the winch cable suspends the bottom of this structure. Unwinding the winch cable allows for in-crane upending of the monopile. This way, the dependency on the size of the available cradle is circumvented. The focus is laid on determining the workability of the application of the MUST in the crane of the Seaway Strashnov and identifying limitations in its design. Moreover, the potential of systems that increase the workability or reduce the limitations is investigated.<br/><br/>The installation of monopiles using the MUST comprises three phases: the barge mooring / lift-off, upending / slewing and lowering / driving phase. Based on the results from a qualitative critical event analysis, the lift-off phase is expected to be limiting. Hence, a hydrodynamic model is developed to quantitatively analyse this phase. Experimental simulations, which are performed in parallel with the model development, result in the preliminary conclusions that multiple pendulum effects influence the results to a limited extent, while viscous roll damping and hydrodynamic interaction effects can be strong determinants of the resulting responses. <br/><br/>The relative z-motion between the lifted monopile and the barge and the barge roll response are identified as governing parameters. To reduce the first limiting factor, a system that allows for instantaneously increasing the vertical clearance between the monopile and the barge is proposed. The effectiveness of this system is tested for two barge loadcases. For the first case, the average workability increase for the optimal heading at a typical location is calculated as 8.3%. For the second, the increase is marginal, as the barge responses are more limiting. Furthermore, is it found that a Passive Motion Compensator (PMC) can reduce the probability of the introduction of snap loads in the winch cable, and therefore allows for system optimisations. A PMC with 10% of critical damping can reduce the required winch capacity with a factor of 2.3 w.r.t. the uncompensated case.<br/><br/>It is recommended to perform follow-up studies into the system performance during upending / slewing and lowering / driving. Also, it is advised to evaluate the effect of a larger barge and a PMC on the workability. To balance the associated investments and workability increases, the logistical models developed in a parallel study can be used. Finally, for iterative calculations, it was found to be beneficial to make an estimate based on a fast simplified model and to subsequently feed the results back into a more detailed, but slower model.<br","Barge; Floating; Heavy Lift Vessel; Lift-Off; Monopile; Offshore Wind; Operability; Passive Motion Compensator; Upending; Workability","en","master thesis","","","","","","","","2024-02-14","","","","Offshore and Dredging Engineering","",""
"uuid:b3dfcd1c-934b-49c7-8a62-03b49b803fe3","http://resolver.tudelft.nl/uuid:b3dfcd1c-934b-49c7-8a62-03b49b803fe3","Inculcating ​a ​sense ​of ​stewardship ​and ​responsibility ​towards urban ​​trees ​amongst ​citizens: Using i-tree technology as a means to facilitate active participation of local communities in urban forestry","Ramchandani, Deeksha (TU Delft Industrial Design Engineering)","Price, R.A. (mentor); van Erp, J. (graduation committee); van der Velde, J.R.T. (graduation committee); Delft University of Technology (degree granting institution)","2022","Cities are in an urgent need to adapt to the impacts of climate change, particularly, high temperatures and heat stress. Urban Forests are the most effective means of climate adaptation. However, the multiple benefits of urban trees are highly undervalued in the urban contexts. This project focuses on positioning urban trees as effective agents in improving the overall liveability of cities. The premise of the project lies in the fuzzy front end of the innovation process where the i-Tree technology is being redeveloped for its effective adoption in Netherlands. The goal of the project is to synchronize the technical potential of i-Tree as a tool and communicate the benefits of trees to multiple stakeholders in the process.<br/><br/>The overall design direction aims to address these problems through a series of interventions across the system of urban forestry. The concept introduces a public awareness campaign to bridge the knowledge gap between citizens and other stakeholders. The campaign is proposed to stretch over a duration of 10-11 months with several touchpoints along the way for citizens to get enthusiastic about the idea of maintaining and taking care of urban trees. The touchpoints aim to target events like Dutch Design week, Boomfeestdag (Tree Festival) and Springsnow festival. To make the awareness program desirable and interesting. A podcast series and a guide is developed called “How to befriend a Tree?”. A concept for the i-Tree Eco tool is proposed which communicates tree benefits in a way that is comprehensible by all the citizens. All the touch points lead the audience of the campaign to the digital platform of i-Tree Netherlands which helps people become caretakers of trees easily.","strategic design; urban forestry; i-Tree; Speculative Design; climate resilience","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:97030ec0-9cf6-4dd6-8109-b4864e9273e3","http://resolver.tudelft.nl/uuid:97030ec0-9cf6-4dd6-8109-b4864e9273e3","Pile Dredging in Cohesive Soils: Experimental research on the influence of different dredging configurations","Aouragh, Bilal (TU Delft Mechanical, Maritime and Materials Engineering)","Miedema, S.A. (mentor); van Rhee, C. (graduation committee); Pahlavan, L. (graduation committee); Nobel, Arno (mentor); van Giffen, Ike (mentor); Delft University of Technology (degree granting institution)","2022","After decades of exploitation of hydrocarbons, the offshore facilities constructed for this purpose are nearing the end of their design life and/or economic operation. According to international law, these offshore structures need to be completely removed. Decommissioning of the substructures often requires for soil to be removed in piles to facilitate pile cutting works below the seabed. One way of achieving this is by deploying a specialized tool, a so-called Soil Plug Removal Tool (SPRT), that operates using hydraulic excavation. <br/><br/>This research carried out under supervision of Royal Boskalis Westminster N.V. aims to get a more solid basis for comparison of different SPRT concepts that are available in the market. The tools are designed to handle a wide range of soil types. Removal of cohesive sediment is more challenging, mainly due to the very low water permeability present compared to granular soils. This study therefore focusses on the excavation of cohesive soil types only. <br/>In order to verify the performance of several concepts an experimental test program is set up on model scale. The primary goal is to investigate the achievable excavation production in terms of tool progress rate. Therefore, a jetting tool is developed that covers the (complete) spectrum in terms of cohesive soils and performance of the available tools. Two basic SPRT concepts are incorporated in this single tool based on head movement: static or rotating. <br/><br/>Jet pressure, clay strength, rotational velocity and set down pressure of the tool are altered during testing on the condition that all other parameters are fixed. This requirement is met for the testing clay by merely varying the shear strength. The testing clay was therefore prepared both with an artificial and natural clay with shear strengths ranging from 20 kPa to 100 kPa. <br/><br/>It is found that next to jetting, soil failure can also be attributed to cutting and jet trench failure under influence of the jetting head that rests on top of the clay. For this reason, production values belonging to jetting could not be obtained directly and had to be calculated using jetting theory to distinguish between jetting and jet trench failure. Based on the power that is required to excavate a certain volume of soil (i.e. specific energy), insight is given in the contribution of each failure mechanisms to the production in terms of tool progress rate. <br/><br/>During static jetting, the current (nozzle) configuration did not remove enough soil from the jet cavities for the jetting tool to progress downwards. The opposite is true for the rotational tests which comprise the largest part of the test series. An analytical model is proposed to predict the cavity width and depth. This model is only valid for jets with small rotational velocities as encountered in this study. <br/><br/>The total production, which was measured, is found to be inversely proportional to shear strength and directly proportional to jet pressure and rotational velocity. <br","Cohesive soil; Hydraulic excavation; Jetting; Soil plug; Artificial clay; Experimental Research; Model scale; Pile dredging; Rotating jet","en","master thesis","","","","","","","","2024-02-14","","","","Offshore and Dredging Engineering","",""
"uuid:0be34223-4780-4110-8096-d7e188bb0320","http://resolver.tudelft.nl/uuid:0be34223-4780-4110-8096-d7e188bb0320","Electromagnetic navigation in mandible reconstruction surgery: Introduction and assessment of a noninvasive method for patient registration","de Geer, Fleur (TU Delft Mechanical, Maritime and Materials Engineering)","Loeve, A.J. (mentor); Karakullukcu, M.B. (mentor); van Alphen, M.J.A. (mentor); van Veen, R.P.J. (mentor); Jansen, F.W. (graduation committee); van Erven, L. (graduation committee); Delft University of Technology (degree granting institution); Universiteit Leiden (degree granting institution); Erasmus Universiteit Rotterdam (degree granting institution)","2022","In patients with oral cavity cancer invading the mandible, a segmental bone resection is performed and the original contour of the mandible is reconstructed with a free fibula flap. Virtual surgical planning is performed prior to surgery to determine the locations and orientations of the osteotomy planes on the mandible and fibula. Currently, patient-specific cutting guides are designed and three-dimensional printed to translate the virtual surgical plan to the patient in the operating room. However, these cutting guides are not ideal; they lack adaptability when the intraoperative situation is different than expected, e.g. due to tumor progression. Alternatively, surgical navigation could be used to translate the virtual surgical plan to the patient. To enable surgical navigation, accurate alignment of the preoperative imaging data, including the virtual surgical plan, and the patient is required, i.e. image-to-patient registration. In this thesis, a simple, accurate, and noninvasive registration method for electromagnetic navigation of the mandible is introduced and assessed.<br/><br/>Chapter 1 gives an introduction to the clinical background of mandible reconstruction surgery and the technical background of surgical navigation. The clinical problem, a potential solution and the thesis objectives are also discussed. <br/><br/>The systematic review in Chapter 2 gives an overview of currently used registration methods in navigated mandibular surgery: point registration, surface registration, hybrid registration, and computer vision based registration. The main conclusion of the review was that there is always a tradeoff between the usability, registration time, accuracy, and invasiveness of a registration method.<br/><br/>Chapter 3 introduces a simple and noninvasive registration method for mandible navigation: hybrid registration. This method consists of two steps: 1) point registration; performed for initialization using three anatomic landmarks on the mandible, and 2) surface registration; performed for optimization using the surgically exposed mandibular bone surface after removal of soft tissue.<br/><br/>In previous research in the NKI-AvL, an applicator was used to fixate an electromagnetic sensor to the mandible to track its movements during navigated surgery. The design of this applicator, however, enabled movement of the sensor in the applicator, which resulted in inaccurate navigation. Therefore, in Chapter 4, a renewed design for the sensor applicator is proposed. <br/><br/>In Chapter 5, the optimal approach for hybrid registration of the mandible is determined in phantom experiments. Different registration configurations, i.e. different surface point areas and number and configuration of surface points, were evaluated as well as registration with different patient anatomies. In all experiments, the target registration error (TRE) was below 2.0 mm, which meets the practical clinical requirements for mandible reconstruction surgery. The results suggest that only a small surface area of the mandible, marked by limited surface points, is required to obtain accurate registration.<br/><br/>Chapter 6 describes the preliminary results of hybrid registration of the mandible in four patients during surgery. Registration could be performed within on average 4.5 minutes. Mean TRE values of 3.4 mm for anatomic landmarks and 2.3 mm for cutting guide landmarks were obtained, indicating that the registration procedure should be further optimized to achieve clinically acceptable registration accuracy.<br/><br/>Chapter 7 provides an overall conclusion and future perspectives. Although the preliminary results of the patient study for mandible navigation are promising, the registration method should be further optimized and evaluated in more patients before implementation into clinical practice is possible. Ultimately, we want to use electromagnetic navigation to position a universal cutting guide during mandible reconstruction surgery. Multiple challenges still lie ahead before this can become reality in the NKI-AvL.  <br","surgical navigation; computer assisted surgery; image-to-patient registration; mandible surgery; electromagnetic tracking","en","master thesis","","","","","","","","2025-02-14","","","","Technical Medicine","",""
"uuid:7d150ea8-1cdd-4584-a99e-65392599bfb9","http://resolver.tudelft.nl/uuid:7d150ea8-1cdd-4584-a99e-65392599bfb9","Photon-bunching in ground-based submillimeter-wave astronomy","Tiebosch, Joris (TU Delft Applied Sciences)","Endo, A. (mentor); Baselmans, J.J.A. (graduation committee); Otte, A.F. (graduation committee); Rybak, M. (graduation committee); Delft University of Technology (degree granting institution)","2022","DESHIMA (the Deep Spectroscopic High-Redshift Mapper) is a 347 channel superconducting spectrometer with spectral resolution R =500 that operates in the range of 220GHz to 440GHz and can therefore accurately measure the frequency of spectral lines in order to calculate redshift z.<br/>This report investigates the sensitivity of DESHIMA-like spectrometers by investigating photon noise due to Poisson and bunching effects. It gives a broad overview of photon statistics and explains, through an analogous model, that photon bunching occurs due to an underlying change in the probabilistics, rather than the act of detecting itself. After that I investigate photon and quasiparticle recombination noise for a DESHIMA-like spectrometer with Lorentzian filters and find a closed form equation for NEP per channel for a constant power spectral density arriving at the filters.<br/>Previously the bandwidth of the filters was assumed to be negligible, resulting in an overestimation of the bunching. Because the photons that are impinging on the detector span a bigger bandwidth, the bunching is a factor of π/2 smaller than previously approximated.<br/>This NEPτ is defined at an integration time of τ=0.5s. For other integration times this is scalable, however this will only hold while the integration time is much bigger than the coherence time τ≫tcoh. Because of the correlation between photons arriving shorter than a coherence time apart, the scaling of the NEPτ drops in cases when τ≫̸tcoh.<br/><br/>Finally I propose and describe modifications to the sensitivity model DESHIMA uses. The following features have been be improved and added:<br/><br/>- Integrate over the entire power spectrum when calculating photon noise<br/>- Use arbritatry filter designs loaded from a file<br/>- Improve estimations of the quantities that express sensitivity<br/><br/>I compare the proposed modifications to the old model, which has previously been compared with measurement results, and use it to validate the changes. Other than the previously mentioned factor of π/2 for the bunching term and the smoothing out in local extrema, the modified simulation results are similar to the old model. This is because the Lorentzian filters have a small bandwidth ν≫Δν, such that the previous narrowband approximation held for most non-extreme cases.<br","Photon bunching; DESHIMA; Quantum optics","en","bachelor thesis","","","","","","https://joristiebosch.github.io/thesis/ Interactive version available https://github.com/deshima-dev/deshima-sensitivity Python model described in Thesis","","","","","","Applied Physics","DESHIMA",""
"uuid:32c30c78-7f85-4606-9891-89ea012cb86a","http://resolver.tudelft.nl/uuid:32c30c78-7f85-4606-9891-89ea012cb86a","Cost-effectivity of logistical strategies for the installation of offshore wind turbine substructures","Tjaberings, Jorick (TU Delft Technology, Policy and Management; TU Delft Mechanical, Maritime and Materials Engineering)","Fazi, S. (mentor); Verburg, R.M. (graduation committee); Jarquin Laguna, A. (graduation committee); Delft University of Technology (degree granting institution)","2022","The ever-increasing size of offshore wind turbine substructures and the development of wind farms at sites further offshore, with greater water depths and with extremer weather conditions, raise logistical challenges that have never been faced before. Additionally, the offshore wind industry has to deal with governments cutting subsidies, small profit margins and limited practice guidelines, while it is expected to lower the associated levelised cost of energy to a competitive level in the market. Scientific studies have identified room for optimisation in the substructure (the focus is laid on Monopiles (MPs) with Transition Pieces (TPs) and pre-piled jackets) transportation and installation phases. However, no studies that evaluate the performance of strategies for these phases are identified. Hence, the objective of this study is to “generate insights into the complex system of interdependent strategies for the installation of offshore wind turbine substructures, and to identify and quantify cost-reduction opportunities.” The considered strategies are formed by combinations of transportation and installation strategies, which differentiate based on the number and type of the deployed vessels and the sequence in which the operations are performed.<br/><br/>To quantitatively compare the strategies, and to consider stochastic processes (e.g., weather conditions), a discrete-event simulation modelling approach is adopted. To arrive at substantiated conclusions, a framework is followed, which provides a roadmap and rigour criteria for the design, implementation and evaluation phases. First, a conceptual model is developed and face validated. Next, a numerical “base model” is constructed, which describes the most basic strategy. This model is face validated by industry experts and evaluated by parameter variability, convergence and historical data validation tests. It is concluded that the base model is structured according to shared practical experiences, responds satisfactory to parameter changes, requires 35 simulation runs to converge, and has good predictive capabilities. Hence, it is deemed suitable to function as a “template” for the modelling of the other strategies.<br/><br/>The simulation results are evaluated for each of the considered substructures separately. (i) MP – TP installation. In general, assembly-line installation strategies, in which two Heavy Lift Vessels (HLVs) are deployed, are associated with the shortest installation time. The shuttling – assembly-line and the shuttling–alternating (in which MPs and TPs are installed alternatingly) strategies are associated with the lowest costs. Both involve a shuttling transportation strategy, in which the HLV(s) ensure(s) both the transportation and installation of the components. The mooring of barges alongside an HLV in feeder strategies (feeder vessels supply components to an HLV, which stays at the wind farm under development) and the installation of TPs by a relatively small HLV in assembly-line strategies are identified as the main bottlenecks. Reducing these by relatively simple solutions can result in significant performance increases. Lastly, the project start date is found to be a strong determinant of strategy performance. (ii) Jacket – foundation pile installation. The assembly-line strategies are found to result in the shortest jacket installation times as well. However, only the shuttling – assembly-line strategy is additionally associated with the lowest costs. Furthermore, it is found that a separate pile-dredging vessel can help to reduce the time and costs associated with separate phases installation strategies, in which jackets and their foundation piles are installed in different phases. Also for jackets, the barge mooring alongside the HLV is identified to be the largest bottleneck. Reducing this bottleneck can result in significant performance benefits. Lastly, a relationship is found between the performance of jacket installation strategies and the project start date, although weaker than for MP installation.<br/><br/>The developed decision support tool can provide a platform for further research into the logistics of offshore wind and other industries, whereas the obtained results are only valid within the set boundaries. To widen the applicability, it is recommended to perform follow-up studies in which a stochastic mechanical failure component is included, and the sensitivity to the wind farm size and port-to-farm distance is tested. Furthermore, it is advised to extend this study to investigate the potential of the industry adopting a more holistic process or market point of view.","Decision Support Tool; Discrete Event Simulation; Feeder Vessel; Heavy Lift Vessel; Logistics; Offshore Wind; Strategies; Substructures","en","master thesis","","","","","","","","2023-02-14","","","","Management of Technology (MoT)","",""
"uuid:3c8df541-eded-4abe-aae2-e0448d2c87dc","http://resolver.tudelft.nl/uuid:3c8df541-eded-4abe-aae2-e0448d2c87dc","Haptic Lullaby: Research &amp; design of a vibrating smart mattress that helps young children sleep","Schoorl, Marjolein (TU Delft Industrial Design Engineering)","Lomas, J.D. (mentor); Huisman, G. (graduation committee); Delft University of Technology (degree granting institution)","2022","Young children often have problems sleeping. Some are afraid of the dark. Or wake up multiple times during the night. Another just does not want to go to bed or lays awake for a long time. Whatever the reason, a lack of sleep makes the children tired during the day. For parents, their child's well-being is important, so they want them to sleep well and be energised during the day. Bad sleep does not only have a negative influence on daytime functioning, but also on a child's cognitive development or behaviour. When a child wakes up often during the night, it influences the well-being of the parents, as they sleep worse too. Lots of parents walk with a stroller till their child sleeps, or drive around in a car. Both involve rhythmic motions and vibrations. Inspired by those phenomena, this graduation project explores if and how vibrations can help young children fall asleep, and a product is designed around that.<br/><br/>The final design concept is the Haptic Lullaby, a smart mattress that uses vibrations to help children between 1 and 5 years old fall asleep. The mattress consists of materials that ensure the vibrations are transported throughout the whole product, while also feeling soft and comfortable when lying down. Whichever position the child prefers to sleep in, they will feel the vibrations. Research indicated that a lullaby-like vibration works best when felt through the mattress. The combination of sound and vibrations together create a sleepy experience. One of the options to start the vibrations is through an app on the parents’ phone. This allows for remote control without entering the child’s bedroom. Another option is to turn on the smart function of the mattress. With sound and movement sensors, Haptic Lullaby measures if the child is awake, and it will turn on the vibration when lots of sound and movement is detected. When everything is quiet again, the vibrations are turned off.<br/><br/>The graduation project’s goal was to design a vibrating sleep product for young children that helps them fall asleep more easily. What was designed in the end was not only the product itself, but a methodology on how to design and evaluate such a product. As there is very little research done on the sleepiness of different vibrations, an initial model of characteristics and factors that determine the sleepiness of a vibration is offered. Also new is the ranking of thirteen different vibrations on their sleepiness. The assumption is formulated that what feels sleepy for an adult does not differ much from what children perceive as sleepy. Research results indicate this assumption to be true. This implies that future design and research on sleepy vibrations can be done with adults instead of children, which is easier to conduct. The graduation furthermore communicates a vision of what possibilities are for a haptic, vibrating sleep product. Its activities contribute to the fields of haptics and child research, and have value for companies who want to design research based sleep products.","Haptics; Vibrations; Design for Children; Research through Design","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:225ee891-b2bd-4c96-979a-a7c2fdb86a70","http://resolver.tudelft.nl/uuid:225ee891-b2bd-4c96-979a-a7c2fdb86a70","Mitigation of Weather effects on Optical Satellite Imagery","Eijgenraam, Bram (TU Delft Civil Engineering and Geosciences)","Lopez Dekker, F.J. (mentor); Hanssen, R.F. (graduation committee); Lhermitte, S.L.M. (graduation committee); Delft University of Technology (degree granting institution)","2022","How to deal with the presence of weather affected data is an unavoidable topic in the processing of optical imagery. Clouds and cloud shadows significantly alter the spectral signatures obtained from satellite data, which often leads to problems for any kind of scientific analysis. In this research there has been elaborated on two different kind of problems: The detection of clouds and cloud shadows and the mitigation of the effect caused by cloud shadows. Most of existing operational cloud detection algorithms are so-called rule-based. Their performance is highly variable and they have their limitations. A new promising research was done by Mohajerani and Parvaneh (2019), where a convolutional neural network (CNN) named ’Cloud-Net’ was developed. In this study we have elaborated on this CNN, by converting the analysis to Sentinel-2 data and making significant modifications on the model setup. The results have been compared to the ESA Scene Classification Map (SEN2COR algorithm). It was found that for the detection of clouds the overall CNN accuracy outperforms the ESA Scene Map (95.6% vs. 92.0% respectively). For the detection of cloud shadows the modified Cloud-Net model also gave better results (90.4% vs. 84.4%). Previous work on cloud shadow correction algorithms show rather complex and inconvenient methods, where the only goal was to remove the effect of the shadow. If one is interested to also correct for illumination effects, to make it more aligned to a predetermined ground truth, new possibilities arise which allows for simpler and more direct methods. Two proposed methods have been investigated in this study. The first method, called ’decomposition of components’, investigated the use of a single formula. The affected cloud shadow pixel is corrected based on the RGB difference with a ground truth image, and a single correction factor that was determined based under the assumption that cloud shadows cause a homogeneous alteration effect in a small area. The second method, called the ’CNN based method’, presents a totally new idea by changing the Cloud-Net model to a regression model, in order to correctly alter cloud shadow affected pixels. The performance of both methods was quantified by the structural similarity index measure (SSIM). It was found that the decomposition of components method has the most potential, showing significant improvements on the correction of cloud shadow affected areas.","convolutional neural network; Cloud detection; cloud shadow detection; cloud shadow mitigation","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:1732b9db-6795-4990-ae56-c02fb6d7c81a","http://resolver.tudelft.nl/uuid:1732b9db-6795-4990-ae56-c02fb6d7c81a","Reducing the environmental impact of gloves used in the Intensive Care Unit: Towards greener ICUs","van den Berg, Lisanne (TU Delft Industrial Design Engineering)","Diehl, J.C. (mentor); Albayrak, A. (graduation committee); Hunfeld, N.G.M. (graduation committee); Delft University of Technology (degree granting institution)","2022","Background<br/>The healthcare sector is one of the most polluting sectors in the Netherlands. To limit the environmental impact of the medical sector, Erasmus MC collaborated with Metabolic to conduct a Material Flow Analysis (MFA) and Impact Assessment for the Intensive Care Unit (ICU). The research revealed the hotspots of the ICU, contributing to this polluting sector. Based on the hotspots The Convergence, a cooperation between the Erasmus University, Erasmus MC, and TU Delft have set up the first three design projects. <br/>Project aim<br/>This graduation project aimed to make a start towards greener ICUs. In the ICU care is delivered to critically ill patients. The number of gloves used is high because of the intensity of care and high standards. Due to its resource-intensive production and frequency of use, the use of nitrile disposable gloves was found as a hotspot. The question to be answered was; How could the environmental impact of gloves in the ICU be reduced, while remaining quality of care? Research<br/>Extensive research is done with different focuses; product-centred, human-centred and material centred. Furthermore, the waste from the PICU was analysed for one week. The research revealed the importance of the procurement department and the Unit Infection Prevention. <br/>Design direction<br/>Together with the nursing staff, it was decided to go for the design direction of reducing the number of unused gloves. The scope was set to the current situation in the ICU and the idea should be implementable in the short term. The research resulted in five building blocks for the design that need to be incorporated; (1) infection prevention, (2) zero-risk, (3) ease of use, (4) efficiency and (5) technology. <br/>Ideation<br/>Ideation was done by involving people in creative sessions. Restrictions were excluded in the creative sessions, to come up with a wide range of ideas. Three ideas were chosen based on their short-term implementation possibility and incorporation of the building blocks. The ideas were presented to the Green Team of the ICU and it was decided to go on with an addition of the current box and applying a different way of dispensing gloves. <br/>Prototyping and testing<br/>Prototypes were made to quickly verify the functioning of the ideas. While testing the prototypes, iterations were applied. A user evaluation was performed and resulted in a preference for the vertical dispensing design. <br/>Final design<br/>The final design is GloVe, a vertical dispense system. By incorporating the five building blocks, the design can provide benefits for multiple stakeholders. It reduces the environmental impact of gloves in the ICU by dispensing one glove at a time. Furthermore, the gloves are dispensed at the cuff, which comes in little contact with the patient. The vertical movement is pleasant to the user. The use of colour for different sizes makes it clear to the care assistant which box should go in which holder. Also, nurses will see at a glance, which size gloves they are dispensing. The small V-shaped opening makes the undesirable behaviour, of placing gloves back, almost impossible. <br/>Transformation towards greener ICUs The design thinking approach has yielded a design, insights, and recommendations for subsequent projects. Furthermore, the project has drawn a lot of attention to making healthcare more sustainable. The project has been a necessary start towards more sustainable ICUs.","Personal Protection equipment; Gloves; Sustainability; Healthcare; Medisign","en","master thesis","","","","","","","","","","","","Integrated Product Design | Medisign","",""
"uuid:21c8cdc7-0933-4943-af05-6e87dd3f6278","http://resolver.tudelft.nl/uuid:21c8cdc7-0933-4943-af05-6e87dd3f6278","Propeller Aircraft Design Optimization for Reduced Climate Impact","Thijssen, Roel (TU Delft Aerospace Engineering)","Proesmans, P. (mentor); Vos, Roelof (mentor); Delft University of Technology (degree granting institution)","2022","To reduce the climate impact of the turbofan dominated aviation industry, a conceptual propeller aircraft study has been performed to see the a possible reduction in climate impact between the two. The results analysed showed great promise for the reduction of the climate impact at the cost of block time. Additionally, a loss in productivity or fleet size is observed for the climate impact seen. The change in productivity or fleet size is remedied with an decrease in block time, however this results in an increase in climate impact, especially when compared to the turbofan aircraft. Overall it is safe to say that the climate impact can be reduced by utilising propeller aircraft, however either the productivity or fleet size must be changed. Additionally, the costs per flight potentially go up. All for a more sustainable and greener aviation industry.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:3a2cf648-a7ef-498d-923d-f0b12f90595f","http://resolver.tudelft.nl/uuid:3a2cf648-a7ef-498d-923d-f0b12f90595f","Preliminary design and analysis of fuel systems for box wing aircraft","Piet, Robin (TU Delft Aerospace Engineering)","la Rocca, G. (mentor); Delft University of Technology (degree granting institution)","2022","This work is aimed at quantifying the expected advantages and disadvantages of fuel systems for box-wing aircraft, with respect to fuel systems for conventional aircraft. For this, the Multi Model Generator has been extended with an aircraft type-agnostic fuel system module capable of generating preliminary fuel system geometries, assessing the system weight, and estimating the fuel flow for a mission comprised of a single cruise segment. It is found that the box-wing aircraft struggles to maintain within the flight envelope for ferry and maximum range missions, and that the difference in fuel consumption between fuel system designs is negligible. The most effective fuel system design has a mass of 291.59kg (0.23% of aircraft mass), connects the front and rear wing tanks through the connecting element, and features a forward trim tank with a capacity of 858kg (3.0% of total capacity). With this fuel system, the reference box-wing aircraft is stable for maximum payload missions, and unstable at the start of maximum range missions.","Fuel systems; Box wing","en","master thesis","","","","","","","","","","","","Aerospace Engineering","PARSIFAL",""
"uuid:588dae93-59f1-494a-a5ea-ca52fd292050","http://resolver.tudelft.nl/uuid:588dae93-59f1-494a-a5ea-ca52fd292050","Blind collision detection and classification framework for a heavyweight, low-speed mobile robot colliding with soft and hard objects","Kooi, Emma (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Biomechanical Engineering)","Eisma, Y.B. (mentor); Roelse, L. (mentor); de Winter, J.C.F. (graduation committee); Dodou, D. (graduation committee); Delft University of Technology (degree granting institution)","2022","Abstract— Visual occlusion can cause object detection and classification systems to fail due to swift movement or a soiled, moist or dusty environment. Hence, this asks for a ’blind’ collision detection and classification method. This paper presents a novel blind collision detection and classification scheme for a<br/>heavyweight, low-speed, wheeled mobile robot. By recognizing the target signal pattern in phase current data, the robot can detect whether the wheels are blocked caused by overload (G1). After this, using acceleration and phase current data, the robot will be able to differentiate between a collision against a wall<br/>or a collision with an object between the wall, or no collision of interest (G2). Additionally, an algorithm based on the pitch angle can detect if the robot slides on top of a soft object (G3). Three different algorithms are developed that address these goals. Finally, the developed algorithms are validated in<br/> dynamic and soiled environment (G4). The first two goals are reached by training machine learning classifiers that identify the signal pattern of its target event and place uneventful data in a separate class (open-world classification). During training the classifiers Random Forest, Multi-layered Perceptron, Decision<br/>Tree and Logistic Regression are compared, and the two best perfoming classifiers are subsequently tested for a time-series open-world classification task. The third goal is reached with the development of a heuristic algorithm based on the running mean of the pitch angle.<br/>Experiments were performed in a controlled environment, creating collisions with varying floor conditions, robot weight and collision objects. The best performing algorithm for blind collision overload detection has achieved 98.6% detection accuracy. The object classification algorithm can differentiate<br/>between two types of soft objects, a wall or no event with an accuracy of 93.3%. The algorithm based on the deviating pitch angle can detect events with 100% detection rate and 0% false positive rate. Detailed implementation schemes are provided for real-time implementation, illustrating a robust framework in soiled environments. The proposed solutions can be used to improve collision detection on blind mobile robots, as well as mapping the environment using the object classification model.","Collision detection; Object classification; Mobile robot; Blind sensing; Visual occlusion","en","master thesis","","","","","","","","2024-02-04","","","","Biomedical Engineering","",""
"uuid:0e5acbe1-c55f-4b15-a781-0ac249130e27","http://resolver.tudelft.nl/uuid:0e5acbe1-c55f-4b15-a781-0ac249130e27","Forearm Rotation after Malunited Diaphyseal Fracture: Predicting Range of Motion with a Kinematic Model","van Loon, Derek (TU Delft Mechanical, Maritime and Materials Engineering)","Colaris, Joost (mentor); Veeger, H.E.J. (graduation committee); van Es, Eline (graduation committee); Delft University of Technology (degree granting institution)","2022","Introduction Fractures of the diaphysis of the radius and/or ulna are most common in children from 5 to14 years old and take up to 40% of all pediatric fractures. Patients with a diaphyseal fracture of the forearm can develop a malunion: healing of the bones in non-anatomical position. This can lead to pain, cosmetic differences and a limitation of pronation and/or supination. A malunion with an angulation of at least 15degrees leads to a limitation in rotation of the forearm in 60% of the cases. However, it is not known how amalunion leads to a rotational limitation and why certain patients have a predominant supination limitation and some have a predominant pronation limitation. It is hypothesized that the distance between the bonescan explain the limitation: a too small distance leads to bone impingement and blocking the rotation, a toolarge distance leads to contracture of the central band, a ligament between the radius and ulna.AimThe aim of this research is to explain the loss of rotational function in malunited forearms by using akinematic model in which bone impingement and contracture of the central band can be recognized.MethodFifteen (n=15) patients were included who developed a malunion after a one-sided, both-bonediaphyseal fracture of the forearm during childhood (age &lt; 18) which led to a range of pronation and/orsupination lower than 50 degrees. Their range of motion was measured and CT-scans were made of bothforearms, from which three-dimensional bone surface models were retrieved. A kinematic model for prona-tion and supination of the forearm was developed in which the patient specific anatomy was used to detectbone impingement, measure central band length (CBL) and measure minimal interosseous distance (MID)between the radius and ulna. Bone impingement and CBL were used for prediction of the range of motion ofthe malunited forearms, MID was used to compare the distance between the bones at maximum supinationand pronation between the affected and unaffected forearms of the patients. Central band length relative tothe neutral position was calculated in unaffected forearms to define a threshold for contracture. Bone im-pingement was defined as overlapping of the bone surface models. The root mean squared error (RMSE)between in vivo measured range of pronation, supination and full range and the predicted values is calcu-lated.ResultsAll fifteen patients showed bone impingement as reason for limiting pronation, fourteen patientsshowed contracture of the central band as reason for limiting supination. By setting the threshold at 103%of the relative central band length, the pronation, supination and full range of thirteen patients could bepredicted with a RMSE between 15.5 and 17.9 degrees. Bone distance was significantly lower in malunited forearms than in unaffected forearms in maximum pronation. In supination this effect was much less clear.The kinematic model showed an error less than one millimeter and one degree for translation and rotation compared to cadaveric scans in different pronation and supination positions.Conclusion The kinematic model showed that bone impingement and central band contracture are the best explanations for limiting pronation and supination of malunited forearms. Prediction is difficult because the kinematic model uses the neutral position as starting point, which is not always clear because the kinematics of forearm rotation still has some unknowns and the central band origin and insertion is now located based on a cadaveric study","","en","master thesis","","","","","","","","","","","","Technical Medicine","",""
"uuid:b2bf818d-1cc9-40fb-8515-eef9b8eb348a","http://resolver.tudelft.nl/uuid:b2bf818d-1cc9-40fb-8515-eef9b8eb348a","Driving behavior in mixed traffic in combination with variable speed limit","Wiersma, Jitse (TU Delft Civil Engineering and Geosciences; TU Delft Transport and Planning)","Farah, H. (mentor); Reddy, N. (mentor); Calvert, S.C. (mentor); Papadimitriou, E. (mentor); Delft University of Technology (degree granting institution)","2022","New applications of connectivity between vehicles and the infrastructure are developed. One of these applications is providing upstream information on variable speed limits to connected and automated vehicles. It is expected that the connectivity can contribute to safer roads due to better compliance to the posted speed limits. Those expectations are based on microscopic models with the assumption that human drivers behave similarly in mixed traffic as they do in only human driven vehicles traffic. However, few studies have shown that human drivers tend to change their driving behavior when interacting with automated vehicles in mixed traffic. For this reason, a driving simulator experiment is executed to investigate the effect of the penetration rate of connected and automated vehicles and the distance at which the information is provided on the driving behavior of human drivers. The driving behavior was analyzed in terms of longitudinal and lateral behavior in the context of a three-lane motorway. The penetration rate was found to only impact the speed adaptation when combined with a large distance of upstream information. Lower means speeds, lower section entry speeds and increased speed compliance was observed with an increasing level of penetration rate. For the effect of distance of upstream information, a similar effect was observed. When the distance was increased the mean speed lowered, section entry speed lowered, and speed compliance increased. No change was observed regarding the lateral behavior or Time Headway. As a result, it can be concluded that the cooperation between connected and automated vehicles and variable speed limits on motorways can be used to slow down unconnected vehicles more upstream, without inducing aggressive driving behavior in terms Time Headway and lane changing behavior.","Mixed traffic; Behavioral adaptation; Variable speed limit; Upstream information; Driving simulator","en","master thesis","","","","","","","","","","","","Transport, Infrastructure and Logistics","",""
"uuid:f465b713-33b3-46cf-bcfa-0b939371fc6d","http://resolver.tudelft.nl/uuid:f465b713-33b3-46cf-bcfa-0b939371fc6d","Continuous and Discrete Algorithms for Modelling the Kessler Syndrome","Soliman, Philip (TU Delft Applied Sciences; TU Delft Electrical Engineering, Mathematics and Computer Science)","Visser, P.M. (mentor); Thijssen, J.M. (mentor); Bouwman, W.G. (graduation committee); Budko, N.V. (graduation committee); Delft University of Technology (degree granting institution)","2022","This thesis contains the development of continuous Kepler orbit- and a discrete numerical integration-based collision detection algorithms in a system of LEO satellites, which in combination with collision algorithm form a simplified space debris evolution model. This model is then used to study the Kessler syndrome. The continuous and discrete algorithms get their names from the solutions of the Two Body Problem (TBP) and the methods for collision detection that they are based on; the analytical and continuous time solution of TBP resulting in the Kepler orbits and the numerical, discrete time Velocity Verlet integration of the TBP. The collision model consists of an algorithm for fragmentation collisions largely based on the NASA Standard Breakup Model and a method for elastic, random scattering collisions. Comparison between the continuous and discrete algorithms shows that on average both predict the same time to the first collision in a system of homogeneously distributed satellites. The algorithms differ in their efficiency depending on the number and the radius of the satellites in and the geometry of the system. For relatively small satellite numbers in large systems, the continuous algorithm is computationally more efficient. However, as more satellites or fragments result from previous collision, the continuous algorithm is outperformed by the discrete algorithm. Consequentially, its time complexity appears to be O(N<sup>2</sup>). Armed with this knowledge, the continuous algorithm is used to show that an initially small system of satellites is able to evolve into a large population of debris particles within several decades. Similarly, the discrete algorithm is used to show that an ordered collection of satellites in an homogeneously distributed system of debris-like particles exhibits the effect that a collision early on in the simulation can cause a cascade of collisions at a later stage. Hence Both the discrete and continuous algorithms predict a Kessler Syndrome and mimic predictions made by more advanced models from leading space agencies like NASA’s LEGEND, ESA’s DELTA and JAXA’s LEODEEM [Lio+13].Future research could focus on including atmospheric drag and gravitational perturbations to the continuous algorithm, thereby lengthening the time frame during which it can realistically simulate a system of satellites in LEO. To achieve this, it is suggested that one execute the calculations inherent to the algorithm in parallel on a GPU, as these are independent of each other. ","Collision detection; Kessler Syndrome; Discrete time integration; Kepler orbits; NASA standard breakup model","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics | Applied Physics","",""
"uuid:df22a214-60a6-465d-af1a-49661a0b4be7","http://resolver.tudelft.nl/uuid:df22a214-60a6-465d-af1a-49661a0b4be7","Illumination normalization for Industry 4.0: Specular reflection removal from non-dielectrics","Dijksman, Rick (TU Delft Applied Sciences; TU Delft Support Delft Center for Systems and Control)","Soloviev, O.A. (mentor); Smith, C.S. (graduation committee); Delft University of Technology (degree granting institution)","2022","With the introduction of machine learning algorithms in industry came a new improvement to excising production line. Image recognisance can now be used to detect defects of the product made by these production lines. However these kinds of flaw detection can be fooled by mirror-like specular light effect on these products, which can reduce the reliability of these detection methods. In this thesis two approaches are taken to<br/>minimize these spurious specular light features. Here I look at images of welding spots taken from a car-door production line of Fiat Chrysler Automotive Italy. First a median filter is used on multiple images of welding spots, which each have a different illumination. Secondly the same images were fed into a modified algorithm developed by Antonello et al,2018 , originally used to split fore-and background of videos, to remove these spurious features. Then I tried to improve the output of this algorithm so that oversaturated pixels in the output were replaced by a combination of pixel values of the input images that were not oversaturated.<br/>Here is found that the median filter does not satisfy the desired goal of this thesis. The algorithm however gives a good filtered output of the input images and therefore are suitable to possibly be used for computer vision applications. The improvements made to the output of the algorithm do not correct the oversaturated pixels the right way, however the method I propose here seems to have some promising results if some improvement to this method are made, mainly concerning the normalisation of these pixels.<br","industry 4.0; illumination; non-dielectrics; specular reflection; surface reflection; image pre-processing; quality Inspection","en","bachelor thesis","","","","","","","","","","","","Applied Physics","MADEin4",""
"uuid:66a5fdba-6508-4b6f-b20f-c1766ec4fc7f","http://resolver.tudelft.nl/uuid:66a5fdba-6508-4b6f-b20f-c1766ec4fc7f","Using Explainable Artificial Intelligence to Improve Transparency of Reinforcement Learning for Online Adaptive Flight Control: Breaking Open the Black Box","van Zijl, Job (TU Delft Aerospace Engineering)","van Kampen, E. (mentor); Monteiro Nunes, T.M. (mentor); Delft University of Technology (degree granting institution)","2022","Deep Reinforcement Learning (DRL) shows great potential for flight control, due to its adaptability, fault-tolerance, and as it does not require an accurate system model. However, these techniques, like many machine learning applications, are considered black-box as their inner workings are hidden. This paper aims to break open the black box of RL for adaptive flight control by applying Shapley Additive Explanations (SHAP). The generated explanations are aimed at control experts, but can be useful for anyone interested in RL for adaptive flight control. This research proposes a novel Constant Weight Segment Detection (CWSD) algorithm, facilitating the use of eXplainable Artificial Intelligence techniques to adaptive RL. The algorithm and its usefulness are tested on an Adaptive Critic Design controlling a high-fidelity model of a Cessna Citation aircraft. It is demonstrated that SHAP in combination with CWSD provides detailed and useful insights into the relation between input and output of the RL algorithm. Using SHAP, linear relations between input and output are discovered, simplifying the understanding of the learned strategy.","reinforcement learning (RL); explainable artificial intelligence; SHAP; adaptive control; machine learning; online learning; black box; deep learning","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:960550ce-eb34-4f3d-873a-1f2a6f4763f0","http://resolver.tudelft.nl/uuid:960550ce-eb34-4f3d-873a-1f2a6f4763f0","Vaporizing Liquid Micro-resistojet experimentation","Hutten, Rick (TU Delft Aerospace Engineering)","Zandbergen, B.T.C. (mentor); Delft University of Technology (degree granting institution)","2022","The Delfi program at the Delft University of Technology aims to develop nano satellites between 1 and 10 kg to provide high level education and to develop a platform for novel space technologies. Miniaturized satellites require miniaturized propulsion systems to provide orbital adjustments for functions like station keeping, extending mission duration and precise formation flying. Current research into micro-propulsion systems with aims to improve performance and efficiency is focused on Micro-electromechanical systems (MEMS), solar thermal and Commercial off-the-shelf (COTS) resistojet thrusters. The COTS design and prototype by Versteeg was the first leak resistant micro-thruster produced and successful experiments were performed using hot and cold nitrogen as propellant. The usage of liquid water as propellant for a Vaporizing Liquid Micro-resistojet (VLM) has been suggested as it is easy to store, has a high storage density, decent performance and is relatively safe to use. However as of writing this thesis, experimental tests using liquid water as propellant have been unsuccessful. In this thesis thrust tests with nitrogen have been repeated and show similar results to the data obtained by Versteeg verifying results of both experiments. In order for liquid water tests to be performed in the absence of a liquid mass flow sensor, a syringe pump was used to expel a constant volumetric flow. The liquid mass flow has been calculated by calibrating the syringe pump combined with the measured chamber pressure. Using liquid water, it was found that the chamber pressure increased over the course of the thrust experiment due to the feed system being volume based instead of driven by pressure. Since the test bench is dependent on the center of gravity of the thruster, thermal expansion significantly effects the measured thrust. Using nitrogen this effect can accurately be corrected for, while for water the effect is more difficult to correct due to the unpredictability of the liquid water remaining between the last propellant valve and the thruster chamber. This led to a decrease in accuracy of the measured thrust using liquid water compared to nitrogen, where the error grew from ∼1.5% to ∼13%. Thrust tests with water have been successfully performed at a chamber pressure of 1.02 bar and temperature of 300 °C for 15 minutes producing 8.0-8.3 mN of thrust with a specific impulse of 94-100 seconds with an accuracy of 14%. Several areas of improvement have been listed for both thruster design and experimental setup.","COTS; Resistojet","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:0a010f0d-e3d3-40aa-9650-8f185ef5bfa6","http://resolver.tudelft.nl/uuid:0a010f0d-e3d3-40aa-9650-8f185ef5bfa6","Aircraft engine maintenance planning using model-based remaining useful life prognostics: A Master of Science Thesis","Schiettekatte, Niels (TU Delft Aerospace Engineering)","Mitici, M.A. (mentor); Delft University of Technology (degree granting institution)","2022","Aircraft maintenance methods are shifting from conservative maintenance approaches such as a periodic maintenance approach towards predictive maintenance approaches, leading to a reduction of costs, less unexpected aircraft-on-ground events and less wasted useful life of components. In this paper, we propose a new remaining useful life prognostics approach for aircraft engines and integrate this into a maintenance planning framework. First, an explicit health indicator is constructed from an implicit multi-sensor aircraft engine degradation data set using principal component analysis. Then, the remaining useful life prognostic model is developed using a polynomial chaos expansion approach, which allows for uncertainty quantification in the form of a probability density function which is faster than Monte Carlo simulation. A Markov decision process is used to determine the optimal time of maintenance for aircraft engines. During a case study, these optimal times for individual engines being part of a pool of operational engines are integrated using a linear programming model and a rolling horizon approach to obtain an optimised maintenance schedule. The prognostic model performs in the mid-range compared to other papers using the same data sets. Furthermore, with the current cost parameters the integrated remaining useful life maintenance planning strategy reduces costs by a factor of 3 and 2.5 compared to a periodic maintenance strategy or a run-to-failure maintenance strategy, respectively. The waste is reduced by a factor of 2.5 compared to periodic maintenance, while no failures occur. This research has demonstrated that the polynomial chaos expansion remaining useful life prognostic approach can be used for optimal maintenance planning for aircraft engines using a Markov decision process, showing benefits in terms of costs, waste and unexpected failures.","Remaining useful life prognostics; Polynomial Chaos Expansion; Aircraft Turbofan Engines; Predictive Maintenance","en","master thesis","","","","","","","","2022-02-11","","","","Aerospace Engineering","",""
"uuid:c1c104ed-8b4f-4c52-9df3-9e87bb398a72","http://resolver.tudelft.nl/uuid:c1c104ed-8b4f-4c52-9df3-9e87bb398a72","Tender Price Predictor: Predicting Tender Prices of Dutch Infrastructure Projects with Machine Learning","Schleipfenbauer, Bent (TU Delft Civil Engineering and Geosciences)","Bosch-Rekveldt, M.G.C. (mentor); Delfos, J. (graduation committee); Bakker, H.L.M. (graduation committee); Delft University of Technology (degree granting institution)","2022","The Dutch public procurement market is a multi-billion industry, with a total value of 73 billion euros per year. Competitive tendering is the most popular method of selecting a supplier for the required construction services. The realisation of a tender bid is an expensive and complex process, established on the intersection of various disciplines e.g. safety, constructability, finance, cost estimation and risk management. <br/><br/>Machine Learning has been a popular method in various industries to predict future outcomes and uncover patterns in historical data but remains a rather novel phenomenon in the construction industry. Machine Learning models have been developed in the past to aid tender management, but not with a focus on predicting the contractor’s tender price. <br/><br/>The objective of this research is to develop a Machine Learning tool that is able to predict the tender price of infrastructure projects accurately and is able to assist the contractor’s tender professionals in their decision to tender.<br/><br/>In order to achieve this objective, the following research question was formulated:<br/>How can a Machine Learning algorithm, predicting the tender’s price using tender project data, be developed to support the contractor’s decision to tender?<br/><br/>First, a literature study is conducted to explore the state-of-the-art developments of Machine Learning within construction tender management, discover what the most popular regression algorithms are and what the most important tender features are that influence the tender price. Based on the most important tender features and interviews with tender professionals of a Dutch contractor, an extensive list of 93 tender features is filtered until a final set of tender features remains. Data on these tender features are collected in order to be used as input for the Machine Learning model. <br/><br/>The SVR model performed the best with an R-Squared of 0.846, implying that 84.6% of the variance of the tender’s price could be explained by the model. The SVR model includes an optimised set of features, which is a subset of the initial dataset. The initial estimate is considered to be significantly more important than the other features.<br/><br/>In order to implement the Tender Price Predictor in the organization of a Dutch contractor, attention should be paid to the required effort of the users and to ensuring a high quality of tender data. Requiring too much effort from tender managers entering the input data into the database may result in worse quality of data. Both the users of the model and the managers submitting tender data should be trained accordingly in order to obtain maximum effectiveness.<br/><br/>It should be noted that some important features, according to practice and literature, are omitted from the final dataset. Although the final set of features complies with the requirements of generic features and sufficient occurrences in either literature or the interviews, they were not present in the database of the contractor. These omitted features are: ‘Project team experience’ and ‘Location’","Machine Learning; Tender Price; Construction Industry; Infrastructure projects","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:3af2e6ad-4dc2-4acc-9cbf-a9afc15cebd9","http://resolver.tudelft.nl/uuid:3af2e6ad-4dc2-4acc-9cbf-a9afc15cebd9","Experimental simulation and assessment of the geysers of icy moons in the laboratory","Sklavenitis, Stavros (TU Delft Aerospace Engineering)","Cazaux, S.M. (mentor); Schrijer, F.F.J. (graduation committee); Delft University of Technology (degree granting institution)","2022","The Cassini spacecraft, observing the Saturnian system for over 13 years, discovered aspects of the planetary system that were previously unseen. One such discovery is the eruption of geysers (plumes) from the Tiger Stripes on the surface of the icy moon Enceladus. An unexpected liquid water ocean exists underneath Enceladus’ icy crust (Postberg et al. 2018). A consequence of this finding was the complete revision of the habitability of the Solar System. This liquid ocean is propagated through conduits within the crust, and forms plumes when it reaches the surface. The plume material is believed to accelerate supersonically through nozzle-like channels (Schmidt et al. 2008) before being ejected at high speeds from the plume vents. <br/><br/>This thesis aims to improve the physical understanding of the interaction between the ocean, icy crust, and the plumes of Enceladus, by experimentally simulating such a plume in the wind tunnel laboratories of TU Delft, and monitoring and analyzing the dynamic physical processes taking place across the experimental setup. A physical analog, separated into regions simulating the ocean, crevasse, and vent of the plume mechanism, is monitored with pressure and temperature sensors, while plume particles are detected with optical tracing<br/>techniques. These observations lead to estimations of the vapor mass flow rate, the outflow Mach number, and the fraction of the plume mass that is condensed. It is found that the ocean conditions can be easily controlled through an adjustable heating power supply. The vapor flow generated by the boiling ocean becomes choked in the crevasse and can attain supersonic velocities. The thermodynamic conditions at the vent of the plume exhibit a greatly varying behavior suggesting that the combined effect of the crevasse geometry and the<br/>nucleation of vapor into liquid and icy particles results in considerable diversity in the plume characteristics. Thus, an isentropic description of the plume flow is found to be inadequate, while a Rayleigh flow is found to be feasible. Heat exchange phenomena appear to dominate locally the plume flow, as strong evidence of thermal choking in the crevasse is found. Particles with speeds of up to 426 ± 5 m/s are detected being ejected from the vent of the crevasse, and the maximum fraction of condensed plume mass is found to be 2.94% ± 0.15%. Finally, the possibility of a supersonic plume generated on Enceladus by a crevasse of constant cross-sectional area and cold walls is examined and found to be feasible.","icy moon; Enceladus; plume; Plumes; geyser; cryovolcanism; HTFD; Saturn; Nucleation; condensation; flow dynamics; thermodynamics; phase change; ice; water; crevasse; europa","en","master thesis","","","","","","","","","","","","Aerospace Engineering","","51.9886133,4.3761493"
"uuid:a0bd1c6a-5cca-46ce-bd31-56673dac4024","http://resolver.tudelft.nl/uuid:a0bd1c6a-5cca-46ce-bd31-56673dac4024","Dynamic continuous fiber optical strain sensing for damage diagnosis on beam-like composite structures: An experimental and numerical study","Solbes Ferri, Irene (TU Delft Aerospace Engineering)","Castro, Saullo G.P. (mentor); Groves, R.M. (graduation committee); Knebusch, Johannes (mentor); Delft University of Technology (degree granting institution)","2022","The objective of this master project is to improve the current SHM techniques for global damage identification of beam-like composite structures. The studied damage diagnosis method is based on structural vibrations from which the modal parameters are obtained. The literature study provides an overview of the most common vibration-based damage identification methods. The modal curvature shape- and modal strain energy-based methods are selected due to their higher sensitivity to local damages. These methods are applied on an aero-elastically tailored composite wing. High-spatial-resolution modal shapes are extracted from the structure with a state-of-the-art fibre optic strain sensing technology based on Rayleigh back-scattering. Damages are simulated in the wing employing localized mass attachments. The achievable level of damage identification with this technique is found and characterized. The different vibration-based methods are compared and their potential is discussed. It is concluded that the used sensing technique is an excellent choice for global damage diagnosis in composite structures.","Dynamics; fibre optic sensors; Experimental modal analysis; Structural Health Monitoring (SHM); Damage Identification; Composite structures; beam-like structures; Strain sensor","en","master thesis","","","","","","The present master thesis was a collaboration between the Aerospace engineering faculty of TU Delft and the Aeroelasticity Institute of DLR (Göttingen).","","","","","","Aerospace Engineering | Structures and Materials","","51.5271927, 9.9314321"
"uuid:20e2041c-4c70-41fc-879d-d7f22fa6cf62","http://resolver.tudelft.nl/uuid:20e2041c-4c70-41fc-879d-d7f22fa6cf62","Characterizing the architecture of reconstituted minimal septin and septin-actin cortices at high resolution","de Ridder, Djim (TU Delft Applied Sciences)","Koenderink, G.H. (mentor); Castro Linares, G. (mentor); Baldauf, L. (mentor); Idema, T. (graduation committee); Jakobi, A. (graduation committee); Delft University of Technology (degree granting institution)","2022","In animal cells, cell shape is primarily regulated by the actin cortex, a thin filament network connected to the plasma membrane. The architecture of the cortex is considered a key regulator of its function. Visualising the cortex is difficult due to the high density of numerous small-sized proteins involved in its formation. Consequently, the structure of the cortex at the membrane remains poorly studied. This study aims to gain insight into the organisation at the membrane of two key cortical components, human septin and septin-recruited actin. To study these filament structures, we reconstitute minimal cortices on supported lipid layers as model-membranes, allowing for imaging with electron and atomic force microscopy. We show that membrane binding of human septin results in ordered organisations of filaments. However, we find septin organises into arrays of paired filaments when incubated on a lipid monolayer and networks of bundles when incubated on a lipid bilayer. In addition, we showed a proof of concept for actin cortex reconstitution on lipid monolayers, which allowed us to see actin recruitment by septin meshworks.","Cytoskeleton; High-resolution; Septin; Actin; Lipid membrane","en","master thesis","","","","","","","","","","","","Applied Sciences | Nanobiology","",""
"uuid:a1a66d83-1283-47d5-a7aa-21292817a356","http://resolver.tudelft.nl/uuid:a1a66d83-1283-47d5-a7aa-21292817a356","Reliability and validity of IMU-based foot progression angle measurement under different gait retraining strategies","Urbanus, Francine (TU Delft Mechanical, Maritime and Materials Engineering)","Harlaar, J. (mentor); van der Kruk, E. (mentor); Delft University of Technology (degree granting institution)","2022","Background <br/>Gait retraining strategies are used to reduce medial compartment load in people with medial knee osteoarthritis. Two key gait retraining strategies are based on changing the foot progression angle (FPA). The FPA can be measured using a pressure sensitive walkways (PSW), but inertial measurement units (IMUs) are considered more suitable for routine clinical use.<br/>Research question <br/>The purpose of this study was to evaluate the reliability and validity of an IMU system to measure FPA under different gait retraining strategies in a potential clinical setting.<br/>Methods <br/>Twenty healthy participants (14 females, 6 males, mean age=33.7 years, SD=10.3 years) walked along a ± 8.5 m long path using different gait strategies (2x natural gait, 1x toe-out -and 1x toe-in gait) during four 90 second trials. FPA was measured simultaneously with the IMUs (Opal, APDM, Portland, USA) and a PSW (Zeno™ Walkway, ProtoKinetics, Havertown, USA), the latter considered the reference standard.<br/>Results <br/>Test-retest intraclass correlations (ICCs) for the IMUs and the PSW were indicative of good and excellent reliability respectively (IMU ICC=0.89; PSW ICC=0.97). This difference in reliability was also reflected by a higher standard error of measurement (SEM) for IMUs compared to the PSW (IMUs SEM=1.6°, PSW SEM=0.96°). Minimal detectable change (MDC) was 4.5° for the IMUs and 2.7° for the PSW. The repeated measures ANOVA indicated a significant effect of gait type on FPA (p&lt;.001), whereas the measurement instrument did not affect FPA (p=.875). Bland-Altman plots indicate good agreement of both systems for the baseline condition, though the IMUs seem to consistently overestimate the FPA value compared to the PSW. We conclude that IMUs are reliable and valid measurement systems for measuring FPA in natural gait, toe-out and toe-in gait. Differences between the systems are significant for all gait strategies, so systems should not be used interchangeably.<br/>Significance <br/>The IMUs provide a promising tool for clinicians and researchers aiming to quantify FPA for gait retraining.<br","","en","master thesis","","","","","","","","","","","","Biomedical Engineering | Bioelectronics","",""
"uuid:d8c67609-8b29-4e1f-a9ba-80cf218055a8","http://resolver.tudelft.nl/uuid:d8c67609-8b29-4e1f-a9ba-80cf218055a8","Validating a novel set of driving scenarios and measures for assessing driving skill and style: A high-fidelity driving simulator study","Verschoor, Koen (TU Delft Mechanical, Maritime and Materials Engineering)","de Winter, J.C.F. (mentor); Doubek, Fabian (graduation committee); Happee, R. (graduation committee); Dodou, D. (graduation committee); Delft University of Technology (degree granting institution)","2022","Although the capabilities of automated driving systems (ADS) are growing, the human operator remains in charge of driving the vehicle outside the operational design domain and after requests to intervene. The vehicle sensors required for ADS and new regulation for driver availability monitoring systems stimulate the development of systems that can monitor human driving ability. Such systems could allow for ADS to track possible driving skill degradation, monitor driver impairment, or adapt to the driver’s needs. However, knowledge is required about how to assess human driving ability effectively. This work proposes a novel method to capture driving skill and style based on curve driving, straight-road driving, and driving through road narrowings. In addition to conventional measures, the study introduces new measures, including the relationship between steering angle and eye movements. Employing a high-fidelity simulator, we compared the vehicle-control-related measures (i.e., driving skill measures), trajectory-planning and speed-related measures (i.e., driving style measures), and eye movements of sixteen inexperienced and thirteen experienced drivers. It was examined which of these measures are valid, i.e., allow a statistical discrimination between experienced and inexperienced drivers. The study was complemented with two expert drivers serving as a benchmark. The results showed that the experienced drivers adopted a more abrupt braking style when approaching curves and a higher speed through the different track sections than the inexperienced drivers. No statistically significant differences were observed between the skill measures of the experienced and inexperienced drivers. An analysis of lead times obtained through a cross-correlation between horizontal gaze angle and steering angle showed that eye movements generally preceded steering movements. However, differences in lead times between experienced and inexperienced drivers were not statistically significant, which may have been caused by eye-tracking measurement inaccuracies, the layout of the driving task and strong intra-individual variability in looking behavior. The eye-tracking results of the road-narrowings showed that the experienced and inexperienced drivers reduced their vertical gaze dispersion, while only the experienced drivers statistically significantly reduced their horizontal gaze dispersion compared to the straights. In other words, the experienced drivers showed increased horizontal gaze tunneling from the straights to the narrowings, while the inexperienced drivers only showed vertical gaze tunneling. The results of the expert drivers showed consistent higher speed, lower control activity, and more of a racing line through the curves than the experienced and inexperienced drivers. Furthermore, the results showed that the expert drivers adopted a more variable horizontal gaze strategy between different curves. Overall, these results indicate that driving style and eye-movement measures, but not driving skill measures, allow differentiating between experienced and inexperienced drivers using a driving simulator. These findings may be explained by the fact that driving is a self-paced task, i.e., more competent drivers increase their own task demands by driving faster. Future research could examine how strongly scores the present driving and eye-movement measures correlate with drivers’ take-over quality in automated driving scenarios.","Driving skill; Driving style; Simulator; Driving Behaviour; Driving performance; Expert drivers; Driving ability; road narrowings; Trajectory planning; vehicle-control","en","master thesis","","","","","","","","2024-02-09","","","","","",""
"uuid:4b6e7c54-d221-4388-83eb-dba43e33a9de","http://resolver.tudelft.nl/uuid:4b6e7c54-d221-4388-83eb-dba43e33a9de","Assessing the Important Factors for Obtaining Technological Dominance in the Concrete Armour Unit Industry","Batenburg, Leonard (TU Delft Civil Engineering & Geosciences)","van de Kaa, G. (mentor); Dolkens, T.L. (mentor); Schraven, D.F.J. (mentor); Reedijk, Bas (graduation committee); Bakker, Pieter (graduation committee); Delft University of Technology (degree granting institution)","2022","The concrete armour unit industry exist for more than 70 years, in this period various units were developed. The first units derived their hydraulic stability on their own weight, later the units got more complex shapes and got interlocking capabilities. The first interlocking units were placed in a two-layer configuration, like Tetrapod and Dolos. Later the industry shifted to a one-layer design where concrete use became less since fewer units were needed. The industry standard of one-layer gave rise to various new armour units, like Core-Loc and Xbloc. <br/><br/>Up to the present, this industry is mainly studied from a technological perspective where the hydraulic capabilities and design formulae are extensively researched (so called 'hard factors'). However, some units became very commercially successful in terms of units placed but others did not. In this highly technological industry, no market research is done in order to study which factors led to commercial success.<br/><br/>In this study, an effort is made to investigate which factors are responsible for becoming successful in this branch. To do so, the concept of technological dominance is linked to this industry. Technological dominance is a technology management concept wherein a market similar technologies are ‘battling’ for the allegiance of the market. Eventually, the market selects a particular design and becomes dominant. <br/><br/>Over the years scholars identified factors that contribute to obtaining technological dominance and collected those in a framework. In this study, the framework by Van de Kaa et al. (2011) is chosen. This framework consists of 29 factors that influence the outcome of a technology battle.<br/><br/>The methodological approach for this study is to select relevant factors regarding this industry by interviewing 4 key experts. The identified relevant factors are then carried into the next round of interviews, where a broader group of 14 experts were asked to rank these factors according to the Best Worst Method. <br/><br/>The Best Worst Method (BWM) is a multi-criteria decision-making tool, designed by Rezaei (2015), where the decision-maker expresses their preference by making pairwise comparisons. This method gives more reliable weights and requires fewer pairwise comparisons in respect to other multi-criteria decision-making tools, like AHP.<br/><br/>The results yielded by this method suggest that the factor ‘brand reputation and credibility' are among experts considered as the most important factor for technological dominance regarding this industry. Furthermore, ‘hydraulic stability’ is in this branch considered second most important for obtaining technological dominance. Also, factors like 'marketing communications' and having a large network of stakeholders are considered very important. Based on the results, there can be concluded that in this technological branch soft factors can be more important than hard factors. <br/><br/>This implies that in order to be successful in this industry actors should focus more on building a reliable and well-known brand reputation. In this branch, actors have proved that a strong brand name can help to extend the commercial lifespan of an armour unit with expired patent and can help to speed up the adoption of new armour units.<br","BWM; technological dominance; concrete armour units; Best Worst Method; dominant design","en","master thesis","","","","","","","","2023-02-09","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:3d12337d-ac8f-43bc-be4e-c74c8cb819ae","http://resolver.tudelft.nl/uuid:3d12337d-ac8f-43bc-be4e-c74c8cb819ae","Coopi: a custom fitted chair for the modern home workspace combining manual processes with robotic 3D printing","van den Dikkenberg, Lean (TU Delft Industrial Design Engineering)","Tempelman, E. (mentor); Noordhoek, E.J.L. (graduation committee); Delft University of Technology (degree granting institution)","2022","Chances are that you, the reader, have been working from home during this pandemic. Working from home has been more common than ever before and is predicted to stay. However, chairs have not adapted yet: office chairs are complicated and bulky products. They are designed to be adjustable to multiple users, but are not the best solution for working in a nicely styled living room. This design project aims to develop a stylish chair that fits the home working environment while offering a personal, comfortable fit.<br/><br/>This design process is driven by the opportunities and limitations of digital manufacturing. The benefits of 3D printing seem promising, but can be time consuming and costly. This project focuses on realistically applying the manufacturing techniques for this scenario and for the start-up client. During an extensive ideation process, it was explored how to manufacture the seat by printing, how to add comfort, how to make it sturdy, stylish, and most importantly: how to do this in a manner that can be adjusted to the dimensions of the user.<br/><br/>This resulted in Coopi, a chair design that combines the strengths of robotic 3D printing with the benefits of a manual upholstery process. This, to avoid long and expensive printing times. Coopi is designed to showcase a bold, open and trendy character that fits in modern home workspaces while visually communicating the combination of manufacturing processes.<br","Customization; Furniture design; Additive Manufacturing; Robotic 3D printing; digital manufacturing","en","master thesis","","","","","","","","2023-02-09","","","","Integrated Product Design","",""
"uuid:1bfe8c73-30f9-4a83-93c6-07bd0521a25c","http://resolver.tudelft.nl/uuid:1bfe8c73-30f9-4a83-93c6-07bd0521a25c","Engaging the Crowd in Sensing for Smart Mobility: A Discrete Choice Experiment Investigating Users' Preferences in Participatory Sensing Applications","van den Boogert, Mirjam (TU Delft Technology, Policy and Management)","Chorus, C.G. (graduation committee); Ding, Aaron Yi (graduation committee); Szép, T. (graduation committee); Kherrazi, R. (graduation committee); Delft University of Technology (degree granting institution)","2022","In 2050, it is expected that 70% of the world’s population will live in cities (Jin et al., 2014), leading to increasing congestion in and surrounding cities. This will raise new challenges, requiring more efficient and interactive cities. A novel paradigm contributing to these so-called smart cities is participatory sensing. Also known as mobile crowdsourcing, this solution enables both public and professional users to actively gather, analyse, and share local data about the urban environment using built-in sensors in smart devices (Truong et al., 2019). Considering that over 94% of the population has access to a mobile network, obtaining real-time data from these already existing sensors can be a low-cost solution for acquiring a huge amount of information (International Telecommunication Union, 2016). These real-time data can be used to analyse and predict mobility flows, and make public and private transport more efficient, safe, and sustainable.<br/><br/>However, a clear benefit is required to motivate smart device users to share data about their activities and their environment. Sharing data comes with the risk of disclosing private information, as location data can lead to the identification of living and work locations, as well as individual habits. Research on motivations of <br/>smart device users to engage in participatory sensing tasks is required in order to be able to design valuesensitive participatory sensing applications. This study aims to identify factors related to incentives and privacy that explain choice behaviour of users in participatory sensing applications. The main research <br/>question being addressed is as follows: “<i>How do factors relating to incentives and privacy affect the willingness among smart device users to contribute to participatory sensing systems for smart mobility?</i>”<br/><br/>A choice modelling approach was taken in order to identify the trade-offs made by users between potential benefits and costs of sharing data. This is an approach not often used before in the field of participatory sensing and provides novel insights in user behaviour in these systems. First, a literature review was <br/>conducted identifying possible factors relating to incentives and privacy, influencing the willingness of people to share data. Five factors were selected: <i>monetary reward</i>, <i>effort</i>, <i>risk of re-identification</i>, <i>types of data</i>, and <br/><i>data use</i>. These factors were incorporated in a stated choice experiment distributed among smart device users through an online survey. In total, 125 valid responses were collected. The required effort of participating was regarded the most important factor influencing the willingness to share data in sensing <br/>applications for smart mobility. This provides new insights, as previous studies do not include effort in choice experiments regarding data sharing. As expected, the perceived ease of use declines if more inputs by the user are required. Moreover, respondents are reluctant to the collection of contextual and multimedia in <br/>addition to location and motion data, a finding which is confirmed by recent studies. Almost half of the respondents indicated to be highly concerned about their privacy. Therefore, a surprising finding is that the risk of re-identification was regarded the least important factor influencing the willingness to share data. <br/>However, when taking a deeper look at the data, it appears there is a group of people having extreme preferences regarding privacy and trust, who assign a higher importance to privacy related factors (risk of re-identification, types of data, data use). <br/><br/>The identified trade-offs were used to evaluate the implications for different use cases in the field of smart mobility. Three interviews were conducted, which each led to the definition of a use case, being crowd management in a city, safety research using car accident information, and real-time travel information in <br/>public transport. By aggregating the quantitative and qualitative parts of the research, it can be concluded that the accuracy of collected information can be improved by collecting more types of data in addition to location data. However, this will lead to a decline in the acceptance rate. A proposed solution is to provide <br/>tailor-made sensing applications, giving the user control to indicate which data they agree to share. <br/><br/>Furthermore, the communication of the purpose of the data collection is important to users. Moreover, being transparent about the risks related to the data collection can help users to make a well-informed decision and <br/>will ensure an ethical design of sensing applications. Finally, increasing the attractiveness of the application is recommended to reduce the perceived effort, which could be done by gamification of sensing tasks. <br/><br/>Besides societal implications, this study provides several recommendations for future research. First, it is recommended to repeat the experiment without the provision of a financial compensation, in order to see if this leads to different choice behaviour and preferences of users. Furthermore, research on the understanding of privacy risks among users is recommended. Finally, this study can be used outside the smart mobility field, in order to analyse the willingness to share data in a broader sense.<br","Participatory sensing; Choice modelling; Data sharing; Privacy calculus; Smart mobility","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:c652c12a-b47e-4580-8385-014a2bade03d","http://resolver.tudelft.nl/uuid:c652c12a-b47e-4580-8385-014a2bade03d","A Method for the Hooking of Floating Monopiles","van Gelder, Hidde (TU Delft Mechanical, Maritime and Materials Engineering)","Wellens, P.R. (mentor); Boon, A.D. (graduation committee); de Vos, P. (mentor); Delft University of Technology (degree granting institution)","2022","To facilitate the installation of larger monopiles multiple players in the offshore wind market are investigating the floating transport of monopiles to installation locations. This brings the challenge that when these floating monopiles are to be installed by heavy lift vessels, they must safely be handed over to the installation vessel and hooked onto the main crane of the installation vessel for installation. Current literature mainly focusses on two topics. Some studies exist on the behaviour of a floating monopile near a heavy lift vessel. Studies also exist that study the behaviour of a monopile hanging on the crane of a heavy lift vessel. The step between these two moments in time, where the floating monopile is handed over from the tug towing the monopile to installation vessel, is the focus of this study. This thesis presents a method for the hooking of a floating monopile to the crane of heavy lift vessel Oleg Strashnov and a model for the hooking operation. This model is used to determine a maximum allowable sea state for this operation. Two methods for hooking a floating monopile to the crane of a heavy lift vessel were defined. In the first option, the monopile would be moored alongside the vessel and kept in position by a supporting tug while the rigging is handed over to the heavy lift vessel and the rigging can be hooked onto the vessel crane. The second option entails positioning the monopile perpendicular to the heavy lift vessel, with fenders placed between the monopile and vessel...","","en","master thesis","","","","","","","","","","","","","",""
"uuid:0da88bb4-40f2-47f6-9793-4fe81a34f9b9","http://resolver.tudelft.nl/uuid:0da88bb4-40f2-47f6-9793-4fe81a34f9b9","A comparison of wave spectra reconstruction methods","ZHANG, XINYI (TU Delft Civil Engineering and Geosciences)","Tissier, M.F.S. (mentor); Rutten, J. (graduation committee); Matsuba, Y. (graduation committee); Delft University of Technology (degree granting institution)","2022","Infragravity (IG) waves are long waves whose frequency ranges between 0.005 Hz to 0.04 Hz. The directional properties of IG waves are essential in various engineering fields, but few spectra reconstruction methods have been tested to be robust for the last forty years. In this study, artificial wave signals were created to check the accuracy and reliability of several wave spectra reconstruction methods. These data were designed as if produced from the REFLEX field measurements. Three commonly used conventional directional wave spectra reconstruction methods, EMEP, IMLM and BDM, are applied and compared over Sea-swell (SS) wave field and IG+SS wave field. <br/><br/>Though the existence of bound IG waves weakens the accuracy and reliability of these methods, they may be used to reconstruct the IG wave spectra with reasonable results. It is found that the EMEP outperforms the BDM and the IMLM since it yields accurate results with low sensitivity to noise in most cases. The BDM is reliable in moderate wave conditions, but would fail in case of high wave height or narrow directional spreading. The IMLM tends to produce less accurate results than the EMEP. The EMEP is recommended because of its overall reliability and low sensitivity.<br","Infragravity waves; Directional wave spectra; Wave spectra reconstruction method","en","student report","","","","","","","","","","","","Civil Engineering","",""
"uuid:2647fa9c-7cb0-4f43-80a5-555540e65734","http://resolver.tudelft.nl/uuid:2647fa9c-7cb0-4f43-80a5-555540e65734","Effects of variable cycle lengths on Transit Signal Priority operations","Donaldson, Narayan (TU Delft Civil Engineering and Geosciences)","Salomons, A.M. (mentor); Knoop, V.L. (graduation committee); Fick, Marcel (mentor); van Oort, N. (graduation committee); Delft University of Technology (degree granting institution)","2022","class=""MsoNormal"">Traffic signals in a coordinated network normally use a common cycle length which remains constant at all times, including when there is a request for priority from a public transport vehicle. This enables green waves to be maintained effectively but can limit the signals' ability to promptly serve the prioritised vehicle.<br/><br/>To study the effects of momentarily relaxing the constraint of cycle length during Transit Signal Priority (TSP) interventions, a new TSP system is developed for a CRSV halfstarre traffic signal controller, which permits a flexible cycle length during priority interventions. That system is tested using a Vissim microsimulation of a simple fictional network, and compared to the existing fixed-cycle-length TSP system included with the controller.<br/><br/>The new TSP system permits TSP actions as long as it is expected that the signal can return to its normal ""in sync"" timings within two cycles. During the intervention, the positive and negative impacts on each signal phase are monitored, and ""Offset Correction Credits"" are distributed, which each represent one second of additional green time. Signal phases which received extra time during the TSP intervention will receive negative OC Credits, and phases which were truncated will receive positive OC Credits. Once the intervention is complete, the signal will execute ""offset correction"" to return the signal to its normal ""In Sync"" timings while redeeming OC Credits.<br/><br/>The subject road network consists of fictional road with three coordinated traffic<br/>signals, spaced 150 metres and 400 metres apart. The central intersection is the capacity-critical intersection and also includes a frequent bus line (12 buses per hour per direction) travelling along a median busway perpendicular to the coordinated direction.<br/><br/>In the scenario with a high flexibility to reduce green durations, the average delay for late buses dropped by 59% from 10.7 secondsto 4.4 seconds for the flexible-cycle system compared to the fixed-cycle system. With low flexibility, the average delay for late buses dropped by 78% from 28.0 seconds to 6.2 seconds. The large improvements in performance for buses are due to the flexible-cycle TSP systems being able to execute more TSP actions such as phase insertions which may not fit within a fixed cycle length.<br/><br/>However, the controller’s ability to remain in sync was negatively impacted and the frequency of queues exceeding storage increased by as much as 70% on short roadway links. However on long roadway links, delaysand queue lengths decreased in the coordinated directions thanks to the new TSP system’s green time compensation mechanism.<br/></p><p class=""MsoNormal"">When the assumed occupancy rate for late buses is 50 passengers (corresponding to a busy but not overcrowded standard bus), there was no significant difference in person-delay between any of the scenarios. Early buses were not included in the calculation for average person-delay.","Traffic Signal Control; Traffic control; Public Transport; Prioritisation","en","master thesis","","","","","","","","","","","","Civil Engineering | Transport and Planning","",""
"uuid:8a15ebd2-5668-48f1-9cb5-d681b6b37fad","http://resolver.tudelft.nl/uuid:8a15ebd2-5668-48f1-9cb5-d681b6b37fad","Characterization and Mitigation of High-Confidence Errors Through the Use of Human-In-The-Loop Methods: Domain Expert Driven Approach to Model Development","Hoogland, Pavel (TU Delft Electrical Engineering, Mathematics and Computer Science)","Yang, J. (mentor); Inel, O. (mentor); Schuur, Margje (mentor); van Vliet, Jasper (mentor); Houben, G.J.P.M. (graduation committee); Chen, Lydia Y. (graduation committee); Delft University of Technology (degree granting institution)","2022","In the use of Machine Learning systems, attaining the trust of those that are the end-users can often be difficult. Many of the current state-of-the-art systems operate as Black-Boxes. Errors produced by these Black-Box systems, without further explanation as to why these decisions were made, will deteriorate trust. This effect is especially strong when these erroneous decisions are generated with high confidence. This thesis presents both a data-driven as well as a human-in-the-Loop based methodology to characterize and mitigate high-confidence errors. We propose an Iterative Expert Session based methodology. By engaging domain experts through a series of interaction sessions, we aim to reduce the disconnect and knowledge gap between data scientists and domain experts, and to ultimately increase trust in the model. A practical approach was taken working in close connection with the practice of the data scientists of the ILT, helping them in improving their model and providing a direct contribution. We study the problem in the context of Road and Transportation law violations, by engaging inspectors (i.e., domain experts) in day-in-the-life and in-house interview sessions.<br/>A thorough analysis is performed of the most important features for data instances that were in error with a high degree of confidence. A method is presented that helps in characterizing these errors by predicting errors.<br/>We show that by careful removal of biased data features, proper data selection and by bridging the knowledge gap between domain experts and data scientists, we can improve the performance of the machine learning model. We show an increase of model Precision from 0.56800 with a baseline of 0.32968 to a Precision of 0.52077 with a baseline of 0.23473. Considering the baseline, this is an increase of 28.9% in Precision. We reduce biases existent in the data by reducing variables that predict on inspector practice. The magnitude of High Confidence Errors in the top 20% errors went from 0.70435 to 0.70465 showing an improvement taking into account the reduced baseline and removal of overfitted variables.","Machine Learning; Human-Centered Computing; High Confidence Errors; Interpretability; End-User Trust","en","master thesis","","","","","","","","","","","","Computer Science | Data Science and Technology","",""
"uuid:baa29072-781f-45ce-ae10-10ae5a4718e3","http://resolver.tudelft.nl/uuid:baa29072-781f-45ce-ae10-10ae5a4718e3","Improved production value through organised DFMA: allowing for one big manufacturing step less through redesigning a recreational vehicle fridge","Nederend, Johan (TU Delft Industrial Design Engineering)","Tempelman, E. (mentor); Kuipers, H. (graduation committee); Delft University of Technology (degree granting institution)","2022","Thetford needs to improve their efficiency to generate more output, make space on their full factory floor for new products and decrease their human dependency at their absorption refrigerator plant in Etten-Leur. The market becomes more competitive and that is why Thetford choose to change its strategy from customer intimacy towards product leadership. This strategy is focused on generating new revolutionary products like iNDUS. The existing product portfolio does not alter much though while the output increased the past year and is not going to decline the coming years while new products are introduced. So how is Thetford going to generate more output with less people on reduced floor space?<br/><br/>In 2018 a feasibility study was done to explore the possibility of eliminating one big manufacturing step. The project was called ‘one-step foaming’ because the manufacturing route was designed to contain two foaming steps for isolating the fridge and could be shortened to just one foaming step. One-step foaming could fulfill the strategic needs of Thetford because of the necessary changes in the manufacturing route and design: one big foaming machine less and less assembly steps. The study was successful, but the design was not feasible for mass-production yet. A next step should be taken to further improve the manufacturing route and design.<br/><br/>This project tended to improve one-step foaming up to a level that would increase the output by at least 20% while reducing the necessary floor space by at least 20%. The method chosen to achieve this was by applying a DFMA study on both the present product and a product of a competitor. The lessons learnt would generate a design where the value of the work of production workers would be highest. Meaning: no use of materials or handling that would not add any value to the external customer. The customer is not going to pay more for this internal manufacturing change and that is why the project should result in a cost neutral business case while also generating the same customer experience.<br/><br/>The result is one concept, chosen from 3, that has an output increase of probably 57% with the same amount of workers, floor space reduction of 42% and cost price reduction compared to the new expected encasement of €11,83 with an investment of €250.000. These numbers are calculated only for the implementation of one-step foaming on the 140L fridge line (the beaker or N4140) and not the tabletop or the larger fridges. The assumption made is that new encasement regulation will be introduced resulting in a big change Thetford. The encasement regulation means that Thetford needs to change their cheap and light-weight cardboard encasement with heavy sheet metal encasement. When one-step foaming will be introduced on the 140L fridge line it will allow for usage of the automatic line 2nd step machine to foam other fridges as well. <br/><br/>The next step after this project is to validate the concepts by making a prototype. The project shows a high potential for Thetford to remain competitive on both the present and new product portfolio while not needing to move to another plant. Validation makes the promises of one-step foaming more realistic. Another important lesson for Thetford from this project is to rethink their level op operational excellence. In the past efficient production and high output were not important but they are now. Thetford is already started improving by implementing automation but it could do more in the sense of DFA and active automation. There is still high potential improvement to increase the level of operational excellence for Thetford and one-step foaming shows this.<br","manufacturing; refrigeration; Design for Assembly; Design for Manufacturing; lean manufacturing","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:1a37cb0d-b841-4bce-bc55-71746422f3d0","http://resolver.tudelft.nl/uuid:1a37cb0d-b841-4bce-bc55-71746422f3d0","Applications of geophysical measuring methods for the exploration and securing of old mine workings near the surface using the example of the former lignite mine “Robertshall”","Weinbach, Hannah (TU Delft Civil Engineering and Geosciences)","Preuße, Axel (mentor); Buxton, M.W.N. (graduation committee); Leveinen, Jussi (graduation committee); Delft University of Technology (degree granting institution); RWTH Aachen University (degree granting institution); Aalto University (degree granting institution)","2022","In the former lignite mine ""Robertshall"" near Hamburg damage to the surface was caused by the collapse of underground cavities originating from old mine workings of a lignite mine which had been in operation between 1920 and 1922. During the investigation of the subsurface by drilling it was noticed that the existing mine plans are incomplete.<br/>If mine plans are missing or incomplete, the risk to protected assets at the surface due to mining damage can often only be reliably assessed by means of indirect methods such as geophysics in reasonable combination with drilling. Within the scope of this work the extend of room-and-pillar caving at the “Robertshall” deep lignite mine was determined by geophysical methods. Subsequent backfilling and securing of the old mine workings are the goals of this exploration.<br/>The simultaneous application of several methods on the selected test profile is not only intended to increase the reliability of the results, but also to gain experience as to which methods are best suited for routine detection under the given geological and mining conditions. The geophysical measurements are supplemented by an evaluation of historical data.<br/>The results of geophysics have led to the prompt and reliable discovery of many drifts that were not included in the mine plan. Compared to the conventional approach of exploration by drilling, the application of seismic measurements saves time and costs.<br/>The securing measures could be carried out by the responsible parties and the desired securing success has been achieved so that no further movements of the ground surface are to be expected.<br","mining damage; geophysics; seismic; old mine workings","en","master thesis","","","","","","","","","","","","Applied Earth Sciences | European Mining Course","EMMEP",""
"uuid:472173f7-e452-4542-a626-b2305cf99124","http://resolver.tudelft.nl/uuid:472173f7-e452-4542-a626-b2305cf99124","Verdeling en verdeeldheid in het afvalwatertransportsysteem: Een analyse over de kostenverdeling tussen waterschappen en gemeenten","Geurts, Rebecca (TU Delft Civil Engineering and Geosciences)","Ertsen, M.W. (mentor); Hoes, O.A.C. (graduation committee); Scholten, L. (graduation committee); Delft University of Technology (degree granting institution)","2022","In 1972 the Union of Waterboards and the Association of Dutch Municipalities drew up a directive to give waterboards and municipalities a guideline in how to divide tasks and costs in the new situations that were the result of the Pollution of Surface Waters Act, decreed in 1970. At 7 waterboards costs are still settled with (a part of) the municipalities based on the method proposed in the directive. Most waterboards have therefore already abandoned this cost distribution. With the use of several focus points an overview has been created through interviews and document analysis on the current use of the cost distribution based on the directive. Various aspects emerged from the interviews and documents that may play a role in the application of the cost distribution based on the 1972 Directive. In the end, 9 subjects were mentioned or discussed more often that could have a direct or indirect influence on the fact why the cost distribution is (still) applied. These subjects appear to influence whether or not a cost distribution is used on the basis of the 1972 Directive. It could be a correlation of various factors per waterboard, but it could also be a coincidence. All in all, it is clear that the cost distribution based on the 1972 Directive is being applied less and less. The distribution method is also not being reintroduced by water boards and municipalities.","","nl","master thesis","","","","","","","","","","","","Water Management","",""
"uuid:17f8718a-313c-4f00-a66c-8663ee5b1e45","http://resolver.tudelft.nl/uuid:17f8718a-313c-4f00-a66c-8663ee5b1e45","Back to the Future: Projecting Dutch Daily Day-ahead Market Price Series Under 2050 Energy Scenarios","Gao, Zhi (TU Delft Electrical Engineering, Mathematics and Computer Science)","van der Heijden, T.J.T. (mentor); Abraham, E. (graduation committee); Palensky, P. (graduation committee); Delft University of Technology (degree granting institution)","2022","Under the increasing electrification of end uses in the energy transition towards more renewable integration, the electricity price keeps gaining importance on every scale from individual well-being to the competitiveness of an economy. Though scarce in the scientific literature, Long-Term Electricity Price Projection (LEPP) has great potentials in decision-making and planning, as well as complementing the long-term energy scenarios. This study takes features from the Dutch, Spanish and Danish data in five years (2015-2019) to train deep neural networks in the conditional Wasserstein Generative Adversarial Nets with Gradient Penalty (cWGAN-GP) framework, in order to project Day-Ahead Market (DAM) price series under Dutch 2050 energy scenarios. <br/><br/>The LEPP to 2050 is made possible by normalising the selected markets. As a result, the conditions unprecedented in Dutch data are covered in the normalised and combined data set. Generally, under scenarios with high proportions of hydrogen power in the energy portfolio, the cWGAN-GP model projects that DAM price series would have slightly lower mean and daily standard deviation than the 2019 level. Whereas much lower mean and daily standard deviation are projected when natural gas is still the fuel of the most frequent final generating technology. To explore the possible application of the projector model, the German DAM prices series in 2019 have been projected and evaluated, and the projections under Dutch 2050 energy scenarios have been used in calculating the generic profit potential of energy storage.<br/><br/>Five findings can be summarised from the main results. Firstly, from a literature survey and importance analyses, seven features are shown relevant to the DAM price in the combined data set, namely month of the year, day of the week, total hourly load forecast, national daily mean temperature, fuel cost of the most frequent final generating technology, hourly renewable power generation forecast and total installed renewable power capacity. Secondly, it has been found that two of the four proposed market state normalisation solutions, the Renewable Scarcity Factor (RSF) and the Renewable-Load Ratio (RLR) help the cWGAN-GP model strike a balance between price value distribution and hourly inter-dependencies. Thirdly, in this LEPP study, the cWGAN-GP model performs better than the Conditional Variational Auto-Encoder (CVAE) and multivariate Gaussian distribution (mGaus) models. Compared with the two alternatives, the cWGAN-GP model produces samples in better quality while remaining sensitive to temporal conditions. Fourthly, projections by the cWGAN-GP model are more realistic than those made by the Energy Transition Model (ETM), with price values varying continuously in smooth boundaries. Finally, the fuel cost of the most frequent final generating technology is found critical to LEPP. The annual mean and daily standard deviation of the DAM price series are expected to rise significantly when natural gas is mostly replaced by hydrogen power in the national energy portfolio.","Generative Adversarial Networks; Long-term Electricity Price Projection; Energy Scenarios; Series Generation; Electricity Prices; Renewable Energy","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:33571df8-98f3-466a-a231-2545cc0eb8cb","http://resolver.tudelft.nl/uuid:33571df8-98f3-466a-a231-2545cc0eb8cb","Modelling of aerosol deposition in human lungs","Kokkedee, Diederik (TU Delft Applied Sciences; TU Delft Electrical Engineering, Mathematics and Computer Science)","Kenjeres, S. (mentor); Vuik, Cornelis (graduation committee); Thijssen, J.M. (graduation committee); Schuttelaars, H.M. (graduation committee); Delft University of Technology (degree granting institution)","2022","A one-dimensional model of respiratory deposition is developed based on an Eulerian approach. The model simulates aerosol deposition in all generations of the respiratory tract by numerically solving the aerosol general dynamics equation (GDE) for a range of aerosol diameters. The lung geometry is described by Weibel’s morphometric model, with a time varying alveolar geometry to accommodate inhalation dynamics. The model is first valuated by comparing it with numerical and experimental results. Afterwards a series of parameter studies is performed by changing breathing conditions, particle parameters and lung geometries. An increase in Tidal volume and decrease of breathing period resulted in an increase of the total deposition fraction for coarse particles and a decrease of the total deposition fraction for ultrafine particles. An increase in the particle density resulted in an increase in the total deposition fraction. A decrease in the airway diameter generally resulted in an increase of the total deposition fraction. This difference was most noticeable in the tracheobronchial region. Decreasing the airway diameter in the tracheobronchial region mostly effects coarse particles while decreasing the airway diameter in the alveolar region mostly effects ultrafine particles.","","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics | Applied Physics","",""
"uuid:e97af41a-ccc8-4212-af93-703947c35bad","http://resolver.tudelft.nl/uuid:e97af41a-ccc8-4212-af93-703947c35bad","System integration of a high pressure alkaline electrolyser","Boons, Bart (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Process and Energy)","Van Kranendonk, Jan (mentor); de Jong, W. (mentor); Goetheer, E.L.V. (graduation committee); Boersma, B.J. (graduation committee); Haverkort, J.W. (graduation committee); Delfos, R. (graduation committee); Delft University of Technology (degree granting institution)","2022","To anticipate for future demand of sustainable liquid fuels, Zero Emission Fuels B.V. develops a solar powered micro plant which produces methanol from water and carbon dioxide captured from outside air. An intermediate step in this process is the electrolysis of water to create hydrogen which reacts with carbon dioxide to methanol. This study encompasses an integration of the pressurised alkaline electrolysis system, in which problems observed in previous generations of the electrolyser have been solved and functionalities have been added. In addition to that, electrolyte samples are taken after different periods<br/>of operation to investigate electrolyte deterioration over time. <br/><br/>A new Balance of Plant (BoP) has been designed, realised and tested. Eight new features to the system can be distinguished, two of which are included to add functionality: the degasser to decontaminate the carbon dioxide-rich<br/>feed water and the pressure booster to replenish the consumed water at system<br/>pressure. The other features are integrated to enlarge the operational envelope, the determination of which was central to the experiments conducted in this research. <br/>Experiments are conducted to find and characterise the four limitations to the operational envelope: the relative valve opening duty (RVOD), flow stagnation, temperature control and crossover.<br/><br/>The RVOD experiments showed deviations from the modelled valve opening cycles, attributed to additional pressure drops, valve opening interference and smaller discharge volumes. Subsequently a corrected model is presented to improve valve cycle time predictions.<br/>Flow stagnation was investigated at various current densities, pressures and temperatures using camera images and a characteristic temperature response to establish flow stagnation. The results showed a minimum volume flow rate decrease in comparison to the previous system, expressed in parameter &#x1d44b; which decreased from 3.4 to 0.74 A K bar<sup>-1</sup> cm<sup>-2</sup>. The minimum volume flow rate decrease is attributed to the larger number of cells and the increase of the height difference between the stack and buffer tanks.<br/>In the temperature control experiments, steady state temperatures were monitored at different current densities, with and without crossflow fan operation. This resulted in a temperature control map, in which the reachable temperatures for different current density are depicted. Furthermore, electrolyte mass flows are determined and pressure dependency of temperature control was investigated at low current densities, concluding that steady state temperatures are independent from pressures in the 10 bar to 50 bar regime. <br/>Hydrogen crossover was tested by taking gas samples at different operating conditions and subsequent gas composition analysis in a gas chromatograph; oxygen crossover was determined by an oxygen sensor implemented downstream the hydrogen exhaust. All steady state crossovers values were found to be below the safety limits, concluding that crossover is not limiting in the acquired system on all possible operating points. Overnight diffusion crossover experiments showed that maintaining the system under pressure overnight, keeps crossover values below the safety limit.<br/>In addition to the operational envelope, complementary general characteristics such as power consumption and efficiency are presented and compared to industry and literature. On top of that, unexpected findings, design deficits and other relevant phenomena are described to complete the perspective on system performance and behaviour of the electrolysis system. Due to the electrolyte mist purged into the degasser and pressure booster, the electrolyte deterioration experiments are deemed inconclusive. Moreover, a demister is found to be an essential system feature to include in the next generation electrolyser, because both degasser and pressure booster were damaged by the electrolyte spill.","Balance of Plant; Alkaline electrolysis; System integration; hydrogen; pressurised electrolysis","en","master thesis","","","","","","","","2024-02-04","","","","Mechanical Engineering","",""
"uuid:f71c6c3b-27b4-494c-a854-9884fddb8310","http://resolver.tudelft.nl/uuid:f71c6c3b-27b4-494c-a854-9884fddb8310","A Circular Approach for the Fire Safety Design in Mass Timber Buildings: Balancing the impact between material use and fire risk","Qvist, Siri (TU Delft Civil Engineering and Geosciences)","Ravenshorst, G.J.P. (graduation committee); Jonkers, H.M. (graduation committee); Alkisaei, H. (graduation committee); Steenbakkers, P.A.H.J (mentor); Wattez, Y. (mentor); Delft University of Technology (degree granting institution)","2022","The building industry consumes a lot of material, which causes depletion of material stocks, toxic emissions, and waste. Circular building design can help to reduce this impact, by moving from a linear to a circular design approach. <br/>To reach a circular build environment, all disciplines should be involved, including fire safety design. However, there is a contradiction between the objectives of circular and fire safety design, either affecting the aim of protection of material sources, or protection against fire risk. <br/><br/>Timber is a material that has high potential in contributing to a circular building industry, as it is renewable, recyclable and can store CO2. However, timber is combustible, which increases the risk of fire. Therefore, mass timber building design has traditionally been restricted by building regulations. To enhance mass timber building design research on timber buildings has increased, to allow understanding of the risks. However, yet general guidelines or understanding on the fire behaviour and risk in timber buildings is lacking. This is a problem for the fire safety design and the potentials of timber contributing to a circular building industry. <br/><br/>Until now, there was no specific method available that quantifies this relation between material use and fire risk in mass timber buildings. This limits the possibility of fire safety design and mass timber design to contribute to a more circular building industry. By creating a method that allows comparison between the economic and environmental impact of material use and fire risk, a well-founded choice of building materials is easier to make. <br/><br/>The design tool created in this research quantifies the impact on material use for fire safety measures relating to CLT, encapsulation and sprinkler availability and their effect on the fire risk in mass timber buildings. This way insight is provided between the balance of material use and fire risk. By the sum of the impact on material use and fire risk, the total “circular fire safety impact” value is calculated. This value represents the total economic and environmental impact of the design based on the choice of building materials. By changing the fire safety design, the most optimal design variant can be determined. This is the variant with the lowest total impact value. <br/><br/>This way, a circular design approach is used to steer fire safety design in mass timber buildings towards a design solution that does not only provide sufficient safety for people, but also provides maximum economic and environmental safety from a material point of view.<br","Mass timber; Fire safety design; Circular design; Fire risk; Fire resilience; CLT","en","master thesis","","","","","","","","","","","","Civil Engineering | Building Engineering - Structural Design","",""
"uuid:79a29b51-7ee6-4605-86ed-0cef87cd6e79","http://resolver.tudelft.nl/uuid:79a29b51-7ee6-4605-86ed-0cef87cd6e79","Additional Graduation Research: Sensitivity Analysis of the Circular Arch Bridge","Kooijman, Rick (TU Delft Civil Engineering and Geosciences)","Messali, F. (mentor); Nijsse, R. (graduation committee); Snijder, A.H. (graduation committee); Cabboi, A. (graduation committee); Delft University of Technology (degree granting institution)","2022","","Sensitivity Analysis; Circular Arch Bridge; Finite Element Analysis","en","master thesis","","","","","","","","","","","","Civil Engineering","",""
"uuid:50d94e0f-058d-4853-8a72-203e3c3c86ac","http://resolver.tudelft.nl/uuid:50d94e0f-058d-4853-8a72-203e3c3c86ac","Operational Characteristics Of A Metal Supported Solid Oxide Fuel Cell Power Generation System On Methanol For Naval Applications","Hoff, Yannick (TU Delft Mechanical, Maritime and Materials Engineering)","van Biert, L. (mentor); Visser, K. (graduation committee); Delft University of Technology (degree granting institution)","2022","The characteristics of a metal supported solid oxide fuel cell on methanol is analysed in as the power generator in a balance of plant consisting out of a reformer, combuster, heaters, pumps, turbines and tubes. The system is reviewed on performance regarding efficiency, power density, fuel utilization and viability for marine applications.","Fuel Cell; Methanol; Balance of Plant; Reformer; Marine Technology; Naval Ships","en","master thesis","","","","","","","","","","","","Marine Technology","",""
"uuid:f0652148-be1e-4a54-9153-ee8ff9fa1481","http://resolver.tudelft.nl/uuid:f0652148-be1e-4a54-9153-ee8ff9fa1481","Data Origin Authentication And The Classical Data Plane of A Quantum Network Link","Abrahams, Joël (TU Delft Electrical Engineering, Mathematics and Computer Science)","Wehner, S.D.C. (mentor); Elkouss Coronas, D. (graduation committee); Erkin, Z. (graduation committee); Delft University of Technology (degree granting institution)","2022","Quantum networks allow multiple devices to exchange information encoded within quantum systems.<br/>Such quantum networks use classical control messages to coordinate entanglement between nodes.<br/>Third parties which can forge such control messages may interfere with the workings of quantum links, however:<br/>They may either perform fraudulent requests for entanglement, destroying local quantum memory of nodes as a result, or interfere with the inner workings of protocols within the quantum stack targeting the availability of the link(s).<br/>We, therefore, conclude that all link and physical layer control messages must be transmitted via authenticated channels.<br/>Typically one uses a Message Authentication Code (MAC) to do so, which takes as input a message and outputs a tag which is transmitted alongside the message.<br/>Additionally, it takes as input a unique number each time (nonce) to prevent replay-type attacks.<br/>In this work, we first investigate the use of information-theoretic MACs combined with quantum key distribution (QKD) to authenticate control messages. We find that the fastest QKD solutions provide key material at a rate that is sufficient to not become a bottleneck in current quantum links.<br/>Second, we survey multiple computationally secure MAC solutions and benchmarks to get an indication of their performance when authenticating short messages.<br/>While not information-theoretically secure, their latency is generally speaking greater than or equal to that of information-theoretic solutions.<br/>Finally, we augment the existing simulation of a single quantum link by Dahlberg et al. by inserting delays based on the performance of these MACs.<br/>The performance of the link is evaluated using the mean throughput:<br/>The rate at which successfully entangled pairs are delivered.<br/>We find that the introduction of transmission time overhead, without any authentication, causes a noticeable decrease in throughput of the link. <br/>When considering an authenticated channel that uses SipHash (a popular MAC) we find that throughput decreases even further, though less significantly. <br/>Therefore, the overall decrease in throughput appears to not be detrimental to the working of the quantum link, which remains functional even when the classical channel is authenticated.","Quantum networks; Data origin authentication; Classical data plane; Simulation","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:4c32c283-626e-4a6b-9ede-7040b93ae8d5","http://resolver.tudelft.nl/uuid:4c32c283-626e-4a6b-9ede-7040b93ae8d5","The societal impact of different technical lay-outs of an energy hub","Visscher, Just (TU Delft Electrical Engineering, Mathematics and Computer Science)","Palensky, P. (mentor); Cvetkovic, M. (mentor); Ghaffarian Niasar, M. (mentor); Delft University of Technology (degree granting institution)","2022","The Dutch government's ""Green deal 173"" increases the challenge of electrification of mobility. The ""Green deal 173"" states that city centres will be emission free as from 2025 and whole cities will be emission free as from 2050. Emission free cities are in need of electric buses in the city centres. Thus, the need for charging infrastructure for new electric bus fleets is needed in urban areas. These urban areas are densely populated with not a lot of space to work in, therefore the electrification of mobility creates a new challenge for the distribution system operator, concessionaires, concession granters and municipalities. An energy hub is a solution to this challenge. An energy hub combines the new charging infrastructure with the existing electrical infrastructure in a new system, with large energy users and new technologies such as solar energy and vehicle to grid (storage). This report will explain the societal impact of different technical lay-outs of an energy hub, to do so different case studies are modelled and simulated to test the technical feasibility. Furthermore, the costs and benefits will be assessed and valued to research the business case of an energy hub, because the difference between theory and real life implementation is bound to cost reduction and/or profitability in most cases. <br/>The results show that an energy hub can reduce the net capacity of the used lines, reduce the occurrence of peak demand and be profitable over time for the parties in the energy hub. However, all the parties involved need to work together to achieve the realisation of an energy hub. The distribution system operator, concessionaires, concession granters and municipalities need to find similarities in their priorities instead of conflicting priorities. The similarities in their priorities will be an important factor to realise an energy hub. <br/><br","Energy hub; power grids; micro grid","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:b87bba30-eca9-48ba-afde-849f9a4b65e4","http://resolver.tudelft.nl/uuid:b87bba30-eca9-48ba-afde-849f9a4b65e4","Asymmetric Stall and Control Effectiveness reduction Modeling for the Cessna Citation II","DELFOSSE, Alexandre (TU Delft Aerospace Engineering)","de Visser, C.C. (mentor); Pool, D.M. (graduation committee); Delft University of Technology (degree granting institution)","2022","Since 2019, the FAA and the EASA impose to all airline pilots to follow, as part of their training, a stall and recovery training. To mitigate the risks, this training takes place in ground-based simulators. To make it happen, models of the aircraft behaviour at high angle of attack need to be developed. Among the different modeling approaches possible, when available in such flight conditions (i.e. at high angles of attack, near and beyond stall), the use of actual flight test data is particularly interesting as it makes this work not being just a simulation study. Additionally, the method already proved to be efficient and effective for aerodynamic modeling purpose, especially in the nominal flight envelope, but it has also demonstrated interesting and encouraging results in modeling an extended (longitudinal) flight envelope, including stall entry up to post-stall conditions, using Kirchhoff theory of flow separation. With this work, it is<br/>intended to support the idea that despite the development of digital techniques (CFD, physical simulation, etc.) flight data based models are still tools of major importance in order to create and develop models capable of positive transfer of training for the pilots in simulators. The purpose of this research is to try to fill a gap in the modeling of the lateral-directional dynamics of stalls using flight test data, by making use of an extended and adapted version of Kirchhoff Theory’s of flow separation. From a numerical point of view, it then seems that this approach<br/>allows to improve by a few % the accuracy of the lateral-directional model.","Stall Modeling; Aerodynamic Model Identification; aerodynamic modelling; Aerodynamic Properties; Identification; Modeling; Modeling and optimisation; Parameter Estimation; Parameter Identification","en","master thesis","","","","","","","","2025-02-03","","","","Aerospace Engineering | Control & Simulation","Citation Stall Modeling Task Force",""
"uuid:f1373ca3-47ea-42ab-8d9e-20a8a2652c99","http://resolver.tudelft.nl/uuid:f1373ca3-47ea-42ab-8d9e-20a8a2652c99","Structural Dynamic Response of the Circular Arch Bridge","Kooijman, Rick (TU Delft Civil Engineering and Geosciences)","Nijsse, R. (mentor); Snijder, A.H. (graduation committee); Messali, F. (graduation committee); Cabboi, A. (graduation committee); Delft University of Technology (degree granting institution)","2022","The Circular Arch Bridge is a pedestrian bridge consisting out of four different recycled materials: cast glass, ceramic, circument and geopolymer concrete. Due to an increasing amount of vibration problems in modern pedestrian bridges they should not only be designed for static loads, but dynamic loads have to be considered as well. There are currently no guidelines in the Eurocodes for the dynamic assessment of a bridge like the Circular Arch Bridge. Therefore, this paper provides a research on how the dynamic assessment of the Circular Arch Bridge should be conducted.<br/><br/>The Circular Arch Bridge is considered a dry-stacked masonry arch bridge. A full dynamic assessment is conducted, with the use of finite element software, according to the guidelines for pedestrian bridges. The eigenvalues of the Circular Arch Bridge are not within the critical range for pedestrian induced dynamic loads. It is found that for everyday use the Circular Arch Bridge is within Comfort Class 2 from the Eurocode, thereby providing a medium comfort level. A special load case is added to the analysis representing a group of 60 people dancing on the bridge during experimental testing of the bridge. For this load case the Circular Arch Bridge is within Comfort Class 3 from the Eurocode, thereby providing a minimum level of comfort.<br/><br/>With a sensitivity analysis it is determined that the most sensitive input parameter of the finite element model is the modulus of elasticity of the interlayer. An investigation of the effect of large stiffness differences between the interlayer and the stones on the dynamic properties of the bridge is conducted. It is concluded that the large stiffness differences have a positive effect on the dynamic properties of the bridge. The effect of the dry-stacked assembly of the bridge on the dynamic properties is also investigated. This as a negative effect on the dynamic properties of the bridge.<br","Circular Arch Bridge; Structural Dynamics; Structural glass; Pedestrian Bridge; Masonry Arch Bridge; Dry stacking; Dry assembly; Finite Element Analysis; Sensitivity Analysis","en","master thesis","","","","","","","","","","","","Civil Engineering","",""
"uuid:69a62bc8-8ce9-4f15-bbbf-1449949c5a20","http://resolver.tudelft.nl/uuid:69a62bc8-8ce9-4f15-bbbf-1449949c5a20","The Application of a Composite Sandwich Design for the Undershield of a Structural Automotive REESS","Schmetz, Toine (TU Delft Aerospace Engineering)","Bergsma, O.K. (mentor); Alderliesten, R.C. (graduation committee); Sinke, J. (graduation committee); Delft University of Technology (degree granting institution)","2022","To reduce greenhouse gas emissions, electrification is the biggest trend in the current-day automotive industry. In this transition, important topics are efficiency and weight reduction. This study focuses on the application of composite materials for the undershield of an automotive rechargeable energy storage system (REESS). In this application, the undershield forms the structural floor of a battery enclosure. The goal of the research was to determine if the homologation and safety demands for the undershield can be met with a composite-dominant design. Additionally, the goal was to determine if such a design can result in mass, cost, and emissions improvements compared to current metallic designs. Based on European and Chinese homologation documents, SAE standards, and demands by Volvo Cars, a set of relevant requirements was constructed. Based on these requirements, a sandwich design proposal was done and potentially suitable materials were identified. Multiple material configurations for the design were then verified based on the driving requirements. Lastly, a performance comparison was done of the mass, cost, and CO¬2 emissions of each configuration. The results indicate that it is feasible to meet the homologations and safety demands for the undershield of an automotive REESS with a composite sandwich design. Using polyester or phenolic glass fiber SMC for the top face of the sandwich can provide a successful fire protection barrier. PET foam was identified as a low emissions core material for improved impact protection in combination with steel or PP GMT bottom plate. Additionally, lower costs and emissions can be offered with steel configurations compared to current metallic designs. Alternatively, PP GMT configurations offer mass and emissions reductions. All in all, the research has succeeded in demonstrating the potential of composite or hybrid designs for the application in an automotive REESS for the improvement of mass, cost, and/or greenhouse gas emissions.","REESS; Automotive; composites; impact; Fire; Sustainability","en","master thesis","","","","","","","","2027-02-02","","","","Aerospace Engineering","",""
"uuid:4d828686-33e5-4fa7-8d6f-54b318b9c260","http://resolver.tudelft.nl/uuid:4d828686-33e5-4fa7-8d6f-54b318b9c260","Predicting the number of students in the Netherlands","Mooiman, Arthur (TU Delft Electrical Engineering, Mathematics and Computer Science)","Vuik, Cornelis (mentor); Gijswijt, D.C. (graduation committee); van Til, Willemijn (mentor); Delft University of Technology (degree granting institution)","2022","In this thesis the Conjugate Gradient method used in the forecasting of the number of students in the Netherlands is investigated. The addition of international students to the forecasting led to mathematical problem of which a solution could not be computed. While the numerical method is working as intended, the work presented in this thesis shows that the unsolvability lies with a linear system that has no solution. The cause of this is attributed to the use of a selection process in the linear system. Leading to a hugely singular matrix and a forecasting problem without a solution. Several methods were tried to change the use of the selection process but without any results .","Conjugate Gradient; CG; Referentieramingen; OCW","en","master thesis","","","","","","","","","","","","","",""
"uuid:e36fcece-9e8a-4a96-a52a-644f273b33e0","http://resolver.tudelft.nl/uuid:e36fcece-9e8a-4a96-a52a-644f273b33e0","Buried rock contour of a megalithic structure: Assessment of the buried rock contour of a megalithic structure by means of non-destructive geophysical methods","Zijlstra, Maarten (TU Delft Civil Engineering and Geosciences)","Draganov, D.S. (mentor); Ngan-Tillard, D.J.M. (graduation committee); Yang, Y. (graduation committee); Delft University of Technology (degree granting institution)","2022","The dolmens erected in the province of Drenthe between 3350-2700 BC are the most ancient monuments of the Netherlands. They consist of a long assemblage of rocks capped with boulders which served as burial chambers for the Funnel Beaker population. Despite their robust look, dolmens are vulnerable. For example, one of the caprocks of dolmen D14 fell off in 2019, once again. The method currently used to repair megaliths is not optimal: a crane is mobilized and the rocks are repositioned using a trial and error strategy. The reconstruction scenario should be selected and fine-tuned digitally beforehand. Moreover, the structural stability of the new assemblage of rocks should also be checked numerically. This necessitates a digital model of all the rocks that have to be rearranged. Not only the visible part of these rocks has to be digitized. The buried parts of the support rocks have to be modelled too as these rocks might have to be displaced and tilted to obtain a more compact and interlocked structure. Since dolmens occupy a prominent position in the Dutch heritage, only non-destructive see-through techniques have to be used for imaging the hidden contours of the bearing rocks. In addition, the bearing stones have complex geometries and are not isolated, which increases the complexity of the problem.<br/><br/>Two suitable geophysical methods are the Ground Penetrating Radar (GPR) and seismic techniques with a focus on reflection measurements. For the GPR specifically, we choose a Common Offset Survey, which can map reflections from the subsurface. For the seismic techniques, we choose a line array measurement, among others. We use the GPR to estimate the buried rock contour of the keystone Sl2 of megalith D14, which is a bearing stone formerly supporting capstone D9. We perform several reflection tests on various rocks unrelated to D14 using different seismic sources and receivers to estimate the reflection depths. We follow a proposed approach for both methods. <br/><br/>To evaluate the GPR data from the field, we assume a simplified GPR with zero-dimensional antennas (GPR point model). Subsequently, we develop two mathematical models (GPR point-to-GEO and GEO-to-GPR point model), based on this conceptual model in order to I) calculate the (buried) rock surfaces from field data and II) model field data from estimated buried rock contours.<br/><br/>We first perform the Common Offset Survey on a non-buried boulder on the campus of the TU Delft to evaluate the accuracy of the developed GPR point-to-GEO model and to optimise the second survey on keystone Sl2. We first perform the seismic reflection measurements on several rock samples to determine the best seismic source. Finally, we perform a line array measurement on a cylindrical basalt column using 300 kHz transducers.<br/><br/>We calculate rock contour coordinates from the GPR data and these show a reasonable fit with the contour of the TU Delft boulder, with an accuracy of 5-10 cm. For the keystone Sl2, the maximum burial depth is determined to be 80 cm at the southern side. The bottom of the keystone is sloping downward starting from ground level at the northern side. The southern, eastern and western rock faces are steep, almost vertical, which is confirmed by historic photographs. However, the calculated (buried) rock surface coordinates consist of an incoherent set of coordinates with locally a lack of data or blind-spots. Estimating a coherent buried rock contour, therefore, requires shortcuts and a decrease of accuracy is to be expected especially for rock surfaces near blind-spots in the GPR data. Furthermore, the identification of relevant reflection surfaces is rather subjective and combined with blind spots in the acquired GPR data, this can lead to wrongful interpretations of the buried rock contour.<br/><br/>The seismic reflection measurements we perform give clear reflections for the 300 kHz transducers on rocks of limited size with simple geometries. However, the transducers should first be applied on rocks with increasingly more complex geometries before being applied in the field. The accuracy in the order of 1 cm can be considered promising, but its applicability for complex geometries and reflection depths larger than 0.5 m remains unknown.","megalithic structure; Non-destructive geophysical methods; Ground Penetrating Radar; Common Offset Survey; Seismic reflection methods; Line array measurement; Buried rock contour","en","master thesis","","","","","","","","","","","","Geo-Engineering","",""
"uuid:6256cb61-eab8-4c4c-bd3a-07ff8e709219","http://resolver.tudelft.nl/uuid:6256cb61-eab8-4c4c-bd3a-07ff8e709219","An investigation into the carbon and material footprint of the Dutch consumption of pharmaceuticals","Hagenaars, Rosalie (TU Delft Technology, Policy and Management)","De Koning, Arjan (mentor); Kweekel, Dinemarie (mentor); Steenmeijer, Michelle (mentor); Delft University of Technology (degree granting institution); Universiteit Leiden (degree granting institution)","2022","This thesis explores the relatively large contribution of the product category ‘chemicals n.e.c.’ (chemicals not elsewhere classified) to the Dutch healthcare sector’s carbon and material footprint observed in previous studies. For this, an input-output study using SNAC-EXIOBASE data was performed. SNAC-EXIOBASE uses national statistics for the Dutch part of the multi-regional input-output table. It also distinguishes a separate chemical and pharmaceutical industry in the Dutch part. This can help identify possible aggregation problems in the EXIOBASE category ‘chemicals n.e.c.’ which is an aggregate of the chemical and pharmaceutical industry sectors. Comparing the carbon and material footprint of pharmaceuticals used in the Dutch health care sector as calculated with (default) EXIOBASE and SNAC-EXIOBASE shows that there is an aggregation problem in the ‘chemicals n.e.c.’ category. This means that grouping the pharmaceutical industry with the chemical industry greatly influences the carbon and material footprint of pharmaceuticals. The carbon footprint decreases by 11% and the material footprint by 61% when using SNAC-EXIOBASE compared to EXIOBASE data. The multiplier analysis showed that in all cases the Dutch pharmaceutical industry has a lower carbon, mineral and metal intensity (footprint per euro) compared to the Dutch chemical industry or ‘chemicals n.e.c.’ confirming the aggregation problem. The LCA literature review showed that the range of carbon intensities of individual pharmaceuticals matches the carbon intensity of the ‘pharmaceutical industry’ in SNAC-EXIOBASE. This study also showed that the material footprint of the Dutch healthcare sector is uncertain and should be used with care. Future research should focus on using MRIOs that better depict the pharmaceutical industry like the ICIO which is based on the ISIC Rev. 4 classification and, therefore, includes a separate pharmaceutical industry. Before performing analyses with the ICIO is possible, higher sectoral resolution and environmental extensions are needed.","Carbon footprint; Material footprint; pharmaceutical industry; Healthcare; input-output analysis","en","master thesis","","","","","","This thesis was written in combination with an internship at RIVM.","","","","","","Industrial Ecology","",""
"uuid:839d23f0-a529-4ba6-a3c1-687c0f9a5b9b","http://resolver.tudelft.nl/uuid:839d23f0-a529-4ba6-a3c1-687c0f9a5b9b","Towards Optimization of ECG Noise Suppression in Adaptive Deep Brain Stimulation","Koers, Pallas (TU Delft Mechanical, Maritime and Materials Engineering)","Dauwels, J.H.G. (mentor); Beudel, Martijn (graduation committee); Serdijn, W.A. (graduation committee); Delft University of Technology (degree granting institution)","2022","Adaptive Deep Brain Stimulation (aDBS) offers the potential for personalized stimulation strategies for patients with Parkinson's Disease (PD). The closed loop characteristic of this system requires the incorporation of PD relevant biomarkers that determine the patient's need. In order to obtain high quality LFP (Local Field Potential) input signals, the ECG (electrocardiogram) noise should be suppressed. The aim of this project is to study the performance of various algorithmic ECG noise suppression methods. Out of the ADAPT-PD trial, we have taken 9 LFP channels with consistent ECG artefacts for exploring the performance of ECG noise suppression models. As a reference point for filtering performance, we have used survey data (DBS-OFF). Using an externally measured ECG as reference, we have implemented two Adaptive NLMS (Normalized Least Mean Squared) Noise Cancellation algorithms. For the first version, we have used stimulation ramping alone for synchronization of the data sets. The second version includes an extension that aims to improve only the data synchronization feature. Furthermore, we have explored the ECG noise suppression performance of a proposed template subtraction method, using 11 different variations of epoch length. For improved analysis, we have used three data sets, namely personal (#1), patient group (#9) and simulated (#5346) data, using the Perceive toolbox ECG filtering method as the benchmark. Simulated LFPs are based on survey data combined with 9 external ECGs in 11 levels of contamination (100-1100 %). We have conducted analysis in both the time and frequency domain (beta-range 13-30 Hz), in order to estimate the absolute difference from the reference survey. Outcomes in the frequency domain show that, for personal performance, template subtraction tweaking provides an improvement up to 37.6 % over the Perceive toolbox. Furthermore, the outcomes show that, for both the patient and simulation group, optimal performance is obtained using the Perceive Toolbox with 20.7 % accuracy for the patient group and 4.7 % for the simulations. It can be concluded that the survey LFPs can be used for personal calibration of ECG noise suppression. This contradicts the aim to find one universal LFP ECG noise suppression method. There is a need for a reliable data synchronization method between the Percept LFPs and other biometric data. Reliable synchronization would improve the usability of the external ECG as reference signal in adaptive filters. Furthermore, reliable synchronization would accelerate the discovery of linked physical symptoms for PD biomarkers.","signal denoising; neurotechnology; Bioelectronic Medicine","en","master thesis","","","","","","","","","","","","Biomedical Engineering","",""
"uuid:61a05814-bde3-4bee-90d5-ce73434d4fc5","http://resolver.tudelft.nl/uuid:61a05814-bde3-4bee-90d5-ce73434d4fc5","The effect of intra-organisational data sharing during the tender phase on risk awareness in multinational construction companies: A multiple-case design","de Metz, Skip (TU Delft Civil Engineering and Geosciences)","Jalali Sohi, A. (mentor); Chan, P.W.C. (graduation committee); Wang, T. (graduation committee); Verstegen, R. (mentor); Delft University of Technology (degree granting institution)","2022","Due to the dynamic and complex nature of the construction industry, it is evident that the integration of processes and groups is more challenging to attain in comparison to other industries (Demirkesen &amp; Ozorhon,2017). Therefore, there is a call for better integration of project participants and processes in construction projects (Franz et al., 2017). Consequently, organisational collaboration and integration are often considered inefficient and dependent on individuals. This inefficiency can be caused by individuals not making the right connections to gain access or obtain relevant data for the decision making process. This can be explained by the fact that the industry is renowned for its fragmentation and temporary project teams Whitley, 2006). Due to this fragmentation, it is not uncommon for parties to have their own internal silos. These internal silos contain different sorts of data and have limited connections within their own or with other project teams, resulting in bad data sharing and communication. The presence of data silos and limited data sharing affects risk awareness as this can cause unavailability of data or subjective biases in the decision-making process. As a result, the employees that make the decisions are not (completely) aware of the involved risks, which can give the impression of soundly under-supported choices (van der Meer, 2021). By utilising data sharing and ensuring the proper coordination and communication, one could take on the silo’s created by this fragmentation between and in project teams, and by doing so, one could expect to reduce the detrimental effects on risk awareness. Especially when firms are active in a multinational environment, research has shown that connections between people that cross physical boundaries can enhance opportunities to improve performance and improve entry to information (DeSanctis &amp; Monge, 1999). That is why, one could argue that data sharing could contribute significantly to risk awareness among team members. To investigate this, the following research question has been formulated: How does data sharing in intra-organisational project networks contribute to risk awareness in the tender phase?","social network analysis; intra-organisational data sharing; Expert panel; tender phase; risk awareness; data sharing; multinational construction companies","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:23ab613c-d5d0-46ba-b18f-e53f7c6b5349","http://resolver.tudelft.nl/uuid:23ab613c-d5d0-46ba-b18f-e53f7c6b5349","A Fully Implantable Closed-loop System for Autonomous Opioid Detection and Treatment","Kerssemakers, Tom (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Delft Center for Systems and Control; TU Delft Delft Center for Systems and Control; Massachusetts Institute of Technology; Harvard Medical School; Brigham and Women's Hospital)","Mazo, M. (mentor); Huang, Hen-Wei (graduation committee); Traverso, Giovanni (graduation committee); Delft University of Technology (degree granting institution)","2022","With over 75,000 attributed deaths in 2020, opioid overdose is now the leading cause of death amongst Americans under the age of 50. With record-breaking increases in fatalities for the past 10 years, fentanyl in particular has many experts worried about the future of the opioid epidemic. To reverse opioid overdose there exists a drug called Naloxone, an opioid antagonist that completely restores the subject’s vitality within minutes. As the US opioid epidemic is surging by the increase of synthetic opioid-related overdoses, current methods of Naloxone administration are unsuccessful in suppressing the rise. One large obstacle in the rate of success for Naloxone is related to the fact that opioid users are not able to administer the antagonist to themselves due to their overdosing symptoms, which includes unconsciousness. Therefore, to save a life with Naloxone, one has to rely on a bystander that is present during the overdose, recognizes it, possesses Naloxone, and is able to administer it in time. The rising death toll of opioid overdose reveals that one of these conditions are often not met. This thesis presents a fully implantable device that is capable of autonomously detecting and treating opioid overdose to provide an alternative solution that takes the said bystander out of the equation. To achieve this, three different sensors (an Inertial Measurement Unit (IMU), Electrocardiography (ECG), and Photoplethysmography (PPG) sensor) are used for the monitoring of heart rate and respiratory rate. These vital sings are continuously fed into an advanced decision-making system that is capable of detecting opioid overdose within 81 seconds. Once detected, instructions are sent to a novel drug delivery pump that is capable of delivering high volumes of Naloxone within only 3.25 seconds, while outperforming similar technologies in terms of energy efficiency. The proposed subcutaneous implantable device can be refilled through a refill port, be wirelessly charged, and has a battery capacity that lasts up to 78 days. It is concluded that the proposed closed-loop drug delivery system is a feasible and effective autonomous tool that could complement existing Naloxone administration solutions in the ongoing fight against the opioid epidemic.","Vital Sign Monitoring; Opioid Overdose; Closed-Loop Device; Medical Robotics; Implantable Device; Drug Delivery System; Naloxone; Fentanyl","en","master thesis","","","","","","","","2024-02-01","","","","Mechanical Engineering | Systems and Control","",""
"uuid:00021d50-b7c2-465e-8dcc-a274f646ff3a","http://resolver.tudelft.nl/uuid:00021d50-b7c2-465e-8dcc-a274f646ff3a","Scheduling cardiac catheterization laboratories with Monte Carlo simulation","Jongeneel, Hilda (TU Delft Mechanical, Maritime and Materials Engineering)","van den Dobbelsteen, J.J. (mentor); Hendriks, B.H.W. (mentor); Butler, R.M. (mentor); van Essen, J.T. (graduation committee); Delft University of Technology (degree granting institution)","2022","The growing demand for cardiovascular treatments and the need to control the ever rising health care expenditures require efficient use of expensive resources, such as cardiac catheterization laboratories (cath labs). These in cardiac catheterization specialized operating rooms are labor and capital-intensive. Therefore, a high utilization is desired, although overtime should be prevented. However, this is complex in practice, because uncertainty in procedure duration and the number of patients makes it difficult to predict shift duration. At the moment, scheduling is mainly done by hand and the result strongly depends on the scheduler’s experience. Furthermore, little research is done on cath lab scheduling. Hence, this study aims to further define the cath lab scheduling process, identify the areas of improvement, and explore the usefulness of Monte Carlo simulation to support human schedulers. Schedulers of two Dutch hospitals, the Reinier de Graaf Gasthuis and the HagaZiekenhuis, are interviewed to map the scheduling process and identify the main difficulties. According to the schedulers, the main area of improvement is the estimation of procedure and shift duration, which currently is based on experience and rules of thumb. Based on the process in the HagaZiekenhuis, a Monte Carlo simulation is developed that computes the shift duration, utilization, and number of deferrals based on the blueprint schedule, the distributions of procedure duration and the emergency arrival rate. A first attempt to validate the model is done with input data from the VUmc as reported in another paper, as no historical data of the HagaZiekenhuis was available. The number of simulations required for convergence of the model was found to be at least 300. Next, the utilization, overtime, and undertime of the simulation were compared with these metrics from the VUmc. They were found to be close, even though the scheduling decisions are based on another hospital. To examine the sensitivity of the model, several scenarios are tested, namely, no emergency arrivals, a double amount of emergency arrivals, both halving and doubling the standard deviation of input distributions, adding extra patients to the inpatient waiting list to increase the demand, changing the threshold when patients are deferred and changing the type of input distribution from lognormal to normal. The effect of these scenarios is mainly as expected. Less variation in the output can be obtained by reducing the variance of the input distributions. Additionally, the type of input distribution seems to have limited effect on the output distribution. Furthermore, the effect of changing the deferral threshold, which is stochastic according to the interviews, seems limited. Moreover, no inexplicable behaviour was discovered by inspecting the realizations of the blue print schedule. Lastly, the data of the VUmc was applied to the blueprint of the HagaZiekenhuis, but inspection of the blueprint schedule revealed that the procedure duration in the VUmc data is longer than in the HagaZiekenhuis. This demonstrates that one cannot use the data and blueprint of different hospitals. An attempt was done to correct for this by scaling the distributions such that the mean corresponds to the scheduled duration. This led to more realistic results for some procedure types, although the standard procedure duration appears to not match the average duration for other types. The first results are promising, hence, a more in-depth validation of the model is recommended. The most promising application of this simulation seems the estimation of shift duration given a specific set of patients, integrated in the scheduling software.","cath lab; scheduling; Monte Carlo simulation; cardiac catheterization laboratory","en","master thesis","","","","","","","","2024-02-01","","","","Mechanical Engineering","",""
"uuid:20c7415a-4cca-4b5e-928a-0ea83e630574","http://resolver.tudelft.nl/uuid:20c7415a-4cca-4b5e-928a-0ea83e630574","The influence of residential and work locations on commuting durations and distances: Changes in the last decade for different income groups in Amsterdam","Schroten, Mike (TU Delft Architecture and the Built Environment; Amsterdam Institute for Advanced Metropolitan Solutions (AMS); Wageningen University & Research)","Maat, C. (mentor); van Wee, G.P. (mentor); Kujawa, K (graduation committee); Delft University of Technology (degree granting institution); Wageningen University & Research (degree granting institution)","2022","This study examines the extent of which residential location and workplace location affect commuting duration and commuting distance. Moreover, by splitting to income groups social equity issues in commuting in connection to rising property values in Amsterdam come to the fore. The report employs data from the 2010, 2011, 2016 and 2017 OViN surveys to investigate changes over a time period of five years.<br/><br/>The findings from the spatial analysis, data analysis and regression models indicate that not low income households but instead middle income households more often live less central than high income households. Middle income commuters did not reduce their commuting duration and commuting distance by moving away from the city centre. Both increase when they reside less central. Low income commuters, however, did improve their commute and now commute shorter than middle and high income commuters. When working outside Amsterdam commuters who reside central in Amsterdam but not central outside Amsterdam experience the shortest commutes. People who reside not central outside Amsterdam experience shorter commuters than those who reside central outside Amsterdam.<br/><br/>Given the findings described in this report a new debate could arise in which not the worsening opportunities of low income households should be prioritised, but instead should give way to the worsening conditions of middle income households. Future research should focus on personal preferences of individual commuters. In this research the assumption was made that every respondent that lives in Amsterdam choses to do so. This assumption cannot be made for people living elsewhere, because they may not want to live in a dense urban area. By integrating the personal preferences of respondents the different groups can be better compared.","Mobility; Amsterdam; OViN; Commuting; Social equity; Housing","en","master thesis","","","","","","","","","","","","Metropolitan Analysis, Design and Engineering (MADE)","",""
"uuid:0bf679ef-8644-45f4-a2b0-751a3b516d09","http://resolver.tudelft.nl/uuid:0bf679ef-8644-45f4-a2b0-751a3b516d09","Influences on Technology Entrepreneurship: A Comparative Analysis Between The Netherlands and Japan","Avé, Tondan (TU Delft Technology, Policy and Management)","Ortt, J.R. (mentor); Giga, A. (mentor); Delft University of Technology (degree granting institution)","2022","This thesis explored the contrast between the overarching category of entrepreneurship (from here on, “mainstream entrepreneurship” or ME) and the subset of technology entrepreneurship (TE) through a comparison of The Netherlands (low TE/high ME) and Japan (high TE/low ME), addressing the problem that currently no dedicated frameworks for TE exist. Five influencing variables were explored at the country level of analysis, namely economic development, technological development, institutions, education, and culture. In contrast to ME, TE benefits from better technological development and education. These influencing variables showed high values, whereas for ME they showed low values. With analysis of 44 additional countries, these results were confirmed, and economic development was also deemed important to TE. A culture high on long-term orientation and individualism (Hofstede dimensions) appeared to benefit TE. Institutions showed little difference between ME and TE. The additional analysis firmly showed that ME and TE are different and unrelated. which was confirmed by a low correlation coefficient and corresponding p-value.<br/><br/>This thesis shows that TE and ME are different, should be treated as such, and has identified several influencing variables that affect TE differently than ME. Thus, TE and ME can be independently stimulated by increasing the levels of the influencing variables. For governments seeking to increase their levels of TE through relevant policies, despite a traditionally non-entrepreneurial environment, it means that all is not lost, and that the levels of TE can be raised by focusing on increasing levels of education, economic environment, and technological environment. Managerial recommendations include the geographical placement of technology start-ups and the diversification of the team to improve success.","Entrepreneurship; Technology entrepreneurship; Mainstream entrepreneurship; The Netherlands; Japan; Comparative analysis","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
