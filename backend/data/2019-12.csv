"uuid","repository link","title","author","contributor","publication year","abstract","subject topic","language","publication type","publisher","isbn","issn","patent","patent status","bibliographic note","access restriction","embargo date","faculty","department","research group","programme","project","coordinates"
"uuid:4ffcf084-71ac-4f9d-b98d-2969fb237406","http://resolver.tudelft.nl/uuid:4ffcf084-71ac-4f9d-b98d-2969fb237406","Contextual Refurbishing: Renovations of the Residential Building, Skopje, Macedonia","Wang, Wei-Chieh (TU Delft Architecture and the Built Environment)","Staničić, Aleksandar (mentor); Mejia Hernandez, Jorge (mentor); Havik, Klaske (mentor); Culek, Jana (mentor); Delft University of Technology (degree granting institution)","2019","Skopje, in the last decades, underwent a dramatic spatial shift, due to transformation (traditional to modern), natural disasters (seismic destruction), and resurgence (re-plan and reconstruction). These changes have created a complex city, which over time became even more diverse through the creation of various cityscapes by both residents and architects. On the level of the building blocks we<br/>can see some of the changes that have been made by residents in the form of building extensions. These adjustments reveal that a pure architect-driven project is incapable of reflecting the diversity of society.","","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences","",""
"uuid:baf07691-9475-40d1-963e-f2eeb8604739","http://resolver.tudelft.nl/uuid:baf07691-9475-40d1-963e-f2eeb8604739","Investigation and implementation of the PV-Chimney'system on building emvelopes","Lysandrou, Andri (TU Delft Architecture and the Built Environment)","van den Dobbelsteen, Andy (mentor); Bokel, Regina (mentor); Haghighi, Zoheir (mentor); Stellingwerf, Martijn (graduation committee); Delft University of Technology (degree granting institution)","2019","This study refers to the PV/T-chimney system, an innovative system that combines two solar systems, a Trombe wall system and a PV/T system in order to gain more energy per square meter of application. The research analyzes the impact of the PV-chimney system on the energy performance of residential high-rise buildings and the architectural integration of the system as part of the facade. Different facade design alternatives, which investigate different facade patterns and their limitations in terms of functional and practical issues, provide a categorization of different ways of its use. Based on that, for each architectural category, by the help of energy simulations, a multicriteria analysis of the system is done. The aim is to understand the behavior of the proposed PV-chimney system under different geometrical characteristics in different climate conditions, in order to find the most optimal parameter combinations in terms of performance. In the second part, having as case study the Europoint Towers, in Rotterdam, a detailed facade design of PV/T-chimney is proposed based on the findings of the architectural and multicriteria analysis. This design, was developed in order for the system to adapt in the climate of the Netherlands, where the case study building is located as well as the climate of Hungary, where, it was constructed in 1:1 scale under the framework of Solar Decathlon 2019 competition, which took place in Hungary. In Hungary, an experiment of the system was conducted, in order to test the efficiency of the Photovoltaics under high temperatures and the potential use of this system for ventilation purposes. The results of the experiment indicate the viability of the simulations and underline the possible future improvements of the system for higher energy performance. According to the experiment measurements and the simulations, a comparison of the proposed system with conventional products proves that there is a reduction of the PV efficiency due to high temperatures. Thus, there are energy losses in the operation of the PVs. However, the electricity losses are depreciated by the thermal gains of the system, which give a final positive energy sign to the system.","Trombe walls; PV/T systems; high-rise; sustainable high-rise; passive ventilation; high-rise facade; passive design strategies","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Building Technology | Sustainable Design","",""
"uuid:388baa4e-f424-4aa6-b779-1c8cb92a90e2","http://resolver.tudelft.nl/uuid:388baa4e-f424-4aa6-b779-1c8cb92a90e2","Workspace Extension in Shoulder Elevation/-Protraction Actuated, By-Wire Controlled Grasping and Squeezing in a Virtual Environment","Broekzitter, Jelle (TU Delft Mechanical, Maritime and Materials Engineering)","Plettenburg, Dick (mentor); Abbink, David (graduation committee); Delft University of Technology (degree granting institution)","2019","Many users of body-powered upper extremity prostheses experience difficulties using their device and a large group abandons usage altogether. Shoulder control via Bowden cable is widely used because of the intuitive use and low cost, but requires large shoulder movements and high operating forces that, according to literature, often exceed the upper limit of around 20N that would allow for fatigue-free prolonged use. Implementing by-wire control reduces friction forces due to shorter cables, but it also allows for prosthesis control to be treated as a telemanipulation problem: workspace extension methods could prove effective in further reducing these movements and forces. To test if these methods are indeed applicable, three different modes of control - proportional gain control, non-linear variable gain control, and velocity control - were implemented in an ideal virtual environment. Performance was measured at both ends of the range of motion using an experiment based on Fitts' translational tapping task. It was hypothesised that variable gain control would improve speed during gross positioning and accuracy during fine positioning, improving overall performance, while velocity control would perform worse. The results show that the hypothesis holds, as well as improved controller performance when using a variable gain. It can be concluded that variable gain control in shoulder actuated prostheses can be beneficial and it would be worth exploring in real-life applications.","Upper limb prosthetics; Workspace Optimization; Grasping","en","master thesis","","","","","","","","","","","","Biomedical Engineering | BioMechatronics","",""
"uuid:6307c7bf-8b5a-4da2-b0bc-15961d2c436b","http://resolver.tudelft.nl/uuid:6307c7bf-8b5a-4da2-b0bc-15961d2c436b","On the non-normality and sensitivity of the linear stability equations in boundary layer flow: Bi-orthogonality, pseudospectra and mode sensitivity","Kessels, Fleur (TU Delft Aerospace Engineering)","van Oudheusden, Bas (mentor); Groot, Koen (mentor); Delft University of Technology (degree granting institution)","2019","Recall that the first aim of this thesis was to assess whether we can derive bi-orthogonality relations demonstrating that the adjoint LST eigenvectors are orthogonal to the direct eigenvectors, for both the compressible and incompressible LST equations; thereby resolving the non-orthogonality complication. It is to that end that we derived the adjoint operators for the incompressible and compressible LST equations using both the discrete and the continous approach in chapter 3. Subsequently, we derived, implemented and assessed bi-orthogonality relations using the adjoint eigenvectors resulting from the discrete and continous approaches in chapter 3. It was found that theoretically relations can be derived for which a weight matrix ensures bi-orthogonal sets of direct and adjoint eigenvectors. Numerical implementation of these biorthogonality relations for both the incompressible and compressible LST yielded diagonal biorthogonality coefficient matrices for the discrete case. Results for the continous approach have shown that the coefficient matrices are diagonally dominant, but do contain substantial offdiagonal terms. As per the theoretical bi-orthogonality derivation, the complex conjugates of the adjoint eigenvalues were shown to match the direct eigenvalues in the physically interesting range, for both the incompressible and compressible LST spectra. The discrete and continous adjoint eigenmodes were found to be similar in shape and location, but the modes did not coincide. A potential explanation for the discrepancy might be the use of the Chebyshev collocation nodes in the continous adjoint EVP. The adjoint EVP may require different stretching of the mesh. Alternatively, closing the continuous adjoint system using the ’adjoint wall-normal equation’ as a compatiblity condition for the adjoint pressure amplitude might possibly adversely affect the continous adjoint eigenmodes. An interesting observation was made when considering the spatial structure defining the overlap between direct eigenmodes and discrete adjoint eigenmodes. For both a wall mode, and a ’middle region’ mode, the location of the maximum amplitude of the direct eigenmode was found to differ spatially from that of the maximum amplitude of the discrete adjoint eigenmode.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:8facf33f-2224-4418-bea9-4ffcfbca0c21","http://resolver.tudelft.nl/uuid:8facf33f-2224-4418-bea9-4ffcfbca0c21","Highly Automated Driving: Transitions of control authority using Haptic Shared Control","van Dintel, Kevin (TU Delft Mechanical, Maritime and Materials Engineering)","Abbink, David (mentor); Petermeijer, Bastiaan (mentor); de Vries, Edwin (mentor); Plettenburg, Dick (graduation committee); Delft University of Technology (degree granting institution)","2019","The arrival of highly automated vehicles introduces a new interaction between the vehicle and driver. System limitations during highly automated driving require the driver to be ready to take back control at request.<br/>Previous studies on the take-over process concluded that the driver requires a transition period to stabilize vehicle control after resuming manual control. These studies used traded control to instantaneously transfer control back to the driver, causing an abrupt switch in control authority. Therefore, this study explores Haptic Shared Control as a different transition approach. By varying the level of haptic authority, a smooth connection between automation system and driver can be realized. The aim of this study is to investigate if Haptic Shared Control improves the take-over performance compared to the traded control approach. A total of 30 participants drove two trials in a driving simulator, one for each transition approach. Each trial consisted of 10 take-over scenarios divided into two levels of time-criticality. During autonomous driving the participants were engaged in a secondary task. The take-over performance was assessed based on safety performance, lateral vehicle control, controller performance and subjective measures.<br/>Results showed a significant decrease in the standard deviation of the lateral position evaluated over the mean trajectory per participant for the Haptic Shared Control approach compared to traded control. Haptic Shared Control also showed a significant decrease for the mean lateral obstacle clearance. The analyses on torque conflicts revealed a significant increase for critical take-over maneuver compared to non-critical take-over maneuvers. <br/>This suggests that haptic shared control can assist the driver in stabilizing lateral vehicle control after resuming manual control. On the other hand, the driver is limited in performing a sharp evasive maneuver, and this relationship is discussed. More research is needed on using an adaptable human compatible reference.<br","autonomous driving; control transitions; Haptic shared control; driving simulator","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Vehicle Engineering","",""
"uuid:fd9de39b-2f6b-45d7-94a6-5b5754497a61","http://resolver.tudelft.nl/uuid:fd9de39b-2f6b-45d7-94a6-5b5754497a61","Iterative Bias Estimation for an Ultra-Wideband Localization System","van der Heijden, Bas (TU Delft Mechanical, Maritime and Materials Engineering)","Grammatico, Sergio (mentor); Kober, Jens (graduation committee); Ferranti, Laura (graduation committee); Kok, Manon (graduation committee); Delft University of Technology (degree granting institution)","2019","Three bias estimation frameworks are presented that mitigate position-dependent ranging errors often present in ultra-wideband localization systems. State estimation and control are integrated, such that the positioning accuracy improves over iterations. The frameworks are experimentally evaluated on a quadcopter platform. Two state augmentation frameworks show that the anchor placement has a significant influence on the observability of the problem. A third framework circumvented any observability issues by using a classifier. This framework performed best as it improves the tracking performance with respect to ground truth, and also smoothens the overall flight by significantly reducing unwanted oscillations; see https://youtu.be/J-htfbzf40U for a video.","Ultra-wideband technology; adaptive observer design; Bayesian methods; sensor fusion; recursive least squares; classification; non line-of-sight","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:b2bdeb70-027a-40cc-b941-46269321f79f","http://resolver.tudelft.nl/uuid:b2bdeb70-027a-40cc-b941-46269321f79f","Seismic liquefaction analysis of a critical facility with PM4Sand in Plaxis","Portugal Quevedo, Hugo (TU Delft Civil Engineering and Geosciences)","Sigaran-Loria, Carolina (mentor); Brinkgreve, Ronald (mentor); Doeksen, Jan (graduation committee); Pisano, Federico (graduation committee); Hicks, Michael (graduation committee); Delft University of Technology (degree granting institution)","2019","In seismically active areas, liquefaction hazards have always been a complicated aspect to evaluate as part of the seismic design of a project. In the case of the design of critical facilities, this becomes crucial, as beyond design basis conditions may elevate the seismic loads significantly and create a considerable liquefaction risk in areas of deep alluvial deposits. Furthermore, traditional semi-empirical methods lose their applicability at depths larger than 15 m, which becomes problematic if one wishes to analyse the liquefaction hazard of deep Holocene deposits. Given this shortcoming and the rapid growth of numerical tools available for geotechnical earthquake engineering, the use of liquefaction-predicting constitutive models, like PM4Sand, provides the opportunity to obtain more accurate and physically-consistent results. For this purpose, this research is divided in three main parts. The first part covers the study of the onset of liquefaction with the use of two cyclic undrained direct simple shear test databases and the identification of liquefaction-triggering criteria, in terms of pore pressures and shear strains which can consistently define a liquefied state in sands. The second part includes the thorough analysis of the capabilities of the PM4Sand model, in Plaxis, through a benchmark calibration study using one of the previously mentioned laboratory test databases, concluding in the proposal of a modified calibration methodology based on pore pressure ratio (ru) and shear strain (γ) liquefaction-triggering criteria. The third and last part covered a practical case study oriented towards the design of a critical facility, where a beyond design liquefaction hazard analysis of a hypothetical site was evaluated incorporating the findings from the previous parts. A one-dimensional liquefaction hazard analysis was performed using a single earthquake signal and soil profile, where the consistency of the PM4Sand model in terms of liquefaction-triggering was evaluated and the numerically-obtained results were compared to those calculated through one semi-empirical method. Additionally, the one-dimensional model was extended and a two-dimensional liquefaction hazard analysis, including the presence of a simplified structure, was performed with the aim of evaluating the effects of soil-structure interaction and structural load variation on the liquefaction hazard of the soil profile over distance.","PM4Sand; Liquefaction; Site Response Analysis; Plaxis 2D; Soil-structure interaction; Earthquakes; Earthquake-induced liquefaction; Calibration methodology","en","master thesis","","","","","","","","","","","","","",""
"uuid:babc46a3-1399-452d-9550-d73f4673648e","http://resolver.tudelft.nl/uuid:babc46a3-1399-452d-9550-d73f4673648e","Steel weight reduction in offshore wind jacket structures by wrapped FRP joints","van Vliet, Marc (TU Delft Civil Engineering and Geosciences; TU Delft Mechanical, Maritime and Materials Engineering)","Pavlovic, Marko (mentor); Steeneken, Peter (graduation committee); Vergassola, Marco (graduation committee); Delft University of Technology (degree granting institution)","2019","This report investigates the potential reduction of steel weight for offshore wind turbine supporting jacket structures, if conventional welded joints are replaced by innovative wrapped FRP joints. This new type of connection is under development by Dr. Marko Pavlovic at the Delft University of Technology, and shows outstanding fatigue performance compared to welded counterparts. As jacket structures suffer highly cyclic load, member thickness of current jackets is governed by the fatigue performance of welds. Due to the superior fatigue performance of wrapped FRP joints, substantial weight benefit is expected to be made. The study examines a jacket supported 5 MW wind turbine located in 50-meter water depth in the North Sea. The structure and model are based on the UpWind project. The model includes soil-structure interaction by non-linear depth-dependent springs along with foundation piles. Fatigue limit state (FLS) and ultimate limit state (ULS) are simulated by respectively five and three scenarios. The scenarios consider different combinations of wind (speed and direction), waves (height, period and direction) and current (speed and direction). Six 10-minute simulations are performed for each scenario with different wind turbulence and wave irregularity seeds. Wind and waves are applied in a single simulation, and normal force N and bending moments Mip and Mop time series are recorded at a selection of elements. The time series are post-processed in a self-written MATLAB procedure. For FLS, detailed fatigue analyses of welded joints are performed by evaluating crown and saddle hotspot stress, according to DNVGL-RP-C203. For every time step, the hot spot stress is calculated by applying geometry and load-dependent stress concentration factors (SCFs). Rainflow counting is applied, and the resulting stress range is projected on the details’ S-N curve to evaluate the damage. Linear Palmgren-Miner is applied to accumulate damage. A similar procedure, including stress concentration at thickness transition, is applied to calculate fatigue of elements. For ULS, welded joints are checked for chord face and punching shear failure. Members are checked for tension yielding, local buckling and global buckling. ULS calculations are performed for all time steps and according to Eurocode manuals. The unity check of both FLS and ULS is calculated for each individual member. Next, the member thickness is manually optimised to obtain the most optimal use of material. This optimisation is performed for three different cases with both mild S355 steel and high strength S690 steel. The welded steel structure, case 1, acts as a reference. The unwelded structure, case 2, is the lightest structure if joint fatigue does govern design. Case 3 gives the wrapped FRP structure and includes fatigue results obtained from small scale lab tests. Additionally, due to limited production length of steel tubular elements, it includes circumferential welds in the legs. The potential jacket weight reduction if wrapped FRP joints are applied is large, and the governing unity check shifts from fatigue to global buckling. For mild steel, the reduction of steel weight is more than 50%. The additional reduction of mass for high strength steel is low and not economical. The eigenfrequency of the wrapped FRP structure is viable, as it is outside operating frequencies. The results for the wrapped FRP structure are based on two major assumptions. Firstly, satisfactory joint performance can be obtained, and secondly, this can be accomplished by increasing wrapping thickness only. These assumptions should be verified by future experiments to support the weight reduction statement. In conclusion, the potential benefit of wrapped FRP joints to offshore wind turbine supporting jacket structures is large, and future experiments will show if, or to what extent, the full potential can be exploited.","wrapped FRP; FRP; joint; offshore; wind; Jacket; Jacket structure; Steel; steel reduction; Offshore Wind; innovative","en","master thesis","","","","","","","","","","","","","",""
"uuid:89404b46-5a11-4961-a6ec-6c7afa685d65","http://resolver.tudelft.nl/uuid:89404b46-5a11-4961-a6ec-6c7afa685d65","Design a roadmap and a digital product for the future boarding process","Wang, Qiong (TU Delft Industrial Design Engineering)","Beets, Margreet (mentor); Kuipers, Henk (graduation committee); Delft University of Technology (degree granting institution)","2019","This project is about digitalising the boarding process in the future context for KLM. This project has four phases: Research by explore the context and understand the stakeholders, Define the future vision and roadmap, Design a digital interface for the first horizon in the roadmap and lastly evaluation of the digital prototype. In the research phase, multiple research methods were conducted. The research phase has two parts, understanding the process and understanding the user. To get a thorough understanding of the process, internal documents reading, observation and expert interviews were conducted. After these research activities, the first list of problems was made, based on my personal perceiving. Afterwards, to understand how the stakeholders think about current process and tools, and also what is their desired future, more research was done with the three stakeholders: gate agents, managers and passengers. According to the results, the list of problems was revised adding the problems agents perceived. Besides the list of problems, a main problem was redefined for later design phase. In the second phase, a vision in five years were come up with, with three horizons step by step. The vision was designed considering all the different visions from different stakeholders and aiming at solving the main problem from research phase. Based on the vision and trends analysis, a cocreation session was conducted with four students, to generate ideas in this scope. Later, the ideas were mapped and divided into three horizons according to the importance and feasibility. The third phase started from looking deep into the first horizon in the roadmap. A design brief and a list of requirements were designed, under the context of the first horizon. Ideas were generated and finally two concepts were designed. After validating the two concepts with experts (two gate agents and a shiftleader), one concept was chosen for iteration. And iteration was made based on experts’ feedback. Later on, a high-fidelity interactive prototype was made to describe the functions and to prepare the final user test. The last phase is user test and evaluation. Five gate agents as well as two service agents were recruited randomly to the test. Due to technical limitation, participants were asked to pretend to work using the prototype and give feedback about the design. Based on the interviews and questionnaires, the data analysis was conducted. The result shows that agents rate a high score for the user experience of the new prototype. The prototype is regarded as supportive, proactive and in control in general. Based on the feedback from the user test, improvements were made to finalize the design. Moreover, the conclusions were drawn for the whole project and recommendations were provided for the company.","Design for future; boarding experience","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:65a175b0-0a18-406a-b51b-f9935aca23a8","http://resolver.tudelft.nl/uuid:65a175b0-0a18-406a-b51b-f9935aca23a8","Primitiveren met elementaire functies","Vonk, Maarten (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Applied Sciences)","Hart, Klaas Pieter (mentor); Coplakova, Eva (graduation committee); van Elderen, Emiel (graduation committee); Delft University of Technology (degree granting institution)","2019","In dit bachelor eindproject kijken we naar de integreerbaarheid van eindige elementaire functies. Soms heb je het vermoeden dat een functie geen primitieve heeft in eindige termen, maar dan is dat vaak lastig om te bewijzen. Aan de hand van de stelling van Liouville-Rosenlicht gaan we in een aantal van zulke gevallen bewijzen dat de gevraagde primitieve niet bestaat. Je kunt er in dat proces ook achter komen dat de functie toch wel zo'n primitieve heeft. Dan krijg je met deze stelling vaak ook een aardig beeld van hoe de primitieve er ongeveer uit zou moeten zien. Voor het bewijzen van de stelling van Liouville-Rosenlicht duiken we een stuk de differentiaalalgebra in.","Differentiaal algebra; Integration; Liouville; Rosenlicht","nl","bachelor thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:f9a77112-cbe7-445b-a9fe-36285f3b9381","http://resolver.tudelft.nl/uuid:f9a77112-cbe7-445b-a9fe-36285f3b9381","Structural cast glass-ceramic components: The potential of recycling soda-lime-silica glass into cast glass-ceramic components and its mechanical behaviour","Lei, Cindy (TU Delft Civil Engineering and Geosciences)","Nijsse, Rob (graduation committee); Bristogianni, Telesilla (mentor); Veer, Fred (graduation committee); Schipper, Roel (graduation committee); Delft University of Technology (degree granting institution)","2019","This master's graduation project researches the potential of upcycling waste glass into glass-ceramic components through casting techniques and thermal treatments. To explore its potential and possibilities, the process of crystallization, the material glass-ceramic and influencing parameters are studied at first. A glass-ceramic is a glassy yet crystalline material consisting of inorganic and non-metallic compounds. A glass-ceramic can be produced through different controlled crystallization methods, whereas in this research heat treatment of casted components is applied. Upon heat treatment, crystallization occurs when the right temperatures are applied for the two-steps in crystallization; nucleation and crystal growth. Crystallization may occur spontaneously or along preferential sites, whereas this research makes use of the latter. Many parameters affect the crystallization process, whereas this research only focusses on glass composition, temperature and dwell time. The parameters are set through literature study and trial and error of melting experiments. This research focusses on the crystallization of soda-lime-silica bottle glass, the results of each melting experiment show the effect of the parameters. Each glass from another manufacturing has another glass composition. The amounts of glass formers, modifiers and fluxes are various, resulting in diverse temperature curves and thus diverse melting temperatures and crystallization temperatures. Through the melting experiments are noticeable that the applied melting temperature were of bigger influence than the crystallization temperature. A melting temperature too low resulted in an undesired fused sample, while a too high melting temperature resulted in no or little preferential sites for crystallization to occur. Through the results of the splitting experiment the mechanical characteristics could be observed, which are fracture toughness and fracture behaviour in this research. The fracture toughness seems better of samples with a higher quality crystal polymorph or with a higher amount of crystallinity or high amounts of glassy phases, whereby the material acts as one material upon loading rather than as a composite. While for samples with little and unconnected crystallization it does not seem to benefit its fracture toughness. The fracture propagation through glassy and crystalline phases is very different. A fracture propagation through a glassy phase is conchoidal, while the fracture propagation in the crystalline phase follows the crystalline structure, reaching its extremities or can be conchoidal, depending on the crystal polymorph. Observable from the fracture propagation from glassy to crystalline and from crystalline back to glassy is the discontinuity. The crystal or crystalline surface acts like an obstacle once the failure propagation reaches from the glassy phase. The failure does propagate but once it continues over to the glassy phase again, a change in energy and direction is noticeable. All by all, there do is potential in upcycling waste glass into structural cast glass-ceramic components. Crystallization does influence the fracture toughness and fracture behaviour in a cast glass-ceramic component, but the effect is highly dependent on the amount and distribution of glassy and crystalline phases.","glass; glass-ceramic; cast glass; recycling","en","master thesis","","","","","","","","","","","","Civil Engineering | Building Engineering - Structural Design","",""
"uuid:52ba55e1-fda5-4547-872a-73b69cb95058","http://resolver.tudelft.nl/uuid:52ba55e1-fda5-4547-872a-73b69cb95058","Dynamic modelling and nonlinear model predictive control of a reversible solid oxide fuel cell: for grid-tied power tracking","Schotman, Ronald (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Delft Center for Systems and Control)","Steur, Erik (mentor); Hajimolana, Yashar (graduation committee); Delft University of Technology (degree granting institution)","2019","The primary objective of this work is to research and develop a dynamic model and an advanced control strategy for a reversible solid oxide fuel cell in a grid to ensure load tracking whilst maintaining fuel utilisation and temperature dynamics within a safe range. This report presents the successful development of the dynamic model and corresponding controller. To do so, modeling and control are discussed in two separate chapters where model requirements, specifications and conception are presented followed by the control techniques, control objectives and controller synthesis. A RSOFC model has successfully been developed and thoroughly validated against other literature. To do so, a set of fitting parameters has been distilled from literature to create a good overlap with other studies and are combined in a manner that they can be implemented in other work. Steady state dynamics and the transient dynamics have shown a good match to the available literature. Additionally, the model offers useful insights into RSOFC (transient) dynamics with relation to temperature effects, fuel composition and cell support structure, which have not been documented before. At last the RSOFC stack, together with the developed model has been built in a plug-and-play manner that it can be implemented and adjusted by others, to be used in combination with other models. For control an output-feedback adaptive nonlinear model predictive controller has been developed, which is an advanced version of the well established (non)linear model predictive controller. The development of the temperature controller is given wherein the structure of the MPC is presented together with its trajectory, adaptive constraints and tuning variables. After completing the development of the controller, the controller was simulated together with the dynamic model as part of a micro-grid. The simulations were split up into short and long term scenarios and showed satisfactory results as all the set control objectives were achieved.","RSOFC; Control; Modeling; Reversible solid oxide cell; SOFC; SOEC; MPC; NMPC; Adaptive constraint; DCSC; Energy storage","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:51355f59-7a5e-4cd7-b708-45f4c8993386","http://resolver.tudelft.nl/uuid:51355f59-7a5e-4cd7-b708-45f4c8993386","Watermarking for attack detection in networked control systems: comparison between a linear and a nonlinear approach","Mooren, Maurits (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Delft Center for Systems and Control)","Ferrari, Riccardo M.G. (mentor); Delft University of Technology (degree granting institution)","2019","With the increasing amount of information sent in control systems, data is more often communicated through a communication network. These networked control systems use the network to exchange control and feedback signals among the system’s components. Data sent over a network attracts adversaries that try to read and modify this data. These attempts of modifying the data are unwanted and need to be detected. In order to detect these attacks a digital watermark is added to the data in real time. The digital watermark gives the opportunity to check whether the data is authentic. In order to do this, the watermark embedding function is data dependent where the watermark is created from old data points. The selection of which data point is used changes over time and the moment of changing these so called delay parameters is also data dependent. With this information alone an attack can not be detected. Steganography is used to create a signal independent attack detection technique that has a 100% detection rate for the investigated attacks. There are diﬀerent digital watermarking techniques. Echo Hiding and Quantization Index Modulation (QIM) are a linear and nonlinear watermarking technique that have the possibility to be used in real-time. QIM gives a higher level of security while Echo Hiding can be implemented faster and takes less CPU load. QIM removes some of the accuracy of the data and Echo Hiding takes less memory. Both techniques have advantages and disadvantages which are compared and the two techniques are tested on two systems; a standard three-tank system where data (the ﬂuid levels) change slowly over time and a much faster system, the Van der Pol oscillator. Both watermarking techniques detect the replay and reroute attack on both systems 100% of the tested<br/>time.","networked control systems; watermarking; attack detection","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:5ea18657-5ab8-453d-ac9c-690fa13d7415","http://resolver.tudelft.nl/uuid:5ea18657-5ab8-453d-ac9c-690fa13d7415","Adaptive Damper for Tremor Suppression","van der Kort, Hugo (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Biorobotics; STIL B.V.)","Mugge, Winfred (graduation committee); de Lange, IJsbrand (mentor); Delft University of Technology (degree granting institution)","2019","Pathological tremor is currently not adequately treated with medication; it is effective in only 50% of cases and often does not supress tremor more than 60% at the cost of mild to severe side effects. In recent years, mechanical tremor suppression concepts have been developed, but none have thus far been implemented as replacements for current medication. This paper presents a proof of concept adaptive damper for tremor suppression. Results show that the prototype is able to attain a torque difference of 0.05Nm. Furthermore, the results showed that the prototype was capable of varying the damping torque for the same frequency. Finally, experiments showed that the prototype was able to differentiate between frequencies, meaning that the prototype provided a damping torque to an input perturbation only when a pre-selected frequency was present. Future efforts should be focussed towards optimization of components to increase the maximum torque difference. A working orthosis based on this concept could bring us one step closer to providing a stable life for tremor patients around the world.","tremor; variable damper; Orthosis; Essential tremor; Parkinson; Electromagnetic","en","master thesis","","","","","","","","2023-12-20","","","","","",""
"uuid:0b32ea94-5fee-43d5-b7d3-56519e9b9d96","http://resolver.tudelft.nl/uuid:0b32ea94-5fee-43d5-b7d3-56519e9b9d96","Hand gestures as a form of communicating crossing intent from pedestrians to Automated Vehicles","Epke, Michael Ray (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Biorobotics)","de Winter, J.C.F. (mentor); Dodou, D. (graduation committee); Irmak, T. (graduation committee); Delft University of Technology (degree granting institution)","2019","Communication between pedestrians and drivers partially relies on nonverbal communication methods such as eye-contact and gestures. With the transition from manually driven vehicles to automated vehicles (AVs), pedestrians could lose the ability to communicate their intention to the driver. This study investigated the use of hand gestures as a new form of communication from the pedestrian to the AV. Twenty-six participants participated in a Virtual Reality (VR) experiment, in which they wore an Oculus Rift to interacted with AVs in a virtual environment. The movement of the participants was recorded and visualized through the use of a Xsens Link motion tracking suit, which provided the research with data about the hand gesture usage. The main independent variable of this study was the permission for the participant to use hand gestures to try to make the AV yield. The hand gesture increased the probability of the AV stopping for the participant. The second independent variable was the response of the AV through a message on an external-Human Machine Interface (eHMI). The participants went through four different scenarios. Therefore, both one-way communication and two-way communication were investigated in the same experiment. The participants were given the freedom to decide if they wanted to use the hand gesture. Aside from the hand gesture, the participants were asked to perform a forward step at the moment they felt safe to cross the road in the virtual environment, without actual crossing. Alongside the gathered data on movement of the participants, the research also included data gathered from questionnaires in which the participants were asked about their feeling of safety, assurance of being seen by the AV, the effect that the lack of eye-contact had on their decision making, difficulty predicting the behaviour of the AV, and their trust in communication involving AVs and hand gestures. The research found that the participants used hand gestures to communicate crossing intent to the AV around 80% of the time. The ability to use hand gestures did not improve the feeling of safety significantly, and made it more difficult for the participants to predict the behaviour of the AV. The results of the subjective measurements did show positive results for the hand gesture in combination with responses from the AV by the eHMI, as well as for the eHMI alone. It is concluded that participants were willing to use the hand gesture, and that the hand gesture only increased the subjective feeling of safety if the AV responds to the hand gesture via an eHMI.","Automated Vehicles; Hand gestures; eHMI; Two-way communication; Pedestrians; nonverbal communication","en","master thesis","","","","","","","","","","","","","",""
"uuid:9bf85910-4939-4159-968b-ef558a6ecb7c","http://resolver.tudelft.nl/uuid:9bf85910-4939-4159-968b-ef558a6ecb7c","Monitoring Backward Erosion Piping with Self-Potential Geophysics","Gevaert, Joost (TU Delft Civil Engineering and Geosciences)","Slob, Evert (mentor); Ngan-Tillard, Dominique (mentor); Jommi, Cristina (mentor); Wellmann, Florian (mentor); Delft University of Technology (degree granting institution); RWTH Aachen University (degree granting institution); ETH Zürich (degree granting institution)","2019","Backward erosion piping is a dike failure mechanism. It is the internal erosion process by which sand is eroded away from underneath a dike or levee by seepage flow. This erosion process progresses in the direction opposite to the direction of seepage flow and forms a small pipe directly beneath the dike. As erosion continues, this process can lead to dike failure. During this erosion process, the groundwater flow pattern is subject to continuous change, due to the growth of the pipe. Self-potential (SP) monitoring is sensitive to changes in the groundwater flow pattern, because of the electrokinetic coupling between fluid flow and the streaming potential. The SP field due to flow underneath a test dike was modeled with a FreeCAD -&gt; Gmsh -&gt; pyGIMLi workflow. This workflow can also be used to effectively resolve a wide range of standard and customizable geophysical modeling and inversion tasks. After modeling, field experiments were conducted, on the same test dike, to further assess the possibilities and limitations of SP monitoring to track the progress of backward erosion piping. Given that it is essential to have an accurate resistivity model in order to find the location of the SP source, an integrated electrical resistivity tomography (ERT) and SP monitoring system was designed. The electrodes used in this monitoring system were polarizable stainless steel stakes. The reliability of polarizable electrodes was greatly overestimated, as they turned out to give unstable SP measurements. The reason for the inferior reliability of polarizable compared to non-polarizable electrodes, was found through extensive literature research. The reason being that the largest potential in any electrode originates from the contact between the metal and the electrolytes in solution. The metal of polarizable electrodes is in direct contact with the electrolytes in the soil, which have variable concentrations. Therefore, the potential measured fluctuates together with the concentration of soil electrolytes in contact with the metal. The metal of non-polarizable electrodes, on the other hand, is in contact with a solution of its own salt, which has a constant concentration. Finally, piping is not expected to be measurable with SP monitoring, before a large sand boil is visible in the field. Once a positive SP anomaly develops at the sand boil, changes in the SP field due to the growth of the pipe are expected to be too small relative to the SP anomaly associated with water flow through the sand boil. Even though an integrated ERT and SP monitoring system is known to provide useful information about the hydrology of a dike, such a system is not sensitive enough to be able to monitor the development of a backward erosion pipe.","backward erosion piping; self-potential; dike monitoring; flood proof holland; non-polarizable electrode","en","master thesis","","","","","","","","","","","","Applied Geophysics | IDEA League","",""
"uuid:62761562-9bc9-42bf-9532-f1293028cc5e","http://resolver.tudelft.nl/uuid:62761562-9bc9-42bf-9532-f1293028cc5e","Mergers &amp; Acquisitions in Practice: The Road to Success for High-Tech Firms: An Aggregate European Study on the Effect of Mergers and Acquisitions on High-Tech Target Firm Performance","Offerman, Rochus (TU Delft Technology, Policy and Management)","Roosenboom-Kwee, Z. (mentor); Hakvoort, R.A. (graduation committee); Delft University of Technology (degree granting institution)","2019","In the last decade, Mergers and Acquisitions (M&amp;A) activity steadily enlarged, where global deal making continues to rise. While the M&amp;A activity is increasing, it is the technology sector with the fastest growing number of transitions. Even though M&amp;A are widely used for financial research purposes, there is plenty yet to be uncovered, particularly on an aggregate level and privately held high-tech firms. Europe offer a natural lab- oratory to study the determinant and consequences of mergers and acquisitions given essential variations in laws and regulations, institutions, traditions, and economic environments across countries, continents and over time. Interestingly, novel data has become recently available meaning that we can see how privately held target firms in Europe behave before and after the takeover. This thesis report focuses on understanding whether M&amp;A affect target firm’s performance. The analysis is conducted on 689 European high-tech target firms, in which 95.26% are privately held, that were acquired in the period from 2011 to 2017. Target firm performance changes are tested with the inclusion of four key accounting performance indicators (e.g., Return on Assets, Operating Margin, Sales Growth and Net Profit), the difference in Intellectual Property measured by the number of patent applications, and three prominent quantitative research methods (Ordinary Least Square model, the Intercept model, and the Difference-in- Difference model). Including several approaches enhances the findings, overcomes weaknesses of the individual methods and addresses endogeneity concerns. Overall, the results clearly shows that target firms do not benefit from the M&amp;A in terms of performance. In other words, the synergies did not benefit the target firm, whereas multiple potential M&amp;A motives, including diversification, strategic gains, and market power did not lead to a better performance of the target firm. Interestingly, the results indicate that target firms in general tend to under perform to the adjusted con- trol group or their peer firms. The latter implies that acquired firms failed to keep up with the competition and confirm the fact that targets were in need of a way to strategically improve. Further, distinguishing evidence is found between domestic versus cross-border takeovers, whereas domestic deals outperform cross- border deals. Which proves it is easier to transfer assets between parent and subsidiary operating in the same country. Large enterprises perform better after the M&amp;A compared to small and medium enterprises. M&amp;A between SME are more likely to be financed with equity over debt which better process the transaction of tangible and intangible asset what could be in favour of the synergy exploitation’s. Also, findings suggest that large firm are more capable to exploit economies of scope and economies of scale. Firms that enclose a medium or high cultural distance outperform low cultural distance deals an not vice versa. This suggests that, taking into account the fact that bordering countries have similar cultural characteristics, greater cultural dimension between firms expose significant growth opportunities. Precisely be- cause long-distance target firms tend to have benefited substantially from the diffusion of the acquiring firms’ know-how, while taking into account that management and organisational styles are obviously significantly different between the two firms. In addition, target firms from the Anglo-Saxon region outperform target firms from the Rhineland region. Firms with an Anglo-Saxon corporate governance orientated firms conversely, are more likely to adopt strategic innovate projects on exploitation and external development. Whereas Rhineland corporate governance are more likely to adopt internal growth and exploratory as strategic renewal trajectories. Further, no compelling differences in performance are found for M&amp;A in the same industry than across industries. In general, the findings presented in this paper provide new insights, while it also complements existing evidence, and on the other hand it contradicts former claims.","Mergers & Acquisitions; Accounting Indicators; High-Tech; Difference-in-Difference Model; Intercept Model; OLS Model; Privately held target firms; Europe; Innovation; Intellectual Property","en","master thesis","","","","","","","","2020-12-19","","","","Management of Technology (MoT)","",""
"uuid:06760340-3f5b-4fb8-9342-12c708f30c2e","http://resolver.tudelft.nl/uuid:06760340-3f5b-4fb8-9342-12c708f30c2e","Direct Air Capture: Characterization and design of a novel absorption process","Sinha, Mrigank (TU Delft Mechanical, Maritime and Materials Engineering)","Goetheer, E.L.V. (mentor); Delfos, R. (graduation committee); van Kranendonk, J. (graduation committee); Delft University of Technology (degree granting institution)","2019","Rising concentration of CO2 in the atmosphere has become a significant concern, paving the way for worldwide research on mitigation techniques like carbon capture and storage (CCS) and carbon capture and utilization (CCU). Zero Emission Fuel (ZEF), an aspiring startup based in the Netherlands, aims to develop a micro plant that produces methanol from just solar energy and air. Their process involves capturing CO2 and H2O directly from the air, splitting H2O to obtain H2 and producing methanol by reacting CO2 with H2. The focus of this research is on the absorption process of ZEF's direct air capture unit. Instead of capturing CO2 and H2O through a widely used batch direct air capture process, ZEF chooses to side with a novel continuous absorption and desorption process involving a flow of bulk polyamines without any conventional support structures. Polyethyleneimine (PEI-MW-600) and Tetraethylenepentamine (TEPA) are used as absorbents to achieve a target of capturing 825 grams of CO2 in 8 hours every day from a single direct air capture unit. Preliminary investigations show that the viscosity of PEI-600 is significantly higher than that of TEPA. An increase in CO2 concentration increases the viscosity of both polyamines significantly. In comparison, increasing H2O concentration leads to a maximum viscosity point in both polyamines and subsequent decrease in viscosity with a further increase in H2O concentration. Although, compared to CO2, H2O has a smaller effect on viscosity. Moreover, premixed samples of PEI-600 and TEPA with H2O show an increase in the CO2 absorption rate when pure CO2 is bubbled through the samples. In order to study and characterize the novel absorption process, an experimental setup facilitating a flow of absorbent is developed, and experiments are conducted following an experimental approach to calculate the mass transfer rates and average concentrations of CO2 and H2O. Fourier-transform infrared spectroscopy is used to estimate these concentrations. Experiments are performed on different initial concentrations of PEI and TEPA. TEPA is found to have a better absorption performance with an average CO2 absorption rate that is two times higher than PEI-600. Contrary to preliminary investigations done by bubbling CO2 into polyamines, absorbents with premixed water flowing down a channel were found to have lower CO2 absorption rates than pure polyamines. A multiple regression viscosity model, heat model, and a model of absorption column is developed using the data collected to estimate average viscosity, the heat of absorption of water, and characteristics of the absorption process. Diffusion of CO2 through the absorbent layers is found to be the primary limiting factor, while mass flow rates of absorbent and air are also found to influence the absorption process. Finally, a design of the absorption column is made to meet ZEF's requirement taking into account various performance characteristics studied during the thesis.","Direct air capture; Absorption; PEI; TEPA","en","master thesis","","","","","","","","2022-12-20","","","","","",""
"uuid:88d68c0a-76de-48d0-8310-2902de6280c8","http://resolver.tudelft.nl/uuid:88d68c0a-76de-48d0-8310-2902de6280c8","Techno-economical design study for a sustainable power station powered by simultaneity of wind, solar, and an integrated Li-ion battery","Brouwer, Patriek (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Delft University Wind energy research institute)","Bierbooms, W.A.A.M. (mentor); Verzijlbergh, R.A. (graduation committee); Savenije, Rens (graduation committee); Watson, S.J. (graduation committee); Delft University of Technology (degree granting institution)","2019","Our present-day society is utterly dependant on electricity. This dependence will only grow as electrification of sectors such as manufacturing, transportation and building heating takes off. Most of the electricity these days comes from conventional plants running on coal and natural gas. Despite that these are reliable and cheap, the disadvantage of emitting greenhouse gases is no longer acceptable. Sustainable alternatives such as solar PV and wind have the highest potential. However, the replacement of conventional power plants by sustainable alternatives is subject to understanding the intermittent and unpredictable behaviour of both wind and solar PV and thereby ensuring that generation equals demand at all times. Energy storage technologies allow for separation between generation and supply to the grid. The aforementioned makes the large-scale integration of wind and solar PV more difficult. This study lays the foundation for an interconnected system model where solar PV, wind, and battery storage is combined. This study is therefore deliberately different than existing studies focussing on small, already severely constrained systems, such as island systems. The problems experienced and possible solutions are first identified by conducting a literature review and simultaneity analysis of wind and solar PV power. It turns out that it is possible while being self-reliant, using all the potential renewable energy and shifting the generation by arbitrage on the APX market to design a system with an increasing rate of income. The simulations showed that when the combined generation (of both wind and solar PV) during peak availability is higher than the grid connection capacity, the computed battery size [MWh] increases rapidly, causing a swift decrease in rate of return. This research also shows that with current imbalance settlement prices and battery installation cost minimizing imbalance is less viable than arbitrage on the APX market. The presented results are consistent with how the electricity system currently operates. At last, the results indicate that curtailing ’cheap’ solar PV energy with significant overplanting on the existing limiting grid connection is beneficial. In this research some important steps have been taken towards the design for a grid-connected optimal system. The method proposed should be tested with more wind and solar PV generation data. Further research should consider longer periods with real generation data making the results presented more accurate.","Optimization; Hybrid System; Solar; Wind; Battery storage; Energy integration; Electricity market; Grid connection capacity limitations","en","master thesis","","","","","","","","2022-12-20","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:6d80fd85-393b-4827-80dd-916f02b50e01","http://resolver.tudelft.nl/uuid:6d80fd85-393b-4827-80dd-916f02b50e01","Analyzing gray matter differences in age-related hearing loss using multivariable linear regression and deep learning","Adank, Marloes (TU Delft Mechanical, Maritime and Materials Engineering)","Niessen, W.J. (mentor); Bron, Dr. E. E. (mentor); Croll, P.H. (mentor); Vernooij, Prof. dr. M. W. (mentor); Goedegebure, A. (mentor); Delft University of Technology (degree granting institution); Erasmus Medical Center (degree granting institution)","2019","Objective: Recent studies have suggested an association between age-related hearing loss and cognitive decline. Yet, the underlying mechanism explaining this relation remains unknown. In this regard, several studies investigated gray matter (GM) differences in age-related hearing loss but presented inconsistent results regarding the association and regions involved. To our knowledge, a data-driven approach for exploring this association has not been performed. Therefore, we aimed to investigate possible GM differences and regions involved in age-related hearing loss using conventional multivariable linear regression and deep learning. Methods: Within the population-based Rotterdam Study, 2070 participants (mean age: 65.5 years) underwent pure-tone audiometry to quantify hearing thresholds (hearing loss [&gt; 40 dB], n=205; normal-hearing controls [&lt; 20 dB], n=822). Magnetic resonance (MR) imaging was performed to obtain GM volumes of the superior temporal and precentral gyrus, and GM modulated images. Using multivariable linear regression we investigated the associations between age-related hearing loss and GM volume in the superior temporal and precentral gyrus. A convolutional neural network (CNN) was trained to classify hearing loss and normal-hearing controls based on GM modulated images of the whole brain and the region around the superior temporal gyrus. Visualization of relevant features for the classification was performed with gradient-weighted activation mapping (Grad-CAM).Results: We found that age-related hearing loss was significantly associated with smaller GM volumes in the right hemisphere of both the superior temporal gyrus (difference in standardized brain volume per dB increase: -0.006 [95$\%$ CI: -0.010, -0.003]) and precentral gyrus (difference: -0.005 [95$\%$ CI: -0.008, -0.001]). The CNN classification performance ranged between 0.89 and 0.96 area under the receiver-operating characteristic curves. Analysis of relevant features for the classification showed that features were not specific to the superior temporal gyrus or primary auditory cortex, but appeared across the whole brain. Furthermore, we noticed that misclassified subjects were significantly related to age. Conclusion: This study shows that age-related hearing loss is related to both GM volume in the superior temporal and precentral gyrus. Moreover, relevant features for the classification of age-related hearing loss were observed across the whole brain. These results may be explained by a third factor affecting both hearing loss and neurodegeneration. As age likely is the third factor involved, a longitudinal study design or age-matched groups are required in further studies on age-related hearing loss.","deep learning; brain differences; age-related hearing loss; multivariable linear regression","en","master thesis","","","","","","","","2025-03-15","","","","Biomedical Engineering | Medical Physics","The Rotterdam Study",""
"uuid:cb104e27-892b-4fc5-a32f-201e57c695b9","http://resolver.tudelft.nl/uuid:cb104e27-892b-4fc5-a32f-201e57c695b9","The interface shear anchorage of the U-Bahn weight-saving floor system","Peulen, Stephan (TU Delft Civil Engineering and Geosciences)","Lukovic, M. (mentor); Hendrix, Max (graduation committee); Lagendijke, Paul (graduation committee); Delft University of Technology (degree granting institution)","2019","The U-Bahn floor system is an innovative weight-saving floor system that consists of a prefabricated floor and a structural screed. To connect these two layers, only lattice girders are applied. This means that all stresses in the complete floor system must be taken up by these lattice girders. The U-Bahn floor system is built without propping, a feature that speeds up the building process enormously. Therefore, all building phase depend on each other and together determine the capacity in the use phase. However, to correctly determine the capacity in the use phase, all stresses need to be determined per building phase. The capacity of the correctly anchored lattice girders must after all withstand these stresses. The aim of this research is to find out whether the lattice girders can resist the shear stresses of the U-Bahn floor system. The following research question has been drawn up: In which way does the design of the interface shear of the U-Bahn weight-saving floor system sufficiently anchorage the structural screed? To answer this question, extensive research was first conducted into the various building phases of the U-Bahn floor system. The stresses and forces for each phase individually were calculated. Subsequently, it is examined which type of lattice girder is usable in the U-Bahn floor system and how this type is incorporated in the floor. The stresses that these lattice girders must resist and transfer, have been calculated by means of two methods, an analytical calculation and finite element analysis calculation. As there is no product standard for the U-Bahn floor system yet, the calculations are based on the Eurocode and the floor plank standard. The results of the analytical calculation regarding the anchoring of the lattice girder showed the following : (i) the connection reinforcement, according to the floor plank standard, is sufficient, (ii) the shear force, according to the Eurocode, is not sufficient and, (iii) the detail requirements, as described in the Eurocode, have not been met. The results of the analytical calculation regarding the interface shear capacity of the total floor system shows that the resistance of the lattice girder in the U-Bahn floor system is lower than the acting stresses in the use phase, which results in a unity check of 1.40, which exceeds the maximum unity check of 1.0 as given in the Eurocode. To verify the analytical calculation and to determine to what extent the anchoring of the lattice is insufficient, the floor has been modelled in the finite element program, Diana. Due to the complexity of the program and the calculation, it has been decided to use a linear analysis for the calculation of the different phases of the U-Bahn floor system. Due to this, no result of the crack width and redistribution of the forces in the floor can be given. Nevertheless, the results do show that the concrete cannot take up the calculated stresses, which suggests that the floor will crack. Future research can further investigate the limits of the U-Bahn floor system by means of a non-linear calculation in a finite element analysis. In this non-linear calculation, the factors, deflections, creep and shrinkage must also be included, since this research has shown that these are co-determining factors for the interface shear capacity of the floor. These results will then have to be verified with destructive tests. Finally, if the results are confirmed, they can be converted into a rule-of-thumb, in order to facilitate tenders in the future.","","nl","master thesis","","","","","","","","2021-01-01","","","","Civil Engineering | Structural Engineering","",""
"uuid:e4b77ba7-fe0d-4afa-9e2d-4360360cf8b9","http://resolver.tudelft.nl/uuid:e4b77ba7-fe0d-4afa-9e2d-4360360cf8b9","Reliability Updating of Sheet Pile Walls: An analysis on the parameter updating process","Büller, Jeroen (TU Delft Civil Engineering and Geosciences)","de Greef, Jos (mentor); Vardon, P.J. (mentor); Brinkgreve, R.B.J. (graduation committee); Schweckendiek, T. (graduation committee); Delft University of Technology (degree granting institution)","2019","Throughout the years the requirements of sheet pile walls have changed. Therefore reassessment of these structure's reliability is of importance. In this thesis, Bayesian updating is used for the reliability updating task. Updating processes require measurements of the structure under known conditions. Although for practical and economical reasons failure measurements of structures are seldomely available. Therefore the research focusses on whether it is possible to update a sheet pile wall's reliability using service domain measurements instead. Parameter updating methods generally return the statistically most likely parameter values for producing the observations. Using a theoretical sheet pile wall case, it is tested if the Bayesian updating method is able to effectively return the true soil parameter values as the most likely parameter set. The results show that the Bayesian updating method is very capable of approaching the used observations with the updated model response. Also the updated values of the most influential parameters show evolution in the direction of their true values. But the method does have difficulties with returning the true soil parameter values, even when applied to a theoretical case and with the use of elaborate observation configurations. Recommendations are given on further research concerning the use of the Bayesian updating method, the different influences on its performance and method application limitations.","reliability; updating; Bayesian; sheet pile wall","en","master thesis","","","","","","","","","","","","Geotechnical Engineering","",""
"uuid:85729e1f-214b-4c87-9747-ed08371637bc","http://resolver.tudelft.nl/uuid:85729e1f-214b-4c87-9747-ed08371637bc","Divide and Clean: Multi-Constrained Edge Partitioning and its Application in Debris Management","Vogels, Lucas (TU Delft Electrical Engineering, Mathematics and Computer Science)","Keskinocak, Pinar (mentor); Aardal, Karen (graduation committee); Delft University of Technology (degree granting institution)","2019","Let G=(V,E) be a connected undirected graph, where every edge has two weights assigned to it. This thesis considers the partitioning of the edge set E of G into subsets with three objectives in mind: i) balance the total amount of the first weight among the subsets, ii) balance the total amount of the second weight among the subsets and iii) create a non-chaotic partition. Here non-chaotic means that every subset forms a distinguishable and compact subgraph. We call this Unrelated Unconnected Multi Constrained Graph Partitioning, or UUMCGP. It has applications in the collection of debris after natural disasters and in the assignment of tasks to computers in a distributed network. We are the first to define UUMCGP and we show that for specific cases close-to-optimal solutions can be obtained in polynomial time. Moreover, an algorithm is developed that gives good approximate solutions to the general case of UUMCGP. The algorithm is tested on real-life cases of debris management and gives better results than commercial solvers when they are set to find the optimal solution.","graph partitioning; debris management; multi-resource generalized assignment problem; edge partitioning","en","master thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:90874db6-1123-40d7-b00f-e31ee0781ef5","http://resolver.tudelft.nl/uuid:90874db6-1123-40d7-b00f-e31ee0781ef5","The effects of upcoming emission regulations on the selection of suitable prime mover combinations for the future harbour/terminal Rotortug: A decision-support tool","Karanasios, Alexandros (TU Delft Mechanical, Maritime and Materials Engineering)","Frouws, Koos (mentor); van Hassel, Edwin (graduation committee); Hopman, Hans (graduation committee); Atasoy, Bilge (graduation committee); Delft University of Technology (degree granting institution)","2019","Nowadays the interest for environmental issues is steadily gaining ground. Inescapably, the shipping industry, is also called to contribute its fair share towards the reduction of air pollution. Harbour tugboats need to comply both with international but also with local exhaust air emission regulations, which are anticipated to become more stringent in the future. Kotug, is interested to proactively explore suitable powering solutions, which can be applied at its Rotortugs’ newbuilding scheme, to comply with upcoming regulations of the intended port of operation. The goal of this thesis is to develop a decision-support tool to facilitate the selection process between alternative prime mover combinations, based on what is needed in terms of operation while considering technical challenges, environmental performance and economic returns. The effect of a variety of promising alternative fuels matched with suitable prime movers was investigated for the period 2018-2033, which was set as the study’s time horizon. LNG, Methanol, Biodiesel and DME were assessed as feasible solutions. The first two were associated with gas-burning engines, whereas the rest were associated with conventional 4-stroke compression ignition engines, similar to the ones already installed in the existing Rotortugs running on MGO. The environmental performance differs substantially to a conventional prime mover running on MGO. However, to adhere to future stricter regulations in certain sea areas, additional after-treatment systems are necessary. Research indicated three post-treatment solutions are the most effective in limiting the majority of the combustion-related emissions; Selective catalytic reduction, diesel particulate filter and oxidation catalysts. The total environmental fingerprint of a vessel can be however assessed only under the context of its propulsion configuration layout. The operational profile of a tugboat is highly variable, allowing room for the exploitation of different drivetrains than the traditional diesel-direct layout, which could lead in benefits mainly in terms of fuel efficiency and maintenance savings. Three drivetrains were selected; a diesel-electric and two hybrid, based on AC and DC topology. Before deciding to invest on a future boat a ship-owner is expected to be eager to comprehend the cost-related issues between alternatives. Moreover, the already proven design of the diesel-direct Rotortug, complemented by the necessary after-treatment technologies, makes sense to be the first option to consider, provided it complies with the anticipated regulations. This option is considered the baseline case. It is reasonable to compare all other options against the baseline case. To this end, a decision framework based on a techno-economic evaluation is proposed for supporting ship-owners to take informative decisions on investment considerations; Three objectives were set; economic performance, environmental performance and cost-effectiveness. To quantify economic performance a comparative TCO analysis was implemented, while for environmental performance the emission output of alternatives is compared. Last, cost-effectiveness adds valuable insight into how good money are allocated towards emission reduction targets and provides a methodology to compete for funding from a regulatory authority. Two case studies are presented that demonstrate the utility of these methods and enhance the understanding of the impact of decisive factors in decision-making. It is concluded that the proposed decision-support tool enables decision-support at an early-stage; nonetheless can still be improved, by incorporating additional factors and expanding certain modules with more details.","TCO; GRA; propulsion concept; Prime mover; Decision support tool; decision making; Techno-economic analysis; alternative fuels; after-treatment systems; Cost-effectiveness; emissions reduction potential; Emissions","en","master thesis","","","","","","","","2024-12-01","","","","Marine Technology","",""
"uuid:7ee5f674-c597-47da-9352-d6c37e7bca55","http://resolver.tudelft.nl/uuid:7ee5f674-c597-47da-9352-d6c37e7bca55","The dynamically expressive dress: “Non verbal expression of emotions through desirable Techno-Fashion”","Out, Hugo (TU Delft Industrial Design Engineering)","Jepma, Erik (mentor); Jansen, Kaspar (graduation committee); Rokegem, Jasna (graduation committee); Delft University of Technology (degree granting institution)","2019","How do we express and experience body language, and how can we translate that into an application of Techno-Fashion that is desirable and understandable, for the wearer and his/her environment? How can this application provide an alternative for the current use of regular clothing? Through research about current expressive behaviour through clothing, it was found that there is a desire for an outfit that can dynamically change according to ones mood. Through the Vision in Product Design method, a future context has been created: In a world where technology enables clothing to be dynamically expressive, an application of Techno-Fashion makes people feel more comfortable when expressing themselves, offline, and helps with the human value in interacting. The designed garment is a dress that is able to change its aesthetics according to the expressive desire of its wearer. When the user finds herself in a social setting with a moderate expressive atmosphere, she can choose to change the expressive aesthetics of the dress to being subtle. When being in a more outgoing atmosphere, she can change the dress aesthetics to expressive. The dress makes use of fiber optic wires, LED’s and miniature motors to change the hues and silhouette of the dress. In the end the design proves to be a credible alternative for current expressive behaviour through clothing, and it provides a design that creates a deeper connection with its wearer.","Techno-Fashion; Emotion expression; Emerging materials","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:2d7ae85a-aa2a-462b-8a03-09332febe689","http://resolver.tudelft.nl/uuid:2d7ae85a-aa2a-462b-8a03-09332febe689","Design optimization of an adjustable Pre-Piling-Template: for wind-turbine installation","Ruijgrok, Reinier (TU Delft Mechanical, Maritime and Materials Engineering)","Hoving, Jeroen (mentor); Sliggers, Frank (mentor); Delft University of Technology (degree granting institution)","2019","The demand for a substantial increase in renewable energy causes the need for more and bigger wind turbines. To counter the problem of available space, windfarms will move into deeper water. The challenge of deeper water in combination with higher turbines, require new developments in the wind industry. The often used monopiles make way for a new jacket-founded windturbine. Installation of these type of structures opens a market for a so called Pre-Piling Template.<br/>This thesis aims to analyze the adjustability of the Pre-Piling Template for windturbine installation based on quasi-static calculations. <br/><br/>First a number of conceptual designs of a versatile adjustable Pre-Pilling Template are made. A wide variety of configurations is configured. The complicated part of the design is that the Pre-Piling Template must be viable for a three-legged and four-legged configurations with several centre-to-centre distances. Thereby, it should be possible to convert the entire system on deck of a vessel during given offshore conditions. From eleven concepts a selection of two alternatives has been made, based on listed criteria by the client: Robustness, Adjustability, Financial costs and Safety.<br/><br/>For two selected cross-centre alternatives a global structural analysis is performed under environmental loading. One cross-centre is a composed cross centre, with which a three- and four-legged configuration can be installed with the same cross-centre mid-frame of the PPT. The other alternative consist of two separate mid-frames, one for a three- and one for a four-legged configuration. To speed up the installation process, primarily all the piles to be installed will be stabbed into the Pre-Piling Template. After all piles have been stabbed into the frame, the hammering procedure will start. When all piles are stabbed significant forces arises from wind and especially hydrodynamic actions. The static deformations of the template induced during the multiple installation steps can cause overall displacements of the centre of each particular sleeve. <br/><br/>The added value of a Pre-Piling Template is the installation speed versus the required accuracy of the pile installation. A high installation speed only makes sense if piles can be installed within the required tolerances. Therefore the deformations of the frame and the corresponding displacements are governing. To determine the displacements, a 3D-model is constructed and a rotational and translational spring is implemented to model the soil-structure interaction. To consider this soil-structure interaction, a model by A.B. Cammaert et al (2011) is used to determine the required stiffnesses. The model is modelled using Matrix Frame software, with which the final displacements, at the height of the mid-frame, have been determined. <br/><br/>A detailed analysis of the static internal forces is worked out based on a bolted flange-flange connection. Checks are done conform Det Norske Veritas (2010) and based on a ULS-driven design. Two potential connection configurations are worked out; an alternative with less but more heavy bolts of M64, as well as an alternative with substantial more smaller bolts of M36.<br/><br/>Finally, several optimisations are identified to speed up the installation time of assembling and disassembling the adjustable Pre-Piling Template. Recommendations are made in cooperation with Breman Machinery and will result, in consultation with installation experts that are well known with the barge of the client, to a final design. <br/><br/>A clear conclusion, about the PPT-design, can not be made because the installation is site specific. If a project includes two different configurations, a three- and four-legged foundation design, a composed mid-frame that is viable for both configurations is recommended. For this composed mid-frame variant the operation to adjust the frame to another footprint can be done more efficient with a higher safety level on deck of the vessel. <br","Pre-Piling-Template","en","master thesis","","","","","","","","2023-12-19","","","","","",""
"uuid:ca79e54c-b815-46d4-ab14-7aca3716dfd7","http://resolver.tudelft.nl/uuid:ca79e54c-b815-46d4-ab14-7aca3716dfd7","Absorption of ammonia in an ammonia - ionic liquid solution: A detailed experimental and numerical study of the absorption process","Peshave, Kalyani (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Process and Energy)","Infante Ferreira, Carlos (mentor); Vlugt, Thijs (graduation committee); Delfos, Rene (graduation committee); Gudjonsdottir, Vilborg (graduation committee); Delft University of Technology (degree granting institution)","2019","Excessive consumption of non - renewable resources in the recent times has negative effects on the environment, one of the important of which include global warming. This suggests an urgent need for adaption to the sustainable use of the resources, for which the thermal technologies show a lot of scope. Absorption heat pump is a type of heat pump which uses a thermal compressor instead of a mechanical compressor as in the case for the conventional heat pumps. Thus, such heat pumps are indeed an alternative energy conversion technology. This thesis focuses on the use of an inventive fluid as an absorbent in the absorption thermodynamic cycles: ionic liquids. In this thesis, the process of absorption of NH<sub>3</sub> into an NH<sub>3</sub> + ionic liquid solution is studied. [emim][SCN] was selected as the ionic liquid to be used as an absorbent based on its efficiency, availability and the beneficial economic factors. In the first part of this thesis, an existing numerical vapor - liquid equilibrium model for the working pair of NH<sub>3</sub> - [emim][SCN] developed by Wang (2019) was validated. This is done by comparing the results of the model with the experimental data obtained by Yokozeki and Shiflett (2007) for the same working pair. The second part of this thesis includes experimental and numerical studies of the absorption process in question. For the experimental study, the absorption setup located in Process and Energy laboratory at TU Delft was used. This setup does not accommodate the complete absorption heat pump thermodynamic cycle, but just the absorption process. Firstly, H<sub>2</sub>O - H<sub>2</sub>O convective heat transfer experiments were performed inside the setup, for both the lower range Reynolds numbers (40-140), and for the higher range Reynolds numbers (150-360). It was ascertained that the derived correlations governing the heat transfer for both of these ranges, along with the average correlation covering all the ranges of the Reynolds number, agree with the previous literature, to ascertain that the setup worked correctly. Consecutively, the absorption experiments were performed with NH<sub>3</sub> - [emim][SCN] working pair. The amount of vapor flow recorded during these experiments was quite low (maximum upto 0.1\%), suggesting that most of the heat was transferred to the cooling water by means of the sensible heat transfer. A numerical model for the absorption + sensible heat transfer process developed by Wang (2019) was used as a reference to design a similar numerical model in the present work. The data obtained from the experiments was used as an input to the numerical model. It was observed that the overall heat transfer coefficient for the absorption process is indeed more than that for the convective heat transfer process. The numerical results agree with the experimental results including a moderate error margin. Therefore, the numerical model was considered validated. The conceptual reasoning behind the error margin between the numerical and the experimental results are also presented. Little can be said about the validity of the empirical correlations governing the absorption process estimated by Wang (2019), since absorption only took place during a small part of the length of the absorber (maximum 10.5\%). However, it is expected that these correlations work satisfactorily for those cases where the solution is subcooled before entering the absorber. It is concluded based on the numerical results that the correlation governing the convective heat transfer derived from the water - water experiments is considered acceptable for the present case. Finally in the last part of this thesis, an attempt was made to predict the accurate value for the viscosity of NH<sub>3</sub> + [emim][SCN] solution by an experimental study. A separate set of convective heat transfer experiments was performed with NH<sub>3</sub> + [emim][SCN] solution and the cooling water. The experimental data obtained was analyzed using the correlations obtained from the H<sub>2</sub>O - H<sub>2</sub>O convective heat transfer experiments. The results of this analysis were compared with the solution viscosity values predicted by Wang (2019) with a logarithmic correlation, wherein the solution viscosity is a logarithmic function of the viscosities of the individual fluids present in the solution. The reasonable agreement (with on an average 32.05 \% accuracy, as was estimated by Wang (2019)) between the viscosity values obtained by the analysis and the values predicted by Wang (2019) confirmed the validity of this logarithmic function. Recommendations are presented in the last part of this thesis for future studies.<br","absorption; ammonia; ionic liquid; Plate Heat Exchanger","en","master thesis","","","","","","","","","","","","","",""
"uuid:83c5ba1e-8a2b-4f9b-813c-a5b0b6990f5a","http://resolver.tudelft.nl/uuid:83c5ba1e-8a2b-4f9b-813c-a5b0b6990f5a","Change Request Risk Model: Improving The Migration Of Networks","Broens, Tom (TU Delft Technology, Policy and Management)","de Reuver, Mark (mentor); Bots, Pieter (graduation committee); Delft University of Technology (degree granting institution)","2019","Internet and mobile phones have become essential in our lives. Without the internet and our smart phones, large parts of our society would stop functioning or even collapse completely. It is therefore of critical importance that the service is of the highest quality and that the delivery of service is not interrupted. Telecommunication providers are responsible for exploiting and maintaining the infrastructure necessary for delivering mobile and internet connections. It is not an easy market to survive in. Competition is fierce and the clientele demands constant service of the highest quality. This is a big challenge for telecommunication providers. In order to be able to deliver the best quality, maintenance is necessary. But maintenance is often the cause of service interruption. Combined with the fact that technology is evolving at such a pace that upgrades are coming faster and faster, the demand for maintenance has never been higher. Efficiently organising these maintenance activities has therefore become a priority.","","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:86d84b5e-dd09-4f67-807e-42b795dcb6b9","http://resolver.tudelft.nl/uuid:86d84b5e-dd09-4f67-807e-42b795dcb6b9","Investigation of meso-scale Sentinel-3 product along-track correlations and the potential of inter-track SSHA estimation using machine learning","Vlachos, Kostas (TU Delft Civil Engineering and Geosciences)","Lopez Dekker, Paco (graduation committee); Smal, Ihor (graduation committee); Eleveld, Marieke (mentor); Verlaan, Martin (graduation committee); Delft University of Technology (degree granting institution)","2019","Satellite altimetry is an important technology used to measure sea level with high spatial and temporal resolution. Sentinel-3, a Copernicus satellite mission, offers three types of variables captured simultaneously for the first time; sea level (SSH), sea surface temperature (SST) and ocean colour (OC) variables. Sea level is measured with SAR altimetry, a technique that considerably increases spatial resolution compared to other means of observation. Altimetry measures sea level across a line that coincides with the satellite ground track, whereas SST and OC are measured on a grid. What we lack are sea level observations in-between ground tracks that would better resolve meso-scale variability. This thesis is focused on two objectives, considering previous work that has indicated associations between those variables. The first objective was to investigate the correlations among SSH, SST and OC, while the second objective was to assess to what extent inter-track sea level can be estimated using SST and OC as predictors in machine learning algorithms. Daily Sentinel-3 data over a period of eleven months were pre-processed and brought into a form that allowed for computation of metrics such as auto- and cross-correlations in the along-track direction. The focus was on the spatial scales that would enable to detect meso-scale features, such as eddies. With respect to the inter-track sea level estimation two paths were followed. In the first path, Random Forest (RF) and Multilayer Perceptron (MLP) were applied using the complete 11-month dataset as input. Moreover, RF was applied on input data that belong to each separate day. In the second path, 1D Convolutional Neural Network (CNN) was used on the complete 11-month dataset, which inherently honors the spatial dependency of the variables in contrast to the first path. Generally, the correlations between the variables were found to exist in the meso-scale but were not always strong and they depend on several other factors, such as meteorological conditions, scales included in the analysis and techniques used. All three techniques -RF, MLP and 1D CNN- that were applied on the complete 11-month dataset gave poor results. On the contrary, when RF was applied on the per-day data gave promising results that are reliable mostly in the vicinity of the ground track, although they are not based on one single global model. The results from this project suggest that there must be more research on the correlation analysis of Sentinel-3 data. It can be improved by using additional or similar techniques, such as localized cross-correlation metrics on various spatial scales. With respect to the inter-track sea level estimation, far more investigation is needed. However, there are indications that a machine learning data-driven approach could potentially work to some extent. Sentinel-3 data will become more abundant in the next years which will assist data science algorithms such as CNNs which require huge datasets.","Sentinel-3; Random Forest; sea level; sea surface temperature; ocean colour; Convolutional Neural Network","en","master thesis","","","","","","","","","","","","Geoscience and Remote Sensing","","37.5008467, -74.014843"
"uuid:e38f8648-a1cd-4db4-8489-a8c82f4b7b75","http://resolver.tudelft.nl/uuid:e38f8648-a1cd-4db4-8489-a8c82f4b7b75","Behaviour of two-way spanning walls subjected to out-of-plane loading by numerical analysis","Soni, Mohit (TU Delft Civil Engineering and Geosciences)","Rots, Jan (mentor); Esposito, Rita (mentor); van Dalen, Karel (graduation committee); Ravenshorst, Geert (graduation committee); Delft University of Technology (degree granting institution)","2019","Unreinforced masonry (URM) buildings are vulnerable when subjected to out-of-plane dynamic loading, especially under as earthquakes. Within the masonry building, the wall spanning in the direction perpendicular to the seismic loading is the most critical component. Damage to these walls (out-of-plane failure) frequently leads to the partial or global collapse in the URM building structures, especially if the wall is a load-bearing wall. Boundary conditions and overburden load drastically influence the response of out-of-plane loaded walls. Two-way spanning walls that are restrained on three or four sides show a larger force capacity compares to one-way spanning walls, which are only restrained at top and bottom. Nevertheless, the studies on the behavior of two-way spanning walls are limited. This thesis aims to understand the two-way bending behavior of unreinforced masonry walls subjected to out-of-plane loading employing numerical analysis. A three-dimensional model using a shell element is adopted. Cracking is modeled with a continuum damage approach by comparing the isotropic model, namely the rotating smeared cracking approach (TSRC), and an orthotropic model, namely the engineering masonry model (EMM). The effect of the top boundary condition on the response of the two-way spanning walls is examined by considering case studies: four sides restrained wall with overburden load, and three sides restrained wall without overburden load. Both the walls are vertically connected with the pier (or return wall) with an alternate row of headers providing full moment restraint. The description concerning the seismic behavior of the two-way spanning wall made based upon the analysis carried out incorporating different loadings types like the uniform, mode proportional loading, time history, and cyclic loading. The orthotropic material model is better in evaluating the response of the two-way spanning wall as compared to the isotropic material model if the proper support condition is specified. The difference in response using either material model is visible at the onset of cracking. The response of the two-way spanning wall under monotonic increasing load using EMM demonstrates walls have a displacement capacity to sustaining a relatively constant load, whereas the TSRC fails to capture this behavior. Due to high non-linearity because of cracking in the elements, the solution becomes non-convergent, and a solid statement regarding the ultimate displacement capacity of the wall can not be made. However, based on the results from static analysis using EMM, a two-way spanning wall have sufficient displacement capacity well over the wall thickness. The displacement capacity signifies the wall can deform in the out-of-plane direction without failure and is beneficial, especially during an earthquake event. In two-way spanning walls, both the peak load and initial stiffness of the walls is enhanced by higher pre-compression and top lateral support. It is found both experimentally and numerically, as precompression increases flexural and shear resistance capacity of the wall to resist the out-of-plane load. Furthermore, in the wall restrained on three sides, the crack pattern is initiated at the main-wall and pier connection, representing the head-joint cracking, leading to changing the behavior from two-way to one-way. While in the wall restrained on four sides, the cracking is initiated at the top and bottom support, therefore the wall can sustain the load both via horizontal bending along the vertical edge. Furthermore, the influence of top rotation fixity on the crack pattern in four sides restrained wall demonstrates the change in crack pattern without significant difference in the force-displacement plot. Therefore, it is vital to know the proper boundary condition in the wall to help in identifying the weakest link and suggest the necessary strengthening location. To predict the dynamic behavior of the two-way spanning wall by alternative load application is studies using static, non-linear time history, and cyclic analysis. The analysis of the wall with uniform monotonic increasing load fails to capture the post-crack behavior. Whereas, under the application of mode-proportional loading and using the material properties as stated in the case study, the initial stiffness and peak load is significantly lower, because of the applied load pattern. Therefore, the material properties are calibrated to match the initial stiffness and peak load but fail to provide information regarding peak load and ultimate displacement capacity. Using the original material properties, the outcome of the non-linear time history (NLTH) gives reasonable prediction in response up to the pre-crack run as compared to the case study. The four sides restrained wall shows very stiff response with very few cracks initiations to dissipate energy in the wall while rapid degradation in the three sides restrained wall is found, which attributed to the brittle response with wall top reaching the larger out-of-plane displacement. Due to non-linearity (follows from cracking), irrespective of the material model, the outcomes of NLTH analysis fails to capture the crack and post-crack behavior. Therefore, the material model needs improvement in tension and cohesion softening to better account for non-linearity in the time-history analysis. Due to the limitation of the NLTH analysis, cyclic analysis with increasing magnitude of load cycles was carried out to replicate the dynamic response. The outcomes give a fair indication of material degradation (based on energy dissipation) and crack formation but fail to capture the displacement capacity. Furthermore, the contribution of mode-II fracture energy in the overall energy degradation is significant for three sides restrained wall but not in four sides restrained wall. Due to top support, and increased shear strength capacity of the wall due to pre-compression load. Analyzing the two-way spanning wall under different loading shows the asymmetric response in the positive (toward pier) and negative (away from pier) displacement directions (with a 36% difference in force capacity). This asymmetry is arisen due to the presence of the return wall at the vertical junction. Finally, the combination of static (with uniform load) and cyclic analysis provides a reliable indication of wall force degradation of the two-way spanning wall. It can be used as a substitute for NLTH analysis. However, no solid statement regarding displacement capacity can be made based on the non-convergence in the numerical analysis. Furthermore, the crack pattern observes under different loading shows the damage is primarily influenced by boundary conditions rather than the type of loading. Based on the outcome of the thesis work, further studies are needed to improve the convergent behavior of the numerical analyses to gain information on the displacement capacity of two-way spanning walls subject to out-of-plane loading. Additionally, it becomes interesting to explore the use of micro-modeling to understand the crack propagation in the masonry wall, and to exploring different anisotropic model such as the Rankine-Hill model, or to<br/>explore the implementation of strain rate dependent constitutive model (mainly used for impact loading) to understand the dynamic behavior in NLTH analysis.","Unreinforced masonry wall; Out-of-plane behaviour; Numerical Analysis; Orthotropic vs Isotropic material","en","master thesis","","","","","","","","","","","","","",""
"uuid:58d1eaa7-f37f-40d2-980f-cd98b6905795","http://resolver.tudelft.nl/uuid:58d1eaa7-f37f-40d2-980f-cd98b6905795","An investigation of numerical analysis for modeling free-surface elevation from flow over a shallowly submerged 2D naca0012 hydrofoil","Sprong, Geert (TU Delft Mechanical, Maritime and Materials Engineering)","Pourquie, Mathieu (mentor); Wellens, Peter (mentor); Westerweel, Jerry (graduation committee); de Koning Gans, Henk (graduation committee); van der Heiden, Kasper (mentor); Delft University of Technology (degree granting institution)","2019","The bulbous bow is a common feature for large displacement vessels. The purpose of the bulbous bow is to reduce the bow wave, hereby making use of wave cancellation theory. The main drawback of these type of bows is that the drag reduction effect is only present for a limited range of sailing speeds. If the transit velocity is altered, the effect of the bulbous bow can even result in an increase of wave making drag. Due to this sensitivity to the sailing speed it is important to be able to predict the location of the waves generated by the protruding bulb. Computational fluid dynamics is gaining interest in commercial marine industries. The size and transit velocity at which the previously mentioned vessels that employ the protruding bulb operate, results in the common use of Reynolds averaged Navier Stokes (RANS) models. To investigate the accuracy of these RANS models, a 2D model is presented in this thesis. The bulbous bow is modeled as a shallowly submerged 2D naca0012 hydrofoil. The justification for this simplification is that the geometry and flow over a bulbous bow is too complex for the duration of this project. A submerged 2D hydrofoil can still capture the important flow dynamics for free-surface waves. In this thesis we focused on evaluating the accuracy of RANS models for simulating the wave dynamics that arise when a shallowly submerged 2D naca0012 hydrofoil moves through water. The main objective is to find which geometrical and fluid dynamic properties have an effect on the free surface wave profile. Apart from questioning if these properties have an influence on the wave profile, we also want to know how the wave profile changes by altering these properties.<br/>The interFoam package from OpenFoam was used for simulating the flow. InterFoam adopts the volume of fluid (VOF) approach proposed by Weller (Weller, 2008) for simulating multiphase flows. Turbulence modeling was done using the k-ωSST two equationmodel from Menter et al. (Menter, 1992). In 1983 Duncan and his colleagues published a paper on the free surface wave dynamics generated by a towed naca0012 hydrofoil (Duncan, 1983). The results from their experiments are used as a benchmark for the present study. From a single phase test we found that the experiments from Duncan where performed in the regime where transition of the boundary layer from laminar to turbulent is present. The presence of this transition is expected to be one of the reasons for the disagreement in literature on wave elevation, wavelength zero point crossings and lift and drag coefficients. It is shown that the relatively small gap between the basin floor and the hydrofoil of 0.86 chord lengths has a significant impact on the wave profile and the flow at the hydrofoil. Reynolds independence is found to be at Re ¸ 2•10<sup>5</sup> for a towed hydrofoil submerged at h/c = 0.955 with the basin floor located 10 chord lengths below the hydrofoil. Below this value a reduction in Reynolds number results in an decrease of the wave amplitude and an increase in the wavelength. The assumption to neglect the resistance from the hydrofoil wake made by Duncan is shown to be false. The dominating dimensionless parameters for these types of flows are: Froude based on submergence Frh, Froude based on basin to foil height Fr<sub>D</sub> and the Reynolds number based on the chord length and the bottom fluid parameters Rec . Note that in this thesis the angle of attack (α) has been kept constant at 5° which does<br/>effect the flow but this has not been investigated during this research. A attempt is made to simulation breaking waves in the present model. The Breaker type in the present study differs from the one found by Duncan et al. (Duncan, 1983). Even if the same breaker type was found the elevation and wavelength differ a lot. It is therefore concluded that The present model is not suited for predicting<br/>breaking waves.","fluid dynamics; hydrofoil; free-surface; multiphase; VOF; RANS; k-omega sst; javafoil; waves; breaking; non-breaking; OpenFOAM; interFoam; CFD; naca0012; transition","en","master thesis","","","","","","","","2024-12-19","","","","","",""
"uuid:c53aa605-1b2e-47a7-b991-c1917d7463b4","http://resolver.tudelft.nl/uuid:c53aa605-1b2e-47a7-b991-c1917d7463b4","Numerical analysis of the flow past a leading edge inflatable kite wing using a correlation-based transition model","Demkowicz, Patryk (TU Delft Aerospace Engineering)","Viré, Axelle (mentor); Schmehl, Roland (graduation committee); van Zuijlen, Alexander (graduation committee); Folkersma, Mikko (graduation committee); Delft University of Technology (degree granting institution)","2019","Thorough understanding of flexible wing structural and aerodynamic properties is crucial to reduce uncertainties in the design process of energy generating kite systems. A flexible leading edge inflatable (LEI) tethered kite connected to a drum-generator module is currently being developed by the Airborne Wind Energy research group at TU Delft jointly with its commercial spin-off Kitepower. During each energy generation cycle, the kite experiences persistent regions of flow separation, which combined with the bowed shape of the kite and its low aspect ratio cause multiple 3D flow phenomena. Furthermore, a kite is a lightweight and flexible structure and there exists very strong coupling between the aerodynamic loads and its structural dynamics, forming an intricate aeroelastic problem.<br/><br/>Due to computational limitations of today's hardware, it is difficult and expensive to numerically solve the coupled aeroelastic problem in detail. As such, the focus of this thesis is to resolve and characterise one side of the problem, which is the LEI kite aerodynamics. Kitepower LEI V3A kite, modelled as a rigid geometry, has been analysed for various Reynolds numbers and angles of attack using a steady-state Computational Fluid Dynamics solver. A high quality, hybrid mesh has been generated. The gamma-Rethetat transition model has been used to improve the accuracy of the results at low Reynolds numbers and to assess the significance of transition at high Reynolds numbers. <br/><br/>Obtained force coefficients for a range of angles of attack are in general agreement with the values used in existing numerical models and measurements from experiments. The results indicate that flow transition is important to take into account for Reynolds numbers at least up to 3 million in order to accurately predict the stall angle. Large amounts of cross flow have been observed over the span of the kite that may affect the integral drag coefficient. The employed methodology is only applicable to the traction phase of the pumping cycle, as the steady-state and rigid geometry assumptions do not hold during the retraction phase, where the kite experiences severe deformation.","RANS; transition modelling; kite","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:3aa2c8bc-010d-4450-9ce7-04b0e2f40cfb","http://resolver.tudelft.nl/uuid:3aa2c8bc-010d-4450-9ce7-04b0e2f40cfb","Controllability of solar-sail orbits in the Earth-Moon system","Gamez Losada, Fernando (TU Delft Aerospace Engineering; TU Delft Astrodynamics & Space Missions)","Heiligers, Jeannette (mentor); Delft University of Technology (degree granting institution)","2019","The propellantless nature of solar-sail propulsion allows researchers to design completely new sets of orbits unreachable or not-maintainable by means of conventional propulsion. The advantage of this somewhat new type of low-thrust propulsion system becomes more evident for long-duration missions where chemical or electrical rocket engines would run out of onboard reaction mass. Solar sails happen to be particularly well-suited for polar observation missions. One can find several works concerning solar-sail orbits to establish a permanent communication link between a settlement on the lunar South Pole and the Earth. In addition, the literature also encourages the usage of solar sails to monitor the melting of the polar ice caps. However, these solutions employ either complicated steering laws or more than one sailcraft. In addition, little is known about how to perform necessary station-keeping maneuvers to keep the sailcraft bounded to the reference orbits under the effect of dynamic perturbations.<br/><br/>This thesis focuses on the orbit control of three types of solar-sail periodic orbits within the Earth-Moon system that have been shown potential for polar observation of either body. One of these orbit types, coined the distant-circular family, is newly introduced in this thesis together with transfers<br/>between orbits within the family; its remote orbits can achieve continuous coverage of both the Earth's North Pole and the lunar South Pole with just a single sailcraft. Developed mainly under the simplified, but non-autonomous, dynamics of the solar-sail circular restricted three-body problem, the studied orbits are all unstable and require an active control strategy for station-keeping. By slowly migrating the dynamics to a higher fidelity model, we introduce several disturbances, namely those associated with the eccentricity of the Moon's orbit, the plane offset between the ecliptic and the Earth-Moon orbital plane, the Sun's gravity, and the heliocentric eccentricity of the system's barycenter. Two solar-sail architectures, a fixed-shape and heliogyro sails, are compared with respect to the objective of tracking the ideal reference orbits that all use a simple Sun-sail steering law as reference control. To do so, we develop a methodology based on multiple shooting differential correction, weighted least squares, particle swarm optimization (quantitative analysis) and acceleration bubble visualisation (qualitative analysis). <br/><br/>We find that the effect of the eccentricity of the Moon's orbit is too large to be considered a perturbation and should be included in the design of the reference orbits. Then, we show that other perturbations can be completely counteracted by the heliogyro, which suggests that pure solar-sail quasi-periodic orbits are maintainable.<br","Solar sailing; Periodic Orbits; Earth-Moon system; Differential correction; Quasi-periodic orbits; Polar observation; High-fidelity dynamics; Circular restricted three-body problem; Particle Swarm Optimization; Active control; Disturbance Rejection","en","master thesis","","","","","","","","2020-07-01","","","","Aerospace Engineering","",""
"uuid:adc36a11-9b3c-4963-ba51-4e3563168b48","http://resolver.tudelft.nl/uuid:adc36a11-9b3c-4963-ba51-4e3563168b48","Feasibility Study on Aeroelastic States and Parameters Estimation with Visual Tracking","Abdul Rozak Rivai Fassah, Abdul (TU Delft Aerospace Engineering)","de Visser, Coen (mentor); Mkhoyan, Tigran (graduation committee); Delft University of Technology (degree granting institution)","2019","In recent years, developments in the field of aerospace materials and structures has been bringing major breakthroughs in the construction of air vehicles to be more lightweight yet with higher strength. However, the aircraft body can deform more appreciably due to the occurrence of flow separation and flutter. Therefore, active control is necessary in order to maintain structural integrity. One of the proposed control methods uses visual tracking for structural state estimation which reduces complexity in terms of hardware and data processing requirements compared to the conventional method of inserting a large number of inertial measurement units and gyroscopes in wing sections. The visual tracking routine is then integrated into a new structural state estimation routine that is robust against optical occlusions, and that can accurately reconstruct the states of the complete aeroelastic system. A new idea is to use a state estimator based on a reduced order mathematical model of the aeroelastic wing. This new state estimator is validated in simulation in different gust regimes. The results show that the state estimation convergences to the true values despite the process and measurement noise present in all simulated flight conditions. However, the pole position of the reconstructed state space fails to mimic the stable characteristics of the true model. Further analysis is recommended to constrain the parameter estimation in order to ensure that the stability of the true model can be retained, yielding an accurate solution for the aeroelastic controller feedback.","Model reduction; System Identification; Kalman Filter; Recursive least-squares; Aeroelasticity","en","master thesis","","","","","","","","","","","","Aerospace Engineering | Control & Simulation","",""
"uuid:9ab8f39b-faac-4fa7-a368-d2ada5ed8e33","http://resolver.tudelft.nl/uuid:9ab8f39b-faac-4fa7-a368-d2ada5ed8e33","Ship collision on temporary structures: Combi-walls under collision loading","Jansen, Johan (TU Delft Civil Engineering and Geosciences)","Jonkman, Sebastiaan N. (graduation committee); Molenaar, Wilfred (graduation committee); Abspoel, Roland (graduation committee); van Putten, Eelco (mentor); Delft University of Technology (degree granting institution)","2019","When designing a construction pit adjacent to a navigation channel, the event of a ship colliding with the structure is something to take into account in the design of the pit. However, several aspects regarding ship collisions, i.e. the probability of occurrence of a collision, the magnitude of the collision force and the influence on the safety of the pit, are uncertain. The goal of this research is to develop a method to determine the safety of a temporary construction pit. The Blankenburg Connection, which is being built by BAAK, is used as a case study in this thesis. The construction pit in this project is located in the Scheur and has to deal with a busy navigation channel. The end-wall of the pit is a temporary wall, as it has to be removed in order to to be able to float a tunnel element to the middle of the channel.A Bayesian Network is used as a method to take into account all the different parameters influencing the probability of collision. When comparing the outcome of the model with values based on historical data for the Scheur, it can be concluded that the model predicts the probability quite well. A small difference can be noticed, which is probably explained by the fact of under-reporting. To determine the magnitude of the force, a Monte Carlo simulation is used. In this way a probability density function of the magnitude of the force is generated, giving insight in the occurrence of forces on the structure. The resistance of the structure is determined and mitigation measures to increase the safety of the construction pit are examined.","Bayesian Belief Networks; Ship collision; Safety analysis; Construction site; Temporary; combined sheet pile wall; Local buckling; Monte Carlo Simulation; Immersed tunnels","en","master thesis","","","","","","","","","","","","Civil Engineering","",""
"uuid:1104f824-a4a7-4cf6-bdae-fac9441b5b24","http://resolver.tudelft.nl/uuid:1104f824-a4a7-4cf6-bdae-fac9441b5b24","Additive Manufacturing of Liquid Crystal Polymers: Interlayer features: formation and impact on interlaminar shear strength","Houriet, Caroline (TU Delft Aerospace Engineering)","Rans, Calvin (mentor); Dransfeld, Clemens (graduation committee); Delft University of Technology (degree granting institution)","2019","Recent findings have highlighted the potential of a 3D-printable high-strength Liquid Crystal Polymer, whose anisotropy can be fostered for topology optimization intents. The mesostructure of a 3D-printed liquid crystal polymer is studied: the observation of interlayer features under the form of regular notches or spiraling patterns swirls is reported on optical microscopy of cross-sections. A formation mechanism is proposed: interlayer features may be formed as a result of an offset in placement of material. Another question is raised by the observation of these crenelated shapes: by providing mechanical interlocking between layers, they are expected to enhance interlaminar shear strength of a part. Short-beam shear tests indicate that when interlayer features are tall with respect to the layer height, and oriented perpendicular to the shear loading direction, the interlaminar shear strength of the 3D-printed part is enhanced by up to 112%. Microscopic evidence further indicates the crack-arrest ability of these features.","liquid crystal polymer; additive manufacturing; spiral; 3D Printing; interlaminar shear; mechanical interlocking","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:ccf0c50b-7f6a-460c-bade-13a0947c9c88","http://resolver.tudelft.nl/uuid:ccf0c50b-7f6a-460c-bade-13a0947c9c88","A Roadmap to the Future of Radiology Staff Resilience: Enhancing employee engagement of Millennials","van Schaik, Britta (TU Delft Industrial Design Engineering)","Simonse, LWL (mentor); Albayrak, Armagan (graduation committee); van der Zwaluw, C.S. (graduation committee); Delft University of Technology (degree granting institution)","2019","With the introduction of the Quadruple Aim at Philips, healthcare staff experience is recognized as an important health system performance indicator. Engaged healthcare employees are related to retention, patient-centered care, high patient safety and improved quality of care provided. However, burnout seems to be a common phenomenon among healthcare personnel. Especially employees from radiology departments are prone to developing burnout symptoms. This does not only have negative consequences for the individual’s well-being and the organizations’ performance, but also negatively affects the quality of patient care. As Millennials are the least engaged generation but will take up 75 per cent of the workforce in 2025, this thesis proposes solutions on how Philips might support Millennial healthcare employees within radiology departments to enhance engagement in 2030. This has been done by extensive research on how to create an employee experience that enhances engagement, how this looks like for Millennials at radiology in the future and exploring the opportunities for Philips to support this. Field research revealed that technologists mainly value involvement in the workflow, department and hospital. This can be enhanced by giving them more responsibility based on interests, experiences and knowledge that they build up during their job. This means that in the future, technologists will have tailored roles (e.g. management-expert, patient care-expert and technology-expert) and could take over tasks of radiologists and residents. Residents mainly value staff equality that creates an open and safe learning environment. This can be enhanced by structuring the supervision and assessment and by tailoring their learning pathway. This means that in the future, they will have personalized learning pathways which are tailored to their needs and learning preferences. Radiologists mainly value being result-driven to define diagnoses as soon as possible. This can be enhanced by technology support in the workflow and in the interpretation of scans and images. This means that in the future, technology will take over simple tasks and will enable a more efficient workflow for radiologists who will have more time to focus on complex cases and collaboration with other physicians. Based on these findings, five service propositions are designed on how Philips might support the Millennial employees at radiology in the future to enhance their engagement. Four service propositions are created during a creative workshop with Philips employees. As confidential information was used in this workshop, these four service propositions are considered confidential. One service proposition is created based on an individual brainstorm and insights from the project and is applicable to all roles within radiology: As the roles of radiology employees will change into becoming more visible and specialized based on preferences and technology support, it is necessary to have a clear overview of all employees to sustain the employee engagement within the employee, department and hospital workflow. This can be supported by “a personalized planning that helps radiology employees who want to define diagnoses as soon as possible, be involved in the workflow, department and hospital, and want to learn in an open and safe learning environment by allocating employees correctly based on their tailored tasks and managing the workflow efficiency.” All findings of this thesis are presented in the format of a roadmap where the design innovation elements are visualized: the changing role of radiology in the future, the employee values, the future scenarios and the service propositions. These propositions will serve as inspiration for projects or research initiatives for Philips to continue with. However, the next steps for Philips are to validate these service propositions with radiology employees to explore the desirability. Besides, these service propositions need to be validated based on feasibility and viability within Philips and should be benchmarked to other health technology companies as well as companies that provide educational services within healthcare.","Employee Engagement; Radiology; Millennials; Burnout; Future scenarios; Roadmap; Engagement; Experience; Employee Experience","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:a2179003-b00b-495e-8f2f-225562e65232","http://resolver.tudelft.nl/uuid:a2179003-b00b-495e-8f2f-225562e65232","An Analysis of Deep Learning Based Profiled Side-channel Attacks: Custom Deep Learning Layer, CNN Hyperparameters for Countermeasures, and Portability Settings","Tubbing, Rico (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Cyber Security)","Picek, Stjepan (mentor); Doerr, Christian (graduation committee); Murukannaiah, Pradeep (graduation committee); Delft University of Technology (degree granting institution)","2019","A side-channel attack (SCA) recovers secret data from a device by exploiting unintended physical leakages such as power consumption. In a profiled SCA, we assume an adversary has control over a target and copy device. Using the copy device the adversary learns a profile of the device. With the profile, the adversary exploits the measurements from a target device and recovers the secret key. As SCAs have shown to be a realistic attack vector, countermeasures have been invented to harden these kinds of attacks. In the last few years, deep learning has been applied in a wide variety of domains. For example, convolutional neural networks have shown to be effective for object recognition in images and recurrent neural networks for text generation. In the side-channel analysis domain, deep learning has shown to be successful. Up until recently, no deep learning layer existed that was specifically designed for SCAs. In this work, we analyze this layer, called the spread layer, and demonstrate the flaws of this layer. We improve the flaws and show the spread layer does not enhance the performance of SCAs. Additionally, we show there is no need to develop a deep learning layer specifically for SCAs on unprotected implementations. For implementations where countermeasures are present, literature demonstrated that convolutional neural networks are the most successful. However, for both the masking and random delay countermeasure, little is known about the influence of the kernel size and depth of the network. In this work, we illustrate that increasing the kernel size and depth of the network both increase the attack efficiency for the random delay countermeasure. For the masking countermeasure, we demonstrate that higher kernel sizes and shallow networks perform the best. Additionally, in this work, we consider a portability setting where the probe position has been changed in between the measurements of the profiling and attack measurements. Here, we show that the probe position causes a typical deep learning SCA to be ineffective. We introduce a normalization method such that the attack becomes effective, and show this method enables the attack to perform as expected.","Side-Channel Attacks; Deep Learning; Profiled Side-channel Attack; Convolutional Neural Networks; Spread; Portability","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:84e4e2aa-464c-4629-bbf9-6be2e07f3412","http://resolver.tudelft.nl/uuid:84e4e2aa-464c-4629-bbf9-6be2e07f3412","Development of a portable, multi-agent experimental platform for demonstration of a persistent coverage control algorithm","Vermeulen, Arjan (TU Delft Mechanical, Maritime and Materials Engineering)","van den Boom, Ton (mentor); Keviczky, Tamas (mentor); Mendel, Max (graduation committee); Delft University of Technology (degree granting institution)","2019","At DCSC, research is conducted in the field of multi-agent systems. While this research often takes a theoretical approach, there is a growing need to verify the research on an experimental platform. In this way, the newly developed methods can be experimentally validated. For this purpose, a compact system is developed for localization and pose estimation of small, differential drive agents, using a camera and computer vision. This platform is designed in such a way that it is both portable and quick to set up (&lt; 5 minutes). This platform is developed for two main purposes: verification of developed control methods for multi-agent systems on a physical system, and for the demonstration of various control methods on location, e.g. in a classroom. The requirements for such a platform are formulated and the components needed to fulfill these requirements are selected. The performance of the localization and pose estimation in terms of computational time, precision and accuracy is quantified. To be able to deploy the setup on a table top of various sizes, multiple methods are designed and implemented to keep all the agents within a predefined domain. A Python based program is developed for demonstration and validation of control strategies. A graphical user interface is developed for the demonstration of path-planning and control algorithms, providing feedback on the states of the individual agents, and provide for real-time switching of control objective, observer model and visualizations. This platform is developed, built and tested. Coverage control aims to direct the motion of multiple agents/robots in a way to cover an area. In persistent coverage problems, points in the area to be covered need to be revisited regularly, since their time-varying ""coverage level"", diminishes over time. The coverage level could represent a variety of real-world quantities. Typical examples include tasks such as lawn mowing, visual inspection or robotic cleaning tasks. A state-of-the-art persistent coverage control algorithm for non-holonomic agents is implemented on the experimental platform, and the results are compared with simulations, showing a similar evolution of the coverage level, with a slightly higher variance in the coverage level in practice versus simulations. Furthermore, improvements to the partitioning scheme are proposed, tested and implemented. This novel partitioning achieves marginally higher coverage levels for agents with a constant coverage production function.","Persistent Coverage; Nonholonomic Motion Planning; Experimental platform","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:d7c220ab-3811-47fd-a5cb-19f6d61256ca","http://resolver.tudelft.nl/uuid:d7c220ab-3811-47fd-a5cb-19f6d61256ca","The Next Mugshot: Designing the next identity enrolment facility for the Dutch National Police","Pliakis, Alexandros (TU Delft Industrial Design Engineering)","van Erp, Jeroen (mentor); Bakker, Martien (graduation committee); Salters, Ivo (graduation committee); Delft University of Technology (degree granting institution)","2019","Pushed by technology and international regulations the world of identities is rapidly changing. Among others, the Dutch government is obliged to keep up. In line with these developments, a special facility for execution of identification processes for crime and migration purposes was nationally commissioned in 2015, called the ‘’Basisvoorziening Identiteitsvaststelling’’. Among others, this facility is used by the Dutch National Police to execute identification processes on migrants, aliens, suspects, convicts and witnesses. Throughout the years the appliance has become out-dated. Expensive defects and poor user experiences have caused the Police to initiate the development of a new design. Research unveiled that the Police is placed in a difficult position by relying highly on a product which functionality depends on numerous (uncontrollable) factors. The envisioned product requires be more flexible and future proof. Additionally, it was concluded that standardisation of a new enrolment facility for all identity related governmental agencies is feasible and desired. The Police was focused to design for: they set the highest requirements and have the most difficult users. Technology research provided that future identification will involve more biometric technologies and that a stationary enrolment facility will remain necessary for the coming decade. Using the Vision in Product Design method the current product and context were evaluated. A new user interaction journey was developed to provide a foundation for future development. The participant and the product were envisioned to become more involved in the process. It was chosen to create an unjudged experience for the participant. For the operator, the feeling of police workmanship should be emphasised. This led to the design goal: “Design the next identity enrolment facility for the Dutch National Police”. In order to improve the current situation, the following goals are formulated: Improving the user interaction; Inducing flexibility by: reducing dependency; implementing futureproofing; enabling versatile employability; anticipating identity technology. This initiated the ideation process. Through iterative prototyping, sketching and brainstorming a concept was designed. Eventually, an argumentation is provided on how the Main Appliance for Identification (‘MAID’) meets the design goals. Eventually, recommendations and unused ideas are provided for the client for future development.","Identity; identification; police; dutch; national; enrolment; modularity; modular; design; facility; appliance; government; future proofing; versatile employability; user journey; suspect; officer; Politie; Nederlanse; Nationale","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:3d274cfd-702c-4bba-aa41-5d3b418227ef","http://resolver.tudelft.nl/uuid:3d274cfd-702c-4bba-aa41-5d3b418227ef","Improving space management and bottlenecks in a retailer order-fulfilling system: The case of IKEA Delft","van Eijkern, Adrien (TU Delft Civil Engineering and Geosciences)","Tavasszy, Lorant (mentor); Ludema, Marcel (mentor); Schulte, Frederik (mentor); Delft University of Technology (degree granting institution)","2019","Retailers must adapt their activity to comply with the evolving demands of their customers. Increasing demand on order-fulfilment services, along with determination to keep high service levels, have raised the problem of space scarcity at retailer stores to keep and process picked customer orders. Congestion is then experienced in store order-picking depots. A design proposition is given to overcome this problem for a top retailer’s store in the Netherlands. Using engineering design methodology, the design proposition is created with at least one short-term solution for each of the 3 stages of an item’s movements within the store: (1) incoming items; (2) storage and order-picking that includes storage at the sales SKU, job-sequencing, storage at the depot and storage during peak periods of activity; and (3) outgoing items. Long-term solutions are also given to look into that would enhance technology and prepare for the foreseeable future customer behaviour developments in purchasing methods. Empirical evidence is provided on different job-sequencing methods that extends order-picking theory on picker-to-parts systems; and further on causes for a more complex view of out-of-stock theory than from the perspective of a shopping customer at the store, instead focusing on out-of-stocks for paid items by an ordering customer.","retail; store; order-fulfilment; order-picking; congestion; bottlenecks; out-of-stock","en","master thesis","","","","","","","","","","","","Transport, Infrastructure and Logistics","",""
"uuid:23c11cff-1b6f-4a73-869a-9e29d1542ed1","http://resolver.tudelft.nl/uuid:23c11cff-1b6f-4a73-869a-9e29d1542ed1","Managing circular construction projects","Versteeg Conlledo, Ana (TU Delft Civil Engineering and Geosciences)","Bakker, H.L.M. (mentor); Lousberg, Louis (mentor); Schraven, D.F.J. (mentor); van Schaick, Thomas (mentor); Delft University of Technology (degree granting institution)","2019","The construction sector has been the world’s largest consumer of raw materials since years. Construction and building activities together account for 36% of global energy use and 39% of energy-related carbon dioxide (World Green Building Council, 2017). Considering the built environment puts major pressure on the natural environment, a change in the construction sector is crucial. Circular economy is one of the concepts that can be applied to the built environment. The circular economy is based on three principles: design out waste and pollution, keep products and materials in use and regenerate natural systems. This requires a shift in the way of thinking and in the way of executing and planning a construction process. Where traditional projects are executed according to the ‘take-make-dispose’ plan, circular projects work according to a ‘reduce-reuse-recycle’ plan. Research by Van den Berg explains that the new circular construction method requires a radical new approach (Berg, 2019).<br/><br/>The objective of this research is to find out what changes must be made to traditional project management to deliver circular construction projects. This is done by describing the difference in practice in management, between traditional projects and circular projects. Furthermore, the aim of this research is to help project teams to control and implement the circular ambitions in the project. To meet the objective, the following research question is answered:<br/>What changes must be made to the management of projects, compared to traditional project management, to deliver circular construction projects?<br/><br/>In this research, traditional project management is defined with the help of the Project Management Body of Knowledge+ framework, which is the PMBoK framework including two extensions and therefore called the PMBoK+ framework. The framework discusses 12 project management themes, including the different activities for each theme that ought to be executed. Four circular case studies are performed, they are analyzed by interviewing 13 key stakeholders and by investigating project documents. The interviewees are asked about the 12 PMBoK+ themes, to find out if the same themes have been applied and in what way. The degree of circularity of a project is divided into two categories: circular product and a circular process. The four cases are all circular constructions (products), described with the help of the 10R-model. However, it is unclear if the projects used a circular process. The outcomes of the four case studies are compared, by means of cross-case analysis. The findings and recommendations of the research are validated with the help of an expert panel. Based on the validation and the results of the cross-case analysis, the conclusions, discussions and recommendations are composed.<br/>The four projects that are analyzed are (partly) circular construction projects. However, it is unknown whether in the cases circular project management or traditional project management was used. A distribution is made between the four projects, project A to D. For projects B and D, which are projects with public entities as owners, traditional project management is used. This is different for projects A and C. These two projects can be characterized as experimental circular construction projects. The projects were built with the aim to show the sector how circular buildings are delivered, money was not the main criterion and more funds were available due to media attention. For the experimental projects, circular buildings were delivered where circular processes were used. In both projects, alterations were made to the PMBoK+ framework. These alterations were done for the Scope, Cost, Human Resource, Procurement, Integration and Financial Management. For the other themes, traditional project management was applied. <br/><br/>The following conclusions explain what changes must be made to traditional project management to deliver experimental circular construction projects. To start, the aim to develop a circular construction should be an aim at the start of the project. For the scope, the client should define ambitions (instead of detailed requirements) and after the project team is selected, the requirements should be defined. For Project Cost Management, the budget should be accessible to the project team in a transparent way. The project team should consist of people with the same circular economy commitment, vision and philosophy, as part of the Human Resource Management. The procurement process should be different from the traditional process: plan the tender process timely in the project and involve suppliers early in the project. Besides, parties such as suppliers and subcontractors should be selected with the entire project team. Finally, new contract forms should be used to ensure that the building does not get demolished after the life cycle of the building. For project teams non-hierarchical and cooperative organizational structure should be used to ensure team work, shared responsibility and a creative process. With this, project knowledge is shared in a transparent way. Lastly, for Project Financial Management, responsibilities and risks should be distributed among the involved parties. <br","Circular Economy; Built Environment; Circular building; Project Management","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:abf3b2ef-37bb-42c9-901f-8a4cb944e440","http://resolver.tudelft.nl/uuid:abf3b2ef-37bb-42c9-901f-8a4cb944e440","Investigating Wind-Waves Impact and Sea Level Rise on the Long-term Morphological Development of Estuarine Shoals","Zheng, Jiechen (TU Delft Civil Engineering and Geosciences)","Wang, Zhengbing (mentor); Van der Wegen, Mick (graduation committee); van Prooijen, Bram (graduation committee); Elmilady, Hesham (graduation committee); de Vet, Lodewijk (graduation committee); Delft University of Technology (degree granting institution)","2019","Estuarine shoals are valuable areas with functions of nature, safety and navigation. It is of utmost importance to understand their underlying physical processes and long-term evolution to achieve protection. The first aim of this report is to determine the impact of wind-waves on long-term morphological development of estuarine shoals. The rapid sea level rise requires a valid model prediction of esturine shoal evolution in the future. Whether waves should be included for forecast needs to be evaluated. This rises the second aim to investigate wind-waves impact on estuarine shoals evolution under the sea level rise. A 2-D, process-based numerical model (Delft3D) is applied. This study sets up a large scale realistic model covering the whole Western Scheldt geometry and focuses on shoal Van Ossenisse by constructing high resolution grids and imposing wind-waves. Simulations are compared on a timescale of 50 years, with and without wave effects. Results revels that waves tend to slightly migrate shoals along their propagation direction. Waves erode sediment in the intertidal area, resulting in a lowering elevation of the shoal and high suspended sediment concentrations in water column. On the one hand, high SSC combined with wave asymmetry and wind-driven flow enhance sediment transport rate along wave propagation direction over top of the shoal, causing more sediment appearing in the lee side of the shoal. On the other hand, wave-induced suspended sediment follows tidal currents and transport to shoal edges where low bed shear stress exists. These cause shoal widening at lower intertidal area and upper subtidal area. Channel velocity hence increases with response to channel area reduction. This leads to erosion in the channel and channel deepening. In a longer timescale, waves impact do not lead to fundamental difference on estuarine autonomous behaviors. It reveals that waves impact may be sensitive to some parameters (eg. sediment grain size, tidal range, type of boundary conditions), especially in the inner channel. It is recommended to do more investigations. Sea level rise scenarios are carried out by imposing gradually sea level rise at the seaward boundary. Its timescale is 100 years. Both in wave and no wave case, sea level rise leads to elevation of shoal height and area lose in shoal edges, resulting in steeper slope in the intertidal area. Larger channel area and volume are presented with sea level rise. Waves maintain their function under the sea level rise. It lowers and widens the shoal, resulting in the increase of intertidal area and volume. Sea level rise does not change the tendency of waves impact.","Intertidal flats; Morphodynamic modeling; Sea level rise; Estuarine morphology; Western Scheldt","en","master thesis","","","","","","","","","","","","","",""
"uuid:6a0b71b9-3ba9-457d-969b-d3e6c133ba07","http://resolver.tudelft.nl/uuid:6a0b71b9-3ba9-457d-969b-d3e6c133ba07","Functional Characterization of Human iPSC-Derived Neural Networks using MEA Systems for in vitro Modeling of Psychiatric Disorders","Sfakianou, Areti (TU Delft Mechanical, Maritime and Materials Engineering)","Valente, V. (mentor); Delft University of Technology (degree granting institution)","2019","Psychiatric disorders are associated with major societal, personal issues and comprise 13% of the global burden of disease. They are heritable and present a complex pathophysiology, characterized by hundreds of genetic variants which are cumulated together and provoke a specific psychiatric disorder. Although a considerable progress has been made in the identification of genetics variants, the way a cellular phenotype is related to a gene expression caused by biological pathways remains unclear. Significant effort has been focused, over the last years, on psychiatric diseases modeling, to investigate the complex, polygenic neurobiological nature of these disorders. Human induced pluripotent stem cell (iPSC) technology has been widely used for in vitro disease modeling. Human iPSCs can be readily derived from patients and differentiated into any cell type including neurons. The functional characterization of neurons constitutes a challenging procedure and different electrophysiological techniques can be applied. A hallmark of a non-invasive technique, in which the neuronal network dynamics can be observed, is the Microelectrode Array (MEA) measurements. The functional characterization of neuronal activity contributes to the cellular phenotype investigation of neuronal cultures, derived from patients who are affected by psychiatric disorders. The cellular phenotypes could be used as readouts for high-throughput pharmacological screenings and enhance the development of new drugs. In the current thesis project, the combination of a long-term neural differentiation protocol with extracellular MEA measurements was implemented, to assess the spontaneous and synchronized network activity of human iPSC-derived neural cultures. This protocol generates both neurons and astrocytes from a common neural progenitor cell (NPC) into a control ratio (60:40). A commercial MEA system (Multiwell-MEA, Multi Channel Systems, GmbH, Germany) was used for extracellular recordings on the neural populations. Additionally, a spike sorting analysis was performed for spike waveform observation. Experimental results presented a robust network activity derived from neural populations cultivated in neuronal medium (BrainPhys), for a period of ten weeks in vitro. Neuronal activity was characterized in terms of cumulative firing rate (CFR) per cell culture and mean firing rate (MFR) per electrode. Results showed a peak CFR of 1700 spikes/minute/culture (±260 SEM) and a peak MFR of 215 spikes/minute/electrode (±22.5 SEM). Additionally, a bursting activity was constantly detected on a scale of 270 burst/10 minutes/culture (±31 SEM), during the period of ten weeks in vitro. A spike sorting analysis verified the successful monitoring of spikes’ waveforms derived from the same unit of neurons in a two-week period. 88% of the detected waveform patterns presented a normalized cross-correlation higher than 0.9, which reinforced the argument that the electrodes detected electrical activity derived from the same unit of neurons in a constant way. This project contributes to the creation of an optimized functional readout of human neural model in vitro, which, in a long-term vision, could be used as reference point for comparison between healthy and diseased cell lines derived from patients with psychiatric disorders.","Microelectrode arrays; Neural Networks; Human induced Pluripotent Stem Cells; Spike Sorting Analysis; Long-term neural differentiation protocol","en","master thesis","","","","","","","","","","","","Biomedical Engineering","",""
"uuid:a86f06e9-7010-4fcb-b9d0-3e841da66d1b","http://resolver.tudelft.nl/uuid:a86f06e9-7010-4fcb-b9d0-3e841da66d1b","SIS Epidemics on Network with Non-Markovian Curing Process","Zhou, Xiaoyu (TU Delft Electrical Engineering, Mathematics and Computer Science)","Van Mieghem, P.F.A. (mentor); Ma, L. (mentor); Liu, Q. (mentor); Delft University of Technology (degree granting institution)","2019","Susceptible-Infected-Susceptible (SIS) model is commonly used to describe the spreading of virus on networks. However, a real-life epidemic process is not necessarily Markovian. The spreading of diseases, behaviors and information in real systems are sometimes dependent on the characteristics and current status of individuals. Thus it is far from enough to just consider Markovian processes. We need to consider a more general model with non-Markovian processes. Although some recent works focus on the SIS model with a non-Markovian infection process, systematic research on the non-Markovian curing process is still lacking. Therefore, this thesis project is to study the influence of the non-Markovian curing process on the performance of SIS viral spreading on networks. Through continuous-time SIS epidemics simulator, we find some dramatic effects of a non-exponential curing time (while still assuming an exponential infection time) on the prevalence and critical point of effective infection rate by considering Weibullean curing times with same mean, but different shape parameter α. For α ∈ [0.2, 10], the epidemic threshold satisfies τ<sub>c</sub> = 1/λ<sub>1</sub>, which is the same as the NIMFA conclusions of Markovian SIS process. Relatively, when α is too small, a large number of curing events synchronously happened at the beginning of the simulation, which will lead to collective deaths on finite network. The effect on initial condition of nodes further cause a decline on prevalence and an slow phase transition between healthy state and the meta-stable state. Furthermore, the heavy-tailed distribution of curing time leads to a small percent of nodes still surviving at the meta-stable state, even under a very low effective infection rate. The heavy-tailed distribution gives some nodes an extreme long curing time and thus can infect other nodes with a pretty small probability, thereby maintaining the virus' long-term spread in a small group of nodes. This spreading mode seems can explain some virus spreading phenomenon, like the spreading mode of hepatitis B virus (HBV). Additionally, when the shape parameter α of Weibull distribution is pretty large, the distribution of curing time is like a pulse or a Dirac delta function ( δ function), thus a huge amount of nodes can get synchronously recovered. We find when we control the successful curing probability <i>p </i>=1-1/<i>e</i> ≈0.632, the prevalence of pulse curing at the meta-stable state is equivalent to a Poisson curing process. Therefore, the pulse curing strategy can suppress the spreading of viruses and further save medical resources.","SIS Epidemics; Non-Markovian Curing Process; Epidemic Threshold; Pulse Curing Strategy","en","master thesis","","","","","","","","","","","","Electrical Engineering | Telecommunications and Sensing Systems","",""
"uuid:a08e8eee-7e38-48c7-9c8d-71f6f516361f","http://resolver.tudelft.nl/uuid:a08e8eee-7e38-48c7-9c8d-71f6f516361f","Risk analysis for reuse of a Dutch natural gas transmission pipeline for 100% hydrogen transport","Froeling, Hidde (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Wijk, Ad (mentor); Nane, Tina (mentor); Henkes, Ruud (graduation committee); Spliet, Arne (graduation committee); Dröge, Marc (graduation committee); Delft University of Technology (degree granting institution)","2019","As an alternative energy carrier alongside electricity, hydrogen is considered one of the key factors in the impending required changes in the energy system transition. Due to the decrease in natural gas extraction in the Netherlands, the reuse of the natural gas network which eventually will become available for hydrogen transmission has emerged as a topic, recently. Although it seems to be possible to reuse the existing natural gas transmission network for the transmission of hydrogen, a quantitative risk analysis is still lacking and there is uncertainty about the safety of hydrogen transmission. This report aims to quantify the risk of the reuse of an existing natural gas pipeline for 100% hydrogen transmission and compare it with the natural gas case. A risk analysis entails the quantification of both the probability of failure and the adverse consequences. This research investigated the current methodology to determine the probability of failure for hydrogen transmission and proposed a new calculation method using a Bayesian network and historical natural gas data to derive new failure frequencies. The consequence of failure for both hydrogen and natural gas will be modelled using the SAFETI-NL; the influence of the gas different characteristics on the lethality will be quantified and risk values are produced, assuming the probability of failure to be similar for both gases when transported through natural gas pipelines. This research illustrated the promising application of a Bayesian network is a promising method to derive failure frequencies while taking into the significant influence of the pipeline characteristics. However, from the results, it emerges that further research is required with more redundant data. Also, future research should investigate the application of natural gas data since some failure scenarios are not entirely independent of the transmission gas, which could result in less favourable failure frequencies. Furthermore, calculations in SAFETI-NL have shown that hydrogen release is associated with a shorter duration and lower release power than natural gas, resulting in less significant consequences in the vicinity of the pipelines. Also, the low weight and high diffusive coefficient of hydrogen cause the consequences to decrease much faster with distance. As a result, there is concluded that hydrogen transmission is accompanied by lower risk values than natural gas, assuming the failure frequencies to be similar when both gases transported through natural gas pipelines. Although, numerous input parameters affect the risk values determined, of which at least the probability of ignition for hydrogen release has to be investigated in future research.","Sustainable Energy; Hydrogen Transport; Natural Gas Pipelines; External Safety; Risk Analysis; Failure Frequency; Bayesian Network; Lethality; SAFETI-NL","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:92ea666d-fc25-4519-ba10-b2d6d0db10d8","http://resolver.tudelft.nl/uuid:92ea666d-fc25-4519-ba10-b2d6d0db10d8","Entertainment Education - a strategic implementation for fire safety: Research, design and implementation for maximum effectiveness","Hellewaard, Jens (TU Delft Industrial Design Engineering)","Hultink, Erik-Jan (mentor); Keller, Ianus (graduation committee); Boosman, Martijn (graduation committee); Delft University of Technology (degree granting institution)","2019","Every 3 minutes, someone dies in a domestic fire accident. The Comics for Safety Foundation aims to improve worldwide fire safety with the help of entertainment. In this thesis, the effectiveness of the communication strategy Entertainment Education is tested for the use of fire safety.  A qualitative research was performed on Dutch children between 12 and 15 years old to determine their values and needs during their entertainment consumption. The results included a strong need for self identification in entertainment and the need to share their entertainment with friends and be able to enjoy it together. A quantitative research was performed on the same target audience to measure how know-ledge, attitude and behaviour are affected by comparing education provided in comic book form versus education provided in plain-text form. It was found that children who read the comic book significantly learned and remembered more knowledge after two weeks compared to the group that received the education in plain-text form. To create a successful campaign, elements were designed to reinforce the strength of the comic books. An app was designed that functions as a digital reading environment were children can enjoy the comic books together with their classmates, using AR features to enhance the reading experience. The education will be provided via secondary schools on a thematic fire safety day. The goal for the next five years is to successfully implement the campaign and improve fire safety by reaching 200.000 children in at least two countries.","Design for Behaviour Change; Entertainment Education; Fire Safety; Comics","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:63dbaf75-d8fd-4f20-af56-4fabd141f4e5","http://resolver.tudelft.nl/uuid:63dbaf75-d8fd-4f20-af56-4fabd141f4e5","Design of a 2-DOF wrist prosthesis","Karthaus, Zoë (TU Delft Mechanical, Maritime and Materials Engineering)","Plettenburg, D.H. (mentor); Delft University of Technology (degree granting institution)","2019","Although a wide variety of upper limb prostheses is available, a large number of prostheses include wrist joints providing an insufficient amount of functionality. Compensatory movements have to be made in order to execute activities of daily living, causing fatigue and discomfort. This dissatisfaction amongst prosthetic users, which can result in rejection of the prosthesis. A 2-DOF prosthetic wrist is designed in which two curved hydraulic cylinders apply for flexion-extension and pronation-supination. The device is passively adjustable in a certain position by the sound hand and can be locked in any desired position. After a prototype is 3D printed, the wrist prosthesis is evaluated to validate if the wrist prosthesis has met the design requirements. With ROMs of 132 degrees for flexion-extension and 154 degrees for pronation-supination, the wrist prosthesis approached the functional mobility of a biological wrist. Requirements for the dimensions and mass have been met, with a diameter of 43 mm, length of 36 mm and mass of 43 g. Adjusting the wrist prosthesis can be executed with a maximal torque of 0.078 Nm. A static torque higher than 1.9 Nm causes leakage of the curved hydraulic cylinder. Although this does not meet the requirement, it enables lifting of an object up to 2.6 kg.","","en","master thesis","","","","","","","","2021-12-19","","","","Biomedical Engineering","",""
"uuid:ba522e96-1f0e-43ae-b126-f9806a5d3576","http://resolver.tudelft.nl/uuid:ba522e96-1f0e-43ae-b126-f9806a5d3576","Quantum Enhanced Accelerometer using NV Centres in Diamond","Mouris, Roel (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft (OLD)Quantum Integration Technology)","Ishihara, R. (mentor); Sarro, Pasqualina M (graduation committee); French, P.J. (graduation committee); Delft University of Technology (degree granting institution)","2019","Silicon accelerometers used in the automotive industry should be improved in resolution and accuracy. Exploiting quantum effects in diamond to improve sensing accuracy is a popular technique for nanoscale sensing applications. This thesis will present a new design concept for an accelerometer using these quantum effects for sensing on a macroscopic scale. This sensor can sense these forces with a resolution of 6g and a range of 120g. In measurement time it is slower than current sensors, but our sensor can still serve as a prototype to be improved in the future.","Quantum; Accelerometer; Airbag; Sensor; NV centre; Nitrogen Vacancy; Diamond; Strain","en","master thesis","","","","","","","","2021-12-19","","","","","",""
"uuid:899d16bc-98f2-4fcc-be64-820a8fa4b8fd","http://resolver.tudelft.nl/uuid:899d16bc-98f2-4fcc-be64-820a8fa4b8fd","Prioritisation of Measurement System Analyses: At the Airbus plant in Stade, Germany","Mestrom, Pascal (TU Delft Aerospace Engineering)","Sinke, J. (mentor); Unckenbold, Wilm (graduation committee); Delft University of Technology (degree granting institution)","2019","class=""MsoNormal"">The thesisproject concerns the development of a methodology to connect data, from theAirbus department in Stade, with each other and find relationships between themwhich lead to a prioritising tool with which justifiable decisions can bededuced in order to plan which Measurement System Analysis (MSA) to conductnext, focusing on cost effectiveness.  Therefore, the main content will revolvearound studying and analysing relevant literature and connecting this with theactual data, as present at Airbus, to arrive at a functional tool.  As such, the main aim and objectivesconcentrate around developing a thorough understanding of the relevant data anddiscovering how they relate with one another and with costs. Aim would be tofind a causal relationship, which is then subsequently also verified andvalidated.      The main findings areexpected to give the relationships between the data, e.g. that a certainimprovement of X% in MSA leads to Y% better Cpk (Process Capability Index. Adjustmentof Cp for the effect of non-centred distribution) and as such Z% reduction inCost of Non Quality (CNQ) per process.      As Airbus is in a toughcompetition with Boeing and other aircraft manufacturers, finding ways to bemore cost effective is very useful. Especially now with the populationof the earth rapidly growing and the use of aircraft for travel becoming morereadily available/affordable for everyone, the amount of aircraft that need tobe in the worlds fleet is expanding even more. As such, the rate ofconstruction of aircraft is rising tremendously and improvements in recurringcosts are ever more valuable. Even though the work is dedicated to Airbusprocesses, the methodology as developed for the prioritisation tool should begeneralisable to also be applicable for other situations and as such give aworthwhile contribution to the body of knowledge: How these data relate witheach other and how this knowledge/information can be turned into practicalimprovements.","Measurement System Analyses; Statistical Process Control","en","master thesis","","","","","","","","2020-10-31","","","","Aerospace Engineering","",""
"uuid:5b44449a-a472-4567-8983-e1d68908a28d","http://resolver.tudelft.nl/uuid:5b44449a-a472-4567-8983-e1d68908a28d","A strategic approach to 'Office as a Service': An explorative study into the optimization of the physical resource in order to obtain maximum added value","Schreurs, Thom (TU Delft Architecture and the Built Environment)","den Heijer, A.C. (mentor); Hermans, M.H. (graduation committee); Plomp, H. (graduation committee); Delft University of Technology (degree granting institution)","2019","Problem statement: Organisations need real estate to enable them to perform their activities effectively and efficiently in a safe, protected and pleasurable environment. Typically, large organisations use many buildings to perform their activities. The relationship between a building (supply) and its users (demand) is constantly changing. This change is fuelled by technology and a host of economic and cultural trends. Because the supply - demand is changing continuously, most of the time there is a mismatch between what a building can offer and what an organisation requires. Therefore, one of the biggest challenges in Corporate Real Estate Management is reducing the gap between the high speed of business and the slow speed of real estate, i.e. between the so-called dynamic real estate demand and relatively static real estate supply. <br/>Research objective: Based on the objective of Corporate Real Estate Management, the research objective of this graduation work is to develop and present knowledge of how the physical resource can be enhanced by implementing ‘Office as a Service’. Because the mismatch is dynamic and will change frequently, a strategic decision approach to managing the mismatch between the user organisation and the building is proposed in order to offer a suitable way of approaching these problems. Therefore the main research question is: “How can ‘Office as a Service’ be a strategic decision approach for an organization to optimize their physical resources in order to obtain maximum added value?” Research method: By conducting operational-empirical research, the research questions are answered. By means of operational research, a strategic decision approach is developed that can be used in the process of forming an accommodation strategy to align real estate to the needs of the core business. Empirical research was used to obtain input for the development of the operational model. This empirical research focused on the performance of ‘Office as a Service’ strategies in relation to both the presumed added values of real estate and the various typologies of occupier space demands. To obtain the required input, a method of a literature review, semi-structured interviews and a cross-case study was used. Key findings and conclusion: A strategic decision approach is developed based on the concept of a Multi-Criteria Decision Analysis (MCDA) model. The development of this Multi-Criteria Decision Analysis model integrates the decision-makers criteria, which are based on the presumed added values of real estate as well as the five typologies of occupier space demand, with the alternative ‘Office as a Service’ strategies. Based on the model of Den Heijer (2011) to assess the added value of real estate decisions regarding the four stakeholder perspectives with their corresponding presumed added values, eight added values divided over all four stakeholder perspectives can be related to the concept of ‘Office as a Service’. Next to the presumed added values of real estate which contribute to the strategic goals of an organization, an operational aspect is added to the decision-criteria taking into account five typologies of occupier space demand of an organisation. Based on the Core-Periphery operational real estate portfolio space model of Gibson and Lizieri (1999) in relation to the alternative ‘Office as a Service’ strategies this results in the following interpretation: a stepped ascending relationship where the increase of flexibility is answered by a more external ‘Office as a Service’ strategy.","Corporate Real Estate Management; Strategic decision approach; Office as a Service; Added value","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Management in the Built Environment","",""
"uuid:2c68d396-1b81-41e7-aa7a-f57e674dc059","http://resolver.tudelft.nl/uuid:2c68d396-1b81-41e7-aa7a-f57e674dc059","Algebraic heat flux modeling for numerical prediction of heat transfer and flow in Natural Convection","Kanawade, Kunal (TU Delft Aerospace Engineering)","Gerritsma, M.I. (mentor); Shams, Afaque (graduation committee); Delft University of Technology (degree granting institution)","2019","In nuclear industry applications, from design and safety aspects, it is important to predict the flow and heat transfer. The passive cooling systems, one of the robust cooling systems in the nuclear design are based on natural convections. In the RANS approach, non-linear unknown heat flux term has to be closed by appropriate model for accurate predictions of flow and thermal fields. This thesis presents a numerical framework for simulating heat and flow transfer in natural convection flow regimes by employing algebraic turbulent heat flux model AHFM-NRG+, coupled with second order turbulence model. The turbulent heat flux model coefficients are calibrated and a correlation between Rayleigh and Prandtl numbers with model coefficient is defined. The model is employed for different test cases of Rayleigh Bénard convections and is validated by comparing the simulation results with reference DNS data.","turbulent heat flux; Natural connection; heat transfer; reynolds stress model; Numerical modeling","en","master thesis","","","","","","","","2021-12-31","","","","Aerospace Engineering","",""
"uuid:b06a961e-fe79-46a5-aba5-8831e42188ef","http://resolver.tudelft.nl/uuid:b06a961e-fe79-46a5-aba5-8831e42188ef","Application of Sandwich Panels in Offshore Structures: Static Strength, Buckling Strength and Weight &amp; Cost Analysis","Vidwans, Aditya (TU Delft Civil Engineering and Geosciences; TU Delft Steel & Composite Structures)","Veljkovic, M. (mentor); den Besten, J.H. (graduation committee); Romeijn, Eric (graduation committee); Overal, Jaap (graduation committee); Xin, H. (graduation committee); Delft University of Technology (degree granting institution)","2019","In steel structures, a lot of attention is paid to lightweight structure, i.e. reduction of dead load without compromising structural safety, integrity and performance as well as cost-effectiveness. Thanks to modern steel aluminium sandwich panel manufacturing technology a new possibility became available for lightweight structural design.The objective of this thesis is to evaluate the application of sandwich panels in the construction of steel structures with the aim of weight reduction without affecting other parameters like safety, performance, cost, etc. In this thesis, both column and plate buckling theories are considered and applied to the sandwich panel to evaluate its behaviour under in-plane compressive load. Effects of various material models and imperfections on buckling strength of sandwich panel are evaluated. Stiffened plate and sandwich panel is compared in terms of buckling resistance and self-weight. Three different sandwich panels made from faceplates of steel grade, S355, S690 &amp; S1100, are used for replacement of S355 stiffened plate. Efforts made to understand the effect of various physical parameters on buckling resistance of sandwich panel in both column and plate buckling theories.Finally, as a case study, sandwich panel technology is used to redesign the Huisman structure. The objective is to investigate whether applying sandwich panels in redesign makes it possible to obtain a sufficient weight reduction without losing its performance. For this case study, sandwich panels with faceplates of steel grade S355, S690 and S1100 are used. Static and buckling strength of the new design is evaluated. Also, the cost of new design and original design is evaluated and results are compared. Cost analysis is done to evaluate whether a sandwich panel is an economical solution.Findings of this thesis are that in future it is possible to use sandwich panels in offshore structures to save a significant amount of weight while taking considerations into account. Sandwich panels can be successfully used to replace stiffened plates. Sandwich panels with faceplates made from extra high strength steel can give significant weight reduction. But the use of sandwich panels also results in an increase in the overall cost of the structure. So in terms of costs, it is questioned whether or not using sandwich panels is economically beneficial for offshore equipment.","Steel Aluminum Foam Sandwich Panel; Weight Reduction; Buckling Analysis; Cost Analysis","en","master thesis","","","","","","","","","","","","","",""
"uuid:71d78676-9d18-48da-8225-2262a16d5140","http://resolver.tudelft.nl/uuid:71d78676-9d18-48da-8225-2262a16d5140","Reducing the CO2 Footpring of Business and Commuter Travel, for Companies, by Using Sustainable Cars: A Case Study at TUI","Wesdijk, Xenia (TU Delft Electrical Engineering, Mathematics and Computer Science)","Annema, Jan Anne (mentor); van Wee, Bert (graduation committee); Storm, Servaas (graduation committee); Delft University of Technology (degree granting institution)","2019","class=""MsoNormal"">Decreasing the CO2 footprint related to business and commuter travel for companies presents a multitude of challenges. These challenges range from finding the objections of employees regarding EVs, and ways to overcome them, to determining what an ideal composition of a car fleet would be. At the same time the financial feasibility of all theses challenges have to be taken into account. If no (financial) benefits can be gained, a company is less likely to implement measures to reduce its CO2 emissions. Building on this, the main aim of this thesis is thus to find the barriers against electric driving for company car drivers in The Netherlands and find ways in which the company can aid in overcoming these barriers. Additionally, this research presents a thorough and general investigation into the yield and costs accompanying the installment of rooftop solar systems.  To determine the barriers amongst employees, a quantitative survey was conducted with 176 respondents. The survey was analyzed and generated with the help of TAM, and the results were then used to create three different CO2 reduction scenarios. After which it was possible to calculate cost and benefits associated with each individual scenario. In doing so the one-off and yearly investment costs were determined for both employer and employee. Based on the research done it is concluded that the barriers against the transition to EVs are similar for company car drivers and private car owners.  It is also concluded that the barriers found are similar for all companies in The Netherlands. Furthermore, by driving electrically, while commuting, companies can easily reach a CO2 reduction of 21.0%.  If companies then also use their rooftops to generate electricity, that can be used to charge the EVs, an additional savings can be realized of, in this case, 9.0%","EVs; company cars; CO2 reduction; PV System; Barriers","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:ffcbfc5d-4d56-4c40-9e82-746e87d7857e","http://resolver.tudelft.nl/uuid:ffcbfc5d-4d56-4c40-9e82-746e87d7857e","Design and Analysis of Power Inductors for a Split Capacitor DC-Link Topology In Tractive Inverters, to eliminate high frequency harmonics and minimize capacitance size: Design and analysis of power inductors for the tractive environment","Bhati, Dhruv (TU Delft Electrical Engineering, Mathematics and Computer Science)","Bauer, Pavol (mentor); Chandra Mouli, Gautham Ram (mentor); Delft University of Technology (degree granting institution)","2019","The DC-Link capacitor of tractive inverters is designed to meet the Voltage Ripple requirement set by the manufacturer. The State-of-the-art capacitor design takes into account the minimum most capacitance required for the power rating to achieve the required voltage ripple and to ensure minimum power losses. This master’s work is based on the proposal of a new Split Capacitor DC-Link topology that creates a resonance in the DC-Link which creates an extremely low impedance path for the conduction of the fundamental to high frequency harmonics. This elimination of harmonics allows a further reduction in the Voltage ripple, which can be further translated into a reduction of capacitance size in order to meet the voltage ripple requirement rather than reduce it. The reduction of capacitance has a direct consequence in the reduction of cost and weight also. In order to achieve a continually sustained resonance in the DC-Link, precise inductances are required to create series resonance LC-circuits. In this master’s work, the design and analysis of non-conventional inductors is performed. The inductors are subjected to an array of constraints that are unique to the automotive environment. The effects of high frequency power conduction are analyzed, and a series of experiments is performed to deduce optimum parameters to minimize power loss. The inductors are designed on the basis of these experiments and then further analyzed for stray magnetic fields to ensure sanity in the automotive environment. Design of the inductors is validated using impedance and EMC measurements performed using an impedance analyzer and an anechoic chamber setting. The precision and tolerance of the inductors is thus measured and validated against the simulations. The effects of the inductors on the shields and the inductance regulation is also validated. At the end of this master’s work, scope of the application is revisited. The possible applications in other domains is also explored. To conclude, improvements to the proposed design methodology and their possible impact are delivered.","Inverter; Inductor; Electric Vehicle","en","master thesis","","","","","","","","2024-12-18","","","","","","48.7688, 11.3991"
"uuid:295dd608-fdf0-4702-8d64-514ca0a011af","http://resolver.tudelft.nl/uuid:295dd608-fdf0-4702-8d64-514ca0a011af","Analysing BGP Origin Hijacks","van Veen, Simone (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Cyber Security)","Doerr, Christian (mentor); Picek, Stjepan (graduation committee); Murukannaiah, Pradeep (graduation committee); Delft University of Technology (degree granting institution)","2019","In the past years, society has become increasingly more reliant on the Internet. Consequently, the security of the Internet became of critical importance. This thesis focusses on the security of one of the Internet's main protocols. This protocol, called the Border Gateway Protocol (BGP), is used to exchange information that allows Internet traffic to reach its intended destination. BGP is vulnerable to misconfigurations and attacks that can cause a range of problems. This thesis focusses on one of them: BGP origin hijacks. In this thesis, a year of possible origin hijacks is analysed. These possible origin hijacks were detected by BGPStream between 20 May 2018 and 31 May 2019. Analysing these hijacks gives insight into the causes and characteristics of origin hijacks. This can help to find the most pressing issues and may provide guidance in securing BGP. Various data sources are used to collect and compute features that give more information on each hijack. These features are used to find relations between hijacks and to label them using labels that indicate a cause or a certain aspect of the hijack. These relations and labels are used to analyse groups of similar hijacks. This approach is very effective. Using the context of a group of hijacks gives much more insight than looking at hijacks individually. It shows that many of the possible hijacks are likely not a hijack at all and that hijacks that look like origin hijacks are often the result of another type of attack called a path hijack. In addition, this thesis provides a way to detect several types of misconfigurations and points out weaknesses in the detection system used by BGPStream. It also gives an overview of the characteristics of hijacks and how often specific behaviour occurs.","BGP; Origin hijacks; Internet","en","master thesis","","","","","","","","","","","","","",""
"uuid:5c3fdf81-dbe9-45cb-8021-3acc6222a112","http://resolver.tudelft.nl/uuid:5c3fdf81-dbe9-45cb-8021-3acc6222a112","Quantum synchronisation and the validity of its derivation","Meijssen, Vosse (TU Delft Applied Sciences; TU Delft Electrical Engineering, Mathematics and Computer Science)","Dubbeldam, Johan (mentor); Blanter, Yaroslav (graduation committee); Delft University of Technology (degree granting institution)","2019","In this bachelor thesis, the paper ”Classical synchronization indicates persistent entanglement in isolated quantum systems” by Dirk Witthaut et al. is looked into and discussed. First, synchronization in a classic sense is explained. The Kuramoto model is introduced, and a few properties of this model are defined. In the next part of the theoretical background, the creation and annihilation operators are defined. An example is given on how to derive these operators, and how to write the Hamiltonian in the form of creation and annihilation operators. It becomes clear that the Hamiltonian of a vector potential in vacuum does not have any coupling terms. This is why no synchronization will occur here. Assuming the Hamiltonian has a different form with two-body interactions and a coupling factor, then it will have some sort of interaction between modes. Dirk Witthaut published in his paper a way to derive the Kuramoto equation from this Hamiltonian. First, the time derivative of the expecta- tion value of the â n operator is evaluated by using the Ehrenfest theorem. This returns multiple three point functions. These can also be evaluated by the Ehrenfest theorem, but that will only result in more coupled equations and five point functions. To solve it, a first order mean field approximation is used. According to Witthaut, this results in a series of coupled complex differential equations which can be rewritten into the Kuramoto equations. Witthaut then further elaborates this result in the remainder of his paper. My calculations point towards a different conclusion. Witthaut made a mistake when calculating the commutation relations that were used in the Ehrenfest theorem. This resulted in a different system of coupled equations, which I couldn’t elaborate into the Kuramoto model. This is the conclusion of this bachelor thesis.","Synchronization; Kuramoto model; Kuramoto oscillators; Witthaut; Mean field approximation","en","bachelor thesis","","","","","","","","","","","","","",""
"uuid:5321df04-39e6-4128-9eec-c3adcac8a68a","http://resolver.tudelft.nl/uuid:5321df04-39e6-4128-9eec-c3adcac8a68a","Parametric Modelling Method based on Knowledge Based Engineering: The LNG Bunkering Vessel Case","Charisi, Nicole (TU Delft Mechanical, Maritime and Materials Engineering)","Kana, Austin (mentor); Hopman, Hans (mentor); Papapanagiotou, Nikos (mentor); Beelaerts van Blokland, Wouter (graduation committee); Delft University of Technology (degree granting institution)","2019","This thesis aims in the development of a parametric modelling method for the preliminary ship design based on Knowledge Based Engineering (KBE). The research work was conducted in cooperation with C-Job Naval Architects. Nowadays, parametric models can be seen as the core of the design practice since they facilitate the exploration of the preliminary design space, and thus, multiple design solutions can be assessed. The present work proposes a parametric modelling method based on knowledge building blocks instead of geometric entities, and thus, KBE was identified as a suitable tool to deploy for its development. The starting point of the design method is the identification of the design requirements and the main drivers analysis of the vessel type. The next step is associated with the determination of the High Level Primitives (HLPs), which are the building blocks of the design containing product knowledge. The HLPs are qualitatively and mathematically described. Finally, in order to form the vessel’s parametric model, the HLPs are combined and tuned to fit the design problem. The proposed method was applied to the LNG bunkering vessel in a case study. A real design case of the company and three more design cases are described and assessed.","Ship Design; Preliminary design; Parametric modelling; KBE; LNG Bunkering Vessel","en","master thesis","","","","","","","","","","","","Marine Technology | Ship Design","",""
"uuid:e2c6c533-bb66-4bff-8e49-70fce4968763","http://resolver.tudelft.nl/uuid:e2c6c533-bb66-4bff-8e49-70fce4968763","A Real-time Simulator for the Sport of Skeleton","Shankar, Sanjit (TU Delft Mechanical, Maritime and Materials Engineering)","Schwab, Arend (mentor); Seth, Ajay (graduation committee); Shyrokau, Barys (graduation committee); Delft University of Technology (degree granting institution)","2019","The track bound sliding sport of Skeleton was permanently added to Winter Olympics programme in 2002. This has led to increased interest in the sport. Engineering has already proved to be a vital contributor to improved performance in the related sport of Bobsleighing. We hope that engineering can do the same for Skeleton. This report describes an attempt at developing a platform to be used as a real-time training simulator for the sport of Skeleton. For a multitude of reasons athletes are, on average limited to a total of two hours of practice and competitive on-track time in any given year. When compared with time spent practising and in competition in most sports, this is extremely low. It is hypothesized that a simulator can augment track time by providing a realistic environment to practise in, even when access to a track is not available. This work is guided by simulators that have been developed for Bobsleighing. The main components are the models to describe the dynamics of the sport, an input method and visualization of the simulation. The main considerations for the dynamic model are of the track surface, the sled and contact between sled and track surface. These models lead to a system of equations which when solved provide accelerations and contact forces. The accelerations are integrated over a fixed time interval to determine changes in velocities, position and orientation. The position and orientation obtained after the integration is passed on to a game engine which provides the user with real-time visual output of the position and orientation along a digitally recreated track surface. A video game controller was chosen to serve as the input device. It has two joysticks, which can be mapped so as to mimic the forces applied by an athlete. A number of descents were performed using this platform both at real-time speed and at a slower speed to give the user, unfamiliar with the sport, a better chance to steer the sled. We were able to consistently reach the exit of curve 2 in real-time speed and curve 4 at the slower play speed before failure of the simulation. In most cases the algorithm used here proves to take lesser time for computation than the chosen integration time step, which is a great sign for future development as we did not make any attempts to optimise its omputation<br/>time. We made an attempt at validation using time elapsed to traverse a certain distance and the sum of magnitude of Lagrangian multipliers. We had poor results with the time elapsed comparison, with simulated runs being 15% slower than competitive descents. While the sum of Lagrangian multipliers showed good relation to expected behaviour. This first attempt was reasonably successful, and we believe that the lessons learnt from this work has brought us one step closer to realizing a training simulator that can be useful to Skeleton athletes.","Real Time Simulation; Winter Sport; Skeleton; Dynamics","en","master thesis","","","","","","","","","","","","","",""
"uuid:feeb2223-49c8-42fc-b23c-632488f05f3d","http://resolver.tudelft.nl/uuid:feeb2223-49c8-42fc-b23c-632488f05f3d","Insight into the May 2015 inflation event at Kīlauea volcano, Hawai'i: A look into the subsurface with geodetic measurement tools","Bemelmans, Mark (TU Delft Civil Engineering and Geosciences)","de Zeeuw-van Dalfsen, Elske (mentor); Hanssen, Ramon (graduation committee); Draganov, Deyan (graduation committee); Delft University of Technology (degree granting institution)","2019","We use ground and space geodetic data to study surface deformation and gravity change at Kīlauea volcano from January to September 2015. This period includes an episode of heightened activity in May 2015, which we refer to as ’the May 2015 event’. The data set consists of Global Navigation Satellite System (GNSS), tilt, visual and seismic time series along with 25 descending and 15 ascending acquisitions of the Sentinel-1a satellite in Interferometric Wide swath mode and microgravity surveys taken a few years before and just after the May 2015 event. We identify four different stages of surface deformation and volcanic activity during the May 2015 event which we attribute to the movement of magma and pressure changes in response to a magma supply and withdrawal imbalance in the shallow plumbing system. In particular, we model the deformation sources attributed to the Halema’uma’u reservoir (HMMR) and South caldera reservoir (SCR). The SCR was best described by inflation of a spheroidal at 2.8 (2.65-3.07) km depth below the Southern caldera region. The HMMR source was modelled by a point source deflation located East of the Halema’uma’u crater at 1.5 (0.95- 2.62) km depth. The surface microgravity changes which would result from changes in these reservoirs are significantly lower than the actually observed microgravity changes. We attribute this to the lack of complexity of the single point source model used. Mechanisms that add/remove mass from the subsurface without accompanying surface deformation, which are not part of the point source model, played a significant role. More frequent microgravity campaign surveys, if needed with a smaller network, are the only way to improve our understanding of these processes and help to quantify them.","Volcano deformation; InSAR; Gravimetry; Kīlauea; May 2015 event","en","master thesis","","","","","","","","","","","","Geoscience and Remote Sensing","","19.420,-155.288"
"uuid:85aa19e0-a3c4-4a6b-9d25-dbf0c2f6c8bd","http://resolver.tudelft.nl/uuid:85aa19e0-a3c4-4a6b-9d25-dbf0c2f6c8bd","Instrumentation of a Skeleton Sled: Novel Tactile Steering Force Sensors","Rachello, Camilo (TU Delft Mechanical, Maritime and Materials Engineering)","Schwab, Arend (mentor); Plettenburg, Dick (graduation committee); van der Wijk, Volkert (graduation committee); Delft University of Technology (degree granting institution)","2019","The purpose of this project is to design and develop a set of force sensors to measure steering forces applied by an athlete down the ice track. Currently, there is not enough information about instrumentation in skeleton, and to maintain competitive advantages, most of the research remains private and unpublished. Athletes use their shoulders and knees to steer down the track. For this reason, four handmade piezoresistive tactile force sensors were built to measure the force applied by each joint. Each sensor has its own model to convert bits recorded into force. Results showed a difference between applied and calculated forces by each model. However, calculated results followed similar trends compared to the real values of the applied force. In addition, a graphical user interface was created to present the results to the athlete in a simple and easy way to read and understand. It is planned to use a shimmer (an inertial measurement unit) to collect information about accelerations developed on each run. Coupling both measurement systems have to be done during the processing stage. Further work has to be done regarding electronics size and testing the systems in a real run down the track.","Skeleton; Sports; Instrumentation; Sports engineering","en","master thesis","","","","","","","","","","","","Mechanical Engineering | BioMechanical Design | Sports Engineering","",""
"uuid:b6314865-e661-44fa-b757-701950f503a7","http://resolver.tudelft.nl/uuid:b6314865-e661-44fa-b757-701950f503a7","Improving higher manganese silicide thermoelectric material by phonon scattering with nanostructures","Rooijmans, Jannick (TU Delft Electrical Engineering, Mathematics and Computer Science)","Böttger, Amarante J. (mentor); Delft University of Technology (degree granting institution)","2019","Matching the increase in energy demand while also reducing the greenhouse gas emission is a worldwide problem. Thermoelectrics have the potential to fit in everywhere, recovering waste heat to generate electricity. Higher manganese silicide (HMS) is a thermoelectric material made from abundant elements, with promising performance for temperatures of 700 to 900 K. In this research, HMS samples containing SiO2 and TiO2 nanoparticles were prepared using ball milling and spark plasma sintering to reduce the thermal conductivity of HMS by phonon scattering. The microstructure of the samples was evaluated with SEM/EDS and XRD, confirming the presence of the nanoparticles inside the HMS. TiO2 nanoparticles were reduced to Ti2O3. Room temperature thermal conductivity measurements show that adding 2 vol% nanoparticles reduces the thermal conductivity by more than 10% for both SiO2 and TiO2 nanoparticles. As a side-effect, the material became denser with added nanoparticles, resulting in a higher electrical conductivity benefitting the thermoelectric performance. However, the reaction between manganese and silicon is incomplete when nanoparticles are present, leading to increased MnSi and silicon phases resulting in a 10% decreased Seebeck coefficient. The nanoparticles successfully improved the thermoelectric performance of HMS, and with further improvements such as preventing the MnSi phase from forming and doping the material to increase electrical conductivity, HMS is a promising thermoelectric material.","Thermoelectric","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:1b482e0f-6e06-465a-8f7d-ec680d80ac0b","http://resolver.tudelft.nl/uuid:1b482e0f-6e06-465a-8f7d-ec680d80ac0b","Late payment prediction of invoices through graph features","Hovanesyan, Arthur (TU Delft Electrical Engineering, Mathematics and Computer Science)","Wang, Huijuan (mentor); Redi, Judith (mentor); Cesar Garcia, Pablo (graduation committee); Lofi, Christoph (graduation committee); Delft University of Technology (degree granting institution)","2019","Keeping a steady cash flow is one of the biggest if not the biggest problem that Small to Medium Enterprises (SMEs) deal with daily. Within the different types of cash flow, Accounts Receivable (AR) classifies the balance of money that needs to be paid by the company's customers. In the most typical case, after receiving goods or services, the customer receives an invoice with the amount that is owed to the supplier. However, this often does not happen before the aforementioned date, meaning that the invoice is often paid late. Intervention requires resources and over-intervention could cause unwanted customer dissatisfaction. Knowing whether an invoice is going to be paid late can be vital information. Current methods of late payment prediction focus only on the history between the seller and the buyer and are unusable when this history is not present. Intuitively, one's business depends on the relationships and transactions that it has with its neighbors. Suggesting that neighbor behavior could be useful when predicting the cash flow of a company. Unfortunately, this type of information is not always given and needs to be data mining from non-relational data. This work presents a method for building a relational network of SMEs using entity resolution and improving the current state of the art of late payment prediction using features extracted from the graph.","Machine Learning; Feature Engineering; Graph Embedding; Entity Resolution","en","master thesis","","","","","","","","2020-07-01","","","","Computer Science","",""
"uuid:096776e4-5a78-4cee-b764-24c8d964811f","http://resolver.tudelft.nl/uuid:096776e4-5a78-4cee-b764-24c8d964811f","Are University Business Incubators Overprotective Parents?: A Knowledge as a Resource-Based Perspective on Growth of Academic Spinoffs using an Open Innovation and Absorptive Capacity Framework","Tandon, Mihir (TU Delft Technology, Policy and Management)","Verburg, Robert (graduation committee); Scholten, Victor (mentor); Delft University of Technology (degree granting institution)","2019","University business incubators are a global rising phenomenon and have an imprint on the genetics of high technology-based academic spin-offs and are central to the triple-helix model of innovation systems for academia-industry-policy. Research focused on Regional Innovation System of Delft suggest that the high technology-based start-ups face challenges in their growth up to a time period as long as four years due to resource-based obstacles and this can be a factor affecting the mortality rate of start-ups in the regions. University business incubators are a powerhouse of open innovation and support permeable firm boundaries for external knowledge, organizations cannot enjoy competitive advantage just by the virtue of being exposed to it but have to acquire, assimilate (Potential Absorptive Capacity), transform and exploit (Realized Absorptive Capacity) knowledge as a resource. Relatively less is known about how does the incubator support help the start-ups to develop their dynamic capabilities and the possible implications of this parent-spin-off relationship on their growth after graduation from that incubator and removal of the incubator support. Thus, to address this research gap, this research study examines 67 academic startups from Yes! Delft by finding the answer to the research question -<b><i>” What are the implications of a university incubator’s support to academic start-ups to implement open-innovation &amp; develop dynamic capabilities on the growth of academic start-ups?”</i></b>. From an extensive literature review, a hierarchal conceptual model is developed where a lower order consists of open innovation based activities and higher-order consists of dimensions of absorptive capacity, tested for outcome variable competitive advantage using three constructs- Innovation, Strategic Flexibility and Product development Related Performance. The data is collected using a questionnaire &amp; analyses is done for PLS-SEM using the software SmartPLS3.0. The findings for three sub-research questions are then interpreted to understand growth implications for navigation critical junctures -<i>opportunity recognition, entrepreneurial commitment, credibility &amp; sustainable returns,</i> followed by suggestions for practitioners.","regional innovation systems,; incubator support; triple-helix; academic start-ups; absorptive capacity; Open Innovation; dynamic capabilities; knowledge-based view; competitive advantage; growth of academic start-ups; strategy management; entrepreneurship; PLS-SEM","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:196d467a-f0ae-480d-a3e3-d2da97e821bc","http://resolver.tudelft.nl/uuid:196d467a-f0ae-480d-a3e3-d2da97e821bc","Estimating snow cover decline using the RSLE in Google Earth Engine: A Caucasus case study","van Esch, Thijs (TU Delft Civil Engineering and Geosciences)","Hrachowitz, M. (mentor); Lhermitte, S.L.M. (graduation committee); Steele-Dunne, S.C. (graduation committee); Delft University of Technology (degree granting institution)","2019","Snow in mountainous areas is of great importance for the water supply in many catchments. To get data on snow cover, ground station data is not enough and, in many catchments, not available. Therefore, satellite data is used to measure snow cover. In this thesis the MODIS daily snow cover dataset (MOD10A1) is used. These images are obstructed by clouds. In order to create a complete dataset, the Regional Snowline Elevation Method is used which uses the elevation of the snowline to interpolate over the missing data. This method is accurate but is computationally demanding. Using Google Earth Engine, it is attempted to improve the method. The method developed combines grid cells with daily images and computes the RSLE for each cell, for each day. The results are exported to a CSV file, reducing the downloaded data from 150GB to 41.6 MB for the 0.50° resolution and 168MB for the 0.25° resolution. The computation time however was not improved with this method. The developed code was used on the Caucasus area. After the data from Google Earth Engine was downloaded, trends on yearly snow cover duration were computed using the Mann-Kendall test. It followed that 17% of the trends in both resolutions were significant and, except for one location, were all decreasing trends. The decreasing trends show a decline of snow cover duration of 1-4 days per year. Looking at regional differences it becomes clear the greatest number of trends can be found in the south-west. The Google Earth Engine code was able to compute the required data however, it took a long time doing so. Therefore, a more sophisticated code has been developed, making used of the ability to reduce the resolution of an image, and computing the value of pixels at the same time. This code runs quicker, but is at this moment unusable, due to problems with the thresholds and export. Being unable to export an image collection is one of the shortcomings of Google Earth Engine. Others include: download tasks that run out after twelve days without raising an error when starting the task, limits to the amounts of bands used, and sensitivity of the computation time to busyness on servers. Things that need to be improved and need further research are: the filters applied to smoothen the dataset, the use of other trend analyses, the effect of snow cover trends on the area, and the resolution in combination with the cloud threshold value. The analyses took six hours to run, which can be improved by using function-based programming, instead of process-based.<br/>In the end the goal to develop a more efficient method has partly been met by decreasing the amount of downloaded data significantly, even though the running time has not been improved. Using the data from the developed method, decreasing trends were found in snow cover duration over the entire Caucasus but mainly in the South-West, which can greatly influence the water supply to a large part of the Caucasus and its surrounding areas.","Snow; Google Earth Engine; Caucasus","en","master thesis","","","","","","","","","","","","Water Management","","41.323071, 44.265189"
"uuid:00975f34-bfb3-4289-8aca-51ed498c9ceb","http://resolver.tudelft.nl/uuid:00975f34-bfb3-4289-8aca-51ed498c9ceb","Strategic Design of a Medical Consumable: From product to circular service","van Hamersveld, Mike (TU Delft Industrial Design Engineering)","Mugge, Ruth (mentor); Baldassarre, Brian (mentor); Heesemans, Michael (mentor); Shahbazi, Kevin (mentor); Delft University of Technology (degree granting institution)","2019","The world of today is facing a large environmental challenge. We all need to reduce our impact to remain sustainable. Companies must look at a more circular approach of producing their goods. Without consumers engaging in circular behavior however, the circular economy will not reach its potential.To examine the circular economy approach in a medical domain, a case study is done at Philips Design. Specifically, we look at the Healthdot, a medical sensor for at home, currently not envisioned to become circular, being developed by a venture team within the company.The objective in the case is: How can we engage patients to send back the device after wearing it at home in order to enable a circular offer for the Healthdot? To find opportunities that make a circular offer for the Healthdot the product and its ecosystem is analyzed. When a device with the current product design can be recovered, the PCBA can be reused. To increase circularity, it needs a redesign. A feasible redesign allows every component except for the adhesive part to be reused. Since the latter opportunity requires are design, it is a long-term opportunity. Both scenarios require the Healthdot to be retrieved from the patients wearing it at home. The hospitals role is limited in this recovery. They are pressured to move the care they provide more outside of the hospital and extra handlings with a device means a less attractive value proposition towards them. By interviewing ex-patients it became clear that the experience they have after surgery, is not pleasant in any way. Specific pain points throughout this recovery show potential to improve patient experience and motivate them to send back the device. Patients receive scattered and non-personal information, are physically and mentally burdened, are uncertain about their progress. Next to that, family and friends are heavily involved during this period. Picking the device up at patients homes is an expensive undertaking and needs an additional pick-up service to be realized. The most promising opportunity is to have the device sent back by the patients. According to Fogg (2009), three preconditions need to be present simultaneously for an action to happen.These elements are addressed in a first concept, which aimed to provide motivation through pleasure in the means of a package with insight in patients data. The concept increases their ability to perform the behavior by providing all the materials needed for send-back, together with clear instructions. The concept aimed to trigger them through several text messages. After testing this with 6 other ex-patients and their partners at their dinner table, 4 main insights led toan improvement and final design.• The hospital contacting patients created the feeling of reciprocation, this was perceived as the most motivating factor to send back the device.• When patients are being monitored they have expectations for meaningful insight in the data. They except to hear something from the hospital related to their monitoring and recovery.• Perceived as easiest to send back was taking it to a regular mailbox, when the materials such as a return envelope were provided and sending was free of charge. This allowed patients to be in control of when and where exactly to return the healthdot. • Physically moving the device out of the house while sending back resembled closure of are covery phase for patients.These insights led to a final solution of an advent calendar, communication platform and a redesigned device. To reach this solution in 2022, the first step that can be made towards the end of 2020 is a concept that entails a messaging service and send-back materials for the patients. One component of the final solution is an advent calendar that patients receive when they are discharged. It is to be placed at their homes, and includes several boxes to be opened during the recovery phase at home. The final box includes all material needed for sending back the Healthdot. The calendar works together with a communication platform. Patients receive notification when they can open another box and QR-codes link to the platform. Healthdot functionalities are integrated in a larger communication platform in development by Philips. The platform enables communication between different care providers and the patient. It also can be accessed by a patients partner or other loved one, if permitted. The Healthdot needs a redesign to increase value retention and go from a parts recovery strategy on the short-term, to refurbishment for the final solution. This redesign would enable reuse of all components except the adhesive part of the device. The Healthdot becoming circular results in a triple win. Philips is able to save money, improve their value proposition towards hospitals and can add yet another proof point of sustainability to their repertoire. The patients will go through an improved recovery experience compared to the current experience. Thirdly, the environmental impact decreases through the reuse of components and less intensive use of the full manufacturing processes. This thesis led to the Healthdot venture team pursuing circularity already on the short-term, instead of a future possibility onthe longer-term.","circular economy (CE); medical consumable; behavior change","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:51b817f4-6763-4d69-b5eb-d8a2efa62eb5","http://resolver.tudelft.nl/uuid:51b817f4-6763-4d69-b5eb-d8a2efa62eb5","Distributional Fairness in Road Safety Policies: Α Discrete Choice Approach to Explore Citizens’ Preferences on the Distribution of the Effects of Road Safety Policies","Kosmidis, Ioannis (TU Delft Technology, Policy and Management; TU Delft Transport and Planning)","van Wee, Bert (mentor); Molin, Eric (graduation committee); Farah, Haneen (graduation committee); Delft University of Technology (degree granting institution)","2019","This study aims to explore the preferences of citizens regarding fairness considerations related to the distribution of the effects of road safety policies in order to provide with policy recommendations that will help to promote more fair road safety policies. To achieve this aim the Discrete Choice Approach is going to be followed, using stated preference data. This requires a Stated Preference experiment to be conducted, which consists of two distinct parts. The first part is related to the citizen’s perception of fairness of different types of distribution of the effects of road safety policies, while the second one is related with the importance of this perceived fairness in the preference of citizens over specific road safety policy alternatives. In the first case, two Linear Regression models have been estimated, while for the second case, three Discrete Choice models. This study has shown that the Discrete Choice Approach can actually give some insight to moral dilemmas as it is suggested in literature. It also showed that low public acceptance can be a show-stopper for road safety policies, thus looking only at the aggregate effects of a road safety policy can be often misleading. The way that the effects of road safety policies are distributed among different groups of people can have a significant influence on the public acceptance of road safety policies.","Distributional Fairness; Road Safety; Discrete Choice Modelling; Fairness Perception; Stated Choice Experiments; Hierarchical Information Integration","en","master thesis","","","","","","","","","","","","Civil Engineering | Transport and Planning","",""
"uuid:d688f5eb-023e-4366-90af-6effdcf673ac","http://resolver.tudelft.nl/uuid:d688f5eb-023e-4366-90af-6effdcf673ac","Explorative study towards the integration and combination of three technologies into a virtual control system","Spel, Bart (TU Delft Industrial Design Engineering)","van Heur, Rudolf (mentor); Horvath, Imre (mentor); Eijkelenboom, Ad (mentor); Delft University of Technology (degree granting institution)","2019","Interacting with holograms is something which is widely speculated about. Combining holographic projections with haptic feedback and gesture control might bring this concept closer to reality. This project aims at exploring the possibilities of combining these three technologies into a combined virtual control system. Project owner Safran initiated the project concerning the combination of three technologies into a single virtual control system. This system could provide added value to a lavatory environment by enabling the passenger to open a door without having to physically touch the unhygienic surface. An analysis phase was concluded investigating the different individual technologies and their respective maturities. Conclusions were drawn based on the ability of the components to be integrated into a system operating in a single volume of space. Next to the technological aspects, business, user and environmental aspects were analysed in order to create a better understanding of the aerospace market, the potential target group and the operational environment. Trends were used to indicate potential opportunities and the user and environmental analysis formed the basis for further conceptualisation. Different application environments were explored together with respective scenarios. A lavatory implementation was selected as the preferred context for the creation of a functional prototype. The detailing selected an ultrasound transducer array as carrier for the haptic component. An eye-tracking stereoscopic display was selected as the carrier for the holographic component. Finally a camera based sensor using a skeletal algorithm was selected as the most suitable carrier for the gesture component. An architecture was proposed combining these technologies into a single system. The interface was designed for the selected context in order for the development of a demonstrator. The prototype was created in collaboration with Dimenco, the developer of the Simulated Reality (SR) development kit, an eye-tracking stereoscopic screen. The SR kit was combined with the already acquired Ultrahaptics transducer board and a Leap Motion sensor to start building the proof of concept. The projections were aligned in order for the user to perceive the designed interface in a single volume of space. Functionality was added and visual polishing concluded the creation of the demonstrator. The demonstrator showed the combination of the three technologies into a single interface which allowed the user to interact with a lavatory door. Test results indicated a good understanding of the 3D system with intuitive reactions without additional instructions. However more research is required to prove the viability of a virtual control system in an aircraft environment. Weight and cost play an important factor in the industry, both have to be optimised in order for the system to become viable. The thesis concluded with suggestions for further development.","Virtual; Control; System; Holographic; Ultrasound haptics; Stereoscopy; Gesture control; Lavatory; Aircraft environment","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:8f10daad-cdd6-41ae-b402-b6bd00825bca","http://resolver.tudelft.nl/uuid:8f10daad-cdd6-41ae-b402-b6bd00825bca","Air-based Contactless Wafer Precision Positioning System: Contactless Sensing Using Charge Coupled Devices","Hooijschuur, Rico (TU Delft Mechanical, Maritime and Materials Engineering)","Saikumar, N. (mentor); Hossein Nia Kani, S.H. (mentor); van Ostayen, R.A.J. (graduation committee); van Wingerden, J.W. (graduation committee); Alijani, F. (graduation committee); Delft University of Technology (degree granting institution)","2019","This thesis presents the development of a contactless sensing system and the dynamic evaluation of an air-bearing based precision wafer positioning system. The contactless positioning stage is a response to the trend seen in the high-tech industry, with the substrates becoming thinner and larger to reduce the cost and increase the yield. With contactless handling, it is possible to avoid damage and contamination. The system works by floating the substrate on a thin film of air. A viscous traction force is applied on the substrate by steering the airflow. A cascaded control structure has been implemented to the contactless positioning system, where the Inner Loop Controller (ILC) controls the actuator which steers the airflow and the Outer Loop Controller (OLC) controls the position of the substrate by controlling the reference of the ILC. The dynamics of the ILC are evaluated and optimized for the performance of the positioning of the substrate. For the OLC a linear charge-coupled device (CCD) has been implemented as a contactless sensing system. The sensing concept is implemented in the contactless actuation system and the results are presented.","contactless; Handling; CCD; air-based; Actuator","en","master thesis","","","","","","","","2021-12-18","","","","Mechanical Engineering | Mechatronic System Design (MSD)","",""
"uuid:69be960d-2ef3-4945-99c2-43eb1e1a52bb","http://resolver.tudelft.nl/uuid:69be960d-2ef3-4945-99c2-43eb1e1a52bb","Green Haber-Bosch Process:A Small-Scale Ammonia Reactor System Design","Liang, Cheng (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Process and Energy)","Goetheer, E.L.V. (mentor); Feenstra, Maartje (graduation committee); de Jong, W. (graduation committee); Eral, H.B. (graduation committee); van Kranendonk, Jan (graduation committee); Delft University of Technology (degree granting institution)","2019","The global energy transition from a fossil fuel base energy system to a renewable energy source base system is the key mission for a low-carbon future. The target of CO<sub>2 </sub>emission reduction by 2050, following the Paris Climate Agreement, is 90% compared to the CO<sub>2</sub> level of 1990. Haber-Bosch process is the main industrial procedure for the production of ammonia today and about 80% of the global ammonia is consumed by the fertilizer industry. However, the century old Haber-Bosch process is normally energized by fossil fuel and it<br/>releases about 3% of the global carbon footprint. In light of this fact, replacing the conventional fossil fueled Haber-Bosch process for manufacturing ammonia with renewable source powered ammonia production is the main goal of this study. Instead of obtaining H<sub>2</sub> from steam-reformed CH<sub>4</sub>, H<sub>2</sub> is produced from electrolyzed H<sub>2</sub>O. This transition enables the conventional ammonia manufacturing process transforming into a green Haber-Bosch production of ammonia. Two Dutch companies, TNO and Zero Emission Fuels, are cooperating<br/>and developing a small scale of reactor system that can convert ammonia from air and water by using solar PV panels. In this work, a new design of ammonia reactor system is developed. Ammonia is typically formed at high pressure (150 - 250 bar) and high temperature (400 - 500<sup>o</sup>C) using a promoted iron base catalyst. High temperature ensures rapid reaction kinetics, and high pressure boosts the product yield. Here a reactor system, that is operated at lower pressure (≤100 bar) and uses condensation to remove ammonia, is kinetically simulated in ASPEN. The effect of different operation conditions - reaction temperature (300<sup>o</sup>C, 350<sup>o</sup>C and 400<sup>o</sup>C) , pressure (50, 75 and 100 bar) and feed gas (N<sub>2</sub> : H<sub>2</sub>) ratio (1 : 3 and 1 : 5) - on the production rate in a small-scale ammonia reactor have been systematically computed. The mass flow rate of the single pass reactor is set to 50 g/h in this work. With a catalyst bed length of 15 cm and inner diameter of 3.6 cm, according to the simulation, reaction temperature of 400<sup>o</sup>C and operating pressure of 100 bar can lead to the highest conversion (40%) in a single pass reactor. The average heat transfer area of the reactor system is to a great extend less than 50 m<sup>2</sup>, therefore, the double pipe heat exchanger is a favorable heat exchange system for the proposed reactor system. In the reactor design validation section, the selected optimum operation conditions are tested in the same scale reactor laboratory setup. Experimental results show that the single pass conversion of nitrogen at 400<sup>o</sup>C and 100 bar in such a small-scale reactor can reach 15.4% which is in the range of the industrial one pass conversion level. For reaction operated at 50 bar, 6% of ammonia yield is obtained. It is clear that ammonia production in small-scale and in milder operation condition is possible and the results are promising. The techno-economic analysis has been performed based on above mentioned outcome. The reactor system is integrated with ZEF AEC, ZEF compressor system and a membrane nitrogen separation system. With current ammonia design production (350 g/day), the cost of ammonia per kilogram can be achieved in the range of €1.8 to €2 depending on the operation condition. This is about 5 times more than fossil ammonia prices, but it is very competitive with biomass ammonia. In accordance with the sensitivity analysis, increasing the capacity of feed gas production or reducing the cost in plant equipment can remarkably reduce the ammonia price to less than 1 €/kg NH<sub>3</sub>. Furthermore, recommendations in four categories are discussed in the last section of this work, which can lead to a further step towards a green ammonia plant in small-scale.","ammonia; Haber-Bosch Process; Sustainabilty; Small-scale reactor","en","master thesis","","","","","","","","2021-12-18","","","","Mechanical Engineering | Process and Energy Technology","",""
"uuid:7b54a664-e297-4f45-9840-68b185289926","http://resolver.tudelft.nl/uuid:7b54a664-e297-4f45-9840-68b185289926","Electric Propulsion Plasma Plume Simulation","Massaccesi, Nicolo (TU Delft Aerospace Engineering)","Naeije, M.C. (mentor); Laube, Jens (graduation committee); Delft University of Technology (degree granting institution)","2019","In recent years the interest of the space community for electric propulsion has been rising thanks to the advantages that this technology offers. To ensure a correct integration on the spacecraft, it is important to be able to predict the behavior of the plasma plume generated by the thruster. Such plume could in fact damage spacecraft surfaces, produce parasite torques, etc. In order to simulate a plasma with contained computational power, the most used method in literature is the Hybrid Particle In Cell method.<br/>In this research, a model of a Hall Effect Thruster is developed starting from on-ground measurements of the plasma. The model is built for a Hybrid Particle In Cell software. In order to validate the capability of the software to predict in-orbit plasma plume, a comparison with three space mission’s set of data has been performed: Express-A, SMART1 and a satellite developed by OHB System. This thesis aims at proving that the Hybrid Particle In Cell software is capable of predicting the plasma plume reliably, given that this has been correctly set up. The research question leading the work is:<br/>To which degree of precision can a hybrid particle-in-cell method as implemented by PICPluS predict in-orbit plume behavior when tuned with a nonempirical set of simulation parameters?<br/>The thesis has been developed in cooperation with OHB System, a large system integrator leader in the sector, with proven experience in electric propulsion plasma plume simulation. The company provided supervision, all the hardware and software tools employed and an internal set of in-orbit data.<br","electric propulsion; monte carlo collisions; plasma; hall effect thruster","en","master thesis","","","","","","","","2024-12-10","","","","Aerospace Engineering","",""
"uuid:f1c0a23f-63e0-4da3-9595-460218f1d0de","http://resolver.tudelft.nl/uuid:f1c0a23f-63e0-4da3-9595-460218f1d0de","Interpretable Machine Learning for Biomarker Discovery in Imaging Mass Spectrometry Data","Tideman, Leonoor (TU Delft Mechanical, Maritime and Materials Engineering)","Van de Plas, Raf (mentor); Delft University of Technology (degree granting institution)","2019","Imaging mass spectrometry (IMS) is a multiplexed chemical imaging technique that enables the spatially targeted molecular mapping of biological samples at cellular resolutions. Within a single experiment, IMS can measure the spatial distribution and relative concentration of thousands of distinct molecular species across the surface of a tissue sample. The large size and high-dimensionality of IMS datasets, which can consist of hundreds of thousands of pixels and hundreds to thousands of molecular ions tracked per pixel, have made computational approaches necessary for effective analysis. This thesis focuses primarily on biomarker discovery in IMS data using supervised machine learning algorithms. Biomarker discovery is the identification of molecular markers that enable the recognition of a specific biological state, for example recognizing diseased tissue from healthy tissue. Biomarkers are increasingly used in biology and medicine for diagnostic and prognostic purposes, as well as for driving the development of new drugs and therapies. Traditionally, the focus has been on maximizing the predictive performance of supervised machine learning models, without necessarily examining the models' internal decision-making processes. Yet, in order to generate insight into the underlying chemical mechanism of disease or drug action, we must go beyond the scope of just prediction and learn how these empirically trained models make their decisions and who are the primary chemical drivers of this prediction process. Machine learning model interpretability is the ability to explain a model's predictions, and can practically be translated into the ability to explicitly report the relative predictive importance of each of the dataset's features. When analyzing IMS data, interpretability is crucial for understanding how the spatial distribution and relative concentration of certain molecular features relate to the labeling of pixels into different physiological classes. The key to our data-driven approach to biomarker discovery in IMS data is to establish (in relation to a specific biomedical recognition task) a means of ranking the molecular features of supervised machine learning models according to their respective predictive importance scores. Ensuring model interpretability and feature ranking in supervised machine learning allows empirical model building to be used as a filtering mechanism to rapidly determine, among thousands of features, those features that exert a large amount of relevance to a specific class determination. With regards to biology, the top-ranking features can help empirically highlight important molecular drivers in the biological process under examination, and can help generate new hypotheses. In terms of translational medicine, such top-ranking features can yield a shortlist of candidate biomarkers worthy of further clinical investigation. Three different classifiers, namely logistic regression, random forests, and support vector machines, are implemented and their performance is compared in terms of accuracy, precision, recall, scale invariance, sensitivity to noise, and computational efficiency. Subsequently, several approaches to explaining these classifiers' predictions are implemented and investigated: model-specific interpretability methods are tied to intrinsically interpretable classifiers, such as generalized linear models and decision trees, whereas model-agnostic interpretability methods can also explain the predictions of black-box models, such as support vector machines with nonlinear kernels or deep neural networks. In addition to three model-specific methods, we present two post-hoc model-agnostic interpretability methods: permutation importance and Shapley importance. Our implementation of Shapley importance, based on Shapley values from cooperative game theory, is novel. Having observed a variability between the rankings of different interpretability methods, we investigate improving the inter-method reliability of feature rankings by decorrelating the features prior to training the classifiers. We also propose a robust ensemble approach to interpretability that aggregates the importance scores attributed to each feature by different model-specific interpretability methods. We demonstrate our methodology on two biomedical case studies: one MALDI-FTICR IMS dataset taken from the coronal section of a rat brain, and one MALDI-TOF IMS dataset taken from the sagittal section of a mouse-pup.","Machine Learning; Imaging Mass Spectrometry; Medical imaging; Interpretation; Artificial intelligence; Biomarker; Support Vector Machines; Logistic regression; Random Forest; Principal Component Analysis; Classification; Supervised machine learning; Data Science","en","master thesis","","","","","","","","2022-12-01","","","","Mechanical Engineering | Systems and Control","",""
"uuid:0beabb3b-b4d8-41c7-bd3a-9b5dcef78bfc","http://resolver.tudelft.nl/uuid:0beabb3b-b4d8-41c7-bd3a-9b5dcef78bfc","Using the water pinch analysis to optimize the water network of a brewery and its neighbours to achieve circularity: Can the process effluent of a brewery be used to grow oranges?","Holland, Noor (TU Delft Civil Engineering and Geosciences; TU Delft Sanitary Engineering)","Spanjers, H. (mentor); Rietveld, L.C. (graduation committee); Korevaar, G. (graduation committee); Bruijn, Paul (mentor); Delft University of Technology (degree granting institution)","2019","Water is an important resource in many industries in the world. Due to emerging regulatory framework, change in consumer’s perspective and increasing costs for water, industries are forced to move towards sustainable water use. Nowadays, improvements in the brewery industry are focussed on increasing the efficiency of the processes or treating the complete wastewater stream on site. Water network optimization models can effectively decrease the fresh water flowrate and wastewater flowrate production. The water pinch is in most cases used to optimize fresh water use and wastewater production in a single industry. This thesis is the first to use the water pinch in a circularity concept of a wider network with a brewery and external user. Circularity is in this thesis defined as the percentage of water from a brewery that can be reused by an external party, after it has been used inside the brewery. Two case breweries in Egypt were used to illustrate the water pinch method, El Obour brewery and Sharkia brewery. For both breweries an orange orchard of 87 ha with a water demand of 9836 m3/month was indicated as the external user. Per brewery, a list of water using processes that produce an effluent was determined. This list contains the CIP processes in the brew house and cellars and includes every process in the packaging department. In addition, the utility department processes cooling towers, boilers and CO2 washers were part of the water network of the breweries. The initial water network of El Obour consisted of 18 brewery processes and one external user, the orange orchard. Sharkia brewery had 17 brewery processes and the orange orchard. Actual process water flowrates were used as well as UBM process water flowrates. For El Obour brewery the initial fresh water flowrate was 9755 m3/month and 8466 m3/month for UBM process water flowrates. The Sharkia brewery initial fresh water flowrate was 15695 m3/month and 14961 m3/month for UBM process water flowrates. COD, Total N and Na+ were identified as key constituents. Per key constituent, a composite curve was constructed and a new, optimized water network designed. For the El Obour brewery the water pinch steps were described in detail to show how the composite curves and the networks could be constructed. The Sharkia brewery was used to validate the method. With the composite curve and pinch point determined, processes could be indicated as source or sink. The orange orchard was always considered as a sink and was satisfied first with every possible source. The water that was flowing from the brewery to the orange orchard identified the circularity potential of the network. COD was the reference constituent for both breweries as the most restrictions occurred in this network. With the COD limiting network as basis, integrated networks were designed that complied with every constituent restriction. The results showed that for El Obour the fresh water consumption decreased with 7% to 7909 m3/month and the wastewater production decreased with 22% to 6607 m3/month. Resulting in an initial circularity potential of the El Obour brewery of 11 – 13% (depending on the used process water flowrates based on actual measurements or UBM). The fresh water consumption and wastewater production savings for Sharkia were respectively 0% and 34%. The Sharkia brewery could be 28 – 34% circular on water in the initial phase without treatment of effluents (depending on the used process water flowrates based on actual measurements or UBM). 100% circularity could not be achieved due to too high Na+ and COD concentrations. Total N caused no restrictions for reuse. The results show that the water pinch can be used to determine to what extend the case breweries can be circular on water with an external user. The water pinch is not only an optimization tool but it can help industrial sites including a brewery to identify collaboration between different users of the local watershed. Hereby increasing the circularity on water. <br","Circularity; Water; Water pinch; Industry; Brewery; Reuse; Optimization","en","master thesis","","","","","","","","2021-12-18","","","","Civil Engineering | Environmental Engineering","",""
"uuid:d1640a29-c0e2-4738-b0ae-21ed9d1a7f77","http://resolver.tudelft.nl/uuid:d1640a29-c0e2-4738-b0ae-21ed9d1a7f77","The footprint of yacht production: Defining a framework for the Yacht Environmental Transparency Index","Cozijnsen, Lisette (TU Delft Mechanical, Maritime and Materials Engineering)","Pruijn, Jeroen (mentor); Korevaar, Gijsbert (graduation committee); Tsalidis, George (graduation committee); Kana, Austin (graduation committee); Jongepier, Bram (graduation committee); Delft University of Technology (degree granting institution)","2019","This research has been performed with the goal to set up a model for the comparison of the environmental impact caused by the production of yachts. This model is created in such a way that it can be implemented in the YETI, Yacht Environmental Transparency Index, which is currently under development. The model that is created is based on a Life Cycle Assessment methodology named Fast Track LCA. This methodology consists of five steps which are further standardized to meet the requirements of the YETI. Choices are made for the functional unit, system boundaries, the quantification of materials, the assessment method, environmental database and LCA software. With a case study, the created model is validated as the results have realistic values. Some other design choices are applied on the case study to check the sensitivity of the model. The sensitivity was enough to show the effect of a different hull material and the use of batteries for the hotel load and peak shaving. It is concluded that the model can be used for the comparison of the environmental impact from production of different yachts. However, it should be noted that due to design choices for the model based on the requirement for comparison, the outcome itself is an underestimation of the environmental impact from yacht production.","Yacht building; Yacht production; Ship production; Sustainabilty; Footrprint; Fast Track LCA; Life Cycle Assessment","en","master thesis","","","","","","","","","","","","Marine Technology","",""
"uuid:e7e4d24e-122c-4b20-9130-4d608e38b4d3","http://resolver.tudelft.nl/uuid:e7e4d24e-122c-4b20-9130-4d608e38b4d3","Exploring the use of agile project management for infrastructure projects: Creating and using a serious research game to test the use of agile project management for infrastructure projects","Diepersloot, Boedi (TU Delft Civil Engineering and Geosciences; TU Delft Integral Design and Management)","Bakker, Hans (mentor); Bosch-Rekveldt, Marian (mentor); Steenhuisen, Bauke (mentor); Buijnsters, Marco (mentor); Eijkelkamp, Hilde (mentor); Delft University of Technology (degree granting institution)","2019","This thesis researched the possible use of agile project management for infrastructure project through the use of a serious research game. The thesis showed that there are different serious games and created a serious research game. By playing the serious research game with agile and traditional project management experts a hypothesis was created to use agile project management in the realisation of infrastructure projects. It showed that by using agile thinking at the start of project conception stakeholders are more seen as design experts. By using a minimal viable design and frequent collaboration and communication with the stakeholders a design is made through iterations. This design is than build.","Agile project management; Serious Game; Serious Gaming; infrastructure; Project Management; project management approach; serious research game","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:8598a4ac-5be2-4f98-a02b-19d54ece11ac","http://resolver.tudelft.nl/uuid:8598a4ac-5be2-4f98-a02b-19d54ece11ac","Viability assessment of satellite navigation filters for close-proximity operation: Selection, implementation and testing of alternatives to established satellite navigation filters","Weber, Noel (TU Delft Aerospace Engineering)","Guo, Jian (mentor); Delft University of Technology (degree granting institution)","2019","As satellite systems become more and more complex and interact with each other in space, close proximity operation becomes an important aspect of many satellite missions. Simultaneously, systems are becoming increasingly autonomous, for example in rendezvous and docking operations. This poses harsh requirements for the guidance, navigation and control systems on-board of satellites, and especially on satellite navigation filterswhich estimate the state of the satellite and of other systems and objects that it is interactingwith, often based on information input from visual sensors. The commonly used Extended Kalman Filter (EKF) performs well but is not necessarily ideally suited for these emerging challenges, which is why the viability of potential filter alternatives in close-proximity satellite operations was studied. The project was conducted in cooperation with DLR Oberpfaffenhofen in Germany, where currently an EKF is used in close-proximity satellite operations. This filter serves as a baseline for performance testing conducted throughout the project. Potential filter alternatives were identified based on an extensive background study and the mission needs for close-proximity satellite operation. Furthermore, the purpose of the project is to identify and document concrete mismatches between the different testing methods used to serve as a reference in future projects. From the background study two filters, the Extended Kalman Filter with intermediate smoothing step (EKFS) and the Unscented Kalman Filter (UKF) were selected based on a qualitative performance trade-off that focussed on the expected performance under the demands of closeproximity operation in space. The filters were judged based on the available documentation. For the selected filters, as well as for the EKF currently used by DLR, performance criteria were formulated, with a focus on the accuracy of satellite state parameter estimation and filter convergence speed. To collect test data, two approaches were taken: a newly developed simulation test assessing the theoretical performance of the filters in different test scenarios; and a hardware-in-the-loop test in the EPOS 2.0 facility in Oberpfaffenhofen where approaches using two physical satellite models can be performed. The latter test is used to identify problems in the filter performance that have not been found using the simulation test and to validate the filters for more representative real-world performance. An analysis of the test results from the simulation performance test have shown that the EKFS and the UKF can outperform the EKF in the convergence speed and the estimation of some, but not all satellite state parameters. However, it was also identified that the UKF using its current implementation struggles to assess the attitude of the satellite state accurately. Apart from the attitude estimation from the UKF the filters were considered verified and were implemented in the hardware test facility. The hardware test could not confirm the previously seen performance consistently and both filters showed state estimation divergence at closeproximity of the satellites. Thus, their performance could not be validated and they cannot yet under the current implementation be called viable filter alternatives to the EKF. This is due to the fact that sudden state estimation divergence is potentially catastrophic, especially at close distances of the satellites. In addition, differences in the quality of the measurements between the tests of the different filters highlighted potential problems in the comparability of test results. It was concluded that the UKF is the more promising alternative filter for the future since it showed better performance in the hardware test prior to divergence than the EKF and outperformed the EKFS in all hardware tests. In addition it converged the fastest of the three filters. Further studies need to be performed to correct implementation problems, however. Possible approaches for validating the suggested approaches are presented. Different test approaches should also be taken to make the hardware tests more representative and the simulation test should be updated to be more reflective of real world conditions. Several observations on the challenges in moving from simulation to hardware testingwere identified and are presented. Primarily, challenges were found to arise from the faulty selection of test cases for comparability, the neglect of certain inputs observed in hardware testing with previously unpredicted effects in the simulation test and the continuous change of inputs in the real world which were modelled constant in the simulation test.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:f8efc51a-db33-4db9-a74b-10a5d9135b37","http://resolver.tudelft.nl/uuid:f8efc51a-db33-4db9-a74b-10a5d9135b37","Interwoven: Growing a Durable yet Delicate Composite Textile","Ford, Damienmarc (TU Delft Industrial Design Engineering)","Karana, Elvin (graduation committee); Sonneveld, Marieke (mentor); Delft University of Technology (degree granting institution)","2019","Growing design is an emerging new design approach at the confluence of materials science, biology, arts and design. It challenges current industrial consumption and production because it offers the opportunity to co-create with nature and shift the paradigm of production towards more sustainable solutions. Diana Scherer is an artist exploring the creation of a novel material by utilising the natural processes of the growth of a living organism. She has created a material called Interwoven, which is made of plant roots. far, plant roots have not yet been used for the production of a material. In contrast to comparable textiles made from natural fibres, the material itself weaves. Producing itself through the search of the plant for nutrients and water. This project explored different methods to improving the strength of Interwoven as a bio-composite, while assessing its technical and experiential properties. In its current state Interwoven is limited in its functional use because of the technical characteristics of the roots being weak. Therefore it was required the strength be improved as an aspect of durability. Apart from the technical challenges presented, there are also challenges with peoples perception of new emerging grown materials as they trigger uncertainty in peoples perceptions. Experiential characterisation and technical characterisation was conducted on the material interwoven so that both may be utilised towards finding a meaningful application as a textile","Material Experience; Growing Design; Bio-Composite; Material Driven Design","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:bda285c9-117d-49a3-93a1-2530a07f6cff","http://resolver.tudelft.nl/uuid:bda285c9-117d-49a3-93a1-2530a07f6cff","Android App Tracking: Investigating the feasibility of tracking user behavior on mobile phones by analyzing encrypted network traffic","Meijer, Wilko (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Cyber Security)","Doerr, Christian (mentor); Delft University of Technology (degree granting institution)","2019","The mobile phone has become an important part of people's lives and which apps are used says a lot about a person. Even though data is encrypted, meta-data of network traffic leaks private information about which apps are being used on mobile devices.Apps can be detected in network traffic using the network fingerprint of an app, which shows what a typical connection of the app resembles. In this work, we investigate whether fingerprinting apps is feasible in the real world. We collected automatically generated data from various versions of around 500 apps and real-world data from over 65 unique users. We learn the fingerprints of the apps by training a Random Forest on the collected data. This Random Forest is used to detect app fingerprints in network traffic. We show that it is possible to build a model that can classify a specific subset of apps in network traffic. We also show that it is very hard to build a complete model that can classify all possible apps traffic due to overlapping fingerprints. Updates to apps have a significant effect on the network fingerprint, such that models should be updated every one or two months. We show that by only selecting a subset of apps it is possible to successfully classify network traffic. Various countermeasures against network traffic analysis are investigated. We show that using a VPN is not an effective countermeasure because an effective classifier can be trained on VPN data. We conclude that fingerprinting in the real world is feasible, but only on specific sets of apps.","Android; fingerprinting; network traffic analysis; machine learning","en","master thesis","","","","","","","","2020-03-31","","","","","",""
"uuid:9217a115-9275-47b5-97f6-62a5d47e734e","http://resolver.tudelft.nl/uuid:9217a115-9275-47b5-97f6-62a5d47e734e","Modelling of buoyancy-driven circulating bubbly flow","Li, Cipher (TU Delft Mechanical, Maritime and Materials Engineering)","Haverkort, Willem (mentor); Delft University of Technology (degree granting institution)","2019","Buoyancy-driven bubbly flow widely exists in equipment like bubble columns, electrochemical cells, etc. The influence of bubbles on the overall velocity and local flow behaviours is complex and still under debate these days. In this study, the focus is put on the numerical modelling of buoyancy-driven flow in a circulating channel. The circulating channel is composed of a riser channel and a downcomer. The gas is evolved from the vertical wall along the riser channel, forming a bubble plume covering the wall. In the context of electrochemistry, this kind of setup is commonly used for electrolysers, and the existence of the bubble plume could result in a decrease in the reaction surface and overall efficiency. Therefore, studying the behaviour of the flow inside the circulating channel and relation between certain operating parameters is important. First, a multiphase flow model is used to simulate the buoyancy-driven flow in a vertical channel without the overall circulation. The purpose is to reproduce the results of the experiments and simulations from literature to prove the validity of the numerical model used in this work, for lack of detailed experimental data for electro-generated bubbles in the circulating channel. The velocity profile across the channel matches well with the experimental data under the same operating conditions, while the volume fraction qualitatively matches the simulation from other works. Afterward, the same multiphase model is used to simulate the buoyancy-driven circulating bubbly flow. A parametric study is conducted to investigate the variation of the volume fraction profile, the overall circulating velocity, and local velocity profile under different current density and riser channel width. It is found that when the channel width is small ( &lt; 0.5cm), the plume thickness decreases with an increasing channel width and a decreasing current density. However, as the channel width keeps increasing, the bubble plume thickness gradually becomes independent of current density and channel width. Regarding the velocity, as the riser channel gap increases, the circulating velocity first increases then decreases, reaching its maximum value at around 0.2 cm channel width. Based on the velocity profile from the simulation, it is because the velocity profile gradually deviates from the solution of Poiseuille flow. Analytical solutions based on certain assumptions are given to estimate the circulating velocity.","","en","master thesis","","","","","","","","","","","","","",""
"uuid:f58a23c7-50d5-4c96-9c16-ceccd1bfe5cc","http://resolver.tudelft.nl/uuid:f58a23c7-50d5-4c96-9c16-ceccd1bfe5cc","Radio Frequency Identification in the Operating Room: A systematic approach to test the feasibility of RFID in the operating room for surgical phase recognition","Hengst, Staffan (TU Delft Mechanical, Maritime and Materials Engineering)","van den Dobbelsteen, John (mentor); van der Elst, Maarten (graduation committee); Hermsen, Pleun (graduation committee); Delft University of Technology (degree granting institution)","2019","Hospitals are facing enormous financial pressure over the last years. To achieve lower costs, hospitals should invest in smart ways of working to make optimal use of the scarce capacities. A solution can be digitising processes in the hospital to prevent it from making more costs. In line with this founding, planning and scheduling of the operating room (OR) program during a day is a process that could be improved by digitising. Overtime and idle time are consequences of inaccurate planning and are both expensive elements that do not contribute to satisfaction of hospital personnel and patients. Radio Frequency Identification (RFID) is proven and proposed in previous research to be used to acquire data for surgical phase detection. Up until now, the detection accuracy for this model is too low and requires optimization before it can be implemented in the OR. This research uses a systematic approach to investigate the feasibility of implementation of RFID in the OR in Reinier de Graaf Gasthuis (RdGG) in Delft for the purpose of surgical phase recognition. The systematic approach is divided in four parts: theory, design, testing and evaluation. The first part presents an analysis of the OR in RdGG and the RFID technology and is used in the design part to compile a list of of design requirements. This list presents criteria that must be met in order to achieve succesful implementation of RFID in the OR. Based on the requirements an optimal position of the antenna is chosen above the surgical table, in the center of the plenum ventilation area and on a distance of 1.5 meter of the surgical table. On the basis of the optimal antenna position, an antenna, tag and reader is chosen. The proposed RFID system is tested in the MISIT-lab at the TU Delft and in an OR in RdGG. The goals of the experiments were to visualise the detection field and to compare the effect of the environment on the RFID performance. In the MISIT-lab, the antenna was able to detect a vast majority of tags up to a perpendicular distance (from the antenna to the surgical table) of 1.3 meter. At longer distances of 1.4 and 1.5 meter the antenna was still able to detect tags but to a lesser extent. The OR experiment yielded poor results compared to the laboratory experiment. None of the tags was detected on the predeterimined distances. The antenna was only able to detect tagged instruments on a distance of approximately 0.8 meter. The results are evaluated in the last part of this research. Normally, when facing poor performance of an RFID system the performance can be improved by increasing the antenna gain or choosing stronger RFID tags. These choices are both constrained by the dimensions of the antenna and the tag. An RFID antenna with a large surface cannot be placed in the airflow above the surgical table because this increases the risk on infections and large RFID tags do not fit on surgical instruments. The most probable reason for the decrease in performance between the two experiments is electromagnetic noise from surrounding electrical equipment and wires in the floor and ceiling. In conclusion, it is not possible to implement an RFID system in the OR for phase recognition purposes. RFID technology is fast evolving and new technologies can offer a solution. It is certainly possible that RFID can be implemented in the future when tags and antennas are more powerful while retaining small dimensions. In future, it is recommended to perform on site tests of RFID in the OR before further developing an application.","RFID; Radio Frequency Identification; Operating room; Surgical instruments","en","master thesis","","","","","","","","","","","","Biomedical Engineering","",""
"uuid:bd62150d-db33-4249-a88a-86a7169cc0dd","http://resolver.tudelft.nl/uuid:bd62150d-db33-4249-a88a-86a7169cc0dd","On the aeroelasticity of an extreme scale wind turbine: Using an FSI framework in NLR's in-house code ENSOLV","Rietema, Roald (TU Delft Aerospace Engineering)","van Zuijlen, Alexander (graduation committee); van Oudheusden, Bas (mentor); Timmer, Nando (graduation committee); van Muijden, Jaap (graduation committee); Delft University of Technology (degree granting institution)","2019","Recent decades, an ongoing trend has emerged in the upscaling of wind turbines in order to compete with traditional energy resources. For conventional wind turbines, aside from improving safety, the driving factors for new designs have always been increased efficiency and performance. This has led to novel wind turbine designs comprising thin-walled structures and light-weight composite materials that produce more power per unit. The current cost of wind energy is strongly dominated by operational and maintenance costs throughout the full lifetime of a wind turbine. Most wind turbines do not reach their design lifetime due to various reasons, from which fatigue failure is the most prominent one. The events responsible for gearbox or blade failure are caused by complex interactions between aerodynamics and structural responses that are inherently of unsteady nature. Aeroelasticity has become increasingly important for a safe and cost-effective design. Additionally, longer and lighter wind turbine blades undergo extremely large, low-strain deformations. A more accurate understanding of the aeroelastic behavior demands nonlinear analysis methods.<br/><br/>Most aeroelastic solvers in aerospace industry rely on linear structural models. This thesis work has modified the existing semi-nonlinear aeroelastic analysis method of the in-house developed CFD code at NLR by using Nastran's nonlinear structural module. Both analysis methods were utilized to obtain a converged static aeroelastic solution for two different operational conditions of the design curve. Subsequently, mode shapes of the deformed state of the structure were determined, to be used in the flutter analysis.<br/><br/>A 108-meters theoretically designed blade, provided by the Dutch blade design company We4Ce, was analysed using both methods. The results of static aeroelastic analysis and flutter analysis were compared to assess the effect of structural nonlinearities on the aeroelastic behavior. It is concluded that linear analysis overestimates the structural deformations and that pre-stressing due to nonlinear deformations and follower-forces alter the dynamic properties of the wind turbine blade. For the test case considered, the inclusion of geometrical nonlinearities resulted in a change of behavior of various modes. Naturally-low damped modes were affected negatively, eventually leading to dynamically diverging behavior. This thesis has successfully provided the first steps in the implementation of a nonlinear aeroelastic analysis for extreme scale wind turbines, including the capability of performing stability analysis.","Aeroelasticity; Flutter; Wind Turbine; fluid-structure interaction; CFD; Nonlinear finite element analysis","en","master thesis","","","","","","","","","","","","Aerospace Engineering | Aerodynamics","",""
"uuid:4c5f10f5-4707-4763-bb42-1db42faaaa2f","http://resolver.tudelft.nl/uuid:4c5f10f5-4707-4763-bb42-1db42faaaa2f","Pareto Set Extrapolation method: an efficient solving technique for multi-objective optimization problems","Kappelle, Derk (TU Delft Mechanical, Maritime and Materials Engineering)","Langelaar, M. (mentor); Aragon, A.M. (mentor); Delft University of Technology (degree granting institution)","2019","When considering techniques for producing the Pareto front of a <i>Multi-Objective Optimization Problem</i> (MOOP), there exists a trade-off between the effectiveness of the method in obtaining the Pareto front and the computational cost required to achieve that. For a method to be effective, the generated solutions must result in a true representation of the Pareto front. Frequently used techniques are the <i>Genetic Algorithms</i> (GAs). These methods are designed to be effective but are known to be computationally expensive. This is problematic when applied to also expensive MOOPs, which is often the case in engineering applications, as it makes them impractical to use. To solve expensive MOOPs, the applied method should be both effective and computational cost-efficient. Depending on its use, <i>multiple run</i> (MR) methods have been proven to achieve an appropriate level of effectiveness at a significantly lower computational cost compared to GAs. In this paper we present the \textit{Pareto Set Extrapolation} (PSE) method, which is a modification of the general MR technique and is designed to be more effective and cost-efficient than the existing MR method. In this first phase of its development, the approach is limited to solving constrained bi-Objective Optimization Problems (BOOPs) with a continuous P<sub><b>f</b></sub> as its solution, but could be extended to MOOPs with relatively small effort and has possible use in solving discontinuous problems. The PSE method is proven to perform favorably over multiple test problems on both effectiveness and cost-efficiency, compared to the <i>Non-dominated Sorting Genetic Algorithm</i> (NSGA-II) and <i>Normal Constraint</i> (NC) method, representing the GAs and MR techniques, respectively.","Multi-Objective Optimization; Multiple run method; Pareto set; Pareto front","en","master thesis","","","","","","","","2020-12-31","","","","Mechanical Engineering | Precision and Microsystems Engineering","",""
"uuid:f5c72765-9d12-4f0b-8a91-1aee190d316a","http://resolver.tudelft.nl/uuid:f5c72765-9d12-4f0b-8a91-1aee190d316a","The poetics of Japanese sensibility","L' Herminez, Claartje (TU Delft Architecture and the Built Environment)","Koorstra, P.A. (graduation committee); van de Pas, R.R.J. (mentor); van de Voort, J.A. (graduation committee); Vitner, Daan (graduation committee); Delft University of Technology (degree granting institution)","2019","This research project aims to identify and describe those qualities that contribute to an architectural response to nature’s phenomena, such as time (constant change) and space (Ma **), our spatial conception and experience, and our relationship with nature (En *). Often these qualities are present in the form of architectural elements and methods, composition of elements. Possibly this research develops tools based<br/>on Japanese philosophical and architectural principles and notions in which emptiness and ephemerality play a key role.","Japanese architecture; Japanese philosophy","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Explorelab","",""
"uuid:49729781-1eb5-424f-acf7-d627fd118cd5","http://resolver.tudelft.nl/uuid:49729781-1eb5-424f-acf7-d627fd118cd5","Mechanical and histological characterization of thrombi retrieved during thrombectomy for acute ischaemic stroke","Snouckaert van Schauburg, Philip (TU Delft Mechanical, Maritime and Materials Engineering)","Gijsen, Frank (mentor); van der Helm, F.C.T. (mentor); Dodou, D. (graduation committee); Schwab, A.L. (graduation committee); Delft University of Technology (degree granting institution)","2019","Background: The efficacy of a thrombectomy procedure for acute ischaemic stroke (AIS) is largely dependent on mechanical behaviour of thrombi and interactions with the thrombectomy device. Studies have examined clot analogues and evidence suggests that thrombus mechanical properties largely depend on composition, yet evidence based on thrombi retrieved from AIS patients is still lacking. Therefore, this study aims to characterize the mechanical properties of thrombi retrieved from AIS patients and to determine the relation to thrombus composition. Additionally, results were compared to literature in order to assess clot analogue representativeness.Methods: Directly following a thrombectomy procedure, unconfined compression tests were performed on thrombi retrieved from acute ischaemic stroke patients. For all tested samples, the material properties were characterized and related to the histologically determined composition. Identified histological components were 1) Fibrin &amp; platelets, 2) Red blood cell and 3) Leukocytes. A subgroup analysis was performed to compare values with literature, where samples were stratified into four groups based on fibrin &amp; platelet content (F&amp;P -low, -moderate low, -moderate high and -high). Results: A total of 18 patients yielded 39 samples which were successfully tested and histologically analysed. Sample stiffness was found to be positively correlated to fibrin &amp; platelet content (Rs=0.69, p&lt;0.001). A good histological distribution was present within the data, as the fibrin &amp; platelet content ranged from 7% to 99%. Subgroup analysis showed little difference in mechanical behaviour between the F&amp;P moderate-low and F&amp;P moderate-high subgroups, with the F&amp;P low and F&amp;P high groups respectively exhibiting a decreased and increased stiffness. Comparing to current literature, the results demonstrated that analogues most accurately resemble thrombi with a low fibrin &amp; platelet content. Furthermore, all samples displayed viscoelastic and non-linear stress-strain behaviour.Conclusion: It was found that composition is a strong influencing factor of thrombus mechanical properties. Both at high and low fibrin &amp; platelet contents, the relation between composition and stiffness was strongest, while it was least pronounced at moderate fibrin &amp; platelet contents (approximately 25%-75%).","Thrombi; Mechanical characterization; Histology","en","master thesis","","","","","","","","2020-07-31","","","","Biomedical Engineering","",""
"uuid:e5bbffcc-346d-4b59-9d7c-8cbf33df7df8","http://resolver.tudelft.nl/uuid:e5bbffcc-346d-4b59-9d7c-8cbf33df7df8","Analysis of fluid flow around a rotating circular cylinder using RBVMS and IGA","Feij, Christiaan (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Ship Hydromechanics and Structures)","Akkerman, I. (mentor); ten Eikelder, M.F.P. (mentor); Westerweel, J. (graduation committee); Delft University of Technology (degree granting institution)","2019","The case of the flow around a rotating circular cylinder is very complex. This thesis investigates the properties of a fluid flow for Reynolds numbers ranging from 50 to 400. Numerical simulations are performed using a combination of isogeometric analysis and the residual-based variational multiscale method, providing high accuracy. The results show how the lift and the drag generated by the cylinder are related to the spin rate and the Reynolds number. When comparing the lift and drag values to the required amount of torque which is needed to spin the cylinder, it is shown that at medium spin rates, a very high aerodynamic efficiency is obtained at a reasonable amount of torque. 3D simulations are performed and show at high spin rates strong vorticity and a wake that is dominated by vortex shedding. These results differ strongly from the 2D simulations, which leads to the question whether 2D simulations are still representative for real real at high spin rates, despite the low Reynolds number.","Cylinders; Spin rate; CFD; isogeometric analysis; RBVMS; NURBS; Flettner rotor","en","master thesis","","","","","","","","","","","","Offshore and Dredging Engineering","",""
"uuid:e4b97307-1ce2-4b41-84ae-36ccb910ba81","http://resolver.tudelft.nl/uuid:e4b97307-1ce2-4b41-84ae-36ccb910ba81","Medical Instrument Tray Optimization: Combining Use Rates, Expert Opinions and Risk Analyses","van Trier, Teun (TU Delft Mechanical, Maritime and Materials Engineering)","Dankelman, J. (mentor); Jansen, F.W. (graduation committee); Plettenburg, D.H. (graduation committee); van der Eijk, Anne (graduation committee); Delft University of Technology (degree granting institution)","2019","The operating room and central sterile supply department (CSSD) are two<br/>resource-intensive healthcare departments. Reducing the environmental and financial impact of these departments is of great importance in the global debate on sustainability. Removing unnecessary items from instrument trays may provide a partial solution. However, improvements to tray compositions are often time-consuming, not permanent and not using the full reduction potential. This research compares different methods of medical instrument tray optimization and combines different aspects to create a new methodology. Three models compared and evaluated objective and subjective instrument use percentages and different suggestions for tray optimizations. New tray compositions, based on objective use rates, were discussed with the medical specialists and attuned to their requirements. The result<br/>was then reviewed by the OR-assistants, before making any final adjustments. This methodology is tested for abdominal instrument trays at the gynaecology department of the Leiden University<br/>Medical Center (LUMC). The new trays were evaluated over a test period and missing items were registered during follow-up. Risks to patient safety as a result of missing individual instruments<br/>and chances of missing instruments for different reduction methods are discussed and quantified. Mean use rates of the designated instrument sets are 28.4% (SD=6.43%) for open surgery (n=16) and 47.6% (SD=8.16%) for minimally invasive procedures (n=12). A 37% reduction of instruments is reached across three abdominal trays by removing unnecessary items. Weight of the tray contents is reduced by 31%. During the evaluation (n=7 procedures), mean instrument use for abdominal procedures increased from 28.4% (SD=6.43%) to 46.47% (SD=10.96%) after tray optimization. A reduction based on use rates with a 10% cut-off or based on the recommendations of the medical specialists, induces an 8.7% or 3.9% chance of missing any instrument during the procedure, respectively. Tray content reductions based on OR-assistant suggestions and objective use rates with a 0% cut-off are safe, but do not utilize the complete reduction potential. Different tray optimization methods were compared. Use rates were measured in the OR and expert recommendations were discussed in group sessions. A combination of objective use rates and subjective expert considerations can lead to a significant reduction of the amount of unnecessary items in the medical instrument cycle without harming patient safety. Group consensus amongst medical specialists suggests the most radical reduction of instruments on the tray, but increases chances of missing instruments during surgery. Recommendations based on use rates have to be supplemented by reduction efforts based on the clustering of equivalent instruments. Future work should focus on ways to scale reduction efforts to an autonomous hospital-wide system and teach optimization models to mimic human expert input. It should also focus on exact measurements in the CSSD to estimate reductions in costs and CO2-footprint reliably.","OR and CSSD Sustainability; OR and CSSD Efficiency; Patient Safety; Risk Analysis; Medical Instruments; Tray Optimization","en","master thesis","","","","","","","","2021-12-01","","","","Biomedical Engineering","",""
"uuid:d2511d1c-947e-44b4-a8dc-1ad263d531c7","http://resolver.tudelft.nl/uuid:d2511d1c-947e-44b4-a8dc-1ad263d531c7","Numerical Simulation of Dispersion in Stratified Porous Media","Kortekaas, Steven (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Applied Sciences)","Romate, Johan (mentor); Kleijn, Chris (mentor); Delft University of Technology (degree granting institution)","2019","The transport of a solute dissolved in a fluid flowing trough porous media is, next to advection and diffusion, determined by hydrodynamic dispersion. This be- haviour is commonly characterized using the longitudinal and transverse dispersion coefficients. Laboratory and field measurements of these coefficients tend to differ, which might be attributed to heterogeneities found in field porous media. To investigate this, a stratified porous medium consisting of two layers is con- sidered. Each layer has different physical properties, resulting in a different average fluid velocity. As a consequence of the difference in velocity, transport of the solute occurs between the two layers. Under certain circumstances the layers start to be- have as one single layer, with one single effective dispersion coefficient, explaining the discrepancy between field and laboratory measurements. The two-layer stratified porous medium is characterized using a dimensionless number. It is investigated for which values of this number the porous medium acts as one single layer, and for which values the medium behaves as two separate layers. This is done by introducing an index, which effectively measures the behaviour of the medium in terms of these two limit cases. The calculation of the index is done using a numerical simulation of flow and dispersion in the stratified porous medium. It was found that the dimensionless number was in general a good predictor of the behaviour of the stratified porous medium. The system behaved as one single layer if the dimensionless number (after a correction with a certain factor) was much greater than unity. Similarly, the system behaved as two separate layers if the number was much less than unity. However, this number failed if the ratio of the two layer thicknesses was varied. A correction to the dimensionless number was suggested, taking the ratio into account.","","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics | Applied Physics","",""
"uuid:f5bab9f2-e67e-41a6-815c-05dc21987ea0","http://resolver.tudelft.nl/uuid:f5bab9f2-e67e-41a6-815c-05dc21987ea0","HPC Based Acceleration for Optimization of Predictive Models: Lithography Overlay Performance Modeling","Tuna, Ozan Dogu (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Quantum & Computer Engineering)","Al-Ars, Zaid (mentor); Valente, Frederico (mentor); Delft University of Technology (degree granting institution)","2019","This thesis project achieves designing and comparing two parallel implementations for exhaustive grid search along a large model space to find the optimum mapping model for overlay predictions used in ASML lithography machines. The search algorithm leads to an effectively intractable problem as long as sequential implementation is concerned, but a parallel implementation using the technologies pro-vided by ASML High Performance Cluster (HPC) pave the way to tackle the challenge. A number of parallel execu-tion concepts have been developed using different frame-works that are exposed to the ASML HPC developer com-munity by the platform maintainers. Among these con-cepts, the most promising ones with respect to a defined set of criteria have been chosen to carry on with the implemen-tation effort. It has been shown that a PBS based Lab im-plementation can scale on HPC with a parallel efficiency of 66%, with most of the efficiency loss stemming from scheduler overhead. A second, Spark based Fab implementa-tion has an increased efficiency of 82%, paving a way for speedup of almost 1700x for a Spark cluster with 2048cores. Moreover, It has been shown experimentally that perfor-mance scales linearly over the model space dimensions. Baseline sequential implementation is estimated to take, by extrapolation, 2590 hours to execute on a single core for a typical model space use case. Refactoring the sequential implementation to utilize multiple CPU cores through mul-tiprocessing can drive execution down to 115 hours on a 24-core machine. Fab parallel implementation executes the same use case in 1.6 hours, enabling exploratory and itera-tive approaches to modeling for data scientists and domain experts.","Parallel Frameworks; Predictive Model Optimization; Spark; PySpark","en","master thesis","","","","","","","","2020-12-31","","","","Computer Engineering","",""
"uuid:6c6bd6a3-4d1b-457e-a25a-fbdc32c068e3","http://resolver.tudelft.nl/uuid:6c6bd6a3-4d1b-457e-a25a-fbdc32c068e3","Bus ridership prediction: Development of a framework","de Lanoy, Jasper (TU Delft Civil Engineering and Geosciences; TU Delft Transport and Planning)","van Oort, Niels (mentor); van Arem, Bart (graduation committee); Annema, Jan Anne (graduation committee); Stikvoort, Marc (mentor); Delft University of Technology (degree granting institution)","2019","During tenders in public transport, the bus network is reconsidered and adjusted. An accurate prediction of the effect on ridership is required. Due to the tender environment, time and input data are limited. This research focuses on deriving a relation between level-of-service (LOS) and ridership, and implementing this in a model suitable for the tender environment. A before-after study is performed based on two different levels of detail: OD-based and line-based. An OD-based analysis shows two issues for translation to model parameters: a poor fit of the trend line and a large share of a-typical data. A line-based approach provides more promising results. The range of elasticities and growth factors found is large, which is insufficiently acknowledged by current literature. Context is one of the main explanations for the large range. A regression analysis indicates a significant relation between LOS and ridership and indicates possible significance of additional predictors for ridership change. A comparison model is developed, which enables the user to match its request with an entry in the data base, providing the ridership development and context. The model is able to provide the user with growth factors for full day and peak/off-peak interaction and indicates sensitivity of the user groups. Future expansion of the model is recommended.","Public Transport; Elasticity; Public transport modelling; Bus ridership; Ridership prediction; Level of service","en","master thesis","","","","","","","","2020-09-01","","","","Civil Engineering","",""
"uuid:a94b7431-22d2-4d95-bfd1-986519857ba1","http://resolver.tudelft.nl/uuid:a94b7431-22d2-4d95-bfd1-986519857ba1","Quantum Gaussian Processes for Data-Driven Design of Metamaterials","Kuś, Gaweł (TU Delft Aerospace Engineering)","Bessa, M.A. (mentor); van der Zwaag, S. (graduation committee); Delft University of Technology (degree granting institution)","2019","The data-driven approach shows great potential for designing new materials with unprecedented properties by using machine learning and optimization. Recently, a data-driven framework was successfully applied to design a unit cell of metamaterial achieving super-compressibility, despite being built out of brittle base material. The key element of the framework is the algorithm called Gaussian processes regression (GPs) – a unique machine learning method that provides with the uncertainty of the prediction, which can be used during the design process to account for inherent material imperfections, ensuring the robustness of the design. Despite their superior predictive performance, however, GPs suffer from scalability issues, which limit their application to relatively small design problems. In the future, those limitations could be surpassed by quantum computing.<br/><br/>This research aims at demonstrating how quantum computing could enhance the computational design of materials, specifically by replacing the expensive machine learning step of the data-driven design framework with an exponentially faster quantum algorithm for Gaussian processes (QGP). This objective is achieved in two steps. First, the QGP algorithm was Implementation and simulated within a quantum computing framework (Qiskit), which allowed to understand and control its performance (in particular its accuracy), proving the feasibility for practical applications. Furthermore, the numerical tests exposed a mechanism for inducing a low-rank approximation, which allows for additional speed-up, making the QGP algorithm similar to classical sparse Gaussian processes, which rely on low-rank approximations to improve the scalability of full GPs. In the second part of this research, the implemented QGP algorithm was integrated within a computational framework for the data-driven design of materials and applied to two example design problems of optimization a unit cell for a super-compressible metamaterial. The results obtained with the QGP were comparable to those obtained with classical methods (also from literature), which proved the feasibility of the concept.","Quantum Computing; Gaussian Process; data-driven design methodology; Materials science","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:69b56494-0731-487a-8e57-cec397452002","http://resolver.tudelft.nl/uuid:69b56494-0731-487a-8e57-cec397452002","Handling Qualities of a Flying V Configuration","Cappuyns, Thibaut (TU Delft Aerospace Engineering; TU Delft Flight Performance and Propulsion)","Vos, Roelof (mentor); Bender, Klaus (mentor); Delft University of Technology (degree granting institution)","2019","Generally, performance of aircraft is optimized within the limits of adequate Handling Qualities. The dominant challenges in designing flying wings exist in their paradigm relating stability margin and the effectiveness of controls. The project, undertaken at Airbus Future Projects Office, provides a qualitative assessment of the Handling Qualities of the Flying V concept. The Flying V is an aerodynamically efficient tailless design, based on similar requirements as the Airbus A350-900. Relevant Handling Qualities criteria are selected and a 6 Degrees of Freedom Flight Mechanics Toolbox is set-up. Data was assembled from parametric models. These were utilized to create aero data based on a Vortex Lattice Method and lumped masses model providing the inertia estimation. The same methodology was repeated for a reference aircraft of conventional configuration based on the A350-900. Results revealed the characteristically lower centre of gravity range of flying wings in comparison to conventional configurations. The trivial effects of a shorter tail arm, emphasizing the need for a yaw damper and increased directional control for the Flying V were also reviewed. Lateral-directional controllability were however found to be limited but not insurmountable. Taking into account the limitations of the toolbox, this study concludes that the basic handling characteristics tested of the Flying V's design are favourable.","Flying V; Handling Qualities; Tailless Aircraft; Flight Mechanics; Flight Dynamics","en","master thesis","","","","","","","","2024-12-17","","","","Aerospace Engineering","",""
"uuid:a6f05abc-fe60-446d-a0fc-a1818edd25e2","http://resolver.tudelft.nl/uuid:a6f05abc-fe60-446d-a0fc-a1818edd25e2","Privacy in federated deep learning on medical data","Enthoven, David (TU Delft Electrical Engineering, Mathematics and Computer Science)","Al-Ars, Z. (mentor); Delft University of Technology (degree granting institution)","2019","With the increasing number of data collectors such as smartphones, immense amounts of data are available. These data have great value for training machine learning models. Federated learning is a distributed machine learning approach that allows a machine learning model to train on a distributed data-set without transferring any data and therefore claims that privacy is preserved. In this thesis, privacy is considered specifically for the use-case of medical data. These are sensitive and distinct for different patients. A step-wise argument as to what constitutes privacy preservation is formulated. This notably requires systems to be able to train on singular samples without compromising their privacy. As such, the federated averaging algorithm (FedAvg) is demonstrated to be critically insecure against certain attack methods. A chosen attack method is used to show how training data is reconstructed with solely the model update. The viability of this attack method is demonstrated to great extend for fully connected neural networks and convolutional neural networks To adhere to the strict privacy formulation, a novel federated learning method is presented in this thesis which is called Locally Encoded Federated Averaging (LEFedAvg). This method works on the premise that a part of the model remains private throughout. Subsequently, it is demonstrated to be usable and how this method allows for collaborative training. The privacy benefits of this federated learning method are empirically shown. The trade-off between performance and privacy is demonstrated and discussed for a more realistic operational setting.","Federater learning; Deep learning; privacy; Model sharing","en","master thesis","","","","","","","","2020-12-31","","","","Electrical Engineering | Embedded Systems","",""
"uuid:0ce291ef-a587-4702-ac22-a3c3198d6558","http://resolver.tudelft.nl/uuid:0ce291ef-a587-4702-ac22-a3c3198d6558","Scene Classification for a Mobile Interactive Robot","Donadoni, Laura (TU Delft Electrical Engineering, Mathematics and Computer Science)","Neerincx, M.A. (mentor); Broekens, D.J. (mentor); Abbink, D.A. (graduation committee); Delft University of Technology (degree granting institution)","2019","The use of social robots increased in the past few years. Current technology, however, lacks in deploying a single robot for different applications without the help of a human being. Current solutions are time-consuming, labour intensive and hard to generalize. Being aware of its surroundings, in terms of environment and context, the robot can select the appropriate application that the situation needs. We propose a multi-modal, knowledge-based hybrid scene classification method for applying awareness to the robot. As scene we refer to the combination of the environment and the context of the surroundings; a study on how to describe a scene has been done through knowledge-engineering methods that comprehend an anonymous online questionnaire and observations. The method inputs features of the type of objects, audio, and human detection and understanding; and outputs the probabilities of the possible social roles for the robot (Receptionist, Tutor and Waiter). The classification is based on a hybrid approach and trained and validated on a real-time multi-modal data-set collected by a mobile robot. The training experiment aimed to collect the data-set, to select the features that describe different roles and to calculate their weights. The validation experiments aimed to measure the performance and the generalization of the method. Results show that the robot was able to successfully classify the Receptionist role with an accuracy of 83.4%; the Tutor role with 82.7%; and finally, the Waiter role with 55.9%. On average, the method generalizes for 74% of unseen data.","Scene classification; Robotics; human robot interaction; Interactive robots","en","master thesis","","","","","","","","","","","","Electrical Engineering | Embedded Systems","",""
"uuid:93a5ab3e-8406-4f42-96a6-194a1ac72a38","http://resolver.tudelft.nl/uuid:93a5ab3e-8406-4f42-96a6-194a1ac72a38","Strategies towards effective emission reduction of the inland shipping industry in the port of Rotterdam: Using a mixed-integer linear programming model","Baas, Daniël (TU Delft Civil Engineering and Geosciences)","Bakker, H.L.M. (mentor); Stikkelman, R.M. (graduation committee); Binnekamp, R. (graduation committee); Delft University of Technology (degree granting institution)","2019","Currently, the inland shipping industry is not sufficiently incentivised to invest in sustainable technologies in order to reduce their emissions. The industry itself wants to be more sustainable, but there is insufficient financial room to invest in alternative technologies. Besides, public authorities try to achieve a reduction using command-and-control policy instruments. Therefore, this study aims to gain insights into the relationship between policy instruments and incentivising technical alternatives. In this study, emission-reducing strategies have been identified using a mixed-integer linear programming (MILP) model based on the fleet owned by the Port of Rotterdam. As a result, this study has identified two effective strategies – environmentally differentiated port dues and environmental fees. The effectiveness of the environmentally differentiated port dues can be allocated to the degree of pollution control. The implication of an environmental fee on carbon dioxide (CO2) emissions, has led to a reduction in either greenhouse gas and pollutant emission.","Linear Programming model; Mixed Integer Linear Programming; Emissions; Greenhouse gas; Pollutant emissions; Emission reduction; Ports; Rotterdam; Inland Shipping; Policy Instruments; Economic Incentives; Environmental fee; Environmentally differentiated port dues","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:7d2b5493-9cd0-4197-991f-1937f007e6c9","http://resolver.tudelft.nl/uuid:7d2b5493-9cd0-4197-991f-1937f007e6c9","Increasing the Effectiveness of the Capacity Usage at Rolling Stock Service Locations","van Hövell tot Westerflier, Madeleine (TU Delft Civil Engineering and Geosciences)","Goverde, R.M.P. (mentor); Bešinović, Nikola (mentor); de Weerdt, M.M. (graduation committee); van de Velde, Didier (graduation committee); de Groot, Anneke (graduation committee); Delft University of Technology (degree granting institution)","2019","Passengers often complain about dirty trains indicating the relevance of interior cleaning of rolling stock (RS). Servicing tasks (i.e. interior and exterior cleaning and smaller technical checks) are executed on a daily basis at service locations (SLs). Currently, due to train operations during daytime, the current focus lies on night servicing. In this thesis daytime servicing is considered in order to tackle the capacity shortages at SLs. Therefore, the Rolling Stock Servicing Scheduling Problem (RS-SSP) is developed comprising a Mixed Integer Linear Programming (MILP) model. By complying with the planned timetable, the RS-SSP maximises the RS units being serviced during daytime. The RS-SSP allows RS exchanges between RS units having completed servicing and operating RS units requiring servicing. Due to this RS Exchange Concept, the number of RS units visiting the SL during daytime can be increased. Within the thesis three RS-SSP model versions have been developed: the RS-SSP Base Model and two model extensions. The RS-SSP Base Model considers trains running with a single RS unit per train and RS units to be immediately serviced when entering the SL. The first extension (RS-SSP-MU) considers multiple unit trains and the second extension (RS-SSP-MU-W) allows RS units to wait for servicing. The proposed RS-SSP models have been tested on a real-life case from the Dutch railways. The RS-SSP-MU-W yielded the most feasible and improved solutions as compared to the other two model variants. For multiple scenarios, the model was able to exchange all running RS. As a conclusion, the capacity usage at SLs can be increased by the RS-SSP by shifting the excessive workload to daytime, and thus solving the capacity shortages. As the RS-SSP model is a generic model, it may not only be applied to other railway operators, but also to other public transport companies. Further extensions on the model are suggested for an appropriate applicability on large scale.","maintenance routing; daily maintenance; daytime servicing; servicing capacity; rolling stock exchange; decision support model; MILP","en","master thesis","","","","","","","","","","","","Transport, Infrastructure and Logistics","",""
"uuid:f8871449-a00f-4ec7-a2c4-ee99d89ab0cd","http://resolver.tudelft.nl/uuid:f8871449-a00f-4ec7-a2c4-ee99d89ab0cd","A Techno-Economic Evaluation of Green Ammonia","Zomer, Emma (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Wijk, Ad (mentor); Mulder, Fokko (graduation committee); Lukszo, Zofia (graduation committee); Delft University of Technology (degree granting institution)","2019","Up until now, ammonia has primarily served the fertilizer and chemical industry with limited regards to carbon emissions. The hydrogen within the ammonia molecule is commonly produced using fossil fuels; this process accounts for 1,2 % of the global CO2 emissions. Rather than using fossils fuels, electrolysis with renewable energy could be used to produce “green” carbon-free hydrogen and ammonia. The transition could decarbonize the ammonia industry and reduce carbon emissions drastically. Considering future emission restrictions and emerging new technologies, the techno-economic cost of green ammonia is expected to decrease. Accordingly, the the research question to be answered was: What are the effects of techno-economic induced cost reductions on the potential for green ammonia in the current and future global ammonia market? This report investigates the production and import costs over several global-oriented supply chains using a supply chain model. Rather than predicting the future, the aim is to gain an insight into the future of the global ammonia market. The scope of this thesis considers world scale ammonia production facilities with a capacity of 2200 ton NH3 per day. Due to their potential to become a producer or consumer of green and grey ammonia, the following countries are examined in more detail: Australia, Brazil, Chile, China, India, Japan, Morocco, Mexico, the Netherlands, Norway, Oman, South Korea, Trinidad &amp; Tobago, United Kingdom, United States. The supply chain model distinguishes between the “grey” (with hydrogen from natural gas through SMR) and “green” (with hydrogen from electrolysis on renewable energy) production process. The supply chain model that is used to gain insight into the future global ammonia market models a green ammonia production process. The following components are included in the model: a 1,5 GW electrolyser (78 % efficient, 2020), 100 MW Haber-Bosch reactor, 57 MW air separation unit, and a 94 MW fuel cell (60 % efficient) for a location that has 5000 FLH. The modelled production plant is sized according to the full load hours in a given country and implemented electrolyser efficiency according following a learning curve (75 % in 2020 to more than 82 % from 2030. In future research, it would be more exact to optimize the production plant’s exact sizing using the available resources at one specific location. Results show that up until 2030 importing grey ammonia is cheaper than domestically producing green ammonia. In addition, due to the sensitivity of the ammonia industry to carbon leakage, a strong CO2 policy is essential to the transition. The main cost drivers for green ammonia are the hydrogen buffer and firm up power of the Haber-Bosch reactor and air separation unit; both are directly related to the cost of the renewable energy, which in turn is strongly dependent on the weather conditions. Currently, Morocco, Chile and China are considering the domestic production of green energy as it is expected to become cost-competitive with domestic grey production of ammonia by 2020. The analyses show that in addition to these countries, Australia, the United States of America and Oman show optimal conditions for domestic production of green ammonia as well.","Green Ammonia; Techno-economic analysis; Sustainable Energy; Hydrogen; Ammonia","en","master thesis","","","","","","","","2025-12-16","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:c0c27e23-edbe-4757-a980-24199806eac2","http://resolver.tudelft.nl/uuid:c0c27e23-edbe-4757-a980-24199806eac2","Performance and thermal-vacuum testing of terrestrial cameras in pocketqubes","Meesen, Rick (TU Delft Aerospace Engineering)","Bouwmeester, Jasper (mentor); Delft University of Technology (degree granting institution)","2019","Due to their low mass pocketqubes are relatively inexpensive to launch. This makes them ideal for the creation of large constellations in low Earth orbit and a sufficiently large constellation would be able to perform measurements over the same area multiple times per day. Equipping these pocketqubes with cameras would increase the chance of cloud free images and would allow scientists to study dynamic processes which happen on sub-daily timescales. A camera in a pocketqube would have a spatial resolution of about 40 meters which would be sufficient for, for example, ocean color measurements or measuring land related variables, such as vegetation extent or land use, which allows biologists<br/>to better study conservation efforts. The economics of pocketqubes requires that the development cost and production cost per pocketqube must be comparable to the launch cost. For this reason it is preferable to use commercial off the shelf over purpose built cameras. to test whether or not those commercial off the shelf cameras would survive in space, environmental testing is required. The launch environment, consisting of the accelerations and vibrations experienced during launch, and the thermal-vacuum environment potentially have the largest immediate impact on a camera and should be tested for. Other environmental effects in low Earth orbit, such as atomic oxygen, UV radiation, ionizing radiation, et cetera, are damaging over time but might only require analysis rather than extensive testing. Due to limited resources only a thermal-vacuum test was conducted. For this test two cameras, the See3CAM_CU30 and a generic ELP H264 720p usb camera, were selected. These cameras were subjected to a thermal-vacuum test by placing the cameras inside a vacuum-oven in which the cameras were exposed to a vacuum while being heated to a temperature of 50∘퐶. Because the vacuum-oven was not suitable to test the cameras at temperature below room temperature a thermal-ambient test was also conducted in which the cameras experienced four cycles of heating up and cooling down to the expected in-orbit temperature extremes of 50∘퐶 and −5∘퐶 respectively. Before, in between, and after the thermal-ambient and thermal-vacuum tests a performance test was conducted to identify changes to the cameras. These performance tests measured the modulation transfer function, change in color representation, change in full well capacity, change in average dark signal, change in chromatic aberrations, and change in image distortion.<br/>Both cameras still functioned after the thermal-ambient and thermal-vacuum tests and showed no significant outgassing. Both cameras also showed no change in the distortion and chromatic aberration after the conducted tests indicating that the lenses survived the thermal-vacuum environment without<br/>detectable changes. After the thermal-ambient test, conducted prior to the thermal-vacuum test, only the See3CAM_CU30 showed some minor changes in its color representation. The ELP camera was unaffected. After the thermal-vacuum test the See3CAM_CU30 only showed again some minor changes in the color representation. The ELP camera became unusable. It experienced a large change in color representation and showed significant performance deterioration in the full well capacity and average dark signal. This indicates the camera overexposing all its images. However, a test measuring the effective integration time at various camera settings before and after the experiments showed that<br/>the camera integration time is unlikely to have been affected.<br/>Both cameras still functioned after the thermal-vacuum experiments. However, the fact that the ELP camera, and to a lesser extent the See3CAM_CU30, experienced performance degradation shows the necessity for good and rigorous performance testing of commercial off the shelf cameras before<br/>using them in pocketqubes. Although the See3CAM_CU30 showed potential it is too early to conclude whether or not it can survive in space for any length of time. In order to determine this at least a test is required demonstrating its ability to survive the mechanical environment experienced during launch.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:8dbaf118-ea20-421d-97f2-0ffe974a9570","http://resolver.tudelft.nl/uuid:8dbaf118-ea20-421d-97f2-0ffe974a9570","Water Energy Food nexus: 3 Cases on Resource Demand of Urban Farming and Resource Availability in Urban Waters in Amsterdam and Boston","Haitsma Mulier, Margot (TU Delft Civil Engineering and Geosciences)","van de Ven, Frans (mentor); van den Dobbelsteen, Andy (graduation committee); Kirshen, Paul (graduation committee); van de Giesen, Nick (graduation committee); Delft University of Technology (degree granting institution)","2019","Urban agriculture lies at the core of the Water Energy Food nexus and seems to provide a partial answer to confront modern trends such as population growth, climate change and resource depletion by increasing food security in cities and enhancing sustainability in an urban realm. The assembly of a WEF nexus framework taught, however, that most work that has been published on the nexus is very hypothetical and that the acquisition of quantitative data poses the biggest challenge in WEF nexus research. The mere absence of data collected at a local level impedes informed decision making on nexus sector integration and feasibility of sustainable solutions. This study attempts to bridge the existing knowledge gap and aimed to contribute to the quantification of the nexus regarding urban agriculture. It investigates the water, energy and nutrient demand of urban farms along with the presence of those resources in urban waters at three case study sites. Demands for water and nutrients (nitrogen &amp; phosphorus) at a greenhouse in Amsterdam and a community farm and a container farm in East-Boston could be met by resources present in urban waters (rainwater and wastewater) in the direct vicinity. Whether enough energy is available to run each of these farms is related to the type of agriculture which is applied.","Water Energy Food Nexus; Urban Agriculture; Resource Reuse; Urban Water; Circularity","en","master thesis","","","","","","","","","","","","","",""
"uuid:3d33e6bc-ea69-4e03-8333-3abf436b926d","http://resolver.tudelft.nl/uuid:3d33e6bc-ea69-4e03-8333-3abf436b926d","Magnetic Behaviour of a Steel Ellipsoid","Jongbloed, Henk (TU Delft Electrical Engineering, Mathematics and Computer Science)","Heemink, Arnold (mentor); Vijn, Aad (graduation committee); Lepelaars, E (graduation committee); Vermolen, Fred (graduation committee); Delft University of Technology (degree granting institution)","2019","Reliable and efficient modelling of magnetic hysteresis in inhomogeneous and aniso-tropic media is an important step in developing a state-of-the-art closed-loop degaussing system for naval ships and submarines, to be developed by TNO and to be used by the Royal Netherlands Navy in an updated generation of naval vessels and submarines. Different models have been proposed to describe the nonlinear and history-dependent nature of ferromagnetic hysteresis at a material level. With a focus on three key differing aspects of models, namely linear versus nonlinear(hysteresis), isotropic versus anisotropic and homogeneous versus inhomogeneous, we attempt to discriminate between the performance of models on the basis of these criteria. More specifically, with increasing model complexity, we have combined Maxwell's equations with four different hysteresis models within the context of a prolate steel ellipsoid, whose ferromagnetic properties evolve under the influence of a uniform applied background field. Among other aspects, the hysteresis models differ in terms of physical motivation, complexity and parameter spaces. In this research, we have analysed four hysteresis models in more detail: The Induced - Permanent magnetization model, The Rayleigh} model, the Jiles-Atherton model and an Energy-Variational model, based on energy balances. The thus derived forward models have subsequently been inverted in order to estimate material hysteresis parameters. With increasing complexity also, twin experiments have been performed. This increasing complexity \textit{temporally} stems from the fact that the hysteresis models named previously, are stated in increasing order of complexity, and can all be modified in order to model anisotropic material by generalizing model parameters to tensors. Spatially, the increase in complexity is caused by the fact that in special cases, namely of uniform ellipsoid magnetization, an analytical formula relating the magnetic field, the background field and the ellipsoid magnetization exists by solving the Poisson partial differential equation on an infinite domain using direct computation with Green's functions.","Ferromagnetism; Hysteresis; Finite Element Analysis; Inverse Modelling; Partial Differential Equations","en","master thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:77ebadc7-8af9-4b42-8f36-a94755eb5009","http://resolver.tudelft.nl/uuid:77ebadc7-8af9-4b42-8f36-a94755eb5009","Exploring the Potential of Uber Movement Data: An Amsterdam case study","Krishnan, Vishruth (TU Delft Civil Engineering and Geosciences)","van Lint, J.W.C. (mentor); Calvert, S.C. (mentor); Bozzon, Alessandro (graduation committee); Knijff, Tom (graduation committee); Delft University of Technology (degree granting institution)","2019","With the increasing use of big data in varied applications to improve decision making and provide new insights, the research explores the potential of the Uber Movement data set released by Uber comprising of travel times from one zone to the other. A better understanding of the potential of the dataset could lead to the addition of the existing tool kit of Transport planners and city officials at the municipality of Amsterdam. Moreover, it would be the first of a kind data set enabling an understanding of taxi movement in the city. The Uber Movement Travel Time comprises of the average travel time between two wijken, where the ‘sourceid’ and ‘dstid’ do not correspond to the origin and destination of a trip but simply represent the directionality of the travel time measured. The data is aggregated across different levels of temporal detail and the number of data points directly corresponds to the level of temporal aggregation. For instance, if the quarterly aggregated data for the different days of the week is downloaded, the number of data points between a ‘sourceid’ and ‘dstid’ cannot exceed seven.<br/>Three aspects of the data set were explored: 1) ability to capture the demand for Ubers 2) ability to capture recurrent congestion and 3) ability to capture non-recurrent congestion. While the data according to the Uber Movement and previously used instances, the data is suited for performance (recurrent congestion and non-recurrent congestion) and impact-related studies of the network. The absence of route related information limits the applications of the data. The potential of the data is also limited by the data sparsity. The potential of the data was best revealed through demand studies which indicated a skewed user group of tourists, airport users (to and fro), work-related trips and users using Ubers late at night. In addition, with respect to the goals of the municipality in managing traffic activity across different zones and time periods, by implementing and extending an existing model in the form of adding ‘occupancy related measures’ and ‘shortest path’. Thus, based on the data penetration levels and travel time data, the model developed offers insights at a strategic level to the city in the form of Spatio-temporal concentration of Uber vehicles, occupancy levels through the day. The potential of the data lies in its ability to offer strategic insights to the city of Amsterdam and the greater Amsterdam region in the form of the unique Spatio-temporal spread of Uber vehicles across different hours of the day.","Uber Movement; Amsterdam; Markov chains; Travel time","en","master thesis","","","","","","","","","","","","Civil Engineering | Transport and Planning","","52.3667, 4.8945"
"uuid:2bda7359-fc44-4e32-a639-8e04de0f7a77","http://resolver.tudelft.nl/uuid:2bda7359-fc44-4e32-a639-8e04de0f7a77","An automotive MIMO radar calibration using targets of opportunity in different weather conditions","Audenaert, Lisa (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Microwave Sensing, Signals & Systems)","Krasnov, Oleg (mentor); Yarovoy, Alexander (graduation committee); Petrov, Nikita (graduation committee); Remis, Rob (graduation committee); Delft University of Technology (degree granting institution)","2019","Automotive radar has an advantage over other sensors in that it is better at operating in bad weather conditions. To see the extent of the effect that adverse weather conditions might have on the statistics of the data a statistical analysis was performed on real measurement data. During heavy rain there is a shift that can be observed in the Radar Cross Section (RCS) of the target. The average RCS of the target increases slightly when it is raining. In (Multiple Input Multiple Output) MIMO radar it is important to calibrate the radar system as there can be both amplitude and phase distortions between the channels that can give unexpected results. These are usually estimated in a predetermined setting for known targets. However instead it might be feasible to estimate this from objects of opportunities that are regularly appearing in the radar field of view.<br/>To tackle this problem a method is used that tries to estimate these calibration coefficients from measurement data. The method needs to know the angle at which the target is located, however the range of the target can remain unknown. It uses the ideal steering vector and one of the antenna elements as a reference element. The method can recreate the phase errors very well, but relies on the reference element for the amplitude estimation. Therefore the performance is based on what element is chosen as a reference. To choose the right reference element some pre-processing is done. Then the estimation of the calibration coefficients was implemented in a Simultaneous Localization And Mapping (SLAM) framework. This was solved by using an Extended Kalman Filter (EKF). The EKF is a nonlinear form of the normal Kalman filter that will be used to make an estimate for both the location of the radar, the location of the objects of opportunity and the estimation of the calibration coefficients based of these landmarks at the same time. The resulting algorithm proves that it is feasible to calibrate the radar while driving in this way.","Automotive radar; MIMO radar; Calibration; Weather statistics; Targets of opportunity; Extended Kalman Filter; Antenna pattern; Statistical Analysis","en","master thesis","","","","","","","","","","","","","",""
"uuid:6211ddd2-62cb-48c4-9edd-521f3adf9335","http://resolver.tudelft.nl/uuid:6211ddd2-62cb-48c4-9edd-521f3adf9335","Development of a reversible solidoxide cell test station","Wagemans, Tom (TU Delft Mechanical, Maritime and Materials Engineering)","Aravind, P.V. (mentor); Delft University of Technology (degree granting institution)","2019","In a effort to curb climate change, more and more countries are adding solar and wind farms to their electrical grid. These solar and wind farms produce electrical energy based on environmental conditions, for example solar irradiation intensity or wind speed. As such these farms create fluctuations in the electrical grid and create a mismatch between energy supply and demand. To solve this problem the European Balance project proposes to use reversible solid oxide cell (ReSOC) systems. These systems can convert the excess energy produced by the solar and wind farms into an energy carrier when the supply of energy is bigger than the demand. At a later time this energy carrier can be reverted back to electrical energy when the energy demand is bigger than the supply. As these ReSOC systems are still in the development phase, experimental work is being carried out to develop these systems. For the Balance project the university of technology Delft (TuD) is tasked to determine the performance and the degradation, during constant operation and during cyclic operation, of a ReSOC system. To achieve these goals the university utilises a ReSOC test station. After use of the test station, the university found that the ReSOC systems showed high degradation and fractured within short use in the test station. As these results were not replicated by other balance partners, a cause for these results had to be found. In this work the test station was investigated to find the cause of the high degradation and breaking of the cells. After investigations of the voltage fluctuations and voltage spikes seen during electrolysis operation, it was found that water condensed in the fuel inlet duct. The liquid water droplets, formed as a result of condensation, caused the voltage fluctuations, high degradation and thermal gradients in the system that eventually fractured the cells. By redesigning the water injection system the fluctuations were reduced by 70% and the voltage spikes were completely removed. This indicates that the redesign solved the problem of water condensation in the fuel inlet duct. The resulting decrease in degradation rate of the ReSOC system extended the experimental duration up to a verified 1000 hours of continuous operation. The extended duration allowed the ReSOC system to complete 900% more cycles, within Balance protocol specification, whilst the current density was also increased by 60%. These improvements enable the test station to determine the objectives given by the Balance project. Whilst investigating the the high degradation, markings were found on the fuel electrode of the cells as well. A computational fluid dynamics (CFD) study confirmed that these markings indicated the fuel flow distribution. By converting the CFD data to current density and fuel utilisation data, it was shown that the overall performance of the ReSOC system was influenced negatively by the flow distribution plate. The results also showed that the ReSOC performance in the test station of the TuD can improve significantly if the fuel inlet flow is switched from a perpendicular to a tangential flow direction at the cell surface area. A redesigned flow distribution plate is therefore proposed that closely matches an ideal tangential flow distribution.","Experimental; Reversible solid oxide cell; Test station; CFD","en","master thesis","","","","","","","","","","","","Mechanical Engineering","",""
"uuid:fa888cb6-067a-4f7c-82ef-b872cfa674b1","http://resolver.tudelft.nl/uuid:fa888cb6-067a-4f7c-82ef-b872cfa674b1","The Thermodynamics of Economic Engineering: With Applications to Economic Growth","Manders, Nicolas (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Systems and Control)","Mendel, Max (mentor); van Wingerden, Jan-Willem (graduation committee); Vlugt, Thijs (graduation committee); Stikkelman, Rob (graduation committee); Delft University of Technology (degree granting institution)","2019","The economic engineering group at the DCSC uses Newtonian and analytical mechanics to model economic systems but makes no use of thermodynamics. The introduction of thermodynamics to the economic engineering framework would increase the extent of analysis and interpretation of economic systems in economic engineering. In this thesis the foundations of the thermodynamics of economic engineering are developed in order to include thermodynamic modeling of economic systems in the field of economic engineering. After the development of the thermodynamics of economic engineering theory, the theory is applied to analyze economic growth, factor productivity, and the value of a business. An axiomatic approach is taken to derive economic analogs to thermodynamic concepts. The meaning of an axiomatic approach is that these economic-thermodynamic analogs are developed in a logical order, e.g., the economic analog to temperature is not introduced before developing the economic analog to the first law. Key analogs between economics and thermodynamics are established in this thesis that include but are not limited to two fundamental economic laws, work as an expenditure, heat as an expense, temperature as a price level, and entropy as a quantity referred to as human capital in the thesis. By deriving key analogs, the thesis establishes the foundational principles of thermodynamics within economic engineering. Utilizing the theory of the thermodynamics of economic engineering results in applications to economic growth. Empirical growth accounting is modeled by the fundamental thermodynamic relationship. A relationship between linear production functions and Cobb-Douglas type production functions is shown by analyzing the productivity of an economy. Furthermore, a method to evaluate the worth of a business is created by determining the business' total potential earnings. Additionally, the thesis shares a vision of how to include thermodynamics within a control engineering framework. A higher-dimensional energy-based approach to model dynamical systems offers a way forward to include thermodynamic energy and entropy within control formalisms. Such a framework would account for availability and heat buildup in controlled dynamical systems. One potential application is to account for the heat build up that occurs in integrated circuits.","Thermodynamics; Economic engineering; Economic Growth; thermoeconomics","en","master thesis","","","","","","This thesis is part of the Economic Engineering group at DCSC.","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:ffc5274e-230c-4de9-b423-465fed96b612","http://resolver.tudelft.nl/uuid:ffc5274e-230c-4de9-b423-465fed96b612","Water, Sanitation and Hygiene in East Sumba, Indonesia","Djohan, Dennis (TU Delft Civil Engineering and Geosciences); Machairas, Ilias (TU Delft Civil Engineering and Geosciences); van Lienden, Kirsten (TU Delft Civil Engineering and Geosciences); Prihesti Iswarani, Widya (TU Delft Civil Engineering and Geosciences)","Scholten, Lisa (mentor); Mostert, Erik (graduation committee); Sihombing, Daniel (graduation committee); Delft University of Technology (degree granting institution)","2019","This research aims to identify the key stakeholders, explain factors that influence water, sanitation, and hygiene (WASH) behaviours, determine the chance of bacterial contamination in water, and hygiene and sanitary practises in East Sumba. The interview results show that DinKes (health agency), PAMSIMAS (rural water company), and the village board are the key players that connect the upper administrative units to the local communities. The data obtained also show that the root causes that influence the WASH condition are low education level, upbringing norms, weak economy, and geography. The water quality testing results show that in terms of E. coli 14% and 12% of the respondents had a high chance of contamination in their water source and household respectively. These numbers are 25% and 29% in terms of total coliforms. Approximately 59% respondents still use poor sanitation facilities, which includes open defecation (33%) and unimproved latrines (26%). The other 14% respondents are listed under limited sanitation service, and 27% of the respondents had their own toilet, however, it is difficult to conclude if these people fall under the basic or safely managed category of sanitation services.","Stakeholders; Sanitation; Hygiene; Water Quality; WASH","en","student report","","","","","","","","","","","","","CIE4061-09, MP288","-9.6526, 120.2733"
"uuid:bcadae15-3429-443f-8421-3aa661d8495b","http://resolver.tudelft.nl/uuid:bcadae15-3429-443f-8421-3aa661d8495b","Chalk putty: specimen preparation and aging properties","Sanchez Alonso, Carlota (TU Delft Civil Engineering and Geosciences; TU Delft Geo-engineering)","Ngan-Tillard, Dominique (mentor); Jommi, Cristina (graduation committee); Zitha, Pacelli (graduation committee); Delft University of Technology (degree granting institution)","2019","Chalk putty is a soil-like material that is formed when intact chalk is disturbed. Recently, it has become of special interest due to the development of offshore wind farms in the North and Baltic Seas, where in a number of sites piles are driven into chalk strata. Several pile tests reported in the literature show increased shaft capacity up to 4 months after driving. Although it is a widespread remark in the scientific publications that chalk properties improve over time, laboratory replications of this phenomenon are scarce and the results are inconclusive. The aim of this thesis is to develop a specimen preparation technique yielding representative specimens as well as feasible for commercial purposes. Thereafter, the evolution of the characteristics of chalk putty over time is assessed through laboratory tests. Triaxial with Bender Elements, Direct Simple Shear, Constant Rate of Strain and Thixotropy have been conducted on specimens aged up to 3 months. Finding that the behavior of chalk putty cannot be classified among the classic types of soils. On one hand, Constant Rate of Strain tests have shown that the response is comparable to silty soil, with a gradual transition between re-loading and virgin compression lines, leading to difficulty in the determination of the yield point. On the other hand, in shear, the critical state friction angle is in the range of dense sand. Regarding the volumetric response, there is an initial compressive response, succeeded by a constant volume phase during destructuration and eventual dilation or contraction at larger strains. Furthermore, it was determined that the material possesses thixotropic properties when mixed with de-ionized water. Finally, no increase in the shear strength or was recorded while the initial shear stiffness decreases with aging time -due to unconfined preservation of the samples. However, the ultimate dilatancy of the specimens increases over time, this may be a result of dissolved calcium carbonate during crushing and saturation which re-precipitates or re-cements around the grains.","Chalk; Ageing; Sample preparation; Soil laboratory testing","en","master thesis","","","","","","","","","","","","Applied Earth Sciences","",""
"uuid:1b2434fb-28a3-4b19-8fa7-ccac59c6b6c8","http://resolver.tudelft.nl/uuid:1b2434fb-28a3-4b19-8fa7-ccac59c6b6c8","Experimental research of pore water pressure fluctuation on the stability of submarine slopes: A case study of the Eastern Scheldt storm surge barrier","Steijlen, Florentine (TU Delft Civil Engineering and Geosciences)","Askarinejad, Amin (mentor); Maghsoudloo, Arash (mentor); Hicks, Michael (graduation committee); Labeur, Robert Jan (graduation committee); Janssen, Hans (graduation committee); van den Berg, Stefan (graduation committee); Delft University of Technology (degree granting institution)","2019","In this report, an experimental investigation of the influence of currents on submarine slope stability is presented for the Eastern Scheldt storm surge barrier case. Slope instabilities, including liquefaction failures, have been observed in the scour hole slopes near this barrier. The currents above the sloping bed are expected to initiate the liquefaction slope failures. The effects of the excess pore water pressure increase, that is generated by the currents, on the soil response are investigated by triaxial tests. Multiple excess pore water pressure rates are applied on a loose soil sample. The triaxial tests show that higher excess pore water pressure rates result in earlier developments of strains at lower stress ratios. This research is intended as a step towards a better understanding of the initiation mechanism of the liquefaction slope failures near the barrier.","Liquefaction; Slope stability; Excess pore water pressure; Triaxial test; Submarine slope; Eastern Scheldt Barrier","en","master thesis","","","","","","","","","","","","","",""
"uuid:2cc14807-9aea-4926-a505-98e790f5b95b","http://resolver.tudelft.nl/uuid:2cc14807-9aea-4926-a505-98e790f5b95b","Towards the ambient aerosol extinction from dried aerosol in situ observations","van Binsbergen, Priska (TU Delft Civil Engineering and Geosciences)","Biskos, George (mentor); Henzing, J.S. (graduation committee); Russchenberg, Herman (graduation committee); de Roode, Stephan (graduation committee); Delft University of Technology (degree granting institution)","2019","Accurate predictions of the extinction and scattering properties of the atmosphere are important for climate research and interpreting satellite data. This study introduces a model (called the H-model) that calculates the scattering coefficients and scattering enhancement factors based on in situ measurements of the dried ambient aerosol. A disadvantage of using dried aerosol measurements is that they do not correspond with the ambient conditions, as they are measured at a relative humidity below 40% and thus the particles are assumed to contain no water. Measurements of aerosol chemical composition do not contain water mass concentrations and measurements of the particle size distribution do not include water. To solve this problem, the H-model uses ISORROPIA, a thermodynamic equilibrium model, to estimate the expected amount of aerosol water content and growth factor g(RH) of aerosol particles for any given temperature and relative humidity (RH). With this information, the conversion between dry and enhanced relative humidity can be made. The chemical composition measurements can be complemented with the estimated aerosol water concentrations and the particle size distribution can be recalculated based on the growth factor for any given RH. In addition, the growth factor is also calculated by using k-Köhler theory and compared to the results of ISORROPIA. The findings of this sub-study show that the growth factors calculated by both approaches (ISORROPIA and k-Köhler theory) are similar as they significantly correlate. ISORROPIA, however, is more sensitive to small chemical changes which makes it more appropriate for the H-model. The calculated growth factors are used in the H-model to estimate changes in the chemical composition and particle size distribution of the aerosol particles at enhanced relative humidity. Subsequently, the H-model uses MIE theory to estimate the scattering properties of the particles at a specific relative humidity. By doing so, the scattering properties can be calculated at dry and enhanced RH, making it possible to calculate scattering enhancement factors. Finally, the H-model is validated by comparing the calculated scattering properties to measured scattering properties of a (humidified) nephelometer. To do so, in situ measurements from the CINDI campaign in 2009 and the TROLIX campaign in 2019 at Cabauw are used. The findings of this validation show that the results from the H-model do not yet accurately match the measurements. That being said, a strong correlation is observed between the calculated and the measured scattering properties. This shows that the H-model is able to capture changes in the particle size distribution and chemical composition while calculating the enhancement factors. It can be concluded that the results from the H-model are promising but need further work to close the gap between the calculations and measurements. The H-model makes multiple simplifications and assumptions which could be improved upon, thereby increasing the precision of the results as well. Furthermore, to fully conclude the findings of this study, the measurements of the SMPS and the nephelometers should be calibrated. A better statement can then be made about the accuracy of the comparison between the scattering properties calculated by the H-model and measured by the nephelometers.","Aerosol; Scattering; Atmosphere; Relative Humidity; Extinction","en","master thesis","","","","","","","","","","","","","",""
"uuid:2ef71b90-f856-464a-a9c8-e26317ddded5","http://resolver.tudelft.nl/uuid:2ef71b90-f856-464a-a9c8-e26317ddded5","In Search of Sun: Solar Pretreatment to enhance the Biomethane Potential of Empty Fruit Bunch (EFB) Fibres","Mc Gregor, Julia (TU Delft Civil Engineering and Geosciences; TU Delft Sanitary Engineering)","van Lier, J.B. (graduation committee); Lindeboom, R.E.F. (mentor); Eral, H.B. (graduation committee); Al-Muraisy, S.A.A. (graduation committee); Delft University of Technology (degree granting institution)","2019","In the past decades, fossil fuels have become an increasing concern, due them being a non-renewable energy source and due to the environmental concerns related to the production and use of this fuel. This has led to increasingly more research in the value of bio-sourced lignocellulosic biomass such as Empty Fruit Bunch (EFB) fibres from the palm oil industry. EFB fibres are a major by-product of the palm oil industry and globally, over 30 million tons are produced annually. Due to its biomass characteristic, it is a potential source of energy in processes such as anaerobic digestion, however, its complex structure results in poor biological degradation. A pretreatment such as a hydrothermal (HT) pretreatment can be used, to improve the biodegradability, prior to anaerobic digestion; however, this is an energy intensive process and has led to investigating the use of alternative energy sources for the pretreatment such as solar power. The geographical position of Malaysia is beneficial to make use of solar radiation as an alternative energy source. Concentrated Solar Power (CSP) is a technology that is gaining more interest as a way to convert solar radiation into usable energy and in particular the Fresnel lens. This research investigates if a Fresnel lens can be used to improve the biodegradability of the EFB fibres and analysed what effect this pretreatment has on the fibres (in terms of the solar radiation and the duration of exposure). Two conditions are investigated; wet (water and EFB fibre mixture) and dry conditions (dry fibres in an inert environment). These two pretreatments are compared to a conventional HT pretreatment in terms of the biodegradability based on the Biomethane Potential (BMP). From the experimental results, it was found that the Fresnel lens can achieve very high temperatures (&gt;400oC) and possesses fast heating rates resulting in a predominantly photothermal pretreatment. The biodegradability of the EFB fibres (using the Fresnel lens) was significantly improved in comparison to the HT pretreatment under the wet conditions; however, based on the analytical methods used in this research, no conclusive explanation can be given to why the biodegradability increased. Possible explanations are increased available surface area and pore size, which will need to be further researched. The dry condition pretreatment was too inhomogeneous to observe a significant improvement in the biodegradability. However, based on the overall biodegradability and the structural changes observed in the EFB fibres, it is expected that with improved operating conditions that this pretreatment will also improve the biodegradability. Overall, based on this research, the CSP pretreatment has potential to be used as alternative to the conventional HT pretreatment and the surface area for the CSP required by this process is estimated to be 2% of the actual plantation size. Therefore, CSP pretreatment has potential to be feasible in large-scale, however process efficiency needs to be improved due to the low efficiency of the lens and high energy requirements. Secondly, and most importantly, an economic analysis is crucial to validate the economic feasibility of implementing such a pretreatment.","Empty Fruit Bunch; Concentrated solar power; Biomethane Potential; Biomass Pretreatment","en","master thesis","","","","","","","","2024-12-31","","","","Civil Engineering | Environmental Engineering","",""
"uuid:b6446035-6ef0-42e7-babc-0f54071c111e","http://resolver.tudelft.nl/uuid:b6446035-6ef0-42e7-babc-0f54071c111e","Microneedles for Optical Spectroscopy: To measure across the skin barrier","Demirci, Eda (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Electronic Instrumentation)","French, P.J. (mentor); de Graaf, G. (mentor); Pandraud, G. (graduation committee); Delft University of Technology (degree granting institution)","2019","[Background] This project provides a proof of principle to use microneedles in combination with optical spectroscopy for bilirubin detection. For newborns, high bilirubin levels in the blood can lead to serious health consequences, such as jaundice, which can lead to brain damage. Therefore, it should be detected as early as possible. However, bilirubin monitoring of newborns in remote African areas is insufficient. In these areas the current invasive methods are time-consuming, and minimally invasive methods, such as bilirubinometers, are quite expensive, and may be inaccurate in babies with stronger skin pigmentation. In short, the conditions are not optimal to detect jaundice, and therefore an affordable method is needed to accurately and quickly measure the concentration of bilirubin. [Aim] The aim of this project was to develop microneedles for optical spectroscopy, and to test them in simulated skin to determine the usability for reflection measurements. [Fabrication] Microneedles are created by using microfabrication techniques with a focus on backside exposure. Multiple prototypes have been developed and evaluated based on dimensional properties. The prototype closest to the requirements was chosen to take measurements. These were the microneedles with an average length of 410 μm, an average base diameter of 106 μm and an average tip diameter of 43 μm. [Measurements] To test the microneedles for their performance, an indentation test, and transmission and reflection measurements has been performed. The indentation test showed that the average fracture point of one microneedle is at a force of 72.5 mN and an average displacement of 63 µm. The fracture point per area microneedle is on average 16.5 N/mm^2. Furthermore, transmission measurements have shown that the reduction in transmission is 70 % from the base and 75 % from the tip. Therefore, the maximum amount of light that can be used for reflection measurements is 7.5 %. Moreover, reflection measurements have shown that the differences in color concentrations in the simulated skin results in differences in absorption and therefore reflection values. Also, the measurements in simulated bilirubin (skin simulation with yellow colorant) showed a dip in the blue spectrum, e.g. at 460 nm, the absorption peak of bilirubin. [Conclusion] In this project microneedles have been developed that are minimally invasive, biocompatible, optically transparent, and easy-to-process. The first measurements have shown that it seems possible to use the microneedles in combination with optical spectroscopy to detect differences in “bilirubin” concentrations. Moreover, the microneedles can be used to puncture the skin without fracturing. However, the actual usability in the clinical setting still needs to be investigated. Other important recommendations for future research are research into measurements with real bilirubin; the optimal alignment between the microneedles and the optical spectrometer; optimization in the manufacturing process to cover the spaces between the microneedles; and possible other development methods for microneedles (e.g. 3D printing) and other designs (e.g. mirrors for efficient light use).","microneedles; optical spectroscopy; bilirubin; minimally invasive; microfabrication","en","master thesis","","","","","","","","2023-12-16","","","","Biomedical Engineering","",""
"uuid:b509e532-102b-4871-ba09-0130a7ad08e8","http://resolver.tudelft.nl/uuid:b509e532-102b-4871-ba09-0130a7ad08e8","Life Cycle Assessment and Life Cycle Costing on Brine Effluent Treatment: A Case Study of the Zero Brine Project in the Netherlands","Panteleaki Tourkodimitri, Kallirroi (TU Delft Technology, Policy and Management)","Korevaar, G. (mentor); Ludema, M.W. (graduation committee); van Beers, Cees (graduation committee); Tsalidis, G.A. (graduation committee); Delft University of Technology (degree granting institution)","2019","The water crisis is one of the most important global risks influencing humanity. Urbanization as well as economic, social and technological evolution have led to water overconsumption across the world and thus to water scarcity. Industry comprises one of the main water consumers along with agriculture and municipalities. At the same time, industry constitutes a significant water polluter since a large amount of its wastewater does not receive treatment prior to its disposal to the environment. One of the greatest sources of wastewater is brine effluent, a hypersaline concentrate created during the water treatment in the industries. In an effort to tackle the challenges that brine effluent imposes, both in terms of management and costs, the process industry should shift to technical solutions that foster sustainable development. There are three dimensions with respect to sustainability; the environmental, the economic and the social. Life Cycle Assessment (LCA) as well as Life Cycle Costing (LCC), both of which are the main axis of this thesis, are tools for identifying and analyzing environmental and economic impacts respectively. The object of this thesis is the Zero Brine (ZB) project which promotes a closed-loop approach to address the complex brine effluents by eliminating them, mitigating the effects of industrial processes while recovering materials such as water, energy, minerals, magnesium, and salts. This research is focusing on the Dutch case study where the assessment of a demineralized water production system before and after the implementation of ZB applications is taking place. The evaluation of sustainability performance comprises one of the main goals of this project. Thus, this thesis aims to assess the environmental and economic sustainability of the ZB project by implementing the LCA and LCC techniques. To that end, the parallel implementation of LCA and LCC was performed. Furthermore, the three types of LCC; conventional (cLCC), environmental (eLCC) and societal (sLCC), were also included in the analysis. The results of the analysis showed that the implementation of the ZB system has ambiguous results concerning environmental performance. On the one hand, the majority of the environmental impacts were decreased by 15% to 22%, On the other hand, global warming, acidification as well as particulate matter formation categories were sharply increased by more than 100%. From the economic assessment results, it was concluded that the application of ZB design is not financially viable since it degrades the economic performance of the current production scheme. By estimating the NPV after the implementation of ZB applications, it was observed that it is negative thus rendering the project unsustainable Overall, to enhance the environmental and economic performance of ZB applications, more research required to tackle the abovementioned issues and to render ZB project a sustainable, industrially applicable solution for the treatment of brine and the recovery of valuable resources.","Life Cycle Assessment; Life Cycle Costing; Brine Effluent; Zero Brine","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","ZERO BRINE",""
"uuid:700c930f-7a74-4e30-b384-108d11bdef1c","http://resolver.tudelft.nl/uuid:700c930f-7a74-4e30-b384-108d11bdef1c","Equivalence in Experimental Source Characterisation","Spoel, Tom (TU Delft Mechanical, Maritime and Materials Engineering)","Steeneken, P.G. (mentor); van der Seijs, M.V. (mentor); Delft University of Technology (degree granting institution)","2019","Transfer Path Analysis methods allow to describe the propagation of vibrations from an active source to a passive receiving structure. These methods are based in the experimental modelling domain, where the dynamics of the problem are described based on empirical observations from an experiment, as opposed to a numerical model based on natural and engineering laws. These methods describe the boundary conditions for the experiment, as well as how the obtained data can be used to deduce an equivalent force that describes the vibrations. Within the class of Transfer Path Analysis methods there is a specific class called the Component-based methods that are able to describe the vibrating source in such a way, that the assembled dynamical behaviour of the source attached to any other receiving structure can be predicted. This is by defining the characterisation in terms of an equivalent force on the interface. These methods are said to be a function of the source only. This is called source characterisation. In this thesis some of the assumptions of these Component-based Transfer Path Analysis are challenged. This will be done based on theoretical research as well as experiments on a numerical model. The reason this research is of interest, is that while these Component-based methods show to be valid in theory, their results in practice are not satisfactory. This is especially apparent when a characterised source is virtually assembled on a different receiving structure. Its predicted behaviour is not in line with what the real world counterpart. These Component-based Transfer Path Analysis methods involve solving an inverse problem to determine the equivalent force. Due to the experimental nature in which the data are obtained, the data has error-contamination. This happens because of interference effects causing noise on the analog sensors. This noise can have a profound effect on the solution of the inverse problem, since the problem is poorly conditioned.  The main assumption of Component-based Transfer Path Analysis methods is that if an interface force can be defined that excites the interface in the same way as the source does, the interface force can be regarded as equivalent. Due to the linearity of the problem, this equivalent force can be added in negative on top of the source excitation. This would theoretically then cancel out all motion, since both the source excitation and equivalent force have the same effect on the receiving structure. This thesis proofs that it is not always possible to find an equivalent force that represents the source excitation. This is due to the position of the equivalent force, specifically that it is placed on a single point. Some dynamic modes will show a node of their motion on the interface, meaning the interface force can by definition never excite those modes. This limitation is based from the modelling choices of the interface. It will be uncovered that the modes with such nodal behaviour are the eigenfrequencies of the source for a perfectly fixed interface. The interface limitation can be expressed as a controllability measure, where the controllability defines to what extend the interface force can excite the possible modes crossing the interface from the source. This controllability is a function of the source, the receiving structure and the sensor placement, where the source determines at which frequencies the controllability problems occur and the receiving structure and sensor placement determine the size of the controllability measure. Both an upper and lower bound of controllability can be defined. It can be quantified what the effect of the incomplete interface description is on the source characterisation. This is based on comparing the motion from source excitation and the motion from the predicted dynamics from the equivalent force. It is shown that the interface motion cannot be reproduced by the equivalent force at the frequencies where there are controllability problems. This mismatch in interface motion has an effect on the motion of the receiving structure, where it will be clear that these mode occur at range of frequency bins. While a portion of the source cannot be characterised, a large part of the behaviour can be. To solve for this equivalent force, an inverse problem has to be solved. This problem is an over-determined problem with a full rank column space. Using a priori information about the levels of noise that are expected on each measurement, the problem can be altered. This makes it possible to reduce the propagation of noise from the measurement data to the solution. A set of guidelines are proposed that can help to dampen or emphasis individual modes of the inverse system. Alternatively, the entire spectrum of modes can be dampened or single modes can be truncated. The regularisation methods will all be judged on how they change the physical relevancy of the problem. ","Component-based Transfer Path Analysis; in-situ; source characterisation; equivalent force; virtual point transformation; interface limitation; controllability; equivalence; inverse regularisation","en","master thesis","","","","","","","","2021-12-16","","","","Mechanical Engineering | Micro and Nano Engineering","",""
"uuid:4ae5a4cb-e910-4d9d-8642-ed113dcf7fb3","http://resolver.tudelft.nl/uuid:4ae5a4cb-e910-4d9d-8642-ed113dcf7fb3","Quantifying the effect of amyotrophic lateral sclerosis on the neural and non-neural properties of the wrist","Stikvoort, Diederik (TU Delft Mechanical, Maritime and Materials Engineering)","van der Helm, F.C.T. (mentor); Mugge, W. (graduation committee); Wiertlewski, M. (graduation committee); Meier, Jil (mentor); Sleutjes, Boudewijn (mentor); Delft University of Technology (degree granting institution)","2019","class=""MsoNormal"">Amyotrophic lateral sclerosis (ALS) is themost frequent form of motor neuron diseases (MND). This neurodegenerativedisease progresses relentlessly quick. The characteristic feature of ALS is theconcurrent degeneration of the upper and lower motoneurons (UMN &amp; LMN) inthe central and peripheral nervous system. Symptomatic behavior in ALS is theresult of complex symptom interplay, as well as symptom counteraction. Therefore,adequate examination of motor function in ALS requires an examination techniquethat quantifies disease symptoms at their origin, rather than at their point ofexpression. The goal of this study was to quantify and explore the effect ofALS on intrinsic and reflexive properties of the limbs of the patients underpassive and active conditions. To the best of our knowledge, this study was thefirst to assess a MND within this particular framework. A group of10 ALS patients and 9 controls were recruited for participation in an extensiveprotocol, comprising of several motor tasks and maximal voluntary contractionmeasurements. The tasks were performed on a single-axis wrist manipulator,which produced multisine torque perturbations. A linear system identificationand parameter estimation procedure was implemented to estimate the parametersof a neuromuscular model with 5 task-dependent (2 intrinsic, 3 reflexive) and 8task-independent parameters. Allparticipants were able to fully comply with the study protocol and indicatedthat the effort required for the tasks was easily maintained. Variance of theintrinsic parameters was generally increased in the patient group, with atendency towards a reduced median. The median of the reflexive parameter musclespindle position dependence was significantly increased in ALS patients during arelax task. Additionally, reflexive and intrinsic parameters of individual patientswere frequently found to be responsive to the patients respective clinicalstate. Muscle stiffness during the relax task was strongly correlated to thesummed average EMG in ALS patients (r = 0.75, p = 0.013). During active tasks,three main control strategies were derived from the intrinsic and reflexiveparameters in patients. We showthat our study protocol is viable for examination of ALS patients within alarge range of physical capacity. The use of quantitative parameters allowed usto disentangle fundamentally overlapping UMN and LMN symptoms. The derivedparameters were shown to enhance clinical scores within their respective clinicaldefinitions. Lastly, our results offer new insights beyond the current clinicalknowledge of motor function under active conditions in ALS.","Neuromuscular control; amyotrophic lateral sclerosis; system identification; motor neuron disease","en","master thesis","","","","","","","","2020-12-16","","","","Mechanical Engineering | BioMechanical Design","",""
"uuid:03724a07-f3cc-44a7-80b8-eedee0bab3c3","http://resolver.tudelft.nl/uuid:03724a07-f3cc-44a7-80b8-eedee0bab3c3","Design Space Exploration of a Spiking LSM Classifier for RADAR applications","Spessot, Davide (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Leuken, T.G.R.M. (mentor); Kumar, S.S. (graduation committee); Delft University of Technology (degree granting institution)","2019","Recent trends in platforms for the consumer market increased the need for low-power and reliable classification engines. Spiking Neural Network (SNN) is a new technology that promises to deliver 4 orders of magnitude more performance per watt than competing solutions. Moreover, the adoption of RADAR for gesture detection provides higher reliability compared to image sensors. However, no accepted topology for a temporal SNN classifier focusing on RADAR data exists. In addition, previous research did not account for several design limitations necessary to export the design in analog hardware. In this work, we explore the possible SNN topologies and propose a Liquid State Machine (LSM) with fully-supervised readout, suitable to be exported to a mixed-signal neuron array. A complete parametric model of the architecture and learning rule has been implemented in a simulation environment. Following, the design space was explored in search for the optimal operating region. By analysing the results, we: (i) highlight and explain the effects of several parameters and the trade-off between accuracy and power consumption; (ii) emphasize the need for a good balance between global excitation and inhibition in the LSM; (iii) suggest that the limitations of the proposed design point to the importance of an adequate feature extraction for a stable LSM behaviour and to the unpredictable nature of the SNN backpropagation algorithm, caused by the non differentiability of the spike signals.","Spiking Neural Networks; Radar; Machine Learning","en","master thesis","","","","","","","","2021-12-16","","","","Electrical Engineering | Embedded Systems","",""
"uuid:0e99cbcc-3497-4a34-887f-9c8370dd5870","http://resolver.tudelft.nl/uuid:0e99cbcc-3497-4a34-887f-9c8370dd5870","Fiber optimization of a carbon windsurfing boom: FEM fiber optimization for mass and stiffness","Huisman, Niek (TU Delft Mechanical, Maritime and Materials Engineering)","Keijdener, Chris (mentor); Metrikine, Andrei (graduation committee); Pavlovic, Marko (graduation committee); Delft University of Technology (degree granting institution)","2019","The goal of this research is to optimize the fiber layup of a carbon windsurfing boom for weight and stiffness. A windsurfing boom should be stiff to provide an efficient basis for the energy transfer from the sail through the surfer to the board. The weight of the boom is important as the total weight of the rig influences the performance, especially during movements where the swing weight of the rig is important. To optimize the fiber layup the FEM simulation software of SolidWorks is used. This software allows the user to divide the part in sections and specify the layup per section in terms of orientation, thickness, and material. The output of the FEM simulation is the mass and the displacement under different load cases. The load cases are based on an experiment where the loads during sailing are determined with load cells and strain gauges. <br/>The FEM simulation is validated and scaled based on two experimentally determined force-displacement relations. The FEM is scaled with the force-displacement relation of the first loading point by scaling the given material parameters by 0.78. The FEM is then validated with the force-displacement relation of the second loading point. New fiber layups are generated based on stress direction, previous iterations, and engineering intuition. The 50 new generated layups and their respective mass and displacement results are evaluated with a performance equation to determine which layup has the highest performance for the combination of mass and displacement. The coefficients in the performance equation are chosen so that both parameters have equal weight. The chosen layup is further evaluated with a required fiber overlap section. Two booms with the new layup are evaluated with the same experiment that is used to validate and scale the original FEM. At the first loading point, where the main loading during sailing is applied, the new layup is 16 percent stiffer than the original layup, as predicted by the FEM. The experiment results for the second loading point showed that the new layup was 5.5-7.5 percent stiffer than the original layup instead of the predicted 13 percent. This difference is due to the straight tubes that are glued to the end of the optimized boom body which are made by a different manufacturer. Changing the stiffness of these pipes makes the FEM results converge to the experimentally determined values. The experiment results of both layups are evaluated with the performance equation as the stiffness has increased but the mass has increased from 2.19 to 2.25 kg as well. The performance equation showed that the new layup outperforms the original layup for both loading points. The project goal to optimize the layup for mass and stiffness is therefore achieved. For the layup of the boom, a sandwiched layup of unidirectional fibers with biaxial fibers at the in- and outside of the circular cross-section was determined as the best performing layup for the sections loaded under bending. For sections that are loaded under both torsion and bending additional layers of biaxial fibers are added at the inside of the circular cross-section. These biaxial fibers are added at the inside as the unidirectional fibers are used at the outside to create the largest moment of inertia for these fibers as the displacement due to bending is leading in this case. Even the small translation of fibers from the inside to the outside of the layup can make a significant difference.","FEM analysis; optimization; carbon fiber","en","master thesis","","","","","","","","","","","","Offshore and Dredging Engineering | Bottom Founded Structures, Arctic and Wind","",""
"uuid:0abd5c96-4675-423a-a12a-9c0ab16d1246","http://resolver.tudelft.nl/uuid:0abd5c96-4675-423a-a12a-9c0ab16d1246","Effects of silver nanoparticle- containing 3D printed antibacterial implants on macrophages","van Poll, Mathijs (TU Delft Mechanical, Maritime and Materials Engineering)","Fratila-Apachitei, Lidy (mentor); Zadpoor, Amir (graduation committee); Delft University of Technology (degree granting institution)","2019","Orthopedic implants used for total joint replacements are under a high clinical demand. Although most total joint replacements are successful, premature failures are still affecting tens of thousands of people annually. The major causes of implant failure are aseptic loosening and bacterial infections. To overcome these issues, multifunctional biomaterials that can on one hand battle implant associated infections (IAI), while on the other hand enhance osseointergration are being researched. Additive manufacturing and surface modification of titanium and its alloys are very promising strategies to enhance osseointergration, as the micro-architectural structures generated by these techniques have been shown to improve bone tissue integration. However, bacteria can more easily evade defense mechanisms in porous structures. To battle possible IAI, silver nanoparticles (AgNPs) can be incorporated into the surface. However, it is crucial that such antibacterial mechanisms do not interfere with tissue regeneration processes or impact cells that play a key role in regulating bone regeneration, such as macrophages. Therefore, the aim of this study was to generate an implant which could inhibit bacterial activity, while preventing adverse effects towards macrophages. 3D printed Ti-6Al-4V implants were modified by plasma electrolytic oxidation (PEO), during which different concentrations of AgNPs were incorporated into the surface. Surfaces were characterized by scanning electron microscopy (SEM) and energy- dispersive X-ray (EDX). The viability of human mesenchymal stem cells, mouse J774A.1 macrophages and primary human macrophages was determined following the culture of each cell type on the surface of implants. Additionally, inflammatory gene and secreted protein levels were determined following the culture of human primary macrophages on the surface of the most promising implant. Finally, antibacterial activity of these implants was investigated. Implants that were surface modified in the presence of 0.3 g AgNPs/L were identified as the most promising implant to support cellular viability. Furthermore, human macrophages cultured on the surface of PEO + 0.3 g AgNPs/L implants had comparable inflammatory gene expression and cytokine production levels compared to cells cultured on implants not containing AgNPS. Moreover, metabolic activity assessment of S. aureus and E. coli in the presence of PEO + 0.3 g AgNPs/L implants showed that E. coli was affected, while S. aureus was not. Interestingly, SEM images showed none of the bacteria were able to colonize the surface, highlighting the generation of an implant which can inhibit bacterial colonization, while not showing adverse effects towards macrophages.","Silver Nanoparticles; plasma electrolytic oxidation; Orthopedic implants; Macrophages; Antibacterial","en","master thesis","","","","","","","","","","","","Biomedical Engineering","",""
"uuid:2a0538ba-c79e-4572-bdb7-c82db303f169","http://resolver.tudelft.nl/uuid:2a0538ba-c79e-4572-bdb7-c82db303f169","Question Retrieval based on Community Question Answering: Baseline Selection among Retrieval Models on two Datasets","Yang, Wanning (TU Delft Electrical Engineering, Mathematics and Computer Science)","Hauff, Claudia (mentor); Wang, Huijuan (graduation committee); Zuñiga Zamalloa, Marco (graduation committee); Delft University of Technology (degree granting institution)","2019","Community question answering (CQA) platforms provide a social environment for users to share knowledge online. Users can submit complex and subjective questions on CQA platforms and then derive the desired answer from other community users. A large number of user-generated data has been produced by various CQA sites (e.g., Quora, StackExchange) and been used in different CQA researches. Question retrieval task is one of the popular CQA tasks aiming at solving the overloading issue of CQA platforms and increasing user satisfaction by reducing their waiting time. A question retrieval system is expected to automatically retrieve similar questions from the CQA archives regarding a new question, and the answers to similar questions are returned to users directly. <br/>Different information retrieval (IR) approaches have been proposed for question retrieval task ranging from the conventional retrieval models to the learning to rank models and neural ranking models. However, the IR community is now facing the issue of overusing the weak baselines. Thus, it is hard for researchers to identify the reported improvement of the newly-proposed methods, which greatly impedes the development of the community. Some researchers have already proposed several competitive baselines for ad-hoc retrieval task, but currently, the proposals of strong baselines for question retrieval are still not enough. Thus, this work targets on identifying the suitable baselines for question retrieval task on different datasets. We conduct an empirical comparison among different retrieval models on two representative datasets and analyze the performance of models on different question sets. Analyzing on CQA questions is challenging since the CQA questions are more diverse and complex, compared to the questions on traditional question answering (QA) (e.g., Wikipedia) system as well as the queries on traditional search engine (e.g., Google). Our work investigates the impact of the question from two perspectives. We first display how retrieval performance changes on various question sets (e.g., questions with different lengths and different levels of specificity) and then explain the reasons for the performance changes. Moreover, we conduct an error analysis to reveal the hard types of questions for different retrieval models on two datasets. In order to overcome the existing weakness of the retrieval models, we further select two techniques that have already proven effective in other retrieval tasks. We hypothesize that the two techniques can also be useful on question retrieval task. We then implement the two techniques on our datasets to validate the hypothesis. Our findings show that one of them can not help to enhance the retrieval effectiveness of models due to the different characteristics of task design while another technique successfully demonstrates the additive effectiveness gains. Based on our findings, we find out the suitable baseline models on different datasets as well as emphasize their relative strength and limitation. We believe our work can provide useful guidance on how to select an appropriate baseline for future works on question retrieval.","Community Question Answering; Baseline Selection; Question Retrieval","en","master thesis","","","","","","","","","","","","","",""
"uuid:256cb467-8dcf-4dcd-b5c3-5f7db7bb8ebe","http://resolver.tudelft.nl/uuid:256cb467-8dcf-4dcd-b5c3-5f7db7bb8ebe","A Decision Support Tool for Strategic Planning of Multimodal Transport Infrastructure: The Case of Brazil","van den Boogaard, Raquel (TU Delft Civil Engineering and Geosciences)","Tavasszy, Lorant (mentor); Maknoon, Yousef (mentor); Atasoy, Bilge (graduation committee); Demenint, Wouter (graduation committee); Delft University of Technology (degree granting institution)","2019","The ever increasing need of developing efficient solutions for the transport of cargo, able to reduce transport costs while complying to green policies has promoted the use of multimodal transport during the last decades. Multimodal<br/>transport consists of the use of at least two modes of transportation for the transport of cargo from origin to destination. Governments and transport authorities (network planners) seek to make the optimal investment decisions when choosing where to allocate their budgets. To accomplish this they need to predict the response of the formulated policies on the cargo flow distributions over a multimodal network. Cargo flows over a multimodal network are in turn dependent on the behavior of water and land transport companies (network users), aiming in minimizing their own total costs of transportation. This research has developed a Decision Support Tool that is able to model cargo flows over a multimodal network, and predict the changes of cargo flows as a response to network planners policies. The research has used the freight transport network of Brazil as a testing ground for the model, and focused on improvements on the railway infrastructure. The results of the model suggest that the establishment of new railway connections and higher railway operating speeds can reduce the total costs and environmental footprint of transportation over a multi modal network. Finally, according to the model assumptions, it was concluded network users have a preference towards faster railway services.","Freight Transport; Multimodal transportation; policy decisions; Railway network","en","master thesis","","","","","","","","","","","","Transport, Infrastructure and Logistics","",""
"uuid:c8fa3202-dac8-4246-8ff2-eb08f3ac008a","http://resolver.tudelft.nl/uuid:c8fa3202-dac8-4246-8ff2-eb08f3ac008a","Semi-Analytical Buckling and Optimisation of Variable Stiffness, Variable Thickness Laminates","Vertonghen, Lander (TU Delft Aerospace Engineering)","Castro, Saullo (mentor); Peeters, Daniël (graduation committee); Bisagni, Chiara (graduation committee); Delft University of Technology (degree granting institution)","2019","Variable Angle Tow designs have shown to improve structural performance by providing a better stiffness distribution. However, additional manufacturing constraints are involved compared to straight fibre laminates: mainly the maximum fibre steering curvature that can be achieved. Moreover, if a gap free laminate is constructed, overlaps will be formed depending on the relative fibre orientation when the continuous tows are bent to follow a reference path in Automated Fibre Placement and a one-sided irregular thickness profile is created. To counter the latter effect and still obtain uniform thickness laminates, a cut and restart strategy of the tows is often used in industry, leaving the final product with small gap areas. However, previous research has hinted both numerically and experimentally on further buckling improvements of variable stiffness laminates incorporating overlaps, resulting in a variable thickness profile. To investigate these possible benefits and their extent, the thickness build-up and overlap locations are specially considered in this proposed framework on Variable Angle Tows. In first instance, a virtual manufacturing surrogate of the laminate is produced to represent the discrete thickness profile due to the overlaps. This is performed by plotting each tow graphically and subsequently retracing the total thickness based on the superimposed opacity over the laminate. The tow paths are obtained from the interpolated fibre orientation, which simultaneously incorporates the steering limit of the manufacturing process. The surrogate information is then compared to a smeared approximation of the thickness build-up, based solely on the steering angle. The linear buckling simulation is performed by means of a semi-analytical model on a plate formulation, where the one-sided thickness profile variation is modelled by incorporating an offset from the geometrical varying midplane to a common one, around which the laminate stiffnesses are calculated. These adapted stiffnesses are then used in solving the neutral equilibrium buckling problem, where the displacements are approximated by means of the Ritz method, with a set of Legendre polynomial shape functions and numerical integration of the stiffness matrices. The semi-analytical smeared model correlates to within ± 5% of the discrete thickness Finite Element Model for a range of geometries, loading and boundary conditions. This verifies the thickness approximation for linear buckling of small tow widths compared to the laminate's dimensions, yet was inconclusive for larger tow width ratios. Finally, laminates with a varying thickness profile are optimised alongside the variable stiffness for different cases and compared to uniform thickness counterparts at isomass. The results show small improvements in the symmetric problem, but a higher gain is obtained for unsymmetrical conditions with an unrestricted layup sequence, as the thickness increase can be highly tailored together with the variable fibre orientation to locations requiring higher stiffness.","variable stiffness; semi-analytical model; overlaps","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:216b45cf-6756-4252-93b6-ba91780b93a9","http://resolver.tudelft.nl/uuid:216b45cf-6756-4252-93b6-ba91780b93a9","Navigation through terrain recognition for on-board radar systems","Stefanovici, Vlad (TU Delft Aerospace Engineering)","Maas, J.B. (graduation committee); van Gent, Ronald (mentor); Hoekstra, Jacco (mentor); Delft University of Technology (degree granting institution)","2019","Radar technique advancements have made it possible to equip lightweight aircraft with radar systems. These systems can help determine the relative position of the world around the aircraft. Performing calculations on the incoming radar signals, it is possible to determine the locations of the ground elements in the aircraft body of reference, which can be done using Direction of Arrival Estimation (DAE) in a lateral setting, as a Side Looking Airborne Radar (SLAR). Using traditional computing techniques for image processing as well as two pre-trained image segmentation machine learning algorithms, it is possible to identify the aforementioned structural elements onto a satellite image to determine the actual position of the aircraft. As a consequence, navigation may be possible alongside Global Positioning Systems (GPS) methods, through obtaining the coordinates of the aircraft based on radar images. Experiment results show that a high accuracy identification rate is possible, based on large features, such as highways, within the radar image.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:b02cb64a-5ac3-49ef-848e-9f88bb135cc9","http://resolver.tudelft.nl/uuid:b02cb64a-5ac3-49ef-848e-9f88bb135cc9","Hybrid energy systems for remote island electrification in the Philippines: A techno-economic feasibility study of tidal stream energy implementation","Bosch, Rayen (TU Delft Electrical Engineering, Mathematics and Computer Science)","Smets, Arno (mentor); Weber, Fabian (graduation committee); Ramsundersingh, Atem (graduation committee); Delft University of Technology (degree granting institution)","2019","Climate mitigation measures are integrated in various governmental and commercial initiatives. The sector of electrification and energy is no exception to this. For remote island communities however, the access to reliable and affordable electricity comes with additional difficulties. The effects of climate change, energy dependency and isolation are more pressing here. Island electrification therefore requires more customized or flexible solutions compared to urban environments. Using local renewable resources can significantly improve the electrification status and independence while aiding sustainability goals. The various renewable resources contain different potentials due to availability and location and any combination of multiple resources can be accompanied with uncertainty of effectiveness and complexity of integration. Seeing that island communities have direct access to ocean energy with its global potential of 16 TW, the potential for tidal energy, and in particular tidal stream energy, is assessed in combination with the more mature technology of solar PV as to reduce the reliance on conventional energy systems and investigate the possibility of fully renewable hybrid energy systems for small scale island applications. In order to assess the technical and financial aspects of such a system, first the context of implementation needs to be clarified. Identifying the technical generation principles, resources and characteristics of each component to be integrated. To do so a framework was designed for fully renewable energy system feasibility assessment. As an assessment strategy it was decided to prioritize reliability and subsequently assess the related costs and competitiveness compared to conventional hybrid (diesel-fueled) energy systems. This was followed with a selection of performance indicators and software optimization tools to simulate the full system behavior over the desired lifetime of 20 years. Subsequently, an expedition was held to a targeted location for the case study in this research, selected by WEnergy global Pte Ltd, to create the necessary knowledge base for future reference and investigate local tidal potential. The energy demand was quantified, and data was collected on both the local tidal energy potential and tidal system to further calculate representative tidal stream generation profiles. By using a simple tidal energy model, the representative hourly current velocity datasets could be created necessary for the simulations. An inhouse Excel based simulation model was adapted to account for tidal energy implementation, and a specialized hybrid energy system optimization software was used to validate and improve the optimization speed, accuracy and sample size. Using the available data and models the technical performance in relation to the installed generation capacity, battery storage capacity, and complementarity of resources could be analysed. The selected key performance indicators were calculated for multiple configurations and compared to a conventional hybrid energy system for its commercial feasibility. For the specific case in this study insufficient tidal energy could be generated. However similar tidal type systems were found to contain sufficient potential in combination with a suitable turbine providing up to 200 [MWh] turbine per year. Resulting from the optimization the implementation of tidal stream energy in combination with solar PV and a battery storage system showed to be technically challenging but capable of providing in the annual island community energy need of 2.5 [GWh]. Commercially however, it remains uncompetitive even in a best-case scenario with a levelized costs of energy of 0.45 [$/kWh] compared to a cost of energy of a conventional system of 0.37 [$/kWh]. This study hopes to aid in the acceleration of sustainable electrification and climate change mitigation, the further pursuit of tidal energy implementation as a local renewable energy sources to reduce energy dependency and to provide more opportunity for improvement of socio-economic conditions in remote communities in The Philippines in line with the objectives of WEnergy Global Pte Ltd.","Tidal Stream energy; Hybrid renewable energy systems; Remote island electrification; Fully renewable hybrid systems; Philippines; Optimisation; Data acquisition; Feasibility study","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:0d2ebc46-09ee-493f-bb4c-c871133bff6f","http://resolver.tudelft.nl/uuid:0d2ebc46-09ee-493f-bb4c-c871133bff6f","Preliminary Propulsion System Design and Integration for a Box-Wing Aircraft Configuration: A Knowledge Based Engineering Approach","Proesmans, Pieter-Jan (TU Delft Aerospace Engineering)","la Rocca, Gianfranco (mentor); Elmendorp, Reno (mentor); Veldhuis, Leo (mentor); van Zuijlen, Alexander (mentor); Delft University of Technology (degree granting institution)","2019","The design and integration of the propulsion system is known to be an interesting, multi-disciplinary challenge in aircraft design projects. Especially for new aircraft configurations, it is important to gain a lot of knowledge in the preliminary design stages. An example of such an unconventional configuration is the box-wing aircraft examined by the PARSIFAL project. Therefore, a Knowledge Based Engineering approach towards engine design and integration is developed in this thesis. This new approach allows to consider the propulsion discipline in multi-disciplinary design and analysis routines. By employing the ParaPy software, the complete aircraft geometry can be created and subsequently subjected to aerodynamic analyses in VSAERO. The developed tools are validated and employed to explore the design space offered by a closed-wing arrangement. Based on this exploration, a turbofan system and installation location are recommended for the PARSIFAL aircraft.","Knowledge Based Engineering; Turbofan; Aircraft design; Nacelle Design; PARSIFAL; GSP; Propulsion system","en","master thesis","","","","","","","","","","","","Aerospace Engineering","PARSIFAL",""
"uuid:ae2a210f-4164-4f45-af9c-ec11c3b6b627","http://resolver.tudelft.nl/uuid:ae2a210f-4164-4f45-af9c-ec11c3b6b627","Analysis of application-based traffic load balancing over satellite links of divergent performance","Vyas, Chinmaya (TU Delft Electrical Engineering, Mathematics and Computer Science)","Smeitink, Eric (mentor); Atkinson, Gint (graduation committee); Noldus, Rogier (graduation committee); Delft University of Technology (degree granting institution)","2019","The main goal of the thesis is to investigate how to optimize Quality of Experience (QoE) of users using applications over satellite links by application aware load balancing capabilities of SD-WAN. SES (Commercial satellite operator) customers want to use applications over satellite links that have high latency and are often more congested than terrestrial networks which results in lower Quality of Experience (QoE) of users. The applications have been designed and optimized for terrestrial networks, not for satellite networks. Thus, SES wants to use its hybrid (MEO/GEO) satellite network and application aware routing capabilities of SD-WAN to prioritize and steer traffic at the application layer based on intent and business rules and enforced via policy for appropriate QoE.<br/>In the thesis, work is carried out in two parts: Firstly, experiments in lab to perform performance measurement of selected widely used applications over the different satellite links (GEO, MEO and LEO). Then performance of video applications over MEO link in different congestion scenarios (Unidirectional and Bidirectional Congestion) was measured. In order to improve the performance of video applications load balancing mechanism was defined to optimize QoE of the user. Secondly, a simulation model emulating a future SD-WAN scenario on Simulink, which is used to measure QoE of multiple users is designed. A load balancing mechanism which not only optimizes the QoE for multiple users but is also a cost effective alternative to manage the QoE is proposed.<br/> It was concluded that applications belonging to the same category have varied performances in different congestion scenarios on satellite links. Hence, each application has its performance, variation and should be dealt with accordingly. Identifying performance thresholds in different scenarios is essential to derive load balancing mechanisms to improve QoE and optimize the cost. Key applications that drive the behaviour of experience should be identified (which differs in each use case and for different customers) and steered accordingly to the best possible link so that overall QoE could be improved. Recommendations on the designing of policies for different use cases and overall development of SD-WAN as a product have also been presented in the thesis.","QoE; SD-WAN; satellite","en","master thesis","","","","","","","","","","","","Electrical Engineering | Telecommunications and Sensing Systems","",""
"uuid:15430978-1cf3-41bf-b5cc-448d7310d237","http://resolver.tudelft.nl/uuid:15430978-1cf3-41bf-b5cc-448d7310d237","Evaluation of a material hub as a circular waste management strategy: A case in Haarlem municipality","Karamanou, Maria (TU Delft Civil Engineering and Geosciences)","Tavasszy, Lorant (graduation committee); Maknoon, Yousef (mentor); Schraven, Daan (graduation committee); Delft University of Technology (degree granting institution)","2019","Dutch municipalities face the waste management problem of assets which are reaching their end of life cycle. This is why, they investigate ways to effectively tackle this issue, by simultaneously complying with the goal imposed by the Dutch government about 100% circular construction sector by 2050. As a preparatory step in the transition towards Circular Economy (CE) in the Netherlands by 2050 and the forecasted changing regulations in waste management, a material hub is deemed as a solution to the waste management concern on the level of municipalities. For this reason, the Dutch public authorities are searching a unified framework to evaluate the impact of the material hub as a circular waste management strategy. The main objective of this study is to create a decision-making tool from the municipalities’ perspective to explore the circumstances under which the material hub can contribute to circularity objectives in waste management domain, given the increased cost incurred, and assess the future feasibility of the material hub. In order to achieve the above-stated objective, this research, first, introduces the concepts of circular waste management practices in the Netherlands and the material hubs based on the academic evidence and exploratory discussions with relevant professionals. Moreover, it entails literature review of recent publications relevant to waste management models and specifically Reverse Logistics (RL) models. Second, this study describes the conceptual framework of the defined problem: • by categorising all the construction and demolition waste (CDW) into fifteen material clusters that reflect sufficiently the various waste streams in municipalities • by translating circularity in this context • by configuring a RL supply chain which is universally applicable for the fifteen material clusters. Third, the methodology used to provide a solution to the postulated problem is formulated together with simplifications for transforming the actual problem into optimization model. Fourth, the real-life problem is simulated in a mathematical model, which is then tested in the municipality of Haarlem. Fifth, the data for this case, which is either gathered or generated and inserted as model inputs, is summarised. In data generation, various scenarios of supply-demand ratio of returned materials are used. Sixth, the model results are evaluated in order to determine whether the material hub can lead to economical and circular objectives. Finally, conclusions are drawn about circumstances under which the material hub is financially viable investment for the Haarlem municipality. The cost effectiveness of the material hub is determined by two criteria. The first one is that investment in the material hub as waste management practice could evoke cost savings for the municipality in comparison with the current strategy. This is achieved by giving a new purpose to returned materials and avoiding buying all materials needed in new construction projects. The second financial criterion is the required storage capacity of the material hub. The outputs of the model for different scenarios lead to the conclusion that these two financial criteria can be fulfilled when the supply is higher than demand for returned materials. More specifically, it is concluded that in scenarios with supply-demand ratio of 2:1 and 3:1, cost savings can reach 2.5-3.6% and 10.8-12% respectively compared to the current situation. In parallel, circular objectives are realised within the aforementioned scenarios. It is identified that the optimal objective values (minimum cost, maximum circularity and minimum CO2 emissions) are not obtained simultaneously in one scenario. Subsequently, the optimal solution is determined depending on the focus of the decision-makers in the municipality. Furthermore, it should be commented that even though financial and circular goals are accomplished under the specific circumstances, the cost savings are deemed relatively low considering the initial effort and time of building a material hub. Another implication from the model results is that only limited quantity of returned materials is actually stored at the material hub. This is in contradiction with the intended basic function of the material hub as storage facility.","Material hub; Circular Economy; Construction & Demolition waste; Reverse Logistics; Linear Programming model","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:52904af0-09cb-4958-9658-691377864f80","http://resolver.tudelft.nl/uuid:52904af0-09cb-4958-9658-691377864f80","Operational Gate Allocation Using a Sliding Time Window","Borghart, jasper (TU Delft Aerospace Engineering)","Roling, Paul (mentor); Curran, Richard (graduation committee); Ellerbroek, Joost (graduation committee); Delft University of Technology (degree granting institution)","2019","The steady growth of air traffic volumes and the subsequent increase of congestion at major airports require airports to increase their operational efficiency. Inefficient or the absence of gate reassignment models increase the possibility and occurrence of gate blockage and at the same time reduce the comfort of passengers as they often receive the notice that they have to wait for their assigned gate to become available. This thesis describes a model to optimally reallocate flights to available gates on the actual day of operation for a large airport, such as Amsterdam Airport Schiphol (AMS). It takes into account the scheduled arrival time of a flight for the initial assignment, during daily operation the model updates the scheduled arrival time with the estimated arrival time as soon as the flight is enroute. The proposed model allows the user to do a trade-off between delaying, gate changing and remote handling of flights. The sliding time window has shown to reduce the number of gate changes required during daily operation in order to mitigate gate conflicts. Validation of the model with data obtained from AAS showed that the approach is feasible for real world application and that it improves the operational efficiency of the airport.","Gate allocation; Airport; MILP; Aircraft","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:daf3d84d-eb81-4e0e-a620-c257b98b598d","http://resolver.tudelft.nl/uuid:daf3d84d-eb81-4e0e-a620-c257b98b598d","Ecological Engineering of Acidogenic and Photoorganoheterotrophic Microbial Metabolisms to Valorise Cheese Whey","Mondini, Camille (TU Delft Civil Engineering and Geosciences)","Weissbrodt, David (mentor); Delft University of Technology (degree granting institution)","2019","Green phototrophs such as microalgae and cyanobacteria have been proven to be able to perform photoorganoheterotrophic metabolism. The use of organic carbon can result in higher biomass production and increased concentrations of valuable compounds. Organic waste streams can serve for this purpose and lower the biomass production costs. Cheese whey, a by-product of the dairy industry with a high organic content, can be a suitable organic carbon source.<br/>Previous studies have focused on axenic cultures, determining the species that can perform this metabolic pathway and the best substrates for their growth. However, the use of organic substrates by phototrophs in mixed microbial communities is less understood, as it is the result of multiple metabolic processes. As mixed cultures are economically preferable to pure ones, further research is needed to understand the competition mechanisms taking place in mixed-culture processes and how they can be engineered to promote the selection of phototrophs.<br/>The first part of this work focused on the production and spectrum of volatile fatty acids from the acidogenic fermentation of 40% demineralized cheese whey. The maximum degree of acidification (77±7%) of 40% demineralized cheese whey (DWP40) was obtained when thermal (90°C) pre-treatment of the inoculum was applied and combined with a F/M ratio of 0.5 g COD/g VS.<br/>The second part aimed to assess the selection for green phototrophs in a photoorganoheterotrophic mixed culture, using organic carbon sources derived from cheese whey, namely DWP40, lactose (as a model constituent of cheese whey), and acetate (as model volatile fatty acid derived from acidogenic fermentation of cheese whey). The cultivations were carried out in shake-flasks prior to implementation in a continuous-flow stirred-tank photobioreactor. DWP40, lactose, and acetate sustained the growth of green phototrophs in the mixed culture. Amongst the organic carbon sources, the use of acetate resulted in the highest biomass growth (170 mg VSS/L) and pigment content (87 μg/mg VSS). The selection for phototrophic organisms was possible both in batch and continuous mode.<br/>The results obtained showed that the conversion of the lactose inside cheese whey to acetate could improve its uptake by phototrophs. Their selection inside a photoorganoheterotrophic mixed culture can be improved by higher pH and inorganic nutrient concentrations, and lower dissolved oxygen levels.","photoorganoheterotrophy; green phototrophs; mixed culture; cheese whey; photobioreactor","en","master thesis","","","","","","","","2025-01-01","","","","","",""
"uuid:e12eb0e2-67a2-4640-8598-3f639f12cea4","http://resolver.tudelft.nl/uuid:e12eb0e2-67a2-4640-8598-3f639f12cea4","Wave Dynamics in Inverse Krylov Subspaces","Belier, Joris (TU Delft Electrical Engineering, Mathematics and Computer Science)","Remis, Rob (mentor); Delft University of Technology (degree granting institution)","2019","Recent studies have shown an increased interest in modal solutions of wave problems with resonating structures. These studies demonstrate that resonating structures with physical dimensions close to a wavelength can be accurately described by a few relevant resonating modes. The physical dimensions of the demonstrated resonating structures were close to a wavelength, which suggests that these highly-resonating modes have relatively low eigenvalues. Those resonating-modes are therefore dominantly present in Krylov subspaces generated by inverse projections of the wave-operator. Relevant wave dynamics can, therefore, be effectively computed from inverse Krylov subspaces. Furthermore, inverse Krylov subspaces are computationally stable and are therefore a powerful way to compute high-fidelity modal solutions. With interesting applications in high Q-factor wave problems. The aim of this work is on improving the performance of inverse Krylov subspaces. Improvements to inverse Krylov subspace can be grouped into two approaches. In the first approach symmetry is exploited in the inverse wave-operator for reduced computational complexity and in the second approach the wave-operator is conditioned for desirable characteristics at the relatively low side of the spectrum. We will study several wave-operator configurations and optimize according to those approaches. Earlier studies have shown that in the dimensions with pseudo-periodic boundary conditions, the double-curl is efficiently eigendecomposed as spatial derivatives are diagonal operators acting on frequency representations. We extend this work by providing an alternative, more compact presentation in the continuous domain of the eigendecomposition of the double-curl. This eigendecomposition is used to create a nullspace free eigenvalue problem. Consecutively, we analyse the characteristics of the inverse wave-operator with Perfectly Matched Layers (PML). This analysis shows that in terms of inverse Krylov subspaces, the PML is not the obvious choice for the optimal absorbing boundary condition. Most notably, the PML introduces undesirable effects at the lower end of the spectrum, significantly impeding the performance of inverse Krylov subspaces, which leads to the conclusion that absorbing boundary conditions should be reassessed in terms of inverse Krylov subspaces behaviour. Lastly, we will study the so-called Fixed-Frequency PML (FF-PML), which is a PML inspired time-independent absorbing boundary condition. Our study has shown that the FF-PML is a more suitable absorbing boundary condition candidate for inverse Krylov subspaces. It does not have the undesirable effects at the lower end of the spectrum, which the traditional PML has. Furthermore, and even more importantly, we derive analytic expressions of the inverse wave operator with FF-PML absorbing boundary conditions. This simple and novel insight is easily exploited to invert the wave-operator efficiently, which enables a new approach to the computation of modal solutions of open scattering problems. The first results of which look promising.","Wave simulation; Reduced order model; Krylov; Modes; Periodic boundary condition; PML","en","master thesis","","","","","","","","","","","","Electrical Engineering | Signals and Systems","",""
"uuid:cb91f195-abea-4908-817d-8198fb8eadb2","http://resolver.tudelft.nl/uuid:cb91f195-abea-4908-817d-8198fb8eadb2","A Numerical Study of Swirl Flow in Pipes: Application to Inline Swirl Separators","Karimpoorheidari, Alireza (TU Delft Civil Engineering and Geosciences)","Portela, L. (mentor); Zitha, P.L.J. (graduation committee); Voskov, D.V. (graduation committee); Delft University of Technology (degree granting institution)","2019","For many decades, conventional gravitational separators have been the backbone of the fluid separation in the oil and gas industry. The stricter environment regulation for purification of the recycled water, together with a tighter profitable margin of the produced oil, requires more efficient and faster separators. Inline swirl separator uses centrifugal acceleration up to hundreds of gravitational accelerations to perform separation in a much faster time. However, its efficiency is still lower than the industry expectations. There are essential geometric parameters such as swirl intensity and the collector tube, and vital operating conditions such as flow-rate at the entrance and mass flow-rate at each exit that impact the dynamics behavior of swirl flow in the pipe. The dynamic behavior of the swirl flow determines the efficiency of the apparatus. Thus, the main objective is to understand the dynamics of the single-phase swirl flow in the pipe and determine an inline swirl separator that presents sufficient efficiency. The first part of the study focuses on a better understanding of the dynamic behavior of the swirl flow in a pipe. The second part utilizes the results from the first stage to determine an inline swirl separator that presents sufficient efficiency. The performed numerical study suggests that the dynamic behavior of swirl flows in a pipe is determined by the intensity of the swirl flow, which is quantified by the swirl number. The swirl intensity shapes the axial velocity profile at the core of the vortex. When the swirl number increases beyond a critical number, a columnar vortex appears, with a reverse flow along with the center of the entire tube. The swirl intensity decays along the wall of the pipe; the swirl intensity and the decay of it form the shape of the axial velocity profile. In case the disturbance of the flow results in a stagnation point at the vortex axis, it may develop a vortex breakdown. The vortex breakdown in high Reynolds numbers ( Reb &gt; 100,000) is a function of the swirl number, and the instability at the vortex core increases by increasing the swirl intensity. Furthermore, the results show that the stability of the vortex is a function of the Reynolds number. Considerable reduction of the Reynolds number kicks in the effect of viscous forces, which stabilize the vortex core. Reynolds and swirl numbers determine the dynamic of the low Reynolds number but turbulent, swirl flow. Therefore, the industry needs to rely on Reynolds Averaged Navier-Stokes (RANS) simulations; Direct Numerical Simulation predictions obtained at much lower Reynolds numbers may not predict the occurrence of the vortex breakdown inside the pipe. These findings show that there are essential design considerations, which determine the efficiency of the swirl separator. Thus, a combination of the geometry parameters and the swirl flow characteristics should be considered to avoid the reverse flow zone and vortex breakdown inside the inline separator. One of the vital elements of the inline swirl separator is the collector tube. The study shows that the collector tube at the neutral flow split, with no bias of the mass flow-rate at each outlet, changes the velocity to the extent that he reverse flow zone for Sw=0.5 is eliminated. Pressure actuators can control the flow; therefore, controlling the flow split at both outlets. The numerical results show that an additional percentage of flow split enhances efficiency by eliminating the reverse flow zone for the higher swirl numbers. Additionally, the study reveals the counter effect of the extreme flow splits, which hinders the efficiency of the inline swirl separator. These optimal settings for the geometry of this research were found at swirl number 1.6 and flow split of 50%.","Swirling flow; Inline Swirl Separator; Vortex; CFD computations; liquid-liquid separation; oil and water separation","en","master thesis","","","","","","","","","","","","Petroleum Engineering and Geo-sciences","TOMOCON EU",""
"uuid:51a113ff-0e7f-474f-965f-05319c988bad","http://resolver.tudelft.nl/uuid:51a113ff-0e7f-474f-965f-05319c988bad","Design and optimisation of an additively manufactured patient-specific partial mandible reconstruction implant","Oldhoff, Miriam (TU Delft Mechanical, Maritime and Materials Engineering)","Mirzaali Mazandarani, M. (mentor); Tümer, N. (mentor); Zadpoor, A.A. (mentor); Delft University of Technology (degree granting institution)","2019","Additive manufacturing (AM) provides the opportunity for complex porous designs, without the costs depending on batch size. Therefore patient-specific implants can be rapidly manufactured. In clinical practice, reconstruction of the mandible is needed in case of bone tumors or trauma. Part of the mandible is removed and the shape of the missing part needs to be estimated, before an implant can be designed. Now-a-days the golden standard for mandible reconstruction is autograft surgery using the iliac or fibula bone. However, this comes with extra donor site surgery and asymmetrical face contours. Mandible movements are needed for mastication and speech and the mandible bone accounts largely for the individual’s face appearance. Hence, good estimation is needed for both function and aesthetics<br/>In this study, a statistical shape model (SSM) of the mandible was generated by segmentation of the mandibles from 35 full body CT-scans. The missing shape of the mandible was estimated using an extruded base, the SSM and mirroring of the intact side. Two finite element models (FEM) were made; one of a healthy mandible and one with a 25% total volume defect with a solid Ti-alloy implant created with the SSM. Two loading conditions were simulated separately; incision clenching (INC) and right molar biting (RMB). Topology optimizations were made with a volume constraint of 0.2 and 0.24 together with an objective function to minimalize the strain energy. To investigate more initial conditions, more topology optimizations were completed. These included one in which the initial implant included pores and two in which extreme mandible cases were used, which were retrieved using the b-values for the first mode of the SSM. <br/>Variations in shape of the mandible were seen in the modes of the SSM. Mode 1 described the variations in shape between the intercondylar angle and distance, mode 2 of the gonial angle and symphysis length, mode 3 described the variations in shape and position of the condyle and mode 4 was associated with the coronoid process. Calculations of the maximum and average distances of the point cloud of the original missing bone part to the estimated shapes illustrated that both mirroring of the healthy side and SSM resulted in the closest estimation. No significance was found between the two methods. Limitations of the mirroring method in relation to the locations of the defects, resulted in the use of SSM for the design of the implant. Topology optimization resulted in optimized implant frames that were located at lateral inferior sides of the implants for both volume constraints and biting tasks. Small differences were seen in the exact location of the crossing of the implant frame. FEM results suggested correct maintenance of stress concentrations and displacements, when compared to the healthy intact mandible. It was suggested that the initial implant shape influences the optimized outcome. Different mandibles resulted in unique optimized implant frames, making the outcome patient specific. The workflow created in this study can be used as a proof of concept for the design and optimization of patient-specific implants for mandible reconstruction, which can easily be manufactured using additive manufacturing processes.<br","implant; additive manufacturing; mandible; Statistical Shape Model; patient-specific; Topology Optimisation","en","master thesis","","","","","","","","","","","","Biomedical Engineering | Tissue Biomechanics and Implants","",""
"uuid:a27d9271-497b-49a3-bee1-cc265f9945f4","http://resolver.tudelft.nl/uuid:a27d9271-497b-49a3-bee1-cc265f9945f4","“Apologies for any inconvenience caused”: A better public bus traveller experience: Improving traveller information during disruption","Bottema, Anne-Minke (TU Delft Civil Engineering and Geosciences)","Hoogendoorn, S.P. (mentor); van Oort, N. (graduation committee); Ozcan Vieira, E. (graduation committee); van IJperen, Stephan (graduation committee); Delft University of Technology (degree granting institution)","2019","","Traveller expierence; Disruptions; Traveller information; User research; Buses","en","master thesis","","","","","","","","","","","","Civil Engineering | Transport and Planning","",""
"uuid:8f882714-76c1-45ab-afbe-4f383b580b61","http://resolver.tudelft.nl/uuid:8f882714-76c1-45ab-afbe-4f383b580b61","Stinger monitoring system: A sensor placement method for damage localisation and damage quantification applied to a stinger monitoring system","Wolters, Djurre (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Biomechanical Engineering)","Steeneken, P.G. (mentor); Hendrikse, H. (mentor); Wellens, P.R. (graduation committee); Delft University of Technology (degree granting institution)","2019","A stinger is a steel space frame structure, used on pipe-lay vessels, to support the weight of a suspended pipeline. A stinger is highly fatigue loaded due to environmental loads, vessel motions and variable pipe loads. In the design phase, predictions for the structural behaviour of the stinger were made. However, inspection history showed discrepancies between the design phase and reality. A stinger monitoring system was proposed to provide a solution for this problem. The goal of the thesis was formulated as follows: Design of an optimised sensor placement method for a stinger monitoring system to localise and quantify damage. A method based on the vibration characteristics of a stinger model was chosen for damage localisation and quantification. This method correlates the measured modal property changes with analytical modal property changes to identify damaged members and to estimate the damage extent in these members. A sequential sensor placement method was applied to determine the sensor locations contributing most to the modes of vibration of the stinger model. The proposed method can accurately localise damage for damage situations with one damaged member. For damage situations with multiple damaged members, the method is able to correctly identify one of the damaged members. To identify the other damaged members, a modification of the method was proposed. On the condition of a damage threshold, this modified method is able to localise multiple damaged members in a selected number of damage situations. The damage quantification method was able to give a good estimate of the damage extent.","Stinger; Monitoring; Modal properties; MDLAC; damage","en","master thesis","","","","","","","","","","","","Biomedical Engineering","",""
"uuid:2f1dc98e-9544-4817-83f3-3c26d2964934","http://resolver.tudelft.nl/uuid:2f1dc98e-9544-4817-83f3-3c26d2964934","A frequency dependent drag coefficient on the motion response of a hybrid STC wind-wave energy converter","Kohlmann, Lars (TU Delft Mechanical, Maritime and Materials Engineering)","Wellens, P.R. (mentor); Delft University of Technology (degree granting institution)","2019","The vertical viscous drag force acting on a heaving cylinder with flat and hemispheric bases is investigated by means of an experiment, a linear and a nonlinear analytic model. Viscous effects create a significant uncertainty in estimating the motion response of oscillating cylinders in waves of different frequencies. Forced oscillation tests are compared with a linear analytic model and approximated with a nonlinear model to quantify the viscous drag force for a range of oscillating frequencies. The results asses the behaviour of the drag coefficient, CD, to be used for calculating the drag force. The main interest of this study is to improve the estimation of the motion response of floating hybrid wind-wave energy converters. The hydrodynamic parameters, added mass and radiation damping, used in the linear model are obtained with the boundary element method (BEM) solver NEMOH. The same parameters are obtained from the experiment for comparison. Near the natural frequency of the geometries the linear model underestimate the forces due to the absence of a nonlinear viscous drag term. The time traces of the force measurement around the natural frequencies show period doubling behaviour which can be described by the quadratic velocity term in the drag force calculation. By applying the least-squares optimization method on the obtained data, optimal variables in the fit-function including the quadratic drag term are found. The results show the drag coefficient, CD, is changing over the frequency of oscillation. The vertical drag force is frequency dependent and therefore important to consider when calculating the motion response of wave energy converters","Drag coefficient; WEC; Viscous drag; Damping; Heave; Forced Motion; Frequency","en","master thesis","","","","","","","","","","","","Marine Technology | Hydromechanics","",""
"uuid:13f3c500-4edd-4cf3-80ea-a4464279a78e","http://resolver.tudelft.nl/uuid:13f3c500-4edd-4cf3-80ea-a4464279a78e","Flexible Graphene-Based Passive and Active Spinal Cord Implants","Velea, Andrada (TU Delft Mechanical, Maritime and Materials Engineering)","Giagka, Vasiliki (mentor); Vollebregt, Sten (mentor); Serdijn, Wouter (graduation committee); Steeneken, Peter (graduation committee); Delft University of Technology (degree granting institution)","2019","The spinal cord, considered to be the most important path of the human body, when injured induces severe motor dysfunction. Therefore, patients affected by lesions on the spinal cord, are most of the time unable to walk, stand or perform motor activities that are trivial for healthy people. To provide a better quality of life for these patients, extensive research and effort have been put by both neuroscientists and engineers to provide clinical therapies for pain relief and locomotion restoration together with dedicated platforms that could deliver these therapies. Currently, for these purposes, epidural spinal cord stimulation is widely used. Apart from being used as a method to reduce pain, it has also been proven to promote locomotion recovery. Apart from clinical trials, it is of great importance to understand the mechanisms that occur while delivering specific therapies. To this end, more exploratory research is mostly conducted in rodents. However, the availability of tailored neurotechnologies, for experiments conducted in small animals, is limited mostly due to size constraints. Moreover, when developing implantable devices that would target the spinal cord, careful selection of the materials used is equally important. However, understanding the underlying mechanism leading to a specific behaviour or motor outputs requires exploring and quantifying new methods of stimulation. For instance, optogenetics has been gaining a lot of popularity in the field of neural stimulation as it is a more specific technique that could help neuroscientists map the neuronal circuitry within the human body. Thus, apart from developing spinal cord implants that resemble best the anatomy of the body, while inducing as little stress as possible on the spinal cord, for exploratory reasons the developed implants must provide optogenetic compatibility. Therefore, this thesis reports the development as well as the characterization of both passive and active spinal cord implants with optogenetic compatibility.<br/>To achieve the desired goal of having a fully implantable, flexible spinal cord implant with optogenetic compatibility, a scalable and reproducible microfabrication process has been developed. Materials such as graphene, for transparency, flexibility and conductivity were used to develop the microelectrode arrays. Moreover, soft, polymeric encapsulation was employed to sustain the high flexibility and transparency of the implant. The end result of the microfabrication process would lead to a device consisting of a multi-layered graphene structure between two polymeric-based encapsulation layers and metal test pads for interconnection to the outside world. However, towards achieving this final structure, several challenges were encountered. Suspension of the implants after developing them on a rigid substrate, yet ensuring high quality for the graphene layer leads to several iterations of the fabrication process. Despite the challenges encountered, several prototypes were successfully developed. However, having prototypes that can only validate the process flow would not suffice. Therefore, extensive evaluation of the devices has been conducted and reported. Methods such as Raman spectroscopy and optical transmittance to evaluate the graphene layer or cyclic voltammetry and electrochemical impedance spectroscopy to characterize the performance of the fabricated devices were employed. The degree of transparency obtained using the reported microfabrication process was ~78 %, leading to the conclusion that the number of graphene layers for the final device was 10. It has been proven that graphene does not deteriorate over time when soaked in saline solution for several consecutive days and apart from that, the graphene-based implants showed no performance deterioration when bent over rods down to 3 mm in diameter. Moreover, the graphene electrodes provided impedance values of ~8 kΩ at 1 kHz frequencies, values comparable to what literature has previously reported. Apart from developing a passive graphene-based spinal cord implant, the focus of this thesis was also to fabricate and characterize an active implant. However, embedding active components with a flexible, graphene-based array of electrodes is not trivial. Therefore, system integration of small test chips was investigated and after several iterations of flip-chip bonding processes, a complete, active, graphene-based prototype was obtained. The measurements performed after the bonding process have proven that both bonding on graphene-only as well as on graphene and metal substrates is possible and the four-point measurement results indicated resistance values ranging from 10 mΩ up to 16 Ω for individual connections, depending on the substrate used.<br/>Therefore, with this research project, not only the first fully transparent, graphene-based spinal cord implants have been developed but also the results obtained from their characterization illustrate that the process is stable and the performance of the devices is promising.","Graphene; Passive; Active; Spinal Cord Implants","en","master thesis","","","","","","","","2020-12-31","","","","Biomedical Engineering | Bioelectronics","",""
"uuid:667a7a77-fb81-4aca-99db-804cd4c0a516","http://resolver.tudelft.nl/uuid:667a7a77-fb81-4aca-99db-804cd4c0a516","Development of a finite rate chemistry solver with tabulated dynamic adaptive chemistry","SURAPANENI, ANURAG (TU Delft Aerospace Engineering)","Martinez, Daniel Mira (mentor); Gangoli Rao, A. (mentor); Delft University of Technology (degree granting institution)","2019","Despite the onset of peta-scale computing, simulations of reacting flows with detailed chemistry is still considered computationally expensive. Better understanding of the chemistry of various fuels has led to increase in the complexity of the simulations in an effort to compute flows with real complex fuels. The increase in complexity makes CFD simulations prohibitively expensive even for the next generation of exa-scale computing. To have accurate reacting flow simulations with detailed chemistry at realisable costs some sort of cost mitigation strategy is to be applied. Solution of the chemistry in reacting flows is one of the most expensive steps of such simulations as it involves solving a system of highly non-linear stiff equations. There have been various methods proposed to reduced this computational costs at the expense of some assumptions. These methods can be broadly classified into two categories: (1) methods based on tabulation which include ISAT and Flamelet methods, and (2) methods based on adaptive chemistry. Former methods are developed to work on specific regimes of combustion and are known to predict reacting flows accurately, but when used outside this regime they may fail. <br/><br/>The present project falls under the adaptive chemistry category and aims to develop a numerical framework for the study of turbulent flames at various regimes using high-fidelity numerical simulations with on-the-fly adaptive kinetics. The chemistry reduction process is based on the Path Flux Analysis (PFA) enforcing Adaptive Chemistry (AC) based on local conditions. <br/><br/>PFA is a chemistry reduction method based on truncating reaction pathways. Key species are defined, usually reactants, major products, and species of specific interests like pollutants. PFA classifies reaction pathways between theses key species and eliminates pathways which fall below a specified threshold. PFA algorithm is formulated in a way that multiple generations of intermediate species can be tracked. In literature a universal threshold is specified, however, as the reaction pathways and their weights depend on the local chemical state, a universal definition of the threshold would lead to different levels of reduction and can lead to over-reduced/under-reduced regions. In this work the definition of the threshold is modified to be dependent on the local thermodynamic state, this ensures a uniform level of reduction. <br/><br/>Current state-of-the-art model of dynamic adaptive chemistry rely on an error estimator which decides when and where in the computational domain the reduction algorithm to be applied. This error estimator, usually a correlation function between specific chemical species is user specified and has a great impact on the reduction. This makes it necessary for the user to have an \textit{a priori} understanding of problem and its chemistry. The methodology developed in this project eliminates the need for this error estimator as the reduced chemistry is tabulated based on a set of controlling variables. These controlling variables have global definitions and are identified for different regimes of combustion. The expensive operation of chemistry reduction is tabulated, hence reducing the computational time needed for chemistry reduction significantly. <br/><br/>State of the art reduction models and the proposed model are tested in: (1) laminar steady-state cases: premixed free flame, counterflow diffusion, and partially premixed flames; and (2) transient cases: auto-ignition, flame kernel propagation in stratified mixtures, flame vortex interaction, and a reacting Taylor-Green vortex. The proposed model is found to predict solutions with the same accuracy as the state of the art models in steady state cases and performs better in transient cases due to its nature of chemistry reduction which makes it applicable to a variety of combustion problems without any tuning. Computationally the proposed model was found to be between 5 to 20 $\%$ faster for specific cases than the respective reference case with no chemistry reduction.","Combustion; Dynamic Adaptive Chemistry; Path Flux Analysis; Computational Fluid Dynamics (CFD); Tabulation","en","master thesis","","","","","","","","2021-12-12","","","","Aerospace Engineering | Flight Performance and Propulsion","",""
"uuid:0220e4e5-978f-423c-b443-508011f0b13c","http://resolver.tudelft.nl/uuid:0220e4e5-978f-423c-b443-508011f0b13c","Re-entry vehicle aerodynamic database reconstruction from the analysis of test dynamics","Bunt, Riccardo (TU Delft Aerospace Engineering)","Naeije, M.C. (mentor); Sudars, Martins (graduation committee); Delft University of Technology (degree granting institution)","2019","During the design and analysis of a mission characterised by re-entry flight, consistent effort and resources are invested in the definition of the aerodynamic database of the re-entry vehicle. An aerodynamic database collects a set of dimensionless coefficients that describe the interaction of the vehicle's geometry and airflow, and an accurate estimate of its elements is key to the correct modelling of the accelerations experienced during flight.The methodology elaborated herein focuses on the reconstruction of the aerodynamic database of a capsule-shaped vehicle, based on the analysis of simulated data from wind tunnel tests and drop tests. The estimation process is characterised by linear regression of the data that requires linearisation of the dynamics, with the use of Taylor series expansions, and a polynomial representation of the coefficients' dependency on the angle of attack. The preliminary estimate of the coefficients computed by linear regressions is introduced in data smoothing models in order to reduce the noise and errors present in the dataset. The effectiveness of the Extended Kalman filter, the Unscented Kalman filter and the Square Root Unscented Information filter applied to the measurement is established and the results proved their performance to be comparable one to another in the presented problem.Finally, the core of the research performed is related to nonlinear regression methods, oriented towards aerodynamic database reconstruction. At first, an analytical approach is elaborated by defining a harmonic solution for curve fitting of oscillatory dynamics. However, the iterative Gauss-Newton algorithm does not converge to a definition of the regression parameters in the presented case. The focus is therefore then concentrated on optimisation methods. Multi-island Genetic Algorithm, Adaptive Simulated Annealing, Nealder &amp; Mead Downhill Simple, Hooke-Jeves Direct Search and a Hybrid Algorithm are all methods applied to the problem. From the analysis of the results, based on a simulated wind tunnel test of a Hayabusa type capsule in subsonic flow regime, three algorithms emerge for greater accuracy in the reconstructed database: the Hybrid Algorithm, the Hooke-Jeves Direct Search and the Adaptive Simulated Annealing method.","AEDB reconstuction; Aerodynamic database; Regression analysis; Wind tunnel simulation; Re-entry vehicle; Capsule; Drop test simulation; Optimisation Algorithms","en","master thesis","","","","","","","","2021-12-13","","","","Aerospace Engineering","",""
"uuid:ee144ad9-2049-4c95-8f3a-533f0b6906e5","http://resolver.tudelft.nl/uuid:ee144ad9-2049-4c95-8f3a-533f0b6906e5","Reverse Engineering of existing reinforced concrete slab bridges","Harrewijn, Thomas (TU Delft Civil Engineering and Geosciences)","Yang, Y. (mentor); van der Veen, C. (mentor); Vergoossen, R.P.H. (mentor); Lantsoght, E.O.L. (mentor); Hoogenboom, P.C.J. (mentor); Delft University of Technology (degree granting institution)","2019","Most bridges in the Western European road networks are ageing. The vast majority of about 90% of these bridges have reinforced concrete as a building material. The traffic intensity, as well as the axle, and the average vehicle weight have increased since these structures were opened to traffic. Furthermore, the structural (design) codes have changed over the years. Therefore, there is a need to investigate if existing structures meet the safety/reliability level described by the current codes. However, a frequently faced problem in practice is that the original design calculations and technical drawings of a large percentage of the existing bridges are unknown or lost. Especially for bridges in the lower road network, often designed for the lower load classes B/45 and maintained by a local government, the documentation is missing. The national road network, designed for load classes A/60 is maintained by the national government and faces the same problem but to a lesser extent. Bridges within this scope have different detailing rules and execution practices than used nowadays. Plain reinforcement was in general used which is bend-up at a support. Therefore, the study is twofold: first, Reverse Engineering is applied to determine the reinforcement of existing reinforced concrete slab bridges, second the capacity margin of RE bridges are examined with the current assessment codes. A Reverse Engineering-tool is developed to automate the dimensioning of the required reinforcement according to the former design codes. This tool uses the year of design, load class and the geometric dimensions of the bridge as input parameters. A parametric study is performed to examine bridges from different design periods. Consequently, the Reverse Engineering-tool is used to assess the Reverse Engineered bridge according to the current assessment codes. The validation of the model shows for the majority of the Reverse Engineered bridges that the Reverse Engineered reinforcement is slightly less than the reinforcement amounts from the technical drawings. This proves a conservative approach where the actual structural capacity is underestimated. Consequently, an assessment of the Reverse Engineered bridge can be performed with sufficient robustness.The computer code ran with the input parameters having a normal distribution, showed the largest effect for the uncertainty in the design year and load class especially around 1940 and 1962. Therefore, the design year and load class are crucial in Reverse Engineering and assessment of an existing bridge. The capacity margin of the Reverse Engineered bridges is assessed according to the current Eurocode based design codes. The traffic- and permanent load including load factors according to the general assessment codes from the NEN8700/NEN8701 and the RBK-1-1, and the decentralised load model from TNO are applied. The assessment with the Eurocode including the load factors from the NEN8700 showed Unity Checks for bending moment at the mid-supports and mid-spans of larger than 1.0, where the Unity Checks for shear forces resulted below 1.0. The assessment with the Decentralised load model showed Unity Checks for bending moment at the mid-supports and mid-spans and shear force below 1.0. In case the amount of support reinforcement is based on the amount of span reinforcement, the bending capacity margin at the mid-supports is insufficient for large spans. Significant bending capacity margins are obtained in structural design of RC slab bridges in the period 1930-1970. The main contribution of this research is that bridges designed between 1940 and 1962 show the most critical Unity Checks for bending in the assessed period. In this period account the following design methods: The dynamic amplification factor introduced in the GBV1940 for concrete bridges, the traffic load class from the VOSB1933, the N-method to determine the cross-section capacity and the effective width method from the GBV1940 and from the Guyon Massonnet method.The capacity margin for shear is found to be almost independent of the design period. Here can be concluded that the slenderness of the bridge deck is the main contribution in the shear capacity. Bridges designed in the period 1940-1962 with the support reinforcement based on the span reinforcement and with a span length &gt;10m designed for load class B/45 or with a span length of &gt;11m designed for load class A/60, form the group with the most critical bending capacity. However, the size of the group of former bridges designed according to these conditions is unknown.From the results can be concluded that bridges designed between 1940-1962 with RE reinforcement are found to be legally unsafe for bending according to the parametric assessment with the Eurocode.","Reverse engineering; existing bridges; Reinforced concrete slab; Parametric model; structural capacity margin; plain reinforcement; former design codes","en","master thesis","","","","","","","","2021-12-13","","","","Civil Engineering | Structural Engineering | Concrete Structures","",""
"uuid:264cfd01-b8d2-4ea9-a8eb-bddf9d957615","http://resolver.tudelft.nl/uuid:264cfd01-b8d2-4ea9-a8eb-bddf9d957615","Induction welded unidirectional carbon fiber reinforced thermoplastic L-joints: Joint performance and testing methodology","van Dijk, Milan (TU Delft Aerospace Engineering)","Kassapoglou, C. (mentor); Villegas, I.F. (mentor); Labordus, Maarten (mentor); Zarouchas, D. (graduation committee); Rans, C.D. (graduation committee); Delft University of Technology (degree granting institution)","2019","Induction welding is an effective technique for joining unidirectional carbon fiber reinforced thermoplastic composites and L-joints can be produced through quick and cost-effective processing steps. However, due to high localized stresses in the skin-stiffener interface, these L-joints are often avoided in primary aircraft structures. Also, no international testing standards have been developed for testing of such joints.<br/><br/>A method was developed for the implementation of a neat thermoplastic resin fillet between the L-joint skin and stiffener web using the induction welding process in an attempt to remove the high stress concentration at this location. A 35.4% increase in quasi-static pull-off strength was measured with a weight penalty of less than 0.5%. This result was compared with a similar autoclave co-consolidated joint, which showed an 80.9% improvement. An ANSYS Parametric Design Language finite element model was developed based on the virtual crack closure technique and it showed that the joint pull-off performance is strongly dependent on geometric parameters such as the skin and stiffener thickness. Also, a new test setup was developed, which reduced internal stresses created by the setup compared to those commonly used in literature.<br/><br/>By further improving the method through which the fillet is joined to the induction welded L-joint, a performance increase similar to that of the co-consolidated joint should be achievable. Test results have shown that the use of this type of fillet can lead to the skin-stiffener interface no longer being the critical failure point for realistic joints in primary aircraft structures.","Thermoplastic; Composites; Induction welding; L-joint; Skin-stiffener joint; Pull-off test; KVE","en","master thesis","","","","","","","","2021-12-13","","","","Aerospace Engineering","",""
"uuid:a255be10-eec4-4073-926a-2ecf66e7e541","http://resolver.tudelft.nl/uuid:a255be10-eec4-4073-926a-2ecf66e7e541","Automatic multimodal detection of team cohesion in meetings","van der Wel, Marissa (TU Delft Electrical Engineering, Mathematics and Computer Science)","Hung, H.S. (mentor); Timmermans, Benjamin (mentor); Oertel, Catharine (graduation committee); Lehmann-Willenbrock, Nale (graduation committee); Tan, S. (graduation committee); Delft University of Technology (degree granting institution)","2019","In this thesis the automatic multimodal detection of social and task cohesion in meetings is studied. The presence of social and task cohesion has positive benefits on employee well-being, creativity and productiveness, and can therefore be used to assess meeting quality. Conversational partners imitate each other's body language and speech characteristics to have smoother interactions, to increase liking, and it can cause a coordination of expectations. We hypothesize that social and task cohesion are therefore positively related to the imitation of both body language and speech characteristics. As the group-level alignment of non-verbal speech behaviour has been previously linked to social and task cohesion in meetings, this thesis investigates the relationship between cohesion in meetings and both motion and posture mimicry from accelerometer and video data. Motion mimicry is described using accelerometer features previously used for the detection of friendly and romantic attraction in pairs. We propose a method to convert these features to group-level descriptors of mimicry. The same quantifications of mimicry are also applied to video-based motion quantifiers that have been previously used to detect team cohesion. Appearance is described using HOG descriptors from densely-sampled feature points that are tracked over time. To our knowledge this is the first-time appearance similarity is used to estimate cohesion. We also test if a multimodal mimicry model performs better than a unimodal mimicry model to investigate if the different forms of mimicry contain complementary information. Our group-level movement mimicry features detect social cohesion with average an area under the ROC-curve of 0.64 for social cohesion, and the accelerometer-based movement mimicry features specifically detect task cohesion with an average AUC of 0.63. The multimodal combination of the different features does improve over the unimodal models with an area under the ROC-curve of 0.68 for social cohesion and 0.65 for task cohesion. This shows both that movement mimicry is an indicator of verbal expressions of cohesion, and that measuring mimicry in different modalities can better model cohesion than a unimodal model. Further experiments are recommended for general appearance feature mimicry, specifically in the method used to measure mimicry, to confirm or deny if these are related to cohesion.","Social signal processing; Cohesion; Mimicry; Multimodal; Accelerometer; Small group meetings","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:f0c41e9c-df95-4841-b088-1ffbdfb4ead1","http://resolver.tudelft.nl/uuid:f0c41e9c-df95-4841-b088-1ffbdfb4ead1","Development of a large scale rooftop PV potential assessment tool","Etxebarria Azanza, Josu (TU Delft Electrical Engineering, Mathematics and Computer Science)","Ziar, Hesan (mentor); Isabella, Olindo (mentor); Delft University of Technology (degree granting institution)","2019","Recently, climate action has become a priority in the agendas of every government, and the Netherlands was no exception. Almost 6 months ago, the so-called Klimaatakkord was released. This climate agreement sets ambitious goals to reduce greenhouse gas emissions, such as ensuring that 70% of the electricity comes from renewable sources by 2030 (only 13% does today). Considering that the Netherlands is the 2nd most densely populated country in the EU and that by 2050 95% of the population will live in urban areas it can be predicted that rooftop PV will play a major role, since it occupies no extra space and generates energy next to the consumption points. This project aims to develop a large scale rooftop PV potential assessment tool which can help urban planners, grid operators and homeowners stimulate the uptake of clean solar energy. In order to build such a tool, the first step was to extract the information of the rooftop surfaces. To do so, a model that uses openly available height point cloud data (AHN3) and cadastral data (BAG) was developed in-house. This model can extract the tilt, orientation, and area of every roof surface on a building. It can do it with an average estimation deviation of -0.02° for tilts and -0.66° for orientations. The area estimation percentage is 80.5% of the total area of the roof, mainly due to data quality issues, while the model takes an average of 5 seconds to extract the roof information of a building. The second step was to develop a PV yield calculation tool for estimating the potential of the extracted roof surfaces. As computational time is a constraint for large scale PV potential assessment, the Simplified skyline-based method was used. This method was improved by implementing two correction factors, optical airmass and angle of incidence, which can now be applied to surfaces with any tilt and orientation. Consequently, the PV yield calculation tool estimates the energy potential with an average estimation deviation of -6.64% and takes 2.7 seconds on average per building. In an effort to prove the application of the developed tool a PV potential assessment was done for the municipality of Delft. The results show that if every rooftop in the city would be covered with the state of the art PV module technology (SunPOWER MAXEON 3 | 400 W), 437.38 GWh could be generated, which represents 81% of the total electricity consumption in 2018. In the case of only suitable rooftops being covered, those with a yield of over 650 kWh/kW and payback time of less than 10 years, 384.81 GWh could be yielded, which could cover up to the 72% of the electricity demand in 2018. The research made in this project together with the positive findings hope to support in accelerating the transition towards a more sustainable world.","Solar energy; urban energy transition; rooftop PV","en","master thesis","","","","","","","","","","","","","",""
"uuid:2380b6d1-94c2-4e5b-8003-495058d25acd","http://resolver.tudelft.nl/uuid:2380b6d1-94c2-4e5b-8003-495058d25acd","Finding the climate optimal cruise altitude for a selection of aircraft types and mission combinations","Rosenkrantz, Rick (TU Delft Aerospace Engineering)","Grewe, Volker (mentor); Melkert, Joris (mentor); Delft University of Technology (degree granting institution)","2019","The climate impact of aviation is assessed as function of the emission altitude for two different aircraft types, the Boeing 787-800 and Boeing 777-300ER. The basis for this research is an assembly of 2,738 historical trajectories for which the fuel consumption and emissions were determined by using Piano-X aircraft performance data and atmospheric weather data from the European Centre for Medium-Range Weather Forecasts. The resulting emissions served as input for the climate response model AirClim which calculated the resulting climate response over time. To analyze the effect of changes in cruise altitude, the fuel consumption and corresponding emissions were recalculated for scenarios with relocated cruise altitude profiles ranging from an upward shift of 2000 ft to a downward shift of 18000 ft with respect to the original cruise altitude. By shifting cruise altitudes down, the total climate impact was found to be reduced for both aircraft types where the minimal climate impact is found for the lowest analyzed cruise altitude. The reduction in climate impact is mainly the result of the reduced short term forcings from contrail cirrus, ozone and the induced destruction of methane where their individual contribution to the total climate impact reduction was found to be dependent on aircraft type. Relocating cruise altitudes up was found to increase the climate impact for both aircraft types.","Climate; cruise altitude; Aircraft","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:ae33d094-d8cf-401c-a7be-6b593eeb9b70","http://resolver.tudelft.nl/uuid:ae33d094-d8cf-401c-a7be-6b593eeb9b70","3D NAND memory as radiation monitor","Lie, Sonny (TU Delft Aerospace Engineering)","Menicucci, Alessandra (mentor); Delft University of Technology (degree granting institution)","2019","This thesis explores the feasibility of using 3D NAND flash memory as space radiation monitor. Space radiation is composed by ionizing particles such as protons and ions, which can be harmful to electronics. Shielding and Error Correcting Code can be implemented to counteract these effects. Monitoring<br/>the space radiation environment is necessary to better understand the space radiation environment and design shielding and ECC according to the exposed dose of a spacecraft during its mission. Following the trend of miniaturization, using 3D NAND flash technology will drive down the cost of a radiation monitor. This allows for space radiation monitors which can be used on small satellites such as a picosatellites.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:f6d4dd49-a215-4220-8d6d-f5d53f375287","http://resolver.tudelft.nl/uuid:f6d4dd49-a215-4220-8d6d-f5d53f375287","An Aircraft and Schedule Integrated Approach to Improve Cockpit Crew Pairings","Korte, Johanna (TU Delft Electrical Engineering, Mathematics and Computer Science)","Yorke-Smith, Neil (mentor); Santos, Bruno F. (graduation committee); van Essen, Theresia (graduation committee); van Eeden, Karin (graduation committee); Delft University of Technology (degree granting institution)","2019","For airlines, crew costs make up the second largest expense, behind fuel costs. Because these costs are very high, there is a large potential gain in improving the crew efficiency within the bounds set by the law and collective labor agreements. This thesis investigates the dated crew pairing problem, and how the crew pairing problem can be integrated with aircraft routing and flight retiming in order to achieve more crew-efficient schedules for a low-cost airline operating a point-to-point network. Three different levels of problem integration, non-integrated, aircraft routing integrated, and aircraft routing integrated including retiming, are investigated on real point-to-point airline data, leading to five different models using either a generate-and-test or branch-and-price approach. It is shown that the currently presented models return pairings that reduce the number of duties up to 10% and increase the crew productivity up to 1.5%.","Aviation; Integer Linear Programming; Branch-and-Price; Crew Pairing","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:1c056849-d54e-46fc-857c-86dcb89f007f","http://resolver.tudelft.nl/uuid:1c056849-d54e-46fc-857c-86dcb89f007f","Estimation of River Width with Fully-Focused SAR Altimetry Data","Yuan, Yan (TU Delft Civil Engineering and Geosciences; TU Delft Geoscience and Remote Sensing)","Riva, Riccardo (mentor); Kleinherenbrink, Marcel (mentor); Naeije, Marc (graduation committee); Delft University of Technology (degree granting institution)","2019","River width is an important indication for water storage, with the development of remote sensing techniques, estimating river width in a large area becomes possible. In this report, fully-focused SAR altimetry data with an advantage of high spatial resolution is applied to compute river width for the first time. Methodology developed based on morphologic characters of rivers and data features is validated in two different areas, the Netherlands and Vietnam, with good statistical results.","Fully-focused SAR; Altimetry; River width","en","student report","","","","","","","","","","","","","",""
"uuid:d8d5dfcf-a5ac-4b54-bac5-9f78fb15f786","http://resolver.tudelft.nl/uuid:d8d5dfcf-a5ac-4b54-bac5-9f78fb15f786","Adjoint-based 3D Shape Optimization for Turbomachinery Applications","Garrido de la Serna, Pablo (TU Delft Aerospace Engineering)","Pini, Matteo (mentor); Anand, Nitish (graduation committee); Delft University of Technology (degree granting institution)","2019","In order to reduce the carbon foot-print of turbo-generators to global warming, a step-change in the design process is needed. Extensive CFD simulations coupled with optimization algorithms are required, resorting to novel techniques to capture the complex flow phenomena occurring in the passage. However, the computation of the optimization gradients and the imposition of geometrical constrains is computationally expensive and non-trivial due to the large number of design variables. In the 1980s, the adjoint method arose as an alternative technique to compute the sensitivities at a cost independent of the number of design variables. This technique is extremely popular in external aerodynamic applications. However, its full potential is yet to be exploited to internal flows. The use of an adjoint solver, together with a surface parametrization technique based on traditional blade design parameters, presents a unique opportunity towards a fully-automated design methodology based on high-fidelity models for turbomachinery applications. Stemming from the above considerations, the aim of this thesis is to develop a common open-source numerical framework for the optimization of both axial and radial turbomachinery. In order to achieve so, the open-source CFD suite SU2, that includes an adjoint solver, is coupled with ParaBlade, an open-source blade parametrizer based on traditional turbomachinery design variables. The proposed methodology is successfully applied in an axial turbine stator, where a reduction of 7.59% in the entropy generation across the passage is achieved. The study performed in a mixed-flow turbine rotor highlights the need to parametrize the hub and shroud surfaces. However, its optimization revealed a reduction in the objective function value, showing the robustness of the proposed methodology in two types of turbomachinery.","Adjoint-based optimization; SU2; mesh deformation; Turbomachinery; Surface parametrization; Open-source; Shape design; Axial turbine; Radial turbine; CFD","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:d14904b2-e144-4ea6-9184-4f0d4c2ea7f7","http://resolver.tudelft.nl/uuid:d14904b2-e144-4ea6-9184-4f0d4c2ea7f7","Short Term Delay Prediction in Passenger Railways: Using Machine Learning; Applied in the Dutch Rail Network","Lehká, Eva (TU Delft Civil Engineering and Geosciences)","van Oort, Niels (mentor); Hoogendoorn, Serge (mentor); Duinkerken, Mark (mentor); Fioole, Pieter-Jan (mentor); Delft University of Technology (degree granting institution)","2019","We test the effect of a variety of feature sets representing passenger volumes, weather conditions and train interactions, when defined as features and used in a gradient boosting model to predict passenger train delays 20 minutes to the future from the last registration point. Effects of the features and their combinations on the prediction quality are analyzed and the best performing feature sets selected. The results showed that the passenger volumes features (in the form as defined in our work) do not have any prediction power and rather introduced noise in the predictions. The weather features resulted in reduced expected delay change with a slight positive effect on precision of the classification task while worsening the recall. The largest positive effect was observed when train interaction features were introduced despite their highly simplified form. Considering the low computational efforts necessary to retrieve the features, we conclude there is a potential for application of similarly defined train interactions features in other models.","","en","master thesis","","","","","","","","","","","","Transport, Infrastructure and Logistics","",""
"uuid:dcb98e1a-ea51-4fe5-8a24-14fd90153673","http://resolver.tudelft.nl/uuid:dcb98e1a-ea51-4fe5-8a24-14fd90153673","Digital holography integrated with flow cytometry for detection of urinary schistosomiasis","Nijman, Patrick (TU Delft Mechanical, Maritime and Materials Engineering)","Agbana, TEMITOPE (graduation committee); Vdovin, Gleb (mentor); Diehl, Jan-Carel (graduation committee); Delft University of Technology (degree granting institution)","2019","Schistosomiasis is an intravascular infection with major public health consequences in developing countries. It is one of the major Neglected Tropical Diseases with more than 240 million people infected and 800 million people at risk in 2015, mostly in sub-Saharan Africa. It is caused by trematode parasites of the genus Schistosoma, in this report the focus was on Schistosomiasis Haematobium since it is the most prevalent form of the disease. One of the limiting factors of the control program is the standard diagnostic procedure set by World Health Organization, which is based on counting the parasite's eggs in a person's urine. Examination by microscopy requires the use of expensive microscopes, is prone to human errors and inconsistency, is time consuming, and uses filters which are often not available. The research objective was identified from these shortcomings: ""Develop a low-cost, smart diagnostic method for Schistosomiasis Haematobium based on detecting eggs in urine by combining lensless imaging and flow cytometry, and developing Artificial Intelligence models for automated detection."" In-line planar wavefront digital holography was identified as the most suitable lensless imaging method. A sample will be analyzed by the following repetitive procedure: (1)mechanically press the piston of a syringe by a small volume, (2)wait for the flow to stop, (3)record a hologram, (4)detect eggs. The implemented egg detection procedure consisted of a series of image processing algorithms: (1)apply Foreground detection, (2)localize the moving objects with a Blob detector, (3)locally reconstruct the hologram at the found locations, (4)classify the reconstruction as egg or not egg. The imaging method provided accurate reconstructions of eggs and the object detection algorithm was able to locate moving objects with sufficient accuracy and computational time. On the other hand, the lab and field tests showed that the data set of the classifier did not contain enough images to train a generalized model and that the local reconstruction and classification takes increasingly more time during analysis. As of now the method is an order of magnitude slower than an expert microscopist. The diagnostic method is not yet able fulfill the research objective. However, there are some promising aspects such as the low-cost imaging method, fast object detection algorithm, and absence of sample preparation which makes further research worthwhile.","Diagnostics; Imaging; NTD; FLow cytometry; Digital holography; Computer vision; Schistosomiasis","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:3e4a2119-0507-48ca-8aea-7fdbc3d98a64","http://resolver.tudelft.nl/uuid:3e4a2119-0507-48ca-8aea-7fdbc3d98a64","Optimizing the Reduced Basis Construction for Reduced-Order Mechanical Models: Automatic and efficient load case selection using Bayesian machine learning","Tjensvoll, Knut (TU Delft Civil Engineering and Geosciences)","van der Meer, F.P. (mentor); Rocha, I.B.C.M. (mentor); Sluys, Lambertus J. (mentor); Bessa, M.A. (mentor); Delft University of Technology (degree granting institution)","2019","Numerical simulations have become an essential part of design in every field of engineering, and the boundaries of technology are pushed further out every year. In structural engineering, the desire to design structures that have complex shapes or that are simply cheaper and more efficient, has necessitated the use of complex numerical simulations. This necessity is further substantiated when taking into consideration structures such as wind turbines that are subjected to extreme environmental conditions. In many cases, however, such simulations are prohibitively expensive due to complex material behaviour or the many-query nature of design optimization. The lack of knowledge and understanding of the behaviour and failure mechanisms is compensated by adopting less complex designs and/or high safety factors, which leads to less efficient and more expensive designs. In recent years, methods to circumvent such high computational costs have been developed. Acceleration techniques such as model-order reduction (MOR) are now widely researched, and significant developments are being made to overcome the issues of prohibitively expensive high-fidelity models. This thesis uses Proper Orthogonal Decomposition (POD) to drastically reduce the degrees of freedom of a simply supported beam that is loaded in the downwards direction along the span. The result of the MOR process is a reduced-order model (ROM) that accurately approximates the behaviour of the full-order model (FOM). The ROM is constructed by determining a set of basis vectors that contain compressed information of representative full-order solutions collected in an \textit{offline} training phase. The goal in this thesis is so collect the information and construct the reduced basis as efficiently as possible while guaranteeing a given accuracy of the ROM. Two methods are presented to iteratively construct the reduced basis. The first one is the \textit{Surrogate Parameter Space} (SPS) method, where greedy sampling is performed on incrementally finer grids of points along the beam. Each individual grid is referred to as an SPS, and they are exhausted by selecting the load location that in each iteration will add the most new information to the ROM. The other method is the \textit{Gaussian Process Regression} (GPR). Greedy sampling using a Bayesian machine learning algorithm involving GPR is used to predict load locations along the beam that add the most new information to the ROM. A method to efficiently combine and compress information obtained in each iteration was also developed. The results showed that the SPS method is efficient to construct an accurate ROM for the beam model in this thesis, but the GPR managed to recognize that some areas in the span did not have to be sampled as much as others. This makes GPR the more promising method for other high-fidelity models when high accuracy is desired. The results also showed that both methods depend greatly on input parameters that define how much information is kept in each iteration, and for GPR an additional parameter that determines how much accurate the regression itself should be. In order to execute an efficient offline phase, these parameters must be chosen carefully, and it is recommended for future work to develop methods to adaptively choose them. It was also shown that the number of ROMs that have to be run as part of the greedy sampling is the bottleneck of efficiency for both methods. For high-fidelity models with higher-dimensional parameter spaces, this bottleneck necessitates the use of hyper-reduction techniques such as the Empirical Cubature Method (ECM) to reduce the computation time of the ROM itself. It is recommended that the methods investigated and the corresponding results in this thesis are used as a stepping stone to implement automatic and efficient sampling methods to other high-fidelity models.","Model Order Reduction; Reduced Order Model; Reduced Basis; Machine Learning","en","master thesis","","","","","","","","","","","","Civil Engineering | Structural Engineering","Computational Mechanics",""
"uuid:13b2d5c9-f99d-4f2f-8f9f-079fe0c2b091","http://resolver.tudelft.nl/uuid:13b2d5c9-f99d-4f2f-8f9f-079fe0c2b091","Automated multi-criterial treatment planning for adaptive high-dose-rate brachytherapy for locally advanced cervical cancer","Oud, Michelle (TU Delft Mechanical, Maritime and Materials Engineering)","Breedveld, Sebastiaan (mentor); Lathouwers, D. (graduation committee); Perko, Z. (graduation committee); Kolkman-Deurloo, Inger-Karine (graduation committee); Delft University of Technology (degree granting institution)","2019","Purpose - To develop and evaluate a fast and automated multi-criterial treatment planning strategy for High-Dose-Rate (HDR) brachytherapy (BT) for patients with locally advanced cervical cancer. This automated strategy avoids suboptimal and slow manual treatment planning and results in reproducible and conformal treatment plans with a clinically favorable trade-off between multiple treatment objectives. Methods and Materials - An automated treatment planning approach was developed using the Erasmus- iCycle framework. A wish-list containing hard constraints and prioritized objectives is required as input was configured according to the clinical protocol using 22 single-fraction training plans. Special at- tention was paid to establishing the clinically desired ‘pear-shaped’ dose distribution. To evaluate the dwell time optimization approach, 66 automatically generated single-fraction plans (PLANauto) were compared against the clinically delivered plans (PLANref ), both by blind-pairwise comparison carried out by an expert clinician and by the analysis of dosimetric plan parameters. Subsequently, for 17 complete fractioned BT treatments each consisting of 3 single-fraction BT plans, automatically generated plans (TREATMENTauto) were compared against the clinically delivered plans (TREATMENTref) to evaluate dosimetric plan parameters according to the clinical protocol. The possibility of extending the algorithm with a needle selection objective was also explored on 13 test cases and its performance was evaluated by studying the number of needles selected in the optimized plans and its effect on the remaining treatment objectives.Results - All PLANauto were considered clinically acceptable by the clinician. The clinician’s plan comparison pointed strongly at an overall preference for the automated plans: in 62/66 cases the clincian preferred PLANauto over PLANref , in three cases the overall quality was considered equal and for one case the clinical plan was preferred. For PLANauto, the mean HR-CTV D90% improved while also the rectum was spared compared to PLANref . The average optimization time was 19.5 seconds (range [4.4 – 106.4] s). The mean D90% for TREATMENTauto improved by + 3.0 Gy (in EQD2) (p&lt;0.005) over the whole radiotherapy treatment with differences ranging from -4.3 to +6.0 Gy, while the bladder and rectum were spared similarly (p=0.01, p=0.02 respectively). In 6/13 of the plans, the number of needles that were implanted could be reduced while still establishing sufficient plan quality. Conclusions - Fast automated multi-criterial treatment planning for locally advanced cervical cancer HDR-BT is feasible. High-quality treatment plans are automatically generated within a clinically acceptable time frame and treatment plans have a clinically preferable trade-off between all treat- ment objectives. The observed improvement in dosimetric parameters, mainly the improvement of the dose to the HR-CTV, is clinically relevant. The algorithm can be extended with an approach for the optimization of the implant geometry, which could allow interactive intra-operative treatment planning.","brachytherapy; Automated treatment planning; optimization; HDR; Treatment Planning; radiotherapy","en","master thesis","","","","","","","","2020-10-01","","","","Biomedical Engineering","",""
"uuid:28f96ac7-f5ae-43af-9ba0-14832af5c103","http://resolver.tudelft.nl/uuid:28f96ac7-f5ae-43af-9ba0-14832af5c103","The applicability of deep learning to detect the progress of laparoscopic surgery using video recordings","Meij, Senna (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Biomechanical Engineering; Spaarne Gasthuis, Haarlem, The Netherlands)","van den Dobbelsteen, J.J. (mentor); Vos, F.M. (graduation committee); Vijfvinkel, T.S. (graduation committee); Guédon, A.C.P. (graduation committee); Delft University of Technology (degree granting institution)","2019","The operating room is one of the most complex and expensive environments in the hospital. Research has been focusing on improving the efficient use of the OR time, for instance by using intraoperative data to update the planning of the OR during the day. This thesis used a deep learning network to automatically recognize surgical tools and pre-defined surgical phases present in the recordings, to ultimately track the progress of the procedure. The aim of this thesis is to assess the performance and applicability of this deep learning method for the use of image recognition in a medical environment. To ultimately predict the remaining surgery duration and improve the efficiency of the OR planning. Two datasets of laparoscopic recordings were used, one containing laparoscopic cholecystectomies and one containing total laparoscopic hysterectomies. The surgical tools and the pre-defined phases of the procedure were annotated in every recording, after which the deep learning network was trained with this data. The performance of the network was tested in multiple experiments. The results showed that the performance of the deep learning network was promising and in line with published literature, but that the results varied between recordings. An experiment using three different sized datasets showed that a larger dataset corresponded with the best results and results that varied the least between recordings. Testing the generalizability of the network showed that a network trained on one type of surgery can also be used to recognize similar tools in a different type of surgery. Important is that the tools have the same design. It was found that the most important resources for a project like this are a dedicated hardware with image recognition software and time. This thesis showed the applicability of a deep learning network to automatically recognize the progress of a surgery and provided insight into the steps that need to be taken to use it on a larger scale.","Deep learning; Image recognition; surgery progress","en","master thesis","","","","","","","","2020-12-12","","","","Biomedical Engineering","",""
"uuid:a68cd69a-25bb-4c47-acb1-e2512e754510","http://resolver.tudelft.nl/uuid:a68cd69a-25bb-4c47-acb1-e2512e754510","Improving the Design of Persuasive Games for Complex Systems: Effectiveness of the Design Principles Praise,Suggestion, and Comparison as perceived byIndividualists and Collectivists","Macquart, Laurane (TU Delft Technology, Policy and Management)","Verbraeck, A. (mentor); Kortmann, L.J. (graduation committee); Annema, J.A. (graduation committee); Erdbrink, A.E. (graduation committee); Delft University of Technology (degree granting institution)","2019","Persuasive games for complex systems have subtle messages they want to convince stakeholders of the complex system of in question of in order to help them solve certain problems. However, there currently is little known about the persuasive game design principles used in those games to convey the persuasive message, especially how people with different cultural backgrounds perceive the persuasiveness of the persuasive design principles. This paper describes the research executed to determine how Individualists and Collectivists perceive the persuasiveness of 'Comparison between individuals' and 'Comparison between groups', this was done using a combination of a persuasive game for complex systems and storyboards. The results showed that Individualists are persuaded more by 'Comparison between groups' than by 'Comparison between individuals' which was not expected. Further research using another persuasive game for complex system should determine whether this was due to the game or is also valid for other persuasive game for complex systems.","Persuasive game design principles; Individualism Collectivism; Serious Games","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:7d1bba33-c2c6-428d-af35-2a2e3603f019","http://resolver.tudelft.nl/uuid:7d1bba33-c2c6-428d-af35-2a2e3603f019","Float, the next generation hydrofoil","Tas, Jesse (TU Delft Industrial Design Engineering)","Tempelman, Erik (mentor); Baha, Ehsan (graduation committee); Delft University of Technology (degree granting institution)","2019","This project focusses on the creation of a hydrofoil specifically for the windsurfing market. The assigment was created for PWsurfsport. PWsurfsport is a windsurfing company based in Leiden. The company has two subsidiary companies called Tribal and KA. Sails. Tribal produces windsurfing fins and KA produces windsurf sails. Tribal wanted to add a new product to its product portfolio. In this case, the key objective for this project was to create a windsurfing hydrofoil, fitting the current product portfolio of the company and the future windsurfing market.<br","Hydrofoil; Carbon Fiber; Windsurfing; Master thesis","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:1cd1eef6-ee7b-42b9-9326-b8856cdf031c","http://resolver.tudelft.nl/uuid:1cd1eef6-ee7b-42b9-9326-b8856cdf031c","Ferrofluid Rotary Seal with Replenishment System for Sealing Liquids","van der Wal, Karoen (TU Delft Mechanical, Maritime and Materials Engineering)","Lampaert, S.G.E. (graduation committee); van Ostayen, R.A.J. (mentor); Delft University of Technology (degree granting institution)","2019","Ferrofluid rotary seals are mechanical contact-free magnetic liquid seals that are characterised by their simple structure, low friction and ability to hermetically seal. Although ferrofluid rotary seals for sealing vacuum and gases are part of a well established industry, the sealing of liquids has not been implemented yet. Literature learns that degradation of the ferrofluid seal over time when it dynamically contacts a liquid results into premature seal failure. This thesis presents a new type of ferrofluid rotary seal in which a ferrofluid replenishment system is implemented that renews the ferrofluid in the sealing ring while sealing capacity is maintained. By replacing the degraded ferrofluid in the seal at a sufficient rate, service life of the ferrofluid rotary seal can theoretically be unlimited. An analytical model and FEM analysis are used to design the ferrofluid sealing device and to predict its sealing capacity. An experimental test setup has been built on which the sealing capacity and service life of the device has been tested for different sealing conditions. It is demonstrated that the ferrofluid replenishment system successfully extends and controls the service life of the ferrofluid rotary seal that dynamically seals pressurised water.","Ferrofluids; magnetic liquid seal; ferrofluid transport; magnetics; water; shaft seal","en","master thesis","","","","","","","","2021-12-12","","","","Mechanical Engineering | Mechatronic System Design (MSD)","",""
"uuid:e47f4f8f-765d-41a7-9cca-818191bce120","http://resolver.tudelft.nl/uuid:e47f4f8f-765d-41a7-9cca-818191bce120","The average wave overtopping discharge for a composite slope: A case study to the Afsluitdijk rehabilitation project","Jordans, Luuk (TU Delft Civil Engineering and Geosciences)","Hofland, B. (mentor); Antonini, A. (graduation committee); Kuiper, C. (graduation committee); Capel, Alex (graduation committee); Ockeloen, Wouter (graduation committee); Delft University of Technology (degree granting institution)","2019","“During the last safety assessment of Rijkswaterstaat in 2006 the Afsluitdijk failed on the current safety standards regarding flood protection. A new design was needed which ensured continuous protection against flooding in the future. Large scale and small scale tests are performed to optimize the design. Clear differences in the average wave overtopping discharge are observed between large and small scale. The new design of the Afsluitdijk has a complex geometry and consists of new types of elements of which not much information about the roughness of these elements is available. Also, the combined effect of roughness elements and berm has not been fully investigated yet. This asks for a more accurate method to predict the average wave overtopping discharge for composite slope. Various adjustments to current theories are proposed for this type of structure. “","Overtopping; Run-up; Afsluitdijk; Roughness influence; Capel; Van der Meer; Rib profile; Composite slopes","en","master thesis","","","","","","","","2021-12-12","","","","Civil Engineering | Hydraulic Engineering","",""
"uuid:bcb4db68-dc36-4c7b-8fd4-b5505b9ed1b1","http://resolver.tudelft.nl/uuid:bcb4db68-dc36-4c7b-8fd4-b5505b9ed1b1","A systematic study of macrophages’ response to submicron pillars","Isaakidou, Katerina (TU Delft Mechanical, Maritime and Materials Engineering)","Fratila-Apachitei, E.L. (graduation committee); Nouri Goushki, M. (mentor); Zadpoor, A.A. (graduation committee); Delft University of Technology (degree granting institution)","2019","Objective: Advances in the field of biomaterials have positively affected implant acceptance and nowadays nanostructured surfaces are known to have a positive effect on bone regeneration. The development of the field of osteoimmunology has contributed to a steadily increasing interest towards the investigation of the immunomodulatory effect of nanopatterned surfaces. Luckily, advances in nanofabrication methods have resulted in fabricating relatively large nanostructured areas with high resolution. This study is taking advantage of the 3D printing technique called two-photon polymerization (2PP) for the generation of 3D submicron pillar structures (patterns) to systematically investigate their effect on murine macrophages regarding cell migration, viability, cytoskeletal organisation and phenotype polarization. Methods: Six different pillar patterns were fabricated using a Photonic Professional GT (Nanoscribe, Germany) system. The pillars were characterized with scanning electron microscopy (SEM). Cell viability of J774A.1 macrophages on the nanofabricated patters was assessed by live/dead staining with calcein AM and ethidium homodimer-1 and fluorescently analyzed. Cell migration to the patterns was studied using DAPI staining. The cytoskeletal organization of the macrophages was investigated by actin staining and analyzed both through fluorescent microscopy as well as SEM. Macrophage expression of nitric oxide (NO) was tested with Griess assay. The phenotype polarization of the macrophages on the patterns was explored by dual immunofluorescent staining with iNOS/ARG-1 and CCR7/CD206.<br/>Results: It was demonstrated that different pillar heights and pillar pitches induce different cell attachment mechanisms (lamellipodia, filopodial extensions) and directly affect cytoskeletal reorganization of the macrophages after one day of seeding. Patterns with a height of 1000 nm and a pitch of 700 nm cause an increase in the number of elongated cells. Round cells are experiencing larger area growth when adherent on patterns with a pitch of 1000 nm. Elongated macrophages are strongly affected by patterns of 1000 nm height and 700 nm pitch. Moreover, patterns with a pillar height and pitch of 1000 nm are shown to be the more potent leading to a M1/M2 macrophage phenotype switch.","Biomaterials; Οsteoimmunology; Νanofabrication; Τopographies; Macrophages; Cytoskeleton; Phenotype; M1,M2","en","master thesis","","","","","","","","2021-12-12","","","","Biomedical Engineering","",""
"uuid:3155c096-b26a-4567-b6fb-db67732a2aae","http://resolver.tudelft.nl/uuid:3155c096-b26a-4567-b6fb-db67732a2aae","Degradation Analysis by Accelerated Ageing of Epoxy-based Mortar: Durability reserach on the Lantern of the Liverpool Metropolitan Cathedral","de Bie, Lisette (TU Delft Aerospace Engineering)","Poulis, J.A. (mentor); Tennent, Norman H. (graduation committee); Delft University of Technology (degree granting institution)","2019","The Liverpool Metropolitan Cathedral is the Roman Catholic Cathedral in Liverpool. It was constructed between 1962 and 1967, to the 1959 competition winning design of Sir Frederick Gibberd. The roof of the building is crowned by a tapering lantern formed from coloured glass adhered by means of an epoxy-based mortar. This construction method was experimental and at the forefront of the technology of the period. Soon after opening, the Cathedral began to exhibit flaws in detailing and construction. Leaks through the glazed lantern, between the epoxy and the glass, were observed. Therefore, the effects of outdoor exposure on the stability and strength of the used epoxy was assessed. Accelerated ageing tests allow the prediction of the effects of weathering and the state of degradation of the mortar used in the LMC in an expedited manner. Since a limited amount of original material from the cathedral is available for testing, a replica mortar was made. After a performed material analysis, the original epoxy/sand/carbon black mortar formulation was replicated. This replica mortar as well as the original mortar core samples were used to undertake accelerated ageing tests (e.g. by moisture, UV exposure and elevated temperature). This was followed by mechanical tests on the replicated specimens, to observe changes in structural integrity and adhesion. The link between the original and the replicated material was made with various chemical analysis, such as FTIR, DSC, DMA and XPS. The generated data showed evidence on that the likelihood of major structural loss is small, within the undertaken testing period. The loss of adhesion is attributed to high relative humidity. Changes in the chemical and physical properties of both materials is difficult to observe. The high filler content in the epoxy may hinder physical changes substantiality.","Conservation; Epoxy; Environmental degradation; Composite","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:1f7a2f92-9fac-42c6-a3bc-a91b0c70fea8","http://resolver.tudelft.nl/uuid:1f7a2f92-9fac-42c6-a3bc-a91b0c70fea8","The design of risk sharing to promote cooperation","Perrone, Antonio (TU Delft Civil Engineering and Geosciences)","Molaei, M. (mentor); Bakker, H.L.M. (graduation committee); Steenhuisen, B.M. (graduation committee); Wals, Jorian (mentor); Delft University of Technology (degree granting institution)","2019","Cooperation figured prominently in the Dutch construction industry’s agenda over the past years. In 2016, major clients, sector organizations and the relevant market parties officially committed to promote a culture based on good cooperation and healthy relationships by signing the ""Market Vision"" (De Marktvisie, 2016). This document illustrates the objectives, principles and necessary changes to achieve this ambition in 2020. However, according to the report of Rijkswaterstaat (2019), there have not been structural changes in cooperation within the supply chain where fighting relationships, self-interest and opportunistic behaviours still prevail. The unattractive risk-return profile, i.e. the ratio between the expected return and the amount of risk undertaken by contractors, of large projects in the civil engineering sector is considered to be a barrier that prevent this change. The current approach to risk management is one factor that contribute to decrease the risk-return ratio. According to the report of Rijkswaterstaat (2019), market parties have the impression that risks are not always allocated to the ""natural owner"". The natural owner is the party that has the knowledge, ability and financial capacity to manage a certain risk. Market parties have more or less consciously accepted risks under competitive pressure although Rijkswaterstaat argue that during the tendering process of large complex projects some risks are taken back based on the contractors’ argumentation. However, construction companies point out that the dialogue focus on limiting risks on the client’s side and they are not yet sufficiently stimulated to discuss their own risks. This research proposes risk sharing to fills the gaps of the current approach with the purpose of stimulating the development of cooperation. The scope of the research is limited to Dutch infrastructure projects procured by public authorities through Public-Private Partnership. The research objective is to provide partner organizations with a framework to share risk at the project level in order to foster commitment and cooperation for the long duration of the partnership. The first step to achieve the research objective is to investigate current risk sharing from a theoretical and practical perspective. This is achieved through literature review, exploratory interviews with employees of WitteveenBos and document review. The results of these activities are compared with the elements mentioned in the literature to stimulate cooperation. Afterward, a conceptual model is elaborated based on the<br/>results of literature review and exploratory interviews. The purpose of the proposed conceptual model is to illustrate contractual and relational elements that can be added to the current risk sharing in order to promote cooperation. Then, the proposed risk sharing mechanisms that constitute the conceptual model are discussed with practitioners. This activity aims to refine the proposed risk sharing mechanisms in order to obtain detailed measures that form the risk sharing framework. Finally, the proposed framework is validated with experts in order to assess whether it meets the economic and functional requirements of its intended users and fits within the restrictions imposed by the current practice. The risk sharing mechanisms applied in the construction sector mentioned in the literature refer to financial incentives such as government guarantees, target cost contracts, etc. However, the literature study suggests that the attitude and willingness of partners to engage in cooperative behaviours is stimulated more by trust and relational norms than formal enforceable rules. Therefore, it can be argued that risk sharing requires additional elements in order to promote cooperation. The proposed risk sharing framework requires certain personal attitudes of team members in order to be effective in promoting cooperation. According to practitioners, partners should: • seek the participation of all team(s)members, internal and external; • take the initiative to help rather than being passive; • show behaviours oriented toward the achievement of common goals and mutual benefits; • be open and receptive to new ideas, different perspectives, external influence; Furthermore, an essential attitude is to accept and embrace the idea that risk ownership does not exclude the chance of managing a risk together. The legal boundary of having one risk owner should not prevent partners from being forthcoming and providing support to control risks. Based on the results of the discussion with practitioners, the proposed risk sharing framework is effective in stimulating cooperation only if partners coordinate with each other and commit to implement these measures together.","Risk sharing; Cooperation; Risk Management; Public Private Partnerships; Relational contracting; Infrastructure construction projects","en","master thesis","","","","","","Rijkswaterstaat. Toekomstige opgave rijkswaterstaat: Perspectief op de uitdagingen en verbetermogelijkheden in de gww-sector. Technical report, Rijkswaterstaat, 2019. Rijkswaterstaat; Rijksvastgoedbedrijf; ProRail; Bouwend Nederland; NL Ingenieurs;Association of Water Builders;SME Infra; Uneto VNI;Astrin. (2016). Marktvisie.","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:aceb6e2b-2daf-4abe-b28a-e5917b55ec46","http://resolver.tudelft.nl/uuid:aceb6e2b-2daf-4abe-b28a-e5917b55ec46","Hedging interest rate risk for pension schemes: Optimization and effectiveness: The case of the Netherlands","Kroon, Aizo (TU Delft Electrical Engineering, Mathematics and Computer Science)","Oosterlee, Kees (graduation committee); Grzelak, Lech (mentor); Pochet, Alexandre (graduation committee); van Boxtel, Job (graduation committee); Delft University of Technology (degree granting institution)","2019","Efficiently managing hedging portfolios on behalf of pension funds is key in achieving the target hedging strategy, which can significantly impact coverage ratios. A new optimization approach to fixed income portfolio management for pension funds is proposed that finds interest rate risk hedging strategies while incorporating additional requirements. These are relevant requirements for pension funds such as country allocations, low transaction costs and reasonable investment costs. In doing so, pension fund regulations and common practices are investigated in a rigorous mathematical framework. The hedging strategies are shown to perform well when back-testing. In addition, simulation of the interest rate and cash flows in a Defined Benefits pension scheme displays the good performance of the strategies. These strategies are further tailored to specific pension funds by considering the trade-off between yield and risk, which could contribute to increasing a pension fund’s coverage ratio. Alternatively, a procedure is also proposed to generate more diversified albeit less optimal hedging portfolios using the optimization approach.","Pension fund; Pension scheme; Defined Benefits; Optimization; Interest rate risk; Hedging; Key rate duration; Simplex","en","master thesis","","","","","","","","","","","","Applied Mathematics | Financial Engineering","",""
"uuid:c7e407a6-0a2a-4828-b5d5-8d3fab78ea96","http://resolver.tudelft.nl/uuid:c7e407a6-0a2a-4828-b5d5-8d3fab78ea96","Safe Reinforcement Learning Applications","Monteiro Nunes, Tiago (TU Delft Aerospace Engineering)","van Kampen, Erik-jan (mentor); Delft University of Technology (degree granting institution)","2019","Reinforcement Learning (RL) focuses on maximizing the returns (discounted rewards) throughout the episodes, one of the main challenges when using it is that it is inadequate for safety-critical tasks due to the possibility of transitioning into critical states while exploring. Safe Reinforcement Learning (SafeRL) is a subset of RL that focuses on achieving safe exploration during the learning process and, thus, allowing it to be used in safety critical tasks. This research focuses on expanding already existing SafeRL algorithms through a combination of two previously developed safety metrics into a novel one. Furthermore, this research also uses an ellipsoid-based bounding model to replace the interval analysis bounding model. To validate this combination of the metrics, two different examples are used to test the performance of the various algorithms and compare their relative survivability and computational efficiency: a quadrotor navigation task and an elevator control task. Results show that the novel combined metric (ProxOp) outperforms one of the metrics in the quadrotor navigation task and the other one in the elevator control task. Overall, the combined metric is a better option for usage when there is no \textit{a priori} knowledge on how any of the metrics will behave. The ellipsoidal bounding model is tested using the elevator control task and is shown to have comparable performance when used in combination with the proximity and the ProxOp metrics but shows a significant degradation of performance when used solely with the operative metric. The ellipsoidal bounding model is also preferable for use in tasks where there is no knowledge on what are the bounds of the system model, as the ellipsoidal bounding model estimates the model error initially through the use of Gaussian processes. This research, thus, presents a viable novel safety metric as well as an alternative bounding model that can be used with it for applications of RL where safety is important.","Reinforcement Learning; Flight Control Systems; Safety; Machine Learning; Safe Exploration; Gaussian Process; Ellipsoid","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:596faa12-de1d-4de5-96ba-1c583675b3a0","http://resolver.tudelft.nl/uuid:596faa12-de1d-4de5-96ba-1c583675b3a0","Vessel's Performance Modelling: Developing a digital twin for the propulsion system, a Spliethoff group case","Mavroudis, Stamatis (TU Delft Mechanical, Maritime and Materials Engineering)","Frouws, Koos (mentor); van Hassel, Edwin (mentor); van den Berg, Max (mentor); Hopman, Hans (graduation committee); de Koning Gans, Henk (graduation committee); Delft University of Technology (degree granting institution)","2019","In this thesis, it was examined how high-frequency operational data collected from an automated recording system, can be used to develop a vessel’s performance model. Both the traditional and the Machine Learning (ML) approach were examined. In the traditional approach, every component of the propulsion plant was examined separately, while empirical or semi-empirical methods were used for the added resistance due to waves, wind and shallow water. Historical data were used for verification and tuning (where needed) during the development of the model. In the Machine Learning approach, the method of Support Vector Machines was used. Also, it was examined whether a vessel’s performance model can be developed by combining the methods mentioned above. Thus, in total four models were developed. The data regarding the last year of operation of the vessel Schippersgracht were used (45000 data points) to test the models. It was found that with all the four models, 80 % of the examined dataset was calculated with an error of less than 10 %. The daily fuel consumption was calculated for the same dataset and for 90% of the days examined, the daily fuel consumption was calculated with an error of less than 10 %. The main conclusions about the developed performance models is that all the models resulted in more less the same accuracy. The model based on the traditional approach has the advantage that it offers more information and more outputs can be taken, compared to the ML approach which only provides the output of the fuel consumption. On the other hand, the model based on the ML approach is significantly faster and allows many iterations to be performed in a short time. Regarding the models which were developed by combining the approaches mentioned above, they did not result in additional advantages. Finally, two case studies were performed. In the first case study, it was presented how the model, developed following the traditional approach, can be used to examine how modifications in the propulsion system will influence the vessel’s fuel consumption. The case of switching from fixed rpm (that is currently used) to a variable rpm system was examined, which is a real scenario that the company is considering. It was calculated that installing the variable rpm system and a frequency converter will result in annual savings of around 250,000 € while the investment’s payback time is estimated to be around two years. In the second case study, a future voyage simulation algorithm was developed. This algorithm receives as inputs the voyage plan(route and speed) and performs a calculation for the voyage’s fuel consumption by taking into account the weather predictions. The voyage simulation algorithm is making use of the ML model. A few cases were examined in order to examine how many days in advance the calculation is reliable (due to the uncertainty of the weather predictions) and about the time interval that should be used in the algorithm. However, clear conclusions were not derived, and further examination is suggested(by examining more voyages).","Vessel's performance model; Fuel consumption; operational data","en","master thesis","","","","","","","","2024-12-31","","","","Marine Technology","",""
"uuid:75210d94-22f5-4f99-9327-c65044543b3e","http://resolver.tudelft.nl/uuid:75210d94-22f5-4f99-9327-c65044543b3e","Design of a Miniature Cone Penetrometer: Design and Calibration of a Miniature Cone Penetration Test Device for the Geo-Technical Centrifuge of Delft University of Technology","Honardar, Siavash (TU Delft Civil Engineering and Geosciences)","Askarinejad, Amin (mentor); de Lange, Dirk (mentor); Delft University of Technology (degree granting institution)","2019","The aim of this project is to elaborate upon the design proposal of a miniature cone penetration test device. The usage of CPTs in the geotechnical centrifuges has proven to be a reliable experimental method. The usage of a CPT in a centrifuge can provide determinant results for many applications of geotechnical experimentation. The usage of cone penetration tests in centrifuge modelling is a significant experimental method in geotechnical engineering. The measurement of cone resistance and pore-pressure during in-flight tests can provide valuable data to correlate with soil properties and material behaviour. Through the years, this method has proven to be reliable and repeatable and has helped in verifying correlations of laboratory measurements and field data. The inexpensive and time-efficient nature of centrifuge testing and the reliability of cone penetration testing complement each other. This method has many relevant applications and acts as an effective tool. A literature study is conducted to obtain practical information on the design process of minia- ture CPTs. The existing designs are studied and their specifics are compared to the boundary conditions of the centrifuge of Delft University of Technology. This apparatus is capable of con- ducting tests at 300 times the gravitational acceleration and can carry samples with widths up to 400 millimeters. Two sets of existing sample containers are considered in this project which define physical dimensional boundaries. These sample containers consist of rectangular and cylindrical boxes with defined dimensions. The existing boundaries are further analyzed with respect to boundary effects derived from previously conducted tests to define design specifications for a potential miniature probe. The definition of such boundaries set the basis of the design proposal. For the rectangular containers a miniature probe with a maximum diameter of 4 millimeters can be used. As for the cylindrical sample containers, miniature probes with maximum diameters of 7.5 and 9.5 millimeters are appropriate to be designed. The analyzed existing designs are then scaled and altered with respect to the determined boundary values and the proposal is further evaluated.<br/>Three miniature CPTs are designed with diameters of 4, 7.5 and 9.5 millimeters. Each design has certain applications and can be used in specific scenarios. All three designs include modular load cells and sub-parts that can be replaced and altered. Each proposed device consists of a modular load cell designed based on required material properties to experience a minimum amount of 500 micro-strain without buckling. The first design, with a cone diameter of 4 millimeters, can be used in any container with a minimum width of 12 centimeters and for soil samples with a maximum average grain size of 200 micrometers. The second design, with a cone diameter of 7.5 millimeters, can be used in containers with a minimum width of 22.5 centimeters and is applicable to soil samples with a maximum average grain size of 270 micrometers. The final design, with a diameter of 9.5 millimeters, is meant to be used in sample containers of widths above 28.5 centimeters and for soil samples with a maximum average grain size of 340 micrometers. The designs are then evaluated with regards to manufacturing costs and feasibility. An estimation is made based on previously designed and patented devices and material catalogues provided by manufacturers. The cost of the first two designs are estimated to amount to 1580 to 2080 Euros, whereas the third design is estimated to cost 3080 to 3580 euros due to temperature compensated pore-pressure sensor that is included in the design. Upon further evaluation, the first design with a diameter of 4 millimeters is chosen as the most feasible and practical concept due to applicability and practicality of the design.","Cone Penetration Test; CPT; Centrifuge modelling; Design Proposal","en","student report","","","","","","","","","","","","Applied Earth Sciences","",""
"uuid:cafaa08b-ba25-48f3-bb44-50d009520a2f","http://resolver.tudelft.nl/uuid:cafaa08b-ba25-48f3-bb44-50d009520a2f","Collision risks for end-of-life satellite de-orbit trajectories","Huisman, Wouter (TU Delft Aerospace Engineering)","Noomen, Ron (mentor); Stam, Daphne (mentor); Snellen, Mirjam (mentor); Delft University of Technology (degree granting institution)","2019","Satellites that have reached their end-of-life pose a threat to the space environment. An object in orbit that no longer adds value to its user is called space debris. Collisions between objects in Low Earth Orbit (LEO) can have disastrous consequences and have the potential to create thousands of new debris objects, which in their turn can cause collisions. In order to limit the number of potential collisions it is vital to remove space debris from orbit. Removing space debris from orbit can be done via a so-called de-orbit maneuver. Satellites often have an integrated on-board propulsion system, used for stationkeeping. At the end-of-life, these systems can be used to apply a thrust force and guide the satellite into a de-orbit maneuver. This thesis investigates the effect of a controlled low-thrust de-orbit maneuver on the propellant usage, duration and collision risk of the trajectory. This maneuver is conducted for three different objects in LEO: Zenit-2, Tsyklon-3, and Kosmos-3m. These three objects represent a wide range of different debris scenarios that form a potential danger to the space environment. Two different epochs of the debris environment are investigated: October 23, 2013, and November 7, 2014. Each trajectory is shaped by a thrust magnitude and thrust control algorithm that turns the engine of the object either on or off at different time points. The values for the thrust magnitude and thrust activation times are determined by an optimization algorithm that tries to find trajectories with optimal (minimal) values for the propellant usage, trajectory duration and collision risk. The collision risk associated with a de-orbit trajectory is determined by representing the position error of each object as an error covariance matrix. By mapping the error covariance matrix of each object pair during a close conjunction onto a common plane of reference (the B-plane), the collision probability can be described in terms of a probability density function. Integrating this function over the occupied area of the two objects in the B-plane results in a collision probability associated with that close conjunction. The total collision probability associated with a de-orbit trajectory is then the result of the accumulation of the collision probabilities of all close conjunctions. The result of this analysis is a set of different de-orbit trajectories with varying values for the propellant usage, duration and collision probability. Trajectories with a high collision risk have collision probabilities ranging from $10^{-1}$ to $10^{-3}$. The low-risk trajectories have collision probabilities ranging from $10^{-6}$ to $10^{-16}$. A general trend is observed where trajectories with a short duration have relatively low collision probabilities. However, by observing the accumulation of the collision probability over time, it can be seen that the value of the total accumulated collision probability is largely determined by a low number of high-risk conjunctions. A sensitivity analysis is performed to assess the robustness of the obtained trajectories. It is found that a small variation in an initial state vector element results in a difference in the associated collision probability ranging from $10^{-3}$ to $10^{-6}$ for some cases, and $10^{-2}$ to $10^{-48}$ for other cases. This shows that the obtained result are not robust and are highly sensitive to variations in either the initial state vector or the state derivative (i.e. changes in the environment model). Additionally a high thrust is applied in order to further assess the statistical effects of multiple conjunctions on the accumulated collision probability. Again, the associated collision probability was determined by a low number of risk-risk conjunction events. These results lead to the conclusion that no robust method was found for a de-orbit trajectory that limits the collision probability. The accumulated collision probability is not smoothly determined by the number of encountered conjunctions but rather a limited number of high-risk conjunction events. Additionally, the collision probability is highly sensitive to small position offsets of either of two objects in a conjunction. Therefore, a prediction of a de-orbit trajectory that limits the collision probability is unreliable.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:cb9d7348-5596-4048-a08d-af18353a16f6","http://resolver.tudelft.nl/uuid:cb9d7348-5596-4048-a08d-af18353a16f6","Characterization and Chemical Performance Assessment of Cementitious Materials: In Relation to the Dutch Case of Geologic Disposal of Nuclear Waste","Yiğittop, Yasin (TU Delft Mechanical, Maritime and Materials Engineering)","Offerman, S.E. (mentor); Bykov, D. (mentor); Smith, A.L. (graduation committee); van Eijck, L. (graduation committee); Delft University of Technology (degree granting institution)","2019","In this study, non-destructive methods are applied to quantify the influence of concrete degradation by geologic conditions on the ability to retain nuclear waste deep underground in The Netherlands. Nuclear reactors play an important role in all four scenarios of the recent report of the IPCC to reach the CO2 reduction goals. Safety related criticism against nuclear energy technology are less relevant for Generation IV nuclear power plants, of which several are scheduled to be constructed in Europe within the next few years. This is partially due to the inherent safety features of Gen IV power plant designs, where disasters experienced before (e.g., Chernobyl, Fukushima) are technically impossible. Concrete samples provided by COVRA are degraded by immersion in a solution that contains chlorides and sulphates in concentration levels that are similar to geologic conditions. The influence of concrete degradation on the internal structure of concrete has been investigated using X-ray and Neutron radiography. Pore size distributions, pore geometry and sorptivity are presented. In order to validate the results, standardized tests are performed and the results are compared.","Cementitious; Nuclear Ethics; Tomography; Neutron Tomography; X-ray Imaging; Imaging; Sorptivity; Pore size distribution; Porosity","en","master thesis","","","","","","","","","","","","Materials Science and Engineering","CEBAMA Project","51.991028, 4.381670"
"uuid:be6a41d2-6071-47b9-926d-f22c23edadba","http://resolver.tudelft.nl/uuid:be6a41d2-6071-47b9-926d-f22c23edadba","Modelling the transport and fate of buoyant macroplastics in coastal waters","van Utenhove, Erik (TU Delft Civil Engineering and Geosciences)","Reniers, A.J.H.M. (mentor); Uijttewaal, W.S.J. (mentor); de Schipper, M.A. (mentor); Kleissen, Frank (mentor); Minns, Tony (mentor); Delft University of Technology (degree granting institution)","2019","As a result of the unabated growth in plastic usage worldwide, their abundance in the marine environment has steadily increased over the last few decades. Nowadays, plastic litter is observed across all oceans and shores. Due to their wide spread and adverse effects on ecology, economy and potentially human health, plastic pollution has been recognized as a worldwide environmental and ecological threat. For these reasons, it is important to reduce and mitigate the abundance of plastic litter in the marine environment. As marine plastic litter predominately originates from near the coast, it is critical to study the plastic behaviour in coastal waters. However, there is considerable uncertainty regarding what factors are influencing the trajectories, distribution and deposition sites of plastic litter. Along with complex physical processes and scarcity of empirical data, there is currently little knowledge and understanding on the transport and fate of plastics in coastal waters.<br/><br/>With the aim of obtaining more insight into plastic behaviour, the present study intends to examine the most important processes and quantify the effects of parameter uncertainty on modelling the transport and fate of buoyant macroplastic in coastal waters. The transport and fate of plastics is modelled by combining hydrodynamics with particle tracking concepts. For the simulations the Delft3D software Suite was used, where a Delft3D-FLOW model of the southern North Sea (ZUNO-DD) was coupled to Delft3d-PART. The model calculates how the position of plastic particles evolves in time from their release until the end of the simulation. In this study, model simulations are used as a numerical tool for exploring the relative influence of current uncertainties inherent in process parameters and data inputs on model results. A set of scenarios were defined by changing parameter values on at a time. By studying the changes in particle trajectories and shoreline deposition areas, a better understanding of their relative importance was obtained.<br/><br/>The modelling results imply that the effect of windage and release location are the most important parameters. Further, it is observed that dominating driving mechanisms may change with varying forcing conditions and object characteristics. Other factors such as small-scale processes and moment of release may impact particle trajectories and fate. However, the relative influence of these processes is less significant and therefore considered less critical. Adopting the findings of this thesis into decision making policy can support emergency response operations and monitoring strategies.<br/><br/>The research on plastic behaviour in the coastal environment is still in its early stage, and much has yet to be revealed. Therefore, further improve understanding of buoyant macroplastic behaviour is required. Validation of the results presented in this study is limited due to the scarcity of empirical data. Thus, further research should be directed towards collecting more field data. Further, it is recommended that effort is put into parametrizing accurately the effect of windage. Furthermore, expanding numerical simulations should be<br/>expanded to a range of conditions and coastal environments so that trends can be compared and highlighted, but also allows for exploring new hypotheses.<br","plastic litter; buoyant macroplastic; modelling; Delft3D; sensitivity; North Sea; coastal waters","en","master thesis","","","","","","","","","","","","Civil Engineering | Hydraulic Engineering","",""
"uuid:acbf2447-4dc4-4ed3-81b1-e0752061d39a","http://resolver.tudelft.nl/uuid:acbf2447-4dc4-4ed3-81b1-e0752061d39a","A process framework for the transition to circular urban area development of M4H","van Slobbe, Nesaneth (TU Delft Civil Engineering and Geosciences)","Leclercq, E.M. (mentor); Bakker, H.L.M. (graduation committee); Quist, J.N. (graduation committee); Vries, Isabelle (graduation committee); Delft University of Technology (degree granting institution)","2019","In this research, a practical process framework is developed to facilitate the transition to circular urban area development (CUAD) of the MerweVierhavens (M4H). One of the five objectives of the Rotterdam Makers Districts is to become the pilot for the circular economy in the built environment of Rotterdam. M4H is an old harbour area that belongs to the Rotterdam Makers District. In previous research done by Team 1010, the potential circular flows for M4H have been analysed. The result was an overview of what is necessary for the transition to the circular economy of the built environment. However, no further steps have been taken so far. The transition to CUAD is rather complex, and the current urban area development process does not fit most circular strategies. This research, therefore, examines the process strategy needed to facilitate the transition to CUAD. Moreover, previous research has shown that the transition to CUAD requires a practical tool or framework. That is why, in this research, a practical process framework that facilitates the transition to CUAD, called the CUAD framework, is developed. The CUAD framework is based on the conditions for the transition to CUAD distinguished through the literature study and two case studies. The CUAD framework is tested through a pilot study conducted with stakeholders involved in the development of M4H. The CUAD framework can be applied to facilitate the complex and dynamic environment by developing areas with a CUAD vision, through short cycles and by incorporating multidisciplinary perspectives. The pilot study has indicated that the CUAD framework can indeed facilitate aspects of complex CUAD projects. However, the framework should be further developed. Nevertheless, this research has shown that CUAD is an ongoing learning process.<br","Circular built environment; Scrum; Urban Area Development; Rotterdam","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:d4786d82-9836-4eb4-a8cc-775f9e5bd83f","http://resolver.tudelft.nl/uuid:d4786d82-9836-4eb4-a8cc-775f9e5bd83f","Investigating brain function and anatomy through ICA-based functional ultrasound imaging","Ntekouli, Mado (TU Delft Mechanical, Maritime and Materials Engineering)","Hunyadi, B. (mentor); Strydis, Christos (graduation committee); Kruizinga, Pieter (graduation committee); Delft University of Technology (degree granting institution)","2019","Understanding the hidden organizational principles existing in the human brain was always one of the great challenges in Neuroscience. To uncover the way the brain functions, advancements in the fields of Medical Imaging and Computational Science have been of great importance. Powerful imaging tools, such as functional magnetic resonance imaging (fMRI) and positron emission tomography (PET), have already enabled scanning the whole brain volume and visualizing the brain functioning, both at rest and during task execution, to a significant degree. However, several limitations especially in spatiotemporal resolution led to the need for further advancements in the field of functional imaging. An alternative technique, that overcomes most of the previously existing problems, is functional ultrasound (fUS). fUS is capable of imaging even the microvasculature blood-flow dynamics in response to brain activation with high spatiotemporal resolution. The wealth of fUS-acquired data calls for advanced data-analytic methods to uncover new information, beyond the well-applied simple univariant correlation method. This is the main goal of this MSc thesis, to use a proper analysis technique, mainly borrowed from the same-principle fMRI technique, in order to produce powerful inferences. For this reason, a detailed literature review regarding fUS imaging and fMRI analysis methods is introduced. Then, the main analysis part is focused on the Independent Component Analysis (ICA) method, trying to segregate the brain into spatially independent components that share a similar activity response. Here, the whole processing pipeline is established, describing all the necessary preprocessing steps along with ICA parameters and approaches (single- and group-ICA) using the ICASSO software package. As a post-processing step, functional images-to-Allen brain atlas registration is also performed in order to identify the different regions represented in the ICA-derived spatial components. The effectiveness of the methods is assessed based on the collected results on different datasets, obtained from 2D visual-stimulation as well as 3D resting-state experiments conducted on mice at the Neuroscience department of the Erasmus MC. As a conclusion, ICA was able to separate different anatomical and functional sub-networks. More specifically, from the visual-stimulation experiments, brain regions such as Lateral geniculate nucleus (LGN) that play a role in the visual pathway are identified, while from the resting-state the spatial continuity of different regions is confirmed.","functional ultrasound; Independent component analysis (ICA); brain function; brain atlas","en","master thesis","","","","","","","","2020-12-31","","","","Biomedical Engineering","",""
"uuid:ec82cf17-884d-4b17-8f6a-d7941be81acc","http://resolver.tudelft.nl/uuid:ec82cf17-884d-4b17-8f6a-d7941be81acc","Designing a Robust Supply Chain for Military operations: A Multi-Agent Simulation approach considering Platooning","Reinders, Brian (TU Delft Mechanical, Maritime and Materials Engineering)","Schulte, Frederik (mentor); Negenborn, Rudy (graduation committee); van Gelder, Pieter (graduation committee); Delft University of Technology (degree granting institution)","2019","Supply chains are to be found in almost every corporation around the world. When tryingto manage a supply chain often two types of disturbance can jeopardize the effectiveness of a supply chain. These are supply and demand uncertainty. This thesis tries to investigate the effects of those two types of disturbances in a supply chain and seeks to find a remedy. When taking a closer look at supply chains, robust supply chains are considered to withstand a higher level of supply and demand uncertainty. Robustness knows many definitions but is mostly characterized by the responsiveness and adaptability of a supply chain. Responsiveness implies a degree of quick reaction to sudden changes, while adaptability is defined as the capacity to deal with new circumstances. This thesis tries to relate robustness according to a level of resistance of supply and demand uncertainties. The supply chain of the royal dutch land forces is prone to such sudden changes. Therefore this research incorporates the context of a military supply chain to perform experiments on. The military supply chain in operational areas is selected and identified as a 3-echelon-multiple tier-supply chain, where the implementation of a networked supply chain can result in an increase in robustness. The research uses three key performance indicators to ”measure” a degree of robustness. With the use of a multi-agent discrete-event model that incorporates a highly dynamic environment including real-time transportation and order handling simulations. The model also contains an <br/> nteger supply optimization module using CPLEX and a distance-based swarming<br/>algorithm to emulate the lifelike situation of the supply chain concerning order handling and ”Notice to move”. Three experimental setus have been created that try to quantify robustness levels according to networked supply chain operations while coping with demand and supply uncertainty. First, a sensitivity analysis is performed, revealing the basic relationships between the indicator and <br/> emand/supply fluctuation. Second, an extensive model testing according to three different load cases in uncertainty is performed. Thirdly a case study specified for a military context is done. It is found that robustness can be increased by increasing the amount of networked forward supply nodes and interesting dependencies are revealed between the amount of forward supply centers and robustness. The findings of this research can be applied to other industries that have a similar supply chain design.","Supply Chain; Multi-Agent Simulation; Robustness; Military","en","master thesis","","","","","","","","2020-12-31","","","","Mechanical Engineering | Transport Engineering and Logistics","",""
"uuid:c2b94777-1dfa-4214-89e1-6f9017a645d8","http://resolver.tudelft.nl/uuid:c2b94777-1dfa-4214-89e1-6f9017a645d8","Direct Nanofiltration of Surface Water: Investigating the fouling and rejection performance of low MWCO hollow fiber nanofiltration membranes","Arun, Anurag (TU Delft Civil Engineering and Geosciences)","Heijman, Sebastiaan (mentor); Haidari, A.H. (graduation committee); Rietveld, L.C. (graduation committee); Spanjers, H. (graduation committee); Delft University of Technology (degree granting institution)","2019","In this thesis, direct application of hollow fiber nanofiltration on surface water is suggested as an efficacious method for surface water treatment. This thesis was carried out as a collaborative effort between Lenntech B.V. and TU Delft. The current research aims to assess the performance of these membranes as a potential solution for surface water treatment and to gain a meaningful understanding of rejection performance and fouling tendencies of these modules through lab-scale experimentation of a low MWCO hollow fiber membrane. Direct application of nanofiltration on surface water was carried out on a lab-scale using the dNF-40 hollow fiber nanofiltration membrane supplied by NXFiltration B.V. Enschede. This membrane is fabricated using a technique called Layer-by-Layer (LbL) polyelectrolyte deposition which consists of an assembly of alternatingly deposited polycationic and polyanionic nanolayers on a polyethersulfone (PES) ultrafiltration support. The dNF-40 membrane is negatively charged at neutral pH. The main objective of the research was to determine the effectiveness of the dNF40 membrane for surface water treatment in terms of three key performance parameters viz. rejection, membrane fouling and concentration polarization. Membrane characterization was carried out by measuring the pure water permeability, Molecular Weight Cut Off (MWCO) of the membrane and rejection of single salt solutions. The pure water permeability of a pristine membrane was 1.53×10^{-14} m. The MWCO was measured using PEG filtration method and was found to be 200 Da. The membrane performance is limited in terms of the flux due to concentration polarization. CP factor was measured experimentally and compared with Sherwood analytical model. Since the flow through the fibers in laminar, high cross-flow velocities are required to reduce CP are high (&lt; 0.5 m/s) due to which hydraulic pressure losses along the feed channel are high. A pressure drop of 0.2 bar was measured for a pristine membrane at a cross-flow velocity of 0.5 m/s. Filtration experiments were carried out with two kinds of surface waters: Delft Schie water and Biesbosch reservoir water. The influence of flux and cross-flow velocity on the rejection of ions were investigated. The removal of Natural Organic Matter (NOM)in both surface waters was between 80 and 85%. The rejection of divalent cations viz. Ca2+and Mg2+was higher at low system recoveries (upto 30%) but a severe drop in rejection was observed at higher recoveries (80%). The final permeate collected at 80% recovery contained 37 mg/L of Ca2+and less than 1 mg/L of NOM. 98%rejection of SO42- was observed irrespective of the feed composition and operating conditions. The dNF-40 membrane exhibited high fouling-resistance during surface water filtration showing no mass transfer coefficient(MTC) decline during 6-hour experimental cycles with surface water. To test for fouling fractions of surface water,additional tests were carried out with model foulant solutions including sodium alginate, humic acid and bovine serum albumin with varying foulant concentrations and ionic strengths; of the three, alginate fouling was most severe in terms of flux decline. Irreversible fouling was observed during the alginate filtration tests. Fiber-blocking was also observed during alginate filtration due to aggregation of alginate and Ca2+. Chemical cleaning with 200 ppm NaOCl solution at pH 12 completely re-stored the permeability. The results presented in this thesis demonstrate that the dNF-40 hollow fiber membrane with the LbL structure can treat surface water with-out pre-treatment. These membranes are ideal for applications such as production of drinking water where partial removal of hardness and complete removal of organic matter is required.","Nanofiltration; membrane fouling; concentration polarization; solute rejection","en","master thesis","","","","","","","","2021-12-10","","","","","",""
"uuid:43d1f917-d0f3-44e4-bd54-29cf52f814e7","http://resolver.tudelft.nl/uuid:43d1f917-d0f3-44e4-bd54-29cf52f814e7","Tracking Electromechanical Muscle Dynamics using Ultrafast Ultrasound and High-density EMG","Waasdorp, Rick (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Biomechanical Engineering)","Daeichin, V. (mentor); Mugge, W. (mentor); Schouten, A.C. (mentor); de Jong, N. (graduation committee); Smit, G. (graduation committee); Delft University of Technology (degree granting institution)","2019","Muscles generate force and enable movement. After excitation of a muscle the muscle fibers contract. Methods to assess muscle contraction in vivo are scarce. Electromechanical delay (EMD), defined as the time lag between muscle excitation and contraction onset, has been proposed as a measure for contraction efficiency, but provides limited insight in electromechanical muscle dynamics. The current paper proposes and evaluates a novel non-invasive method to simultaneously track the propagation of both electrical and mechanical waves in muscles using high density electromyography and ultrafast ultrasound imaging (5 kHz). The method successfully tracked the propagation of the excitation-contraction (E-C) coupling in electrically evoked twitch contractions of the Biceps Brachii in three healthy participants. The excitation wave (i.e. action potential) had a velocity of 3.90 ± 0.65 m/s and the subsequent mechanical (i.e. contraction) wave had a velocity of 3.52 ± 0.89 m/s. Both waves propagated from distal to proximal and had similar spatiotemporal characteristics, indicating that our method can track the propagation of the E-C coupling. The experimental results were compared to simulated contractions of a newly developed multisegmental muscle fiber model, consisting of 500 sarcomeres in series. Both the experiment and simulation showed evidence that excited muscle sarcomeres pull on sarcomeres that were not yet reached by the action potential. In conclusion, our method can track the electromechanical muscle dynamics with high spatio-temporal resolution. Ultimately, the method can be used to characterize E-C coupling in patients with neuromuscular disease to assess contraction efficiency, monitor the progression of the disease and determine the efficacy of new treatment options.","Ultrafast ultrasound; speckle-tracking; high-density electromyography; electrostimulation; wave tracking; skeletal muscle; muscle modeling; Hill; multisegmental modeling; excitation-contraction coupling; latency relaxation","en","master thesis","","","","","","","","2021-12-11","","","","Mechanical Engineering | BioMechanical Design","",""
"uuid:c006c829-ab8b-4acc-ac79-f1c9f6f15abd","http://resolver.tudelft.nl/uuid:c006c829-ab8b-4acc-ac79-f1c9f6f15abd","Single lift blade alignment for large offshore wind turbines: A critical assessment of the alignment process of next generation wind turbine blades","de Leeuw, Koen (TU Delft Mechanical, Maritime and Materials Engineering)","Sliggers, P.G.F. (graduation committee); Jarquin Laguna, A. (mentor); Voormolen, Job (graduation committee); Delft University of Technology (degree granting institution)","2019","In 2022 the first 12 MW offshore wind turbines are expected to be installed. Due to the continuous upscaling of wind turbine generators new problems are expected to arise during the installation of the turbines. Especially the workability of the installation of larger wind turbine blades, which are already causing problems during the installation of 8.4 MW turbine blades, are questioned by Van Oord. This research focuses on the alignment process of the blade with the hub, which is considered to be the limiting factor in installing wind turbine blades. The ultimate goal is to reduce single blade installation times by facilitating the alignment process To investigate how different environmental conditions influence the dynamic behavior of the blade in the alignment process, a numerical model is developed. The motions of the blade, forces in the taglines and aerodynamic forces on the blade are evaluated for different environmental conditions during 30-minute simulations in the time domain. Wind velocity, turbulence intensity and the angle of the incoming wind relative to the blade are environmental parameters that influence the motion of the blade. Results for a 8.4 MW reference turbine blade are compared to a 12 MW turbine blade and conclusions are made concerning the installation workability for larger turbine blades. Results show that the displacement of the blade root is caused by the rotation of the blade and installation tool around its x- and z-axis. The response spectrum of the blade root motions contains a significant amount of energy at the lower frequency part of the spectrum. In this part the first and second natural frequency of the system occur, which correspond to the rotations that are the main causes of the blade root displacement. The effect of wind speed, turbulence and incoming wind angle on the response of the blade is significant. Furthermore simulations are conducted for different rotation angles of the blade in the blade installation tool, which can result in large reduction, around 50%, of blade root motions. The responses of larger turbine blades (length 107 metre) increase compared to a smaller turbine blade (length 80 metre). Workability is expected to decrease due to the increase in blade root motions. Based on the results of the analysis, several improvements are proposed for decreasing the blade root motions using the existing tagline set up. Using a different angle of the blade in the installation tool and increasing the tagline tension both decrease blade root motions. A solution using an extra tagline is proposed and discussed to show how the current setup could be improved.","Single-blade installation; Alignment; Blade motion; Outcrossing rate; Wind loading; Numerical model; Frequency domain; Time domain","en","master thesis","","","","","","","","","","","","Offshore and Dredging Engineering","",""
"uuid:516aa463-3d7a-4d65-8092-6d0ef7a61562","http://resolver.tudelft.nl/uuid:516aa463-3d7a-4d65-8092-6d0ef7a61562","Selection of cost-effective emission abatement options for early-stage ship design: A selection tool implemented for a road ferry and workboat","van Grootheest, Ivar (TU Delft Mechanical, Maritime and Materials Engineering)","Pruijn, Jeroen (mentor); Frouws, Koos (graduation committee); Duinkerken, Mark (graduation committee); Delft University of Technology (degree granting institution)","2019","The maritime emission regulations and incentives require and motivate the selection of different types of energy systems, fuels, and abatement options. In early-stage ship design, the design space of possible combinations can be significant. Therefore, a selection tool has been developed to find the most satisfactory combination of abatement options at minimum costs that at least meet the emission requirements. This decision problem is studied from a general perspective to develop a universal selection tool to enable a widespread application in the maritime industry. The selection tool contains datasets with decision parameters of different energy systems, fuels, and abatement options. The energy systems, including reference fuels, can be selected and assessed on their annual economic and environmental performance. Both upstream and operational emissions are considered and, in addition, the external costs of the emissions are quantified. The abatement options, including fuels, have different effects on fuel consumption and emissions. Moreover, interaction effects occur when combining alternatives. The identified problem is a combinatorial optimisation problem and the objective space is constrained by the emission and compatibility constraints. It is formulated as a multi-objective optimisation problem, whereby the annual internal (investment plus operational) costs and external costs are simultaneously minimised. The external costs can serve as a balancing approach for emission reduction. Furthermore, it can encourage the reduction of the overall environmental impact beyond the regulatory emission constraints. A genetic optimisation algorithm is integrated into the selection tool, which optimises the combinations of abatement options that are subject to the applicable constraints. The functioning of the methodology is evaluated by case studies for the NAVAIS subjects: a battery-electric road ferry and a diesel-electric workboat, both for European waters. The results can provide useful insights into the concept design space of feasible combinations that comply with emission regulations.","Emission reduction; Multi-objective optimisation; Decision support; External costs; Early design stage","en","master thesis","","","","","","","","","","","","Marine Technology","",""
"uuid:c1201f27-964c-4257-ad65-89224bef94a1","http://resolver.tudelft.nl/uuid:c1201f27-964c-4257-ad65-89224bef94a1","Longitudinal Flight Control by Reinforcement Learning: Online Adaptive Critic Design Approach to Altitude Control","Lee, Jun (TU Delft Aerospace Engineering)","van Kampen, Erik-jan (mentor); Delft University of Technology (degree granting institution)","2019","Reinforcement learning is used as a type of adaptive flight control. Adaptive Critic Design (ACD) is a popular approach for online reinforcement learning control due to its explicit generalization of the policy evaluation and the policy improvement elements. A variant of ACD, Incremental Dual Heuristic Programming (IDHP) has previously been developed that allows fully online adaptive control by online identification of system and control matrices. Previous implementation attempts to a high fidelity Cessna Citation model have shown accurate simultaneous altitude and roll angle reference tracking results with outer loop PID and inner loop IDHP rate controllers after an online training phase. This paper presents an implementation attempt to achieve full IDHP altitude control under the influence of measurement noise and atmospheric gusts. Two IDHP controller designs are proposed with and without the cascaded actor structure. Simulation results with measurement noise indicate that the IDHP controller design without the cascaded actor structure can achieve high success ratios. It is demonstrated that IDHP altitude control under measurement noise and atmospheric gusts are achievable under four flight conditions.","Reinforcement Learning; Adaptive Critic Designs; Flight Control Systems","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:27ce0846-0a5a-49e1-b169-10352d0830c6","http://resolver.tudelft.nl/uuid:27ce0846-0a5a-49e1-b169-10352d0830c6","Calibration of optical backscatter sensor for measurements of sediment transport through the Marsdiep inlet","Bertoncelj, Vesna (TU Delft Civil Engineering and Geosciences; TU Delft Environmental Fluid Mechanics)","van der Molen, Johan (mentor); Katsman, Caroline (mentor); de Schipper, Matthieu (graduation committee); Delft University of Technology (degree granting institution)","2019","In highly dynamic and vulnerable tidal systems such as the Wadden Sea, the importance of understanding natural processes and how they are hampered by anthropogenic pressure is highly demanding. Within these processes the sediment transport is one of the most challenging movements to be monitored. With this in mind, suspended particulate matter (SPM) transport in the Marsdiep inlet, the southeastern most tidal inlet in the Dutch Wadden Sea, is monitored with high frequency acoustic backscattering measurements obtained with acoustic Doppler current profiler (ADCP) on Texels Eigen Stoomboot Onderneming (TESO) ferry. The calibration of ADCP measurements is practiced with another device - optical backscatter sensor (OBS). In order to obtain reliable suspended particulate matter concentration (SPMC) measurements, the first step is to calibrate OBS output with high precision. Based on the studies done in the past, the calibration needs to be done locally and regularly as the OBS is sensitive to the variability of SPM properties. The objective of the present study is to formulate an improved OBS calibration method with<i> in situ</i> water samples taken from the Royal Netherlands Institute for Sea Research (NIOZ) jetty. This was achieved by applying pumping suction method to collect the water samples while measuring optical backscattering signal with Campbell Scientific OBS3+ device. Subsampling of the water samples was tested and the results revealed that subsampling leads to undesirable outcome. Procedural control filters that were applied to the laboratory procedure showed filter mass loss that needs to be taken into the account, and the analysis of salt retention showed 1.06 mg of salt remaining on the filters after filtration procedure. Moreover, loss on ignition (LOI) technique revealed the amount of organic content of SPMC which is linearly correlated to full SPMC. The analysis of spring-neap tidal cycle showed that during neap tide there was 0:5 mg l<sup>-1</sup> more organic SPMC compared to the one during spring tide. Finally, the sources of uncertainties were identified and the guidance for further research was suggested.","Optical backscatter sensor; OBS; Marsdiep inlet; OBS calibration; Suspended Particulate Matter; SPM; Sediment transport; Wadden Sea; Loss on ignition","en","student report","","","","","","","","","","","","","","53.001775, 4.789047"
"uuid:94f0bfec-d69a-41b2-8522-bd1744c9dd22","http://resolver.tudelft.nl/uuid:94f0bfec-d69a-41b2-8522-bd1744c9dd22","Dynamics of resonant low-frequency waves over a schematized fringing coral reef","Gaido, Camila (TU Delft Civil Engineering and Geosciences)","Tissier, Marion (mentor); Reniers, Ad (graduation committee); Bricker, Jeremy (graduation committee); Pearson, Stuart (graduation committee); Delft University of Technology (degree granting institution)","2019","Low-lying islands are highly vulnerable to wave-induced flooding, with low-frequency waves (frequency &lt;0.04Hz) being one of the main drivers. The impact of these inundations can increase due to wave resonance over coral reefs, which has been observed in the range of low-frequency waves. This study aims to understand the reef resonance phenomenon along with processes that could limit its resonant amplification over wave height and wave run-up. A numerical experiment was carried out based on a 1D SWASH numerical model. A cross-shore profile of a schematized fringing coral reef was built, and resonance was forced over this bathymetry for the first two resonant modes and two water depths. The offshore forcing was designed as a simplified wave climate, with small amplitude regular low-frequency waves. Resonance was found to occur in a bandwidth of periods for each resonant mode, generating two resonant amplification peaks (one for each resonant mode). The periods leading to the maximum resonant amplification inside each resonant bandwidth are the modeled resonant periods, which were found to be longer than the theoretical resonant periods (based on reef flat width and water depth). The resonant amplification over wave height and run-up were found to be more significant for the fundamental mode than for the first mode, decreasing for both resonant modes when increasing the water depth. Moreover, for the wave conditions modeled in this experiment, the relative resonant amplification was found to be stronger for smaller wave heights than larger wave heights. Reef wave resonance presented a build-up behavior, needing a minimum number of waves to reach a maximum resonant amplification, which varied depending on the wave period, wave height, and water depth. Resonant amplification was found to increase for a larger amount of trapped wave energy over the reef and lower friction dissipation. Frictional dissipation was found to be the most effective process to counteract wave resonant amplification. Thus, increasing coral reef bottom friction is essential for enhancing low-lying island coastal safety.","Wave resonance; Low-frequency waves; Fringing coral reefs","en","master thesis","","","","","","","","","","","","","",""
"uuid:32bf01ba-b6c6-410e-b0e1-b15d95eb05d9","http://resolver.tudelft.nl/uuid:32bf01ba-b6c6-410e-b0e1-b15d95eb05d9","Designing and Evaluating Rebalancing Algorithms for Payment Channel Networks","van Engelshoven, Yuup (TU Delft Electrical Engineering, Mathematics and Computer Science)","Roos, Stefanie (mentor); Epema, Dick (graduation committee); Pawelczak, Przemek (graduation committee); Delft University of Technology (degree granting institution)","2019","Payment Channel Networks(PCN) utilize payment channels with an established link capacity between two nodes to route transactions over multiple links to carry out transactions. Such transactions can support a blockchain due to the transactions happening off-chain, i.e., not requiring any information to be published to a ledger. PCNs can help aid in the scalability of blockchains, by moving transactions off-chain not all transactions need to be stored on the blockchain, reducing the amount of data that needs to be stored on the blockchain. Lightning is the PCN implementation that makes use of Bitcoins blockchain. As transactions occur over the network the capacity of the link may vary over time between two nodes. This change may lead to the link being only available from one side. If enough links become unavailable then processing transactions may take longer or in the worst-case scenario transactions may no longer be feasible in the network. To help avoid these short-comings in PCN strategies can be designed in path-based transaction algorithms to help keep links capable of handling transactions bidirectionally. This work presents two such algorithms, the Passive Merchant and Active Merchant. Additionally, two synthetic data-set models are proposed to help evaluate the effectiveness of the Merchant algorithms, due to a lack of data-sets in this field. In the evaluation two different topologies are examined to evaluate the impact a graph has on the success rate of transactions within a PCN. The evaluation of the The Merchant algorithms is simulation based, experiments evaluated how different algorithms effected the success rate of transactions. The simulation did indicate that the algorithms were able to help increase the success rate of transactions, up to 8%. As these algorithms are embedded in the transaction process of a payment the algorithms are a first of there kind, other solutions have been proposed for rebalancing as a separate protocol. In addition to being the first to propose transaction embedded rebalancing algorithms, no other synthetic data-set models for PCN have been proposed. The synthetic data-set models may allow this area of research to be have constant data-sets that are used to evaluate the effectiveness of path-based transactions.","Blockchain; Payment Channel Network; SpeedyMurmurs; Data-set; Synthetic Data-set","en","master thesis","","","","","","","","2019-12-05","","","","","",""
"uuid:d417f1ac-3222-452d-81bd-163a08ca8e92","http://resolver.tudelft.nl/uuid:d417f1ac-3222-452d-81bd-163a08ca8e92","Droughts and Decisions: Pastoralism, Decision Junctures and Rain Forecasting","Mulder, Esmée (TU Delft Civil Engineering and Geosciences; TU Delft Water Management)","Winsemius, Hessel (mentor); Wright, V. C. (mentor); Steele-Dunne, Susan (mentor); van Gelder, Pieter (mentor); Delft University of Technology (degree granting institution)","2019","The livelihood of the Maasai pastoral communities in Longido District of Northern Tanzania are impacted by droughts regularly, with expectations of increasing variability in rainfall patterns the coming years due to climate change. The goal of this research is to explore if weather forecast and remote sensing data can be tailored to existing coping strategies and decision-making. Furthermore, it is assessed if this tailored information provides enough skill to effectively complement local knowledge and drought management strategies. The study generated important methodological and theoretical findings, both of which have practical implications for policy and technological development. An ethnographic and participatory approach, including four months of immersion with local families, was used to document local knowledge and strategies, and understand what specific, weather information may benefit pastoralists. The study focused on alamei periods, which refers to times of drought and scarcity in the Maasai language. It revealed that weather information around particular important ‘decision junctures’ is most relevant. On the one hand, decisions to move livestock during vulnerable times are based on current water and grass availability; on the other hand, families also consider expectations of rainfall in their decisions. The research determined that at very specific junctures throughout respective seasons, key, timely decisions must be made to maintain household resiliency. It is at these junctures that rainfall predictions become crucial. Using NDVI data and the ECMWF weather model, it was assessed if the onset of rains at such junctures can be predicted with enough skill to support livestock movement decisions. It revealed both optimism and scepticism about the role of current remote sensing and weather prediction technologies vis-à-vis variable, dryland ecologies and pastoral livelihoods.","Drought; Forecasting; Local knowledge; Livelihood; Africa; Tanzania; Rainfall; Decision making","en","master thesis","","","","","","","","","","","","","","-2.756715,37.048843"
"uuid:87f168bf-e2ca-4f0c-ae28-69812b3640db","http://resolver.tudelft.nl/uuid:87f168bf-e2ca-4f0c-ae28-69812b3640db","Proximity Sensing using Time-of-Flight and Single-Photon Avalanche Diodes: Measuring travel time of infrared photons in well-lit environments","Hill, Kevin (TU Delft Electrical Engineering, Mathematics and Computer Science)","van den Bos, Chris (mentor); Cotofana, S.D. (graduation committee); Delft University of Technology (degree granting institution)","2019","Most current proximity sensing methods fail the stringent requirements of modern smartphones. A position-sensing device (PSD) requires a laser placed some distance away from the sensor, intensity-based solutions are sensitive to changes in reflectivity, and ultrasound-based sensors cannot measure small distances because of resonance. With modern transistors getting smaller and smaller, single-photon detectors have become feasible. Using a single-photon detector called a SPAD and a laser, the travel time of light can be measured. This technique, called time-of-flight, existed for several decades where radar and ultrasound are concerned but only recently includes single-photon detectors. Several products exist that use single-photon time of flight to measure proximity. However, they are limited in terms of maximum distance, resolution and ambient light tolerance. The question arises what the best possible performance of such a system is. For radar and ultrasound, this has been calculated long ago already, but for time of flight, no such analysis exists. This analysis is the main contribution of this thesis. A formula is calculated that takes all parameters of the system into account and produces an expected standard error. This formula is verified using a simulator. The effect of an increasing opening angle of laser and SPAD is analyzed, as well as different waveforms of the laser, using multiple SPADs in smart ways, and increasing the time of a single measurement. It is shown that when less than a thousand SPADs are used, no smart way of combining hits on different SPADs exists. The waveform emitted by a laser is typically a mix of a sine, a square wave and some effects resembling RC-behavior. The nearer to a square wave this is, the smaller the resulting standard error is. The most power-hungry aspect of such a proximity sensing solution is often the time discretization device. To obtain a high resolution in the order of millimeters, the time resolution should be in the order of picoseconds. Such an extremely high resolution, below the switching time of a single transistor, can typically only be obtained by trading trade area, power and read-out time for resolution. This thesis analyzes a solution using a low-resolution time-to-digital converter (TDC) and multiple sub-intervals for a shorter time to increase resolution.","SPAD; Time of Flight; TDC","en","master thesis","","","","","","","","2021-12-10","","","","","",""
"uuid:2dbf0e15-a419-4267-ab6c-735409067d1a","http://resolver.tudelft.nl/uuid:2dbf0e15-a419-4267-ab6c-735409067d1a","Rider control identification in cycling taking into account steer torque feedback and sensorial delays","Christoforidis, Christos (TU Delft Mechanical, Maritime and Materials Engineering)","Schwab, A.L. (mentor); Dialynas, G. (mentor); Happee, R. (graduation committee); Schouten, A.C. (graduation committee); Dodou, D. (graduation committee); Delft University of Technology (degree granting institution)","2019","Experimental data were obtained from riding a steer-by-wire bicycle on the open road while perturbing balance with impulsive forces at the seat post (lateral pertubations) as well as perturbing balance with impulsive torques at the steering assembly (steering pertubations). The experiments were conducted at 2.6–5.6 m/s covering both the stable and the unstable forward speed range. For the lateral pertubation experiments two conditions were explored; normal steering and reduced torque feedback steering. Three metrics are used to assess the effect of torque feedback on rider steer control and balance. Results failed to indicate any statistically significant difference between experimental conditions. Bicycle and rider mechanics have been modeled using the Whipple bicycle model extended with the rider inertia. A rider control model is developed that incorporates all of human's sensory pathways and includes a strategy to compensate for sensory dead time. The identified rider control parameters, stabilize the system and mimic realistic rider control behavior. From the results the importance of the torque feedback pathway is strongly indicated. Finally for the steering pertubations the rider control model is modified to account for the cocontraction mechanism. The model manages to approximate the rider measured response and simultaneously captures the significance of the intrinsic response. A high level of intersubject variability is exhibited. The hypothesis that this variability is in fact due to the modulation of admittance in the shoulder joint is strongly suggested.<br","Bicycle; rider identification; control","en","master thesis","","","","","","","","","","","","Biomedical Engineering","",""
"uuid:b485534c-88e8-44d8-84f4-7603afef2bf3","http://resolver.tudelft.nl/uuid:b485534c-88e8-44d8-84f4-7603afef2bf3","The coupling effect in bilateral tele-impedance: Beneficial or detrimental for unstructured environment interaction?","Doornebosch, Luuk (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Cognitive Robotics; TU Delft Biomechanical Engineering)","Peternel, L. (mentor); Abbink, D.A. (graduation committee); Delft University of Technology (degree granting institution)","2019","Tele-impedance augments classical teleoperation by enabling the human operator to actively command remote robot stiffness. Hereby, an essential strategy used by humans to successfully interact with the unstructured environment complements remote robot-environment interaction. However, literature lacks awareness of benefits and disbenefits of currently used stiffness command interfaces (SCIs) in bilateral tele-impedance. In this paper, we introduce a term called the coupling effect. The coupling effect pertains to the coupling between human initiated commanded stiffness and force-feedback from the master robot. It is hypothesized that, whenever the operator’s commanded stiffness and the master device are coupled, like in muscle activity based SCIs, force-feedback can invoke changes in the commanded stiffness due to human reflexes. Although the coupling effect takes away some degree of the operator’s control over the commanded stiffness, these involuntary changes can be either beneficial (e.g. during position tracking) or detrimental (e.g. during force tracking) to the task performance on the remote robot side. In an experimental study 16 participants perform position and force tracking tasks by using both an EMG based coupled type and an external device based decoupled type of SCI. Our results demonstrate a benefit of the coupling effect by showing lower absolute position error during the unexpected force perturbation when a coupled SCI was is in the position task. The coupling effect does not affect reference stiffness tracking in the force task during the process of establishing contact compared to maintaining reference force when a coupled SCI is used. The decoupled SCI is beneficial for tracking reference force in the force task and tracking reference stiffness for both tasks. We conclude that—when using bilateral tele-impedance—one should be aware of the coupling effect, which is beneficial for rejecting a disturbance in a position tracking task but detrimental for establishing contact in a force tracking task.","Tele-impedance; Force-feedback; Coupling effect; Impedance control; Stiffness Command Interface","en","master thesis","","","","","","","","2022-02-01","","","","Mechanical Engineering | BioMechanical Design","",""
"uuid:75e5ebf9-de64-471f-81a3-1e9ce6277e04","http://resolver.tudelft.nl/uuid:75e5ebf9-de64-471f-81a3-1e9ce6277e04","Horizontal and Vertical Eye Movements in Gaze Tracking Tasks: A novel tool to classify neurodegeneration","de Jonckheere, Viktor (TU Delft Aerospace Engineering)","Pool, Daan (mentor); Pel, Johan (graduation committee); Delft University of Technology (degree granting institution)","2019","Eye movements are the result of complex interactions between cortical and sub-cortical regions. Consequently, they are considered as an important bio-marker for neurological function. Attempts to construct an oculomotor model rely on classic paradigms. In this research, a cybernetic approach was used to construct and examine a novel paradigm, which can be used as a new tool to quantify and classify neurodegeneration. Young, healthy adults (N = 24) participated in a quasi-random gaze pursuit tracking task to investigate horizontal and vertical gaze behavior in one- and two-dimensional tracking. Results indicate different horizontal gaze in terms of performance (13% and 23% better) and model parameters (5.6% and 10.2% higher Kg, 6.6% and 7.6% lower τg), comparing the 1D conditions and horizontal and vertical direction in the 2D condition, respectively. Vertical gaze due to cross-feed was observed up to 3 rad/s in presence of a horizontally moving target stimulus, varying in magnitude between subjects. For the proposed paradigm, an increased target signal bandwidth should be used, such that neuromuscular gaze dynamics can be captured as well, as these parameters are known to relate to neurodegeneration.","smooth pursuit; saccades; cross-feed; cybernetic approach; neurodegeneration","en","master thesis","","","","","","","","2025-01-01","","","","Aerospace Engineering","",""
"uuid:8c578ddc-8c66-4622-8f4e-95c76c8023b8","http://resolver.tudelft.nl/uuid:8c578ddc-8c66-4622-8f4e-95c76c8023b8","Development of custom multi-band LTE antenna for telemetric applications: Custom design vs. existing commercial LTE antennas","Hogenhout, Kees (TU Delft Electrical Engineering, Mathematics and Computer Science)","Yarovyi, Dimitry (mentor); Alavi, Morteza (mentor); Claessens, Free (mentor); Delft University of Technology (degree granting institution)","2019","The final goal of this thesis is to figure out if it is possible to design an eight-band LTE antenna for &lt;$0,20 with the same performance, quality and tunability as the current available eight-band LTE antennas. In the introduction the state of the art is presented where the most common currently available comparableantennas and modules are explored. Based on the state of the art, the requirements for the new antenna are set, consisting of a low band of 698-960MHz, a mid band of 1710-2170MHz and a high band of 2496-2690MHz. Based on this the solution is presented and finally 3 antennas are suggested.Antenna I shares the same mid and high band, but operates from 698-894 MHz, while antenna II operates from 805-960MHz due to limitation on the original antenna topology. The third antenna includes a meandered arm for the low band which adds a resonance peak at 960MHz and in this way the bands requirement is met. The antenna was synthesized in two designs and the second design stillneeds an experimental verification. It was concluded that with the given requirements it is possible to design an antenna for below $0,20, but a more in depth experimental verification is needed to check all the requirements.","LTE; Antenna; Multiband; monopole antenna; CST design","en","master thesis","","","","","","","","2024-12-09","","","","Electrical Engineering","",""
"uuid:b215119e-5336-48ba-84b4-eae079535210","http://resolver.tudelft.nl/uuid:b215119e-5336-48ba-84b4-eae079535210","Stability of the first row of an XblocPlus armour layer: A physical model study using Digital Displacement Analysis","Broos, Jan-Willem (TU Delft Civil Engineering and Geosciences)","Aarninkhof, Stefan (graduation committee); Hofland, Bas (graduation committee); Antonini, Alessandro (graduation committee); Reedijk, Bas (graduation committee); Muttray, Markus (mentor); Delft University of Technology (degree granting institution)","2019","XblocPlus is a new uniformly placed single layer armour unit, developed by Delta Marine Consultants (BAM Infraconsult). This report focuses on the stability of the ﬁrst row of armour units, as this row is interlocked less than other rows. When the ﬁrst row starts to slide, this is a big threat to the stability of the entire armour layer. Furthermore, not much is known what exactly inﬂuences the stability of the ﬁrst row. In this study physical modelling is used to determine the stability the ﬁrst row of an XblocPlus armour layer and investigate what inﬂuences this stability. The results of the tests were analysed with a method called Digital Displacement Analysis. Two simplistic theoretical models were devised. The ﬁrst model considers the destabilizing forces to consist only of the drag and uplift forces caused by the wave on the armour units of the ﬁrst row itself, this is called direct hydraulic loading. The second model also considers destabilizing forces transferred by the armour layer to the ﬁrst row, this is called indirect hydraulic loading. From the model tests, it was found that indirect hydraulic loading plays an important role, as the movement clearly occurred during down-rush. When waves started to plunge, the waves failed to destroy the breakwater. Furthermore, loose armour units placed in front of the ﬁrst row moved at higher heights than the ﬁrst row, indicating that the armour layer pushes out the ﬁrst row. Water depth inﬂuences stability, as lower water depth gave a lower stability. It is feasible that this effect is caused by the down rush being closer to the ﬁrst row. The second model is most appropriate when taking these ﬁndings into account. From the tests it was found that a toe berm increases stability as it adds weight to the ﬁrst row and thus increases friction resistance. A foundation layer also increases stability as friction between the foundation layer and the ﬁrst row is higher than between the ﬁrst row and the concrete slab that was used in other tests. Both measures also increase the damage threshold. The damage threshold is the amount of damage that a ﬁrst row can take before brittle failure occurs. Brittle failure is an increase in damage of 0.2Dn (Dn is the nominal armour unit diameter). When both measures are used together, the foundation layer makes the toe berm more stable and this is why the stability of the ﬁrst row is also increased. Based on the tests in this study the stability of the ﬁrst row can be stated as Ns =3.87 (Ns=Hs/(delta*Dn), the stability number is deﬁned as the signiﬁcant wave height divided by the nominal diameter of the armour units and the relative density of the armour units) as at the end of the tests the damage was only 0.13Dn. The test results were used to determine a working hypothesis for a design formula. More tests are necessary to validate this formula and determine its accuracy. A remarkable ﬁnding of this study is that two test series showed contradictory inﬂuences of wave steepness. The ﬁrst test series showed that a lower wave steepness is detrimental for stability of the ﬁrst row, while the second test series showed the opposite. More research should be conducted to investigate on this curiosity.","XblocPlus; Breakwater; Armour layer; First row; stability; Physical model tests","en","master thesis","","","","","","","","","","","","","",""
"uuid:40ad0b1d-a268-42a1-bf25-17c079bd51f5","http://resolver.tudelft.nl/uuid:40ad0b1d-a268-42a1-bf25-17c079bd51f5","Design as a new policy competency: A Learning Environment for capacity-building in public management","Rita, Federico (TU Delft Industrial Design Engineering)","Mulder, Ingrid (mentor); Calderon Gonzalez, Alicia (graduation committee); Mehmeti, Besnik (graduation committee); Delft University of Technology (degree granting institution)","2019","Public management field needs to keep pace with contemporary and evolving problems, and therefore invest in and harvest capabilities to meet future scenarios. It is crucial to have a clear vision on the back end of social advising and a staff who is aware of the wideness of its impact. Public managers need to advocate for critical discussions between them, with the organisations they are cooperating with and with people who are going to benefit their decisions. By exploiting typical Participatory Design paradigms, such as a thorough exploration of the problem space, collaborative approach, and iterative development, the dASAP Learning Environment aims at adapting the design practice to the public management domain. The main goal is, therefore, to strengthen the foundation of the public management approach by reframing Design as a new policy competency. The Learning Environment is the result of a participatory and iterative process, carried out in a team setting. This endeavour to create a safe space in which sharing and nurturing capabilities provides a view on the potential of setting up and running a Design-Enabled Innovation process, while also creating an environment that supports innovation within the public domain. The dASAP Learning Environment does not only provide an array of tools and methods, but it goes beyond them by focusing on underlying factors such as values, knowledge, skills and attitudes, creating appropriate conditions for methods and tools to work.","Participatory Design; Design Capabilities; Learning Environment; Public Management; Capacity Building","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:85668e0e-d04a-418d-94a9-d5659dbaac86","http://resolver.tudelft.nl/uuid:85668e0e-d04a-418d-94a9-d5659dbaac86","Impact of Wrong Ambiguity Fixing on GNSS Positioning","Meng, Fancong (TU Delft Civil Engineering and Geosciences)","Verhagen, S. (mentor); van der Wal, Wouter (mentor); Delft University of Technology (degree granting institution)","2019","Global Navigation Satellite System (GNSS) has been developed in recent several decades, which provides a new technique for timing, positioning and navigation. And GNSS positioning is a basic service to us, both in daily life and scientific research. During high-precise positioning, ambiguity resolution is a key factor that has a huge influence on the accuracy of the result. And the wrong fixing is themain source of lose of accuracy, so many methods of test are proposed to validate the fixing result. We are interested in the performance of solutions that have been labeled as wrong fixing, and want to check if those wrong fixings should be excluded or accepted during estimation.<br/>At firstwe introduce the basic model and challenges of ambiguity fixing, aswell as the widely usedmethod integer least squares and Z-transformation. Some previous research of distribution of fixed solution also enables us to compute the bounds of baseline residual. Then we focus on an example to do some pre-research, and find out the main research question - how to accept wrong fixing during estimation and the impact under different scenarios or estimation methods. We use a simulation-basedmethod to do the research but the<br/>measurements are generated based on the real ephemeris in certain day.<br/>After giving the double difference measurement model based on code and phase with respect to single or dual frequencies, in short baseline scenario, we define some parameters 1-norm, infinity-norm, weighted 2-norm, and good/bad performance of wrong fixings that might be useful for analysis. And some detailed information in chosen epochs are shown with multiple figures and we derive those which are helpful, such as infinity-normratio. Then we develop 4 validation methods, Infinity-normratio detection (RD),Weighted 2-norm detection (WD), 1-norm baseline residual detection (BD1) and Infinity-norm baseline residual detection (BDi), to check if we could recognize wrong fixings with good performance from all wrong fixings.<br/>We also compute some statistics, such as the success rate of detection, the rate of misdiagnose, and the rate of participation to see whether our validation methods are effective or not. The histogram of wrong fixing or correct fixing corresponds the existed research of distribution well. And the time series analysis also proves the reliability of our validation methods, although there exist some errors due to the small sample size of simulations.<br/>We also apply the multi-epoch least squares and Kalman filter to see the influence of fixing success rate, standard deviation of horizontal residuals, residual bounds and performance of wrong fixings. We find that there are obvious improvements on all of them. An extra experiment is designed to see the impact of atmospheric delays and the results show that it is really different from short baseline scenarios and we need to find more proper threshold to make sure our validation methods work.<br/>Finally, we could draw a conclusion that it is possible to find out wrong fixings that could be accepted, but the threshold for each validation method should be adaptive for different scenarios and Kalman filter is very reliable, with which the wrong fixing is always likely to be excluded during the estimation.","GNSS DD positioning; ambiguity fixing; wrong fixing; validation method; Kalman filter; ime series analysis","en","student report","","","","","","Additional Thesis AES4011-10","","","","","","Geoscience and Remote Sensing","",""
"uuid:48869c49-cf5e-426d-bf32-d7f16622491a","http://resolver.tudelft.nl/uuid:48869c49-cf5e-426d-bf32-d7f16622491a","Internal gravity waves in the Rhine ROFI: Applicability of the KdV model","Platell, Hugo (TU Delft Civil Engineering and Geosciences; TU Delft Electrical Engineering, Mathematics and Computer Science)","Pietrzak, Julie (mentor); Schuttelaars, Henk (mentor); Geyer, Anna (mentor); Katsman, Caroline (mentor); Jones, Nicole (mentor); Lamb, Kevin (mentor); Rijnsburger, Sabine (mentor); Delft University of Technology (degree granting institution)","2019","The Rhine Region of Fresh Water Influence (ROFI) is a shallow frictional river plume in front of the Dutch coast. Each tidal cycle a new tidal plume front with fresh-water is released. Recently, internal gravity waves have been observed in this plume. Using a Froude number analysis, support for the internal wave generation mechanism by a tidal plume front is found. It is shown, that on averaged neap tides the density stratification is large. This results in a larger area where the internal waves can be released from the tidal plume fronts compared to spring tides. As the Rhine ROFI is located in shallow water, it is investigated what the effect of bathymetry variation is on internal waves. This is studied by extending the standard KdV model derivation to account for a variable bed. This resulted in a small correction on the propagation speed inside the KdV equation. Observations of internal waves have been used to validate the KdV model. By scaling analysis of the observed waves it is obtained that the relative wave height and relative depth balance for most of the observed events. For these events the wave period and velocity amplitude of the KdV model are well matched with the measurements. This showed that the KdV model may be used for a first estimate of internal waves in the Rhine ROFI. By developing a TGE fitting procedure, it was possible to obtain the pycnocline depth and the direction of wave propagation with only limited data available. Therefore, the parameters have been varied and the error between the TGE solution and the velocity potential obtained from the velocity measurements has been minimized.","Rhine ROFI; Internal waves; Korteweg-De vries; Taylor-Goldstein; Rhine River; Delft3D","en","master thesis","","","","","","Double degree Master of Science in Applied Mathematics and Civil Engineering","","","","","","","",""
"uuid:6f8b90ea-ec59-4da2-8980-68b8e4dfbbec","http://resolver.tudelft.nl/uuid:6f8b90ea-ec59-4da2-8980-68b8e4dfbbec","Modular Platform: Towards a Product Family for a Series of Navy Support Vessels","Smit, Ruben (TU Delft Mechanical, Maritime and Materials Engineering)","Kana, Austin (graduation committee); Hopman, Hans (mentor); Duinkerken, Mark (graduation committee); Broekhuijsen, Joep (graduation committee); Delft University of Technology (degree granting institution)","2019","This thesis is about the identification of an optimal modular platform-based product development design process for a series of support vessels of the Royal Netherlands Navy, viewed from a Damen Schelde Naval Shipbuilding perspective. Because of increasing competition in the global shipbuilding market, the demand for ships with higher quality, lower lifecycle costs and shorter delivery lead time is growing. Advanced manufacturing technologies can partially address these challenges, but advanced design technologies are critical, since most design and manufacturing properties of a ship are influenced by the design decisions that are made in the early design stages. This makes a modular architecture platform approach very suitable. Moreover, it provides multiple opportunities to various stakeholders to benefit from. To clarify, standardisation means the use of identical components across multiple products and modularity means combining standardised components to create modules and/or building blocks. After the evaluation of the literature on modular platforms, an existing modularity method, called Modular Function Deployment (MFD), is expanded by Systems Engineering design disciplines/theories. Hereby, key aspects of platforming and modularisation principles were taken into account. Subsequently, the case study carried out explored whether the composed method is appropriate. In other words, the case study serves as a guideline and indicates which aspects must have close attention, because of encountered complications.","MFD; Modularity; Product platform","en","master thesis","","","","","","","","","","","","Marine Technology | Ship Design, Production and Operations","SDPO.19.035.m",""
"uuid:0ab2d1e4-385e-43cf-9883-cfc6c2f3f19c","http://resolver.tudelft.nl/uuid:0ab2d1e4-385e-43cf-9883-cfc6c2f3f19c","MANtIS: a novel information seeking dialogues dataset","Bălan, Alex (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Web Information Systems)","Hauff, Claudia (mentor); Tintarev, Nava (graduation committee); Al-Ars, Zaid (graduation committee); Delft University of Technology (degree granting institution)","2019","Nowadays, most users access the web through search engine portals. However, information needs can often be ill-defined or too broad to be solvable by a list of results the user has to scroll through, which implies that he is most likely required to refine the need by himself to reach the desired result. In recent years, researchers have attempted to tackle these issues through conversations, more specifically through conversational search. This topic has seen an increase of interest from the research community, proven by the appearance of specialized workshops and seminars. The general public has also started to show interest, proven by the emergence of a wide range of virtual assistants, such as Google Assistant, Microsoft Cortana or Amazon Alexa. As such conversational systems seek to fulfill an information need of a user, they should be able to elicit and fully understand his requirements regardless of the domain, track the conversation as it evolves while attempting to clarify the initial information need and provide suggestions and answers that are based on concrete knowledge sources. Although various developments in domains adjacent to conversational search enabled us to better understand natural language, there is a lack of large-scale datasets that are appropriate for training models to perform conversational search tasks. Through our research, we have built a collection of over 80,000 conversations that fulfill the requirements of a conversational search dataset. We have benchmarked this dataset on three distinct tasks using multiple baselines.","conversational search; Conversation; Information Retrieval; Conversational Agent; Ranking","en","master thesis","","","","","","","","","","","","Computer Science | Data Science","",""
"uuid:5d3f6bd4-bc74-4a98-8655-75871a1001ed","http://resolver.tudelft.nl/uuid:5d3f6bd4-bc74-4a98-8655-75871a1001ed","Riverine flood risk screening with a simple network-based approach: A proof of concept in the Ganghes-Brahmaputra basin","van Meurs, Bram (TU Delft Technology, Policy and Management)","Warnier, Martijn (mentor); Verma, Trivik (mentor); Kwakkel, Jan (graduation committee); Delft University of Technology (degree granting institution)","2019","Floods cause major problems around the world. Over 35 million people were affected by floods in 2018. They have a growing worldwide impact on life and property. Changes in climate conditions lead to unanticipated variations in glacial runoffs, snowmelt and precipitation, which all significantly changing river flows. An imbalance in river network equilibrium leads to flooding and often ends up causing tremendous damage to society and the environment. Regions that are perceived to be downstream from the source of flooding may end up taking the brunt of the river force due to flood cascades. Floods account for about a third of all natural catastrophes worldwide, they cause more than half of all fatalities and are responsible for a third of the overall economic loss.<br/>Modelling approaches are often used to determine flood consequences. Two types of flood models are commonly used: statistical models and flow simulation models. Statistical methods are easy to use but provide limited insight into flood problems. Flow simulation models’ results can be very accurate, especially for hydraulic simulation models. However, these models are expensive to use and develop, and they require a lot of data. These requirements make them unsuitable for application in developing countries and analysing large watersheds. Flood risk screening models try to solve these problems. They are suitable for use in data-sparse regions and are efficient in terms of omputational costs. However, there is a lack of knowledge between river structure and cascading flood effects, and there is a lack of models that are efficient, easy to understand, use topological data and have the purpose of risk screening. In this research, we show a flood model based on complex network theory to efficiently study the cascading effects of floods in riverine systems. Cascading effects are defined as floods that occur as a result of water waves through the system that originate from upstream sources. The developed model uses the hydrological Muskingum routing method. We found that it was possible, notwithstanding many assumptions and a lack of data, to reproduce system behaviour during an extreme flood event in the Ganges-Brahmaputra Basin. Satellite elevation data were used to construct the river network, and satellite precipitation data was used to feed the model. The model can indicate high risk reaches based on the simulated overflow, the flow exceeding a predefined capacity. No existing models are known that can do this, on a laptop, within seven min- utes per simulated day, with limited data for a watershed that exceeds the size of one million square kilometres. The network structure of the model makes it possible to achieve a better understanding between river typology and cascading flood effects. The model is not without its limitations. It cannot pinpoint when and where floods will occur, because it only calculates overflow. Moreover, flood failure mechanisms are not yet included in this model. Failure mechanisms will change model behaviour: when a flood occurs water temporarily leaves the system, which reduces downstream risk. Overflow cascades, therefore, would be shorter in reality than in this model. The model is a proof of concept that shows the potential of a network theory-based risk screening method in flood simulation context. Its properties make it suitable for analysing the effects of changing precipitation patterns, which, for example, could originate from climate change studies. Another use case is real-time forecasting of discharge levels if the mode is combined with real-time discharge levels and precipitations forecasts. The model can be used as an early warning system: alerting when and where high discharge levels are expected. We anticipate our model to be a starting point for policy screening and scenario analysis. Sugges- tions are made to include policy options within the model. Policy analysts can then use the model to compare different policy interventions for all kinds of (future) scenarios. The model should not be seen as a replacement of the advanced hydraulic simulation models, but as a complementary tool useful at an earlier moment in a design process with the purpose of screening options. Ultimately it can become a framework with the aim to support informed decision-making.","Flood risk; Risk screening; Modelling; Complex Network Analysis","en","master thesis","","","","","","https://github.com/bcvanmeurs/rna","","","","","","Engineering and Policy Analysis","",""
"uuid:154af986-f9d5-40d3-a9bf-487b9545a730","http://resolver.tudelft.nl/uuid:154af986-f9d5-40d3-a9bf-487b9545a730","Steering product formation In high-pressure anaerobic systems: The effect of elevated pCO2 on the degradation of glucose and glycerol by a mixed culture","Chang, Kelly (TU Delft Civil Engineering and Geosciences)","Lindeboom, R.E.F. (mentor); Ceron Chafla, P.S. (graduation committee); Delft University of Technology (degree granting institution)","2019","Biogas is the well-known product of Anaerobic Digestion (AD), but nowadays, the intermediate products (volatile fatty acids - VFAs) of anaerobic metabolism have gained increasing attention inside the “carboxylate platform”. However, steering and optimizing the process for selective metabolite production is still an unraveled task inside this field since it relies on the manipulation of operational parameters. The objective is to understand the conversion of glucose and glycerol in the mixed culture of anaerobic digestion to unravel possibilities to steer product formation. Glucose and glycerol are the main components in the waste streams of beverage and biodiesel industries. Regarding the degradation pathways in AD, both glucose and glycerol are oxidized to pyruvate by fermentative bacteria to obtain energy and metabolic intermediates under anaerobic conditions through the same intermediate, glyceraldehyde-3-phosphate. Pyruvate, the key branching-point, allows the process to enter different metabolic pathways which lead to the formation of various metabolites. Under the fermentation conditions, redox balance is necessary to be maintained through terminal electron transfer to internally produced compounds. Since glycerol has a higher degree of reduction than glucose (Glucose: 0.33 NADH/C-Glucose; Glycerol: 0.66 NADH/C-Glycerol), the conversion of glycerol into pyruvate generates a double amount of reducing equivalents. On the one hand, this provides the advantage of higher theoretical product yield of reduced compounds. On the other hand, half of the glucose is lost as CO2 during the fermentation, and this reduces the product yield.1 Therefore, we assume that elevated pCO2 could have a more significant detrimental effect on glucose fermentation. In this research, batch experiments at different pCO2 (0.3, 1, 3, 5, 8 bar) were performed, and different types of measurements and analyses were employed to monitor the pCO2 effect on the metabolism. We designed some of the potential pathways of glucose and glycerol conversion under elevated pCO2. The elevated pCO2 converged the product spectrum of both substrates towards propionate production but affected the degradation and production phase of propionate and acetate. Initial pCO2 of 0.3 bar and 1 bar did not cause visible inhibition on the propionate production of both substrates. However, the propionate degradation was kinetically affected under 0.3 and 1 bar initial pCO2. Although propionate was degradable, its degradation phase at 1 bar initial pCO2 was longer than 0.3 bar. On the contrary, when the pCO2 was elevated to 3, 5, and 8 bar, not only the propionate production phase became longer, but also the maximum concentration became lower on both substrates. Moreover, propionate degradation was ceased. The lower propionate production was suspected to be due to the inhibition of NADH production as a consequence of the elevated pCO2 effect. The undegradable propionate might be attributed to unfavored decarboxylation reactions under elevated pCO2. The enrichment approach was applied to examine the adaptability of the microbial consortium under the CO2-exposing environment. Therefore, not only the more predominant metabolic reaction would be favored during the enrichment, but also changes in the community due to CO2 influence were expected. Propionate degradation was achieved with this inoculum at the only tested condition (5 bar initial pCO2). From the community analysis, Smithella was enriched during the enriched and it was suspected to play a significant role in the propionate conversion. Besides, the difference between the substrates on the fermentation has been observed. Due to the higher available reducing power of glycerol than glucose, glycerol was potentially able to generate more propionate. However, the butyrate formation also needs the reducing power to proceed with the reaction, but it was not detected in the glycerol fermentation. Therefore, reducing power distribution from specific substrates with elevated pCO2 might also be affected. Moreover, the substrate was also hypothesized to influence cell viability, where glycerol fermentation increased the cell viability but glucose not. The degradation of acetate and butyrate in the non-enriched inoculum was observed to be kinetically affected by elevated pCO2, with the later becoming undegradable at 8 bar. The reason for this phenomenon needs further investigation.","High-pressure anaerobic digestion; Resource recovery; CO2 injection","en","master thesis","","","","","","","","2020-12-12","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:c643576f-2a77-4e52-bca2-517e0918458f","http://resolver.tudelft.nl/uuid:c643576f-2a77-4e52-bca2-517e0918458f","Multi-Level Inversion Based On Mesh Decoupling","Shachor, Benny (TU Delft Civil Engineering and Geosciences)","Lahaye, Domenico (mentor); Hajibeygi, Hadi (mentor); Vossepoel, Femke (graduation committee); Delft University of Technology (degree granting institution)","2019","Understanding the permeability of the subsurface is a crucial step to simulate fluid flow in the subsurface. A parameter estimation problem for the flow equations can be solved to find the permeability. The robust identification of material parameters remains a significant challenge. In classical approaches, the non-linear least-squares problem is formulated as a non-linear optimization problem in which the partial differential equation governing the permeability field acts as a constraint. These approaches lead to large scale problems and are, therefore, computationally challenging. This thesis proposes a new approach based on mesh decoupling of state and design variables. This approach allows treating the design variables on various scales of resolution without comprising the accuracy of the state and adjoint solver. The method is implemented on a<br/>one-dimensional and two-dimensional Poisson problem taken from the literature. The first numerical results show that the multilevel approach is able to accelerate the initial stages of the search procedure significantly.","Inverse problem; Multi-Level; optimization; Petroleum Engineering; Partial Differential Equations","en","master thesis","","","","","","","","","","","","","",""
"uuid:19f1710b-b1ef-4f83-9b26-a87202e29bf6","http://resolver.tudelft.nl/uuid:19f1710b-b1ef-4f83-9b26-a87202e29bf6","Feasibility of subsurface imaging using diurnal temperature variations","Bezemer, Marissa (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Delft Institute of Applied Mathematics)","Budko, N.V. (mentor); Dubbeldam, J.L.A. (graduation committee); van Elderen, E.M. (graduation committee); Delft University of Technology (degree granting institution)","2019","The feasibility of subsurface imaging using diurnal temperature variations to determine and/or monitor tuber growth is investigated by creating a model capable of numerically simulating data. The model and the numerical simulations are discussed, as well as the use of effective inversion to determine the volumefraction of tubers.","numerical methods; subsurface imaging; diurnal temperature variations","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:afefd680-9b9e-4ba4-a5e0-a050a2a7c959","http://resolver.tudelft.nl/uuid:afefd680-9b9e-4ba4-a5e0-a050a2a7c959","Adaptive intent recognition for control of an active robotic lower limb prosthesis","Westerink, Aron (TU Delft Mechanical, Maritime and Materials Engineering)","Harlaar, J. (mentor); Fluit, R. (mentor); Delft University of Technology (degree granting institution)","2019","Passive and semi-active knee prostheses demand up to 60% more metabolic energy from transfemoral amputees compared to able-bodied subjects during walking. In addition to this, amputees have trouble with ambulation on stairs, slopes as well as transitioning from stand to sit and vice versa. This limitation is attributed to the nature of current solutions to either store or dissipate energy whereas an able-bodied subject generates energy in the knee during these locomotion modes. Active knee prostheses are able to generate net power. This has resulted in newly developed controllers for various locomotion modes such as ambulation on stairs/slopes and sitting but the question remains how to seamlessly transition between all of them. Intent recognition techniques are described in literature to classify real-time data to switch between these modespecific controllers. In intent recognition, machine learning methods are commonly proposed to differentiate between different locomotionmodes using on-board sensor data. An effective method for real-time classification of standing, walking and sitting are Linear discriminant analysis combined with Gaussian mixture models as these methods are computationally efficient. In the first part of this thesis, a combined model using the Linear discriminant analysis and Gaussian mixture model, is reproduced using an active knee prosthesis from Reboocon Bionics. Current intent recognition systems, however, still require user-specific training data, limiting commercialisation. Extending current research, updating a pre-trained Gaussian mixture model in real-time is researched in a simulated real-time environment. This ""adaptive"" approach is researched in the second part of this thesis together with adaptivity parameters such as the amount of training data, the type of training data and the learning rate. The adaptive classifier is compared to the initial classifier and the current rule-based system available in the prosthesis to see if it is able to improve its classification accuracy over time. With an optimal set of parameters, the adaptive system was able to increase its classification accuracy over time with a bad initial classifier (trained on a different subject) gaining an increase of approx. 5%. Moreover, the system was able to transcend the current commercial rule-based system by detecting mode-changes that the rule-based systemoverlooked.","","en","master thesis","","","","","","","","2021-12-31","","","","Biomedical Engineering","Reboocon",""
"uuid:0d2341b8-197b-4df3-9846-1794a368ee5c","http://resolver.tudelft.nl/uuid:0d2341b8-197b-4df3-9846-1794a368ee5c","Humidity Effects on Turbofan Performance: in a MRO context","van Vuuren, Stijn (TU Delft Aerospace Engineering)","Visser, W.P.J. (mentor); Apostolidis, Asteris (graduation committee); Delft University of Technology (degree granting institution)","2019","Engine performance diagnostics play a major role in keeping track of gas turbine condition and performance and identification of possible errors or faults. One of the key performance indicators used in engine performance diagnostics is the Hot Day Exhaust Gas Temperature Margin (EGTM). Ambient humidity affects the EGTM, however humidity is not measured on current civil aircraft and consequently introduces inaccuracy in the reported EGTM. Research has been performed investigating the effect of humidity on turbofan performance, to provide corrections for the reported EGTM for ambient humidity. Test-cell corrections, simulations and historical data have been reflected and were found to be very comparable. Corrections have been developed increasing reported EGTM accuracy. However not negligible, the overall effect of humidity on the inaccuracy of the EGTM is found to be small. It is therefore concluded that correcting the EGTM for humidity is possible but will increase EGTM accuracy only slightly.","Turbofan; Humidity; Performance; EGTM; Correction; MRO; KLM; Engine Services","en","master thesis","","","","","","","","2024-12-09","","","","Aerospace Engineering","",""
"uuid:5ec9a36f-4b2b-4fb6-81cc-e32ab810b87b","http://resolver.tudelft.nl/uuid:5ec9a36f-4b2b-4fb6-81cc-e32ab810b87b","Alternative fuels on board of carbon-neutral cruise vessels: The selection, implementation and design impact of alternative fuels on board of carbon-neutral cruise vessels","Volger, Casper (TU Delft Mechanical, Maritime and Materials Engineering)","Visser, Klaas (mentor); de Vos, Peter (mentor); Miedema, Sape (graduation committee); Boonen, E.J. (graduation committee); Delft University of Technology (degree granting institution)","2019","The growth of the cruise industry throughout recent years and the changing public opinion on cruise ships has led to increasing concerns regarding the impact cruise vessels have on the world’s climate and environ- ment. Cruise passengers prefer not to be related with heavy polluting vessels. In fact, trends like responsible tourism and sustainable travel are increasing, especially among younger generations. In order to maintain a viable business model, cruise operators are compelled to consider exploring new energy sources and energy carriers to power their cruise vessels. Alternative carbon-neutral fuels are found to be a potential solution. As such, this research aims to evaluate the viability of possible alternative carbon-neutral fuels on board cruise ships.","Alternative fuels; Hydrogen; Ammonia; Methanol; cruise ship","en","master thesis","","","","","","","","","","","","","",""
"uuid:7abbff46-a862-48ae-a751-385d26158e6b","http://resolver.tudelft.nl/uuid:7abbff46-a862-48ae-a751-385d26158e6b","Transferred Graphene as a Conductive Layer on a Thin Alumina Membrane: Investigating the Feasibility to use Graphene as Conductive Layer in a Timed Photon Counter","ten Bruggencate, Thijs (TU Delft Applied Sciences)","van der Graaf, Harry (mentor); Sarro, Lina (graduation committee); Prodanovic, Violeta (graduation committee); Delft University of Technology (degree granting institution)","2019","For this Master thesis the possibility was explored to use a monolayer of graphene as conductive layer, instead of sputtered titanium nitride (TiN), on 25 nm thick aluminium oxide and magnesium oxide membranes. These membranes will be used in a new and faster variant of a vacuum electron multiplier (e.g. the Photo Multiplier Tube (PMT)). These membranes should act as transmission dynodes, or tynodes, where electrons are multiplied while interacting when they travel through the membrane and leave the membrane on the other side instead of being multiplied by hitting the surface of a dynode, where secondary electrons are released on the same side. These membranes are constructed using insulators and can charge up, as more electrons leave the membrane than enter. To circumvent this issue a conductive layer is applied on these membranes. The advantage to use graphene over TiN as conductive layer would be that the maximum transmission electron yield is higher and occurs at a lower incoming (primary) electron energy due to the reduced total thickness of the membrane. In order to get graphene on the membranes a wet transfer method of graphene was used where a layer of Poly(methyl methacrylate) (PMMA) was applied to support and the graphene sheet and to make it buoyant.<br/>The adhesion of graphene to alumina membranes proved to be very difficult and on many occasions the graphene was washed away during the removal of the polymer by acetone. The few remaining samples that were produced on both alumina and magnesium oxide membranes, where the conductive layer was successfully applied, had a lower transmission electron yield than the samples coated with a sputtered TiN layer. Sputtered TiN was used as conductive material in this project, before graphene was researched for this thesis. The reason for the lower yield is that the adhesion between the conductive graphene and the membranes was not good enough to conduct electrons vertically in the membranes causing them to charge up. One of the reasons for the poor adhesion is that the membranes are wrinkled and curved due to internal stresses that are caused by the production process. The graphene layer cannot follow these curves due to the way it is applied and only makes contact at the tops of the wrinkles. The primary electron energy, where the (lower) maximum yield was observed, was higher than samples with TiN, while the expectation was that graphene as the conductive layer would lower this energy, due to the reduced thickness. These observations lead to the conclusion that graphene is not a viable replacement for TiN as the conductive layer on these membranes.<br/>The use of TiN deposited by Atomic Layer Deposition (ALD) instead of sputtering was also tested. The samples produced with this method conducted electrons well enough to prevent charging effects in the membranes. The added benefit is that the TiN can be deposited with the alumina layer in a single ALD run and that its thickness can be controlled more precisely. The positive results make ALD TiN a viable replacement for sputtered TiN, but more research should be done to find the minimum thickness of this layer where it is still conductive enough to prevent charging of the membranes.<br/>In order to circumvent the abovementioned adhesion issues, a transfer-free method was developed to create graphene-alumina membranes, where the alumina was deposited on the graphene through ALD, instead of transferring graphene on the alumina. Since copper is used as a catalyst to grow the graphene, this put a lot of constraints on suitable wet etching techniques. This resulted in chemical baths where the temperature control was not ideal, which lead to much longer silicon etch times and loss of wafers. Near the end of the process a silicon oxide layer needed to be removed, but this step was most likely not performed correctly, leaving a thin layer of silicon oxide that blocked chemicals that should remove a deeper layer to release the membranes. Further testing of these samples fell out of the scope of this thesis and could be researched in the future. In conclusion, it is advisable to etch the silicon earlier in the process when the copper has not been deposited yet. In general the flowchart of this process needs a revision.","Graphene; transfer; aluminum oxide, alumina; membrane; Adhesion","en","master thesis","","","","","","","","","","","","Applied Physics","",""
"uuid:f9c953a8-8d7f-4881-8c76-800cb24ca1c3","http://resolver.tudelft.nl/uuid:f9c953a8-8d7f-4881-8c76-800cb24ca1c3","Dynamical electromechanical analysis of pole-piece rotors in pseudo direct-drive machines: Taking the next step towards tomorrow’s wind turbines","Desmedt, Michiel (TU Delft Electrical Engineering, Mathematics and Computer Science)","Dong, Jianning (mentor); Nilssen, Robert (graduation committee); Delft University of Technology (degree granting institution)","2019","Wind energy has shown to be a great renewable energy source, with a possible penetration of 20 % by 2040. In order to increase its competitiveness with fossil fuels, the LCOE should decrease further than it already has. Increasing the power rating of wind turbines has proven to be an effective way to achieve this. However, this results in impractical large nacelles which are hard to install offshore. Reducing the size can be done with a gearbox, but due to the gearbox being a high-risk component of offshore wind turbines, wind turbine manufacturers have moved to direct-drive topologies. The pseudo direct-drive topology, where a magnetic gear and direct-drive machine are combined, has shown great potential reducing the size of the generator while keeping the reliability of a direct-drive machine. However, due to the introduction of an extra rotor for the magnetic gearing, the mechanical complexity increases. Focusing on a particular 10 MW design, large deflections in this extra rotor of up to five times the air gap length have been observed during nominal operation. Simple modifications have been investigated, resulting in deflections of less than 1 mm. Each modification was then compared to identify the most promising one.","Wind Energy; FEM; Machine Modelling; Numerical Modelling; Permanent Magnet Machine,; Pseudo Direct Drive","en","master thesis","","","","","","","","2019-12-06","","","","European Wind Energy Masters (EWEM)","",""
"uuid:8cf2b5a2-b090-453f-8c87-61ec8172448e","http://resolver.tudelft.nl/uuid:8cf2b5a2-b090-453f-8c87-61ec8172448e","The effect of upstream turbulence on a tip-vortex","Varadharajan, Prasath Krishnaswamy (TU Delft Mechanical, Maritime and Materials Engineering)","Elsinga, Gerrit (mentor); Nanda, Swaraj (mentor); Westerweel, Jerry (graduation committee); Akkerman, Ido (graduation committee); Delft University of Technology (degree granting institution)","2019","A tip-vortex in the wake of a finite length lift generating surface has a low pressure region near the axis of the tip-vortex. This low pressure region can trigger tip-vortex cavitation especially in ship propellers which has adverse effects by causing vibration and underwater noise production. One way of minimising the tip-vortex cavitation is by reducing the propeller blade loading but at a cost of lower operating efficiency of the propeller. An alternative passive approach, to delay the onset of cavitation, by increasing the minimum pressure in the core of the tip-vortex through modification of the tangential velocity profile of the tip-vortex is investigated in this thesis. In this thesis, the effect of upstream turbulence on the peak tangential velocity of the tip-vortex from a NACA 662-415 hydrofoil is investigated through stereo-Particle Image Velocimetry measurements. The turbulence is produced by a passive grid placed in the upstream of the hydrofoil. The tangential velocity profile at three different turbulent intensities were compared with measurements from a baseline no grid case that had nearly uniform and steady inflow to the hydrofoil. The tangential velocity profile of the vortex exhibits a reduction in the average peak tangential velocity under the influence of the grid generated turbulence compared to the no grid case. The measurements taken at two downstream locations, 0.5 and 1.3 chord length downstream from tip of the hydrofoil, showed that a significant reduction in the magnitude of the average peak tangential velocity of the tip-vortex is observed only at the latter position. Also, on examining the axial velocity profiles, a significant reduction in the magnitude of the average peak axial velocity in the core of the tip-vortex was observed under the influence of grid generated turbulence. An apparent effect of the upstream turbulence on the tangential velocity of the tipvortex is seen to appear only when sufficient time is given for a secondary vortex structure, from the upstream turbulence, to form around and be intensified by the primary tip-vortex. At 1.3 chord length downstream from the tip of the hydrofoil, the reduction in the magnitude of the peak tangential velocity is accompanied by increase core radius of the tip-vortex.","Tip-vortex; Turbulence; PIV","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Energy and Process Technology","",""
"uuid:1e87cafc-3f83-4a8d-a12e-72c3c0847b62","http://resolver.tudelft.nl/uuid:1e87cafc-3f83-4a8d-a12e-72c3c0847b62","Micro-scale computational analysis of Fused Filament Fabricated Materials: Experimentally-validated Finite Element Analyses of Representative Volume Elements","Creusen, Frederic (TU Delft Mechanical, Maritime and Materials Engineering)","Bessa, Miguel (mentor); Berens, Julius (mentor); Delft University of Technology (degree granting institution)","2019","This work aims at predicting the elasto-plastic and fracture behavior of ABS polymers obtained by Fused Filament Fabrication (FFF). The strategy adopted is to characterize the microstructure of Representative Volume Elements (RVEs) of the material, as well as the mechanical properties of the polymeric filament used in the FFF process and then conduct Finite Element Analyses (FEA) to predict the nonlinear behavior of the RVEs. The predictions are then experimentally validated. The research presented herein significantly contributes to the ambitious goal of establishing the process-structure-property relationships for polymeric parts fabricated by FFF, opening avenues to conduct data-driven analysis and design of additively manufactured products. The FEA results are compared and validated with empirical tensile tests of FFF ABS products obtained using two different methods, the ISO 527 and the ASTM D3039 standard. The stress strain curves from the ASTM D3039 test procedure show significant overlap with the results from the optimized RVE analysis. The UTS of the 1 and 2 directions are predicted with a deviation of 5%. The difference in the 3 direction is explained through the sub-optimal healing between the subsequent layers. This accounts for roughly 10% of the drop in UTS in comparison with bulk ABS. This implies that porosity is the dominant phenomenon affecting the tensile behaviour of FFF parts. This model has the potential to determine the mechanical properties of fully healed FFF products accurately with different layer orientations and line/width ratios. Subsequent work should consider the use of cohesive elements when sub-optimal healing between filament roads occurs.","Fused Filament Fabrication; finite element analysis; fused deposition modeling; additive manufacturing; Micro-Scale analysis; Mechanical behaviour; Mesostructure; representative volume element; ABS","en","master thesis","","","","","","","","","","","","","",""
"uuid:4ddd6740-2f74-4fcd-aa9f-c0477015f5ba","http://resolver.tudelft.nl/uuid:4ddd6740-2f74-4fcd-aa9f-c0477015f5ba","The impact of soft time windows with penalties on the objective values of large real-world Vehicle Routing Problems","Slotboom, Cynthia (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Essen, Theresia (mentor); Gijswijt, Dion (graduation committee); Keijzer, Marleen (graduation committee); Delft University of Technology (degree granting institution)","2019","In a Vehicle Routing Problem with Time Windows (VRPTW), orders have to be picked up and delivered within certain time windows. In practice, planners often allow violations of these time windows, when the solutions with violations have better objective values. This is done by changing the problem into a Vehicle Routing Problem with Soft Time Windows (VRPSTW). In this thesis, the effect of soft time windows on the objective values of a real-world VRP is analysed for multiple single-day cases of a distribution company. The used algorithm is a heuristic, based on local search methods. At first, a sensitivity analysis is performed on the sensitivity of the number of planned tasks to the time window tolerance. The addition of time window tolerance increases the number of planned tasks in most of the cases. Furthermore, when the tolerance increases, the number of planned tasks generally increases as well, until the number of planned tasks is equal to the number of tasks that is planned when the time windows are completely removed. In the second part of the experiments, trade-offs between the cost function and the amount of violation are investigated, by varying the slope of the linear penalty function (for a fixed tolerance). In general, a higher penalty leads to a lower amount of violation and a higher cost (without penalties), but this is not a monotone correlation. For the smaller cases, the costs can be lowered by 4.8% to 9.0%. To reach this minimum cost, an average violation of 1 to 7 minutes per task has to be accepted. For the bigger cases, only the lowest penalty values lead to a cost improvement. Here, the lowest cost value is achieved by choosing the zero function as the penalty function, which means that the corresponding solution contains a large amount of violation.","VRP; Soft time windows; Real-world problems; Local search","en","master thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:f483be8e-522b-473c-8e83-08cd514915f7","http://resolver.tudelft.nl/uuid:f483be8e-522b-473c-8e83-08cd514915f7","Capacity-based Arrival Sequencing and Trajectory Optimization for Continuous Descent Operations","Janssen, Jaap (TU Delft Aerospace Engineering)","Roling, Paul (mentor); Delft University of Technology (degree granting institution)","2019","Due to the rapid growth of air traffic and the corresponding increase in demanded landing capacity of airports, much research has been done on arrival scheduling and approach trajectory optimization aiming to not only maximize the effective runway throughput of an airports runway system but also significantly reduce fuel consumption. This thesis research considers both, arrival scheduling and approach trajectory optimization, as one combined optimization problem with the goal of balancing fuel-optimality and time-optimality based on the presently demanded runway throughput in a dynamic approach environment. A hybrid optimization tool is developed, solving the arrival scheduling problem by means of a sequential quadratic programming algorithm while solving the corresponding approach trajectories as an optimal control problem using a hp-adaptive Gaussian quadrature collocation method. Both optimization problems are linked through pre-computed aircraft-specific fuel curves, providing fuel information for each achievable landing time to base scheduling decisions on. The arrival optimization tool applies continuous descent approach procedures over a fixed lateral approach path. Further, the freeze horizon concept is applied which together with constrained position shifting confines the optimization problem down to a size that can be solved in real time. Compared to the currently prevailing first-come first-served scheduling method, a 14% increase in effective runway capacity was achieved consistently while a fuel reduction of 2.2-4.8%was achieved depending<br/>on the tested average throughput.","Arrival Scheduling; Sequencing; Trajectory Optimization; Optimal Control; Continuous Descent Approach; Constrained Position Shifting; Capacity-based; Simultaneous Optimization","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:b6bad7a5-0afd-4268-873d-32a4a18b4281","http://resolver.tudelft.nl/uuid:b6bad7a5-0afd-4268-873d-32a4a18b4281","Advanced Set Bounding Methods for Fault Detection","Ritsma, Folkert (TU Delft Mechanical, Maritime and Materials Engineering)","Ferrari, Riccardo (mentor); Al-Ars, Zaid (mentor); Delft University of Technology (degree granting institution)","2019","Performance of set based fault detection is highly dependent on the complexity of the set bounding methods used to bound the healthy residual set. Existing methods achieve robust performance with complex set bounding that narrowly define healthy system behavior, yet at the cost of higher computation times. In this thesis a major improvement is reached in both accuracy and computation time by applying machine learning methods to set bounding. A method is developed which achieves fault detection at several orders of magnitude the speed of an existing set based fault detection method without sacrificing a robust performance.","Fault Detection; Machine Learning; Anomaly Detection; Outlier Detection; Support Vector Machines; Model Based Fault Detection; Set Based Fault Detection","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:acfa4d68-391b-4ada-9aae-0077751a00a8","http://resolver.tudelft.nl/uuid:acfa4d68-391b-4ada-9aae-0077751a00a8","Relocatable Energy Storage Systems for Congestion Management","Janssen, Suzanne (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Intelligent Electrical Power Grids)","Palensky, Peter (mentor); Cvetkovic, Milos (mentor); Chandra Mouli, Gautham Ram (graduation committee); Fu, Aihui (graduation committee); Delft University of Technology (degree granting institution)","2019","In 2018 the Dutch government, businesses and other stakeholders started negotiating an agreement to combat climate change (het Klimaatakkoord). Energy consumption is changing and more Renewable Energy Sources (RES) are implemented. While these changes are ongoing, the Distribution System Operators (DSOs) must ensure no congestion occurs in the grid. However, it seems congestion problems are already arising. As a lot of research has been done on Energy Storage Systems (ESSs) and Electric Vehicles (EVs) for congestion prevention, research on movable ESSs is missing. This thesis proposes a method for congestion prevention by Relocatable Energy Storage Systems (RESS). A Mixed Integer Linear Program (MILP) is proposed to minimise the amount of RESS used and penalise displacement. An algorithm which includes a Minimum Cost Maximum Matching is used to determine the planning of each individual RESS. The results show that, for the test grid designed, it is beneficial to use RESS instead of statically placed ESS in the grid.","Congestion Management; Mixed Integer Linear Programming; Combinatorial Optimization","en","master thesis","","","","","","","","","","","","","",""
"uuid:997a525d-688c-4c70-b2fa-0424bef5fdfe","http://resolver.tudelft.nl/uuid:997a525d-688c-4c70-b2fa-0424bef5fdfe","The safety mind-set in the ammunition chain of the Dutch Armed Forces","Potter, Max (TU Delft Technology, Policy and Management)","van Gelder, P.H.A.J.M. (mentor); de Bruijne, M.L.C. (mentor); Guldenmund, F.W. (mentor); Mac Gillavry, James (graduation committee); Delft University of Technology (degree granting institution)","2019","The ammunition domain is very fragmented and people within the Ministry of Defence often make the assumption that people from the different branches of the Armed Forces think differently about safety and its priority in making decisions for military operations. So far however it is unknown how the people in the ammunition chain think about safety or what causes differences in their thinking. A literature review was used to gain understanding in safety theories that could be applied to the ammunition chain. The focus was on Normal Accident Theory and High Reliability Theory. Q methodology was then used to identify and explore perspectives about safety of the key-players involved in the ammunition chain. A focus group and interviews with experts have been used to confirm the perspectives that were derived from the Q-study and to further explore their implications. In contrast to what was expected at the start of the research, no (organizational) fragmentation has been found in the mind-set on safety with the participants of the conducted Q-study. The findings seem to imply that the mind-set regarding safety is mainly shaped by the organisational position and roles of the people involved with ammunition. The conducted Q-study found three perspectives. The perspectives 1 and 2 seem to correspond with how High Reliability Organisations (HRO) think about and position themselves regarding safety. In perspective 3, there seems to be no clear lower limit for safety, meaning that the mind-set in this perspective allows for trade-offs on safety if resources become limited. The occurrence of perspective 3 was difficult to understand, therefore an explanation was sought. Combining the theory on NAT and HRO from the literature, the focus group and interviews with experts, a possible explanation for this perspective has been proposed. In this possible explanation the complexity in the governance at the top level of the Ministry of Defence seems to result in the loss of accountability for the ammunition chain. From the point of view of safety, this is a structural problem, implying that after some time accidents with ammunition could return regardless of the safety measures put in place. Two possible solutions were proposed to prevent this from happening.","Q methodology; Safety; High Reliability Organisation; Normal Accident Theory; Ministry of Defence; Ammunition; mind-set; perspectives","en","master thesis","","","","","","","","2021-12-06","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:cd320e79-6483-42cb-b26c-97187d3f3ce2","http://resolver.tudelft.nl/uuid:cd320e79-6483-42cb-b26c-97187d3f3ce2","Network-Decentralized Simultaneous Localization and Mapping by Multi-Agent Systems","Witte, Tijmen (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Team Michel Verhaegen)","Giordano, G. (mentor); Mazo, M. (graduation committee); Verhoeven, C.J.M. (graduation committee); Delft University of Technology (degree granting institution)","2019","Multi-Agent Systems (MAS) can be used in the exploration and mapping of unknown environments. To cooperate autonomously, each agent of the MAS must know its own location precisely within such an environment. Simultaneous Localization and Mapping (SLAM) techniques are commonly used when the Global Positioning System (GPS) is unavailable or does not provide sufficient accuracy in positioning the agents. In multi-robot SLAM additional challenges, related to data sharing, arise as the number of robots increases. These additional challenges prevent the multi-robot SLAM solutions to be scaled easily. Network-decentralized state estimation can be used to overcome this problem. The information sharing within multi-agent systems can be modelled based on the topology of a graph. The agents form the nodes and communication is only along the edges of this network. Network-decentralized state estimation consists of designing local state observers for a network of agents to asymptotically estimate their own state based on information exchanges with neighboring agents only. In this thesis, the concepts of network-decentralized position estimation and SLAM are combined to form a novel network-decentralized SLAM which can be used by a multi-agent system in unknown environments to build a map of the surroundings. The network-decentralized SLAM is simulated in MATLAB and evaluated based on different metrics. A volume error metric as well as different timing metrics are introduced. Based on the evaluation of these metrics, it is shown that the proposed network-decentralized SLAM can be easily scaled to larger formations to cover unknown areas faster and in a more robust and accurate way.","Network-decentralized; Multi-Agent systems; Decentralized Estimation; SLAM","en","master thesis","","","","","","","","","","","","Electrical Engineering | Embedded Systems","",""
"uuid:e1cd7309-7ade-4be2-8b2d-b2d40e332095","http://resolver.tudelft.nl/uuid:e1cd7309-7ade-4be2-8b2d-b2d40e332095","Space Time Code for Massive MIMO","RACHURI, Vishnu (TU Delft Electrical Engineering, Mathematics and Computer Science)","Leus, G.J.T. (mentor); Weber, J.H. (graduation committee); Pollin, Sofie (mentor); Guevara, Andrea (graduation committee); Delft University of Technology (degree granting institution)","2019","Ubiquitous connectivity requirements and stringent quality-of-services (QoS)<br/>in recent wireless communications demand new revolutionary wireless network<br/>technologies to support the exponentially increasing traffic growth.<br/>Massive multiple-input-multiple-output (MIMO) with the capability of high<br/>spectral efficiency achieved by large multiplexing and diversity gains grabbed<br/>a lot of attention as a promising solution for future cellular networks. Achieving<br/>ultra-reliable and low latency communication is very challenging without<br/>increasing the network infrastructure cost, or extra processing complexity.<br/>Adapting space-time-block-codes (STBC) can improve the reliability of<br/>the system, but this increases the downlink pilot overhead. Two precoders<br/>are devised to exploit full spatial diversity with the blind combining process<br/>to avoid downlink pilot overhead.","Massive MIMO; STBC; STLC; URLLC","en","master thesis","","","","","","","","2022-09-30","","","","","",""
"uuid:ecb31ded-9b7f-43bf-b726-ce44e8524c57","http://resolver.tudelft.nl/uuid:ecb31ded-9b7f-43bf-b726-ce44e8524c57","Cooperative r-Passivity-Based Control: Development of a Multi-Agent Passivity-Based Control Scheme with Robustness towards Network Effects","de Groot, Oscar (TU Delft Mechanical, Maritime and Materials Engineering)","Keviczky, Tamas (mentor); Delft University of Technology (degree granting institution)","2019","In this work we consider the problem of cooperative formation control between heterogeneous agents when time-varying delays and/or packet loss are present. Specifically, we introduce a control law for nonlinear fully actuated mechanical agents that separates the cooperative coordinates from the local coordinates, which removes the necessity for scenario-dependent tuning. The cooperative outputs encode task-space coordinates and velocities which are transformed into wave-variables to overcome the destabilising effects of the communication network. The cooperative agent couplings incorporate task-space constraints such as collision- and singularity avoidance, while ensuring performance in arbitrary workspaces. The proposed approach improves robustness of existing methods against network effects, and allows to expand their application scope by the inclusion of constraints and nonlinear dynamics. In addition, our approach is scalable by design, and simplifies the tuning task considerably. We demonstrate the efficacy of the proposed approach experimentally.","Formation Control; Collision Avoidance; Passivity-Based Control; Cooperative Control; Scattering Transformation","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:b3b6341a-d9d3-4ebc-af11-b035ae2f66e4","http://resolver.tudelft.nl/uuid:b3b6341a-d9d3-4ebc-af11-b035ae2f66e4","Feasibility study of flushing To Lich River with Red River water through West Lake","Holland, Bram (TU Delft Civil Engineering and Geosciences); Abrahamse, Noor (TU Delft Civil Engineering and Geosciences); van den Brekel, Evelien (TU Delft Civil Engineering and Geosciences); van der Voort Maarschalk, Joost (TU Delft Civil Engineering and Geosciences); Keunen, Oscar (TU Delft Civil Engineering and Geosciences); Janssen, Pauline (TU Delft Civil Engineering and Geosciences)","Bogaard, T.A. (mentor); Gebert, J. (mentor); Mosselman, E. (mentor); Delft University of Technology (degree granting institution)","2019","The goal of this study is to examine the feasibility of this solution, from a water quality and hydraulic point of view. Firstly, the current state of the three water bodies was investigated and a stakeholder analysis was conducted to look into the social and political context. Secondly, the effect of the solution on the water quality in the WL and TLR was researched. The most important water quality parameters were qualitatively discussed and after that, the quantitatively changes in the WL were modelled. A convection-diffusion model was set up for different parameter concentrations in R. The initial parameter concentrations were gathered by field measurements and extensive online research. The water quality assessment shows that the Biochemical Oxygen Demand (BOD), Chemical Oxygen Demand (COD), turbidity and Total Suspended Solids (TSS) concentrations in the RR have a better value than in the WL. The model itself shows for every parameter that after 100 days of mixing the water is not completely mixed in the WL. The water in the TLR is flushed with WL water and its quality is therefore more or less equal to WL water. It is concluded that the proposed solution improves the water quality in the WL and the TLR. However, long and frequent mixing is necessary for the WL water to reach the RR water quality level. Thirdly, a hydraulic analysis was carried out by investigating the hydrological and geometrical characteristics of the three water bodies. Thereafter, the hydraulic impact was examined by comparing six different flushing scenarios.The flow, water depth and sediment transport rates for different time intervals were modelled in R over the distance of the TLR. A Multi Criteria Analysis was done to interpret the results on the consequences in the TLR. The outcome of the optimum scenario is when the gate has an opening height of 5%. The total transported sediment volume is significantly larger in this scenario, which is beneficial. From a hydraulic perspective the proposed solution is feasible for all water bodies. However, more extensive research on for example the impact on the hydraulics in the TLR is needed to get more conclusive results. As a spin-off, our project (co-)developed educational tools that can be used within the HUNRE curriculum and as awareness raising activities in Hanoi with citizens, schools and the like. Fieldwork with Vietnamese students was conducted to start with building a data base on water quality of the water bodies in Hanoi. The tools that are created are manuals, instruction videos and an introduction lecture. Furthermore, the database, that is built, can be extended with more fieldwork in the future. The extent to which the educational tools and the database integrate in the study program of HUNRE remains unsure, however the awareness among Vietnamese students on the importance of water quality has increased. Furthermore, the OKP project strives to realize the integration of the educational tools in the future. Therefore, this research objective is expected to be achieved.","Water management; Hydraulic Engineering; Education; Vietnam","en","student report","","","","","","","","","","","","","CIE4061-09 Multidisciplinary Project",""
"uuid:6bd4cdea-0ed6-4f0f-a24a-69839ae15151","http://resolver.tudelft.nl/uuid:6bd4cdea-0ed6-4f0f-a24a-69839ae15151","Mobility-as-a-Service: Miracle or Misfortune?: Assessing the effects of monthly bundles on travel behavior change in the Netherlands with a combined stated adaptation and stated choice experiment","de Viet, Rein (TU Delft Technology, Policy and Management)","Molin, E.J.E. (mentor); Veeneman, Wijnand (graduation committee); Delft University of Technology (degree granting institution)","2019","Mobility-as-a-Service (MaaS) is a new concept that is expected to make multi-modal travel more seamless, by integrating a variety of different transport modes on a platform, accessible on demand for which monthly bundles can be bought. The hopes of MaaS are that due to the simplicity of the service, and the plethora of alternatives being offered, the need to own a car decreases. As car use starts from car ownership and public transport is regarded as the backbone of MaaS more sustainable travel should be promoted. The expected positive impacts that are being attributed to the implementation of MaaS are however not self-evident. Little empirical evidence is available that supports the effectiveness of MaaS on reaching its attributed goals. This research assesses the effects of MaaS bundles on changing travel behavior of travelers in the Netherlands. Two experiments were integrated into one, namely a stated adaptation experiment, and a stated choice experiment. It was found that the effects of MaaS bundles on improving sustainability and reducing congestion will be very limited. Bundles are currently not likely to be adopted by the people that are thought of as desirable potential adopters. Moreover, bundles are not yet conceived of as viable alternatives for car-ownership by car-owners. Nonetheless, this research showed that MaaS has the potential to change travel behavior. These results thus suggest that MaaS bundles may in fact be used as a mobility management tool in order to stimulate certain travel behavior, but that other ways of diffusion have to be considered instead of adoption by the market.","Mobility-as-a-Service; travel behavior; stated adaptation experiment; stated choice experiment; effects","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:216e393e-031a-4d8d-85e2-1f6c354908a9","http://resolver.tudelft.nl/uuid:216e393e-031a-4d8d-85e2-1f6c354908a9","Ballast for Lifting: A novel lifting method for topsides of offshore platforms","Bakker, Marieke (TU Delft Mechanical, Maritime and Materials Engineering)","Wellens, Peter (mentor); van der Eijk, Martin (graduation committee); Atasoy, Bilge (graduation committee); Advani, Sunjoo (graduation committee); Bailly Guimaraes, Helio (mentor); Delft University of Technology (degree granting institution)","2019","Amazing Grace will be needed for the removal of offshore platforms that are out of Pioneering Spirit 's reach. The base case design of Amazing Grace is an enlarged version of Pioneering Spirit (Figure 1). Amazing Grace uses mainly Quick drop Ballast tanks, releasing a lot of water at once, for lifting. Pioneering Spirit uses mainly a pneumatic-hydraulic system for fast lifting. The idea is to lift bigger platforms with a less complex system. The behaviour of the base case design of Amazing Grace when lifting the upper part of an offshore platform (topside) from its supporting structure (jacket) is studied in this work and the feasibility of the new Quick drop Ballast system is tested. To perform a feasibility study on lifting topsides with Amazing Grace , a set of design requirements is generated. Before using these design requirements, a one tank model is required to simulate the emptying of a tank. The dimensions of an existing Pioneering Spirit Quick drop Ballast tank are used. The model is validated by comparing its output to existing physical test data of emptying the same tank. To lift by means of heave only, a bigger volume is used for the one tank model. Once the Quick drop Ballast concept shows to be feasible, the next step is to introduce waves. Waves are modelled using the linear superposition method. An estimation of the time series duration is done by computing the standard deviation of the heave amplitude. For a converged standard deviation, the time series' minimum length needs to be 1200 seconds. The maximum heave amplitude, derived from another statistical analysis, is applied to the connection plateau (when Amazing Grace connects and starts lifting the topside without creating clearance). The results show that Amazing Grace 's mass, added mass, damping and stiffness (the coefficients of the equation of motion) need to be included to give a more accurate estimation of the dynamics for connecting Amazing Grace to the topside and the possible rebounce to the jacket. Although this is a conceptual study, the dynamics are included to get a better understanding of Amazing Grace 's response. To include the previously mentioned coefficients of the equation of motion, the Cummins equation is implemented. The excitation forces are the sum of the wave- and the Quick drop Ballast force. The Quick drop Ballast force is derived from the one tank model. A convergence study shows which time step is needed for this model to work accurately considering its application. The implementation of the Cummins' equation is verified by showing agreement between time- and frequency domain. A sensitivity analysis is used to show the effect of changing the model's main variables. The peak period has the biggest influence on Amazing Grace 's heave motion. By varying the coefficients of Cummins' equation in the range of 35.5 - 38 meters draught, the computed vessel motions show that the variation of the draught only has little influence. The Quick drop Ballast system is feasible for both the pretension- and fast lift phase when applying the Quick drop Ballast force at the centre of gravity. The Quick drop Ballast force vector is partly relocated at the bow for applying trim during fast lift. A comparison shows that both the required volume and the number of valves reduce by one third compared to the heave only concept. The maximum allowable trim per length of Amazing Grace is 1.5 meter. This maximum is exceeded by 0.2 meters. The 0.2 meters needs to be included for a future topside lift system (TLS) design. It is recommended to apply trim during fast lift since this simplifies the complexity of the Quick drop Ballast system by reducing the required volume of water and the number of valves.","Ballast; Offshore; Lifting; Topside; Decommissioning","en","master thesis","","","","","","","","","","","","Offshore and Dredging Engineering | Floating Offshore Structure","",""
"uuid:7d8adb2e-b4ee-48c0-b068-e9bcfd5060ec","http://resolver.tudelft.nl/uuid:7d8adb2e-b4ee-48c0-b068-e9bcfd5060ec","Finding similarities between the deep mantle structures of Earth &amp; Mercury","Mulder, Liselotte (TU Delft Aerospace Engineering)","Root, B.C. (mentor); van der Wal, W. (graduation committee); Speretta, S. (graduation committee); Delft University of Technology (degree granting institution)","2019","Large Low Shear-Velocity Provinces (LLSVPs) in Earth have been recognized in seismic data for several decades. The anomalies are however still poorly understood for reasons including their inconvenient location in the deep mantle, inhibiting progress in our understanding. Comprehension of these structures is important, because of their speculated major role in the formation and evolution of the Earth, and her residents. The gravity anomaly associated with the LLSVPs, the C22-lobs, are roughly observed in the gravity field of Mercury too. Therefore, the gravity and topography data about Mercury is assessed for indications of similar deep mantle features as observed in Earth. The advantage of Mercury is its thin mantle, that allows for a relatively shallow location of the core-mantle boundary (CMB), hence shallow deep mantle anomalies. The cause of the thin mantle is yet unknown, currently suggested explanations include vaporization of the mantle due to the immense heat of the solar nebula or a hit-and-run collision scenario that ripped off the mantle of Mercury. In this research it is investigated how deep mantle structures like LLSVPs and CMB topography could account for the gravity field of Mercury. It is concluded that deep mantle structures with comparable size and density characteristics as the LLSVPs in Earth could exist. Compensation by CMB topography would require a rough CMB. The results are highly affected by the limited knowledge about crustal compensation in Mercury and the truncation of the gravity field. Better crustal models of Mercury could be obtained by investigating local gravity anomalies in relation to topographic features, considering flexural isostasy and using normal modes. In addition to that, BepiColombo is currently en route to Mercury to gather more global data of Mercury, that would highly aid in our understanding of the crust and mantle of Mercury. A relation comparable to the hypothesised relation between hotspot volcanism and LLSVPs on Earth is also investigated for Mercury. A relation was not necessarily observed, however it was also not ruled out and requires more attention as soon as the crustal models have improved and more global coverage of volcanic features on Mercury is available.","Mercury; LLSVPs; deep mantle structure; gravity; crust; basal layer","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:5b3cd9c8-3b09-405f-90e1-940d7df934ee","http://resolver.tudelft.nl/uuid:5b3cd9c8-3b09-405f-90e1-940d7df934ee","The possibilities of Hybrid steel-FRP bridges in movable highway spans","van der Wateren, Maarten (TU Delft Civil Engineering and Geosciences)","Pavlovic, M. (mentor); Hendriks, M.A.N. (graduation committee); Abspoel, R. (graduation committee); Hylkema, Björn (graduation committee); Delft University of Technology (degree granting institution)","2019","The increasing number of vehicles does not stop, axle loads get higher and wheel contact surfaces have decreased causing bridges to show significant fatigue damage. Demolishing and building a new bridge is out of the picture due to the current ideas on sustainability and environmental impact. Therefore renovation is necessary, as much of the existing structures should be reused in the design of a new structure. This results in massive challenges especially in the design of new movable bridge leaves which should reuse the pillars and foundation of the current bridge. The weight of the new movable bridge is limited to the same or even less than the old one, but should outperform it by many years. Parametric models have been created for both bridge types, orthotropic and hybrid, using finite element software RFEM to quantify this added. Both bridge models have been exposed to the same load cases stated in the Eurocode for traffic loads and fatigue loads. Maximum deflection and stresses have been verified in the steel of both bridges for the traffic loads. The sandwich panel has been verified for buckling and fatigue using a local model. The fatigue load cases have been used to verify the bridges steel frame. Global fatigue details in the connection between main girder and crossbeams have been investigated. Results showed a clear favour towards the hybrid bridge for all of the spans and widths investigated. The difference in weight of the hybrid bridges showed a decrease of 15 to 30% as opposed to the orthotropic steel bridge. This decrease in weight was mainly caused by the difference in deck structure. The sandwich panel, with a weight of 85 kilograms per square meter, shows far less weight contribution in the hybrid bridge than the stiffeners and deck plate, with a combined weight of 256 kilograms per square meter, have in the steel orthotropic bridge. A cost comparison showed that the OSD bridge and hybrid bridge are competitive in pricing in an early design stage. However there are many uncertainties that could result in one of the bridge types being significantly more expensive than the other. More experience with FRP and the hybrid interaction is needed to create better cost indications in such an early design stage. The environmental impact showed a difference ranging from 10% to 30% in favour of the hybrid bridge for both the CO2 impact analysis and the life cycle analysis by GWW. This difference was obtained when considering the production of the movable bridge including the counterweight and span. The difference is mainly due to the large amount of steel needed for the bridge leaf of the steel orthotropic bridge which also means that more material is needed for the counterweight. Although further research is necessary, this report shows the added value of hybrid bridges with full hybrid interaction and creates a step towards more use of hybrid steel and fibre reinforced polymer structures.<br","Hybrid deck; Orthotropic steel deck; Sandwich panel; Fibre Reinforced Polymers; Fatigue resistance; Parametric Design","en","master thesis","","","","","","","","","","","","Civil Engineering | Structural Engineering","",""
"uuid:65000364-7666-457b-b5cd-808e26ed1d68","http://resolver.tudelft.nl/uuid:65000364-7666-457b-b5cd-808e26ed1d68","Multi-criteria decision making for improvement of security and efficiency at airport security checkpoints using agent-based models","Mekić, Adin (TU Delft Aerospace Engineering)","Janssen, Stef (mentor); Sharpanskykh, Alexei (mentor); Delft University of Technology (degree granting institution)","2019","Agent-based modelling and simulation has shown to be a suitable paradigm for analyzing complex airport systems, such as airport security checkpoints. The models can be used to analyze important airport terminal performance areas, such as security and efficiency. However, limited knowledge exists on how agent-based models can be used to aid airport managers in their decision making. The agent-based models allow to estimate the criteria of the alternatives of a decision problem, but without criteria weights and score aggregation, the alternatives can not be compared or ranked. The main branch of techniques to establish weights for multiple criteria such that a score can be aggregated for decisions is called multi-criteria decision making. Thus, integrating multi-criteria decision making methods with agent-based models is a method to provide decision support for airport managers. Therefore, this research aims to answer how multi-criteria decision making methods can be integrated with agent-based models to provide decision aid to airport terminal decision makers with the aim of improving security and efficiency. To answer this research question, a methodology was proposed which combines agent-based models, multi-criteria decision making, discrete choice models, and expert knowledge. The methodology is applied to a case study in which several alternatives of configuring personnel are available. The results show that efficiency focused operators, which have low accuracy, introduce most variance between best and worst alternatives. The best alternatives have efficiency focused operators placed on peak hours because they decrease the queue in the peak hours, while maximizing overall hit rate because less passengers pass per lane in peak hours compared to non-peak hours. For realistic variations of operator performance, operator placement is found to have a significant influence on security checkpoint performance.","Agent-based simulation; Multi-criteria decision making; Discrete Choice Modelling; Airport Security; Airport Efficiency; Trade-off","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:0f113c67-02ef-4d2d-a890-b0c45ff48a3c","http://resolver.tudelft.nl/uuid:0f113c67-02ef-4d2d-a890-b0c45ff48a3c","Improving radiation safety for hospital staff during interventional surgery","Gudde, Tom (TU Delft Industrial Design Engineering)","van Heur, Rudolf (mentor); Beets, Margreet (graduation committee); Bloemen, Bert (graduation committee); Delft University of Technology (degree granting institution)","2019","Radiation is increasingly used to treat otherwise dangerous operations such as valve replacements with minimal consequences for the patient using live X-ray and catheters. These minimal invasive interventions are beneficial for the patient but physicians are exposed to high doses of radiation as a result. Products in the market of radiation protection are focusing on physical barriers for the radiation such as lead aprons and acrylic lead shields. Although effective, these are often not properly used, which increases the risk for exposure. Next to this, new products will enter a highly saturated market with vast generic alternatives. A design opportunity was found in the range of product aiming for training of physicians to properly work with radiation. From interviews and observations, it was concluded that there is no commons census among cardiologists regarding where the dangerous scatter radiation is present surrounding the patient. It is therefore vital to train or even reprogram their instinctive mind to have a clear idea about the presence of scatter in the OR; radiation safety through behavior change. Philips is involved in a strategy that is called the Quadruple aim. Where the current focus is more directed to the patient experience, the quadruple aim also includes the staff experience as a large influence in better healthcare. A product concept is created where staff experience is key. With this direction Philips will fill a gap in the market for training products and create a common census for safe radiation behavior. Introduced to new generations of hybrid OR’s as the Exposure Prevention Package (EPP), the concept solution will provide a set of clear indicators for safe radiation conduct. Physicians and other staff can now identify when they are exposed to the harmful, but invisible, radiation and act upon it. Through further involvement in the hospital itself Philips will be engaged in an introduction phase of their systems. This includes a introductory course in which operators learn to work with the system and at the same time experience a “learning by doing” style radiation safety course.","Radiation; Interventional cardiology; Radiation shielding; Scatter radiation; Philips Healthcare; Staff safety","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:9d5e78c9-0211-4b0c-8593-daba2ee0fdb6","http://resolver.tudelft.nl/uuid:9d5e78c9-0211-4b0c-8593-daba2ee0fdb6","Outlier detection in non-Gaussian distributions","Maas, Youri (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Delft Institute of Applied Mathematics)","Cai, Juanjuan (mentor); Meester, Ludolf (graduation committee); Keijzer, Marleen (graduation committee); Delft University of Technology (degree granting institution)","2019","In this thesis we are going to study outlier detection methods and propose a new method. Classical outlier detection is typically based on the assumption that the data is from a Gaussian/normal distribution. When the underlying distribution of a random sample is heavy tailed, so not normal , it is likely to have some extreme observations which would be identified as outlier using the classical procedure. This paper aims to address this issue by proposing a procedure<br/>to identify real ‘outliers’ for heavy tailed data set. We first dive in the some existing methods and see how they work, try to understand them, simulate them and see their shortcomings in the case of a heavy tailed distribution. Then we study Extreme Value Theory (EVT) which we shall use to set up our proposed method of detecting outliers. Once we have constructed the proposed method, we are going to simulate and compare it with the existing methods. The goal in the case of normality is that the new method is not worse than the existing ones, at least not extremely, and in the case of a heavy tailed function to work better.","Outlier detection; Extreme Value Theory; statistical analysis","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics","Bachelor End Project",""
"uuid:ace20544-9a0c-4b2a-aadc-faf30e4896c7","http://resolver.tudelft.nl/uuid:ace20544-9a0c-4b2a-aadc-faf30e4896c7","Beyond Monetary value: An alternative approach to creating value with innovation","Lukkes, Bart (TU Delft Industrial Design Engineering)","Smulders, Frido (mentor); Bluemink, Bart (graduation committee); Janssen, Albert (graduation committee); Delft University of Technology (degree granting institution)","2019","This thesis answers the question: “How can we generate and maximise value from technologies that sit in the periphery of the technology development ecosystem?”. The launchpad innovation strategy provides the solution. A technology in the periphery of the development eco-system fell out of development after changes to the technology strategy. The project owner remained adamant that there was value to the product if licensed. The goal was to create value, and the product was developed to create as much value as possible to its users. But rather than designing a product to create value for the user, turning those roles around provided an interesting perspective. By designing a strategy to create value for the company from this type of technology product an interesting strategy was designed. The strategy’s aim is to create as much value as possible, but rather than focus on revenue, it looks at what technology can create that creates long term benefits. The strategy revolves around creating a type of company that sits between a corporate startup and a spinout with the purpose of commercialising the technology. The companies are autonomous but have close contacts to the mother company allowing for the exchange of money, information, people and most important knowledge. This is the launchpad strategy.","Technology Commercialization; Strategy development; Design for value; Launchpad","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:556fc976-5f8e-4e17-aae3-c5e051cb4b72","http://resolver.tudelft.nl/uuid:556fc976-5f8e-4e17-aae3-c5e051cb4b72","Safety assessment of the interaction between an automated vehicle and a cyclist","Oskina, Maria (TU Delft Civil Engineering and Geosciences)","van Arem, Bart (mentor); Farah, Haneen (mentor); Morsink, Peter (mentor); Happee, Riender (mentor); Delft University of Technology (degree granting institution)","2019","The operation of automated vehicles in shared areas requires attention with respect to the interaction between AVs and vulnerable road users, including cyclists. Currently, the programmed interaction behavior of AVs is based on the knowledge of the interaction between conventional vehicles and cyclists. However, cyclists may react differently to conventional and automated vehicles. Therefore, this research applies field test experiment to investigate the risks resulting from the interaction between cyclist and an AV. Four possible interaction scenarios were investigated in within-subject design with overtaking speed, overtaking distance and right-hand side objects as attributes. Objective Risk is assessed using the Probabilistic Driving Risk Field and Subjective Risk is assessed based on the self-reported values, cyclist behavior and trust. Results show that in general following has less risk than overtaking. Automated following and manual following have the same level of Objective and Subjective risks, while the automated overtaking has higher risks than manual overtaking. However, results also show that a larger interaction time leads to an increase in cycling speed and decrease in the distance to the curb. Furthermore, in the following maneuver the interaction time is higher than in the overtaking maneuver. Besides high time of interaction, closer overtaking distance and green grass on the right-hand side affect the increase in subjective and objective risks.","Automated vehicles; Vulnerable Road User; Subjective risk; Objective risk","en","master thesis","","","","","","","","","","","","Transport, Infrastructure and Logistics","",""
"uuid:47d51267-3356-454a-8f68-27ac0d4b3d7c","http://resolver.tudelft.nl/uuid:47d51267-3356-454a-8f68-27ac0d4b3d7c","How mature are your lead time estimations?: The proposal of a planning and estimation maturity framework for the maritime industry","Bregt, Tijmen (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Ship Design, Production and Operations)","Pruijn, J.F.J. (mentor); Reppa, V. (graduation committee); Mallee, Nick (mentor); Hopman, J.J. (graduation committee); Delft University of Technology (degree granting institution)","2019","During the start of a project organisations make estimation on the expected amount of work and the corresponding project duration, the lead time. To make these estimations with a low uncertainty is important because a false estimation could result in cost overruns and project delay. This paper proposes an estimation and planning maturity framework where organisation can asses which methods can be used to ensure the estimation and planning are performed to the lowest possible uncertainty. The framework was implemented at a case study organisation, it was found that selecting the correct estimation and planning methods can result in a lead time estimation with a low uncertainty. ","maturity model; lead times; Estimation; man-hours","en","master thesis","","","","","","","","","","","","Marine Technology | Ship Design, Production and Operations","",""
"uuid:49a9d185-6889-46f2-90dd-7e3fbfe0a392","http://resolver.tudelft.nl/uuid:49a9d185-6889-46f2-90dd-7e3fbfe0a392","Mechanical Metamaterials by Topology Optimization","Blokland, Geert (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Precision and Microsystems Engineering)","Langelaar, M. (graduation committee); Koppen, S. (graduation committee); Delft University of Technology (degree granting institution)","2019","Auxetic materials exhibit material properties, which are usually not seen in nature. This type of materials belong to the class of mechanical metamaterials and can be used for e.g. energy absorption, cloaking of objects, shape morphing applications and the design of fiber-reinforced composites. They exhibit a negative Poisson’s value and derive their unusual properties from their architecture and are arranged in a pattern of unit cells. However, the design of their architecture is limited by the combination of degrees of freedom and therefore, a topology optimization (TO) procedure is utilized to allow sufficient design freedom. This thesis focuses on the generation, numerical and experimental validation of mechanical metamaterials. Auxetic unit cells are generated using an energy-based TO approach with periodic boundary conditions, with a valid response in the linear elastic regime. A patch of unit cells is numerically investigated for suitable test conditions and auxetic designs are fabricated for testing purposes using the fused deposit modeling (FDM) technique. The possibilities and shortcomings of this print technique are explored and relevant findings came out. Finally, compression tests of the as-printed auxetic designs are conducted to validate the auxetic behavior in practice. This thesis shows that the experimentally tested novel auxetic designs generate new knowledge towards the validation of mechanical metamaterials. It has been shown that the upcoming and user-friendly additive manufacturing technique, (FDM), is suited to generate and validate optimized geometries.","mechanical metamaterials; Topology Optimization; Additive Manufacturing; Experimental validation","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Precision and Microsystems Engineering","",""
"uuid:582440d0-88ca-4996-a2ce-a502cd2bf770","http://resolver.tudelft.nl/uuid:582440d0-88ca-4996-a2ce-a502cd2bf770","BM design for Impact Startups: A value flow approach to reverse impact barriers and transform catalysts in strategic opportunities","Marsaglia, Giulia (TU Delft Industrial Design Engineering)","Simonse, LWL (mentor); van der Bijl-Brouwer, M. (graduation committee); Delft University of Technology (degree granting institution)","2019","The domain of Sustainable Development innovation is facing a significant transformation. Several trends, social, political, economical forces and players are concurring in the rise the concept of impact on sustainable development challenges. That is being introduces in the strategies of big and small enterprises, at different degrees, varying from innovations along the value chain to small adaptive tactics keeping the pace with the latest governmental regulation in matters of emissions reductions, workforce welfare etc. <br/>Moreover, a growing number of emerging startups already include sustainable development challenges in their DNA as a main mission -often called Impact Startups. However, being hybrids with ambitious impact change goals and financial sustainability needs, they often struggle to survive and develop models of impact. In this context, BMI Lab is a consultancy supporting organisations with business model innovation. The current process does not account for ‘impact drivers’ in the equation for business model generation, therefore does not have the capabilities to support impact startups, and will need to evolve to do so. The project arouse from the knowledge gap of including Sustainable Development Impact as an additional driver in business model generation.<br/>The aim is to provide a strategic design angle to complement the Business Model Design Sprint, based on an explorative approach over the impact factors and challenges in achieving impact models. First, the concept of impact model is defined, then based on field immersion, impact entrepreneurs and experts stories and interviews, and academic sources, the research identifies a set of critical activities that could positively influence the development of impact models. Those have been embedded in a toolkit. The toolkit takes place in the first day of a BMI Lab BM generation Sprint and aims at guiding through the identification of new opportunities that align SD goals and viability. It consist of four main stages focusing on the value exchanged with the ecosystem of intervention.","impact models; business model; startups","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:03007cee-a8cf-4906-8da8-c6e237d5277f","http://resolver.tudelft.nl/uuid:03007cee-a8cf-4906-8da8-c6e237d5277f","Game and Choice Based Simulation: The design of a methodological framework using the case of the Physical Internet inspired “Freight Transportation Game”","Caminada, Sytze (TU Delft Technology, Policy and Management)","Tavasszy, Lorant (mentor); Atasoy, B. (graduation committee); Bekebrede, G. (graduation committee); Lafkihi, Mariam (graduation committee); Delft University of Technology (degree granting institution)","2019","Serious games have the potential to be used as an innovative data collection method. Combining this with Discrete Choice Modelling (DCM) could create a methodology that provides insight into the player's behaviour and allows for creating a realistic simulation. This innovative Game and Choice Based Simulation (GCBS) methodology has been conducted and evaluated using the case of the Physical Internet inspired “Freight Transportation Game”. The bidding behaviour of players is analysed using DCM. Using the insights obtained from the estimated choice model, a decision support tool for carriers is defined as a policy to optimise the system’s performance. Hereafter, the DCM is implemented into a simulation based on the gameplay, creating a realistic simulation of the PI inspired transportation market. By conducting a simulation experiment with this innovative simulation, the policy could be successfully evaluated. Considering this case of application, the GCBS methodology proved its potential. Using insights obtained during the research, a framework for GCBS has been designed explaining when and how to conduct the methodology. More research needs to be done to test the (external) validity of the decision support tool and to test and extend the methodological framework in order to increase its robustness.","Serious Gaming; Discrete Choice Modelling; Simulation; Collecting Choice Data; Physical Internet; Freight Transportation Market; Decision support tool","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:5881b04b-fe32-45b0-8e68-a74e450041a1","http://resolver.tudelft.nl/uuid:5881b04b-fe32-45b0-8e68-a74e450041a1","Designing a co-creation tool for an innovation platform in the Dutch e-government","Meijer, Koen (TU Delft Technology, Policy and Management)","Bharosa, N. (graduation committee); Janssen, M.F.W.H.A. (mentor); van der Voort, H.G. (graduation committee); van Engelenburg, S.H. (graduation committee); van Dokkum, Thanim (graduation committee); Delft University of Technology (degree granting institution)","2019","Digitization often comes with its challenges. This thesis focuses on a new approach to innovating digital public services in the Netherlands. Innovation in the public sector encounters public sector specific innovation barriers, hampering the innovation process. Innovation in the public sector is still a little researched topic in the innovation literature. The co-creation lab is a proposed solution to overcome the innovation barriers through collaboration for innovation and experiments for innovation. Both of these have proposed benefits. Collaboration for innovation increases innovativeness and aids in creating ideas that are prone to adoption. Experimentation for innovation creates learning opportunities, increases the effectiveness of innovation processes, and proposes a solution to overcome governmental innovation barriers.<br/>While the potential benefits of the co-creation lab are understood, it is unclear how the co-creation lab should be operationalized. This is the basis for the main research problem: Although experimentation and collaboration for innovation are adopted to overcome the government’s innovation barriers, it is not clear how to make those concepts operational in the co-creation lab. A tool is designed to support the co-creation lab’s operations. The design of the tool is the goal of the main research question: How can a co-creation tool be designed for a governmental innovation platform in which experiments are conducted with governmental IT infrastructures to foster innovation in the Dutch e-government? The co-creation tool is a tool that supports the co-creation lab in its operations to enable collaborations and to perform experiments. The main research question aims to solve the six challenges that are attached to the research problem: meager research into innovation in the public sector, the adoption of the quadruple helix model, enabling co-creation, requirements to perform experiments, the conditions of the technology used in experiments, and enabling use and reuse of already existing knowledge. The research is based on the design science research methodology of Peffers, Tuunanen, Rothenberger, &amp; Chatterjee (2007), which focuses on design research of Information Systems (IS). This thesis alters the activities to create three research phases: discovery, utilization, and design. For the discovery phase, a review is carried out of relevant scientific literature related to the research challenges. Also, semi-structured interviews are conducted with five people close to the Digicampus to discover the current innovation journey for digital innovations in the Dutch government. The utilization phase is carried out by creating use cases about the process of the experiments according to the UML standard. From the use cases, functional requirements are derived. The design phase is carried out by creating a prototype of the co-creation tool. The UX program Sketch is used to create the prototype. The prototype is evaluated in an interactive workshop. The outcome of this research is a UX/UI design prototype of the co-creation tool. The tool’s design is a website that discloses the required information to support the innovation journey of innovators in the public sector.","Co-creation; Open Innovation; Innovation platform; Experimentation; Experimental platform; E-government; Quadruple helix; Governmental IT infrastructures","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:1b8b8008-3487-4bed-9702-691d65c69ce6","http://resolver.tudelft.nl/uuid:1b8b8008-3487-4bed-9702-691d65c69ce6","Sustainability assessment of quay wall development in the Port of Rotterdam","van Rhede van der Kloot, Godert (TU Delft Civil Engineering and Geosciences; TU Delft Rivers, Ports, Waterways and Dredging Engineering; Port of Rotterdam Authority)","van Koningsveld, Mark (mentor); Taneja, Poonam (mentor); Annema, Jan Anne (mentor); Broos, Erik (mentor); Bosschieter, Caroline (mentor); Delft University of Technology (degree granting institution)","2019","The current social climate in which sustainable awareness is prioritized, is affecting the port sector. In new-to-develop ports and in the expansion and maintenance of existing ports, implementing sustainability is  encouraged.However, applying sustainability is not self-evident. In order to achieve sustainability targets and to comply with the environmental laws, port authorities should be able to define and quantify sustainability. This research aims to define, quantify and improve sustainability in quay wall development, which is a most common infrastructure component in port development. The first step of this research is to develop a framework to assess port infrastructure on its sustainability performance. Following the Frame of Reference method (van Koningsveld &amp; Mulder, 2004), the Framework ofSustainable Port Infrastructure (FoSPI) has been developed. The FoSPI consists of fourteen aspects of sustainability that has been derived from literature, which can be applied to all port infrastructure assets. Each aspect includes one of more targets that are determined by the company and/or by the location’s regulations. Furthermore each of these targets requires their own quantification tool, reference base, intervention measures and evaluation procedure. These are dependent on the location and the type of port infrastructure asset. If the target(s) is (are) achieved, this would mean that the infrastructure has reached a more sustainable level on this aspect. All fourteen aspects should meet their target(s) to conclude that the infrastructure has reached a more sustainable level. The FoSPI has been applied to quay wall development in the Port of Rotterdam(PoR) and this resulted that only four out of fourteen can be specified to be further assessed. The remaining eleven aspects should be investigated further to assess quay wall development in total. As the PoR has prioritizedGreenhouse Gas (GHG) emissions (this was based on literature and interviews within the port), this thesis will focus on the the GHG emissions of the aspect ’Air pollutants’ in quay wall development. Nevertheless, theway this GHG target was included in the analysis can also be used for other sustainability aspects for which the company has a target.The second step of the research is to determine the actual value of GHG emission of a current quay wall project. To do this, an evaluation procedure and quantification tool was selected. The author proposed to quantify a 100meter standard short sea quay wall of the PoR with a life time of 100 years as the reference base case. A tool is selected that is able to quantify GHG emission, is objective and represents actual quay wall development. Usingliterature sources, the tool DuboCalc is proposed, because it is based on the life cycle analysis, is sector specific and is simplified (compared to other tools). However, the tool should be handled with a certain caution. The research showed that the results are not 100 % reproducible. However, when a thorough check and evaluation is part of the process, the results will converge. In the research, the results of the exercise had a percentage relative range of 28 %, but after a thorough check and evaluation, the second results achieved a range of 8 %.Secondly, DuboCalc doesn’t include all quay wall objects, hence it will give an approximately GHG emission. The tool has room for improvements. The tool is used to quantify the reference base by using an actual PoR project, the HHTT terminal as the case study. This resulted in a total emission of 1.9 kt of CO2-eq for a 100 meter standard PoR short sea quay wall with a life time of 100 years.The third step of this research is to determine how the PoR can reach their GHG targets. The reduction measures to achieve the target of being climate neutrality in 2050, are discussed. A summation of suitable measures from multiple reports of PoR is made. Using literature, DuboCalc data and the case study, the most suitable measures were quantified for the PoR. It is concluded that the PoR should focus on the largest contributors of GHG emission. The following actions are advised: As from 2020, renewable energy could be used for the Impressed Current Cathodic Protection (ICCP) which could lead to 15% reduction in GHG emissions over the quay wall’s life cycle. The transition from fossil electricity to renewable electricity is without extra investment costs. Secondly, using renewable energy instead of diesel for the temporary drainage systems will reduce the emission with 14 %. Including previous actions a total reduction of 29 % is achieved. The costs of the amount of renewable electricity is lower than the required amount of diesel. Thirdly, if the PoR will invest approx. 170 euro for every saved CO2-eq, Hydrotreated Vegetable Oil (HVO) can be used as an alternative fuel for dredging to reduce emission with 8 %. Including previousactions a total reduction of 37 % is achieved. Further research could be done in alternative designs. This could lead to a reduction in concrete and steeluse, as they are the larger contributors. Alternative designs includes quay walls made out of Recycled High Density PolyEthylene (RE-HDPE), smaller dimensions of steel piles and prefab concrete quay walls with geo-polymer-based-cements.The evaluation procedure in which the quay wall is monitored every five years, could be implemented. This will help to evaluate the applied intervention measures and to oversee if the targets are going to be achieved. It will be part of the strategical planning of the PoR. Furthermore, the PoR could encourage the constructors to use electrified transport (on commercial scale available around 2025) and machinery (on commercial scale available around 2030) to reduce emission with 3 % and 11 % respectively. Including previous actions a total reduction of 51 % is achieved. Finally, anticipating long term technical innovation in concrete with Carbon Capture and Storage (CCS) (on commercial scale available around 2030), hydrogen as dredging fuel (on commercial scale available around 2050) and steel with hydrogen as reduction-agent (on commercial scale available around 2050). This could reduce emission with 9%, 10 % and 24 % respectively. Including previous actions, except use of HVO, a total reduction of 86 % is achieved. Although the calculated reduction of GHG emission in 2050 does not satisfy the target of being climate neutral, the potential reduction of 86 % is a considerable improvement. For the PoR case, the described three-step approach has led to an improved insight in sustainability of quay wall development, and to specific recommendations to reduce the GHG emission.The method is applied to quay walls and to the PoR, but it can be applied generally as well, provided that the targets are adapted to the concerned company and its location, and the quantification tool, the reference base and the intervention measures are adapted to the type of asset and the location.The research does contain various limitations, namely only one target of one aspect could have been investigated in depth, although the influence of the proposed solutions on the other aspects is not considered. It is recommended that this influence should be determined to see if the targets of other aspects of sustainability are met as well.","Sustainability performacne; Carbon footprint; Quay walls; Port of Rotterdam; Frame of Reference","en","master thesis","","","","","","","","","","","","Civil Engineering | Hydraulic Engineering","",""
"uuid:b457c9c3-922e-4016-9580-f79a2549128d","http://resolver.tudelft.nl/uuid:b457c9c3-922e-4016-9580-f79a2549128d","A framework for the impact assessment of low discharges on the performance of inland waterway transport","Kievits, Servaas (TU Delft Civil Engineering and Geosciences; TU Delft Hydraulic Engineering; TU Delft Rivers, Ports, Waterways and Dredging Engineering)","van Koningsveld, Mark (mentor); Lansen, Joost (graduation committee); van Gelder, Pieter (graduation committee); Taneja, Poonam (graduation committee); Bos, Matthijs (graduation committee); Delft University of Technology (degree granting institution)","2019","Inland waterway transport (IWT) is one of the three main modalities for inland transport of dry, liquid and containerized cargo. As IWT performs well on cost-competitiveness, environmental friendliness, and congestion-related issues, authorities strive to shift freight transport from road to water. Inland waterway connections, however, are vulnerable to the growing impact of climate change. A combination of higher temperatures and more extreme seasonal differences in precipitation is expected to increasingly impact river discharge in the future. In summer, this will result in low water events happening more frequent and more intense. The effects of climate change on IWT could result in a reduced annual transport capacity, thereby weakening the reputation of IWT and increasing the costs of cargo shipment. The objective of this research is to provide more insight into the consequences of climate change-induced low discharges on the performance of IWT and to assist in making justified adaptation decisions. During this research, an IWT performance model has been developed that is capable of studying the capacity and vulnerability of the inland waterway system to low water depths, and simultaneously can be used to propose measures to strengthen the position of IWT. To assess the quality of the logistic simulations, the model has successfully been subjected to a number of validity tests. Consequently, the model was calibrated on two parameters that have a high uncertainty and a significant impact on the simulation. After calibration, the model shows correlation coefficients of r=0.794 and r=0.921 so that it can be concluded that the results of the IWT performance model are relatively accurate with reality. Daily projections of the water depth on the Rhine are obtained by extrapolation of the representative, dry year 1976 with two climate scenarios to the year 2050. The water depths encountered have been compared to the base scenario. To put into perspective these impacts, a model run for the reference scenario of 2018 has been incorporated in the comparison. It follows from this thesis that low discharges, in combination with navigational restrictions, could cause substantial losses for the IWT in 2050 in terms of transported cargo and transport costs. Following from literature, the accurate modelling of IWT should include various local effects that follow from regulations, fleet composition or waterway characteristics. This research is the first study on the impact of low water depths on the IWT performance that does not take the load factor as the only variable but that includes other network parameters as the active fleet size and the number of trips to provide a comprehensive picture of the IWT performance in periods of low discharge.","IWT; Drought; Network performance; Discrete Event Simulation; Agent Based Simulation; Adaptation; Framework","en","master thesis","","","","","","","","","","","","Civil Engineering | Hydraulic Engineering","",""
"uuid:d03db8a6-7cbb-4ac4-884c-142429fd85f2","http://resolver.tudelft.nl/uuid:d03db8a6-7cbb-4ac4-884c-142429fd85f2","Influence of 3D City Layout on Air Quality","Lánský, Imke (TU Delft Architecture and the Built Environment); Ceccarelli, Giulia (TU Delft Architecture and the Built Environment); Mastorakis, Konstantinos (TU Delft Architecture and the Built Environment); de Jongh, Wessel (TU Delft Architecture and the Built Environment); Li, Jinglan (TU Delft Architecture and the Built Environment)","Garcia Sanchez, C. (mentor); Stoter, J.E. (mentor); Delft University of Technology (degree granting institution)","2019","In 2021, noise pollution monitoring will be mandatory in the Netherlands, which requires data on traffic that can be re-used for air quality estimation models. One of the important input parameters for the latter is the street type, which is required by the dilution parametrisation used within the air quality model.<br/>The goal of this project is to show whether automatic street classification for air quality estimation is feasible and reliable, considering the geo-spatial data currently available in The Netherlands. The motivation for this project originates from the common data used in noise and air quality monitoring tools by the Dutch National Institute for Public Health and the Environment, (RIVM).<br/>Currently, street classification is performed manually by many municipalities. The larger municipalities are legally obliged to monitor air quality levels, which makes use of the street types. Automating the process by using existing datasets can save a lot of time, costs, and resources, while providing standardised results in comparison to manual classification. In addition, our method is extendable to the whole of the Netherlands. Consequently, our method can have a large societal impact, since it allows the provision of air quality estimations for all municipalities; even those that are not yet required to do so. To our knowledge, no similar work has been conducted in this field, which made it even a bigger challenge.<br/>The implementation of the automatic classification algorithm, which is thoroughly explained in this re- port, shows very promising results. We first tested the approaches in a small area, the Weesperstraat in Amsterdam, where we have success rates from 76.7% to 83.3% for the different classification methods when compared to the NSL classification. After evaluating the performance of each of the methods, the optimal approach has been tested on larger areas where visual inspection shows a priori promising results as well.<br/>In addition to the automatic classification algorithm, air quality measurements with new Flow sensors from Plume Labs were performed in the city of Amsterdam. The goal was to investigate whether different street types can be identified through the use of small air quality sensors. The limited measurements did not provide distinct patterns for the different street types, and therefore identification based on pollutant concentrations was not possible within the project.<br/>We hope that the results of this project will motivate public bodies and agencies in the Netherlands to invest in automated workflows using currently available and high accuracy geo-spatial data. This can potentially improve their efficiency, while creating a more standardised and scalable framework.","synthesis; 3d geodata; air pollution","en","student report","","","","","","","","","","","","Geomatics","Synthesis Project 2019",""
"uuid:08f2c0b4-2aa8-4e12-9b58-073dcdfb4553","http://resolver.tudelft.nl/uuid:08f2c0b4-2aa8-4e12-9b58-073dcdfb4553","Data Driven Decisions: Validating and Supporting a Continuous Experimentation Development Environment","Mulders, Ernst (TU Delft Electrical Engineering, Mathematics and Computer Science)","Gousios, Giorgos (mentor); van Deursen, A. (graduation committee); Katsifodimos, A (graduation committee); Anderson, Kevin (mentor); Delft University of Technology (degree granting institution)","2019","The number of conducted A/B tests is growing throughout companies in software development. Many of these companies develop their own in-house Experimentation Platform to support these experiments. In this thesis we identify factors that influence the trustworthiness and soundness of A/B tests by conducting a literature review. We discuss nineteen influential factors categorised as essentials and pitfalls. Using the data of 268 experiments from ING we verify the trustworthiness of ING’s own Experiment Platform, and conclude that there is room for improvement. Finally, we provide a method for developers and engineers to consider these factors during the experimentation phase by modelling them into a questionnaire containing 67 questions. These questions are grouped into three categories, which are referred to as the three A’s of A/B Test validation: Availability, Analysability and Accuracy. To help administer this questionnaire we introduce the first Open-Source toolkit for this matter: ABvalidator.","Continuous Experimentation; A/B Testing; Experimentation","en","master thesis","","","","","","","","","","","","","",""
"uuid:255c83b1-ccbc-494a-8784-7fc3474e4bff","http://resolver.tudelft.nl/uuid:255c83b1-ccbc-494a-8784-7fc3474e4bff","Hydrodynamic Loading of Dutch terraced houses due to flood actions using Computational Fluid Dynamics","Bratz, Benedikt","Bricker, J.D. (mentor); Diaz Loaiza, M.A. (mentor); Korswagen Eguren, P.A. (mentor)","2019","Whenever a region - especially the coastal area - is affected by flood risk, it is essential for residential and life protection to gain knowledge about the mechanisms leading to the collapse of houses. There are empirical mortality functions to predict the mortality of population in the Netherlands directly affected by flooding, but due to probable changes in building quality it is necessary to investigate the fragility of the current building stock. For a detailed structural research containing collapse mechanisms, the resulting loads on buildings in case of flooding – depending on flow velocity, water height, building orientation, width, height etc. – should be known. In current research, several physical experiments have been conducted in order to gain information about hydrodynamic loads on houses in flood actions. The present project aims to set up a numerical model for assessing the flow-induced pressure loads on residences. The model is based on physical experiments already conducted in model scale: a dam break wave is generated, impacting on a model residence of typical Dutch dimensions; then the flow-induced pressure loads are determined. The focus is on the quasi-steady flow part after the initial wave impact. For moderate computational load Reynolds-averaged equations are used for the numerical model. The generated flow conditions and load magnitudes are compared to physical results in order to validate the numerical model. It can be shown that the results generated during the quasi-steady flow part conform with physical results largely. Appearing discrepancies may result from model constraints regarding strongly mixed interface regions of air and water. Finally, possible further model applications are demonstrated: the effect of urban density (realised by blockage ratio variation) on the resulting load is investigated; in addition, the experiment is scaled to prototype scale. Generally, the numerical model serves as a useful tool for load estimation induced by the quasi-steady part of a dam break wave. The model can be used to investigate further modifications; a large range of input variables like e.g. flow conditions, residence geometries, residence arrangements can be assessed to gain information about main interrelations or specific scenarios.","Hydrodynamic Load; Dam Break Wave; CFD; RANS","en","student report","","","","","","","","","Civil Engineering and Geosciences","Hydraulic Engineering","","","Additional project thesis",""
"uuid:f006b8fa-ee5a-4aa9-84e9-b80bae6ce4c1","http://resolver.tudelft.nl/uuid:f006b8fa-ee5a-4aa9-84e9-b80bae6ce4c1","Strategies for integrated governance of the water-energy-food nexus in Bonaire","Oliemans, Jelle (TU Delft Technology, Policy and Management)","Quist, Jaco (mentor); Kunneke, Rolf (graduation committee); Delft University of Technology (degree granting institution)","2019","The island of Bonaire is planning multiple sustainable transitions in the water,<br/>energy and food systems in response to numerous challenges, such as increas-<br/>ing population pressure, rising sea levels, environmental damage, high consumer<br/>prices and import dependency. The water-energy-food nexus is a relatively novel<br/>concept that takes an integrated approach to resource security and sustainabil-<br/>ity. This paper applies systems theory and transition management theory to<br/>a water-energy-food nexus approach in Bonaire and proposes three pathways<br/>to reach an integrated sustainable transition in Bonaire's water, energy and<br/>food systems. It shows that this approach can provide valuable insights for the<br/>integrated governance of the water, energy and food systems.","WEF-Nexus; Transitions; Governance; Pathways; Systems analysis; Bonaire; Water; Energy; Food","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:52460e77-d63e-4233-8d5b-aa7840423273","http://resolver.tudelft.nl/uuid:52460e77-d63e-4233-8d5b-aa7840423273","Seperation of coseismic and postseismic signals of Sumatra Andaman earthquake and Indian Ocean earthquake","Vummidi, Narayanee (TU Delft Civil Engineering and Geosciences)","Riva, Riccardo (mentor); Broerse, Taco (mentor); van der Wal, Wouter (graduation committee); Delft University of Technology (degree granting institution)","2019","The gravity field changes associated with the earthquake are analysed using the GRACE (Gravity Recovery and Climate Experiment) data. GRACE data can track the temporal variations in the gravity field and therefore information on mass redistribution can be achieved. There have been many studies already carried out using the GRACE data to analyse the coseismic and postseismic effects of the earthquakes. The previous studies mainly concentrated on the separation of the earthquake signals from various other signals and noises to understand the internal mass redistribution. In this work two recent past earthquakes have been considered. Sumatra-Andaman earthquake that occurred on 26th December 2004 with a magnitude of Mw 9.1. The other major earthquake that has been taken into account is the off coast Northern Sumatra earthquake (also called as Indian Ocean earthquake) which occurred on 11th April 2012 with a magnitude of Mw 8.6. A new initiative has been taken to separate the long term postseismic term (2004 earthquake) from the coseismic term and the effects of the 2012 earthquake (both the postseismic and coseismic effect). This decoupling process was done using the GRACE monthly solutions of spherical harmonics. Gravity disturbances were calculated from GRACE monthly solutions to understand the internal mass redistribution. <br","Earthquake; GRACE; Gravity disturbances; coseismic and postseismic","en","student report","","","","","","","","","","","","","",""
"uuid:eab350a4-0309-4798-ad5f-0cccfafd46b3","http://resolver.tudelft.nl/uuid:eab350a4-0309-4798-ad5f-0cccfafd46b3","The future of the municipal service center: A focus on experience and well-being","van der Loop, Koen (TU Delft Industrial Design Engineering)","Desmet, Pieter (mentor); van Erp, Jeroen (graduation committee); Delft University of Technology (degree granting institution)","2019","Municipalities all over the world are struggling to find their role in this fast-paced society. The general attitude towards the government is negative and people experiencing its services as inefficient, irrelevant and unpersonal. Their functioning shapes people’s sense of trust in and expectations of the municipality. Despite efforts by incorporating modern technologies the relationship between citizens and governmental bodies are not improving. To date, service optimizations focusses on improving efficiency, accessibility and transparency. A problem-driven approach might achieve in a state of neutrality. However, the goal of the thesis is concerned with enhancing well-being of citizens in the municipal service center. Reducing or preventing inconveniences does not promises increased well-being. Moving into the positive zone requires a different strategy: a positive design approach. Activities make up 40% of our happiness level and are vital to our well-being. By investigating what people experience during these activities, possibilities will arise to enhance well-being. Analyzing people’s micro-emotions yielded 144 emotional events that elucidate that people experience one positive on two negative emotions. Dissatisfaction, confusion and unpleasant surprise make up for 23% of negative emotions while satisfaction makes up for 47% of positive emotions. Emotional events are either beneficiary or harmful to our needs. The universal need for Acknowledgement and Ease are carrying the majority of negative emotions in the current situation. However, an opportunity is found in contributing to a sense of belonging when framing interactions in a municipal service center of well-being. It aims to bring municipality and citizens closer, shape trusting relationships and aims to provide citizens a feeling that they are accepted and part of a bigger whole. Creating a sense of belonging is put at its core to design a positive and meaningful moment that contributes to people’s well-being. With many concerns in the context, a dilemma driven approach was applied that juxtapositions people’s concerns to inspire ideation. A concept was created that introduces a positive moment in the waiting room. The concept keeps track of people’s appointments, and meanwhile people can listen to stories that stimulate a sense of connectedness in citizens. An iterative process resulted in a final concept that was tested with 12 people. User test concluded that the prototype evoked only positive emotions, one rich experience and it contributed slightly to a sense of connectedness. Altogether, the concept positively created a moment that elevates people, making them feel connected to others and shed a fresh perspective that broadened people’s horizon.","Well-being; Interaction; Experience; Positive design","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:b8be76b0-c9b5-42e0-b7a9-99a3e8aad4d1","http://resolver.tudelft.nl/uuid:b8be76b0-c9b5-42e0-b7a9-99a3e8aad4d1","Air-Centered Business Travel: Ecomobility 2035","Kindervater, Frederic (TU Delft Industrial Design Engineering)","Hiemstra-van Mastrigt, Suzanne (graduation committee); van Grondelle, Elmer (mentor); Ribeiro Monteiro, Luciana (graduation committee); Delft University of Technology (degree granting institution)","2019","How does business traveling look like in the future? This master project examines the todays travel landscape and uncovers issues business travelers are experiencing during their trips. With the stakeholder Embraer - an aircraft manufacturer from Brazil - the context of this project is very intentionally set to a door-to-door journey with special focus on the transport modes before &amp; after the flight.With the design intervention of an avatar, the traveler is made more confident during the trip, while at the same time the brand Embraer is established. Based on each trip and the travelers unique preferences a trip is crafted by the Embraer AI for each unique travel destination and communicated to the traveler in an easy and understandable manner. The trip is turned into a magical and sheltering experience by the avatar, who translates complex and sometimes inaccessible information into a concrete actions and a transparent itinerary.The Embraer avatar is accompanying the traveler independent of the platform and with the final product design - a mobile application - the trip experience is made tangible.","Business Travel; Ecomobility; air centered; Artificial intelligence; Avatar; Travel; Air Travel; Embraer; Aircraft; app design; UI; UX","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:37911d44-cbe9-49a5-988a-8d782baf90a3","http://resolver.tudelft.nl/uuid:37911d44-cbe9-49a5-988a-8d782baf90a3","Applying parametric optimisation in the concept exploration phase on naval support vessels","de Gaaij, Andreas (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Ship Design, Production and Operations)","Hopman, Hans (mentor); Kana, Austin (mentor); Wellens, Peter (graduation committee); van Oers, Bart (mentor); Delft University of Technology (degree granting institution)","2019","Five naval support vessels are being replaced. For this replacement two focus points are important. The first one concerns creating more unity within the fleet, achieved by using the hull geometry as a monolithic part. The second one concerns the aim to reduce harmful emissions by reducing the effects of the energy transition by minimising the resistance of the vessels. The current design approach at DMO has deficiencies which limit the ability to vary hull forms and to analyse a large set of design options. Also propulsion power is predicted by regression lines only, which makes it difficult to evaluate novel hull forms. Motion predictions are only used in a later design phase. These deficiencies need to be resolved. The technological opportunities which will be used to address these deficiencies are incorporating CAESES and RAPID in the concept exploration phase. CAESES is a CAD method with integrated optimisation algorithms which makes it useful to make hull form variations by using parametric optimisation. RAPID is a potential flow solver which can be used to predict the wave resistance on the geometry. The total resistance will be predicted by using Holtrop and Mennen for the viscous resistance components. The seakeeping capabilities are predicted by a simplified version of the linear strip theory. The main objective can be formulated as: How can the unity and the energy transition be analysed in the concept exploration phase for the new generation naval support vessels with a hull geometry point of view using RAPID/Holtrop/seakeeping integrated with CAESES Four validation studies have been performed. The test case studies are analysed on the differences in effective power and vertical displacement. The first conclusion is that the effective power will increase for a family design strategy in comparison to a single ship design strategy. The second conclusion is that the vertical displacement can be decreased when using a family design in comparison to the single design strategy. But only when the Logistic Support vessel is left out of the family of vessels, because of its restricted length. The design speed can be used as a design variable, but only when a more sophisticated power usage objective is used. The new approach can be very useful in the concept exploration phase at DMO. The new approach uses a more advanced resistance objective in combination with hull variation. It can also predict the seakeeping capabilities in the concept exploration phase already. The integration of a potential flow solver and prediction on vertical displacement at the bow can be done within one optimisation and a study is possible within reasonable time (under six hours). This makes the new approach practical in the concept exploration phase.","Parametric optimisation; Concept exploration; Ship design","en","master thesis","","","","","","","","","","","","Marine Technology | Ship Design","",""
"uuid:a62e9237-a898-4984-89f6-e97bce2c6d81","http://resolver.tudelft.nl/uuid:a62e9237-a898-4984-89f6-e97bce2c6d81","Convective cloud parameterization: Evaluation of the mass-flux approach through observations","Savazzi, Alessandro (TU Delft Civil Engineering and Geosciences)","Siebesma, Pier (mentor); Nuijens, Louise (graduation committee); Russchenberg, Herman (graduation committee); Jakob, Christian (graduation committee); Delft University of Technology (degree granting institution)","2019","In the context of climate modelling, convective clouds in tropical regions play a major role in determining the climate sensitivity. The vertical transport of mass and energy associated with this type of clouds is often represented with so called mass-flux parameterization schemes. In this work the aim is to evaluate the relationship between mass-flux and large scale environmental conditions using observations in a tropical region, over a period of 13 wet seasons. A uniquely comprehensive data set from the C-band polarimetric radar (CPOL) in Darwin, Australia, is used to estimate vertical velocity inside precipitating convective clouds. Ultimately, mass-flux is derived over a domain size similar to that of a general circulation model (GCM) grid box. Five parameters (RH_500, CAPE, CIN, ­Omega_500 and Chi_crit) are selected to describe environmental conditions and with these, the magnitude and shape of mass-flux is analysed. Chi_crit appears to be the most valid parameter to represent both the shape and magnitude of mass-flux. All other selected parameters strongly influence only one of the two aspects of the profile. Additionally, fractional entrainment is retrieved from mass-flux profiles and partitioned into two terms: one dependent on area fraction and the other on vertical velocity. Under all environmental conditions, the layer between 4.5 and 7 km experiences detrainment. It can be inferred that a stable layer, known as the freezing level, is present at 4.5 km. Below the freezing level, the vertical velocity and the mass-flux shape are most relevant to determine entrainment rates leading to the conclusion that the vertical velocity should not be disregarded when parameterizing convection.","Convection; Mass flux; Parameterization; Cloud; Meteorology; Entrainment; Tropical convection; Darwin; CAPE; CIN; Relative Humidity; Radar; Observational data; Climate modelling","en","master thesis","","","","","","","","","","","","","",""
"uuid:df7674b3-8593-4050-8161-8eb903a9860b","http://resolver.tudelft.nl/uuid:df7674b3-8593-4050-8161-8eb903a9860b","Autonomous Guidance and Control for Precision Landing on Planetary Bodies: Convex Optimization Approach For Mars and Titan Case Studies","Mazouz, Rayan (TU Delft Aerospace Engineering)","Mooij, Erwin (mentor); Quadrelli, Marco (mentor); van der Wal, Wouter (graduation committee); van Kampen, Erik-jan (graduation committee); Delft University of Technology (degree granting institution)","2019","Autonomously landing a spacecraft on the surface of a planetary body with a degree of precision in the order of meters is highly challenging. Over the course of time, the landing ellipse, defined as the region with a 99% likelihood of where a space vehicle will land, has improved steadily but currently still has dimensions in the order of kilometers. The first and single Martian spacecraft that has performed a guided atmospheric entry and utilized precision landing technologies is the Mars Science Laboratory (MSL). The MSL probe and its focal point, the Curiosity rover, has thus been the most advanced mission yet to have flown to Mars. Nonetheless, space missions to the Red Planet have thus-far never landed following fuel optimal paths. Similarly, dispersions for landing on Titan with current technologies expand to hundreds of kilometers. The only reference mission to Titan is the Huygens probe, which has not utilized precision landing technologies nor optimal path planning. Besides, the goal of the Cassini-Huygens mission was to maximize descent time to augment scientific data retrieval of Titan's atmosphere. As part of the NASA Space Exploration Technology Directorate, a parafoil is proposed for landing on Titan due to its cost effectiveness, ease of deployment, relatively low mass compared to the prospective payload and capabilities of precise autonomous delivery. While considering all phases of Entry, Descent and Landing (EDL) and all elements of Guidance, Navigation and Control (GNC), the central focus of the research was put on the (powered and parafoil) terminal descent phase. The research core concerns a convex optimization programming approach to guarantee soft-landing. The algorithm has been verified based on the extensive Mars powered descent guidance literature. As part of the research conducted at NASA/JPL/Caltech, the algorithm has been extended to become compatible with landing a parafoil on Saturn's moon Titan. Throughout the discussion a distinction is made between lossless and successive convexification for optimal guidance. Both types have been simulated to either compute fuel optimal paths for powered Mars landing or pull-power optimal paths for parafoil Titan landing. The soft-landing is guaranteed while adhering to imposed mission constraints. By using the full capability of the spacecraft unprecedented precision may be achieved. This will enable engineers and scientists to reach the most alluring places on planetary bodies, thereby providing humanity a deeper understanding of the Universe.","Guidance; Control; Robotics; Simulation; Mars; Titan; Precision Landing; Convex Optimization; NASA; JPL; Caltech","en","master thesis","","","","","","JPL Visiting Student Research Program","","2020-12-31","","","","Aerospace Engineering","",""
"uuid:2e7bbcb9-b83a-43fa-8c5f-b1f684b48ac7","http://resolver.tudelft.nl/uuid:2e7bbcb9-b83a-43fa-8c5f-b1f684b48ac7","Bootstrapping in the Cox-model with interval censored observations","Gouwens, Sigur (TU Delft Electrical Engineering, Mathematics and Computer Science)","Jongbloed, Geurt (mentor); Delft University of Technology (degree granting institution)","2019","In this study the interval censoring case 2 model combined with the Cox model is considered. The event-time distribution function is modeled nonparametrically. Two algorithms are proposed to estimate the event-time distribution function together with the Cox coefficients. Kernel smoothing is applied to the non-parametric MLE of the event-time distribution resulting in the smoothed MLE (SMLE). A two-step method for choosing the smoothing bandwidth based on minimising the MSE is introduced. Given the SMLE, the precision of the MLE is tested using bootstrap simulations. New event-times are sampled from the SMLE which are then used to compute bootstrap estimates of the event-time distribution. This is done for multiple sample sizes to observe large sample behaviour. This study suggests that larger sample sizes lead to<br/>better estimates. Monte Carlo simulations and the bootstrap simulations agree on the bandwidth and the large sample distribution of pointwise estimates of the event-time distribution.","Survival analysis; Cox model; Interval Censoring; Bootstrap","en","master thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:2c32d2e9-b069-4389-b69b-14897e9d953b","http://resolver.tudelft.nl/uuid:2c32d2e9-b069-4389-b69b-14897e9d953b","Thermal deformation in High Temperature ATES systems","Smouter, Chris (TU Delft Civil Engineering and Geosciences)","Vardon, P.J. (mentor); Bloemendal, Martin (mentor); Delft University of Technology (degree granting institution)","2019","High Temperature Aquifer Thermal Energy Storage (HT-ATES) is a technique for storing large amounts of residual heat in the subsurface. In this report, the thermal deformation resulting from the temperature change in the subsurface is investigated and the resulting risks for buildings are assessed. To do this a case study is done on the TU Delft campus subsurface. It has been determined that the thermal deformation due to HT-ATES systems is small with a maximal deformation of 14 cm. It has also been determined that the stability risks for buildings that are constructed in the vicinity of a HT-ATES system are very low.","HT-ATES; Thermal Deformation","en","bachelor thesis","","","","","","","","","","","","","AESB3410",""
