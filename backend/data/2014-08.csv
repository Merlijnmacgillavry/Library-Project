"uuid","repository link","title","author","contributor","publication year","abstract","subject topic","language","publication type","publisher","isbn","issn","patent","patent status","bibliographic note","access restriction","embargo date","faculty","department","research group","programme","project","coordinates"
"uuid:13c85c95-cf75-43d2-bb61-ee8cf0acf4ff","http://resolver.tudelft.nl/uuid:13c85c95-cf75-43d2-bb61-ee8cf0acf4ff","From Smartphone to Futurephone: Assessing the Environmental Impacts of Different Circular Economy Scenarios of a Smartphone Using LCA","Güvendik, M.","Guine?e, J.B. (mentor); Flipsen, S.F.J. (mentor); Deetman, S.P. (mentor); Ballester Salva, M. (mentor)","2014","The lack of literature on using life cycle assessment (LCA) for increasing environmental performance raises the need for concepts or eco-design tools to be combined with LCA to answer the question of how to strategize and take actions based on LCA results. This study intends to address this need by using mobile phones as a case study and answering the question: How can the environmental performance of the Fairphone be improved?","Lice Cycle Assessment; circular economy; mobile devices; smartphones; eco-design; environmental impact; circular design","en","master thesis","","","","","","","","","Technology, Policy and Management","Engineering System and Services","","Master of Science Industrial Ecology","",""
"uuid:294e19d7-4445-451d-9a93-25bc0c00d850","http://resolver.tudelft.nl/uuid:294e19d7-4445-451d-9a93-25bc0c00d850","Discrete benadering van de concentratie A-deeltjes op het membraan van Dictyostelium Discoïdeum","Van Vianen, K.","Dubbeldam, J.L.A. (mentor)","2014","In dit verslag zijn twee manieren bekeken om de concentratie van A-deeltjes te beschrijven. 1. Random walk met een val 2. Tellen van het aantal verschillende roosterpunten dat bezocht is door een deeltje dat een random walk maakt Bij de eerst manier liepen 40 deeltjes in een rooster met 1 receptor. Wanneer een deeltje in de receptor kwam, werd hij geabsorbeerd. Na verschillende simulaties bleek dat op deze manier het aantal A-deeltjes exponentieel afnam. Met behulp van Greense functies en Laplace transformaties is een uitdrukking gevonden voor de overlevingskans van een deeltje, na een benadering in Maple bleek dat ook volgens de theorie het aantal A-deeltjes exponentieel af zou nemen. Bij de tweede manier is het idee dat de overlevingskans van een deeltje afhangt van het aantal verschillende roosterpunten wat een deeltje bezoekt tijdens een random walk over een rooster. Met behulp van genererende functies is de juiste formule gevonden. Na simulaties bleek ook op deze manier de overlevingskans van een deeltje exponentieel af te nemen.","Dictyostelium Discoïdeum; Chemotaxis; Survivalprobability; Gated trapping; Random walk","nl","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","","",""
"uuid:211ee221-a80c-444a-b448-5d62c5f6f987","http://resolver.tudelft.nl/uuid:211ee221-a80c-444a-b448-5d62c5f6f987","Spider web design: “Research and development on the application of spider silk and web typology in the building industry”","Karapanou, A.","Nijsse, R. (mentor); Veer, F.A. (mentor); Klein, T. (mentor); Eigenraam, P. (mentor)","2014","In today’s world, terrorism is an unfortunate reality. Since 9-11, blast design has become a well-sought after design not only for federal and military buildings but also for other high risk buildings being a life safety issue. Facades are the barriers between the blast and the structure. De¬signing a façade for the safety of the occupants has become now more important. As nature has its own optimizing laws, evolving a set of strategies that have sustained over 3.8 billion years, Biomimicry can be used as a design strategy for com¬plex human problems. This thesis explores the options of applying the biomimetic principles of spider webs on the design of a façade exposed to blast loads.","spider web; cable net facade; blast loading","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Structural and Building Engineering","",""
"uuid:684e2fdc-c3b1-4080-8a4d-ff6be96af431","http://resolver.tudelft.nl/uuid:684e2fdc-c3b1-4080-8a4d-ff6be96af431","Citizen Generated Data towards Social Innovation","Wong, J.Y.","Mulder, I.J. (mentor); Brezet, J.C. (mentor)","2014","This project was done in conjunction with DCMR Environmental Agency of the Rijnmond and Delft University of Technology. The project started as an exploration of how citizen participation can influence and change insights for policy advice. The exploration centered around the collection of GPS data from citizens in an open and honest way, in order to better understand personal exposure to pollutants. Because citizens constantly move through cities, areas, and regions throughout their day and/or lives, it is important to understand the impact this can have on our health and future policy. The exploration starts with an investigation on the empowerment and engagement of citizens to take create awareness and take initiative in their own environmental quality. The following report gives an overview of the process of the research and design of this project.","citizen participation; persuasive game design; citizen sensors","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","","",""
"uuid:43992ba8-2446-480a-aa65-95c7fa25cb57","http://resolver.tudelft.nl/uuid:43992ba8-2446-480a-aa65-95c7fa25cb57","Multi-chip dataflow architecture for massive scale biophysically accurate neuron simulation","Hofmann, J.A.","Van Leuken, T.G.R.M. (mentor)","2014","The ability to simulate brain neurons in real-time using biophysically-meaningful models is a critical pre-requisite grasping human brain behavior. By simulating neurons' behavior, it is possible, for example, to reduce the need for in-vivo experimentation, to improve artificial intelligence and to replace damaged brain parts in patients. A biophysically accurate but complex neuron model, which can be used for such applications, is the Hodgkin-Huxley (HH) model. State of the art simulators are capable of simulating, in real-time, tens of neurons, at most. The currently most advanced simulator is able to simulate 96 HH neurons in real-time. This simulator is limited by its exponential growth in communication costs. To overcome this problem, in this thesis, we propose a new system architecture, which massively increases the amount of neurons which is possible to simulate. By localizing communications, the communication cost is reduced from an exponential to a linear growth with the number of simulated neurons As a result, the proposed system allows the simulation of over 3000 to 19200 cells (depending on the connectivity scheme). To further increase the number of simulated neurons, the proposed system is designed in such a way that it is possible to implement it over multiple chips. Experimental results have shown that it is possible to use up to 8 chips and still keeping the communication costs linear with the number of simulated neurons. The systems is very flexible and allows to tune, during run-time, various parameters, including the presence of connections between neurons, eliminating (or reducing) resynthesis costs, which turn into much faster experimentation cycles. All parts of the system are generated automatically, based on the neuron connectivity scheme. A powerful simulator that incorporates latencies for on and off chip communication, as well as calculation latencies, can be used to find the right configuration for a particular task. As a result, the resulting highly adaptive and configurable system allows for biophysically-accurate simulation of massive amounts of cells.","Inferior Olivary Nucleus; systemc; simulation; biologically accurate; massive scale; brain modelling; Spiking Neural Network; linear scalability","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","Embedded Systems","",""
"uuid:fd3c938d-2207-41c6-b976-0cb33e441a1e","http://resolver.tudelft.nl/uuid:fd3c938d-2207-41c6-b976-0cb33e441a1e","Schedule Quality: Delay Analysis Perspective","Yerramreddy, V.A.","Chao-Duivis, M.A.B. (mentor); Hombergen, L.P.I.M. (mentor); Prins, M. (mentor)","2014","Forensic schedule analysis is an analysis method that investigates the events of a CPM Schedule. It is recognized that the forensic schedule analysis may potentially be used in a legal proceeding. This means that the claimant for a delay claim might use the forensic schedule analysis to analyze the events of a CPM schedule to prove his entitlement in a legal proceeding. When forensic analysis is analyzing a CPM schedule, the quality of the schedule is of high importance. This means, if the quality of the schedule is good, the outcome of the forensic schedule analysis will be accurate & explicit and thus the following entitlement. If the quality of the schedule is poor, the outcome of the forensic schedule analysis will be poor. If this is the case, then there is a higher risk that the claimant has to pay someone else’s bill too. Whoever is best prepared for this has the best chance for defending his position successfully and has most chance to pay only for his own risks. There are already schedule quality checks existing that help to build good quality schedules in a project management perspective. This research would like to explore schedule quality checks that can be introduced from a forensic analysis perspective with legal considerations. This would help to improve the outcome of the forensic analysis which will facilitate the true entitlement during a legal proceeding. The research focuses on developing technically superior schedules that can stand a forensic schedule to protect ones rights at all times during a legal proceeding for extension of time claims. One has to be best prepared for it to prove their entitlement. This will lead to a set of technical requirements for schedules and an execution methodology to be rolled out on projects. This research is performed at CB&I (EPC contractor), and hence focussed for EPC contractors.","delay analysis; AACE; EPC; forensic analysis; schedule quality; delay and disruption protocol; FIDIC EPC; window analysis","en","master thesis","","","","","","","","2014-08-29","Civil Engineering and Geosciences","Structural Engineering","","Construction Management and Engineering","",""
"uuid:97b65f3d-f1af-4173-9a3b-ff10869d0b6d","http://resolver.tudelft.nl/uuid:97b65f3d-f1af-4173-9a3b-ff10869d0b6d","Market Introduction Strategy for a new Hilti cordless rotary hammer with dust removal system","Bernhard, P.G.","Jellema, A.H. (mentor); Buijs, J.A. (mentor)","2014","A short term market introduction strategy is developed for a new type of cordless rotary hammer with dust removal system. Additionally long term recommendations for strategy and design are presented. The results are based on an extended user research including an observation of a drilling task.","Hilti; dust removal system; market Introduction; user research","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product Innovation Management","","Strategic Product Design","",""
"uuid:e746359c-d5ab-4541-99d2-dd48ab6abf8d","http://resolver.tudelft.nl/uuid:e746359c-d5ab-4541-99d2-dd48ab6abf8d","Periodicity of alpha-continued fractions","Beltz, E.P.J.","Kraaikamp, C. (mentor)","2014","In the regular case, the continued fraction expansion of a number x is (eventually) periodic if and only if x is a quadratic irrational. In this thesis, we will see if this theorem holds for a special type of continued fraction; the alpha-continued fraction.","continued fraction; periodicity; quadratic irrational","en","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","Applied mathematics","",""
"uuid:b88cc1af-8cf9-4e25-91ce-7ebb5084f69f","http://resolver.tudelft.nl/uuid:b88cc1af-8cf9-4e25-91ce-7ebb5084f69f","Grey-Box System Identification of a Quadrotor Unmanned Aerial Vehicle","Li, Q.","Mazo, M. (mentor); Visser, C.C. (mentor); Hellendoorn, J. (mentor)","2014","","Grey box identification; Kalman filter; Model parameter estimation","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Delft Center for Systems and Control","","Control Engineering","",""
"uuid:5847c025-1975-47b2-b68f-520232bdb692","http://resolver.tudelft.nl/uuid:5847c025-1975-47b2-b68f-520232bdb692","Chinese lion dance in the modern day","Yau, K.K.","Sonneveld, M.H. (mentor); Van der Helm, A.J.C. (mentor)","2014","This thesis is an analysis of the user experience in Chinese lion dance. The lion dancer and the spectator are involved in the research to find an answer to ""how Chinese lion dance can be best preserved and expressed through a Chinese lion dance show?"". The focus is on the interaction between the spectator and the performers.","interaction; performer; audience; spectator","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Master of Science Design for Interaction","",""
"uuid:a9ccc8d7-9c9f-4986-93bc-e080007b2148","http://resolver.tudelft.nl/uuid:a9ccc8d7-9c9f-4986-93bc-e080007b2148","Long-range 3D Range Detector Based on Time-correlated Single-photon Counting","Zhang, D.","Charbon, E. (mentor)","2014","Three-dimensional (3D) range detectors enabling 3D computer vision is now popular in automotive industry. With their participation, automobile safety has been further enhanced, autonomous driving has become realizable. Time-correlated single-photon counting (TCSPC) technique utilizing complementary metal-oxide semiconductor (CMOS) single photon detectors (SPDs) and time-to-digital converters (TDCs) embodies the proper participant of automotive 3D vision, with low power consumption, low cost, high speed, high robustness, small size, and portability. In this thesis, a TCSPC 3D range detector for automotive application was studied and modeled. The model covered all main components of a TCSPC system, including the TCSPC range detection process, the signal, and the noise. It was designed to predict the behavior of TCSPC systems and help future designers optimize the performance in accordance with the targeted application. To verify the model, a experimental setup was designed, implemented, and characterized. The setup consists of a data acquisition system, data processing procedures, and an optical-mechanical system. Measurements performed using the setup have confirmed that the model was designed correctly. For further exploration, range detection from 0.2 m to 60 m were carried out.","3D Imaging; TCSPC; SPAD; TDC; Automotive","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","Master Electrical Engineering","",""
"uuid:a0cbc66d-f1f2-484d-91ff-53b2b18b83b6","http://resolver.tudelft.nl/uuid:a0cbc66d-f1f2-484d-91ff-53b2b18b83b6","Preparation of Space Holding Particles for the Fabrication of Bone Tissue Engineering Porous Titanium Scaffolds with Space Holder Method","Isik, T.","Zhou, J. (mentor); Arifvianto, B. (mentor)","2014","","","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Biomechanical Engineering","","Biomedical Engineering","",""
"uuid:d282041f-4703-400c-976a-55f912f5a5e9","http://resolver.tudelft.nl/uuid:d282041f-4703-400c-976a-55f912f5a5e9","Regions of fresh water influence: The influence of depth on a ROFI","Tas, S.A.J.","Pietrzak, J.D. (mentor); De Boer, G.J. (mentor); Rijnsburger, S. (mentor)","2014","The topic of this paper is the study of the tidal velocity profiles within a region of fresh water influence (referred to as ROFI in this paper). These regions of fresh water influence occur where rivers discharge fresh water into salty seas. The main research question is how depth influences the behaviour of the tidal velocity profile in a region of fresh water influence. The approach for this investigation is to apply a model to two different ROFI systems, and compare the results. The first system considered is the Rhine ROFI, for which numerous field data have been collected (Simpson, et al. 1993) and a numerical model has been created (de Boer, Pietrzak and Winterwerp 2006). The second system is the Fraser ROFI in Canada, having similar tidal characteristics as the Rhine ROFI (Foreman, et al. 1995), but a much larger depth. The model used for this comparison is an analytic model, based on Prandle (Prandle 1982a). In order to do so, it was first necessary to understand the complex behaviour of the tidal velocity profile of the Rhine ROFI. The big difference between the behaviour for neap and spring tide can be explained by decomposing the tidal velocity vector into two counter rotating phasors. Also, two parameters turned out to be important: the depth-averaged velocity and the eddy viscosity. As second goal, and main objective of this paper, was to study the impact of the depth on the behaviour of the tidal velocity profile in the region of fresh water influence. This was done by comparing the shallow Rhine ROFI with the much deeper Fraser ROFI. It turned out that finding realistic values for the eddy viscosity coefficient was the biggest challenge. The ability of predicting vertical current profiles may serve many applications, such as offshore construction or oil leaks. Being able to apply this model to other ROFI’s around the world with different depths, is therefore a very useful aim.","ROFI; Prandle; Region of fresh water influence; Tidal velocity profiles","en","bachelor thesis","","","","","","","","","Civil Engineering and Geosciences","Hydraulic Engineering","","Environmental Fluidmechanics","",""
"uuid:d9ae1ad5-6f21-478c-828e-40f63e0e4dd3","http://resolver.tudelft.nl/uuid:d9ae1ad5-6f21-478c-828e-40f63e0e4dd3","Reservoir Characterisation of the Jurassic Posidonia Shale Formation and the Triassic Deposits of the Main Buntsandstein Subgroup by Seismic Inversion Methods, Block Q16, West Netherlands Basin","Justiniano Cisneros, A.M.","Diephuis, G. (mentor); Pringle, T. (mentor)","2014","The objective of this study was to perform a reservoir characterisation of the Posidonia Shale Formation and the Bunter reservoir, through seismic inversion techniques, in order to obtain several rock properties and analyse how their variations are related to changes in depth, lithology and fluid content. Posidonia Shale is interesting as an unconventional hydrocarbon prospect because it is a bituminous type II kerogen source rock with approximately 5-7% of TOC content. The Bunter reservoir is interesting as it consists of uniform massive stacked fluvial and eolian gas-bearing sandstones of approximately 200 meters in thickness. The study area (256 km2) is located in the Q16 block in the West Netherlands Basin. Structurally it is characterised by half grabens. Posidonia Shale Formation and Bunter reservoir are compartmentalised. Their depths range between 2300 and 2800 meters and between 2500 and 3500 meters respectively. A model-based seismic inversion method and a pre-stack simultaneous seismic inversion method were carried out in order to estimate several rock properties. In addition to the pre and post stack PSTM seismic data, ten wells are located within the study area. As these ten wells did not have recorded shear wave velocities these were estimated by a Xu-White model (Xu and White, 1995 and 1996) and were calibrated at the Posidonia and Bunter intervals with nearby wells that had recorded shear wave velocities. Key horizons were interpreted and were used along with the well logs to generate the low frequency models of acoustic impedance, shear impedance and bulk density. These models were filtered in order to keep the low frequencies, below 10Hz which are missing from the available seismic data. The resultant volumes of acoustic impedance, shear impedance and bulk density obtained from the inversions honoured the well-log data. From these volumes other rock properties were derived namely shear modulus, bulk modulus, Young’s modulus, Vp/Vs ratio, Poisson’s ratio, lambda*rho and mu*rho. At Posidonia Shale, the acoustic and shear impedances and rock properties decrease compared to the bounded shales, which made it easily to follow this Formation laterally. Moreover, at Posidonia Shale interval, the Young’s modulus and Poisson’s ratio were used to estimate a Brittleness index. The southern area of the mapped Posidonia Shale presented the higher brittleness index, which implies that this area has a more plastic behaviour than ductile and thus is likely to be easier to fracture. Furthermore, the west of the mapped Posidonia Shale was selected as a sweet spot area for performing hydraulic fracturing since this zone has a larger continuous extension, it is thicker and it is more brittle. In the case of the Bunter reservoir, the shear modulus and Mu*Rho increased in cleaner sandstones and hence they are considered reliable lithology discriminators, while Poisson’s ratio and Vp/Vs ratio decrease in the presence of gas and, in consequences, they are considered reliable fluid discriminators. The top and base of Bunter reservoir were easier to recognise laterally on these rock property volume than on the original seismic volume.","reservoir characterisation; seismic inversion; rock properties; Posidonia shale; Bunter reservoir; Section Applied Earth Sciences","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Reservoir Geology","",""
"uuid:c498113b-76a9-4377-9cc2-d4952a819d11","http://resolver.tudelft.nl/uuid:c498113b-76a9-4377-9cc2-d4952a819d11","Estimating arsenic concentrations in Bihar (India), a geostatistical approach using DEM data","Pennekamp, M.F.","Weltje, G.J. (mentor); Bloemsma, M.R. (mentor)","2014","Bihar is a densely populated area located in the Middle Ganga Plain (MGP) in India. The Ganges' sinuous nature in the MGP created a vast amount of point bar structures within the floodplain. In 2003 it was discovered that high arsenic concentrations are present in the shallow groundwater aquifers, especially in the elevated point bars. According to recent research the high contents within the point bars are caused by poor cleansing by the ground water flux. Based on the geological setting of the MGP a relation is found between the surface elevation and the arsenic contamination. An Arsenic Risk Assessment Model (ARAM) is developed and to find the high risk regions. Free digital elevation data from the United States Geological Survey (USGS) are used to locate the high risk areas. The free data proved to be inadequate for this task, hence a semi-automated theoretical model has been developed. With high quality elevation data, such as LIDAR, this model could give a quick indication of the regions with a potential high risk of arsenic contamination.","Arsenic Contamination; Meandering river system; Middle Ganga Plain","en","bachelor thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Applied Geology","","25.666667, 84.633333"
"uuid:6b2d183e-996b-4e6e-8218-aba54140e47d","http://resolver.tudelft.nl/uuid:6b2d183e-996b-4e6e-8218-aba54140e47d","Power plant Mátra: Research to development of a coal quality concept for the lignite deposits Visonta and Bükkábrány, Hungary.","Troost, F.","Buxton, M.W.N. (mentor); Marx, H. (mentor)","2014","This Thesis carried out research towards development of a coal quality concept on geological and mining engineering operational level of Mátrai Er?m? ZRt’s Visonta and Bükkábrány open cast lignite mines, with objective to reduce and avoid sub-optimal combustion behaviour at Mátra Power plant. RWE Power AG is the major shareholder of Mátrai Er?m? ZRt (50.9%). Three improvable sub-optimal combustion behaviours were determined based on power plant performance (2012-2014). A coal quality handling recommendation was developed for Mátrai Er?m? ZRt based on results of coal quality modelling carried out within this Thesis. Through a coal sort algorithm the Visonta (V) and Bükkábrány (B) coal was divided into coal sorts (German: Kohlesorte). A programme was written which creates a block model assigned with quality data from geological samples. Subsequently, the coal sorts in the production profile were predicted by modelling the mining of the blocks within the block model. In- and Inter-pit supply strategies and blend ratios were determined to provide an optimal direct coal sort or blend of coal sorts to the Mátra Power plant. A preliminary mine scheduling programme was developed within this Thesis. The Thesis was preformed along the Mátrai Er?m? ZRt operational mining and processing value chain. A technical background introduces the deposit geology, Visonta and Bükkábrány Mine, fuels (i.e. coal and co-combusted biomass) and Mátra Power plant. A theoretical background describes the power plant components of focused sub-optimal combustion behaviour in theory and points out coal quality parameters and operational factors which potentially enhance sub-optimal combustion. The operational procedures at Mátrai Er?m? ZRt were studied on site, i.e.: sampling, geological modelling, mine planning, mining, transporting (logistics, rail supply of Bükkábrány coal and stockpiling facilities), blending and combustion. Historical operational data was used as modelling input, i.e.: geology database, overview on available qualities, technical constraints, blending constraints and acceptance algorithm. The quality modelling consists of determination of a coal quality algorithm (incl. power plant acceptance algorithm), coal quality modelling for the individual coal seams and evaluation of in- and inter-pit supply strategies. Finally, the coal quality handling description summarises the recommendations for the Mátrai Er?m? ZRt operation. The resulting handling recommendation states the determined coal sorts, cutting technique guideline, power plant supply strategies, stockpile supply schedule and blending strategies. The significant result from this Thesis is that the coal in Visonta and Bükkábrány Mine can be divided into minable coal sorts for which a standard combustion behaviour can be expected.","lignite coal; coal quality; mining; coal sort algorithm","en","master thesis","","","","","","","","2019-08-29","Civil Engineering and Geosciences","Geoscience & Engineering","","Resource Engineering","",""
"uuid:0c5d66b1-1470-44e1-b1d6-e02de00c9b8b","http://resolver.tudelft.nl/uuid:0c5d66b1-1470-44e1-b1d6-e02de00c9b8b","Towards a Social Web based solution to bootstrap new domains in cross-domain recommendations","Rentmeester, M.","Bozzon, A. (mentor); Houben, G.J.P.M. (mentor); Hindriks, K.V. (mentor)","2014","Most recommender systems recommend items from a single domain. However, usually users’ preferences span across multiple domains. Cross-domain recommender systems can successfully recommend items in multiple domains when there is knowledge about the user’s preferences for items in at least one of the domains and when there is knowledge about relationships between domains. But when a new domain is added to a cross-domain recommender system, this knowledge usually lacks and giving cross-domain recommendations is not a trivial problem anymore. Current approaches uses content-based relations to bootstrap new domains in cross-domain recommendations. In this thesis we propose a new model that transfers existing users’ preference based relations between domains from an auxiliary Social Web system to a cross-domain recommender system in which a new domain needs to be bootstrapped. In a case study on the Open Images dataset we researched this solution to get insight in how well the model works and whether it has potential for widespread usage.","cross-domain recommendations; cold-start recommendations; recommender systems; Social Web; Open Images; YouTube; collaborative filtering; users' preferences","en","master thesis","","","","","","","","2014-08-29","Electrical Engineering, Mathematics and Computer Science","Software Technology","","Web Information Systems","",""
"uuid:8179ba11-587c-4bf4-80ed-68a46622429b","http://resolver.tudelft.nl/uuid:8179ba11-587c-4bf4-80ed-68a46622429b","Revitalize the Feelin' good-factor: A redesign of the Brunotti brand strategy","Rietbroek, J.S.","Mooy, S.C. (mentor); Kester, L. (mentor)","2014","Introduction Brunotti is searching for growth opportunities, and is therefore developing a new brand strategy with a broader scope. The ‘right’ brand strategy will ultimately lead to an increase of the brands’ equity and increase the brands competitive position. However there is little knowledge about the perception of the brand and therefore the brands’ image is unclear. Knowledge about the brands’ perception is vital for the development of the new brand strategy. Moreover, a strategy in which the differentiation of the brand is unclear can lead to a decrease of Brunotti’s competitive position, since there is no clear reason for consumer to choose Brunotti over other brands. The challenge of Brunotti of developing a new brand strategy and the need to obtain insights in their brand image created the opportunity for this graduation project. This graduation report describes a proposal for the new brand strategy for Brunotti based on internal and external research. Brunotti Brunotti as a company was internally analysed. The analysis pointed out several important aspects for improvements. Firstly, Brunotti’s current brand strategy is aimed at serving a broad target in different industries, and is therefore moving to a strategy with less differentiation. This combined with the shift towards premium pricing; Brunotti has placed itself in the situation where the brand is positioned to be neither being different nor lower in cost than competitors. This strategy, also referred as the “stuck in the middle”, is classified as the worst strategy to be in to stay competitive. Secondly, the portfolio decision-making effectiveness was found to be low, leading to an unbalanced portfolio, with no balance between more or less risky projects. This has a negative effect on achieving the highest return for the development dollar investment. As an example, several brand extensions were only expected to deliver short-term sales growth, and are not leading to structural growth. Third, current brand management is divided over several people, resulting in no objective management of the brand. Herewith there is no structural and objective protection of the brand image. Competitive position The analysis of Brunotti’s external context indicated that Brunotti’s competitive scope is too broad. Brunotti is facing large and strong competitors in different industries, resulting in high competitive rivalry. Moreover the low differentiation strategy makes Brunotti vulnerable for the threat of substitutes, which is therefore regarded to be high. Furthermore Brunotti is a small player in the sports and fashion industry and therefore faces a big challenge to obtain a strong competitive position in both markets, since it has to divide its resources over both industries. Brand image Via qualitative consumer research insights were acquired about the perception of the brand Brunotti. The consumer research was focused on determining the brands’ image and to obtain insights in the level of brand awareness of the brand. From the results it could be concluded that Brunotti is perceived as (board)sports brand for young adults that also delivers clothing for daily life. However Brunotti is not perceived as a fashion brand. Brunotti is furthermore perceived as a colourful and tough brand that evokes a positive feeling in the consumer mind. Brunotti is also expected to deliver good value for money. Moreover it could be concluded that Brunotti’s brand awareness is high, whereas the brands visibility is low. New brand strategy The new brand strategy is designed to overcome the challenges addressed during the internal and external analysis in order to increase the brands competitive position. The new brand strategy consists of four elements: Positioning The new positioning for Brunotti is focused on differentiating the brand based on the brands’ strengths (brand image) and focuses on the sports and boardsports industry, by excluding fashion. Furthermore the positioning uses the brands’ faded feelin’ good-factor to create a unique selling point, which will be implemented via the marketing. The new positioning also provides new core and brand values, to respectively guide Brunotti’s employees and what it delivers to its customers. With the new positioning Brunotti can differentiate itself from its competitors in the sports and lifestyle industry. The new positioning statement: “To our sport enthusiasts and fanatics who enjoy the fresh air a little challenge and excitement, Brunotti brings you sports-lifestyle apparel and products with distinctive design, functionality, and above all a smile.” Portfolio management To create a balanced product portfolio and to focus the allocation of resources on the successful collections and collections that have high growth opportunities, the fashion collection and the footwear collection are recommended to be liquidated. These collections have a low relative market share, show a low growth rate and are in industries where the competition is strongest. Next to the liquidation of these collections a new concept of a signature collection is recommended. This new signature collection combines different products from different collections in one design style, to counter the fragmented brand manifestation. Marketing management Via marketing the new positioning can be translated in to marketing tools. To differentiate the brand ‘on the spot’ within the retail environment and to increase the brands visibility in the store the concept of Active Shopping POS material was developed. The basic idea of active shopping is that consumers are triggered to perform an activity during their shopping, via POS material. The size of the POS material is ranging from fitting on a pay desk to the size of a promotion stand. Herewith Brunotti can stand out at retailers and at for example events. Next to the active shopping concept, concepts for packaging design are presented with the focus on humour, to also be notable on the streets. Brand management The recommendation for brand management describes the proposal to create a brand manager function. The brand manager is the brands’ advocate and controls the brands’ manifestation in order to protect the brands image to be able to increase the brands’ equity.","brand strategy; portfolio management; brand positioning","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Strategic Product Design","",""
"uuid:1f0c26ce-d4ae-4282-acb5-1fa40325f213","http://resolver.tudelft.nl/uuid:1f0c26ce-d4ae-4282-acb5-1fa40325f213","Development of a new traffic enforcement product-service","Ladiges, D.","Roestenburg, E. (mentor); Vroom, R.W. (mentor); Verwaal, M. (mentor)","2014","The ITS (intelligent transportation systems) department of CSC recently started rolling out their first spot speed enforcement product in the Netherlands. This enforcement product uses loops to detect the speed of vehicles. These loops are embedded in the road surface by cutting slots. Customers perceive these embedded loops as invasive, mainly because installing them takes a relatively long time and causing road blocks. This is why CSC wants to develop a non-invasive traffic enforcement product. The new enforcement product called NITE (non-invasive traffic enforcement) should make use of a non-invasive technology and the design of the product should be adapted to this new technology resulting in a competitive non-invasive traffic enforcement product. This project focused on research of non-invasive technologies, which technology is the most suitable for a new enforcement product and which technologies should be used in future traffic products by CSC. Radar is the most suitable technology to implement at this moment. Using a non-invasive technology like radar resulted in a redesign of the product as well, several aspects are highlighted such as: how the product is installed, how it will be aligned to the enforcement area and certification and maintenance of the product. The shape of the product has significantly changed as well making it a current and future proof design. In conclusion NITE has the ability to be produced and used by CSC in the traffic enforcement market, the product will set the pace for future developments by CSC in the ITS market.","traffic; enforcement; ITS; flashpole","en","master thesis","","","","","","","Campus only","2016-08-29","Industrial Design Engineering","Design Engineering","","","",""
"uuid:77e141f3-a0ff-4885-89ab-9a268ccfdad8","http://resolver.tudelft.nl/uuid:77e141f3-a0ff-4885-89ab-9a268ccfdad8","Task recommendation in human computation","Basak, D.","Bozzon, A. (mentor)","2014","Crowdsourcing and Human computation have enabled industry, and scientists to create innovative solutions by harnessing organized collective human effort. In human computation platforms, it is observed that workers spend a considerable amount of time searching for appropriate tasks, thus losing revenues that they could have made and, ultimately, affecting their motivation, productivity and quality of their work. Task recommendation can help solving this problem, by suggesting workers with the task most suited to them. To enable effective task recommendation, access to worker profiles, as well as execution history is fundamental. Also, commercial human computation platform act as black-boxes to researcher, limiting access to such information. This work provides a threefold contribution to this field of research. First, we propose Bruteforce, a novel human computation platform that provides worker profiling and task recommendation capabilities. By interacting with existing (commercial) solutions, Bruteforce provides researchers and practitioners with an extensible and configurable tool to conduct studies over (and with) human computation platforms. Second, we make available a novel dataset specifically designed to support studies in the task recommendation. Finally, we evaluate the performance of several recommendation algorithms on the new dataset, addressing several common use cases for human computation platforms.","crowdsourcing; human computation; recommendation system","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Software Technology","","","",""
"uuid:3e4af7f6-9a7c-4c5b-bb55-9c1b928c9d0c","http://resolver.tudelft.nl/uuid:3e4af7f6-9a7c-4c5b-bb55-9c1b928c9d0c","Embodied Optimisation Tool for low-rise office buildings in steel","Koonath Surendran, S.","Rots, J.G. (mentor); Coenders, J.L. (mentor); Welleman, J.W. (mentor); Den Hollander, J.P. (mentor); Bonnema, B.H. (mentor); Rolvink, A. (mentor)","2014","This thesis investigates the development and application of a computational tool that optimises the conceptual stage design of a building to have minimum embodied energy and some aspects of the operating energy, depending on the adaptability required. For this purpose, a parametric computational framework for sustainable building design was developed and implemented by the tool. The working prototype of the tool focuses on low-rise rectangular grid office buildings in steel. The various competing objectives are optimised by applying multi-objective optimisation techniques. The Embodied Optimisation Tool has been developed as a plugin within Grasshopper, for 3D modeling tool Rhinoceros, in collaboration with Arup, Bouwen Met Staal and Tata Steel.","multi-objective optimisation; embodied energy; operating energy; adaptability; sustainability; parametric design; computational tool; conceptual stage","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Structural Design","",""
"uuid:c32bbe2f-e916-4495-8d92-a8793ba570fa","http://resolver.tudelft.nl/uuid:c32bbe2f-e916-4495-8d92-a8793ba570fa","Optimization of Container Terminal Development: Adopting Virtual Design and Construction","Aceves, J.","Verbraeck, A. (mentor); Wiegmans, B. (mentor); Van de Ruitenbeek, M. (mentor); Reenalda, M. (mentor); Luchtenberg, G. (mentor)","2014","The current research is conducted in the context of APM Terminals, one of the largest container terminal operators worldwide. As a terminal operator, APM Terminals has detected the opportunity to increase operational capacity by developing container terminal infrastructure. Therefore, APM Terminals has expanded its activities from operations to design and construction. In this process, multiple projects have faced obstacles during the development phase related to the multidisciplinary coordination of stakeholders. This situation has been suspected to generate a negative impact on project performance. In order to optimize the current state of container terminal development it was decided to investigate the potential of adopting Virtual Design and Construction as an optimization strategy for container terminal development. At the moment of conducting this research, there is no existing documentation on the use of Virtual Design and Construction for the development of container terminals and even though there are numerous research papers which provide proof of positive benefits derived from using Virtual Design and Construction (such as reduced change orders during construction ranging from 0.5% to 85%) to this day the adoption rate of Virtual Design and Construction is still only slowly raising across the AEC industry. For this reason, this thesis proposes a new approach to the adoption of Virtual Design and Construction by focusing in stakeholders and their behaviour. As a result of this approach, this thesis developed a change management strategy for the adoption of Virtual Design and Construction focused on creating a positive attitude on stakeholders. The theoretical framework was validated by conducting a Focus Group session which involved eleven multidisciplinary experts on designing and constructing container terminals and two users of Virtual Design and Construction from a construction company and a consulting firm, respectively. A prototype of the building information model was demonstrated to the experts to allow them to develop a personal opinion of the potential benefits that they envision through the adoption of Virtual Design and Construction. With the results collected from the Focus Group, the relevance of stakeholders and their behaviour towards the adoption of Virtual Design and Construction was validated. Finally, this thesis provides an Action Plan to adopt Virtual Design and Construction in the multidisciplinary organization of container terminal development.","container terminal development; lean construction; virtual design and construction; focus group","en","master thesis","","","","","","","","2017-08-29","Civil Engineering and Geosciences","Transport & Planning","","Transport, Infrastructure & Logistics","","52.07875, 4.32001"
"uuid:0e942827-0bfc-42b6-86a7-a0dee9c39704","http://resolver.tudelft.nl/uuid:0e942827-0bfc-42b6-86a7-a0dee9c39704","TOM: A wearable robot that supports learning language","Beernink, T.","Rozendaal, M. (mentor)","2014","TOM is a small wearable robot - that helps foreign students to learn Dutch . In the Netherlands, it's common to speak English to foreigners, this causes them not to speak and practice Dutch. TOM - the Dutch abbreviation of Language Practice Buddy - a robot that can be worn around the neck tries to change this. It has an face recognition program, that makes the robot recognize people and then tries to start conversations in Dutch. During the conversation, the robot helps the foreign student to provide things to say.","robot; wearable; language; speech","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Design for Interaction","",""
"uuid:3379a3fc-b8fa-457c-af70-ff30e19f99b8","http://resolver.tudelft.nl/uuid:3379a3fc-b8fa-457c-af70-ff30e19f99b8","Reconceptualising the Periphery: A regional restructuring proposal for Northern New Jersey to catalyse its economic, cultural and environmental capacities from an integrative metropolitan perspective","Lee, D.","Sepulveda, D. (mentor); Van der Hoeven, F. (mentor); Nadin, V. (mentor)","2014","This thesis proposes an Integral, inter-municipal planning/governance and regeneration framework for Northern New Jersey (North Jersey), a major sub-region of the New York metropolitan region facing major urbanisation challenges, namely socio-economic transformations and mobility gaps. The aim is to present a counter proposal seeking to directly engage operational gaps between local socio-spatial conditions and path-dependent regional/municipal planning processes prioritising Smart Growth(a US version of the Compact City)/ TOD and high-level economic growth. Current socio-spatial outcomes of this mismatch are oft en generic developments that ignore or displace existing communities and/or fail to enhance local spatial fabrics. Focusing on TOD-based urban regeneration, the thesis presents the case that improving the linkage between planning processes and socio-spatial outcomes through an integrative governance/planning framework is the key to ensuring the developmental stability of North Jersey and other sub-regions within the New York area.","","en","master thesis","","","","","","","","","Architecture and The Built Environment","Urbanism","","Complex Cities and Regions in Transformation","","40.52, 78.59"
"uuid:f40183e8-807f-41b3-8aa4-488768a1582a","http://resolver.tudelft.nl/uuid:f40183e8-807f-41b3-8aa4-488768a1582a","Ensuring an industry’s durability through reputation management: The influence of social perception on the reputation of the Dutch Food Processing and Packaging Machinery Industry","Baaij, R.J.R.","De Bruijn, H. (mentor); Van der Voort, H. (mentor); Scholten, V. (mentor)","2014","Problem statement The Dutch food processing and packaging machinery industry (food systems industry) is a very important sector considering its benefits to Dutch economy. The sector has a total annual turnover of approximately 2 billion euro’s and furthermore provides employment to more than 8600 people (GMV, n.d.). This sector, and entire Agro&Food sector to which it is closely related, are faced with major future challenges regarding food supply. These challenges consider an enormously rising global demand in a world where fossil fuels become scare and people are more and more concerned with health and the quality of life. Innovation is therefore a vital requisite when facing these challenges, and a requirement to ensure the strong position of the industry in the future. However, innovation could be at risk due to reputational problems. First, the need for innovation shows the importance of recruiting well-educated personnel; currently the sector’s reputation harms its position on the labour-market. Second, its reputation influences the way in which it is perceived in the political environment. Therefore policies might not always favour the sector and can thus limit the resources that are available to the sector. Approach This research has two objectives. The first objective is to describe the current reputation of the food systems industry on different issues and amongst various stakeholder. The second objective of this study is to provide possible routes to success, by understanding the current situation. The structure of the report was set up as ‘a quest’ to fulfil both objectives. Overall, the study is based on literature research and expert interviews. The research environment was provided by one of the leading companies in the industry: Marel. Theoretical insights are combined with empirical findings from within and around the sector. Theories that are used consider: (corporate) reputation, corporate communication and network management. Findings Findings current reputation First, the analysis of the current reputation has provided the following findings: Retail and consumers have proven to be actors that have major influence on the reputation of the Agro&Food sector and the food systems industry. Their preferences influence the entire market behaviour; there is a strong focus at optimizing production at minimum cost level. The retail, and the primary sector are therefore strongly in the limelight of animal welfare organisations; a public discussion on food production is taking place to influence perceptions of end-consumers. End-consumers, on their turn determine the ‘ social environment’ in which the food systems industry does business. Since everybody is a consumer, their perceptions thereby influence the sector’s position on the labour market and in the political environment. However, the food systems industry doesn’t find itself in the position where it is able to intermingle in this public discussion; there is no visibility of the sector on end-consumers. Its potentials on the labour market are unknown to the public. Besides, the innovative character of the industry, combined with its ability to work on global issues related to food production should be the reputation that the sector has on various educational institutions. However, currently this reputation appears to be absent. It is invisible for such institutions and also on potential human-capital which these institutions might provide. Due to this invisibility, the reputation of the Agro&Food sector (low-tech, simple) seems to be adopted as a perceived image. Hence, a link exists between the ‘primary’ Agro&Food sector and the ‘ secondary’ food systems industry. These links are also visible at various government levels. Visibility and reputation of the food systems industry appears to be good on these institutions, however, the sector is affected by the primary sector’s harmful reputation. Provincial governments will have to adapt their policies regarding the entire Agro&Food sector to ‘national benefits’ and ‘ local bottlenecks’ (which mostly involve various NIMBY effects.) Again governments will always have to account for public perceptions on sustainability and animal welfare. Strategies to enhance reputation Secondly, this study focussed on possibilities for the industry to establish a more profitable reputation amongst its stakeholders. Thus, the understandings of the current reputation were complemented with theoretical insights that can be used to construct possible approaches for the food systems industry to achieve its goals. There is reflected upon all approaches to create an understanding of their main advantages and limitation and additionally to create an understanding of the consequences that the proposed strategies may have for the food systems industry as an organisation. These analysis has provided the following findings: Corporate communication can offer the sector with strategies that it can perfectly use to increase its visibility and reputation on policymakers and the labour market. When approaching policymakers, the sector should use its economic importance; emphasizing its uniqueness and distinctiveness for Dutch economy. It can approach human-capital by highlighting potentials of the sector such as job security, innovation and social importance. The sector could establish links between parts of its identity by emphasizing the social importance of innovation for future food demand. Besides, the industry could construct its message on various theme’s and for instance present itself as ‘ Hero Companies’ or ‘ Discovery Companies.’ These strategies especially have a direct approach, with clear targets. Furthermore, they ensure that the industry is in control of all of its activities. When solely focussing on these two parties, the sector will act in the background. The sector will not step into the public limelight. It doesn’t intermingle publically in discussions on food production. Therefore, it doesn’t have to be afraid, that communications will make them target for animal welfare organisations (a current urgent fear within the sector). However the ‘social environment’ on sustainable food production and animal-welfare create an ‘underlying’ problem of social-acceptance. The question arises if corporate communication measures will have enough power to fight this underlying social perception of food production. Increasing visibility and transparency seems problematic since the sector is confronted with all sorts of public moral dilemmas. Besides shaping a message that accounts for social responsibility, in a way that it is perceived as the truth, is massive difficulty, since it doesn’t align with shown modes of behaviour. These perceptions will always influence the way the sector is perceived by human-capital and will always influence public policy. Corporate communication, for this case, only appears to be able to handle the ‘symptoms’ of this underlying social perception without solving it in a more durable way. Such measures will always be a reaction to current feelings in society, but they can’t provide a strategy in which future similar situations are prevented. There is recommended that if the sector truly wants to influence these stakeholders, it is the underlying social perception that needs to be influenced. It is then vital that the sector establishes a more open view towards public concerns and adopts a mind-set in which collaborations are sought with various stakeholders. Within this perspective, the sector shouldn’t solely focus on perceptions, it should focus on networks and relationships. By involving many stakeholders and issues, the sector could increase its possible routes to success; it can search for potential collaborations and behave strategically. This also provides the sector with the possibility to tackle problems before they become urgent; it can act proactively. However, these type of strategies require that parties let go of control and starts such processes of collaborations with vague goals. It also requires that the sector is prepared to face opposing parties in processes with no clear future gain. Actors in the entire Agro&Food sector are currently mainly concerned with their economic position. Next, the current fear for opposing parties and the rivalry within the sector makes that information isn’t shared. Convincing both the Agro&Food sector as the food systems industry to collaborate therefore seems the main challenges. An alliance between strong parties from both sector’s seems an important first step. Nevertheless, the food systems industry’s innovative character can be perfectly used to provide interfaces on which relationships can be established with other parties. Collaborative research and development of new concepts of food production which may involve animal-welfare related issues, appear to be a platforms on which relations can be assembled with parties such as educational institutions, policymakers and animal welfare organisations.","Reputation; Corporate Communication; Network Management; Dutch Food Processing and Packaging Machinery Industry","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Multi Actor Systems (MAS)/Policy, Organisation Law and Gaming","","Systems Engineering Policy Analysis Management","",""
"uuid:aeb8db6e-4cf0-4ba1-8d62-c06c437bd56c","http://resolver.tudelft.nl/uuid:aeb8db6e-4cf0-4ba1-8d62-c06c437bd56c","MI-TP Cast","Leon Loreto, P.","Molenbroek, J. (mentor); Deen, B. (mentor)","2014","The goal is to develop a 3D printed wrist orthesis to replace the traditional plaster type and increases wearing comfort for the patients. It should be a class 1 category medical tool, with limited restrictions. The design should be clean, easy to fit and remove, light, and solid. The result should be a reflection of a clear understanding of 3D techniques and their applications. The final product should be flexible enough to fit different persons, based on a scan. The designs should be ready to print in 3d printing formats (STEP, IGES or STL) and must fit the patient easily shortening the time process as much as possible.","cast; additive manufacturing; 3D printing; Distal radius fracture","en","master thesis","","","","","","","Campus only","2014-08-16","Industrial Design Engineering","Design Engineering","","Medisign","",""
"uuid:b439c314-306f-4ae9-b64c-7033cb43981b","http://resolver.tudelft.nl/uuid:b439c314-306f-4ae9-b64c-7033cb43981b","A Shared Situational Awareness Model for Intermodal Transportation Networks","Joys, J.","Verbraeck, A. (mentor); Lukosch, H.K. (mentor); Ludema, M.W. (mentor)","2014","Intermodal transportation networks are faced with several risks due to their daily operational businesses and environmental conditions. The efficient operation of the network is dependent on the coordination of operations among the different actors in the network: terminal operator, freight forwarder and the inland transport operators (Douma, 2008). An analysis of the problems encountered in the network has established that many of the problems occur due to the lack of communication and sharing of relevant information. Since these factors are also the major requirements for SSA (Bolstad, Cuevas, Gonzalez, & Schneider, 2005; Endsley & Jones, 1997), it was concluded that the root of these problems are lack of SSA. Therefore, the main objective of this research is to show that operational risks in the intermodal transportation network can be minimised by establishing SSA. This objective was translated into the following main research question and sub-questions: Main Research Question How can operational risks at an intermodal transportation network be minimised by establishing shared situational awareness (SSA)? Sub-questions 1. What are the knowledge gaps in the current theoretical models of SA and SSA? 2. How does the challenges faced in the hinterland transport network of the Port of Rotterdam relate to SSA? 3. How can a shared situational awareness framework be designed which will help to minimise operational risks in the intermodal transportation network? 4. How can the framework be translated into a serious game which may help to realise the importance of SSA in minimising operational risks in intermodal transportation networks? This master thesis project focuses on the complex issues involved with the intermodal transportation of import containers through the Port of Rotterdam to the inland terminals. An initial study revealed that the actors are interdependent on each other and a disruption at one point in the network can propagate through the network and disturb the operations of all the actors (Horst & Langen, 2008). This research looks at how the operations of the different actors in the network can be aligned such that risks for the entire network can be reduced. The problems faced by the actors in the network are obtained through interviews and literature review. A link between intermodal transportation and SSA was established. Literature review also suggested that serious games can be used as a means to train the actors in the intermodal transportation network and also signify the need for SSA in such complex multi-actor networks. The current gaps in theory concerning SSA and intermodal transportation were identified to develop the theoretical framework. It was observed that so far SSA had been studied only from an individual and team perspective. The need to study SSA from organizational perspective in intermodal transportation networks was found to be very important as it offers ways to understand the interdependencies among the different actors and their goals and interests with the respect to the entire network. Therefore a theoretical framework is proposed in this project which is based on the three level model described by Endsley (1995b). It describes the requirements to minimise operational risks in the different hierarchical levels (perception, comprehension and projection) from an individual team and organizational perspective. In order to support the framework the conceptual design of a serious game is proposed in this project. The choice to use serious games as a means to signify the need for SSA in intermodal transportation network is supported by literature and interviews. Literature also supports the fact that serious games can be used as a training tool to increase SSA of the actors in the network (Delawari, 2013). Due to the ambition of the Port of Rotterdam Authority to minimise congestion on roads caused by trucks (Port of Rotterdam Authority, 2014), this research is limited to inland transportation of containers via barges and rail. Also, only the actors directly involved in the physical transportation of containers are considered in this research. Therefore the following actors are considered: freight forwarder, deep sea terminal operator, inland terminal operator, barge operator and rail operator. The research showed that although the actors are highly interdependent on each other, they refuse to cooperate with each other due to lack of contractual relations and the desire for autonomy over their operations (Horst & Langen, 2008). The problems faced by the main actors mentioned above were studied in detail through literature reviews and interviews to understand how SSA may affect them. Several problems which occurred were identified to exist due to the lack of SSA: 1. Long waiting times for the inland transport unit at container terminals 2. No feasible visiting time for barges 3. Long processing times of the inland transport unit 4. Inefficient stacking and movement of containers in the container terminal 5. Load and unload list announced late by the inland transport operators 6. Problems with documentation, exemptions and loading lists 7. Securing convenient berth times for barge operators 8. Information about the containers and payment problems between the different actors 9. Incorrect information exchange about the containers between the barge operators and the terminal operators Since the framework developed was theoretical, it was necessary to support it empirically. Therefore a conceptual design of a serious game is proposed. The game design is based on the triadic game design concept where the three parameters: reality, meaning and play are considered (Harteveld, 2010). The game is linked close to reality as possible to increase its learning effect. Problems from real-life were incorporated into the game for this purpose. The major requirements for SSA, i.e., communication and information exchange, were incorporated into this game in order to signify its influence on the operational risks in the network. The game is expected to prove that higher levels of SSA will help to minimise operational risks in the intermodal transportation network. The game design has been validated by experts to support its usability and the fulfilment of its learning objectives. An analysis of the possible results of the game suggested that a shared situational awareness framework for the handling of the intermodal transport operational problems may significantly improve the current situation. Understanding the consequences of one’s decisions and its impact on the network may help to minimise many risks currently encountered by the different actors. The research led to the conclusion that high levels of SSA among all the actors in the intermodal transportation network could result in better performances and reduced operational risks. This has only been validated by expert opinions. However, it is necessary to empirically prove this. Therefore as recommendations for future research, the game should be developed, played and assessed. After verification and validation of the game, the number of operations performed and the number of players can be increased by increasing the number and types of actors.","intermodal transportation; shared situational awareness; operational risks","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Multi Actor Systems","","Engineering and Poilcy Analysis","",""
"uuid:59f39b44-b292-4677-bed7-da6b9b310a46","http://resolver.tudelft.nl/uuid:59f39b44-b292-4677-bed7-da6b9b310a46","Improved Prediction of Runway Usage for Noise Forecast","Dhanasekaran, D.","Roling, P.C. (mentor)","2014","The research deals with improved prediction of runway usage for noise forecast. Since the accuracy of the noise forecast depends on the robustness of runway usage prediction, improved accuracy of runway usage prediction will result in improved accuracy of noise load prediction. The main motivation behind this research is that the current method for runway usage prediction does not account for certain factors such as anticipating changes in weather forecast, additional meteorological phenomena, operational disturbances, which influence the controllers in the runway configuration selection decision-making process. The main objectives of the research are to develop runway usage models with increased accuracy of runway usage prediction compared to the current models and to investigate the effect of the developed models on the results of the computations of the noise load around the airport. The novelty of this research comes from improving the accuracy of runway usage prediction and noise forecast and identification of the main factors that influence runway usage. Most of the recent research in this area focuses on runway usage prediction for tactical and strategic planning. There has been very few research carried out on runway usage prediction for noise forecast and this research aims to fill that knowledge gap. Based on literature study, it was identified that modeling with the use of historical data (empirical modeling) can be used to predict runway usage more accurately since it includes the controller’s decision-making patterns. Two prediction algorithms were chosen for the development of runway usage models: Nearest Neighbor and Neural Networks. Two approaches were chosen for runway usage prediction: determination of runway usage directly and determination of runway usage from runway combination prediction. The combination of the prediction algorithms along with approaches was used to develop four runway usage models. The main factors that influence runway usage were identified and used as predictors for the models. The developed models were verified by a comparison with the actual runway usage. Various predictors were analysed to see if it improves the runway usage prediction accuracy. The developed runway usage models were compared with each other in terms of noise forecast accuracy. Based on the effect of the developed runway usage models on the results of the noise load computations around the airport, the runway usage model that resulted in the highest noise forecast accuracy was identified to be the model developed using neural networks that determines runway usage from runway combination prediction. The main factors that influence runway usage were identified to be – wind direction, wind speed, visibility, period of the day, required capacity, type of operation (landing/take-off), and origin/destination. The developed runway usage models were validated for Schiphol airport and can be applied for other complex multi-runway airports like Schiphol airport. This will aid in noise load prediction around the airport for transparency with surrounding communities, determining annual usage plan and analyzing noise mitigation measures.","runway usage prediction; noise forecast; neural networks; nearest neighbour","en","master thesis","","","","","","","","2015-08-29","Aerospace Engineering","Control and Operations","","Air Transport and Operations","","52.0017, 4.3725"
"uuid:28c002ce-93c5-4442-bede-901ed9cb6d41","http://resolver.tudelft.nl/uuid:28c002ce-93c5-4442-bede-901ed9cb6d41","Infiltration swales: Quantitative performance on an urban catchment scale","Geerling, H.R.","Van de Ven, F.H.M. (mentor)","2014","The research focused on the quantitative performance of infiltration swales on an urban catchment scale. A swale in the city of Utrecht was monitored for 5.5 weeks. Groundwater levels, inflow and outflow were measured. The measured data was used for the validation of a swale model in MetaSwap-Modflow developed for this research. An Infoworks model is used to study the performance of infiltration swales on an urban catchment scale. The research showed that infiltration swales are beneficial on an urban catchment scale. Peak flows and total volume are reduced.","infiltration swales; wadi; sustainable urban drainage system; urban catchment scale","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Water Management","","Water Resources","",""
"uuid:57e572c2-f290-4e88-85e7-4fdae1d7d775","http://resolver.tudelft.nl/uuid:57e572c2-f290-4e88-85e7-4fdae1d7d775","Value-based Pricing in B2B Product Service Combination Markets","Narayan, S.","Ortt, J.R. (mentor); De Bruijne, M. (mentor); Bakker, H.L.M. (mentor)","2014","Pricing strategies, mechanisms and instruments are essential for every commercial organization. Optimum extraction of value in terms of profit from its businesses is one of the important goals of every company. Price determination strategies for companies operating in consumer markets has been studied in detail and is clearly defined, however for the business-to-business markets and specifically for product-service combinations, literature which clearly define pricing strategies and their determinants is not available. On the one hand, a study of the pricing strategy comprising of the structure and components of the price is required while on the other hand, the decision process for the development of this pricing structure and in turn the final price is also of great importance. Though management in networks and business process management is previously researched in detail, there is a lack of detailed research on pricing processes and their optimization in the B2B industry, especially in the product service combination markets. In this graduation thesis project, Applus RTD, a market leader in Non-Destructive Testing technologies is studied as a case where the pricing strategy and the underlying process is developed based on the determining factors of a pricing strategy, the componenets of a pricing structure and the relationship between them. This study intends to improve the market success for the company while improving the existing knowledge base in the field of pricing strategy. The outcome of the research is a holistic pricing model and a process including suggestions and guidelines for its practical implementation. The research is conducted using a case study approach with multiple case studies on existing Applus RTD product lines to gather information about the current pricing strategy and the surrounding factors. Process design principles are used to develop the price implementation process. This study delivers an effective, structured and generalizable process for development of pricing strategy for B2B product service combination markets.","Business-to-Business; Pricing Model; Non-Destructive Testing; NDT; Pricing Process","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Economics of Technology and Innovation","","","",""
"uuid:c241ba84-7979-49bf-8e2c-07c2b7839152","http://resolver.tudelft.nl/uuid:c241ba84-7979-49bf-8e2c-07c2b7839152","Seismic Deblending By Shot Repetition","Wu, S.","Van Groenestijn, G.J.A. (mentor)","2014","Blended acquisition, or simultaneous source acquisition, is a relatively new seismic acquisition design that allows shot interference. Deblending is the procedure that separates the interfering shots as if they were acquired conventionally. This thesis reviews one of the more advanced deblending algorithms in great detail, and demonstrates that it does not perform well when the source sampling is sparse. This thesis proposes a new blended acquisition design, shot repetition, to overcome the restriction of dense source sampling by deblending solely in the common-shot domain. The theoretical fundamentals of shot repetition are derived. Based on that, three possible acquisition configurations are proposed, and the designed deblending algorithm is explained and discussed. This thesis also demonstrates that extreme noise, e.g. competitor’s interference and barnacle noise, can be removed by the same deblending algorithm. The results of implementing the deblending algorithm on synthetic data of three configurations show that all the interfering shots are near-perfect separated. The results do not indicate that one configuration is better than the others. The field data results, on both blended data and the data with barnacle noise, demonstrate that strong overlapping events and weak overlapping events can be separated quite well, while the separation of strong events overlapping weak events leads to signal leakage. The deblending performance is confirmed by a significant SNR improvement on the deblended synthetic data (around 22 dB), a fair SNR improvement (7 dB to 12 dB) on the deblended field data, and a fair SNR improvement (around 5 dB) on the removal of barnacle noise.","deblending; seismic acquisition; encoded source","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Applied Geophysics and Petrophysics","",""
"uuid:0aac7a3b-3c48-4350-b264-fd6b487ea260","http://resolver.tudelft.nl/uuid:0aac7a3b-3c48-4350-b264-fd6b487ea260","Understanding the Mechanisms of Low-Salinity Flooding in Carbonates using Model Systems","Keya, A.L.","Mahani, H. (mentor); Berg, S. (mentor); Rossen, W.R. (mentor)","2014","Low-salinity flooding (LSF) is an improved-oil-recovery method that consists of injecting brine with lower salinity than conventional formation water into the reservoir rock. This method has the potential to improve the oil recovery beyond conventional waterflooding. In sandstone reservoir rocks, it has been reported that the salinity range should be below 5000ppm, whereas for carbonate rocks, laboratory experiments have shown that seawater, which has salinity generally neighboring 50000 ppm caused low-salinity effect. In order words, there was higher oil recovery in secondary mode and additional oil recovery in tertiary mode. Likewise, brines with even lower salinity (highly diluted seawater), trigger incremental oil recovery in the range of 5-10% or even higher. In some other cases, no incremental oil recovery had been observed at all. Consequently, the bandwidth of views ranges from doubt that the low salinity effect for carbonates exists to the potential of relatively high incremental oil recovery. Therefore, the main challenge remains to figure out the true existence of the LSF effect in carbonates, and the understanding of the underlying mechanisms, which ultimately represents a risk in a potential full field scale LSF in carbonates technology deployment. In this project, a similar experimental approach (model system experiments) as in the previous study (Mahani et al., 2014) was taken. The carbonate rock surface is created with patches made of carbonate suspensions (e.g. dolomite, limestone or chalk), deposited on a microscope glass substrate. In addition, oil drops are deposited on the patches and the samples are exposed to brines for investigation at ambient temperature. A camera takes pictures continuously at regular interval of time, from which, contact angle measurement is done, indicating the response of oil drops. This type of experiment was coupled with surface chemistry studies of the system crude oil/brine/ carbonate rock. The results show that surface charges at the rock/brine interface and oil/brine interface tend to be more negative as brine salinity decreases, which translate to lower zeta potential. In addition, the behavior of zeta potential as a function of pH depends on brine composition. Finally, these surface charges at the rock and oil surface are likely to be the main mechanism for the low salinity effect in carbonates, by inducing electrostatic repulsion. In fact, we were able to determine a cause-and-effect relationship between wettability change in different low salinity brines and the zeta potential values. Nevertheless, mineral dissolution could act as a secondary mechanism, by enhancing wettability change through the release of Ca/Mg from the carbonate rock surface, which breaks the bond between the oil-polar groups and the carbonate surface.","low-salinity flooding; model systems; carbonate rock; wettability; zeta potential; mineral dissolution","en","master thesis","","","","","","","","2019-08-29","Civil Engineering and Geosciences","Geoscience & Engineering","","","",""
"uuid:e35e17ad-37a9-4ee7-8a0c-79c321659375","http://resolver.tudelft.nl/uuid:e35e17ad-37a9-4ee7-8a0c-79c321659375","Exploring factors that influence information exchange choices of organizations in network settings: A case study in the underground utility infrastructure sector","Singerling, T.M.","Janssen, M.F.W.H.A. (mentor); Klievink, A.J. (mentor); De Reuver, G.A. (mentor); Wildöer, R.P. (mentor)","2014","Underground utility infrastructure construction projects have become increasingly complex because of the increased number of involved parties and changing laws and regulations. Parties, who normally have nothing to do with one another, intensively share information with each other when building utility infrastructures such as gas, electricity, water, heating and telecommunications networks. Even though information is increasingly digitally available, information is for a large part exchanged via face-to-face meetings, paper mail and e-mail. These paper-based processes result in duplication of effort, unnecessary costs and loss of information during the many transfers. Parties therefore are looking for ways to improve information exchange by deploying inter-organizational information technology. Currently, the most prominent alternative is a platform-like solution, but it is unclear whether such a solution is best for all parties. Significant differences exist between parties in terms of interests and current ways of working. When adapting alternative solutions, parties have to alter systems and processes, which may result in high costs that are not easily recouped. Nevertheless, all parties seek to reap the benefits of an improved information sharing arrangement. Many researchers have investigated systems that facilitate information exchange between multiple organizations, commonly referred to as inter-organizational systems (IOS). IOS research directions have been diverse, but there is still much to discover about why organizations choose for certain IOS configurations. Various frameworks have been developed to distinguish between types of IOS, but none of them is widely accepted and the factors that influence choosing between these configurations are generally unknown or equivocal. This study aimed to identify which factors determine the choices parties make related to information exchange arrangements. The latter is beyond the IOS adoption factors, which have been extensively discussed in IOS literature, because it goes beyond merely choosing between whether or not to adopt IOS. The main research question was as follows: Which factors influence information exchange choices of organizations in network settings? The factors that affect information exchange choices of organizations in network settings have been identified by conducting a literature review and performing a case study underground utility infrastructure. The main unit of analysis was a medium-sized network operator in the telecommunications sector, whose systems, organization and processes regarding underground utility infrastructure projects have been analyzed closely. In addition, external contractors and other network operators have been interviewed. Methods included semi-structured interviews, participant observations and content analysis. The literature review examined both platform and IOS literature as the leading solution in the underground utility infrastructure has characteristics of both. An interesting finding, apart from the above-mentioned knowledge gap that led to the main research question, was that both streams of literature are currently separated, but they can learn from each other. For example, IOS and platform researchers sometimes examine the exact same artifacts. However, platforms lack the information exchange focus that exist in IOS literature, as platform researchers mostly examine artifacts that facilitate the production and selling of products and services. In addition, platform research has focused on business-to-consumer and consumer-to-consumer type of transactions, while business-to-business relationships are hardly ever looked at. The case study revealed four possible information exchange arrangements: 1) manual information exchange, 2) work in the system of the network operator, 3) information exchange through bilateral systems coupling and 4) information exchange through a sector platform. In accordance with a research framework, the factors that influence the choice between these alternatives have been subdivided into organizational, process and system factors. The following factors were identified. Organizational factors:  Available resources for change processes  Degree of dependency on external parties  Degree of impeding competition between contractors  Power  Number of regions in which one operates  Degree of competition in service sector Process factors:  Level of process standardization within the organization  Extent to which the formal processes are followed  Amount of projects on annual basis  Complexity of the product  Focus for potential improvement System factors:  IT maturity  Agents working on projects of multiple external parties  Number of systems that must be coupled (number of interfaces)  Availability of information digitally There appeared to be no single best configuration as each scenario has specific advantages and disadvantages. The platform alternative remains appealing because in concept it can yield all parties benefits. However, provided it meets their needs because based on the current knowledge, it is unclear what the impact would be for parties. If adoption requires major changes to systems and processes, parties fear that the costs outweigh the benefits, even on the longer term. A major cause of the latter is the fact that parties are very diverse, which can be explained using path-dependency. The investigated underground utility infrastructure industry has existed for over a century but has changed considerably in that time. As a result, large differences have emerged between organizations. The aforementioned factors illustrate the parameters in which organizations can differ from one another. These differences make it difficult to decide upon standards that are required for IT facilitated information exchange. An alternative to the platform is to exchange information through bilateral systems coupling, but according to the standards of the platform as much as possible because that would allow easy switching. A practical contribution of this research was that the medium-sized network operator, which was the main unit of analysis, gained insights in current information exchange arrangements regarding underground utility infrastructure projects. Furthermore, the organization has gained an understanding of the possible alternative configurations and their impact. The scientific contribution was also twofold. First, knowledge gaps in both IOS and platform literature were identified. Second, the research deducted IOS configurations and the factors that influence choosing between these configurations from an empirical investigation. Because only a single case was examined, the generalizability of the findings is likely to be limited. Nevertheless, this thesis gives future research sufficient reasons to expand on the findings, for example by examining similar IOS in different sectors.","information systems; platforms; inter-organizational systems; information exchange; B2B; network setting","en","master thesis","","","","","","","Campus only","2016-08-29","Technology, Policy and Management","Information and Communication Technology","","Systems Engineering, Policy Analysis and Management","",""
"uuid:8256a32b-ee93-44c7-8963-48f932d51085","http://resolver.tudelft.nl/uuid:8256a32b-ee93-44c7-8963-48f932d51085","Mitigating Production Uncertainties of Renewables by Adjustable Load Scheduling","Gerres, T.","Lukszo, Z. (mentor); De Vries, L.J. (mentor); Warnier, M. (mentor); Verzijlbergh, R. (mentor)","2014","In the upcoming years, electricity markets in Europe face numerous challenges both on production and demand side. Due to decreasing investment costs for renewable energy sources (RES) and continuing government support for a transition towards green energy technologies, the market share of uncertain and volatile generation capacity will grow. Other than thermal power plants, wind or solar based generation capacity cannot be controlled at will to satisfy the demand for electricity. Furthermore, actual production output for these RES is difficult to predict, because of the limited forecast accuracy of current weather forecast models. On the demand side, household consumption patterns are expected to change due to an increasing share of electric vehicles (EVs). Charging EVs will further increase electricity demand. The additional load has to be provided by renewable energy sources for EVs to be more environmental friendly than fuel powered vehicles. Instead of looking at EVs as an additional burden for the electricity system, this thesis proposes the use of flexible controlled EV charging as a method to mitigate production uncertainty. Introducing the concept of a hybrid aggregator with own photovoltaic (PV) generation capacity and the responsibility to charge EVs, the effects of combining flexible load and RES production are explored. The objective of this research is to determine the value of such flexibility to tackle the challenges imposed by forecast uncertainty of RES production capacity when being traded on the electricity market. The methodology used in this thesis is that of a stochastic linear multistage optimization approach. Based on the analysis of electricity market designs and the stakeholder environment, a conceptual model of the hybrid aggregator is developed and translated into a linear optimization problem. Solving for a maximization of the hybrid aggregator’s revenue, day-ahead market bidding, imbalance requirements and charging schedules can be determined. The optimization problem is implemented in the form of a MATLAB model. Tested for its validity, this model is used to explore the expected market behaviour of the hybrid aggregator given a case study and possible changes of the sociotechnical environment. The possible market effects of the hybrid aggregator are discussed given that he becomes a price maker. Following insights have been gained about the hybrid aggregator: 1.) Given that the hybrid aggregator acts as a party on the liberalized electricity market, his decision making problem can be described as revenue optimizing. 2.) For the hybrid aggregator, scheduling of EV charging is in first place determined by day-ahead and imbalance prices. Instances of EV charging and PV production don’t necessarily coincide. 3.) The market behaviour of the hybrid aggregator is influenced by the market design and can be steered, for example, by imposing limitations on trading capacity on the day-ahead market. Further research is required to explore the market impact of a hybrid aggregator. A recommendation is to determine the aggregator’s behaviour for changes in the sociotechnical environment and its interaction with other electricity market parties. Doing so, input data generated by valid scenario generation techniques should be used.","RES market trading; controlled EV charging; load scheduling; stochastic linear programming; reduced PV production uncertainty","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Engineering Systems and Services","","Energy and Industry","",""
"uuid:5312bd21-d0d9-4aab-8c9f-7dde4217f305","http://resolver.tudelft.nl/uuid:5312bd21-d0d9-4aab-8c9f-7dde4217f305","Reducing Communication in AMG for Reservoir Simulation: Aggressive Coarsening and Non-Galerkin Coarse-Grid Operators","Wobbes, E.D.","Vuik, C. (mentor); Jönsthövel, T.B. (mentor); Lukyanov, A.A. (mentor); MacLachlan, S. (mentor)","2014","Algebraic Multigrid (AMG) is an efficient multigrid method for solving large problems, using only the information provided by the underlying matrices. Unfortunately, on a parallel machine the performance of AMG can be negatively affected by dense communication patterns. The exchange of extensive data sets is generally caused by a high number of non-zero entries contained by the coarse grid operators. We discuss two solution strategies, that can be applied in order to improve the sparsity patterns of these operators: aggressive coarsening and the non-Galerkin method. Aggressive coarsening reduces the number of coarse grid variables by modifying the basic concepts of the standard coarsening scheme. The non-Galerkin approach is entirely different. While preserving the row sums, the non-Galerkin method removes less important entries of the coarse level operators, generated by AMG. In fact, it can be seen as an extension of the standard multigrid algorithm. We explore both techniques in the frame of reservoir simulation. We demonstrate that aggressive coarsening and non-Galerkin algorithm significantly reduce the total number of non-zero entries in the AMG hierarchy. Although aggressive coarsening shows high performance, in terms of execution time, on one processor core, it is less effective for parallel simulations. The non-Galerkin has not been tested in parallel, but its serial results are very promissing.","AMG; communication; aggressive coarsening; non-Galerkin; reservoir simulation","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Delft Institute for Applied Mathematics","","Applied Mathematics","",""
"uuid:1385af79-0a5c-45fe-b139-38f2ca9b68fc","http://resolver.tudelft.nl/uuid:1385af79-0a5c-45fe-b139-38f2ca9b68fc","The Nike Training Club studio: A personal, reciprocal and ongoing customer journey","Tu, S.","Govers, P.C.M. (mentor); Mooij, S.C. (mentor)","2014","Since 2011, in terms of Women’s training business, Nike has relied upon a brand tool called Nike Training Club (NTC). This brand tool has evolved from a fitness phone application to a complete ecosystem that encompasses for instance the NTC trainers, the NTC social media channels and the NTC fitness classes. Following the expansion of this brand tool, the first European NTC studio opened its doors in February 2014. Having in mind the expansion of this concept to key European cities, Nike commissioned this project in order to redesign it into a financially sustainable project. However, we challenged this brief based on a throughout analysis. Indeed, during the evaluation of the NTC studio, the 6 interviews conducted with studio users revealed that the studio was only a free and basic functional training space – and therefore did not increase the brand equity. We thus argued that the studio’s function should be rethought even before thinking about its expansion. In order to redefine the core function of the studio, we conducted a company, a competitor, a trend, and a customer analysis, which resulted in four main strategic directions for Nike and the studio: Nike should build a true and unique club of girls that focus on training, running and active living with Nike+ as the membership. The studio should become more than a training space, but their own clubhouse where all the members feel connected to each other and Nike. Nike should rely with parsimony on trials and education to demonstrate the performance and innovation of its products. The variety of classes available at the studio should highly reflect the 3 silos: studio, High Intensity Training and gym. Nike should offer elevated and desirable experience around live classes lead by NTC trainers. This experience should be more than its training function: it should strengthen the bond between the studio users but also between them and Nike. The studio should drive business to cover its high financial investment, but should not become a classic retail space: the studio should drive traffic to the store using the omni-channel retail model and relying on social shopping behavior. We then combined these four directions into a new design brief that stressed the new goals of the studio: the NTC studio should be redesigned into an elevated training space dedicated for a community of girls – who run, train and live – that drives business. In this interest, we set a new vision: a personal, reciprocal and ongoing journey, which was conceptualized into three stages. The first stage consisted in shifting the core function of the studio from a training space to community space. Since the community would be at the center of the redesigned studio, the initial step of the concept consisted in defining this community. As we identified that the current studio users were part of a Nike run club of girls who also train and live actively, the identity of this club was updated as running, training and living community and had the studio space redesigned for them. Not only we proposed a new space that carried the footprint of a community, but the space was also restructured to enable interactions between the members. The community being set, the second stage of our concept was to create cultural resonance by driving conversation between this community and Nike. We showed in the report how the integration of a plugin to the Nike+ Training Club application – dedicated to the studio – would help Nike to easily collect information about the studio users, and use this information to refresh the training experience in the studio to the community. By offering trainings that are truly relevant to the community, Nike would reinforce the bond between the members and its relationship with these members. Once the cultural resonance formed, we then showed that Nike had the opportunity to take the relationship with the community members at a personal level. Indeed, with the knowledge gathered about the customers, Nike would be able to provide personal shopping service to these customers. In this report, we demonstrated that this personal shopping service could be triggered when the customers interacted with the products. The example of interaction we provided relied on the social behavior earlier outlined: customer would be able to scan with their phone the products, to unlock engaging content and review these products for the other community members. Although these three stages have to be considered as a holistic customer journey, we argued that the first stage was the real game-changer and advised to implement it. Indeed, it is by shifting the studio from a functional training space to a community space that Nike would actually have a return on investment in terms of brand equity and possibly in terms of finances. Yet, the two last stages should still be considered as a framework for Nike to define its future personal service: how to make use of the customer data in order to provide better service in the retail environment.","brand marketing; customer journey; strategy","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product Innovation Management","","","",""
"uuid:867216ba-0dad-4548-a4bc-56dd64a2061b","http://resolver.tudelft.nl/uuid:867216ba-0dad-4548-a4bc-56dd64a2061b","Design of An Integrated Service System for Gracipe to Faciliate and Persuade Home Cooking","Chang, S.","Calabretta, G. (mentor); Vermeeren, A. (mentor)","2014","In October 2013, Gracipe launched its beta website to a limited amount of users with a selection of visualized recipes. Later, the team received a significant amount of feedback, both compliments, as well as suggestions for improvement. However, the initial feedback indicated a graduate decrease of the website’s daily page views per visitor. It became clear that the users had become less engaged with Gracipe over time. The team had concerns of their product’s attractiveness and competitiveness, and also felt uncertain about how and where the company should head to. Therefore, the objective of this project is to provide strategies for Gracipe’s future development, and propose solutions by means of redesigning its service system to revitalize its current business.","home cooking; product design","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Strategic Product Design","",""
"uuid:34e346fa-6df0-4dd7-96aa-c60faad69af0","http://resolver.tudelft.nl/uuid:34e346fa-6df0-4dd7-96aa-c60faad69af0","A Business Model Framework for a “Big Data Analytics as a Service” Platform","Piltan, A.","Hartmann, L. (mentor); De Reuver, G.A. (mentor); Van den Berg, J. (mentor); Heizenberg, J. (mentor); Gopikrishnan, A. (mentor)","2014","Studies show that Data-Driven Decision-Making grounded on large “volumes” of a wide “variety” of data with high-“velocity”, known as Big Data, can considerably enhance the organizational performance. However, the traditional way of capturing, storing, and analyzing digital data through on-premise Business Intelligence (BI) and Analytics systems is neither technically nor economically efficient. Organizations need to incur huge upfront investments to build in-house IT capabilities consisting of infrastructure, platform and tools, and pursue long implementation cycles to deploy on-premise BI systems, which are not also efficient enough to address the scalability and agility required for the big data. On IT service companies side, the challenge is two-folded: first, their intermediary role in BI market has been threatened by rising of cloud-based vendors as IT service companies value propositions are not strong enough to address the aforementioned customer pain points and to seize thoroughly the emerging opportunities in the market. While the emerging cloud-based vendors offer pre-built and almost ready-to-use BI platforms in the cloud that enable customers to access on demand to analytics platforms “as a service” without the need for up-front investments and in-house deployment. Second, IT service companies’ business model including their BI services’ business model is a time-bounded linear function of the consultancy hours which subject them to market risks. Cloud computing as a game changer in the IT industry can help IT service companies to address both challenges. The underlying concept of the Cloud, i.e., as a service, brings Information Technology (i.e., Hardware and Software) one step closer to the IT service companies business logic by servicelization of the (information) technologies. In this way, IT service companies can leverage the cloud computing to offer “service-driven” cloud-based BI and Analytics solutions to address the customer pain points and to gain an edge over rising competition. Besides, the cloud computing helps IT service companies to re-invent their business model from a pure service provider model in terms of the consultancy hours to a product-oriented service provider model based on the solutions. The objective of this thesis is to develop new business model concepts and turn them to a detailed business model framework for a “Big Data Analytics as a Service” platform that address both IT Service companies and the customers pain points as well as to seize the emerging opportunities. To realize the objective, we designed a research framework (i.e., a design cycle) in five phases. The first phase was to understand the theoretical concepts from and through which the design research is accomplished. We used Product-Service Systems (PSS) and business model frameworks as two key paradigms in realization of the research objective. PSS concepts enabled us to develop innovative business model concepts, (i.e., what part). Besides, the business model frameworks provided us with necessary tools (i.e., how part) to turn the developed concepts into a detailed framework. Understanding the current business model is the first step to reinvent it and develop new business models. Therefore, the second phase of the design-research was performed in two consecutive steps: first using the Business Model Canvas the traditional business model was briefly assessed. We identified major pain points of the customers in the traditional business model — High TCO, Long Time-to-value, High risk, Complex deployment and maintenance, and Limited technical performance — while Weak value propositions and Linear consultancy-based business model were pointed out as IT service companies failure points. In the second step, inspired by the emerging trend of “Technology as a Service” mainly enabled by the cloud computing paradigm in IT industry, on one hand, and two innovative PSS classes — use-oriented PSS and result-oriented PSS — on the other hand, we developed two new business model concepts to address the identified pain points as follows:  Analytics Capability as a Service: In this model, the IT service company provides the customers with an analytics environment comprising the required infrastructure, tools, and various services (i.e., analytical capability) in the cloud as service using which, clients can deploy analytical solutions in-house on the top of the environment, while the IT service company designs, implements, owns, and supports the underlying environment as a service.  Analytics Insights as a Service: In this model, the IT service company goes beyond provision of the cloud-based environment by building analytical solutions with the clients on the top of the environment and supports the customers with business insights as a service on an ongoing basis. Moreover, in this model, the IT service company designs, implements, owns, and supports the underlying environment as a service. Next, using the developed concepts, we designed the envisioned Big Data Analytics as a Service platform, on which the business models are created and delivered. In general, the platform consists of three pillars: The cloud-based analytics environment, Services, and Analytics solutions on the top. Therefore, the core concept (value proposition) of the proposed business models can be framed as: ""To enable customers to access on-demand a shared pool of BI and Analytics resources in which the ownership of the resources is retained by IT service companies and its partners, while availability (analytics capability) or results (analytics insights) of the resources is provided to the customers based on the “pay-per-use” pricing via web access without the need to deploy and maintain an on-premises BI system."" Obviously, many actors in the BI and analytics value network will affect (or be affected) by the new business models. Therefore, in the third phase, six relevant actors (i.e., organizations) on the supply side were indentified and their perspectives/interests/requirements/potential roles/resources across the proposed business models were discussed through an in-depth interview with a (senior) representative of each one. The general observation was that all the actors were interested in the new business models and could find a potential role and value for themselves within them. Also, many of the actors could see some sort of alignment between the proposed models and their current or near future strategies/initiatives. For the demand-side, we used two independent and widely referenced surveys in the literature about the organizations’ needs and preferences for cloud-based BI and analytics systems. The corresponding results also indicated that the market is expressing an increasing interest in or need for the solutions aligned with the proposed business model concepts. However, technical challenges such as security, data transmission and on-premise integrations hinder wide adoption. Consequently, the first three phases gave us the necessary inputs — the business model concepts, business needs and methodologies — to design the detailed business model framework in the fourth phase. To this end, we made use of the STOF business model framework, in which the business model design is organized into four domains of Service, Technology, Organization, and Finance largely consistent with the Big Data Analytics as Service platform concept, i.e., a product-service platform created and delivered by a network of organizations. However, the basic STOF method was extended with additional critical design issues (CDIs) to cover the service process and the specific technical concerns raised by the customers. Using eight CDIs within the Service domain, we defined target markets and explained how the associated value propositions address the customer pain points in the traditional business model. Then, customer acquisition and retention strategies were formulated to bridge the gap between the traditional models and the new business models. Then, we designed a service process (blueprint) to create and deliver the business models and bundled it into three service bundles according to the two new business model concepts and the designed customer acquisition program, i.e., the Big Data Value Discovery Program. We elaborated on how the new business models can be customized across various layers of the platform through Customized Architecture, On-demand and tailored Services, and Semi-customized Analytics Solutions. Moreover, the platform branding was chosen as “Capgemini Analytics Subscription Environment” and the customer trust were discussed to pave the way for the associated CDIs in other domains. In general, within the Service domain particular emphasis was placed on the “service elements” as a key differentiator for IT service companies’ business model over typical cloud-based self-service BI and analytics platforms and their underlying business models. The proposed business model concepts are technology-driven and aforementioned service processes and associated values all are realized and delivered via sophisticated technologies. Therefore, one part of the business model framework was dedicated to design the high-level architecture of the underlying platform along with security & privacy, data transmission, on-premise integrations and user profile management (in total five CDIs) within the Technology domain. Here, particular attention was paid to address the identified technical concerns of customers in the third phase beyond the scope of a typical business model design. In general, viable design choices were made to relief technical concerns especially security and transfer of bulk data into the cloud as the two major technical concerns. Besides, IT service companies need to collaborate with several actors to acquire the necessary resources and capabilities to operationalize new business model concepts. Within the organization domain and through 5 CDIs, we defined required roles along with their associated resources and capabilities and the actors representing them. We described how the relevant actors should collaborate, who will deliver what to whom and how the value is created and delivered to the customers. Beyond the STOF CDIs, the service blueprint and technological layers were mapped to the actors in detail to clarify the operational model. Finally, partner selection criteria and network complexity were elaborated. Here, the focus was first on designing an organizational model that stimulate the cooperation among various practices within IT service companies to create and deliver a service, the model that is not happen very often. Second, to make design choices that realize the choices made within the service and technology domain. Finally, the proposed business models profoundly change the financial arrangements by shifting the concept from buying pure products (i.e., hardware and software) to buying capabilities and results enabled by “as a service” concept. Therefore, financial aspects including cost and revenue sources, pricing models and financial arrangements were designed within the Finance domain. Though the cost and revenue sources are almost same as the on-premise systems, the fundamental change is to shift from up-front CAPEX (Capital Expenditure) to the pay-as-you-go OPEX (Operational Expenditure). Also, a new source of revenue can be created from the Intellectual Property (IP) of the “pre-built” analytics solutions that will be ready 70-80% and customized for each client (20-30%) based on the its business requirements. Therefore, with the new business models, we designed a pay-per-use pricing model for most of the components. In the final phase, the designed business model framework was evaluated both internally within the IT service company and externally with potential customers. According to the design research and evaluation, the following conclusions were made:  The two proposed business models enable IT service companies to shift from pure (consulting) service company to a more product-service company, on one hand, and customers to decrease the TCO and time-to-market for BI projects and leverage the Big Data more efficiently.  There is no one-size-fits-all business model. Therefore, two new business model concepts along with the traditional model aligned with the market profiles can address various customers’ needs and preferences more appropriately.  The biggest hindering factor to implement the proposed business models is technological capabilities. Therefore, a wise strategy would be to start from specific analytics use cases for particular market segments less vulnerable to the technical challenges until the technology and the market get mature enough and ready. The new business models bring up organizational alliance and financial implications across the value network. However, emerging trends have already triggered the BI market to re-structure itself, which paves the way for the realization of the required changes.","Business Models; Product-Service systems; Big Data; Cloud Computing","en","master thesis","","","","","","","Campus only","2016-08-29","Technology, Policy and Management","ICT","","Management of Technology","",""
"uuid:ce169ce9-2b4c-4171-bec9-d78968e6d899","http://resolver.tudelft.nl/uuid:ce169ce9-2b4c-4171-bec9-d78968e6d899","Development of a Mental-Stress-Reducing Excavator Cabin","Volmer, D.","Vink, P. (mentor); Quartel, C. (mentor)","2014","To improve work-conditions for machine operators, Grammer develops an ergonomic analysis tool called the ‘Grammer User Experience-Tool’ (GUX-Tool) The first part of this graduation project consisted of a literature research, which has substantiated this GUX-Tool and has identified methods for measuring mental effort. The second part of the project consisted of a design project in which an observation study has been used to identify ways in which the cognitive ergonomic aspects of excavator-machines can be improved. After concluding that the inaccessibility of the current joystick-solution is causing mental and physical stress, a new excavator control-unit has been developed.","excavator; heavy earth moving machinery; control unit; stress; mental effort; ergonomics; joysticks","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Integrated Product Design","",""
"uuid:69942211-7216-4c09-b9e5-e5e452240a5b","http://resolver.tudelft.nl/uuid:69942211-7216-4c09-b9e5-e5e452240a5b","The role of electrical energy storage in a future sustainable electricity grid","Van Staveren, R.J.M.","Herder, P.M. (mentor); De Vries, L.J. (mentor); Cunningham, S.W. (mentor); Verzijlbergh, R.A. (mentor); Aalbers, R. (mentor)","2014","The call for lower CO2 emissions has increased the integration of renewable energy sources in the electricity system. However, these intermittent sources do not follow the cycles of demand and are unpredictable in their nature. As the electrical system needs to constantly balance supply and demand, these renewable sources cause problems in the operations of the grid. Electrical energy storage is proposed as a solution for these issues. The research uses an optimization model to test the effects of energy storage on the operation of the electrical system. It shows that the development of storage can be beneficial in systems with a large amount of renewables. The value of storage is mostly dependent on the amount of renewables in the electricity system. Low amounts of renewables give too little opportunities to load while too much renewables give the storage only few periods to unload. Secondly, the value of storage is dependent on the amount of available transmission capacity. In some situations, investments in transmission can be replaced by investments in storage. As the transmission system operator (TSO) is responsible for system balance, he should have the possibility to choose between different investments and pick the optimal one.","electrical energy storage; renewable energy; optimization","en","master thesis","","","","","","","","","Technology, Policy and Management","Engineering Systems and Services","","Energy and Industry","",""
"uuid:3471e78f-fda2-4a5d-973d-3786604f9875","http://resolver.tudelft.nl/uuid:3471e78f-fda2-4a5d-973d-3786604f9875","DIY design: Developing a toolkit for the layman designer","Sypesteyn, M.","Hoftijzer, J.W. (mentor)","2014","This report describes the analysis of design as a profession as opposed to the do-it-yourself practice, and builds upon the results to develop a DIY toolkit that incorporates many design activities and methods found in the professional product design world. this was done by way of a pre-design, in which a small product was first designed. the design process and parameters were analyzed to construct a design space, and method, available to the layman designer and complemented where necessay.","DIY; Design Tool; Do-It-Yourself","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Conceptualization and Communication","","","",""
"uuid:d967d34b-09ad-490e-94d6-66bc3a30d9c9","http://resolver.tudelft.nl/uuid:d967d34b-09ad-490e-94d6-66bc3a30d9c9","Feasibility study of Air Traffic Control Towers around the globe: “International research regarding the local influences providing an optimal structural design for air traffic control towers around the globe in an economical perspective”","Hartmann, J.H.","Nijsse, R. (mentor); Van der Horst, A.Q.C. (mentor); Font Freide, J.J.M. (mentor); Terwel, K.C. (mentor)","2014","At this moment the global human wealth is getting to the next level, which means a growing amount of people is able to travel by plane and these growth figures are seen in the latest global annual passenger’s flows. These latest developments demand building new airports and extending the existing airports heavily around the world in the nearby future (10 years), subsequently resulting in a higher demand of air traffic control towers (ATC towers). Air traffic control towers are very unique buildings. Most countries possess only one or a few towers and the specific knowledge of the technical and functional design of these towers are owned by a few consultants around the world. One of these consultants is Royal HaskoningDHV. However these (Dutch) designers do not possess knowledge about the entire global construction market and geological conditions, making it very difficult to design an optimal ATC tower in a certain country. From this specific design difficulty, the overall objective of this thesis research is to perform an international investigation regarding the main local influences in order to provide an economical optimal structural design methodology for ATC towers which can be used to design these towers anywhere around the globe. The main research question which follows from the research objective is: “What are the local influences on the structural design of an air traffic control tower and how do they relate with an economical optimal structural design?” First, an investigation has been performed in order to select a few representative countries that will cover the scope for this thesis research. Based on motivated reasons the chosen countries are: the Netherlands, Nigeria, Japan, China, Turkey and Indonesia. On basis of a literature study the main structural characteristics for high and tall building design are investigated. The lateral forces caused by wind and earthquake action are the most vital forces for structural design and the structures must provide enough structural reliability. Next, the local building codes of the chosen countries are compared and it has been examined that all the codes contain the same factors and approaches as the Eurocode (European building standard), which is used along the research. To be able to perform this complex international research, the elementary design process is chosen as a sequential guidance in order to obtain economical optimal structural concepts around the globe. By simulating these concepts (case studies) with designs and calculations, the behaviour can be qualified and relations can be made between the local influences and structural design. This process starts with a comprehensive analysis of the fundamental design principles of ATC towers. It is concluded that ATC towers are the most important buildings on the airport domain regarding the guidance and safety of air traffic in the proximity of an airport, providing all the facilities and utilities air traffic controllers need to operate. Even with advanced radar technical and camera technology this guidance is mainly done (and will be done in future) by visual observation and these towers give the air traffic controllers the best view over active pavement. The towers consist of three basic components; the control cab, tower shaft and base building, each having their own primary function. Next, the fundamental requirements for ATC towers facilities are determined. They are drafted by the two major aviation authorities in the world, the FAA and ICAO. In addition to these requirements; desires, starting points and boundary conditions are determined for ATC tower design. The stated desires and starting points are applicable for every ATC design in a general manner, whereas the local boundary conditions have their own influence and importance on every individual ATC design. The following four local boundary conditions are found to be the most important to determine:  Current and projected future air activity airport  Wind climate  Earthquake hazard  Construction industry For each of the six countries these boundary conditions are determined, by examining literature and conducting interviews with experts in the Netherlands and in foreign countries. It is found that for each country different results are obtained. After the analysis, wherein all the necessary information in a diverging process was gathered in order to design an ATC tower, choices are made in order to achieve targeted optimal design solutions. This choice determination is done by applying a converge process with a self-developed methodology which is performed on basis of three main aspects; structural optimum solutions, labour optimum solutions and material optimum solutions. The input variables for this converge process are directly related with the specific boundary conditions found for each country, resulting in different possible optimal structural solutions as output of this converging process. Next, these optimal structural solutions are simulated to understand and to quality how the local boundary conditions relate with the structural design characteristics. E.g. how does an earthquake load compare with a wind load in certain countries, or how does a steel variant compare with a concrete variant. Unfortunately it is not possible to determine which structural design is the most economical solution, but this thesis research provides a design methodology which gives the designers a direction towards the most optimal solution when they take the specific cost aspects into account. The report closes with two kinds of recommendation: themes for follow-up research based upon the issue are which are not elaborated in detail in this report and some advices for using the design methodology as described.","air traffic control tower; airport control; structural engineering; high rise structural design; International Construction Industry; The Netherlands; Japan; China; Nigeria; Turkey; Indonesia; wind engineering; earthquake engineering; International Building Codes; design methodology air traffic control towers; ATCT","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Structural Design","",""
"uuid:b661af96-8e4c-4266-a565-4e232080ce6d","http://resolver.tudelft.nl/uuid:b661af96-8e4c-4266-a565-4e232080ce6d","City Usage Analysis using Social Media","Titos Bolivar, C.","Bozzon, A. (mentor)","2014","Over the last few years, social media have become part of the daily life of many people, leading scientists to study their users and the data they produce in numerous contexts. For instance, geo-enabled social media provide us with the means to study the dynamics and features of large geographical areas. In this thesis, our goal is to leverage social media to study cities, and their usage by people of different origin (e.g. citizens vs. tourists) and demographics. We design and implement a system that uses Twitter and Instagram as data sources, defining and extracting several features about the city and its users, such as finding points of interests, paths, differentiating users in gender, age, and their role in the city. We also build a proof of concept visualization tool that allows non-scientific users to analyze a city using our extracted data. The system is used for an in-depth analysis, where we compare the usage, as observed through the lens of social media, of cities like Amsterdam, London, Paris, and Rome over a three week period on both Twitter and Instagram. We show that, through social media, it is possible to observe differences in usage patterns, both in the temporal sense, but also in regards to the places that are visited in the city.","twitter; instagram; city; social media","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Web Information Systems","","","",""
"uuid:e4ba2d54-e404-467f-92c0-e0161e2f7ad5","http://resolver.tudelft.nl/uuid:e4ba2d54-e404-467f-92c0-e0161e2f7ad5","The Mobile Honey Processing Center","Yao, J.","Diehl, J.C. (mentor); Brezet, H. (mentor)","2014","The report describes the design of a Mobile Honey Processing Center (MHPC) for rural Tanzanian beekeepers. Many of them earn very little money due to the lack of honey processing facilities and relevant services. The MHPC can be used to alleviate the existing problems of low quality honey and low honey production in order to assist the beekeepers to improve their income. The final design of the MHPC consists of three important parts, (a) a 20ft shipping container in combination with a truck will be used to carry and transport the honey processing facilities to the rural beekeeping areas, (b) a well-planned processing area enables the beekeepers to process their honey in a more hygienic and efficient way, and (c) a honey storage with a nonelectric cooling system which can be used to store the processed honey. Moreover, for connecting the beekeepers to the honey market, the processed honey can be directly sold to Jasmine Bee at a fair price and being stored in the MHPC. Therefore, the quality of the honey can be guaranteed and the income of the beekeepers will be improved.","honey processing; Tanzania; BoP; Tanzanian Beekeeping","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design for Sustainability","","","","6.3070, 34.8540"
"uuid:4513c136-78dd-4fb3-b6df-68702e9e8e02","http://resolver.tudelft.nl/uuid:4513c136-78dd-4fb3-b6df-68702e9e8e02","The Smart Steering Wheel Cover: Enhancing safety and efficiency of driving experiences","Ibragimova, E.","Vink, P. (mentor); Vermeeren, A. (mentor); Mueller, N. (mentor)","2014","The advancement of trends as “internet of things”, with more objects becoming connected to each other is putting the human in the centre of the irtuallyconnected space and turning their physical world into an information system. How can these inter-connected disruptive technologies benefit the experiences of driving that have been an unchanging activity of many lives for so long in the history? The Smart Steering Wheel Cover is an in-vehicle system to enhance drivers safety and efficiency. The system provides real-time feedback on drivers’ behavior and enables a safe interface for accessing mobiles phones directly from the wheel. The cover is customized for users and does fit steering wheels of most cars. The usage of The Smart Steering Wheel Cover not only benefits the safety and fuel efficiency of drivers, but also contribute to the environment.","internet of things; automotive; driving","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design Engineering","","Integrated Product Design","",""
"uuid:1b0159c6-abe8-4c57-a407-a1e255abc1c1","http://resolver.tudelft.nl/uuid:1b0159c6-abe8-4c57-a407-a1e255abc1c1","Driving engagement and online social behavior of employees in an enterprise environment","Stanculescu, L.C.","Bozzon, A. (mentor); Sips, R. (mentor)","2014","In the recent years, gamification, “the use of game design elements in non-game contexts”, has drawn the attention of an increasing number of scientists. Although several studies highlighted the benefits of gamification in several applications, its potential in the enterprise environment still needs to be understood. In the enterprise context, companies strive to foster positive behaviour in employees in order to achieve important business needs. For example, it is important for enterprises to educate their employees about the company’s values, products and services. Also essential is to improve the work environment by facilitating social interaction between employees online. Lastly, companies also need to incentivise their employees to spread awareness of the enterprise’s vision and interests beyond the boundaries of the company. This thesis contributes to the studies on enterprise gamification with a study performed at a large multinational enterprise. We designed and implemented a modular and extensible framework for studying gamification and instantiated it as a Q&A game combined with news sharing and social connections capabilities. We used the experimental tool to test the effectiveness of several game mechanics for promoting several types of behaviour. The study involved N=206 IBM employees, organised in 4 experimental groups, and lasted between May 12th and July 11th, 2014. Results show that the implementation of game mechanics was beneficial for the goals of this thesis. First, the tool was received well by employees, who quickly became engaged. They answered quiz questions, invited colleagues to play the game and shared news. The level of engagement was dependent on the game mechanics assigned to an experimental group. Second, the tool has been proved successful for promoting knowledge acquisition. Third, the results related to social online behaviour were also encouraging, showing that several game mechanics can stimulate the desired response from employees.","Enterprise Gamification; User Engagement; Social Online Behaviour; Learning; Games With a Purpose","en","master thesis","","","","","","","","2014-08-30","Electrical Engineering, Mathematics and Computer Science","Software and Computer Technology","","Web Information Systems","",""
"uuid:dfe3c9d6-1244-41be-a810-58e6002de2bc","http://resolver.tudelft.nl/uuid:dfe3c9d6-1244-41be-a810-58e6002de2bc","Potential Impacts of Climate Change on Drinking Water Supply System: Vitens & Waternet Company","Ebrahimi Gharehbaghi, S.","Herder, P.M. (mentor); Van der Lei, T.E. (mentor); Ruijgh-van der Ploeg, M.P.M. (mentor); Kloosterman, R. (mentor)","2014","Climate change is an inevitable undesired phenomenon affecting the water cycle system. High uncertainties exist in the magnitude, speed, and impacts of the adverse consequences of climate change. In the decision-making processes of Water Companies, dealing with uncertainties such as climate change is part of asset management practices. In addition, the water companies keep looking for appropriate methods to improve the decision-making processes and to fulfill the most important goals of enhancing societal benefits. Society obviously benefits from strategies leading to sufficient supply of high quality water with the least environmental impacts. Nowadays, companies are using methods and approaches such as risk management to fulfill this need. However, in these methods mostly the quantifiable part of uncertainties are considered and in the case of climate change impacts, the unknown uncertain part is often neglected. This study contributes to this knowledge gap by using the outcomes of policy analysis methodologies to inform strategic asset management practices. The main research question is: “How can long-term uncertainties -specifically the climate change- be incorporated in long-term strategic asset management? “ In this study a model of the water cycle system is developed with the help of a system diagram and further specified for two Dutch water companies “Vitens” and “Waternet”. These 2 case studies are selected due to distinct features in the water resources and the structure of water cycle systems. Vitens abstracts groundwater, however, Waternet extracts surface water to supply the drinking water. The models are used to investigate the most important critical factors to be included in long-term decision-making. The XPIROV framework, system diagram, and W&H framework are combined to support water companies with strategies for dealing with climate change uncertainty. The uncertainty identification helps to narrow down to the most important critical factors that asset managers should take into account for long-term decision-making. Results show that the analyzed companies may improve their asset management practices by using the outcomes of the analysis. Based on the system diagrams, Vitens is recommended to take into account the critical external factors of drought, average intensity of flooding, and river Rhine flows. As an example, the strategies for dealing with impacts of flooding on quantity of water include: 1) looking for other sources of water such as the Rhine or wastewater, and 2) Improving the condition of infrastructure such as making changes in network designs and in standards or improving safety measures. For Waternet Company the drought, the temperature, and the average intensity of flooding are the most important external factors. For instance, two kinds of strategies can be used to deal with the rise in temperature; 1) applying demand side tactics such as using water-efficient equipment, 2) exploiting other sources of water such as brackish water or wastewater. For further research it is recommended to focus on quantitative analysis. This would likely enable water companies to implement adaptive policies to mitigate the effects of the climate change.","Climate Change; Water Cycle System; Long-term decision making; Asset Management","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Engineering Systems and Services","","Energy and Industry","",""
"uuid:bc28e3ec-4c06-4224-9b19-7afbfd7c93f3","http://resolver.tudelft.nl/uuid:bc28e3ec-4c06-4224-9b19-7afbfd7c93f3","Network Lifetime Analysis of Data Collection Protocols","Li, S.","Zuniga, M. (mentor)","2014","When a sensor network is deployed, we fundamentally care about three main outcomes: to obtain as much data as possible (high delivery rate), to obtain data as fast as possible (low latency), and to obtain data for as long as possible (long lifetime). This last metric, called network lifetime, is of great importance and has been widely investigated because sensor nodes are usually battery-operated. However, there is a gap between the many theoretical studies and the very few empirical ones. The aim of this thesis is to bridge that gap. To achieve our aim, we analyze two well-known data collection protocols: one based on shortest-path trees, called CTP; and the other based on opportunistic routing, called ORW. Both protocols have advantages and disadvantages with respect to the network lifetime. On the one hand, CTP reduces the total number of ransmissions in the network, but uses an expensive communication primitive and does not care about load balancing. On the other hand, ORW has the exact opposite characteristics, good load balancing with an efficient communication primitive at the cost of increasing the total number of transmissions. There is hence an open question to solve: which protocol provides longer lifetimes? We tackle the problem from an analytical and a practical erspective. For the analytical part, we improve the accuracy of current energy models for CTP and develop a new energy model for ORW. Our models for CTP are up to 95% more accurate than the state-of-the-art. For the empirical part, we evaluate both protocols on a public testbed with 100 nodes. Our analytical results show that ORW has longer lifetimes than CTP for high density networks, and that this advantage should vanish in low density networks. Our empirical results validate that ORW is indeed better than CTP under high densities, but for lower densities, our experiments actually show that ORW performs significantly worse than CTP. We show that this unexpected behaviour (according to the model) is due to some inherent flaws in the implementation of ORW.","WSN; Network Lifetime; Data Collection; Collection Tree Protocol; ORW; Duty Cycle Model","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","Embedded System","",""
"uuid:3a294d27-b342-4dfb-8bd7-775c00be20b0","http://resolver.tudelft.nl/uuid:3a294d27-b342-4dfb-8bd7-775c00be20b0","'Act on Their Stakes' Method and Tools for a Stakeholder Analysis","Loeve, J.F.","Vroom, R.W. (mentor); Bergema, C.P.A.M. (mentor)","2014","Stakeholder analyses are executed in multiple fields. Two of those fields are Industrial Design Engineering and construction. Both fields and literature are studied. Based on the strenghts of each of these three sources a five-step methodolgy for the execution of a stakeholder analysis is developed. To make the five-step methodology actionable supportive tools are developed as well. The proposed methodology, as well as the supportive tools are described in this thesis","stakeholder analysis; IDE; public tender; construction","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Master of Science Strategic Product Design","",""
"uuid:3591767b-e997-497e-82e8-7a842f2a40f9","http://resolver.tudelft.nl/uuid:3591767b-e997-497e-82e8-7a842f2a40f9","Is project success a coincidence or can it be enforced? A comparative study on the critical success factors of the Stadsbrug Nijmegen project and similar civil engineering projects in the Netherlands","Wagner, C.","Hertogh, M.J.C.M. (mentor); Hombergen, L.P.I.M. (mentor); Koops, L.S.W. (mentor)","2014","","CME","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Construction Management and Engineering","",""
"uuid:6153e75c-68cb-4a48-8ea8-2647fc11da41","http://resolver.tudelft.nl/uuid:6153e75c-68cb-4a48-8ea8-2647fc11da41","U-Filter: Bringing Experience Design to an IT consultancy firm","Brussen, Y.","Buijs, J.A. (mentor); Sukirman, E. (mentor)","2014","This report describes recommendations for a better implementation of Experience Design in an IT consultancy firm. The approach has been to design a tool called U-Filter that allows colleagues to check each other’s work for usability issues. The graduation company can best be described as both an IT Consultancy and a System Integrator. The company advises clients regarding technology and implements a system based on this advice later on. Recently the company has initiated an Experience Design (XD) department. The purpose of this department is to make the solutions the company offers useful, usable, and beautiful. However, thus far the XD department has failed to gain traction in the company, this is exemplified by its limited project involvement and its limited size. The XD team has been involved in just a handful of projects, and consists of merely 2 staff members. This is a definite minority, when taking into account the company employs a total of 400 people. This report presents the results obtained in the various stages of the design process of the U-Filter: Discovery, Define, Design, Simulation and Evaluation.","Experience Design; Usability; IT; User-Centered Design; System Integrator; Evaluation tool","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product Innovation Management","","Strategic Product Design","",""
"uuid:f753e368-5831-4209-b3c0-db21f2f0d96e","http://resolver.tudelft.nl/uuid:f753e368-5831-4209-b3c0-db21f2f0d96e","In search for robustness: Combining System Dynamics and exploratory Multi- Criteria Decision Analysis","Tsaples, G.","Pruyt, E. (mentor); Thissen, W. (mentor); Rezaei, J. (mentor)","2014","System Dynamics and Multi Criteria Decision Analysis are two decision aid methods that aim at helping decision makers to better understand the world through formal models and computations. System Dynamics with the use of feedback loops and time delays helps to understand the behavior of a system and how the various elements affect this behavior. Moreover, it can be used for testing policies in a safe, consequence-free environment. However, one of the disadvantages of SD is that it is often difficult for the decision maker to determine which policy is the most appropriate. Multi Criteria Decision Analysis (MCDA) is a method that provides decision makers with tools to establish objectives, clarify criteria that represent their preferences, attach levels of importance to those criteria and finally assess policies in a more structured way. However, there are a lot of MCDA methods making it difficult to choose the most appropriate one. Moreover, it is often difficult to establish the values for the criteria that will be used to evaluate the alternatives/policies. Furthermore, uncertainty is inherent in decision making. Several sources of uncertainty could be identified such as the difference between the system “as is” and “as it is perceived to be”, the errors in the data and the uncertainties that are inherent in every method (parameters, functions etc.). As a result, uncertainty cannot be avoided in the decision making process. The aim of decision aid though, is to help decision makers identify robust alternatives in the face of uncertainty. Robustness is a term with many definitions in the decision making literature. In this master thesis, robustness is a property of an alternative that makes it valid for all or most versions of the process, where most versions means the combinations of parameters, choices etc. One way to mitigate several sources of uncertainty and disadvantages of SD and MCDA is the combination of the two methods. Their nature seems complementary: SD is used for understanding a system and testing policies and MCDA is used for policy comparison and selection. However, not many efforts have been made towards that direction. Moreover, the efforts that were made did not address issues like taking into account different perceptions of the system in question, evaluation of the alternatives over time and how to distinguish robust alternatives in spite of the presence of uncertainty. One method to address issues of deep uncertainty, is Exploratory Modeling and Analysis (EMA). EMA adopts modeling and simulation processes that are not used merely for predictive modeling, but mostly for better understanding of a system and its uncertainties, under different levels of detail and perception. The purpose of this master thesis, is the development of a methodology (along with the development of a computer program) that will combine SD and multiple MCDA methods with the purpose of testing and assessing policies under different perceptions, levels of detail and to reduce the uncertainties deriving from any single method when used alone. For the development of the program several choices had to be made. First, the output of the SD models will serve as the input for the MCDA process. Each policy will be simulated and its results will be used as the data for the MCDA. Second, several decision makers and their preferences could be represented in the program. Each stakeholder can provide different criteria, different values, weights and (utility and preference) functions. Furthermore, the policy assessment will occur for different points in time, since the output of SD shows behavior over time. Moreover, several MCDA methods were studied in the literature and evaluated under the criteria of familiarity with the method, covering of the classifications proposed by Figueira et al. (2005) and finally how much they are used in the literature. The chosen MCDA methods are: performance targets, Multi Attribute Utility Theory and PROMETHEE II. For these methods, each stakeholder/decision maker can provide a range of weights, different utility/preference functions with a range of values for each (function) parameter. Finally, to search for robustness among the different rankings that will be generated the following process was used: for each ranking, each alternative was tested if it falls within 75% of the alternative with the maximum score in the particular ranking. If it did, the alternative became member of a group. Otherwise, the alternative became member of a second group. In the end, the number of appearances in each group is calculated and the alternatives with the most appearances in the first group are considered the most robust. To test and illustrate the program, a model by Tsaples et al. (2013) was used. The SD model deals with the implementation of land value taxation and its consequences in the development of a city. Different taxation regimes were simulated. The different taxation regimes were then tested in the program. The results demonstrated that the combination of SD with MCDA could help decision makers by identifying not only the alternatives that are consistently robust (in a “good” or a “bad” way), but also which alternatives could be potential points of friction among the stakeholders. However, the program did not come without disadvantages. Mainly, the large number of the generated rankings could mean an overflow of information that could result in performance downgrade. Moreover, the program that was developed for this master thesis can be considered a pilot program. Thus, the choices that were (and were not) made might not be ideal and several additions and corrections are necessary. In addition, the program itself provided some insights on the decision making process and the tools that are used to facilitate it. First, the decision making process could be broken down in pieces and different methods could be deployed to analyze every part. Second, even within each method, an exploratory approach with the use of multiple perceptions, points of view and parameter values could mitigate some of the disadvantages that are inherent in each method. The inclusion of multiple stakeholders ensures that the system of interest is studied under different perceptions. Thus, the effort should be focused not on making the decision makers agreeing but on finding solutions that seem appropriate under all those perceptions. The time problem in MCDA lingers as problem in the search for robustness. The static nature of the method means that so far, alternatives were assessed on the specific point in time, although in real life situations, policies are (or should be) assessed over a period of time. Consequently, there is a need for further study on what time actually means for the decision aid tools and how it could help improve those tools. In addition, by assessing policies over a period of time, robust alternatives could be considered not only those that address the specific issues for which they were designed, but also those that change successfully over time to do so. Furthermore, the notion of robustness needs further clarification and a documentation of its properties and levels could be the first step towards the development of methods that will more clearly identify policies that are valid in almost all versions of the computations. Finally, the exploratory approach on modelling needs further studying. The rise of computational power has made it more feasible to use it than a few years ago. Although the exploratory approach does not come without its disadvantages, its use could offer great benefits in the decision making process. This thesis is a demonstration of that potential.","Multi Criteria Decision Analysis; System Dynamics; Exploratory Modeling and Analysis; uncertainty; robustness","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Policy Analysis","","Engineering and Policy Analysis","",""
"uuid:a1571301-b0f4-422a-8d95-75b8c9257206","http://resolver.tudelft.nl/uuid:a1571301-b0f4-422a-8d95-75b8c9257206","Framework to Measure Value in Oil & Gas Industry: A Case study of Non Destructive Testing","Parashar, K.","Bakker, H.L.M. (mentor); Ortt, J.R. (mentor); De Jong, W.M. (mentor)","2014","This master thesis researches about measurement of performance and value of an inspection technology in Oil & Gas industry. The specific focus of this research is to analyze the case of Corrosion under Insulation (CUI) and how can the Non Destructive Inspection Techniques bring value in detecting CUI. Non Destructive Testing (NDT) techniques are used to detect flaws and test for integrity of the installations, in order to reduce the risk of leaks and damages due to CUI. This research has been done from the perspective of Applus RTD, which provides NDT services in the Oil and Gas Industry. A particular case for a refinery owned by Shell, one of the clients of Applus RTD in The Netherlands has been chosen. The current trend in the Oil and Gas industry emphasizes on the use of Visual Inspection for detecting problem of Corrosion under Insulation. As a service provider the company wants to demonstrate the value of Non Destructive Testing to its clients for detecting Corrosion under Insulation. Therefore, the main research question for this thesis is “How effective is Non Destructive Testing in ensuring a valuable inspection campaign to detect Corrosion under Insulation, in comparison to the traditional approach of visual inspection?” The question is divided into six sub research questions. The first 2 sub questions are aimed at discovering the current NDT techniques, their application requirements and limitations for detecting Corrosion under Insulation in Non Destructive Testing Industry. The third sub research question provides a framework developed from the case study of Non Destructive Testing industry and the existing scientific literature on the topics of performance and value management. This framework proposes Six Audit Areas and a set of Inspection Performance Indicators (IPI’s), which will gather the perceptions of the stakeholders about NDT inspection and the most important audit areas and IPI’s.","value; performance framework; stakeholders","en","master thesis","","","","","","","Campus only","2015-01-01","Technology, Policy and Management","Technolgy, Strategy and Entrepreneurship","","Management of Technology","",""
"uuid:64e9b3b9-aade-4121-959a-e2526be5a6bd","http://resolver.tudelft.nl/uuid:64e9b3b9-aade-4121-959a-e2526be5a6bd","Task recommendation in human computation","Basak, D.","Bozzon, A. (mentor)","2014","Crowdsourcing and Human computation have enabled industry, and scientists to create innovative solutions by harnessing organized collective human effort. In human computation platforms, it is observed that workers spend a considerable amount of time searching for appropriate tasks, thus losing revenues that they could have made and, ultimately, affecting their motivation, productivity and quality of their work. Task recommendation can help solving this problem, by suggesting workers with the task most suited to them. To enable effective task recommendation, access to worker profiles, as well as execution history is fundamental. Also, commercial human computation platform act as black-boxes to researcher, limiting access to such information. This work provides a threefold contribution to this field of research. First, we propose Bruteforce, a novel human computation platform that provides worker profiling and task recommendation capabilities. By interacting with existing (commercial) solutions, Bruteforce provides researchers and practitioners with an extensible and configurable tool to conduct studies over (and with) human computation platforms. Second, we make available a novel dataset specifically designed to support studies in the task recommendation. Finally, we evaluate the performance of several recommendation algorithms on the new dataset, addressing several common use cases for human computation platforms.","crowdsourcing; human computation; recommendation system","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Software Technology","","Web information systems","",""
"uuid:04758dc9-97c8-4449-9556-501d6dd778bb","http://resolver.tudelft.nl/uuid:04758dc9-97c8-4449-9556-501d6dd778bb","Modelling Single Particle Settlement by CFD-DEM Coupling Method","Bagherzadeh, M.","Schott, D.L. (mentor); Al-Khoury, R. (mentor)","2014","Dust liberation (a gas-solid two phase problem) is a highly complicated phenomenon to be studied due to great number of variables to be considered, so any related theoretical or numerical simulation is forced to implement many simplifications. Furthermore, there are numerous methods to study such a problem one of them is the newly introduced CFD-DEM coupling method. This method is expected to be used extensively in near future; therefore, it is essential to have an understanding about its applicability, strong points and shortcomings to be able to model complex problems such as dust liberation. Accordingly, this research is aiming to model single particle settlement (SPS) as the simplest version of dust liberation problem using CFD-DEM coupling method to comprehend both the SPS problem and the method. To reach this goal three main steps has been taken. In the first step the focus is on understanding the single particle settlement problem. In settlement of a single particle two sorts of forces play roles, driving forces and damping forces. The only driving force is the force of gravity; damping forces, which are opposing the gravity force, are buoyancy, drag, virtual mass, and Basset and lift forces. Results indicate that buoyancy as well as drag force are most influential damping forces. Basset and virtual mass forces are important in the transient phase of the problem only and if the ratio of fluid density to particle density is smaller than a certain value (10-3), the influence of these forces in transient phase as well as steady phase is negligible. In the second step, reasons why CFD-DEM coupling method is preferred for modeling SPS is elaborated. Based on the final application of this thesis, which is modelling of dust liberation phenomenon for research purposes, three criteria are formulated to identify the suitable method. Firstly, the method should be able to study the microscopic mechanisms; secondly, it should be capable of handling particle-particle and particle-wall collisions. Finally, the needed computational effort should be at least in acceptable range. Considering these criteria, the CFD-DEM coupling method has been chosen because of its ability to study microscopic mechanisms, its capability in capturing the particle interactions, and its acceptable computational effort. In the final step, the performance of CFD-DEM coupling method is evaluated. To do so, the numerical results have been compared to experimental and analytical results. In the calibration step, the influential parameters such as governing equation model, void fraction model and drag models have been studied and the most appropriate ones have been chosen. In the verification step, results of the numerical model are compared to other experimental cases with different fluid properties. Consequently, in the phase of validation, results of the numerical model are compared to analytical results of another problem with different particle size, geometry and fluid. Based on the observations, it can be concluded that CFD-DEM coupling method can perform accurately and efficiently in the steady-state phase of problems by considering the following two points. Firstly, the void fraction model choice should be mainly dependent on particle diameter to container size ratio. Secondly, the improved big particle void fraction model should be used for simulations with fine mesh and the smoothing length is suggested to be in particle size range.","single particle settlement; computational fluid dynamics; discrete element method","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Transport & Planning","","Transport, Infrastructure and Logistics","",""
"uuid:75ca9fc4-96be-44b6-b990-b08efc63608a","http://resolver.tudelft.nl/uuid:75ca9fc4-96be-44b6-b990-b08efc63608a","Backfill in highwall mining: An assessment of the possibilities in West Bokaro, India","Lier, J.S.","Buxton, M.W.N. (mentor); Ngan-Tillard, D.J.M. (mentor); Kleiterp, P.J. (mentor)","2014","A desire for increased recovery in highwall mining has fueled an interest into the possibility of applying backfill technology to highwall mining. Backfill technology offers the potential for additional advantages, including increased stability and profit. This technique is currently applied in underground mines, but has not yet been implemented in highwall mining. There are current plants to start backfilling highwall mines at West Bokaro mine in Jharkhand, India. The purpose of this thesis is to investigate the possibility of applying backfill technology to highwall mining and to determine whether doing so will lead to an increase in recovery, both in a general sense and in the particular case of the West Bokaro mine. In order to investigate this, a numerical model was created using the finite difference modeling program FLAC3D. Input data was acquired from UCS tests that were performed on samples of rock material as well as backfill material obtained from the West Bokaro mine site. The model ran various simulations focusing on the effects of pillar width, mine and backfill sequencing, backfill material, partial backfilling, and mining in multiple lifts. For the situation at West Bokaro, an optimum pillar width of 2.9 m was found. However, this does not take into account existing regulations that limit the minimum dimensions of the pillar. The mining sequence with the highest stability was a 1-by-1 sequence, where adjacent drives are excavated and backfilled one after the other, ensuring that excavation of the next drive doesn’t start until the previous drive has been backfilled. However, a more practical solution would be mining and backfilling simultaneously, while maximizing the distance between the drives in the process of being excavated and backfilled. The efficiency of backfilling increases with increased cohesion and stiffness of the backfill material. For this reason, loose, dry material is not recommended as backfill. Fly ash composite materials are suitable as a backfill material, provided that cohesion and strength are sufficiently high. Partial backfilling imparts some strength to the surrounding pillars, but not enough to be significant. However, a small gap left open at the top should not excessively affect the process. Multi-lift mining increases overall stability, but comes with an increased risk of roof instability. According to the simulations done in this thesis, recovery as a result of backfilling can theoretically be increased up to 36% when compared to conventional methods. However, the data available for this thesis was limited and therefore more research is required to make any conclusive predictions. More research should also be done on the economic feasibility of implementing backfill technology in highwall mining.","backfill; highwall mining; India; FLAC3D","en","master thesis","","","","","","","","2019-08-28","Civil Engineering and Geosciences","Geoscience & Engineering","","Resource Engineering","",""
"uuid:7794dcfc-0971-4646-9ea2-25f8894176c3","http://resolver.tudelft.nl/uuid:7794dcfc-0971-4646-9ea2-25f8894176c3","Effectiveness of a multipurpose artificial underwater structure as a coral reef canopy: Hydrodynamic and ecological connectivity","Kolijn, D.J.","Uijttewaal, W.S.J. (mentor); Van Dongeren, A.R. (mentor); Kramer, A. (mentor); Lowe, R. (mentor); Van den Bos, J. (mentor); Henriquez, M. (mentor)","2014","The following research focuses on artificial underwater structures (a.k.a. artificial reefs) in a coral reef environment to mitigate the natural and anthropogenic pressures which reef systems are increasingly facing worldwide. The research question is stated as: “Establishing a method to determine if a multipurpose artificial underwater structure (MAUS) can perform the functions of a natural canopy cover on a coral reef flat”. To investigate this research question both ecological and hydrodynamic parameters are considered. The MAUS selected for this investigation is composed of a canopy of 1000’s of interlocking synthetic hooks known as ground consolidators (GCs). This investigation employs both a physical and numerical model. The relevant parameters required to assess the research question can be found by obtaining the flow characteristics inside the canopy and wave induced hydrodynamic dampening across the canopy. Wave driven velocities recorded in a 1:5 scale GC canopy model are used to assess the success of larval recruitment. In addition to ecological considerations in the canopy, the bulk-wave height reduction is computed. This component allows for GC canopy design and schematization in a numerical model application. A link between the bulk wave-height reduction and internal wave driven velocities within the canopy is desirable to understand the connectivity of hydrodynamics and larval recruitment. The evidence collected in this study gives an indication of the GC arrangement which can provide a suitable climate for the establishment, and long-term vitality of a benthic community within its pore structure. This study is unique in that it incorporates various fields of research to bridge the gaps needed to present a more complete and comprehensive design guideline for GCs, and other MAUS concepts. Additional outcomes from this study include a more thorough oversight and understanding of the required changes and considerations needed to improve current interpretation of porous canopy media.","ground consolidators; fringing reef; XBeach; physical modelling; turbulence; canopy; drag; larva","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Hydraulic Engineering","","Coastal Engineering","",""
"uuid:5def2dbb-67d1-4672-a0b1-561d7dc1a74f","http://resolver.tudelft.nl/uuid:5def2dbb-67d1-4672-a0b1-561d7dc1a74f","Scheduling with release times and deadlines","Elffers, J.A.","De Weerdt, M.M. (mentor); Witteveen, C. (mentor); Aardal, K.I. (mentor)","2014","We study the single machine version of the task scheduling problem with release times and deadlines. This problem is too simple to be of practical importance in itself, but it is also used as a relaxation in algorithms for the Job Shop scheduling problem, which is a more practical task scheduling problem. We study exact algorithms for solving the single machine problem. We propose a new lower bound for the single machine problem and analyze its practical performance when used in a branch and bound algorithm. We also study the theoretical hardness of the single machine problem with a fixed set of task lengths.","scheduling; exact algorithms; forbidden regions","en","master thesis","","","","","","","","2015-08-28","Electrical Engineering, Mathematics and Computer Science","Software and Computer Technology","","Algorithmics","",""
"uuid:1711fe1c-5090-402a-9085-6a15a53238e4","http://resolver.tudelft.nl/uuid:1711fe1c-5090-402a-9085-6a15a53238e4","An intuitive crew application for KLM","De Winter, E.M.","Keyson, D.V. (mentor); Van der Sanden, M.C.A. (mentor); Schulte, M. (mentor)","2014","In December 2013, the flag carrier airline of the Netherlands, the Koninklijke Luchtvaart Maatschappij N.V. (KLM) approached the TU Delft with an outline for a graduation project. KLM set out the goal to develop an intuitive crew application for their pilots and cabin attendants to fulfill all their non-operational information needs. Furthermore, their aim was to improve interpersonal relationships within a crew with the ultimate goal of creating an engaged and attached KLM flying crew. The thesis is the result of the MSc graduation project, produced in affiliation with the Design for Interaction MsC program at Delft University of Technology and the Koninklijke Luchtvaart Maatschappij N.V. (KLM). THE PROJECT In June 2013, KLM, the flag carrier airline of the Netherlands, began issuing iPads to around 5,000 pilots, senior pursers and pursers (KLM Official Website, 2014). The tablet computer supports the flight personnel’s activities on board and introduces many valuable opportunities to improve the working context of the flying crew. Currently, most of the non-operational information is spread through a great variety of channels, resulting in important information not reaching its intended audience. Therefore, KLM decided to digitize, prioritize and bundle all relevant information into one intuitive crew application. The main goal of the project is to define the needs and wishes from the two main stakeholder groups: the flying crew, and the KLM business. Additionally, these insights need to be combined into one intuitive iPad application in a way that satisfies the involved parties. RESEARCH The foundation of the project was laid during the deconstruction phase. During this phase, relevant literature was studied (including, but not limited to literature on information overload, social design, acceptance of technology and the social identity theory). This literature provided the author with an understanding of the relevant domains and clear guidance for the continuation of the project. Additionally, user research (interviews, observations and context mapping) provided many insights into the world of the flying crew: what are their goals, motivations, needs and behaviors? Several aspects became abundantly clear during the research phase: - The most important thing to a crew member is their schedule: this determines how they fill in their free time and influences their whole personal life. - Traveling can get lonely at times, which is why the crew greatly values social interactions within a crew. Going on a trip, having dinner together, exchanging stories and pictures: all examples of aspects that are deemed as very important. - Exploring a new location is very important to a crew member: the crew is always curious about a new location and the activities that are waiting for them there. This exploration often already starts at home. - For KLM, it is difficult to connect with the flying crew, as they are barely present at Schiphol Airport. Due to this, KLM is having difficulties connecting with their employees and set out a goal to create a more connected and engaged crew. MY PERSONAL PAGE All the needs and wishes established during the research phase were translated into three concepts, which, after several evaluations with the stakeholders, combined into one final concept: The Personal Page application (presented on the right). With the Personal Page application, a pilot or cabin attendant has all non-operational information at hand at the moment he/she needs it. The tool contains several elements to improve one’s complete flight process: - An up-to-date schedule: thanks to the monthly overview the user can easily see all upcoming flights, trainings and other activities. - An explorative flight overview: the user is able to browse through an upcoming journey as if experiencing it at that moment, receiving all potentially relevant information. - Sharing activities: a big database filled with personal tips and tricks about specific locations bonds the crew and provides the user with many valuable location insights. Additionally, the Personal Page application allows the user to suggest activities to the rest of the crew, lowering the threshold for the establishment of a close crew relationship. - KLM news and magazines: a strong wish from the KLM communication department is to create a connected and well-informed crew: a first step in achieving this is by ensuring the crew receives all (personally relevant) KLM updates. EVALUATION In order to assess the usability and user experience of the Personal Page application, an interactive prototype was created and tested with the stakeholders. This prototype can be accessed via www.mypersonalpage.estherdewinter.com. Evaluations with five target users indicated that the Personal Page application has great potential to become a success. All participants expressed enthusiasm about the design and usability of the Personal Page application and conveyed an interest in downloading the application from the KLM application store. Additionally, the usability study results suggested several points for improvement. Several icons and terms used throughout the application caused confusion, resulting in a lack of flow. Furthermore, while the Personal Page application has great potential for improving interpersonal crew relationships, it is important to dedicate further work into creating a stronger relationship between the KLM and the crew. It is recommended to delve deeper into literature on social identities to accomplish this. CONCLUSION Overall, it can be concluded that the assignment to create an interactive crew application has been successfully completed. Valuable insights into the needs and wishes of the flying crew have been established and combined with the demands from the KLM business. Hopefully, these insights will direct KLM towards a future with a (more) connected and engaged flying crew.","KLM; information design; user experience; interface; application; communication; airline; user research; usability","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Design for Interaction","",""
"uuid:da4ec1e1-6def-43f4-9065-f2cd961c7d91","http://resolver.tudelft.nl/uuid:da4ec1e1-6def-43f4-9065-f2cd961c7d91","Is retained austenite controlling the mechanical properties of Q&P steels ?","Kolk, A.J.","Santofimia Navarro, M.J. (mentor)","2014","Stronger and more ductile steels are increasingly demanded in important industry sectors such as automotive, gas transport ad power generation. One of the classes of Advanced High Strength Steels (AHSS) that are attracting researchers and industries are the so-called Quenching and Partitioning (Q&P) steels. The microstructure of these steels, formed by laths of low-carbon martensite separated by films of carbon enriched retained austenite, are responsible for these properties. Although both constituents are certainly, steel developers and scientists do not get an agreement about which one of these constituents is actually controlling the response of the material upon deformation. The way in which retained austenite is believed to contribute to the strain (work) hardening of these steels is via the TRansformation Induced Plasticity (TRIP) effect, by which austenite transforms to martensite during deformation. Therefore, the actual research question is: Is the TRIP-effect playing a role in the response of Q&P steels upon deformation? The crystal structure of the retained austenite is different from the martensite, and these differences can be detected with X-ray diffraction. In this project, the evolution of the crystal structure of different Q&P specimens were studied in Situ using a X-ray diffraction meter equipped with a micro-tensile tester and if necessary a sample heater. The formation of martensite during the tensile tests was divined form the decrease of austenite diffraction peaks. These experiments allowed detecting the possible occurrence (or absence) of the TRIP-effect.","Quenching and Partitioning (Q&P) steels","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Materials Science and Engineering","","Metals Processing, Microstructure and Properties","",""
"uuid:95cfae42-d59d-4183-a3db-43f66fc45ee1","http://resolver.tudelft.nl/uuid:95cfae42-d59d-4183-a3db-43f66fc45ee1","Air freight transportation configurations: Exploration of optimization possibilities in the freight chain within Europe of KLM Cargo","Hemmes, A.F.","Tavasszy, L.A. (mentor); Rezaei, J. (mentor); Warnier, M.E. (mentor)","2014","KLM Cargo transports freight by truck from European outstations to the Schiphol Hub. This freight is transported palletized. It is unexplored what the impact on the KPI’s of KLM Cargo is of changing pallet composition or the transportation method (palletized vs. Loose) of this export freight flow. The objective of this research is to provide insights into these effects.","air cargo; logistic chain; optimization; palletized freight","en","master thesis","","","","","","","Campus only","2015-08-28","Technology, Policy and Management","Transport & Logistics","","Systems Engineering, Policy Analysis and Management","",""
"uuid:3599a1ed-dfcd-44ab-857a-d72dbc276fb2","http://resolver.tudelft.nl/uuid:3599a1ed-dfcd-44ab-857a-d72dbc276fb2","Robustness improvement of polyhedral mesh method for airbag deployment simulations","Alagon Carrillo, S.","Vuik, K. (mentor); Lewis, M. (mentor)","2014","In this project the problem of determining the inner and outer regions of the computational domain for an airbag deployment simulation is addressed. One approach to perform such simulation is via the structural equations of motion for the airbag fabric dynamics, Euler equations of fluid motion for the fluid inside the airbag and a coupling algorithm which defines the dependence between the two systems of equations. The airbag fabric is discretized as triangular finite elements, and the Finite Volume mesh for the CFD solution inside the airbag is formed by two types of cells: structured cubic cells which have no interaction with the airbag fabric, and unstructured cells which are cubic cells that intersect with the airbag triangulation. The unstructured cells that intersect the triangulation are called cut-cells and a proper description of their geometry is required to obtain an accurate solution via the finite volume solver. Two geometric properties of the cut-cells are particularly important: the exact geometry, i.e. the areas of the sec- tions of the cell faces inside the flow, which is needed for proper calculations of the fluxes, and the characterization of the regions of the cut-cells as interior or exterior to the flux. Developing a robust algorithm to determine the inside/outside regions of the cut-cells is the goal of this project.","Cartesian Mesh; cut cell; air bag; arbitrary lagrangian eulerian; point in polyhedron; Geometrical Modeling; Simplicial chain","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Numerical Analysis","","Applied Mathematics","",""
"uuid:6116c204-5c30-4977-b596-0ca0075fbf4e","http://resolver.tudelft.nl/uuid:6116c204-5c30-4977-b596-0ca0075fbf4e","Design of a Free-space and Single-mode Fiber Coupling Device","Zondervan, A.","Spronck, J.W. (mentor); Herder, J.L. (mentor)","2014","A trend in metrology is the development of optical sensors. These types of sensors benefit of the minimum interaction of light with standard noise sources (e.g. electric fields) and the high carrier frequency (THz) - allowing for more accurate measurements than with conventional electronic sensors. The use of a laser and an optical fiber to guide the laser light in such metrology applications can easily be motivated. In order to facilitate the coupling of a laser beam (?10?3[m]) into a single-mode fiber (?10?6[m]), a device is needed. Even though such devices are available today, a clear demand can be seen for a device that reduces alignment effort and increases optical efficiency to a minimum of 30% or preferably more. Realizing established firms designed and build the non-satisfactory devices available today motivates an in-depth study of the optics involved to translate the requirements for a free-space-to-fiber in-coupling device into specifications. An analytical method is presented in this report that allows the user to assess the performance of both theoretical and realized coupling devices based on a single lens principle. The method and assumptions regarding initial alignment are used to assess devices available today, which all proved lacking in specifications or even their basic principles. A new control principle is designed, prototype build and analyzed in accordance with this method. Summing up the results of the report, it can be concluded that a working prototype has been build that demonstrated in-coupling at the expected theoretical maximum efficiency (_ 86%). Regarding the objective, up to 87.8% of the optical power produced by the laser is coupled in to the fiber. The prototype is able to maintain coupling over time with a transmittance efficiency higher than 63.9% for at least 32 hours. Moreover, a layman is able to use the device reaching an efficiency higher than fifty percent.","Optical Fibre Alignment","en","master thesis","","","","","","","","2019-08-28","Mechanical, Maritime and Materials Engineering","Precision and Microsystems Engineering","","","",""
"uuid:a70b8627-2a24-440f-b80b-21dc50a58eae","http://resolver.tudelft.nl/uuid:a70b8627-2a24-440f-b80b-21dc50a58eae","Meaningful interactions for rehabilitation therapy","Szaniawski, M.","Goossens, R.M.H. (mentor); Boess, S.U. (mentor); Kraan, G. (mentor)","2014","Motor rehabilitation therapy requires patients to be highly motivated in order to exercise regularly. However, rehabilitation practices are not designed to be motivating and are of repetitive nature. This is why patients are not motivated to exercise frequently and fail to engage with therapy. As a result of that they cannot regain their hand abilities and need to prolong their treatment. Serious games try to counteract upon. However, in the context of healthcare they always fulfil a medical purpose and are more of an obligation to the patient. For this reason these applications cannot be considered a game, since playing is intrinsically motivated and cannot be compelled. Therefore changing the patient mindset by increasing intrinsic motivation towards rehabilitation effective tasks (i.e. games) is the prerequisite to facilitate practice behaviors and increase therapy adherence. This can be achieved through meaningful interactions by altering the nature of rehabilitation exercises from a repetitive physical effort to a playful and motivating challenge. Introducing the concept of possible selves to rehabilitation therapy, the patient mindset can be altered and practice behavior endorsed on an intrinsic level by giving the patient an outlook on possible future benefits and consequences of his behavior. By bringing the patient´s mindset in the right state any subsequent behavior or application will be performed out of intrinsic interest to recover.","Patient motivation; Motor rehabilitation therapy; Possible selves; Meaningful interactions; Persuasive gaming; Leap motion; Rehabilitation exercises; Engagement; Video; Gamification","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Master of Science Design for Interaction","",""
"uuid:3612b80c-7cd8-4ccf-86bd-6e163f5a25f2","http://resolver.tudelft.nl/uuid:3612b80c-7cd8-4ccf-86bd-6e163f5a25f2","Design of a body supported head rest for people with a neuromuscular disease","Steenbergen, R.","Herder, J.L. (mentor)","2014","People with a neuromuscular disease have to deal with decreasing muscle force as their disease progresses. Muscles around the head and neck are weakened too. As a consequence it becomes energy consuming to keep their head and neck in a forward bended position. For instance during reading, eating or doing computer work. This study proposes an analytical approach to this problem by using a simple biomechanical model of the head and neck. Analysis of forces acting around the head and neck joints resulted in a new balancing strategy for head supports. The proposed design helps the patient’s muscles in creating counteracting head and neck joint torques when the head and neck are in a forward bended position. Reaction forces are guided to the body. A prototype was designed to do a technical evaluation of the conceptual design. Measurement results show a positive indication that joint torque head weight balancing can be done by normal linear and compact torsion springs while reaction forces guided to the body are low. The design is slim, out of the face of the user, concealable underneath clothing and it can be used sitting in a (wheel)chair or while standing and walking.","head rest","en","master thesis","","","","","","","","2014-12-18","Mechanical, Maritime and Materials Engineering","BioMechanical Engineering","","BMD","",""
"uuid:b2b01289-dc32-45ed-b71b-2a0a1e484b56","http://resolver.tudelft.nl/uuid:b2b01289-dc32-45ed-b71b-2a0a1e484b56","Patent to Product: Business models for the case of a patent on control optimization of wind turbines","Marges, S.J.","Verburg, R.M. (mentor); Bouwman, W.A.G.A. (mentor); Kamp, L.M. (mentor); Katzy, B.R. (mentor); Horodyskiy, V. (mentor)","2014","Present master’s thesis is conducted towards the translation of an technological innovation into a viable business model. To accompany the research, the case of Mita-Teknik is introduced. The Danish company has an R&D department based in Ukraine, where a patent is filed for reducing yaw error. The head of R&D is therefore interested in looking for a proposal towards commercialization opportunities of the patent and how to implement this product in the company’s product portfolio.","","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Economics of Technology and Innovation","","Management of Technology","",""
"uuid:7adc1bdb-88a6-4908-b4f5-b20c403ebb53","http://resolver.tudelft.nl/uuid:7adc1bdb-88a6-4908-b4f5-b20c403ebb53","Harnessing Solar Power for Productive Use","Howell, R.","Storm, S. (mentor); Kroesen, O. (mentor); Van Beers, C. (mentor)","2014","As sub-Saharan Africa seeks to address their growing energy demands given financial constraints, limited capital, and poor existing infrastructure; Uganda presents a particularly challenging case among African countries. With a rapidly growing population and economy and rural electricity penetration of only about 5%, the Ugandan government is targeting increased rural electrification in its energy policies. Many private and public initiatives are aiming at exploiting the investment potential that rural electrification provides while seeking to address this economic need. This master thesis explores the economic impact of rural electrification on micro enterprises in western Uganda.","rural electrification; impact evaluation; Uganda; statistical modeling","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Economics of Innovation","","","",""
"uuid:c339da34-8009-4815-8bc9-32547e34227b","http://resolver.tudelft.nl/uuid:c339da34-8009-4815-8bc9-32547e34227b","Control of gene expression in E. coli using light induction","Krishnan, M.","Meyer, A.S. (mentor)","2014","Biomaterials in nature provide abundant source of inspiration for the design and synthesis of novel high-performance materials. Nacre, a bio-mineralized material found in the inner lining of seashells has recently gained attraction due to its impressive material properties and eco-friendly nature. This ultra-tough coating could become inexpensive and can be the next-generation technology in aerospace and civil engineering if produced synthetically. The biological production of nacre can make building bio-concrete on Moon and several architectural applications possible. Controllability in the production of such biomaterials using photo-induction of different wavelengths of light, still remains a challenge. Light is an ideal tool to control living cells since it induces output through an external stimulus1. This provides great flexibility in controlling cells without having to manipulate the cell at genetic and metabolic level1. Light-mediated control of gene expression has various applications in the field of functional genomics, systems biology and biotechnology1. Previously a recombinant red light-sensor in Escherichia coli was engineered by Tabor et.al (2005) by combining Cph1, a red/far-red light switchable cyanobacterial phytochrome and EnvZ/OmpR two-component signalling pathway natively present in E. coli. Thereafter, they reported the development of a green sensor in E. coli from CcaS-CcaR, a green/red photoswitchable two-component system found in cyanobacteria Synechocystis2. This project will study the expression of both red and green sensors in E. coli to construct spatial patterning of layers of output, with further purpose of producing bio-layers of nacre. Study of the two- optical control of transcription across a layer of engineered cells will be the prime aim. Creation of patterns using these engineered cells can be helpful in designing the production of alternate output layers. The transfer function (the relationship between input strength and output strength) of each sensor individually and in combination will be studied, as well as tuning the output through different durations of light application. Fine tuning of the circuit to improve the background output is of high consideration for such a light-switch based application. Therefore, an attempt to create a random RBS library in order to reduce the background output signal given by the sensors under dark will be carried out.","E. coli; light induction; synthetic biology","en","master thesis","","","","","","","","","Applied Sciences","Biotechnology","","Life science and technology","",""
"uuid:229094b2-9d70-425b-b548-c802e8c42b1a","http://resolver.tudelft.nl/uuid:229094b2-9d70-425b-b548-c802e8c42b1a","Foundation repair: In search of a more cost-effective construction method","Klaver, T.","Nijsse, R. (mentor); Schipper, H.R. (mentor); Everts, H.J. (mentor); De Jong, D. (mentor)","2014","","foundation repair; foundation renewal; foundation problems; funderingsherstel","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","","",""
"uuid:a30b307b-2877-4739-a99c-b2f28ec34eb4","http://resolver.tudelft.nl/uuid:a30b307b-2877-4739-a99c-b2f28ec34eb4","Shear-Deforming Textile Reinforced Concrete","Woodington, W.G.","Nijsse, R. (mentor); Bergsma, O.K. (mentor); Borgart, A. (mentor); Schipper, H.R. (mentor)","2014","A new type of material to create double-curved freeform structures using shear-deformation.","TRC; Double Curvature; Shell","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Building Technology & Physics","",""
"uuid:9994980c-e1df-47a6-880a-3a226797e34a","http://resolver.tudelft.nl/uuid:9994980c-e1df-47a6-880a-3a226797e34a","Application of the Spherical Shaping Method to a Low-Thrust Multiple Asteroid Rendezvous Mission: Implementation, limitations and solutions","Roegiers, T.G.R.","Noomen, R. (mentor)","2014","Since the development of the exponential sinusoid for low-thrust trajectory design by Petropoulos and Longuski [2004], more shape-based methods have emerged that ease up the work of a mission analyst. These methods are the ideal tool to generate a quick and almost complete overview of a large search space and are useful for producing first estimate trajectories. The spherical shaping method by Novak [2012] is one of the more recently developed methods capable of shaping a transfer in three dimensions, satisfying constraints on initial and final position and velocity, and capable of satisfying a time of flight constraint; all at the same time. This makes it a particularly interesting method for application to rendezvous missions. In this thesis, the spherical shaping method will be used to generate first estimate trajectories for the GTOC2-mission (a multiple asteroid rendezvous mission). The goal is to find out whether or not the spherical shaping method is capable of producing sub-optimal trajectories. Implementing the spherical shaping method turned out to be a more massive job than anticipated. The documentation in the PhD thesis by Novak [2012] appeared not to be fully sufficient to use the method. Additional derivations were necessary to grasp the meaning of some functions. In this thesis, this process is explained and corrections of some typos found in Novak’s PhD thesis, are given. The spherical shaping function relations are re-ordered in a step-wise implementation scheme. This helps to get an overview of the implementation and will make future applications of this method easier. The implemented method is fully validated, both with respect to general two- and three-dimensional trajectories and with respect to the same test cases as used by Novak [2012]. The applicability of any method is dependent on its limits. For the spherical shaping method, these limits were not given unambiguously. Novak [2012] speaks of low and high inclinations but does not specify what is meant by ""low"" and ""high"". To find out what the limits for the inclination of the orbit are, several trajectories were computed for a range of inclination angles, for both trajectories at a constant inclination and trajectories with inclination changes. It was found that up until an inclination of 15 degrees, the relative difference between the deltav for a transfer at this constant inclination and the deltav for a same transfer at a zero inclination remains below 1 percent. For higher inclinations the difference rises quickly. At high inclinations of about 50 degrees the method breaks down. Also the Keplerian arc can not be reconstructed at inclined orbits. A way to solve this problem is to perform a reference frame transformation. A transformation involving a rotation over the line of nodes to remove the initial inclination was developed. This transformation works perfectly when the right ascension of both the initial and final orbit is equal and removes the effects caused by the high inclination. Also for high inclinations of above 50 degrees the spherical shaping method with reference frame transformation keeps producing feasible trajectories. The Keplerian arc can now be reconstructed at any inclination. When the right ascension of both orbits differs, the rotation is performed over the initial line of nodes, which makes it a less interesting rotation for the final orbit. To find out up to which right ascension difference the transformation can be used, several trajectories were computed for a range of right ascension differences (keeping other characteristics equal). It was found that up to 10 degrees the reference frame transformation can be useful. For higher differences in the initial and final right ascension of ascending node, the reference frame transformation could do more harm than good. To solve for high inclination changes, a solution was proposed to solve for multiple smaller inclination changes and sum the results. A promising result is obtained when combining this summation with the reference frame transformation. A last verification is performed by applying the implemented spherical shaping method to multiple test cases. Good results are obtained and therefore the implementation is considered fully validated. Finally the spherical shaping method is applied to the GTOC2 problem, using the top 3 asteroid combinations found by GTOC2, Heiligers [2013] and Secretin [2012]. Monte Carlo simulations with 100,000 samples were run and for each asteroid combination feasible trajectories are obtained, within the constraints set by GTOC2. The initial search space was set too broad which resulted in less feasible trajectories for GTOC2. Additional runs for a smaller search space are needed. There is however no time left to do this as well. It is recommended that the search is continued and a more thorough optimisation is performed. For the objective function of the GTOC2 problem a best value of 71.12 kg/yr was obtained for the asteroid combination equal to GTOC2 rank 2. Also a minimum value of deltav was obtained, equal to 20.04 km/s, for the asteroid combination of Secretin [2012] rank 3. Better results for both the objective function values or deltav for all asteroid combinations are expected when a more extensive optimisation is performed for the implementation of the spherical shaping method.","low-thrust; shape-based method; mission design; interplanetary trajectory; spherical shaping method; rendezvous; shape-based approximation; trajectory design; GTOC2; Global Trajectory Optimisation Competition; optimisation","en","master thesis","","","","","","","","","Aerospace Engineering","Astrodynamics and Space Missions","","Orbits & Missions","",""
"uuid:8be82b5f-7945-4eef-953f-248ef2d6b16a","http://resolver.tudelft.nl/uuid:8be82b5f-7945-4eef-953f-248ef2d6b16a","Calcite dissolution behaviour during low salinity water flooding in carbonate rock","Den Ouden, L.","Bruining, J. (mentor); Guo, H. (mentor); Nasralla, R.A. (mentor); Kruijsdijk, C.P.J.W. (mentor)","2014","Low salinity water flooding (LSF) has been proved to be a promising enhanced oil recovery method for sandstone reservoirs. The efficiency of LSF in carbonate reservoirs has not been proven completely yet, because there are still uncertainties about the LSF recovery mechanism in carbonate. From experimental studies, it was shown that wettability alteration, due to salinity reduction, is able to mobilize the remaining oil. Some studies attributed the wettability alteration by LSF to Calcite dissolution. Furthermore, Calcite dissolution can influence the salinity and pH of injected brines, and hence the oil recovery. However, there is a lack of experimental data on the Calcite dissolution effect of LSF in carbonate rock. The objective of this experimental study was to get a better understanding of the Calcite dissolution behaviour and how it might affect the oil recovery. Bulk and coreflood experiments have been performed; the experimental data was history matched with the use of PHREEQC. Calcite dissolution decreased with decreasing PCO2 and increased with decreasing pH and increasing NaCl salinity from 500-2000PPM. Increasing the injection rate reduced the interaction time and therefore Calcite dissolution did not reach equilibrium in coreflood at high rates. Calcite dissolution from chalk matched with the Calcite dissolution from pure Calcite, while Calcium concentration in effluent from limestone was higher. The two-phase coreflood experiment confirmed that Calcite dissolution occurs as well if oil is present in the porous media, but showed lower values than in single-phase coreflood experiment. pH increased from 5-6 to 9.5 due to Calcite dissolution, which might have an effect on the rock and oil surface charges, and hence oil recovery improvement. The effluent of the two-phase coreflood showed that an emulsion was formed, which suggested formation of in-situ surfactants. From CT scans, micro-CT scans and material mass balance calculations an increase in porosity around 1 % was observed. The increase in the total dissolved species due to Calcite dissolution was not significant, which will not harm LSF effect.","low salinity water flooding; mineral dissolution; carbonate rock; PHREEQC; core flooding experiments","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Petroleum Engineering","",""
"uuid:c5870e1c-5866-4b56-8f2b-bcc8304acb8c","http://resolver.tudelft.nl/uuid:c5870e1c-5866-4b56-8f2b-bcc8304acb8c","A fully integrated development environment for GOAL in Eclipse","Koeman, V.J.","Hindriks, K.V. (mentor)","2014","For the GOAL agent programming platform, a new, full-fledged IDE was created that provides support for all phases in the agent program development process, with the concepts of integration and adaptation at its base. Using the DLTK framework, a plug-in for the Eclipse platform was created in multiple iterations, continuously evaluating the usability during this process using SUS evaluations. Besides an editing framework, based on newly developed ANTLRv4 grammars, a fully integrated debugging environment was designed and developed. As agent programming languages are based on very different concepts than the more widely supported and documented programming languages like Java and C, this process was not straight-forward. The mapping of popular existing concepts and the creation of new AOP-specific standards has been documented in this work. Besides improving the development support for all different kinds of GOAL developers, this thesis aims to set a new standard in the field of multi-agent programming. Care has been taken to explain all steps in detail, and this work has been made as generally applicable within the multi-agent programming field as possible. Therefore, this thesis is also a full guide to the design and development of a mature and professional IDE for multi-agent programming. The full process of the creation of this IDE is presented in this thesis, with an evaluation of the state-of-the-art through literature and existing IDEs at its foundation. Additionally, a prototype was developed to increase the understanding of the requirements for such an environment.","agent; IDE; Eclipse; AOP; GOAL; development; tooling","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Intelligent Systems","","Interactive Intelligence Group","",""
"uuid:807390dd-a3c9-4442-97ac-2281083bd2f7","http://resolver.tudelft.nl/uuid:807390dd-a3c9-4442-97ac-2281083bd2f7","Unraveling the difficulties of implementing and operating a public SSC: Case study towards the effect of governance on the perceived performance of shared service centers in the public sector","Van Zeijl, E.","De Bruijn, J.A. (mentor); Van der Voort, H.G. (mentor); Janssen, M.F.W.H.A. (mentor); Aalders, M.J. (mentor)","2014","","shared services; public sector; governance; organizational culture; perceived performance","en","master thesis","","","","","","","","","Technology, Policy and Management","Policy, Organisation, Law and Gaming","","","",""
"uuid:604b5873-915b-4aee-aae8-cc2d458c8efe","http://resolver.tudelft.nl/uuid:604b5873-915b-4aee-aae8-cc2d458c8efe","Stakeholders’ Perspective of Mobile Payment Platforms","Manocha, S.","Bouwman, W.A.G.A. (mentor); De Reuver, M. (mentor); Warnier, M.E. (mentor)","2014","Today, mobile phones have become an indispensable part of our lives. With new innovations and advancements in technology, various applications of the mobile phones have been introduced. One of the popular application is ‘Mobile Payments’, which forms an integeral part of this thesis. There are several mobile payment solutions present in the market nowadays. However, not even a single solution has succeeded in achieving a mass-market adoption. A possible reason could be that the stakeholders in mobile payments market belong to different industries, mainly Financial, Telecommunications, Retail and others, where each of these actors have varied interests in payments market. Thus, this master thesis aims to understand the interests and preferences of these stakeholders towards mobile payment platforms. The primary focus of this study is to identify the different criteria on which the stakeholders preferences could be collected. The research also gathers insights on common mobile payment platforms with a goal to identify which platform could emerge as a dominating solution. The research question of the thesis being; ‘What are the perspectives of different stakeholders towards mobile payment platforms and what would be its strategic implications in the market?’ Based on payment providers, three mobile payment platforms have been identified. These are Intermediaries led Over-The-Top Platforms, Bank/Telco-led NFC Platforms and Merchant-led Platforms. An example of each type of the platform is included to induce better and practical understanding of the different platforms. Further the approach for finding the relevant criteria, on which stakeholders opinions would be taken, has been conducted in two ways,  By studying the existing literature focused on stakeholders’ interests and factors that have been found important in mobile payments domain. The criteria identified were: Market Acceptance, Strength of Leading Players, Security with respect to location of secure element, Costs, Universality, Usability and Customer Ownership.  By studying Platform theories derived from Economic research journals and Strategic Management literature. This included concepts like Platform Competition, Platform Openness and Platform properties. The platform related criteria included were: Network Openness, Platform Compatibility, Product Differentiation, Governance, Customer Base, Homing Costs, Market Power, Right Partners. Similar factors have been grouped into four main categories: Technological, Organizational, Strategic and Economic. The research methodology used is a Multi-Criteria Decision Making(MCDM) method called Analytic Hierarchy Process(AHP). This method makes use of hierarchy levels in the criteria/factors for building a research model. Web-based surveys were used to collect opinions from the stakeholders belonging to different industries. Few academic scholars were also approached for the survey purpose in order to differentiate in academic and industrial outlook. Pair-wise comparison method was applied to collect and analyse data in surveys. The results of the thesis indicate that the financial and telecommunications organizations hold the highest priority towards competitive aspects related to mobile payments. Financial institutions prefer to achieve this strategic advantage by possessing a high market influence whereas telecommunications organizations prefer differentiating or bundling new services to the payment platforms. Retailers ranked economic aspects as their priority, implying the importance of customer ownership, costs and acceptance of platform in the market. Whereas the academic experts expressed their opinion of having a universal payment solution. Interestingly, all the stakeholder groups have shown highest preference towards platforms that are provided by banks or telecommunication organizations over the ones provided by merchants or intermediaries. The findings of the research could be used to facilitate better collaboration among the actors of the mobile payments ecosystem. The theoretical contribution lies in extending the concepts from platform theories into mobile payments.Till now these theories have mostly been applied to card solutions in the payments domain. This thesis concludes the relevance of platform competition and platform leadership in the mobile payments domain. Also as most of the studies on mobile payments are based on customers, the focus of this study on multiple supply-side actors provides a unique and significant contribution to the literature. Since the thesis focuses primarily on Dutch market , recommendation has been provided to validate the results in different markets or countries in order to distinguish any cultural differences in the mobile payments market. Finally, this research sets a basis for future researches to identify more similar criteria/factors that could influence the decisions of stakeholders in the mobile payments market.","stakeholders; mobile payments; payment platforms; over the top; merchant platforms; near field communication","en","master thesis","","","","","","","Campus only","2014-08-28","Technology, Policy and Management","Information and Communication Technology","","Management of Technology","",""
"uuid:82720de2-114a-44b7-b160-ce26826121be","http://resolver.tudelft.nl/uuid:82720de2-114a-44b7-b160-ce26826121be","Poetry of the everyday: An exploration into the design for poetic experiences","Santokhi, G.D.","Sonneveld, M. (mentor); Özcan, E. (mentor)","2014","Poetic experiences seem ineffable and rare, but they occur more often than one would assume. Think of gazing at the stars and feeling incredibly small. The joy that stepping in fresh snow brings and makes you appreciating being part of nature. Or standing on top of a mountain and admiring the view, being in awe. See? It is not necessary to be a poet in order to have the same sort of experience as one; neither is reading a poem a prerequisite for poetic experiences of the everyday. This graduation project was a research project to make a first exploration into the possible applications of poetic experiences in product design. Interviews and generative sessions provided examples of moments that are poetic. Analysis through the Grounded Theory approach culminated into a framework that explains what people go through during poetic experiences and what influences them. One of the conclusions of the research is that people have poetic experiences without knowing why they are poetic. There is potential in the field of design to cultivate this awareness in users and improving their wellbeing.","poetry of the everyday; poetic experiences; poetic","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","","",""
"uuid:9bde63b2-d061-4267-acfd-409054090663","http://resolver.tudelft.nl/uuid:9bde63b2-d061-4267-acfd-409054090663","De verschillende aspecten van Riemanns ?-functie","Van Tatenhove, J.I.","Van Neervan, J.M.A.M. (mentor)","2014","In dit verslag wordt de analytische uitbreiding van de ?-functie besproken, samen met nog drie andere alternatieve schrijfwijzen. Er worden een aantal eigenschappen van de ?-functie en haar nulpunten afgeleid, waaronder een formule van het aantal nulpunten N(T) met imaginair deel tussen 0 en T. Daarna wordt numeriek aangetoond dat de pair correlation en de nearest neighbour distribution van ? en Hermitische matrix hetzelfde is. Ook worden Bernoulli-getallen geïntroduceerd en worden twee formules die deze getallen en ? aan elkaar koppelen afgeleid. Het geheel wordt afgesloten met de bespreking en implementatie van een algoritme dat de waarden van ? uit kan rekenen.","riemann; zeta; complex function; analysis","nl","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","","",""
"uuid:0eeda255-a6a2-4225-b070-5a57b65aa1bc","http://resolver.tudelft.nl/uuid:0eeda255-a6a2-4225-b070-5a57b65aa1bc","Alternative approaches to financing innovation","Nobel, A.","Naastepad, C.W.M. (mentor)","2014","Introduction – The principle of shareholder value maximization raises concerns about reduced levels of investment in innovation (Lazonick, 2011a). Since shareholder value maximization entails to maximize profits for the shareholders of corporations, the principle is connected to the allocation of capital in markets. There are concerns about the hampering impact of the short-term orientation of investors in capital markets on corporate governance (Abernathy & Hayes, 1980; Hill, Hitt, & Hoskisson, 1988; Kelm, Narayanan, & Pinches, 1995). A recent survey among corporate executives revealed that 78% of the participants would give up economic value if this would enhance quarterly earnings. Moreover, 55% of the executives would reject very profitable projects in the face of quarterly earnings pressure (Graham, Harvey, & Rajgopal, 2005). This seems to be problematic especially when innovation is concerned. Innovation is a cumulative, uncertain process which requires financial commitment of capital-providers (Lazonick, 2007). This thesis, therefore, attempts to answer the following research question: Research question – “How and under what conditions can finance be linked with innovation?” Research approach – The research conducted for this thesis is mainly theoretical for the reason that corporate governance is shaped to a large extent by the economic theories that corporate executives, investors and policy-makers hold as valid. Importantly, scientific theory and practice can be mutually reinforcing (Miller, 1999; Ghoshal, 2005). Scientific theory can even be self-fulfilling because it generates knowledge that human beings hold (Schwartz, 1997). Thus, in order to see economic theory in relation with corporate governance a research approach is needed that takes into account both theory and practice. The approach taken here is based on the human uncertainty principle (Soros, 2013). Human uncertainty applies to situations in which ‘participating agents’ are part of the world they try to comprehend. Since individuals can manipulate or have an impact on the world, there is reflexivity between the subjective understanding of the participating agents and objective reality. The framework also assumes fallibility at the part of individuals. Finally, Soros (2013) assumes for his framework that individuals make an impact on the world for the purpose of their self-interest. This thesis takes issue with this assumption and subjects it to the principle of reflexivity in itself. Only if such an assumption is not taken for granted, a thorough analysis of its impact on the circular dependency between theory (including moral philosophy) and practice is possible. Two existing theoretical perspectives are analyzed with regard to the question how finance can be linked with innovation: the set of theories that together prescribe shareholder value maximization, and the ‘regulatory’ perspective. For both perspectives the ethical foundation is analyzed as well. In addition, a third perspective based on various extant ideas and an alternative ethical foundation is advanced. Defining innovation – Innovation is a cumulative, uncertain process that aims to develop new or better goods and services by exchanging and creating knowledge (Lazonick, 2007; Landry, Amara, & Lamari, 2000). In literature different kinds of innovation are distinguished, most importantly technological and non-technological innovation, and product and process innovation (Armbruster, Bikfalvi, Kinkel, & Lay, 2008). Technical change as a result of technological innovation is acknowledged to be a driver of economic growth (Rosenberg, 2004; Cameron, 1996). A much quoted piece of work in this field comes from Solow (1957) who derived estimates for total factor productivity (labour and capital) and concluded that technical change is the main cause of economic growth. However, in order to capture all types of innovation and to include innovations that do not necessarily lead to marketable products, innovation is here defined as the development of new ideas, methods, products and processes. Why is innovation important? First, innovation can create benefits for consumers that result from the use of new or better goods and services (West, 1996). Second, innovation can create productivity growth (Cameron, 1996). The productivity of countries is positively associated with national living standards (Abernathy & Clark, 1985), which is often measured by income per capita (Van Ark & McGucklin, 1999; Baregheh, Rowley, & Sambrook, 2009). However, the use of resources that are freed as a result of productivity growth determines whether innovation really leads to higher living standards across society (Wolf, 2014). The gains from higher productivity can result in a shift of the income shares received by workers and capital-owners (Wolf, 2014). During the last decades an increased share of income has gone to capital income at the expense of the share of labour income (Mishel, 2012). An important concomitant fact is that capital income is predominantly received by a small fraction of the population because the ownership of financial assets is concentrated among the wealthier households (Wolf, 2012). The implication is that the distribution of the gains from innovation is an important determinant of the benefits that society reaps from innovation. An interesting concept that aims to evaluate innovation is Responsible Innovation. The following working definition is assigned to Responsible Innovation: “a transparent, interactive process by which societal actors and innovators become mutually responsive to each other with a view on the (ethical) acceptability, sustainability and societal desirability of the innovation process and its marketable products” (Von Schumberg, 2011, p.9). However, how are acceptability, sustainability and desirability operationalised? The responsibility criteria might have different connotations among different groups in society. The meaning of acceptability, sustainability and desirability depends on what human beings think these criteria entail. This implies that the notion of responsibility is tautological: something is responsible if we (the innovators and societal actors) think it is responsible. Hence, the operationalisation of responsible innovation is problematic. Another concept that aims to assess the responsibility of corporations is corporate social responsibility (CSR). This may as well be applied to innovation. CSR refers to the question what the responsibility of firms is beyond their responsibility toward shareholders (Cochran, 2007). However, the bulk of CSR literature focuses on how CSR can enhance profitability (cf. Porter & Kramer, 2006; Motion & Weaver, 2005; Harjoto & Jo, 2011). The lack of rigor renders CSR prone to being used as a strategic instrument, rather than what it was really meant for: assuring that the activities of firms are of public benefit, which was argued by Dodd (1932). CSR is, then, also of little help for the research problem at hand because it lends itself to be used for profit maximization, whilst concerns about underinvestment in innovation exactly revolve around profit-maximizing behavior of corporations. Responsible innovation – and its conceptualization as the inclusion of public values (Correljé, Cuppen, Dignum, Pesch, and Taebi, 2014) – is a more strict subset of CSR, because it gives criteria and explicitly requires the involvement of the public. The use of the concept of responsible innovation requires that responsibility is considered internal to the firm because the production and distribution of goods and services that result from innovation are intrinsically linked to the business. This makes firms more accountable because the boundaries of the concept of responsibility are less ambiguous, leaving less space for unrelated ‘compensation behavior’. However, the fact the distribution of gains from innovation is an important determinant of the benefits of innovation across society – and thus its desirability - implies that there are consequences of innovation – beyond the innovation process and its marketable products – that affect the criteria proposed by Von Schumberg (2011) for the assessment of responsible innovation. It would be sensible to include the economic consequences of innovation in the responsible innovation framework as well. The standard economic approach to financing innovation – The standard theory of the firm consists of several theories that together explain profit maximization for shareholders. First, agency theory analyzes the transaction costs that arise within the firm as a result of ever-growing organizations (Jensen & Meckling, 1976). Jensen and Meckling propose solutions for the agency problem that arises when the ownership of corporate stocks and control over the corporation are separated. This is typical for firms in the Anglo-Saxon world, where ownership is dispersed and individual external shareholders have little control over the firm (Desender, 2009). Agency theory arose because scholars were concerned with the performance of organizations in which the agents who take decisions do not bear the wealth effects of their decisions (Fama & Jensen, 1983). In agency theory, the firm is modelled as a ‘nexus of a set of contracting relationships’ (Jensen & Meckling, 1976, p.9). Agency theory proposes an internal solution to regulate the relationship between shareholders and firm executives by means of a contract that creates incentives for executives to maximise shareholder value. The external solution is to use capital markets as a disciplining device (Jensen & Meckling, 1976). Second, agency theory is based on the corporate objective function of maximization of shareholder value, because it presumes that firm performance equals stock performance. The contractual relationship that arises in the organizational context limits the risks of the agents by promising a fixed payoff, while the principals have the right to claim the remaining net cash flows (Fama & Jensen, 1983). This means that if the responsibility of the firm is to maximize profits, this is equivalent to maximizing shareholder value because the residual cash flows flow to the shareholders under this contract. This idea of shareholders as residual claimants derives from the Anglo-Saxon world and is legally determined in the United States and the United Kingdom (Weimer & Pape, 1999). The assertion that the only responsibility of the corporation is to maximize profits was coined in an essay by Friedman (1970). He argues that any deviation from maximizing shareholders’ profits is against the interest of the executive’s employer – the shareholder - , rendering the appointment of an agent to make decisions on behalf of the principal unjustified. Friedman (1970) further argues that any social responsibility other than profit maximization exercised by executives undermines the basis of free society. The assumption on which this argument rests is that a free society provides individuals with the possibility to maximize personal, material gains. Importantly, if a corporation pursues only profit maximization, it will only attract those investors who seek to maximize their profits. Also, executives who focus on short term profit maximization attract investors who are concerned with quarterly earnings (Brochet, Serafeim, & Loumioti, 2012). On the contrary, if a corporation decides to pursue social objectives other than the maximization of shareholder value, it can attract those investors who have the same social objectives. This means more concretely that if a higher level of investment in innovation comes at the cost of private gains, it may still be justified if it is what the shareholder wants. Yet, the ability of corporations to choose which objectives to pursue is restricted if they are obliged to engage in profit maximization for shareholders. Using Soros’ (2013) reflexivity, a reinforcing mechanism exists between what the corporate objective is and what investors are attracted to the corporation. The possibility for corporations to pursue other objectives than profit maximization is smothered by educating standard economic theory in business schools, which purports that the purpose of corporations is to maximize shareholder value (Ghoshal, 2005), and the widespread acceptance of this assertion among executives and investors. More generally, the embodiment of the idea of self-interestedness in agency theory and the principle of shareholder value maximization has shaped the use of the stock corporation as a vehicle for the pursuit of self-interest via the principle of reflexivity. Third, economic agents looking for profit maximization are in charge of the allocation of capital in markets. However, throughout time the volatility in market prices has been much higher than could be possibly explained by rational expectations about future dividend payouts (Shiller, 1981). This raises the question whether the efficient markets hypothesis is founded on appropriate premises. The efficient markets hypothesis is based on the assumption that individuals are making rational decisions, only care about personal consumption and wealth as ends in itself, have independent and determinate preferences and have a rate of time preference (Mäki, 2002; Gintis, 2000). However, in ‘From Efficient Markets Theory to Behavioral Finance’ Shiller (2003) describes how initial enthusiasm for the efficient markets hypothesis and its assumptions have turned into more realistic thinking about human behavior. This illuminates the importance of understanding human behavior in the light of capital allocation beyond the rational actor model (Shefrin & Statman, 2011). Since the beginning of the 1980s real stock prices show that investor expectations increasingly exceeded what rational expectations of actual returns would have implied. This coincides with two trends in executive pay. First, executive pay has increased dramatically since the 1980s. Second, executive pay has become more closely linked with stock performance since the 1980s (Jarque, 2008). This suggests that investor expectations are more closely related to executive pay, rather than to the discounted value of all future cash flows. The assumption of rational decision-making based on full information is further violated by the uncertain character of innovation. Innovation is a process that is riddled with uncertainty (Jalonen & Lehtonen, 2011). A market allocation of capital to innovation may not be efficient exactly because markets cannot deal with the uncertainty surrounding innovation. Stock prices cannot reflect fundamental value if it is unknown what the fundamental exactly entails. Furthermore, unlike the Modigliani-Miller theorem – which advances that it does not matter how firms are financed and their market value is independent of the allocation of returns (Villamil, 2008) -, several studies indicate that short-term oriented investors can negatively influence investment in research and development (Dore, 2008; Brossard, Lavigne, & Sakinc, 2013; Stockhammer, 2006; Graves & Waddock, 1990; Demirag, 1998). Moreover, the cumulative character of innovation violates with the pace at which capital can be transferred. Ortt, Tabatabaie, Alva, Balini & Setiawan (2009) found that the time span between the invention of a new scientific or technological principle and the large-scale production and distribution of marketable products in five high-tech industries is as much as seventeen years on average, whilst David (2010) shows that the average holding time of stocks on the New York Stock Exchange has declined from up to twelve years in 1940 to approximately seven months in 2010. This implies a mismatch between the time horizons of capital and innovation. Finally, profit maximization guides capital allocation based on the premise that if firms maximize their market value, social welfare is maximized (Jensen, 2001). However, shareholder value can be created without necessarily fulfilling the needs of society by providing goods and services. Firms can pursue financial goals (Epstein, 2005), engage in stock buybacks or simply raise investor expectations (Lazonick, 2011a). Executives cannot do this indefinitely, but it confuses the allocation of capital based on profit maximization because the various ways in which shareholder value maximization can be created violate the justifying assumption that social welfare is maximized if the market value is maximized. Given that self-interestedness is problematic when investment in innovation is concerned, and given that the link between private and social gains is questionable, alternative approaches to financing innovation may be desirable. The ethical foundation of the standard economic approach – Standard economic theory shows resemblance with utilitarianism in two respects: (1) it assumes “the notion of maximizing behavior on the part of all individuals”, whilst managers “[..] will make operating decisions which maximize [..] utility” (Jensen & Meckling, 1976, p.312). This is understood to be profit maximization (Friedman, 1970); (2) it connects individual maximization with social welfare maximization (Jensen, 2001). Thus, the outcomes determine human behavior. This suggests utilitarianism, which holds that the consequences of actions determine the moral rightness of these actions (Van de Poel & Royakkers, 2011). Utilitarianism holds that the ‘greatest amount of good for the greatest number of people’ should be attained (Driver, 2009). The justification for the principle of shareholder value maximization also resembles this principle. Jensen (2001) states about this: “Two hundred years of work in economics and finance implies that [..] social welfare is maximized when each firm in an economy maximizes its total market value” (p.1). Utilitarianism is subject to several criticisms. First, the ‘greatest good for the greatest number’-principle does not take into account the distribution of the good. This is problematic, especially since this thesis is concerned the distribution of the gains from innovation. Second, some matters can not be quantified because they do not carry a quantitative or monetary value (cf Hansson, 2007). Furthermore, utilitarianism depends on value judgments if qualitative values have to be translated into quantitative values. Third, utilitarianism assumes that (1) pleasure is the only thing that is desired, and (2) all other things are instrumental to this (Rachels, 2009). Put differently, pleasure or happiness, is intrinsically good while other things are instrumentally good. This may not be true, since individuals may consider things other than pleasure to be good. Utilitarianism could be stretched to include matters beyond what is assumed to be valued in the standard economic framework. The latter simply assumes that individuals “only advance material self-interest” (Dohmen, Falk, Huffman, & Sunde, 2009, p.1). Importantly, utilitarianism does not necessitate self-interestedness. It is essential to distinguish between three ethical theories which together form consequentialist theories: ethical egoism, ethical altruism and utilitarianism (Craig, 1998). Ethical egoism refers to looking after your self-interest, while ethical altruism refers to looking after the interests of others (Heathwood, 2014). Utilitarianism means to look at the total utility by adding up the self-interest and interests of others. The implication for the standard economic framework is that if utilitarianism is amended to include ethical altruism as well, it may solve the problem of underinvestment in innovation. However, how will we decide on the balance self-interest and the interests of others? Egoism and altruism are still separated, meaning that there is ultimately a divide between the utility derived from self-interest and other-interest. Neglecting this division means to neglect the distribution of utilities. Second, the problem of making value judgments remains. Investors may come to different conclusions than innovators or societal actors, whilst some matters cannot be easily quantified. The implication is that an ethical foundation that looks at what human beings value may be more helpful, because utilitarianism depends on value judgments for which it has in itself no answer. A regulatory perspective on financing innovation – In attempts to address concerns of underinvestment in innovation two more ‘regulatory’ approaches may be taken: (1) publicly financing innovation and (2) a stakeholder approach to financing innovation. Publicly financing innovation - Underinvestment in innovation in capital markets is generally modelled a consequence of the incomplete appropriability of knowledge (Romer, 1990; Hall, 2002). Jones and Williams (2000) point out that a solution for the resulting under-investment in R&D is to publicly fund R&D by creating tax incentives or providing for basic research. These solutions aim to resolve the problem of underinvestment in innovation. However, this approach leaves the market allocation intact, whilst trying to repair what markets are incapable of. Importantly, financing R&D activities publicly has important implications for the distribution of risks and returns. The uncertain character of innovation creates inherent risks associated with investment in innovation. Publicly funding innovation implies that the cost and risks of R&D are borne by taxpayers (Lazonick & Mazzucato, 2013). Bearing in mind the proposed extension of the framework for responsible innovation – which is to include also the gains from innovation – it is not a sufficient argument to justify the publicly funding R&D because it provides society with innovations. Since it leaves the principle of shareholder value maximization intact it can even exacerbate the problem of income and wealth inequality as a result of productivity growth. Stakeholder theory - In an attempt to ventilate discontent about shareholder value maximization as the only corporate responsibility Freeman (1994) developed stakeholder theory. This theory holds that business is concerned with values and has to deal with several other parties beyond shareholders (Freeman, Wicks & Parmar, 2004). Stakeholder theory does not give pre-set clues on how to resolve disputes that can arise as a consequence of taking into account the interests of different parties. This leaves stakeholder theory open to subjective interpretation. Phillips (1997) noted this void and proposed that a principle of fairness can be used as a ‘source of obligation to stakeholders’. Stakeholder theory has important drawbacks that renders it unsuitable for better explaining investment in innovation than the standard economic framework. First, let us consider what stakeholder theory means for innovation. Given that the innovation process is a learning process in which knowledge is exchanged and built (Landry, Amara, & Lamari, 2000), workers within innovating firms make an important contribution to innovation. In this regard workers are essential stakeholders. Indeed, the level of knowledge available in firms positively contributes to innovation and firm performance (Thornhill, 2006). However, the application of the concept of fairness is problematic. Blair (1999) and Lazonick and Mazzucato (2013) claim that capital-providers are not the rightful owners of residual cash flows, but rather the workers themselves. However, others (e.g. capital-owners) may come to a different conclusion. Ultimately, fairness depends on the virtue by which it is established. Second, individuals are seen as stakeholders if they are connected to the corporation in their own interest, though they are bounded by fairness (Weiss, 1995). This means that maximizing behavior is limited to what is considered fair. However, stakeholder theory purports that: “[Stock] owners have financial stake in the corporation in the form of stocks, bonds, and so on, and they expect some kind of financial return from them” (Freeman, Wicks, & Parmar, 2004, p.42, italics added), implying that stakeholder theory accepts the view that capital-providers are interested in return on capital in the first place, because this is what connects them to the corporation. Third, the outcomes of innovation unfold much later in time. This means that a fair distribution of benefits and costs cannot practically be established at the time of the commitment of capital, because the outcomes are unknown. Thus, stakeholder theory is not sufficient for explaining investment in innovation, because fairness is conceptually challenging, and practically impossible to determine when innovation is concerned. The ethical foundation of the regulatory perspective – Stakeholder theory sees the firm as a collection of persons who are aiming to fulfill their self-interest (Donaldson & Preston, 1995). Stakeholder theory, then, seeks to answer a distributive question in which several individuals aim to maximize the fulfillment of their own interest. This raises two questions: on what model of human nature is stakeholder theory based? And, in which ethical foundation is this grounded? An alternative to the rational actor model of standard economic theory is the homo reciprocans model. Research supporting this model suggests that rationality of individuals does not mean that human beings only pursue self-interest (Gintis, 2000; Fehr & Gächter, 1998; Fehr, Kirchsteiger & Riedl, 1993; Dohmen et al., 2009; Falk, 2001; Aktipis & Kurzban, 2004). Individuals are prepared to incur substantial costs in order punish someone else for ‘free-riding’, even though this does not give any direct or indirect benefits (Bowles & Gintis, 2002). Individuals are reciprocal and have a propensity to cooperate. However, it cannot be argued that self-interest plays no role in the H. reciprocans model. Individuals can cooperate also for the purpose of self-interest. This thesis argues that stakeholder theory is based on the H. Reciprocans model. Notwithstanding the motivation that underlies H. Reciprocans (which can be ‘selfless’ reciprocal or ‘selfish’ reciprocal), the model aligns with stakeholder theory since it acknowledges interactions with various other individuals who are connected through their interest in something. Freeman (1994, p. 42) indeed argues that ‘[..] the stakes of each [stakeholder] are reciprocal, since each can affect the other in terms of harms and benefits as well as rights and duties.’ The question that is left unanswered by stakeholder theory and by the H. Reciprocans model is: what is fair? Some principle to determine fairness has to be embraced in order to reach conclusions. Blount (1995) set up experiments in which it was clearly ventilated to subjects that the distribution of benefits and costs was determined by a computer instead of an experimenter. He found that the tolerance for unequal outcomes among subjects was much higher if these were generated by a computer, suggesting that the violation of a cooperative norm is at work, rather than an aversion of unequal outcomes alone (Gintis, 2000). However, what is the source of these norms? When innovation is concerned, how is a moral rule established that is prescriptive for investment in innovation at the part of capital-owners? Phillips (1997) proposes to determine the distribution of benefits and costs among stakeholders by embracing the notion of fairness. Two prominent principles that can be used to make judgments about distributive fairness are the principles of equality and equity (Mayer, 2013; Welsh, 2004). First, the equality principle proposes that everybody should share in benefits equally. Second, the equity principle postulates that the distribution of benefits should tie in with the relative contributions of individuals (Mayer, 2013). If the equity or equality principle is used, then we may argue that it is a form of deontological ethics because it sees human action as morally right if it is in accordance with moral rules or principles (Van de Poel & Royakkers, 2011). Deontological ethics refers to a group of theories of which the work of Immanuel Kant is considered the most important (Mitcham, 2005). Kant argued that everybody should be able to reach conclusions about rules by logical reasoning. Another seminal work in this field is A Theory of Justice (first published in 1971) in which John Rawls explains that the ordering of principles or duties results in a theory of justice. The theory of Rawls is a deontological theory because it sees the protection of freedom of all individuals in society as a fundamental principle to which human action should obey. In his approach it depends on what duty one has to adhere to whether human action advances freedom in the various ways we can interpret it. The implication is that deontology can lead to a moral judgment comparable to the one resulting from a utilitarian approach to the extent that the protection of individual freedom to maximize wealth can be seen as a duty. Following John Rawls approach it depends on the perception of individuals among society whether this is indeed a duty. The implication is that it depends on how individuals across society are capable of reaching conclusions about what freedom they want to have protected. This could mean for capital-owners that they behave in an unjust way if individuals across society perceive their behavior as violating a moral rule (e.g. the rule to invest in innovation for the purpose of maximizing social welfare). This implies that self-interestedness is permitted up to the point where individuals across society think it is no longer fair. In consequentialism the happiness of some may be reduced if it maximizes total happiness for all (Scott, 2003). However, this may also violate the principle of justice as proposed by Rawls. On the other hand, if individuals derive utility from the protection of freedom of others, then consequentialism is not conflicting with deontology. Consequentialism in its widest conception includes both ethical egoism and ethical altruism, implying that it can be applied to stakeholder theory (by the inclusion of fairness). Human behavior based on cooperation and reciprocity can, then, simply be the result of attempts to maximize overall utility. In this regard the stakeholder perspective fits in a consequentialist framework. Importantly, both utilitarianism and deontology depend on human capacity to reason in order to make value judgments or to establish fairness, respectively. This implies that a theoretical perspective based on an ethical foundation that takes into account the human beings themselves may be more helpful for establishing the link between finance and innovation, because the outcomes of utilitarianism and deontology depend both on human capabilities. An Aristotelian perspective on financing innovation – This thesis advances a third perspective on financing innovation: an Aristotelian perspective. Aristotelian ethics was used in some recent attempts to connect ethics with economics (Meikle, 1996; Solomon, 2004; Sison, 2011). However, the Aristotelian perspective presented here does not exist yet in literature to the degree that various ideas are combined. Essential to the Aristotelian perspective is a different set of assumptions about human nature. According to Aristotle, the ultimate goal of human action is to realise human potential (Van de Poel & Royakkers, 2011). Importantly, human beings have to bring out the best in themselves and their community (Solomon, 2004). Realizing human potential can be understood in many ways. Houghton Budd (2011) points out that most people want to become ‘something’. Keynes (1930) also described a future in which human beings are no longer struggling for subsistence and have to look for alternative, non-economic purposes to devote their energy on. Furthermore, Maslow (1943) proposed a theory that outlines how the needs of human beings change once lower level needs (‘physiological needs’) are fulfilled. Lower level needs are ‘instinctoid’, whilst the highest level needs comprise matters such as developing morality, creativity and problem-solving. The conclusion that can be derived from these theories is that there may be a plurality of ways in which human beings can develop beyond the fulfillment of material (financial) needs. This can be different for each and every individual. What does this mean for capital? In Aristotle’s view, ‘wealth is a collection of tools’ that is a means toward realizing human potential (Politics I, 8, 1256b, 37-38; Nicomachean Ethics I, 5, 1096a, 5-7, in Giovanola & Fermani, 2012). Sison (2011) points out that Aristotle distinguished between natural wealth-getting and non-natural wealth-getting. Natural wealth-getting refers to the amount of wealth required to lead a good life. Any level of wealth-getting beyond this necessary amount of wealth is non-natural, because it does not advance the realization of human potential. Houghton Budd (2011) establishes the link between Aristotle and the distinction between material and immaterial needs by arguing that capital is also needed to finance the immaterial needs of human beings (this is called ‘aspirational capital’). How is innovation connected with immaterial needs of human beings? Innovation is a process of exchanging and building knowledge (Landry, Amara, & Lamari, 2000). Thus, we may ask ourselves: what is innovation other than human development in some sort of way (dr. Naastepad, personal communication, April 2014)? Innovation is a knowledge process that requires intellectual achievement for the purpose of building this knowledge. However, human development can happen in many ways (cf. Wachsmuth, 2014). This implies that human development does not equal innovation. Rather, innovation is one particular aspect or dimension of human development. This means that investment in innovation is inherent to the Aristotelian perspective presented here, because it advances that capital serves human development. If innovation is one dimension of human development, then wealth also serves innovation. It is important to note that the provision of aspirational capital is precluded by the standard economic framework and the regulatory perspective. However, Houghton Budd (2004) proposes that the stock corporation is the pre-eminent place for connecting capital with individual initiative. This can happen under the condition that human beings are not solely self-interested and have limited material needs. If human action is based on self-interest, then human beings have no interest in firms which do not lead to benefits for them. This also means that individuals have no incentives to let others establish a ‘Right On’ corporation. In fact, self-interestedness may preclude the establishment of such corporations because human beings would rather prefer corporations that produce benefits for them. In other words, self-interested capital-owners would not provide capital to a corporation which does not yield personal benefits. The implication is that the theoretical embedding of the idea of self-interestedness at the part of all individuals, and the practical entrenchment of it in policy-making and corporate governance conflicts with the existence of the stock corporation in which innovation can take place without being subordinated to profit maximization. The Aristotelian perspective sheds a different light on the concept of freedom. In Development as Freedom Amartya Sen argues that human development is the ‘process of expanding the real freedoms that people enjoy’ (Sen, 1999, p.1). Amartya Sen clearly contrasts narrower understandings of human development – such as gross national product or personal income – with the advancement of freedom. In his view, matters such as personal income are indeed important means of development but exactly that: these matters are a part of the process, but not an end in itself. If freedom is understood in accordance with Sen (1999), then capital-owners can expand the freedom of others by investing their capital in others. The implication is that the understanding of ‘freedom’ is crucial for how a ‘free society’ is actually shaped. Friedman’s (1970) appeal to free society is based on the normative premise that individuals who enjoy freedom will maximize profits. From an Aristotelian perspective the protection of profit maximization as a freedom hampers the expansion of other freedoms. Exploratory case study results – Exploratory case-study research is conducted in order to investigate examples of firms that pursue objectives other than profit maximization. The principle of shareholder value maximization derives from the Anglo-Saxon world (Lazonick, 2011b), implying that cases should not be drawn from this context. Indeed, the Anglo-Saxon model is generally market-oriented and shareholder-centred (Aguilera & Jackson, 2003) whilst the principle of shareholder value maximization has less (legal and cultural) prominence in the Continental European world. Thus, three Continental European firms are studied, because in this context there is more space for firms and capital-owners to finance innovation with aspirational capital. Nevertheless, the Continental European model shows resemblance with the regulatory perspective, because it emphasizes the involvement of workers in corporate governance (Koslowski, 2009). The cases are therefore on the fringe of the Continental European context, rather than typical cases. The principal finding of the case studies is that firms are able to find individuals who are prepared to put their capital in service of the corporate objective. This happens under very different circumstances. L’Aubier, a biodynamic farm in Switzerland, manages to attract investors who put their capital at the disposal of sustainable development. These investors receive a below-market rate of return and cannot sell their shares back to L’Aubier. On the other hand, Mondragon, a worker-cooperative in Basque country manages to lock in profits that are actually owned by its workers. Mondragon was founded as an answer to high unemployment and poor local economic conditions. This means that Mondragon has not been operating in a particularly capital-abundant context. The available evidence further suggests that firms can create additional aspirational capital, depending on the degree to which they can generate profits from their innovations. Firms can also use capital that is generated by other, unrelated activities. The cases also suggest that firms may understand corporate performance in alternative ways beyond profitability alone. Most notably, developments in the fields of sustainability may even reduce profitability from a standard economic or stakeholder perspective, while it may increase performance from the perspective of the innovators. Corporate performance may also include providing individuals with an income by providing education and jobs, technological development itself or community projects, rather than the financial gains that derive from it per se. In the cases under review capital-owners put their proprietary capital at the disposal of the firm, reducing the possibility to instantly change the destination of their capital to alternatives where returns are higher, and reducing full control over proprietary capital. Put differently, capital-owners make use of their freedom to put their capital to the use they consider good. Since to refrain from maximizing self-interested gains happens autonomously, to use positive freedom implies by definition a reduction of self-interested gains. Clearly, the firms under review do not engage in profit maximization. Otherwise it would not be possible for L’Aubier to research biodynamic farming and to hold equally high standards against its suppliers if it does not translate into higher profits. It would also not be possible for Mondragon to create jobs at the cost of profitability, nor for Trumpf to invest in community projects. There may be many purposes for which capital can be used within firms, and the available evidence in this thesis only provides a small sample. This shows there may be various outputs of business activities that may be valued and on which firm’s performance can be judged. Conclusion and discussion – Self-interestedness has become a self-fulfilling prophecy because it is a fundamental assumption of standard economic theory. This has led to underinvestment in innovation, essentially because the pursuit of self-interest does not lead to the maximization of fulfillment of all interests. The mechanism by which the theory of self-interestedness has become valid in itself does not imply that the theory is false. It means that the validity of assumptions about human behavior depends on the choices of human beings with regard to how to behave. Thus, the validity of the fundamental assumptions of the Aristotelian perspective presented in this thesis as an alternative to conventional theoretical perspectives depends also on the choice of human beings to behave accordingly. This thesis advanced an alternative perspective that takes limited needs and self- and other-interestedness at the part of individuals as starting points. The link between finance and innovation can be established if self-interestedness and maximizing behavior do no longer guide the design and use of the stock corporation. The symbiotic relationship between scientific theory and practice implies that the general cognition of the existence of corporations where capital-owners provide capital without demanding a return can be a driving force of change. It can be concluded from the exploratory case studies that there are corporations where capital-owners provide capital without demanding a return. The cases contradict standard economic theory and the regulatory perspective, whilst collaborating the Aristotelian perspective in the sense that capital-owners do not aim for profit maximization and that capital-owners (and workers alike) do not act upon self-interest only. This thesis has shown how different scientific theories have shaped the design and use of the stock corporation and the allocation of capital. The added value of this thesis lies in how the alternative theoretical perspectives are related to financing innovation. However, the contribution of this thesis is limited to the validity of the human uncertainty principle. Furthermore, an analysis of reflexivity with regard to the ethical considerations of human beings was possible only if the assumption of self-interestedness was dropped. Finally, the validity of the empirical findings is dependent on how we reach normative conclusions. The boundaries of the Aristotelian perspective are dependent on the actual thinking and decisions of human beings. This means that the eligibility of the perspective depends on culture. Indeed, financial aspirations form a central aspect of capitalist cultures whilst these can preclude happiness derived from non-material achievements (Kasser & Ryan, 1993). Thus, the assumptions may not be valid for an Anglo-Saxon context in which human beings choose to be self-interested profit-maximizers. Yet, in a truly free society citizens are free to choose otherwise.","finance; innovation; maximization of shareholder value; shareholder theory; stakeholder theory; Aristotelian ethics; capital markets; human uncertainty; reflexivity; self-interest; human nature; responsible innovation; social welfare; uncertainty","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Economics of Innovation","","Management of Technology","",""
"uuid:7a38918a-491a-42b1-80f6-258c29c7e7ec","http://resolver.tudelft.nl/uuid:7a38918a-491a-42b1-80f6-258c29c7e7ec","The design and analysis of steering interactions between automated vehicle and human driver using hybrid control framework","Kaustubh, M.","Mazo, M. (mentor)","2014","Advanced Driver Assistance Systems (ADAS) are primarily radar and camera-based technologies that capture the vehicle’s surrounding environment and assist the driver by keeping him informed about current vehicle state, and if necessary intervene to prevent an impending danger, while the driver is in control of the vehicle at all times. These technologies pose two types of requirements, one on the Human-Machine interface which consists of graphics-based platform or interaction devices like knobs, handles and acoustics etc. for interaction between electromechanical system and the end user, and other, on the Transition of control from manual to automated driving and vice-versa. Whilst the former is a topic of ongoing research in the industry, the latter clearly demands more attention (from a control engineering perspective) than it already receives. The motivation behind this thesis lies in the unavailability of a rigorous mathematical framework, to design and assess the rich dynamic phenomena underlying the steering interactions that take place during a transfer of control authority between human driver and automated vehicle. The current approaches in the academia are based on a monocausal treatment (either from the purview of human factors or from systems engineering) and hence, are too conservative for a sound analysis of combined human-automation interaction. The approach outlined in this thesis addresses these challenges by using a switched system framework to solve the problem of ''effecting a smooth switching of control authority between human driver and automated vehicle, and investigating the underlying parameters to address the issues of driver comfort and safety''. The Human driver has been modeled as preview controller with a neuromuscular dynamics component, whereas the automated vehicle has been developed using PID control strategy for speed control and PD control strategy for steering control. This research uses a 4DOF(degree-of-freedom) ‘two track’ vehicle model for control design and after subsequent linearization, the 2DOF vehicle model for formal verification. Using the concepts of hybrid automata, both the systems were modeled to obtain a two-mode switching automaton. A scheme was then setup using the concept of average dwell time to evaluate stability and temporal logic to incorporate verification of different parameters that affect the switching. Furthermore, the Breach Matlab toolbox was used to perform the parametric verification of the three parameters under investigation, namely, human preview distance, automation preview distance, and driver gain, which were varied for different longitudinal velocities, maximum allowed lateral deviation and time of switching (or the time during the lane change when the switch takes place). In conclusion, the experimental results obtained, validate the correctness and usability of the framework for future developments.","Advanced Driver Assistance Systems; Average Dwell Time Switching; Parametric Verification","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Delft Center for Systems and Control","","Systems and Control","",""
"uuid:3bb6596f-4161-4180-a374-0aa417c99f4e","http://resolver.tudelft.nl/uuid:3bb6596f-4161-4180-a374-0aa417c99f4e","Efficient support structure design for variation of environmental parameters within an offshore windfarm","Pandit, A.M.","Zaayer, M.B. (mentor)","2014","","wind support structure; offshore; windenergy","en","master thesis","","","","","","","","2014-08-28","","Wind Energy","","Sustainable Energy Technology","",""
"uuid:88cfdd3a-3263-42fe-8c17-8e1560863bff","http://resolver.tudelft.nl/uuid:88cfdd3a-3263-42fe-8c17-8e1560863bff","Investigation of the effects of drag reducing polymers on stratified flows","Poursaeidesfahani, A.","Boersma, B. (mentor)","2014","According to the increasing distance between the processing facilities and the oil and gas production sites, especially at subsea production sites (where multiphase flows commonly occur), innovative methods are demanded to help reducing the cost of multiphase flow transportation through the pipelines. In the past decades, Drag Reducing Polymers (DRPs) have been drawing attention in industry and academia. However, in these works it was predominately focused on single phase flows while limited attention was paid to multiphase flows. In order to improve the understanding of the influences of the DRPs on horizontal stratified gas-liquid flows, a conventional air-water flow loop is used in this study. The “Conductance probes method” and flow visualization with high speed camera are used to examine the morphology of the gas-liquid interface. The conductance probe sensors and required electrical circuits are built as a part of this project. The stratified flow of gas and liquid provides the most suitable flow configuration to validate the equipment which was built to measure the time variations of the liquid film height. The effects of drag reducing polymers on stratified gas-liquid flows and particularly the effects of DRPs on the interfacial phenomena as the crucial characteristics of the stratified flows are discussed in this study. Polyacrylamide with the molecular weight of 15000 kg/mol is used in this study. To get more insight on the rheological properties of polymeric solutions, the characteristics of solutions including static and dynamic surface tensions, dynamic and complex viscosities are measured. In order to find a link between these properties and the results obtained from the flow loop tests, the effects of polymer concentration on these properties are also investigated. In this research the relevance of the gas and liquid flow rates to the drag reduction phenomenon is studied. The highest drag reduction observed in this study (about 55 percent) is obtained at the greatest liquid and gas superficial velocities. The maximum drag reduction of a stratified flow is compared with the one obtained from single phase flow of water. Additionally, in this study it is tried to focus on the behavior of the interface between the gas and the liquid by adding polymers. Roll waves’ frequency, velocity and shape as well as the influences of the drag reducing polymers on the roll wave’s properties are discussed as well. Finally a model is proposed to assess the drag reduction of stratified flows as a function of the changes in liquid holdup and the interfacial properties such as disturbances and the shape of the interface.","drag reducing polymers","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Process and Energy","","","",""
"uuid:252937fc-2365-4b72-bb95-d11a79354453","http://resolver.tudelft.nl/uuid:252937fc-2365-4b72-bb95-d11a79354453","Conceptual design of a carrier-pod aircraft configuration","Kappers, J.G.","Vink, P. (mentor); La Rocca, G. (mentor); Vankan, W.J. (mentor)","2014","Whether travelling by aircraft, train or roads or a combination thereof, the EU aims to reduce the door-to-door travel time within Europe to approximately four hours overall travel time. This goal is hard to reach, especially when flights already take three hours or more. Since aircraft realistically can’t fly faster without going supersonic or facing a lot more drag, time must be gained elsewhere. Most time is lost whenever something or someone is waiting for a process to complete, before the next phase of the journey can start: transferring, (dis)embarking, (un)loading, servicing and cleaning, refuelling, waiting (in-line), etc. The target then is to reduce, streamline or even eliminate processes from the entire trip to come to a faster journey. For both passengers and cargo, the process of (un)loading aircraft consists of a lot of consecutive processes, where the loading can only commence once the unloading is done and many process steps require middlemen like luggage loaders. Next to that, aircraft are often loaded one item or passenger at a time. The concept of pods is to be able to quickly replace or (un)load a “payload contained in its own cocoon” from an aircraft. Traditionally a nacelle-pod is mounted underwing, like a range extending fuel tank on a jet fighter; in this case the pod replaces the entire internal fuselage in one go (both passenger and cargo payloads), rather than loading and boarding the aircraft piece-wise. Although the pods would be loaded piecewise themselves, they would be loaded filled onto the aircraft. To allow a pod to be loaded rapidly, an Automated Guided Vehicle (AGV) with a lifting system could drive underneath an aircraft with an opened bottom side (and nose or rear entrance) and leave or collect a pod like it would place or collect a container at container terminals. Next to much faster (un)loading times in the order of minutes, the pod process will separate the cabin process from the platform processes. Separation allows the parallel execution of cabin and cargo processes, halving the time currently required to prepare an aircraft for flight. The logistical advantages gained from such a system are enormous and benefit all of the direct actors and most of the indirect actors immediately by saving time and thus money: For airlines, a lot of time can be gained in turning around the aircraft for the next flight, meaning more flights per day can be executed. As the pod is much smaller than conventional aircraft, gates can be significantly more compact. More compact gates reduce transfer times for passengers, as well as utilising the expensive ground of the airport more efficiently which could increase the amount of slots available at an airport and lower airport costs for airlines per flight. The higher throughput and gate capacity would increase overall airport capacity. With gates closer together and possibly not having to transfer to other vehicles at another part of the airport, passengers lose less time and can transfer more easily. Having passengers (dis)embark outside of the airport has further logistical advantages to the airport, which would see shorter queues, less pressure on the parking terminals and a more efficient boarding process, while passengers would have smaller transfer times. To accomplish this, the same pod could be loaded onto a vehicle that can bring it somewhere other than the airport. It would be best to connect the airport with other destinations through a privatised AGV track. A private track is basically the only solution for security issues as it prevents a huge loss in time due to security bottleneck issues upon entering the airport from a public space with a large group of people. Being able to set the standards for a track would also reduce the restrictions on dimensions and reduce problems with certification of AGVs (due to not sharing the track with manual driven vehicles) and allows for the track to be used by other feeder systems, such as shuttles as well with a more optimal usage (occupation density) of the track in comparison to trains and at guaranteed speeds (significantly reduced chance of congestion or delays).","pod; aircraft; configuration; carrier; passenger; transport; multimodal; AGV; lift-AGV; capsule","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Applied Ergonomics","","Master of Science Integrated Product Design","",""
"uuid:b7af54e2-ed27-4ac7-abe1-5c58606eae8a","http://resolver.tudelft.nl/uuid:b7af54e2-ed27-4ac7-abe1-5c58606eae8a","Designing the UX strategy for Future Fairphone","Xiao, Y.","Giaccardi, E. (mentor); van der Helm, A. (mentor)","2014","The goal of this graduation assignment is to designing the user experience strategy for the second generation of Fairphone, which is a social enterprise with the aim to develop a smartphone designed and produced by putting social values first. The goal of second generation product - Fairphone 2 is to develop a simple, easy-to-use device that focuses on sustainability, openness, longevity, and reparability. In the beginning of the report, related design trends analysis and industry trends analysis outcome are introduced in order to understand the context of the design assignment. Then the product positioning for Fairphone 2 is defined based on company strategy and trend analysis. The quantitative and qualitative research are conducted with the aim to understand current user experience on Fairphone 1 and customer’s expectations on Fairphone 2. An infographic is made to illustrate the profile of Fairphone 1 user, including the demographic information, purchase motivation, usage behavior, current user experience of Fairphone1 and expectations on future Fairphone. Based on the context and user research outcome, five initial UX principles are proposed for the future Fairphone. Those five principles act as the guidance for the final design statement. The final design is demonstrated in the end of the report after continues evaluations with company, university mentors and users.","design; Fairphone; UX","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Strategic Product Design","",""
"uuid:f433da05-2956-4b16-9568-7f32e76d2143","http://resolver.tudelft.nl/uuid:f433da05-2956-4b16-9568-7f32e76d2143","Cargo Driven Intermodal Transportation: A new concept to improve container hinterland transportation","Yuan, L.","Zuidwijk, R. (mentor); Behdani, B. (mentor); Kortmann, R. (mentor)","2014","","container hinterland transportation; discrete event simulation","en","master thesis","","","","","","","","2014-12-11","Civil Engineering and Geosciences","Transport & Planning","","TIL","",""
"uuid:053cc471-da60-482b-a3f9-a3800baaae1e","http://resolver.tudelft.nl/uuid:053cc471-da60-482b-a3f9-a3800baaae1e","Investigation on the possible application of Natural fibres (Abaca fibres) as reinforcement in concrete to create ductility","Sayed Moqadas, M.","Schlangen Erik, H.E.C. (mentor)","2014","Almost 3500 years ago, Egyptians used straw to reinforce mud blocks for construction purposes. Later on, concrete and metals were introduced and the interest for NFC was reduced. In 1900 asbestos fibres were introduced to produce light weight and durable elements; however in 1970 it was discovered that asbestos is unhealthy. Therefore, in 20th century the idea of using natural fibres in materials was resumed which lead to extensive variety of fibre reinforced cement-based materials. Different types of fibres have been used as reinforcement, e.g. polyvinyl alcohol and Polyethene and natural fibres. Natural fibres are renewable resources. Less production energy is required for the production and it’s producible with low investment at low cost, but it has inconstant properties compared with synthetic fibres. Different researches have shown, that by using plant fibres, i.e.; Coir, Sisal, Jute, Hibiscus and Palm in cement-based materials, the compressive strength of the composites decreases with increasing fibre length and percentage. On the other hand, the flexural strength and toughness of the composites increases. Due to addition of fibres in the concrete the amount of the plastic shrinkage and autogenous shrinkage can also be reduced. Amongst the natural fibres, Abaca fibre was chosen and different experiments were performed to investigate the material properties of Abaca fibres and their behavior in concrete which is required to develop composites that show strain-hardening behavior with multiple cracks. The experiments showed that the Abaca fibres have an elliptical shape. It has a width of 100 - 400 µm and it consists of elongated elementary fibres. The tensile strength of Abaca fibre is 604 - 1104 MPa and its MOE is 14.92 - 33.61 GPa. Abaca fibres swell with an average diameter of 11.02% in a humid environment. Furthermore, Abaca fibres were treated with NaOH, Na2SiO3, C2H4O2, NaOH+C2H4O2 and H2O to reduce its hydrophilicity. As a result the surface of the Abaca fibres seemed to be damaged, but no fibre disintegration occurred. The Abaca fibres treated with H2O showed a very high reduction of -OH groups, while most of the treatments lead to an increase of -OH groups. Due to the treatment, the Abaca fibres tend to stick to each other. The effect of different treatments on the moisture absorption of the Abaca fibres was also investigated. Abaca fibres treated with NaOH + C2H4O2 and C2H4O2 exhibited the lowest moisture absorption behavior. Finally, different mixtures were casted using randomly distributed Abaca fibres to develop ductile composites and tested under compression and bending. The content of cement was reduced and replaced with limestone powder. The compressive strength of the specimens reinforced with Abaca fibres remained the same as unreinforced ones. Under bending test, the composites reinforced with Abaca fibres (treated and untreated) showed strain-hardening behavior with multiple cracks, due to increase of paste in the mixture by applying particle size distribution method. Also, single Abaca fibre pullout tests were conducted, but the results showed very low interfacial shear strength. Moreover, combined loading (freeze & thaw and bending) were performed. Under combined loading, the specimens showed strain-softening behavior. From all of the conducted experiments, it can be concluded that Abaca fibres can be used as possible reinforcement in cement-based materials (e.g. concrete) to create ductile composites, although the flexural strength, toughness and ductility is much lower than other fibre reinforced composites.","Abaca fibre; ductility; strain-hardening; multiple-cracking","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Materials and Environment","",""
"uuid:080922ce-de7f-4ce3-a180-1f0bdb4a7d35","http://resolver.tudelft.nl/uuid:080922ce-de7f-4ce3-a180-1f0bdb4a7d35","Product Service System for Laevo","Ling, T.","Badke-Schaub, P. (mentor); Simonse, L. (mentor); Wisse, B. (mentor)","2014","Laevo is a technical-driven company which specializes in “Weight-Transferred Device” that aims to solve back problems of industrial workers and nurses. Heineken is taken as a potential client of Laevo. Previously, in Laevo’s opinion Heineken expects improvement of working efficiency and employability from the Laevo product. Based on my study, it is found that Heineken expect more from Laevo, which is sustainable profit. Besides, User (Heineken workers) also plays an important role in helping achieving this ultimate goal. So, Laevo aims to solve a complicated problem with a simple-designed product. There would be a lot of unexpected issues that deter Laevo from helping Heineken achieve the ultimate goal. This is why the Product Service System is introduced to help Laevo achieve the ultimate goal of Heineken. Product-service systems design is expected to lead Laevo to a new strategic level and provides new industrial perspectives, which not only aims to help achieve the ultimate goal of clients but also become a reliable, responsible and sustainable back-care consultancy with a strong brand identity. In my study, I started with internal & external analysis of Laevo to redefine the positioning of Laevo. Then, I figured out several important factors that may have a huge impact on Laevo by using “MEPSS” method. Later, I translate them into guidelines for brainstorming session. With new concepts popping out, I executed feasibility analysis, internal group discussion, field study, quantitative study in order to fully develop the concepts and turned them into sound strategy that could help Laevo establish a Product Service System. Finally, I analysed strategies and figured out relationships among stakeholders in this new organisational arrangements and made a rough estimation in cash flow chart. All in all, the project aims to help Laevo transform from a technological-driven company into a reliable, responsible and sustainable back-caring service provider.","Product Service System; Business Modeling; Product & Service Strategy","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product Innovation Management","","","",""
"uuid:6c01692a-f5a4-4283-ae7c-9ebe8987ce26","http://resolver.tudelft.nl/uuid:6c01692a-f5a4-4283-ae7c-9ebe8987ce26","Execution time analysis of audio algorithms","Gopalakrishna, N.","Al-ars, Z. (mentor); Hoogland, N. (mentor)","2014","Execution time analysis forms an important part of design space and hardware architectural exploration for hard real-time systems. Some approaches for execution time analysis require prerequisite knowledge of synchronous data flows or timed automata employed in model checkers. This is unsuitable for industry-level use as easy approaches without any prerequisite knowledge requirements are preferred by them. Most of the existing proposals addressing execution time analysis target 'fast' approaches rather than timing accuracy. Also, these existing proposals are validated with simple processors as majority of processors used for hard real-time embedded software are not so complex. However, for audio applications employing audio algorithms, modern processors with high performance are required, to be scalable with increasing audio algorithm complexity. Execution time analysis of audio algorithms on these modern processors is gaining importance as sampling frequencies are getting higher and deadlines getting shorter. In this thesis, we propose an industry acceptable model/simulation framework to perform execution time analysis of audio algorithms on modern mono core and multi-core processors (operating in asymmetric multiprocessing mode). Our framework combines open-source tools such as Gcov, POOSL modelling language (Parallel object-oriented specification language) and Gem5 which is a computer architecture simulator to determine WCET of an audio algorithm using dynamic means as static WCET techniques lead to huge overestimations. This solution framework was proposed after conducting experiments targeting execution time analysis at different abstraction levels and evaluating results based on accuracy, flexibility, hardware compatibility and scalability. Our proposed technique is flexible as Gem5 models several processor architectures and expressing audio algorithms at the basic block abstraction level allows parameters such as loop bounds to be changed easily. It can be easily extended to more cores using the expressive POOSL modelling language. Our technique requires no prerequisite knowledge of any concepts and also solves issues such as infuence of execution contexts of basic blocks on execution time in an implicit way without requiring additional analysis. We were able to achieve almost 99% timing accuracy for integer and floating point programs without long latency instructions using Gem5. For programs with long latency instructions, minor manipulations are presented which yielded almost 90% accuracy using Gem5.","execution time analysis; modern processors; Gem5; POOSL","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","Embedded Systems","",""
"uuid:32a0f9d8-49bc-4727-9fca-451e53a446c8","http://resolver.tudelft.nl/uuid:32a0f9d8-49bc-4727-9fca-451e53a446c8","Persian school 2014","Emami, Y.S.","Willekens, L.A.M. (mentor)","2014","To design a contemporary Persian school in which the essence of the traditional Persian Architecture is constructed, in combination with integrating new pedagogic ideas.","","en","master thesis","","","","","","","","","Architecture and The Built Environment","Architecture","","Explore Lab","",""
"uuid:99a7ef62-d686-4b54-a04b-8a309227a8f2","http://resolver.tudelft.nl/uuid:99a7ef62-d686-4b54-a04b-8a309227a8f2","Managing ambidexterity in fast growing small and medium sized tech enterprises","Bouten, R.A.","Scholten, V.E. (mentor); Van der Duijn, P.A. (mentor); Van de Voort, H.G. (mentor)","2014","","ambidexterity; exploration; exploitation; innovation","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Technology, Strategy and Entrepreneurship","","","",""
"uuid:e558e01e-443c-4cc7-9fed-9ccf0313e971","http://resolver.tudelft.nl/uuid:e558e01e-443c-4cc7-9fed-9ccf0313e971","Relations in Role-Based Data Modeling and Navigation","Harkes, D.C.","Visser, E. (mentor)","2014","Object-oriented programming languages support concise navigation of relations represented by references. However, relations are not first-class citizens and bidirectional navigation is not supported. The relational paradigm provides first-class relations, but with bidirectional navigation through verbose queries. We present a systematic analysis of approaches to modeling and navigating relations. By unifying and generalizing the features of these approaches, we developed the design of a data modeling language that features first-class relations, n-ary relations, native multiplicities, bidirectional relations and concise navigation. The language static and dynamic semantics are formally specified and the language is implemented in the Spoofax language workbench. Evaluation of this implementation shows the language is concise and has good usability but lacks expressiveness.","relations; data modeling; data navigation; programming language; multiplicities","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Computer Science","","Software Technology","",""
"uuid:ff35f932-5f7f-4e85-89ac-d19041e6c32c","http://resolver.tudelft.nl/uuid:ff35f932-5f7f-4e85-89ac-d19041e6c32c","Bike for Life","Beeks, S.J.","Ruiter, I.A. (mentor)","2014","This report describes the redesign of the “Bike for Life”. It is a “bicycle ambulance” designed to be a “stand alone” support vehicle to facilitate the Quick Response Team (QRT-team) and is an integral part of the safety management system of the St. Elisabeth Hospital in Tilburg.","bicycle ambulance; support vehicle","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Integrated Product Design","",""
"uuid:504b4d73-c4ab-4e5e-bcaf-ca6d2ff7347b","http://resolver.tudelft.nl/uuid:504b4d73-c4ab-4e5e-bcaf-ca6d2ff7347b","Tracking known security vulnerabilities in third-party components","Cadariu, M.D.","Van Deursen, A. (mentor)","2014","Known security vulnerabilities are introduced in software systems as a result of depending on third-party components. These documented software weaknesses are hiding in plain sight and represent the lowest hanging fruit for attackers. Despite the risk they introduce for software systems, it has been shown that developers consistently download vulnerable components from public repositories. We show that these downloads indeed find their way in many industrial and open-source software systems. In order to improve the status quo, we introduce the Vulnerability Alert Service, a tool-based process to track known vulnerabilities in software projects throughout the development process. Its usefulness has been empirically validated in the context of the external software product quality monitoring service offered by the Software Improvement Group, a software consultancy company based in Amsterdam, the Netherlands.","known vulnerabilities","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Software Technology","","Msc. Computer Science","",""
"uuid:cd8143c2-3536-42e0-8a34-564c92b0cfb6","http://resolver.tudelft.nl/uuid:cd8143c2-3536-42e0-8a34-564c92b0cfb6","Linking Lean tools and strategic business objectives within the service industry","Rakhan, S.","Janssen, M. (mentor); Lukszo, Z. (mentor)","2014","Concerning Lean projects, the challenge in applying Lean tools in a service environment is the lack of widely available reference implementations. Existing literature is often related to Lean tools and strategic business objectives in a manufacturing context. Because difference in producing products and services exists Lean tools are expected to be better 'translated' into a service context. Lack of knowledge on this field creates uncertainty in selecting the right Lean tools and the way Lean tools should be applied in a service context. To evaluate the effects of Lean, it is imperative to know what the impact of Lean tools is on specific strategic business objective(s). Some say that Lean primarily focuses on efficiency, whereas others argue that a broader range of strategic business objectives are supported. In this study the relation between existing Lean tools and strategic business objectives is researched. The aim of this study is to understand and improve the relationship between Lean tools and strategic business objectives within a service environment. This research should contribute to more focussed Lean programs within the service industry. The relationship between strategic business objectives and Lean tools is complex as it is influenced by factors that can be controlled and other factors which cannot be controlled. In this study the relationship between the variables is researched and not its causalities as there are many other factors influencing these causalities.","Lean tool; Service industry; Strategic business objectives","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Engineering Systemens and Services","","Engineering and Policy Analysis","",""
"uuid:9082235c-3f1c-41da-a85d-2ecf6e1c50cf","http://resolver.tudelft.nl/uuid:9082235c-3f1c-41da-a85d-2ecf6e1c50cf","Professionalizing Academic Industrial Designers","Vos, D.P.H.","Flipse, S.M. (mentor); Van der Sanden, M.C.A. (mentor); Smulders, F.E.H.M. (mentor); De Vries, M.J. (mentor); Stappers, P.J. (mentor); Schoormans, J.P.L. (mentor)","2014","I attended a double-degree master program at the Delft University of Technology (DUT). That means that I combined two master programs, namely Science Education and Communication (SEC) and Strategic Product Design (SPD), into one program. This double-degree program required me to integrate the graduation projects of both masters into one graduation project. This graduation report is about that integrated graduation project. Together with my supervisors I defined two graduation assignments that share the theme ‘professionalizing academic industrial designers’. For the SEC graduation project I looked into how the DUT can effectively support Industrial Design Engineering students and alumni in their professionalization efforts. For the SPD graduation project I developed a writing education method that is tailored to academic industrial design education and I looked into how a brand can make the learnings from this project operational for other education development projects for academic industrial design education.","professionalization; industrial designers; written communication","en","master thesis","","","","","","","","","Industrial Design Engineering - Applied Sciences","","","Science Education & Communication - Strategic Product Design","",""
"uuid:e12db1ed-8d30-460d-9d5e-752caf76ca1a","http://resolver.tudelft.nl/uuid:e12db1ed-8d30-460d-9d5e-752caf76ca1a","Developing a new municipal self-service kiosk","Van de Pol, M.E.","Buijs, J.A. (mentor); Van der Vegte, W.F. (mentor)","2014","In this master thesis the development of a new self-service kiosk for the new municipal office in Delft has been described. This self-service kiosk was designed from scratch and is the third one in its generation. The municipality of Delft wanted to adapt its second version SSK to state of the art technologies and to the new municipal office making a new future proof SSK maintaining general design requirements (safety, accessibility, availability, easy to use, etc.).","self-service; design; municipality; development","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Integrated Product Design","",""
"uuid:ad113f9e-b3d0-4284-8229-3091764dc69b","http://resolver.tudelft.nl/uuid:ad113f9e-b3d0-4284-8229-3091764dc69b","Design-time and Run-time Reconfigurable Clustered ?-VEX VLIW Softcore Processor","Reda, M.B.","Wong, J.S.S.M. (mentor)","2014","The ?-VEX processor is a parameterized reconfigurable Very Large Instruction Word (VLIW) softcore processor. It can be reconfigured in the issue-width, number and type of functional units (FUs), width of memory buses and number of registers in the multi- ported register file. The current design of the ?-VEX processor supports single cluster processor organization. The design also provides run-time dynamic reconfigurability between different processor architectures. As the issue-width of the processor increases, the number of read and write ports from the FUs to the register file increases which enlarges its area utilization. This increase in the number of read and write ports is not scalable with the interconnect wires available in the current IC technology. From literature, we know that clustering the FUs of the processor and splitting up the register file into a smaller subsets significantly reduces the area overhead and power consumption. In this thesis, we have developed all the necessary hardware and software components to enable the design-time and run-time reconfigurable ?-VEX processors to support clustered organization. Those development are the design and implementation of inter- cluster communication FUs, inter-cluster path and local register file per cluster and the adaptation of the compiler toolchain. As an inter-cluster communication model (ICC), copy operation and dedicated issue slot ICC model are implemented. The cycle count and total operations of different benchmark applications are measured and analyzed on the clustered organization of ?-VEX processors. The cycle count for most of the benchmarks is higher in clustered organization except for applications with high instruction level parallelism such as matrix and adpcm. A speedup of 3.04× is achieved by matrix benchmark. On the other hand, an increase in code size of the benchmark applications is measured for the clustered processor by a maximum of 38%. The area utilization of the 4-issue and 8-issue design-time reconfigurable ?-VEX processors are significantly reduced by up to 74% by clustering them into two clusters. In addition, a speedup of 1.55× is obtained on the clock frequency of the processor. Similarly, the run-time reconfigurable clustered ?-VEX processor occupies 61.3% less area, consumes up to 41.6% less dynamic power than the single clustered processor and has a reduced energy delay product (EDP).","reconfigurable processor; clustered organization; run-time reconfigurable processor; multi cluster VLIW","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","Embedded Systems","",""
"uuid:3f20dfb9-8021-4e89-b774-c665512ce8db","http://resolver.tudelft.nl/uuid:3f20dfb9-8021-4e89-b774-c665512ce8db","Clean grass: Development of a pretreatment machine for grass pressing","De Booij, T.","Song, Y. (mentor); Minnoye, A.L.M. (mentor); Van Bergen Henegouw, F.M. (mentor)","2014","In this project a grass refinery process line is designed for producing grass fibers and juice that are suitable for cardboard, fuel pellets and animal feed production. A washing machine is designed for an essential processing step, cleaning the grass.","biobased; biomass; grass refinery; pellets","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Master of Science Integrated Product Design","",""
"uuid:f5448cf1-3046-4755-ba1c-84b7bf08d57e","http://resolver.tudelft.nl/uuid:f5448cf1-3046-4755-ba1c-84b7bf08d57e","Artificial Visual Attention: Real-time search & track by saliency computation for a humanoid robotic head","Donker, J.C.B.","Jonker, P.P. (mentor); Lenseigne, B.A.J. (mentor)","2014","Visual attention is currently actively researched across many different fields. In the domain of computer vision and artificial intelligence, it is both studied and applied, often inspired by observing nature’s solutions. The object of this research, the Binnobot, is a robotic head in which the two camera sensors have embedded perceptual systems, capable of real-time feature tracking. As the hardware takes care of tracking features, the functionality can be extended by adding visual attention. This study investigates if this can be achieved through saliency computation. However, this must not compromise the real-time performance of the feature tracking, merely complement it. Using parallel processing, a measure of saliency for a frame is computed, after which the algorithm decides whether and what to track. Due to a multithreaded approach, the robot is still capable of searching for new or different regions of interest whilst tracking. By selecting the appropriate parameters for the salient region, the Binnobot (re-)configures the relevant features to track.","","en","master thesis","","","","","","","","2014-10-01","Mechanical, Maritime and Materials Engineering","BioMechanical Engineering","","BMD","",""
"uuid:e82b37b2-701b-4fbe-a916-e2c1afebe672","http://resolver.tudelft.nl/uuid:e82b37b2-701b-4fbe-a916-e2c1afebe672","Groundwater modelling of the khettara area of Fezna-Jorf-Hannabou, Morocco","Strikker, C.J.","Olsthoorn, T.N. (mentor); Smits, F.J.C. (mentor); Bertotti, G. (mentor); Jaait, M. (mentor)","2014","This master thesis comprehends a study on khettaras, historical subsurface drainage tunnels, in East Morocco. A numerical groundwater model was set up to simulate these systems and to get a better understanding of their behaviour. Subsequently, the model was used to simulate the effect of several scenarios: increased use of pumped wells in the same area and modern ""super"" khettaras.","Khettara; Qanat; groundwater; Morocco; modelling; MODFLOW; sustainable water resource management; pumping; geohydrology; hydrology","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Water Management","","Geohydrology","","31.477634, -4.442852"
"uuid:eea2f213-5696-4741-a981-f71d8acd2598","http://resolver.tudelft.nl/uuid:eea2f213-5696-4741-a981-f71d8acd2598","Fibre Reinforced Profiled Mortar Joints for Precast Concrete Structures","Hobson, D.A.","Nijsse, R. (mentor); Van Keulen, D.C. (mentor); Grünewald, S. (mentor); Leijten, T. (mentor)","2014","The precast concrete sector is growing and to continue this growth it is necessary that new innovations, ideas, technologies etc. are developed to improve the functionality of precast concrete structures. Many applications can be found nowadays for all different kinds of precast concrete elements. One such application for example is precast concrete shear walls. These walls may consist of elements of different shapes and sizes and are connected at a joint. The joints are important for the structural functionality and have a large influence on the costs of the structure. The joints are often the biggest drawback. To tackle this, many different technologies and methods have been and are being developed to improve the functionality of the joint, while taking the costs into account. One such method is the application of steel fibre reinforced mortar in the joint. The intention is to increase the shear strength of the joint by manipulating the material properties of the mortar through addition of straight smooth steel fibres. The steel fibres can also be accompanied by other fibres for the purpose of enhancing properties other than strength. Since not much is known of the effect of steel fibre reinforced mortar on the shear strength of the profiled mortar joints, research was needed.","precast concrete joints; fibre reinforced mortar; profiled mortar joints; stress-strain relation; stress-crack width relation; fictitious crack model; inverse analysis; multi-layer inverse modelling procedure; tensile strength mortar; compression strength mortar; steel fibre; mortar; thixotropic","en","master thesis","","","","","","","","2016-08-27","Civil Engineering and Geosciences","Structural Engineering","","Structural and Building Engineering","",""
"uuid:2054778b-7666-445a-b397-c3bd6b497ba5","http://resolver.tudelft.nl/uuid:2054778b-7666-445a-b397-c3bd6b497ba5","Haptic Shared Control in Deep Sea Mining: Enhancing Teleoperation of a Subsea Crawler","Wang, K.","Abbink, D.A. (mentor); Kuiper, R.J. (mentor)","2014","Deep sea mining is currently being investigated as a possibility to harvest valuable materials from mineral-rich areas located in water depths up to 2000 meters. One promising mining method is to employ a large crawler on the seabed, remotely controlled by an operator on the supporting vessel. Controlling such a vehicle is expected to be difficult due to unpredictable seabed conditions and limited situation awareness of the operator. In addition, the optimal human-machine interface for controlling the crawler is yet to be determined. A common approach in marine operation is to automate the task as much as possible, leaving the operator in a supervisory role. An alternative approach is haptic shared control, which has shown to be beneficial in vehicle control tasks (automotive, UAVs), yielding improved performance but mitigating traditional human-automation interaction issues such as skill degradation, reduced situation awareness and overreliance. This study aims to compare supervisory control and haptic shared control to manual control of a teleoperated subsea crawler. A simulator was constructed, including a bi-manual control interface capable of rendering haptic feedback, two virtual displays showing primary and secondary task-related information, a mathematical model simulating the dynamics of the slow vehicle, and unpredictable soil properties of the seabed. In a human factor experiment, subjects (n=12) controlled the simulated crawler to complete normal steering, repeated obstacle avoidance, and an unexpected slip event at the end; all with manual control, haptic shared control and supervisory control. During normal steering between obstacles, both haptic shared control and supervisory control improved subjects’ performance and supervisory control allowed a significant decrease in control effort. However, during slip recovery and obstacle avoidance, supervisory control appreciably reduced subjects’ situation awareness. Therefore haptic shared control is a promising approach to assist the operator in underwater teleoperation with improved task performance but not the side-effects from the automation","haptic shared control; deep sea mining; teleoperation; supervisory control","en","master thesis","","","","","","","","2014-10-31","Mechanical, Maritime and Materials Engineering","BioMechanical Engineering","","BMD","",""
"uuid:89f358da-cc93-4744-94d7-50860bb64e9a","http://resolver.tudelft.nl/uuid:89f358da-cc93-4744-94d7-50860bb64e9a","Improving the Experience of Lumbar Puncture for Children","Nannen, P.","Molenbroek, J.F.M. (mentor); Vegt, N.J.H. (mentor)","2014","This report presents a six month project executed for the pediatric hospital Sant Joan de Déu in Barcelona, to improve the experience of lumbar puncture for children between eight and eleven years old. Initially, a literature study is carried out to understand the context, the opportunities, and the requirements of this medical method. Lumbar Puncture is a diagnostic method, in which a sample of cerebrospinal fluid (CSF) is collected between two vertebrae at the lumbar region of the back. Before the physician enters the intervertebral space, the child has to obtain a sitting or lying position with a curved back in order to give room for the needle to enter. It is a very delicate process in which a nurse locks the child to keep him from moving. In practice, some children experience a difficult time while the nurse tries to force them into the right position. As the child tries to move, the chance of a failed puncture increases and the physician may need multiple attempts, giving the child a higher chance of getting side effects afterwards, and, therefore, a possible traumatic experience. To get insights into possibilities to improve this experience for the child, qualitative research is done at two hospitals (Sant Joan de Déu, Barcelona and LUMC, Leiden). This research is aimed at understanding the different perspectives of the users attending this process; the child with their parents, physician and nurse. The outcome of this research gives an overview of the problem, divided into three main elements: (1) discomfort of the position; (2) bodily reflex; and (3) anxiousness from the needle. After analysing the anxiousness through the reversal theory, three main causes were found: (a) discomfort of being caught by the nurse; (b) ineffective communication; and (c) distraction. With these findings, the problem definition was created together with the following interaction vision: “I want the child to feel like Mowgli, sitting on his protective friend Baloo the bear (Junglebook)”, and transmitting the following interaction qualities: comfort, calmness, trust, control, playfulness. During the ideation phase, ideas were generated with an iterative approach to create an integrated solution; designing a persuasive, physical, and emotional support. To create a solution for the anxiousness of the child, a protective frame is created by looking at player types from Gamification literature. Their motivations are translated into solutions to help children holding on to the journey of a lumbar puncture. A selection of ideas is used in a generative session with children and the ideas are, afterwards, developed. In a second session with children, models of concepts are tested and the outcome is evaluated with the hospitals. A final concept which aims to improve the experience of the child by a fantasy journey is chosen. It consists out of three elements: (1) a travel booklet with tips from previous children and small exercises to transmit trust in a playful way; (2) a visual overview of the fantasy journey with clear visual steps for the child; (3) a customizable protective buddy. In the last phase of the design project, the design elements are improved and developed with the outcome of the test results. The travel kit is evaluated with pediatric pedagogues from the LUMC and a prototype of the full journey was made to carry out an assessment at hospital Sant Joan de Déu in a semi-realistic setting. All in all, it shows that the experience can be improved as aimed for. Recommendations are given, focussing on further development to also persuade the highly anxious children.","medisign; children; experience; lumbar puncture; gamification; applied ergonomics; design","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Design for Interaction","",""
"uuid:63c4dc53-fdd2-47db-a9ed-d1ddc19366e8","http://resolver.tudelft.nl/uuid:63c4dc53-fdd2-47db-a9ed-d1ddc19366e8","Precipitation Estimation from Infrared Satellite Imagery","Brasjen, A.M.","Meirink, J.F. (mentor); Siebesma, A.P. (mentor)","2014","Over the years, estimation of precipitation from geostationary satellite imagery has proved to be a useful addition to weather radar and rain gauge networks. Despite the fact that precipitation estimates from geostationary satellites are inherently indirect, a single satellite is able to monitor an area much larger than any weather radar network, and also covers the oceans. Nowadays, many algorithms estimating precipitation from satellite imagery exist. A lot of these algorithms utilize visible imagery, which is only available during daytime and therefore cannot provide a continuous dataset. Other algorithms use infrared satellite imagery, but are only able to estimate precipitation for deep convective clouds. In this research a new algorithm is proposed which is able to estimate precipitation rates both during daytime and nighttime for all types of clouds, solely from infrared satellite imagery.","precipitation; infrared satellite imagery","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience and Remote Sensing","","","",""
"uuid:c3be7d12-5772-47cc-8257-fae559c99f5f","http://resolver.tudelft.nl/uuid:c3be7d12-5772-47cc-8257-fae559c99f5f","A two-step MCDM methodology for heterogeneous situations","Verloop, B.W.J.","Van Wee, B. (mentor); Rezaei, J. (mentor); Van de Kaa, G. (mentor)","2014","The focus of this research is on Multi Criteria Decision Making (MCDM) in complex multi actor environments. Within the field of MCDM, the Analytical Hierarchy Process (AHP) is known for its usage in complex situations. Therefore the focus will be on AHP as a well-known and often used MCDM. This study can function as a benchmark for other MCDM applications in complex multi actor environments. A case study, regarding the widespread acceptance of electric cars, is conducted in order to test for differences in results while applying AHP in homogeneous versus heterogeneous environments. When multiple decision makers are interviewed, for the purpose of AHP application, their judgments will differ and they should, as a group, take all criteria into consideration and seek political consensus. This works well in a decision situation where one decision has to be made and the group of decision-makers is homogeneous; in situations where the group is heterogeneous it is difficult to come to a consensus. When consensus cannot be reached the other option is to calculate the mean. When for example comparing the maximum range and the amount of reduced CO2 footprint in the case study, someone with a background in green energy production thinks the CO2 part is much more important than range. On the other hand someone from the traditional car industry thinks range is way more important than the CO2 footprint. The representing values in the AHP analysis will then be: 1/9 & 9. When applying the geometric mean, a 1 is used in the model. Which basically says these two criteria are equally important. This means these criteria will not play a key role in the calculations. However when looking at the individual preferences this pairwise comparison is a very important one. The assumption is that this misinterpretation of values is due to heterogeneity in groupings, while homogeneity is assumed. Therefore better grouping, which seeks more homogeneity, is needed when the AHP method is applied in complex multi actor situations. In order to reach this homogeneity, multiple tools have been investigated. The technique found to be most suitable for this research is market segmentation. Usually this tool is applied in marketing and its usage in combination with the AHP method is applied for the first time in this research. After the tool selection process it needed to be tested. This is done by means of the case study. In this case study a survey is conducted that consisted of two types of questions. Part one consists of market segmentation questions, which enables us to segment the participants based on generic features such as gender and age. Part two consists of AHP related questions that enables us to calculate the weights per (sub) criterion. After the survey is conducted two different analyses were performed. The first one, method A, applied the AHP method as it currently exists. The second, method B, includes the market segmentation part. First the heterogeneous group is reordered into several homogeneous groupings and for each of these groupings the AHP analysis can be conducted. When homogeneous segments provide the input, the homogeneity axiom is met again. The aim was to find differences in results for method A and B. In order to analyze all possible scenarios a special software tool has been developed which is able to calculate 500,000 scenarios within 8 hours. These calculations provided the knowledge that different market segments indicated different criteria as being their most important one. The application of method A indicated that ‘emissions’ is the most important factor regarding the widespread electric car acceptance. However, when applying method B, multiple segments are indicated in which other factors are more important. Therewith the added value of the newly suggested method has been proven. It is interesting that different segments can be identified when using different factors. Since there is freedom in which factors are being used, the analysis ensures a wide range of applicability, from policy makers towards executive boards. The findings of this research can introduce a future standard in MCDM, and especially in AHP application, in complex multi actor situations. Besides this it can be a basis for further research in this new field of application. In order to provide a robust basis a framework has been developed: “The two-step approach towards group decision making in complex multi actor environments”. Better use of the AHP method in complex multi-actor situations can be accomplished by ensuring that all groups that provide input, for the actual AHP analysis, are homogeneous. When groups are heterogeneous, as often is the case in complex multi-actor scenarios, the suggested framework should be applied in order to ensure better use.","heterogeneity; AHP; complex; multi-actor; market segmentation; software tool","en","master thesis","","","","","","","Campus only","2015-02-27","Technology, Policy and Management","TLO","","Systems Engineering, Policy Analysis and Management (SEPAM)","",""
"uuid:cf397557-f5ef-4027-b9d2-54ae9e5c6e90","http://resolver.tudelft.nl/uuid:cf397557-f5ef-4027-b9d2-54ae9e5c6e90","Biomimetic Nanopores with Yeast Nucleoporins","Dwarkasing, Arvind (TU Delft Applied Sciences)","Ananth, A.N. (mentor); Dekker, C. (mentor); Delft University of Technology (degree granting institution)","2014","Nuclear pore complexes (NPC’s) facilitate the exchange of macromolecules between the cytoplasm and nucleus and act as a selective barrier for macromolecules in eukaryotes. Ongoing research suggests that the discriminatory function of the NPC is caused by nucleoporins rich in phenylalanine-glycine amino acids residue repeats (FG-regions) which fill the nuclear pore. To determine if the FG-domains are responsible for the selectivity of a NPC, in this research we will mimic a nuclear pore complex by coating a solid state nanopore with yeast FG-nup-NSP1. After coating a wild-type nucleoporin, to a solid-state nanopore, we find that a yeast importer protein kap95 was able to translocate through the nanopore. The dwell times were on the order of tens of milliseconds. An artificial control protein, tCherry, with the same size as kap95, was not able to pass the artificial NPC. By<br/>coating a solid-state nanopore with mutated FG-nup-NSP1, where hydrophobic amino acid residues (F, I, L and V) were replaced with serine, we found that kap95 translocated with much lower translocation times, comparable to an uncoated nanopore, indicating less interaction with the mutated nucleoporins. Furthermore tCherry was also able to pass through the mimicked nuclear pore with mutated nucleoporins, making a very strong argument that FG-repeat regions in nucleoporins are responsible for the selectivity in NPC’s.","Biomimetic; NPC; FG","en","bachelor thesis","","","","","","","","","","","","Applied Physics","",""
"uuid:77a1d7a3-7475-453a-b303-c22e6c779a0b","http://resolver.tudelft.nl/uuid:77a1d7a3-7475-453a-b303-c22e6c779a0b","An Empirical Evaluation of and Toolkit for Asynchronous Programming in C# Windows Phone Apps","Hartveld, D.L.","Van Deursen, A. (mentor); Dig, D. (mentor)","2014","Microsoft has introduced the async/await keywords in C# 5.0 to support developers that need to apply asynchronous programming techniques. However, do developers really use the new keywords, and do they use them correctly? An empirical survey of 1378 open source repositories from GitHub and CodePlex shows that developers often make mistakes. By providing live feedback in the IDE, and by providing a refactoring tool to automatically refactor legacy APM-based code to modern async/await-based code, developers can be supported in using the new language feature correctly. An evaluation of the developed tools shows that they are useful: GitHub pull requests based on patches generated with the developed tools were readily accepted by several open source projects.","software engineering; asynchronous programming; empirical survey; refactoring; async/await","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Software Technology","","Software Engineering","",""
"uuid:4d2cd08e-b64f-48d9-935d-d3b09b3840ef","http://resolver.tudelft.nl/uuid:4d2cd08e-b64f-48d9-935d-d3b09b3840ef","Designing the perfect tender","Ipema, C.W.","De Weerdt, M.M. (mentor)","2014","This thesis studies parameters that are assumed to in?uence the outcomes of tender procedures. These parameters are learning, transaction costs, repetition, complex bids, uncertainty, continued work and irrationality. Government agencies have some degree of freedom when they use tender procedures. They can use this freedom to design the perfect tender, if they know how. This thesis shows that certain parameters can have a signi?cant impact on the outcome of tenders. Learning and transaction costs have a positive impact on the outcome of tenders. Uncertainty, continued work and irrationality can have a negative impact and should be minimized where possible.","game theory; tender; games; mechanism design","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Software Technology","","","",""
"uuid:c0b40224-b62b-41ba-827a-321f0899584e","http://resolver.tudelft.nl/uuid:c0b40224-b62b-41ba-827a-321f0899584e","Financing the diffusion of solar portable lighting in Cameroon: An exploratory modelling approach","Jaxa-Rozen, M.","Thissen, W.A.H. (mentor); Pruyt, E. (mentor); Kroesen, O. (mentor)","2014","Access to safe, reliable lighting is a critical need for poor rural households in developing countries. Un-electrified households often rely on kerosene lamps, which cause major impacts on health and the environment. However, advances in LED lighting and photovoltaic (PV) technology have enabled the rapid development of a market for solar portable lighting (SPL), which aims to provide a safer and more affordable alternative to fuel-based lighting as a first step towards more comprehensive energy access. Although sub-Saharan Africa has emerged as a particularly dynamic market for SPL, the west Central African country of Cameroon currently has low adoption rates despite comparatively high rural income levels. Background research indicated that this may in part be related to the high import tariffs which are applied on SPL products, and to a lack of access to finance. However, the economic impact of import policies on private and public actors had not yet been investigated in detail, and these actors have divergent expectations towards the effects of a potential tariff exemption for SPL. Similarly, the potential role of Cameroon's microfinance in promoting access to SPL through micro-energy loans had not been explored in the literature. In an attempt to address these gaps, this research project thus investigated different policy options which could increase the financial accessibility of SPL products in Cameroon, starting from a qualitative assessment of the actors, networks and institutions active in the market, as well as these actors' perceptions of market barriers. These findings were then translated into an exploratory System Dynamics simulation model to compare policy impacts under uncertainty. The qualitative research found that perceived market challenges were largely comparable to conditions in neighboring countries; however, the role of Cameroon's policy environment was particularly emphasized by interviewees as a specific barrier. This perceived impact of tariff policies on financial accessibility was supported by the simulation model, which, based on external data for the willingness to pay of consumers, indicated that a tariff exemption could significantly benefit the adoption of SPL. Furthermore, revised import policies could maintain or increase the government revenue associated with SPL imports, through the savings in kerosene subsidies which are linked to a long-term increase in the use of SPL by households. Crucially, an analysis of this policy option under uncertainty found this effect to be largely independent of the final SPL adoption rate: should the market be held back by fundamentally unpredictable factors, such as low levels of user demand or difficult product supply, the tariff exemption policy should nonetheless remain beneficial for the government in a majority of cases, when compared to the current tariffs. The robustness of the tariff exemption policy was further considered from a different perspective by testing a simpler model based on aggregate market data. The results of this model similarly showed that an exemption was typically associated with an increase in government income, except in cases under which the accessible market fraction would be significantly higher than estimated by the reference data. However, a non-negligible fraction of cases did result in a decrease in government income, which warrants further research. The qualitative research also indicated that significant efforts will be needed to successfully engage the Ministry of Finance and practically implement changes in import policies, as well as product quality standards. Under a second policy option, the model results indicated that micro-energy loans could potentially increase the financial accessibility of SPL products, although this relationship's validity is driven by the quantitative input on willingness to pay. This was supported by qualitative findings in regards to a microfinance pilot project managed in Cameroon by Schneider Electric and the MIFED NGO: given sufficient levels of local capacity, technical support and physical product availability, micro-energy lending programs may be able to usefully support the adoption of SPL products on a greater scale. However, a simpler alternative for the provision of user finance may be distribution models based on ""pay-as-you-go"" or rent-to-own principles, under which consumers could use mobile technology to effectively spread upfront costs over a series of installments. Although this technology remains at an early stage, it may have a significant impact when combined with the development of mobile payment systems in Cameroon. From the perspective of microfinance institutions, it remains difficult to generalize as to the viability of SPL-focused consumer credit: depending on local conditions, interest rates may need to be raised beyond usual practices to compensate for the relatively high transaction costs involved in small loans. An important relationship identified through this process was the link between import tariff policies, microfinance operations and, ultimately, the financial accessibility of SPL products. For instance, an exemption for import tariffs may compromise the profitability of SPL credit, due to a relative increase in transaction costs for smaller loans. Although this relationship depends to some extent on the quantitative assumptions used to test the model, this result was potentially counter-intuitive: an initial assumption of this research was that the interests of financial institutions and SPL distributors were well-aligned, with governmental actors standing to lose from import tariff exemptions. This confirms the relevance of a multi-actor approach to analyze the problem in conjunction with a simulation method.","","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Policy Analysis","","Engineering and Policy Analysis","",""
"uuid:7a720bb2-b85b-4d1d-b92a-25d67d353355","http://resolver.tudelft.nl/uuid:7a720bb2-b85b-4d1d-b92a-25d67d353355","Boosting the value of the ContextMapp","Govaarts, M.K.P.","Creusen, M.E.H. (mentor); Stappers, P.J. (mentor)","2014","As a result of the strongly dynamic, competitive and complex market, companies continuously try to achieve durable differentiated competitive advantages by finding insights in the consumers’ needs and wishes and translating these in new product opportunities. Contextmapping is one of the methods to find these needs and wishes and is applied in the early stages of the new product development process. Service Design agency Koos developed the ContextMapp(CM) to limit the labour and time required to perform this method. The CM allows companies to collect data from smartphones as the user is performing assignments and tasks, which enables the company to capture experiences when and where they happen. Subsequently, an analysis is executed on this data to unravel new insights. The CM is a relatively new commercial product in the Market Research domain and has not yet proven its full potential and added value. In this thesis, the value proposition of the CM’s usability is explored in order to identify improvements that increase the added value so that its potential can be maximized. An Internal, External and Stakeholder analysis is performed to uncover new insights about the CM, the Market Research domain, the competitive environment and how the CM is perceived and experienced. The results of the analyses reveal that the value proposition of the CM is lacking. The core problem is narrowed down to a bad user experience for the client and lack of corporate focus of the CM. Analysis reveals the CM to be a complex and time consuming interim tool, competing without a clear strategy in a highly competitive environment with a growing amount of direct competitors. The problems factors support this statement and are synthesized into a framework that consists of three pillars: experience, transparent collaboration and corporate focus. The pillars will direct towards the solution: The CM should give meaning to the value proposition by combining clients, researchers and respondents in research, analysis and design, resulting in a transparent collaboration and therefore better data quality, experience and reduction of required time. Several creative sessions are held to provide insights about and requirements for the functionalities the CM should contain. These are used as a basis for the solution; a new functional design of the CM. The CM consists of an application and dashboard tool that helps to find the consumers’ needs and wishes by gathering, analyzing and translating the data into a product opportunity. In a project there is a distinction between the role of a client, a researcher and a respondentThe distinction between the roles is based on the required expertise and tasks they have to perform. The client buys the professional services and license of the CM. The researcher(s) acts as the head of the project. The respondent is recruited as research object, but doesn’t participate in further phases of the project. The aim is to establish a transparent collaboration between the client, researcher and respondent throughout all phases of the research, in particular referring to co-research and co-creation. The collaboration results in a decrease of required time and increase of control of the data. All the users of the tool can track the progress and control this by being more involved in the different steps. In this way the analysis can be performed quicker, while maintaining the same quality of insights as in a traditional method. Also a more fitting product can be realized, because the respondents for which the product is meant for, have more and better opportunities to influence the process. The user experience during the whole project is key to reach engagement, quality of data and satisfaction. This is established by simplicity and an intuitive flow through the different screens by minimizing the amount of actions and functionalities along with the use of gamification. The overall benefits and improvements to the value proposition of the CM are validated through an evaluation study with the clients. The results of this study show that the CM is a product which covers all phases in a project, increases the performance and is desired by the clients. Subsequently, an implementation strategy is established that can be used to realize the redefined value proposition of the CM.","design; contextmapping; mobile market research","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product Innovation Management","","Master of Science Strategic Product Design","",""
"uuid:05e02a58-8e1a-4c61-8a52-a3771197302e","http://resolver.tudelft.nl/uuid:05e02a58-8e1a-4c61-8a52-a3771197302e","Computational Modeling of Turbulent Ethanol Spray Flames in a Hot Diluted Coflow","Jamali, S.H.","Roekaerts, D.J.E.M. (mentor); Ma, L. (mentor)","2014","The phenomenon of turbulent spray combustion occurs in all industrial furnaces that consume liquid fuels. It is essential that a furnace is capable to have high efficiency and performance while the pollutant emissions meet the stricter national and international regulations. One of the recently proposed solutions to improve the aforementioned conditions is flameless spray combustion. In this process the combustion of fuel is done with oxidizer diluted with recirculated exhaust gases, which results in a lower peak temperature and more distributed reaction zone, so the NOx produced in conventional burners is highly reduced. Hence, it can be a promising approach in order to increase efficiency and decrease pollutant emission. Because flameless combustion is a novel concept, it should be fully investigated and optimized before being applied to large-scale cases. Due to the considerable costs of experimental tests, numerical simulation is used more and more to predict the performance of the flameless furnaces before utilizing them in a real case. The objective of this study is to develop and validate computational models for flameless spray combustion base on a validation study using the Delft Spray-in-Hot-Coflow (DSHC) flame. The burner has been designed to mimic the flameless oxidation of light oils. The properties of DSHC ethanol flames are computed by using a combination of CFD models for turbulence, chemistry and dispersed multiphase flow. The results are validated by comparison with the available experimental data for gas-phase velocity and temperature as well as droplets statistics. Furthermore, the experimental data are available for another case in which air is used instead of air diluted with exhaust gases. This case is also simulated to validate the models. This study employs a Reynolds-Averaged Navier Stokes (RANS) simulation approach. The combination of different turbulence and combustion models is investigated while the standard Lagrangian spray model is kept the same. The steady flamelet and the Flamelet Generated Manifold (FGM) models are two combustion models that are validated. It is shown that the FGM model can predict flame structure such as double-reaction region, lift-off, etc. better than the steady flamelet model. Moreover, it was observed that the Reynolds stress and the realizable k-epsilon models show similar results while the standard k-epsilon model performs differently. The effects of other models and parameters are also investigated. The results show that radiative heat transfer, secondary atomization and coalescence of droplets as well as buoyancy have negligible effects on the DSHC ethanol flame. Still, the effects of complete two-way coupling between two phases (liquid and gas) are demonstrated to be important.","flameless combustion; spray combustion; Flamelet Generated Manifold (FGM); flamelet; Delft Spray-in-Hot-Coflow (DSHC) flame","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Process and Energy","","Sustainable Prcoess and Energy Technology","",""
"uuid:d5e12b91-5baa-4db2-a7e7-ac3010d1974c","http://resolver.tudelft.nl/uuid:d5e12b91-5baa-4db2-a7e7-ac3010d1974c","Compression of Next-Generation DNA Sequencing Data","Kathareios, G.","Al-Ars, Z. (mentor)","2014","DNA sequencing is the process of determining the ordered sequence of the four nucleotide bases in a strand of DNA, for storage in an electronic medium. Since the mid-2000s, with the advent of “Next-Generation” sequencing technologies, the production rate of sequencing data has surpassed the rate with which hard disc prices are decreasing, meaning that storage hardware is becoming increasingly expensive. Thus, efficient methods to compress this kind of data are crucial for the future of genetic research. Traditionally, this kind of data is compressed using generic compression techniques like gzip and bzip2. These techniques however do not distinguish between the three kinds of data present in the input file - identifier strings, base sequences and quality score sequences - and therefore cannot fully exploit their respective statistical dependencies, resulting in poor compression ratios. In this master thesis, a specialized algorithm for the lossless compression of sequencing data is presented, aiming at high compression. A different compression technique is used for each part of a read: delta encoding for the id strings, linear predictive coding for the quality scores and high order Markov chain modelling for the nucleotide bases. Arithmetic coding is implemented and used as an entropy encoder, based on a different Markov chain modelling scheme for each part. Prior to the selection of these techniques, methods such as hidden Markov modelling and the Burrows-Wheeler transform were investigated, aspiring to improve the compression, but were eventually proven impractical. The resulting algorithm achieves compression rates as low as 19% of the initial size, comparable to state of the art algorithms, compressing the ids, bases and quality scores to 5.5%, 19.7% and 31.3% of their original size, respectively. Finally, we investigate the viability of achieving very high compression speeds for DNA sequencing data, by using a hardware implementation of the DEFLATE standard, which promises a 2GB/s compression speed. We show through simulations that ultra fast compression is possible, with a small degradation of approximately 1.38% in the compression ratio compared to the also DEFLATE-complying gzip.","Next-Generation DNA Sequencing; compression; linear prediction; Markov Chains; arithmetic coding","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","MSc. in Embedded Systems","",""
"uuid:6eb48521-a762-44b8-a6b1-079eb855c8fb","http://resolver.tudelft.nl/uuid:6eb48521-a762-44b8-a6b1-079eb855c8fb","Ondergrondse hoogspanningsstations","Mom, E.J.","Nijsse, R. (mentor); Everts, H.J. (mentor); Van Nederveen, G.A. (mentor); Piepers, P.R. (mentor)","2014","A study on the possibilities of underground substations in the Netherlands.","underground; substation; high voltage; civil engineering","nl","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Design and Construction processes","",""
"uuid:3d582a35-05c6-4c41-8c92-345456d8e057","http://resolver.tudelft.nl/uuid:3d582a35-05c6-4c41-8c92-345456d8e057","Classification of valence using facial expressions of TV-viewers","Holkamp, Y.H.","Hauff, C. (mentor); Schavemaker, J.G.M. (mentor)","2014","Emotion has been shown to have a large impact on our interactions with people and devices. In our daily lives, however, these emotions are not taken into account when working with our computers and other machines. If our devices could pick up on social cues, for instance in relation to disinterest, the usability of various systems could be improved. Current software allows us to detect specific movements in people's faces from video recordings. Using these movements, facial expressions can be linked to specific emotions, allowing for the incorporation of this information in various systems. One application would be to allow a TV to monitor its viewer, suggesting alternative videos to watch when negative emotions are shown. An often used system to describe these specific facial muscle movements is the Facial Action Coding System (FACS). Despite the widespread use of this method, little research has been conducted on the use of FACS measurements to classify viewer emotion of entire videos. In this thesis we evaluated whether it is possible to use FACS measurements to perform classification on emotional labels in real-world environments. To assess the possibility of this application, we conducted a wide range of experiments. We selected an existing method that uses a public dataset of naturally occurring emotions and reproduced this method. Additionally, we developed our own, alternative method. In a novel comparison we evaluated the performance of both methods on three different datasets, selected to cover a range of demographics and experimental settings (highly controlled to near-living-room conditions). Furthermore we evaluated the inclusion of the TV viewer's head orientation. This proved to be beneficial for two datasets. One of the datasets used in our work provided access to heart rate data of the subjects. Based on this data, we included the subject's heart rate and other derived features. We found that this improved performance when training using the history of a specific person. Finally we performed a novel experiment in which we asked a crowd of laymen to annotate videos from each of the three datasets. This multi-dataset evaluation provided us with a reference of how well humans were able to detect the emotion experienced by the subjects using their facial expressions, allowing for a direct comparison with automatic classification methods. Overall we found that (1) using different data processing and aggregation, classification performance can improve and (2) that human annotation of emotional responses offers a way to compare classification difficulty between datasets and performance between classification methods.","machine learning; svm; affective computing; facial expression; FACS; emotion; valence","en","master thesis","","","","","","","","2014-08-26","Electrical Engineering, Mathematics and Computer Science","Software Technology","","Web Information Systems","",""
"uuid:32c30770-b713-4cff-8f3b-d38c4efd1a87","http://resolver.tudelft.nl/uuid:32c30770-b713-4cff-8f3b-d38c4efd1a87","Deconvolution Filters for Dynamic Rocket Thrust Measurements","Ahlfeld, R.B.H.","Schrijer, F.J. (mentor)","2014","Every spacecraft carries small rocket engines called thrusters for the purpose of orbit and position corrections in space. A precise operation of the thrusters saves fuel and a lower fuel consumption can extend the service life of the spacecraft. Precise thrust levels can be better obtained by pulsed firing than by continuous firing of the thrusters. To guarantee a precise operation, thrusters are tested extensively in a vacuum chamber beforehand on earth to measure their thrust. Measurement errors always impede the accurate determination of the rocket thrust. The measurement of pulsed rocket thrust is especially difficult, if using strain gage type thrust stands typical for the space industry. Their low first natural frequency results in a dominant transient response of the thrust stand structure, which interferes with the thrust signal. In this thesis, an augmented state-space Kalman Filter is proposed as a low-cost and easy-to-implement solution to deconvolute the thrust signal from the transient thrust stand response. The typical weakness of the Kalman Filter - the complicated determination of its process and measurement noise covariance matrices - is overcome by presenting several methods of choosing the matrices for pulsed thrust measurements. The measurement state covariance matrix of the Deconvolution Kalman Filter is used to obtain an estimate of the uncertainty attached to the deconvoluted thrust signal. Using several test cases, the Deconvolution Kalman Filter’s superiority to evaluate pulsed thrust measurements is proven by comparing it with Infinite Impulse Response filters commonly used in the industry. Finally, a sequential Monte Carlo method is applied to the dynamic thrust measurement problem for the first time to show that while precise thrust levels may be better obtained by pulsed firing, the attached uncertainty can become up to three times higher.","Digital Deconvolution Filter; Thrust Compensation; Dynamic Rocket Thrust Measurement; Kalman Filter","en","master thesis","","","","","","","","","Aerospace Engineering","Aerodynamics and Wind Energy","","Aerodynamics","",""
"uuid:1bd42128-bfd7-4f0d-bc1d-d993ee624a65","http://resolver.tudelft.nl/uuid:1bd42128-bfd7-4f0d-bc1d-d993ee624a65","Design of a new patient-specific prosthesis for resurfacing of the distal radius","Eekhout, M.","Goossens, R.H.M. (mentor); Wolf, Y. (mentor)","2014","This graduation project describes the results of an exploratory research and design study, focused on developing a patient-specific prosthesis for resurfacing of the distal radius, for patients suffering from wrist osteoarthritis. Pain and limitations in wrist movements are common problems for patients suffering from osteoarthritis. The current treatment options for wrist osteoarthritis are not optimal for the patients. A major problem of current available products is that the lifetime of a wrist prosthesis is only about 5-7 years, which means that they have to be replaced surgically after this short period. These prostheses often get loose, which makes it necessary to apply a wrist fusion, which decreases the range of motion of the wrist. The goal of this graduation project is to develop a patient-specific prosthesis for resurfacing of the distal radius and to guarantee pain relief and full motion of the wrist.","osteoarthritis; patient-specific; prosthesis","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","IPD","","Medisign","",""
"uuid:c2a06ef1-f000-427f-b8f8-d7cba2c4d9a4","http://resolver.tudelft.nl/uuid:c2a06ef1-f000-427f-b8f8-d7cba2c4d9a4","Studying Fine-Grained Co-Evolution Patterns of Production and Test Code","Marsavina, C.","Zaidman, A. (mentor); Romano, D. (mentor)","2014","In this thesis we perform a study that, following a mixed methods approach, investigates fine-grained co-evolution patterns of production and test code. First, we mine fine-grained changes from the evolution of 5 open-source systems. Then, we use an association rule mining algorithm to generate the co-evolution patterns. Finally, we interpret the obtained patterns by performing a qualitative analysis. The results show 6 co-evolution patterns and provide insights into their appearance along the history of the analyzed software systems.","fine-grained; co-evolution; co-evolution patterns; production and test code","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Software Engineering","","Software Technology","",""
"uuid:f881badb-4d3c-4a2a-9616-2ec5cd063e9f","http://resolver.tudelft.nl/uuid:f881badb-4d3c-4a2a-9616-2ec5cd063e9f","Identification of future growth of low-pressure gas markets within the global gas sector","Veenbergen, J.J.","Correljé, A.F. (mentor); Stikkelman, R.M. (mentor); De Laat, H. (mentor); Künneke, R. (mentor)","2014","An analysis of socio-economical and socio-technical factors that determine low-pressure gas market growth.","","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Economics of Infrastructure","","System Design Policy Analysis and Management","",""
"uuid:9fc110f0-7811-4576-9c01-a7e1498660cd","http://resolver.tudelft.nl/uuid:9fc110f0-7811-4576-9c01-a7e1498660cd","Develop a Business Model Framework for service provisioning in a B2B context","Mahalingam, S.","Bakker, H.L.M. (mentor); Ortt, J.R. (mentor); Pesch, U. (mentor)","2014","Product service combinatory businesses have evolved into an important economic force, especially over the past decade (Van Halen, Vezzoli, & Wimmer, 2005). Exploring business model frameworks and hence devising a Business Model (BM) framework for product-service combinations in business to business (B2B) context was the problem at hand. BM frameworks provide a holistic perspective of the business which helps to understand the internal functions and the dynamics of an organization. However for B2B markets and specifically for product-service combinations, there are no BM frameworks available. In an attempt to address this gap in the academic literature, this thesis project aims to investigate into BM frameworks and on the basis of the literature reviewed, devises a BM framework for a firm into service provisioning in the Non Destructive Testing (NDT) industry. In order to conduct research on this subject, a case study was carried out at Applus RTD based in Rotterdam, the Netherlands. The company Applus RTD develops its technology and equipment for the non-destructive testing of industrial systems. However, inside the firm it was realized that the value of innovations is insufficiently captured both in terms of market penetration and margins made on new products. For this, the existing business models were looked into for the portfolio of product services that Applus provides. The outcome of the research is a BM Framework, which could be put to use for its upcoming product-service combinations and comparisons can be drawn with past product service combinations. The thesis project has been divided into four phases, wherein the first phase discusses the structure and design of the thesis and literature on the concept of business models. Phase II discusses about the cases at hand, the case study design and the analysis techniques. Phase III discusses the analysis of the cases with respect to the interviews conducted followed by the devised BM framework. And finally Phase IV discusses the conclusions, recommendations for future research and reflections about the whole journey. The research has been conducted using a case study approach with multiple cases from within Applus RTD to obtain information about the present situation at the firm concerning the different elements of a business model framework. The case study approach is used to deal with different issues that Applus RTD is confronted with: one case is dedicated towards service provisioning on a projects basis (radiography inspection techniques), the second case is specialized or tailor made solutions tackle the problem of corrosion under insulation, while the third case is concerned with the regional operations and how are they carried out. The deliverables of this thesis is the proposed business model framework which can be incorporated with the future product-service launches. The data collection method undertaken for this research has been in the form of two discussion meetings and ten semi-structured interviews with the employees of the company. In addition to the interviews conducted, the archival company internal documents have also been taken into consideration. The interviews conducted by Somendra Narayan (Narayan) for his thesis have also been included as part of the data collection effort since I was present during the interviews conducted and used some insights from those interviews. The analysis of these interviews has been performed using narrative analysis. Firstly the interviews were transcribed, following which one-page summaries were formed of the interview transcripts wherein the responses were broken down into small phrases for the questions asked. The one-page summaries of the transcripts have been added to the appendix. These summaries and the documents reviewed are used simultaneously in developing the narrative analysis section of this thesis. Alongside the description of the proposed business model framework, a few other recommendations have been proposed both from the academic research point of view and also from the firms’ business point of view. The initiatives for the firm include a dedicated effort towards a clearer definition of the value offering, the channel partner program within the Applus umbrella to foster better partnerships and generate added value, a look into the social and technical stakeholders and come up with a socio-technical map which would indicate the influence that this map would have on the final offering.","Business Model Framework; Business Model; B2B","en","master thesis","","","","","","","Campus only","2014-08-26","Technology, Policy and Management","Economics of Technology and Innovation","","Management of Technology 2012-14","",""
"uuid:b8de9be4-bc7e-4ae4-825b-def28367fadd","http://resolver.tudelft.nl/uuid:b8de9be4-bc7e-4ae4-825b-def28367fadd","Success factors for technology development of bio refinery & bio energy technologies at ECN","Pierik, K.S.","Scholten, V.E. (mentor); Stikkelman, R.M. (mentor); Van Beers, C.P. (mentor)","2014","There is an abundance of research on success factors for R&D projects. Most authors have attempted to create a universal list of critical success factors, but different authors have found that the magnitude of significance and the direction of influence vary. Most studies have made no distinction between projects, and often neglected the context in which a project is implemented and differences in relative importance of success factors between stages of a project life cycle. This thesis undertook a review of existing literature on success factors for R&D projects and proposed a different approach to find success factors under case specific conditions. This research focused on technology development projects of bio refinery and bio energy technologies at the Energy research Center of the Netherlands and proposed a list of key success factors per stage in the project life cycle. The method used to derive this list is based on the Analytic Hierarchy Process method. A case study showed a large overlap between what was considered to be important for project success in that specific case and the list of key success factors derived from the AHP analysis. However, this case study also showed that even the smallest case specific conditions have their influence on what is considered to be important for success.The method proposed in this thesis can be applied to other research institutes as well, since it makes use of the experience of local experts who work on development projects on a regular basis. Further research is proposed for the categorization element of the proposed method, for the project life cycle, and for further evaluation of the validity of this method.","technology development projects; success factors; research institutes; R&D projects","en","master thesis","","","","","","","Campus only","2016-08-26","Technology, Policy and Management","Economics of Technology and Innovation","","Systems Engineering Policy Analysis and Management","",""
"uuid:3a7976c1-677c-46fa-a365-31593fe271e9","http://resolver.tudelft.nl/uuid:3a7976c1-677c-46fa-a365-31593fe271e9","Designing a transport system for human waste in Indian slums","Schakelaar, T.","Diehl, J.C. (mentor); Wever, R. (mentor)","2014","The availability of adequate sanitation is something that is taken for granted in most parts of the Western world. It is hard to imagine living in a situation without a proper toilet and sewage. Still, a third of Earth’s population does not have this luxury. The consequences are contaminated water and food, leading to diseases that ultimately cause many deaths. India is one of the places that is suffering. The urban slums have no sewage, and cultural issues make it hard to find solutions. This project aims to aid in offering better sanitation. As part of a team effort to place community sanitation centers in the Indian slums, the problem of moving the waste from the toilet facility to a treatment plant is tackled. The bad road conditions in the slum, the high volume of waste, the large risk of contamination; all these issues play a role in finding a suitable solution that fits in the context. The end result is a transport system of multiple loops taking care of the environmental conditions. The main outcome is the proposed design of a cart, able to transport large volumes of waste through the narrow bumpy alleys of the slum. Its composition allows for a relatively quick implementation and adaptation by the slum community. While the transport of the waste is only a part of the equation, the proposed solution could make beneficial changes. When combined with the right sanitation centers, it has the potential to improve sanitation in places where the conditions are not helpful.","BoP; sanitation","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Master of Science Integrated Product Design","",""
"uuid:47b99955-f965-48dd-9b01-3ba4d9407ab1","http://resolver.tudelft.nl/uuid:47b99955-f965-48dd-9b01-3ba4d9407ab1","Een statistische analyse van Wicksells lichaampjes probleem.","Boes, R.E.","Jongbloed, G. (mentor)","2014","In deze bachelorscriptie wordt het lichaampjes probleem van de Zweedse wiskundige Sven Dag Wicksell geanalyseerd. In verschillende organen in het menselijk lichaam bevinden zich bolvormige lichaampjes, Wicksell bestudeerde de bolletjes in je milt. Dit deed hij aan de hand van data verkregen door post mortem doorsnijdingen van verschillende milten. Op deze doorsnedes namen anatomen de cirkelvormige profielen van de bolletjes waar en noteerden hiervan de diameters. Het doel van Wicksell was het vinden van een schatting voor de verdelingsfunctie van de diameters van de bollen, aan de hand van de diameters van de geobserveerde cirkelprofielen. In deze scriptie wordt beschreven hoe Wicksell zijn schatter algebraïsch afleidde en hoe hij een kant en klare methode ontwikkelde die ook door niet-wiskundigen toegepast kon worden. Vervolgens wordt deze methode toegepast op de beschikbare data om zo tot de door Wicksell gevonden verdelingsfunctie te komen. Ook worden er moderne schatters afgeleid en toegepast en wordt er een zogenoemde histogramschatter geconstrueerd om ook in moderne notatie een verdelingsfunctie van de bollen aan de hand van de echte data te vinden. Vervolgens worden de resultaten van beide schattingsmethoden vergeleken en kan worden geconcludeerd dat Wicksell in zijn tijd een heel aardige schatting had gemaakt. Ten slotte wordt nog de situatie bekeken waarin de lichaampjes niet netjes bolvormig, maar ellipsoïden zijn. Hierbij wordt eerst afgeleid welke relaties van de bollen ook voor ellipsoïde lichamen geldig zijn en vervolgens wordt algebraïsch aangetoond dat de doorsnede van een ellipsoïde een ellips is","","nl","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","Statistics","",""
"uuid:43bdf136-c5fa-4cd2-bc5c-9a2fea42b9ef","http://resolver.tudelft.nl/uuid:43bdf136-c5fa-4cd2-bc5c-9a2fea42b9ef","Heartbead: Assuring do-not-resuscitate statements for frail elderly","Westgeest, V.J.E.","Sonneveld, M.H. (mentor); Wauben, L.S.G.L. (mentor)","2014","Introduction Resuscitation after a cardiac arrest is not always desired. The chance of survival with a good quality of life is very low for elderly with the age of 70+ outside the hospital. Every person has the right to decide whether to receive treatments, thus there is also a choice to decide to be resuscitated or not in case of a resuscitation situation. Besides a patient’s wish or choice to be not resuscitated, a physician can decide that it is medical futile to resuscitate a patient. The decision is called a Do-Not-Resuscitate decision, and is written down in a DNR statement. Next to written DNR statements, a DNR medal is legally accepted, both giving the possibility to communicate this DNR decision to bystanders or healthcare professionals in case of a resuscitation situation where the patient is unconscious. Despite these communication tools, people who decided and recorded for DNR, can be unjustified resuscitated. Bringing someone to life with possible bad quality of life, is a very emotional burden for family, the patient and healthcare professionals, and brings high costs for the hospital. The assignment For this reason, in this project a product is designed to assure the DNR statement for frail elderly. The focus is on resuscitation situations outside the hospital, and the stakeholders that are involved in the process of recording a DNR statement. The transfer of this information between healthcare professionals (and institutions) and between the patient and healthcare professionals in a resuscitation situation. The requirements A product is designed that assures DNR statements and that contains personal information including information about a life-or-death decision. This makes it highly important that all user groups trust the product, so they are able to trust and willing to use the product. A product that assures DNR statements must provide this information fast. In a resuscitation situation speed is highly important, because every second counts for the patient, to give him a chance to survive. In a resuscitation the first priority is to treat the patient, with no time to search for a DNR statement. Stakeholders To get insight in the interests of all stakeholders and the requirements for the designed product, next to literature research, several interviews and participatory research was performed. The four most important stakeholders for assuring the DNR statement, are frail elderly, physicians, ambulanace personnel and bystanders of a resuscitation situation. The ambulance personnel are the first healthcare professionals to arrive during a resuscitation situation outside the hospital, but they have no insight in a patient’s medical information. DNR statements are recorded and talks take place between frail elderly and physicians. Bystanders are the first person who are confronted with a patient having a cardiac arrest. The Heartbead system The Heartbead is a product that includes a RFID tag on which the DNR statement is recorded. The Heartbead is attached to the emergency response necklace of frail elderly, giving them a product that is not bothering their daily life. The Heartbead system is the total system including the Heartbead, which as a system is able to assure DNR statements of frail elderly (see figure 1). The system contains besides the Heartbead, the ambulance’s monitor, the physician’s minitor and reader, and the checkpoint. Physicians are able to read the information from the Heartbead with a RFID reader, and with the physician’s software new DNR information can be recorded at the Heartbead in a familiar way. The addition of a checkpoint at the physician’s office gives frail elderly the possibility to check the information that is recorded at the Heartbead. Ambulance personnel use a monitor during the resuscitation process to monitor the heart rhytm of a victim and if needed to apply electrical shocks to the victim’s body. This monitor with an integrated reader gives ambulance personnel the chance to read the DNR statement from the Heartbead. When the monitor is placed close to the victim, and the Heartbead is within the read range of the reader, the message is shown at the display of the monitor that a Heartbead is found and gives the legally required information about the victim. Evaluation The Heartbead system was evaluated with the main user groups; frail elderly, ambulance personnel and physicians. All user groups experienced the system as useful and were enthusiastic. The physicians liked the fact that the software to update the Heartbead was integrated in their current software, and the ambulance personnel did like the integrated reader in the monitor. Both design decisions did fit the healthcare professional’s workflow and contributed to trust the system. The eldelry did not clearly understand how the system worked, but their evaluation of the Heartbead itself was positive. Recommendations Further research is recommended to be done about the technology, and about the willingness of all technology and healthcare stakeholders to change the existing system. Also a reader integrated in an AED is recommended to make it possible for bystanders to read the Heartbead.","DNR; do-not-resuscitate; resuscitation; elderly; DNR statement","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Integrated Product Design","",""
"uuid:f14f1ed1-4a09-4643-8cac-69d4ea976ddb","http://resolver.tudelft.nl/uuid:f14f1ed1-4a09-4643-8cac-69d4ea976ddb","Statically Balanced Compliant Mechanisms by Tuned Post-Buckling Behaviour","Uitslag, G.","Van Keulen, A. (mentor)","2014","Compliant mechanisms are single piece mechanisms which gain their motion by deformation. They provide advantageous properties for precision application such as the absence of friction and backlash and lack of hysteresis. A major disadvantage of compliant mechanisms is that they store strain energy. Therefore an actuation effort is required. By statically balancing the actuation effort can be eliminated. This thesis explains that the equilibrium path of the post-buckling behaviour of a compliant mechanism can be utilized for designing statically balanced mechanism. There is discussed how to apply a buckling load to a mechanism, which requirements are found for compliant elements that must exert the buckling load and which consequences imperfections have for the designer.","Statically Balanced Compliant Mechanisms; Post-Buckling Behaviour","en","master thesis","","","","","","","","2014-11-12","Mechanical, Maritime and Materials Engineering","Precision and Microsystems Engineering","","","",""
"uuid:ade2482a-15fc-42ba-bb1e-a5b6d9dfa842","http://resolver.tudelft.nl/uuid:ade2482a-15fc-42ba-bb1e-a5b6d9dfa842","Supporting users with credibility assessments of health Tweets","Post, F.","Gao, Q. (mentor)","2014","Twitter is one of the most popular social media platforms nowadays with more than 500 million tweets being send on a daily basis. A great variety of topics is discussed on Twitter and health has become a widely mentioned topic on Twitter. Users share updates regarding their own personal health situation and they use Twitter to look up health information. Inexperienced users have difficulty assessing the credibility of information contained in tweets. Additional visual and textual cues can be added to the tweets that enhance a users ability to determine the credibility. We define different types of feature sets to represent each tweet, which are then extracted and these features are used for automatic methods that can determine the credibility of health tweets. We narrow our domain to tweets about cancer and for each tweet we assess whether it’s credible, neutral or non-credible. We also investigate the different types of cancer tweets and how the credibility differs between the categories of tweets. We evaluate our research by using a labeled ground truth obtained via the crowd-sourcing platform CrowdFlower. Our results show that automatically supporting users with credibility assessments of health tweets is feasible and can be employed in practice but still leaves room for improvement.","twitter; health; classifier; credibility; crowdsourcing","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Web Information Systems","","","",""
"uuid:4cae9d4c-02f1-497c-b676-e3c00067baf9","http://resolver.tudelft.nl/uuid:4cae9d4c-02f1-497c-b676-e3c00067baf9","Improving jack-up capabilities","Dimitriou, A.","Metrikine, A. (mentor)","2014","So far jack-ups have successfully operated in depths of 80 to 100 m and some are capable of operating in water depths of up to 150 m. In order to circumvent the depth limitation, it was suggested by Heerema Marine Contractors (HMC) that a base could be designed with the ability to support a jack-up rig, thereby increasing its operational depth capability. Such a support structure for jack-ups (named SSfJ) that can possibly be mobilized and demobilized by an HMC vessel would allow HMC to offer its services to another part of the Oil and Gas industry, the Drilling and Workover sector. A first investigation into the feasibility of this idea is carried out in this thesis. The focus of the thesis is placed on determining whether a 3-legged North Sea drilling jack-up can potentially survive on a SSfJ and on the calculation of the structural characteristics of the SSfJ that are required for enabling a jack-up to do so. The first step in this research was to verify if there is a commercial driver for the SSfJ. Therefore a market research took place which focused on the North Sea offshore drilling industry and showed that there is a need for high spec and deep water jack-ups and a great need for reduction in drilling costs. The driver was therefore clear, namely that there is a need to design a SSfJ that will enable jack-ups to operate in deeper water without much increase in costs. Then, based on market information it was decided to consider a SSfJ that would add 30m of water depth capability to the GustoMSC CJ 70 jack-up type. The main (technical) part of the thesis focused on identifying how the jack-up integrity will be influenced when it is placed on the SSfJ and what structural characteristics the SSfJ should have in order to enable a jack-up to survive on it through the harshest North Sea environmental conditions. The influence of the use of the SSfJ was assessed via reasonable assumptions that were then verified with analysis in the software SACS. The required structural characteristics of the SSfJ were identified as the SSfJ stiffness and rotational fixity at the SSfJ – jack-up interface. Recommended values for these characteristics were identified via an iterative procedure that includes a simplified dynamic analysis method that uses a Dynamic Amplification Factor. The results were then verified with a more accurate method that employs the time domain simulations in SACS. The outcome of the research is that the jack-up integrity is not influenced negatively by the use of SSfJ and that if the SSfJ has the recommended structural characteristics then the jack-up can survive the harshest environmental conditions in the North Sea.","jack-up; North Sea","en","master thesis","","","","","","","","2014-09-01","Mechanical, Maritime and Materials Engineering","Offshore and Dredging","","Bottom Founded Structures","",""
"uuid:b1b070cf-7be3-4cb9-994f-c77c1d372a2f","http://resolver.tudelft.nl/uuid:b1b070cf-7be3-4cb9-994f-c77c1d372a2f","How to Win the Game? Strategic, Simultaneous, Many-to-Many, Non-Cooperative Negotiation","Hoogslag, J.F.","De Bruijn, J.A. (mentor); Warnier, M.E. (mentor); Nikolic, I. (mentor)","2014","Negotiations are an everyday phenomena, and yet the process is so complex, ill-structured and even chaotic that analysis becomes challenging. Consequently, we currently lack systematic understanding of the dynamics that govern negotiations concerning multiple issues with multiple participants who behave strategically. The objective of this thesis is to enhance this understanding by investigating the effects of different negotiation setups and possible agent tactics (strategic behaviour).","negotiation; strategic behaviour; tactic; agent; simulation","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Technology, Policy and Management","","","",""
"uuid:c5c613f8-3c6e-48f6-89ef-173b95cd2707","http://resolver.tudelft.nl/uuid:c5c613f8-3c6e-48f6-89ef-173b95cd2707","Transit Oriented Development: Identifying market constraints for development of Public Transport Nodes in the Netherlands","De Jong, L.C.","Van Wee, B. (mentor); Annema, J.A. (mentor); Rooij, R. (mentor); Rutten, N. (mentor)","2014","","","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Construction Management and Engineering","",""
"uuid:30fe0b07-f082-4700-bbb8-46e15ddee7bb","http://resolver.tudelft.nl/uuid:30fe0b07-f082-4700-bbb8-46e15ddee7bb","Een duurzaam stedelijk metabolisme","Wobbes, T.H.","Van Timmeren, A. (mentor); Wandl, A. (mentor)","2014","Centraal in dit onderzoek staat de herontwikkeling van het militaire terrein Sijsele voor reductie, hergebruik en duurzame opwekking van emergy in de regio. De grootste opgave voor de ruimtelijke planning is deze eeuw door de verschillende stedelijke schaalniveaus heen, van gebouw tot regio, de transitie naar hernieuwbare energiebronnen. De gewenste integratie van het begrip energie in het ruimtelijk ontwerp is echter lastig daar waarbij de relaties tussen de functionele ruimtelijke organisatie en fysiologische processen complex en obscuur zijn. De stedebouwer bevindt zich hierin op transdisciplinair werkvlak, waarbij ‘traditioneel’ vormgeven van de morfologie zich steeds meer richt op de functionele dynamische organisatie, dat vergezeld gaat met onderzoek naar het stedelijk metabolisme: de totale som van technische en sociaaleconomische processen die stromen van energie en materiaal in de stad genereren, welke resulteren in groei, productie van emergy en (afbraak van) afvalstoffen. Bij een duurzaam stedelijk metabolisme zullen de beschikbare (hernieuwbare) energiebronnen het stedelijk landschap transformeren, waarbij de functies en hun netwerken beoordeeld worden op hun identiteit, diversiteit en flexibiliteit. Meervoudige systemen dienen opgezet te worden die de systeemonderdelen met elkaar verbindt. Naast inzichten in metabolisme van de stad vanuit de Industrial Ecology, zullen de nieuwe stappenstrategie (REAP) en energy Potential Mapping (EPM) de grondbeginselen zijn voor het vormgeven van de postfossiele stad, waarbij de netwerkstad lagenbenadering van Dupuy (2008) en het Emergy concept van Odum (1987) de schijnbaar tegengestelde dimensies van functionele ruimtelijke organisatie en het metabolisme doen vervlechten. Het ontwerp voor het militaire terrein laat zien hoe synergiën in de functionele ruimtelijke organisatie meerwaarde voor het bestaande creëren, door reductie, hergebruik en duurzame opwekking van emergy in de regio","stedelijk metabolisme; netwerkstad; emergy; REAP; Vlaanderen; herontwikkeling; militair terrein","nl","master thesis","","","","","","","","2014-08-30","Architecture and The Built Environment","Urbanism","","Urban Regeneration","","51.202381, 3.316568"
"uuid:79a6fc75-2851-4732-973b-44e09335e203","http://resolver.tudelft.nl/uuid:79a6fc75-2851-4732-973b-44e09335e203","Active Flow Control Using Plasma Actuators Application on Wind Turbines","Dialoupis, Athanasios","van Bussel, G.J.W. (mentor); Kotsonis, M. (mentor); Pereira, R.B.D.S. (mentor)","2014","","Windenergy","en","master thesis","","","","","","","","","Aerospace Engineering","","","Sustainable Energy Technology","",""
"uuid:5b5c8888-9670-464c-945f-8f586bd77235","http://resolver.tudelft.nl/uuid:5b5c8888-9670-464c-945f-8f586bd77235","On data markets as a means to privacy protection: An ethical evaluation of the treatment of personal data as a commodity","Vom Lehn, H.","Van den Hoven, J. (mentor); Koepsell, D. (mentor); Cunningham, S. (mentor)","2014","A number of technological developments such as cloud computing and big data analysis have affected the way in which personal data are processed. These developments go coupled with the currently prevalent business model of free online services that are financed through advertisements and an analysis of user data. Based on these developments, it seems that the new requirements have exposed deficits in the current approach to data protection in the European Union. In the debate on this topic, one of the solutions that are discussed is to create market structures in which users can sell personal data to businesses, thereby gaining control over the ways in which their data is used. Such an approach would constitute an alternative way to the protection of privacy, which is different from the current form of data protection. In order to better assess the validity of claims about the effectiveness of such an alternative approach, it therefore is of importance to know the possible effects that data markets would have on the privacy of online service users. This study investigates this question by means of an ethical evaluation. Since the definition of privacy as such is highly contested, it is not straightforward to determine what an impact on privacy would constitute. To this end, a literature review on the different meanings of privacy is conducted first. The conclusion in this regard is that privacy is a cluster of concepts which does not allow for a single definition. However, for an ethical evaluation it is the moral reasons for the protection of privacy that should be in the focus, and the precise definition of privacy is of secondary relevance. Based on this result, an evaluation framework is constructed for use in this study. Another aspect that requires clarification upfront for an ethical evaluation is the question of what specifically constitutes a data market. An investigation of the relevant literature in this regard shows that first instances of data markets are about to appear in practice, but that most proposals only exist in theoretical form. Only secondary markets for personal data --- which are not accessible by users themselves --- exist in practice. First approaches of real data markets seem to emerge, but are in a very early phase that is too premature for the sake of a detailed evaluation. Yet, there are a number of interesting approaches in the literature which propose the concept of a data market in abstract form. This study makes a selection of these proposals and uses them for an ethical evaluation. The outcome of the ethical evaluation shows that there are a number of different effects that could occur if these data market approaches would be implemented. Although some of these effects are indeed positive for the protection of privacy, there are various effects that would be detrimental to privacy. Most importantly, data markets could lead to a loss of individual autonomy and have adverse effects on the societal function of privacy. Striking is also the symbolic change to privacy as a human right that a commodification of personal data might entail. Moreover, it has to be considered that data markets as a regulatory infrastructure would require the collection of additional data for their own functioning. This in turn leads to new questions of privacy protection that would have to be solved. Overall, it can be said that there is not a single and clear impact on privacy, but a wide range of possible effects that are connected in an intricate manner. To which extent these effects would occur is contingent upon the behaviour of users in such markets and the design parameters of possible data market approaches. Central in this regard is the form in which users would gain access to a data market, and in which way they would be concerned with single market transactions that they engage in. Also, the scope of data markets is of relevance. Although detrimental to allocative efficiency, it would be beneficial for the protection of privacy if data markets are restricted in their scope concerning the market participants and the type of data that is traded therein. Furthermore, the specific design of data markets is relevant for the behaviour of users, and thereby the consequences of their actions. The data market proposals that this study analyses are not specific enough in order to assess all of these parameters, but provide useful indications for elements that are of relevance in this regard. Concerning the overall problems with data protection in an age of big data, it is not apparent at all whether data markets would indeed form a better way of protecting the privacy of online service users. Many of the improvements that data markets could bring could likely also be achieved by modifying the existing methods of data protection. Policy makers in the European Union should therefore not focus on the solution of data markets, but strengthen the existing and proven mechanisms for data protection. This entails providing sufficient funds to the supervisory authorities, stimulating research on the existing weaknesses of data protection, and speeding up the process of political decision making concerning data protection issues.","privacy; data protection; data markets; data brokers; ethics; personal data; personal information","en","master thesis","","","","","","","","","Technology, Policy and Management","Values, Technology and Innovation","","Ethics / Philosophy of Technology","",""
"uuid:923e315e-527a-474f-bc42-7b7e0d00d507","http://resolver.tudelft.nl/uuid:923e315e-527a-474f-bc42-7b7e0d00d507","Haptic learning tool for thoracoscopic suturing","Feldberg, D.G.","Sonneveld, M.H. (mentor); Goossens, R.H.M. (mentor)","2014","Thoracosopic surgery and laparoscopic surgery are related members of the Minimal Invasive Surgery (MIS) family. The first one is in fact the last one on the timeline. Both the more scarce literature on VATS and far more extensive body of literature on laparoscopy were studied on history, “state of the art” and new ideas for designing. The effect of duty hour restriction, rapid advancement of technology in general and in surgery, and a public concern for patient safety have created the need for surgical training outside the clinical arena of the operating room (OR). Simulated practice gives benefits to laparoscopic and thoracoscopic surgery. Surgical simulation is now a part of many surgical programs and takes place in the formats of box trainers to simulate the thoracic and abdominal cavity, Virtual Reality simulators with computer-generated environment, and Augmented Reality trainers with features of the two other platforms. Use of SkillsLabs is effective and enhances performance. Access to these simulators is an issue because of high costs of commercial simulators. Personal ownership of professionally built simulators by trainees is rare. Homemade solutions may fill this training gap. Portable trainers allow for flexibility of training at home with the potential for deliberate practice at a place other than at a formal simulation laboratory and outside of limited in-house duty hours or as modular simulation training. To train the skill of intracorporeal suturing in thoracoscopy, a simple personal, portable, durable, non-collapsible home-based box trainer of transparent Perspex at low cost is developed and improved after demonstrating to and interviewing of expert surgeons. The Haptic learning tool offers a structural process in acquiring the skills that have to do with the tasks of intracorporeal suturing in a VATS setting. The tasks enabled by the elements offer part tasks and a whole task of intracorporeal suturing. The box offers two phases with direct view and indirect view on the lesion area by blocking direct view and adding a smartphone as imaging source. This way the necessary skill to master is built up along the way of following the haptic learning tool. Due to the multiple ports for introducing instruments, the box can be used for both training of thoracoscopy and laparoscopy and is especially intended for first year surgical residents.","medesign","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","","",""
"uuid:47fe7b79-2493-49f2-abb5-078ca385c9d2","http://resolver.tudelft.nl/uuid:47fe7b79-2493-49f2-abb5-078ca385c9d2","Business Intelligence from User Generated Content: Digging into microblog posts about new smartphones","Setiya, K.","Cunningham, S. (mentor); Ubacht, J. (mentor); Oruc, S. (mentor); Van Geenhuizen, M. (mentor)","2014","High-tech and dynamic markets are faced with a rapidly changing environment and consumer requirements. At the same time, UGC is increasing drastically over the past years. UGC is becoming increasingly important in purchasing decisions while the business intelligence methods that leverage UGC are still in their infancy. A model that presents a new way of deriving business intelligence from microblogs was developed and in part applied on the dynamic smartphone market by means of three case studies. Poisson regression, data- and sentiment-analysis suggest that opinion leadership and real-life events effect the online chatter and sentiment about the smartphone and that businesses such as smartphone manufacturers can shape this online chatter with opinion leadership. In future research, the model can be applied in full on more cases and products over various industries. Other data analysis techniques can be applied and a predictive model for volume and sentiment of online chatter can be built using the findings of this study.","User Generated Content; UGC; Twitter; Business Intelligence; BI; microblog; tweets; competitive advantage","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Economics of Innovation","","Management of Technology","",""
"uuid:df8db315-8670-493a-a81e-dfadf5218578","http://resolver.tudelft.nl/uuid:df8db315-8670-493a-a81e-dfadf5218578","Logistics Transition Plan for Heineken Ethiopia","Butt, M.N.A.","Rezaei, J. (mentor); Meijer, S. (mentor); Tavasszy, L. (mentor); Bokelman, S. (mentor)","2014","Nowadays organizations are persistently searching for ways to enhance their performance and to stay competitive in their business sectors. Ambrosino and Grazia (2005, p23) mentioned that ‘‘all companies which aim to be competitive in the market have to pay attention to their organization considering their entire supply chain.” However, at some instances focus on sub problems that are in the different echelons of the supply chain is needed. A clear example is the expansion/addition of production facilities, which calls for the effective redesigning and re-structuring of distribution channels, and is critical for a company to maintain market leadership. The research objective of this research is related to the above mentioned context, in which the problem of restructuring of distribution channels is to be catered at Heineken Ethiopia, given the addition of a new brewery at Addis Ababa. The aim of the project is to determine the arrangement of distribution channels which could yield minimal distribution costs, improved delivery times, better service quality and flexibility.","logistics; supply chain","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Transport and Logistics","","Engineering and Policy Analysis","",""
"uuid:3f60af01-435a-4dbf-8996-ca5240e51e5b","http://resolver.tudelft.nl/uuid:3f60af01-435a-4dbf-8996-ca5240e51e5b","Solar-geothermal symbiosis in cities: Harnessing the potential of an existing district heat grid","Nassikas, M.","Correljé, A. (mentor); Van Bueren, E. (mentor); Künneke, R. (mentor)","2014","Today is a turning point for the energy system in European cities. Shall the exploitation of fi-nite resources continue, or is another path possible, not only technically but also economically? Efforts to curb energy consumption and greenhouse gases emissions have so far been centered on electricity in the European Union, not on heat. Untapped potential in the heat sector exists, such as renewable district heat (DH). Solar and geothermal energy are part of this renewable potential. Because cities in Europe are densely populated, ground surface is a scarce resource. But the sun´s energy can be harvested on un-used surfaces whose utility is under-estimated: rooftops. Using decentralized renewable production implies a modification of existing centralized governance structures and reinforces the powerful interdependencies between subscribers and network owner. Faced with the stagnation of renewable district heating, this research aims at evaluating the technical and economic feasibility of two variants of solar-geothermal symbio-sis under different institutional arrangements. The master thesis focuses on the economic viability of a solar-geothermal symbiosis network in the city of Munich, Germany","district heat; renewable energy; economic feasibility; governance; quantitative modelling","en","master thesis","","","","","","","Campus only","2016-08-25","Technology, Policy and Management","Values, Technology and Innovation","","Economics of Technology and Innovation","","48.1333, 11.5667"
"uuid:d2284a99-9598-4189-a037-1961caad0009","http://resolver.tudelft.nl/uuid:d2284a99-9598-4189-a037-1961caad0009","Examination of insurer fees by means of life expectancy","Verkade, W.J.","Kurowicka, D. (mentor)","2014","In the Netherlands, the pension regulation consists of three pillars. The first pillar consists of the basic state pension called AOW (algemene ouderdomswet), which is meant to provide a financial foundation for every person. At the moment, the yearly AOW contribution for a retired person is somewhere between 10.000 and 15.000, depending on whether or not you have children or a partner with income. The second pillar is meant for every employed person as an addition to the AOW pension. Mostly, the employer has an agreement with an insurer, to which he pays a yearly premium for every employee. The insurer then pledges the employee a pension at retirement, amount of which is based on the yearly premium. This premium is partially paid by the employee's salary and partially by the employer. So the employee actually sets aside a part of salary to save for his pension. Every employer has its own regulation for this secondary term of employment. It is however legally obligatory. The third pillar consists of every other form of building up pension. For example, depositing money into a bank or taking additional insurances. In this report we will only examine the second pillar. For convenience, we shall simply call this second pillar; pension. The insurers costs of providing a pension depends on how much and long a person will receive a pension as well as how long this person saves for his/her pension. The goal of this research is to investigate how the main insurers in the Netherlands determine their costs of providing a pension. We will examine two main algorithms that are used to determine insurers’ premium, discuss assumptions used in these algorithms and investigate whether these assumptions are reasonable. The report is organized as follows: First, we discuss the general approach how insurers calculate their premiums which are based on the estimated future expenses of the insurer. The future expenses of a person are determined on basis of how long this person is going to live after his retirement and the interest rates. To calculate how much a person has to pay now to receive a certain amount of pension in the future, the calculated expenses are discounted. Since the money put aside now could be invested, it is worth now less than it will be worth in the future. Discounting requires the choice of the interest rate. This discount rate is based on the expected return of risk-free investments such as government bonds. Because the discount rate have a huge impact on the premium, we will discuss it in this report in Section 2. Every person is different, so the insurer has to estimate the expected life length of a person after retirement. In section 4 the life expectancy is calculated using mortality rates, which provide the probability of death at a certain age. The data about the historical mortality rates of Dutch population is available. However, to calculate future expenses the insurers need the future mortality rates rather than the historical ones. Hence the future mortality rates have to be forecasted. We will examine two algorithms that allow to forecast mortality rates and provide the life expectancy curves that can be obtain with these forecasted mortality rates. In Section 5 the the Royal Actuarial Association (AG) is presented. Section 6 contains explanation of the PLT model (pensioenen lijfrentetafel workgroup). Both models use a similar approach based on the smooth historical data, which is extrapolated to determine a forecast of 50 years. The models do not contain uncertainty of the forecast. An alternative model is proposed by Central Bureau of Statistics (CBS). The CBS model is different from the other two. It is a lot more complex as it includes causes of death and takes medical developments into account. Besides that, it does give an indication of the uncertainty in the forecast, which is a nice advantage. However, due to its complexity, it will not be investigated in this report. Section 8 contains comparison of fees that the insurers use to cover their future expenses. Insurer fees are essentially the premiums for buying 1 euro of pension of an insurer. Insurers determine these fees based on their own methods. Some just use the forecast of one of the earlier mentioned models, while others do their own calculations. Since the fees would be different for each employee in general the simplified calculations are performed by insurers. Instead of looking at every employee separately, the insurers calculate fees for the employee with average age. We will see how these simplified calculations compare to previously discussed ones. Finally we conclude the report and provide the recommendation. The detailed presentation of algorithms discussed in this report are shown in Appendices. Moreover R-code used to make figures and obtained results included in this report is included in the end.","pension; insurance; life expectancy; fees","en","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","","",""
"uuid:43eb09b3-0874-40b7-b739-04c397538c89","http://resolver.tudelft.nl/uuid:43eb09b3-0874-40b7-b739-04c397538c89","Designing Parametric Modeling for Bioprinting Ear Cartilage","Feenstra, C.J.","Goossens, R.H.M. (mentor); Verlinden, J.C. (mentor); Song, Y. (mentor); Bos, E.J. (mentor); Wolff, J. (mentor)","2014","At the VU University Medical Center, Amsterdam, a new process for total ear reconstruction is being developed. The current ear reconstruction process involves the sculpting of a scaffold which will be wrapped in skin to form the shape of the new ear. This requires the harvesting of large amounts of rib cartilage needed for construction of the ear scaffold, and only limited personalization of the new ear scaffold is realized. The new process has the patient's remaining ear 3D-scanned after which a standard parametric implantable model of a scaffold has to be adjusted to fit the 3D scan. This model is then 3D printed and used in the reconstruction of the ear. This project focuses on the fitting of the parametric model to the scan data. Based on a model made by Tom Scholten, a parametric model is further developed using the Rhinoceros3D plug-in Grasshopper. A MATLAB program is developed, along with a graphical user interface. An automatic feature has also been developed and tested. While the software and model combination is but a proof of concept and only a step in the development of the whole new ear reconstruction process, the results obtained in this project are notable: the shape of the parametric model and its adjustment parameters were evaluated by VUMC experts and found to be good for this stage of the project. The MATLAB program also performed well, but is still subject to further research. The user interface obtained positive feedback from a user test as well as from an accompanying questionnaire. Finally, a number of recommendations for further research and development are given.","ear; parametric; matlab; automatic; scaling; reconstruction; interface","en","master thesis","","","","","","","Campus only","2015-08-25","Industrial Design Engineering","Design Engineering","","Master of Science Integrated Product Design","",""
"uuid:c8de1961-2950-49c7-84f5-34eb65b3f8f1","http://resolver.tudelft.nl/uuid:c8de1961-2950-49c7-84f5-34eb65b3f8f1","Application of digital image correlation to glass fibre-reinforced composites under transverse tensile loading","Cascelli, C.","Janssen, M. (mentor)","2014","Fibre-reinforced polymer composites (FRPs) have been used in structural applications for years mainly due to their outstanding specific mechanical properties. In this thesis, the characterisation of the strain field upon transverse tensile loading of glass fibre-reinforced polymers (GFRPs) was investigated by applying digital image correlation (DIC) to scanning electron microscopy (SEM) images acquired during in situ mechanical testing. Full arrays of strain values were successfully obtained for regions of interest (ROI) atin the microscopicmeter length scale. With an eye towards the effect of microstructure, matrix and fibre/matrix interface properties on the overall mechanical behaviour of the material, GFRPs with two different thermoset polymer matrices were tested under 3-point-bending and compared. A systematic procedure for the generation of speckle patterns based on the deposition of Al2O3 and Fe3O4 nanoparticles has been developed, granting the DIC analysis a high resolution even at high magnifications 5000x. An optimum subset size was determined by using the Gray Level Co-Occurrence Matrix. Cracking at some fibre/matrix interfaces could be detected visually and by means of high strain concentrations displayed in the DIC strain contour plots. Good agreement of displacement and strain fields between DIC analyses and finite element analyses (FEA), that were performed as a validation method, was achieved after taking the cracks into account in the FE-model. A novel double matrix concept was proposed as a means to reduce the stress concentrations that result during transverse tensile loading. FEA were used as validation of the results provided by the DIC analyses. The strain at rupture achieved with GFRP samples with this new concept upon transverse tensile loading is 3 times higher as the state-of-the-art at the expense of 98% in Young’s modulus.","glass fibre-reinforced composites; Digital Image Correlation; Fibre-reinforced polymers; Composites; Strains; Transverse tension","en","master thesis","","","","","","","","2017-08-31","Mechanical, Maritime and Materials Engineering","Materials Science and Engineering","","Materials Engineering and Applications","",""
"uuid:18463dbe-504d-4194-89a2-cf342c970d49","http://resolver.tudelft.nl/uuid:18463dbe-504d-4194-89a2-cf342c970d49","How Social Networks Affect the Performance of the University Spin-offs","Su, Y.","Van Geenhuizen, M. (mentor); Scholten, V. (mentor); Groenleer, M. (mentor)","2014","","social network; university spin-offs; performance; stakeholder; meta-analysis; absorptive capacity","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Economics of Technology and Innovation","","Management of Technology","",""
"uuid:ee8705df-645c-45e5-b3ad-f39c83972872","http://resolver.tudelft.nl/uuid:ee8705df-645c-45e5-b3ad-f39c83972872","Towards adoption of the outside view: An exploration for Dutch road widening infrastructure projects.","Van Zoonen, L.","Van Wee, G.P. (mentor); Annema, J.A. (mentor); Bosch-Rekveldt, M.G.C. (mentor); Van der Velde, M.H. (mentor); Van Leengoed, T. (mentor)","2014","","","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Construction Management and Engineering","",""
"uuid:1307b57c-ea79-4213-b7f2-665ae3b3760d","http://resolver.tudelft.nl/uuid:1307b57c-ea79-4213-b7f2-665ae3b3760d","TRL as a means for effective Innovation Project Performance Management","Bakker, P.","Ortt, R.J. (mentor); Veeneman, W.W. (mentor); Van Beers, C.P. (mentor)","2014","The aerospace industry often faces challenges with respect to managing innovation project performance, due to the interdependence of disciplines. The projects are often managed by means of Technology Readiness Level (TRL). However, the metrics are not available to overcome the challenge of delivering technology in time and within budget. In this thesis a method, evaluated with a case study at Fokker Aerostructures, is recommended to manage the performance of multi-disciplinary innovation projects, using TRL as a stage gate approach and standard project management practices. However, to fully address the need to manage innovation project performance, more research and effort is required to adapt the method in daily practice.","TRL; complex project management; stage gate model; Product development; Technology development; interdependent disciplines","en","master thesis","","","","","","","Campus only","2016-08-25","Technology, Policy and Management","Management of Technology","","Strategy, Technology & Entrepreneurship","",""
"uuid:34c2fd1c-9fcd-4b32-8253-f91a944da8e5","http://resolver.tudelft.nl/uuid:34c2fd1c-9fcd-4b32-8253-f91a944da8e5","Numerical Modelling of Non-Equilibrium Condensing Steam Flows","Pandey, A.","Pecnik, R. (mentor)","2014","Two-phase condensing flows are very common in many technical applications, such as rotating machinery operating with steam and nuclear reactors. The occurrence of condensation can lead to a degradation of a component's performance. Thus, the physical understanding and accurate numerical modeling of the condensation process can be of great help in the design process. The present work is focused on the numerical modeling of non-equilibrium condensing steam flows in 1-D Laval nozzles. The fluid dynamic equations for an inviscid and adiabatic flow (Euler equations) are solved using a quasi-1-D finite volume code, which accounts for the nozzle area variation. The model for homogeneous nucleation and the droplet growth rate in high-speed supersonic nozzle flow and also applicable to the wet stages of a steam turbine, is implemented in the present work. In order to assess the accuracy of the condensation model implemented, experimental data of various 1-D supersonic nozzle is compared to the numerical results.","","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Process and Energy","","Sustainable Process and Energy Technology","",""
"uuid:25e89be3-b3ea-48f0-b735-2575d09bc16e","http://resolver.tudelft.nl/uuid:25e89be3-b3ea-48f0-b735-2575d09bc16e","Het rangschikken van genen (Gene Ranking)","Boon, C.J.M.","Van Gijzen, M. (mentor)","2014","Eén van de grootste uitdagingen in de geneeskunde is op het moment het vinden van onderliggendeoorzaken voor genetische ziektes. Een mogelijk hulpmiddel in dit onderzoek is het rangschikken van genen op mate van belang. Dit rapport beschrijft een onderzoek naar dit rangschikken van genen. Een menselijk lichaam bevat 20.000-25.000 genen, die doordat ze in verbinding staan met elkaar, zijn te ordenen naar mate van belang. Het doel van het maken van deze rangschikking is het vinden van de meest bepalende genen, die een grote rol spelen bij bepaalde genetische ziektes. Het doel van het onderzoek is begrip krijgen van hoe genen zijn verbonden, en het verbeteren van het al bestaande GeneRank algoritme, een algoritme over het rangschikken van genen. Het GeneRank algoritme dat het fundament is van dit onderzoek, neemt twee componenten van data mee in de berekening van de rangschikking, zodat de rangschikking zo betrouwbaar mogelijk is. Het eerste component is de experimentele data, die een rangschikking van genen geeft met eventuele fouten door experimentele onnauwkeurigheid. Het tweede component is de biologische kennis over verbindingen, ofwel de verwachte verbindingen, tussen genen, waardoor de experimentele onnauwkeurigheid zo veel mogelijk wordt ingeperkt. De biologische data is opgebouwd uit de moleculaire functies, de biologische processen, en de cellulaire componenten van de genen. In de beschreven algoritmes is er even veel gewicht gelegd op de experimentele data als op de biologische data. Het rangschikken van genen heeft veel overeenkomsten met het rangschikken van pagina's, zoals het PageRank algoritme van Google doet. Zowel genen als pagina's zijn onderling verbonden, en zowel genen als pagina's zijn te modelleren in een netwerk, en te rangschikken op mate van belang. Het grootste verschil tussen deze twee problemen is dat als een willekeurige pagina op het web met een andere willekeurige pagina verbonden is, dit andersom niet hoeft te gelden, terwijl wanneer een willekeurig gen met een ander willekeurig gen verbonden is, dit ook andersom geldt, ofwel het gen netwerk is symmetrisch. Door de symmetrie van het GeneRank probleem is er na omschrijvingen een snel convergerende methode voor symmetrische matrices toegepast, die een goede oplossing geeft. We hebben het GeneRank algoritme hiermee verbeterd.","genen; rangschikken; GeneRank","nl","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","TW","","","",""
"uuid:df7c3aa6-f8b5-4389-93cd-4ac5bf6cba4b","http://resolver.tudelft.nl/uuid:df7c3aa6-f8b5-4389-93cd-4ac5bf6cba4b","Calibrating a rainfall-runoff model in a data scarce catchment in Mozambique","De Kloe, J.J.","Savenije, H.H.G. (mentor); Luxemburg, W.M.J. (mentor); Zijlema, M. (mentor); Juizo, D. (mentor)","2014","Rainfall runoff modeling is a major task of many hydrologist. Therefore always a lot of research is done to modeling. One of the problems of modeling is often the lack of data. Most of the world is data scarce, in the sense that no discharge is being measured. Although this is the case, it is often preferable to make a model of a catchment in such an area. Therefore a lot of research is carried out in calibrating a rainfall runoff model without discharge data. This research is also focusing in this. With a fieldwork of 3 weeks and knowledge of the local fishermen, the catchment is being investigated. The catchment is in the south of Mozambique, and is the catchment of the Lumane river. This is the last tributary of the Limpopo river. Upstream of the Lumane is a fresh water lake, which feeds the river. The yearly fluctuating of this lake is used for the calibration of the rainfall runoff model. With information of the local fishermen, a hydraulic model of the river and the yearly precipitation pattern; a Fourier series is made, describing the lake’s water level. This Fourier series is used for the calibration of the rainfall runoff model. Next to this, also GIS data of actual evaporation is compared with the outcome of the model. This is also used for the calibration. In order to validate the model is looked at how well the model is following the Fourier series of the lake’s water level. Furthermore is checked if the fluctuating of the reservoirs is reliable, as well as how reliable the calibrated parameters are. Since the rainfall runoff model is a lumped model, but based on an hydrological classification, the parameters really mean something. Therefore can be seen if the model is acting as suspected. From the results it becomes clear that the model is mimicking the level of the lake. Also the discharge data seems to be in the right order of magnitude compared to historical data and local measurements. Only the evaporation outcome differs a lot from the GIS data during summer time. The reliability of this GIS data will therefore be discussed as well as the shortcomings of the model structure. After all one can conclude that it is possible to calibrate a rainfall runoff model without discharge data. However, to validate the model, discharge data is necessary. Else, it is hard to know how good the model really is.","hydrology; rainfall runoff model; data scarce","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Water Management","","Hydrology","","25.034415, 33.285611"
"uuid:7bee67c3-b2ce-491c-89e8-24f0b9d3591a","http://resolver.tudelft.nl/uuid:7bee67c3-b2ce-491c-89e8-24f0b9d3591a","Monitoring Cold Chain items in the humanitarian aid context: A reliable and easy-to-use device for quality control","Bariain, M.","Rhein, D. (mentor); Melles, M. (mentor)","2014","Some medicines, tests and vaccines are sensitive to heat and/or cold. Therefore they need to be transported and stored in a constant temperature between 20C and 80C to keep their medicinal properties. These items constitute the Cold Chain, the preservation of temperature from manufacturing until administration. This is a considerable obstacle in developing countries, particularly in areas that are hot, isolated and lack of reliable electricity supply. UBD (Use Before Date) is a digital expiration date that uses printed electronics technology. UBD is a sticker that calculates and displays the expiration date of the Cold Chain item. It contains sensors, rewritable memory, a display, a wireless communication system and a battery to run the system. It informs about the tendency of an excursion and prevents items to be thrown away while still being in use. UBD informs and alert in an intuitive way. To make the damage of Cold Chain items visible, this project aims to provide understanding about the condition of Cold Chain items to the end users in a very intuitive way. When knowledge is given, also responsibility is given.","monitoring device; temperature; cold chain; humanitarian aid; MSF; digital; expiration date","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master specialisation Medisign","",""
"uuid:6ee1100a-f895-45a2-88ef-2c998195caa1","http://resolver.tudelft.nl/uuid:6ee1100a-f895-45a2-88ef-2c998195caa1","Virtual design and construction in the AEC industry","Scholtes, O.W.J.","Herder, P.M. (mentor); Van der Lei, T.E. (mentor); Van Nederveen, G.A. (mentor)","2014","","CME","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Construction Management and Engineering","",""
"uuid:660e58d7-a82d-46d9-a8ff-1bfba42b2b05","http://resolver.tudelft.nl/uuid:660e58d7-a82d-46d9-a8ff-1bfba42b2b05","Up-scaling of froth flotation equipment","Boeree, C.R.","Buxton, M.W.N. (mentor); Voncken, J.H.L. (mentor)","2014","The up-scaling of flotation equipment has been investigated based on comparisons between laboratory, pilot and industrial scale flotation tests and a characterization study of large-scale industrial flotation cells in Boliden’s Aitik copper mine in Northern Sweden. The use of high volume flotation cells has nowadays become more and more common to deal with the production of high capacity, low-grade open pit mines, which are typically copper or gold mines. Implementation of large flotation cells in the mineral beneficiation process holds several financial benefits, but gives no guarantee of an equal or improved metallurgical performance. From a historical point of view, flotation plants have been designed based on the results of laboratory tests, multiplied with a time up-scaling factor at which recovery was expected to be above a certain value on the industrial scale. Due to the uniqueness of each ore, such an experience-based factor has often resulted into under- or overestimations of the total required cell volume. One of the main differences between lab and industrial flotation in this research is found the be the behaviour of fine particles (-45 ?m), which are shown to have slower flotation kinetics and poor recovery on the industrial scale in comparison to the lab scale, but are also accompanied by a relatively high degree of gangue mineral entrainment in lab tests. A characterization of the industrial flotation equipment was done to acquire more information on the sub-processes that take place within the cells. Sampling on different depths in 160 m3 rougher and scavenger cells revealed a well-mixed regime in the lower cell half, decreasing homogeneity above a depth of 2,5 m under the froth, and an accumulation zone of fine-grained copper-rich minerals directly under the pulp-froth interface. The effectiveness of the low-turbulent zone in the top half of the industrial flotation cell is questioned, while the general trend in flotation cell design of increasing volume even shows an increasing height-to-diameter ratio, which could eventually lead to a larger fraction of the cell volume being low turbulent. To obtain more insight in the functioning of these flotation cell sub-zones, the use of a bubble load measurement is proposed to determine the recovery of both valuable and gangue minerals as a profile of cell height. Furthermore test work in a laboratory pilot scale cell with adjustable height is discussed, in which the volume fractions of the mixing zone, quiescent zone and froth zone can be varied. Combination of these two investigations is expected to allow better understanding of how an industrial flotation cell functions.","froth flotation; up-scaling; mineral processing","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Resources Engineering","",""
"uuid:621fdb7a-220a-4e8b-bc2c-bcc112c9dfbc","http://resolver.tudelft.nl/uuid:621fdb7a-220a-4e8b-bc2c-bcc112c9dfbc","Check in with TickID","Toussaint, R.A.J.","Wormgoor, R. (mentor); Zijlstra, J.J.M. (mentor)","2014","The TickID group is a Rotterdam based company founded in 2010. It provides festivals and events with services that render the use of entrance tickets and cash unnecessary using RFID (Radio frequency identification) systems. One of their products is a registration beacon, used to register visitors and grant access to the right people at the right time. The system proved its usability on multiple events, however the beacon itself shows some room for improvement in the technical and aesthetical area. The problem The beacon does not suit many different event situations, misses the opportunity to promote events or sponsors and does not support TickID brand awareness. Submitting the beacon to a emotional analysis by possible users, based on the Positive design model (Yoon, 2013) showed the beacon is experienced as boring and unfriendly. The goal therefore is to “Create a proposal for a registration point for TickID to use with their current software system, suitable for multiple events and communicating both the event’s and TickID’s name.”. Product development To reach this goal different stakeholders wishes and requirements are analysed, including TickID as a company, event organisations, visitors and bars. This analysis shows the importance for the registration point to suit many different event situations and event identities. Also the product should be very reliable and withstand different external influences. The aesthetics of the registration point are to communicate confidence and respect but also evoke joy and anticipation. A framework is drafted combining all stakeholders interest. Together these result in a list of requirements and wishes covering technical specifications, feedback visibility, aesthetics and a batch size of 50 products. Using the framework different product ideas are generated. A selection of these is further developed into three valid concepts. An analysis is done comparing the three concepts and the original beacon using a method based on the Positive design model (Yoon, 2013). This shows a clear preference by potential users for a ‘Triangular pole’ concept. Next to this the different concepts are analysed using Pugh’s matrix and a weighted product model (Boeijen and Daalhuizen, 2010). These both indicate the ‘Triangular pole concept’ as being most suitable for the TickID registration point.Therefore this concept is selected for further development into a complete and valid product proposal. TickID registration point Prototyping of the triangular registration point resulted in different insights and improvements to the design. Dimensions are adjusted and suitable materials selected. This results in a modular product that creates the perfect registration point for each event situation. Placing a triangular box containing the RFID system in different frames creates in products suitable for different event situations including placement on a desk, on a wall, as a pole on its own or in line to create gateways. The product design is noticeable but not overwhelming or intimidating. This impression is created by its size but also by its triangular shape with rounded edges. Whereas the distinctive triangular shape ensures recognisability of the TickID brand, the product’s black color offers a great basis for promotional branding stickers to really stand out. This branding is not only to promote the event or its partners and sponsors, but it also makes the registration point fit to every different event identity. The registration point provides clear feedback to both visitor and (security) employees by an illuminated top and RFID logo. The employees can be provided by additional extensive feedback by simply adding a simple screen or tablet to the event specific product composition. The illuminated lid also creates anticipation in visitors that notice the product from a distance. A product 0.0 is produced to analyse the product proposal in more details and make some final adjustments and recommendations including further development of the triangular registration point, the RFID system itself and certification of the final product. Eventually this results in a product that creates the perfect registration point for each event situation.","RFID; registration; check in; entrance; festival; promotion","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","","",""
"uuid:93664e5c-6751-42d5-8f02-8ed7778a9528","http://resolver.tudelft.nl/uuid:93664e5c-6751-42d5-8f02-8ed7778a9528","Rehabilitate yourself! Designing a new way of rehabilitation intertwined in daily life.","Möhlmann, A.C.C.","Albayrak, A. (mentor); Melles, M. (mentor); Bodewes, H. (mentor)","2014","The most common cause leading to the total hip arthroplasty is the joint disorder osteoarthritis. Due to osteoarthritis pain will increase over time, to the point the disease will influence the quality of the daily life of people. A total hip arthroplasty (THA) will be the solution to relieve the patient of the damaged hip. Among 33.497 patients had a THA surgery in 2008 and 2.185 patients a revision in the Netherlands. It is expected the demand for a hip replacement will triple by 2030. The literature study revealed that the in-hospital stay has decreased to 1.85 nights, with the ultimate goals of single-day discharge after THA surgery. To continue this trend, rehabilitation is the next step in improving the patient’s experience of THA surgery. The main bottleneck of the rehabilitation phase is the exercise program and regime. After surgery the patients will be referred to a local physical therapist, in which case the patient will continue being a patient. This is in conflict with the approach of rapid recovery where the patients will directly be supported in trusting their new hip, and by using it as normal. Staying a patient can have a negative effect on the rehabilitation phase, so by removing the local physical therapist from the process this patient will not be a patient anymore. By replacing this with a new solution the patients will all receive the same new treatment, and more or less result in the same outcome. This outcome can vary due to difference in personality. Therefor patient types are a good solution to give a tailored approach to different patients. The explorative research explored the patient’s experience, information about rehabilitation and the exercise program. To explore these topics, three researches have been performed; a questionnaire among THA patients, observations at a rehabilitation centre, and interviews with medical specialists. Combining the conclusions of the literature study and the explorative research resulted in five main insights about the future of rehabilitation. 1. A future of rehabilitation without exercise program or restrictions shows great possibility; 2. A void created by an intensive pre-op period should be filled; 3. A new kind of recovery should involve being active, healthy, and resume or renew daily life; 4. Increase medical certainty during rehabilitation; 5. The focus of rehabilitation should be on creating a healthy gait. These five insights provide the basis for three different design directions. Two design directions have been combined to continue this project. The starting point for the ideation phase is the following design vision: ‘Design a solution that supports the patient to create a healthy gait during daily life, and trigger them with feedback to keep conscious of their body and gait. The design should provide the patient with a feeling of medical certainty while giving information, inspiration and feedback.’ After the formulation of the vision, and a list of requirements and wishes, the ideation phase started. The ideation phase started with a research into gait analysis techniques and professionalism without involving a professional. With the gathered knowledge several brainstorms were performed, and clustered into three idea concepts. These ideas were elaborated into three feasible concepts, which mainly differed in the means of use, gait analysis technology, and value. Out of these three concepts, the BioStep concept was chosen to optimize into a final design, prototype and business plan. BioStep provides the user with a new kind of rehabilitation. It provides the user with the freedom to restart daily life directly after their THA surgery without feeling like a patient, because with their new hip prosthesis they are not restricted due to the arthritis anymore. Their daily life and activities become their rehabilitation program together with BioStep. The core elements of the BioStep are: - Creating a healthy gait by tracking the gait, creating awareness, and solutions for abnormalities in the gait; - Create a new way of rehabilitation intertwined in daily life; - Patient empowerment by creating their own rehabilitation path, to motivate, remember and encourage them why they should be active; - Expand motivation and comfort zone by inspiring with new activities, and connecting peers to share information, and experience. After finalizing the final design, a prototype was built to verify the technology and value of the design. To achieve these goals two prototypes, tangible prototype of BioStep and application, were reviewed in two evaluation studies. The first evaluation study verified that the technology shows great probability for the future. The second evaluation study shows a positive reaction of the participants and the added value of the product. Bottlenecks derived from the evaluation study are described, and modified in the final design. The business plan for BioStep was elaborated during the last phase of the design process. The business model canvas is a visual tool to communicate the business in a transparent and organised way. The customers are THA patients and has the potential to grow to 335.682 patients in the Netherlands per year. With a realistic view, an estimation of 10 percent was made, and shows a market of 33.000 possible buyers. The following cost estimation, value of BioStep, introduction plan, and future plan have been established on the basis of the business model. In the final phase of this graduation project the conclusions were drawn in relation to the design vision, and the list of requirements and wishes. Lastly, recommendations will be suggested for the future development of the BioStep by Biomet.","rehabilitation; hip arthroplasty; daily life; design; healthcare; gait; human-centred","en","master thesis","","","","","","","Campus only","2015-08-22","Industrial Design Engineering","Industrial Design","","Master of Science Integrated Product Design","",""
"uuid:d68612c6-42ef-45a9-b3e2-bf54a2fcb745","http://resolver.tudelft.nl/uuid:d68612c6-42ef-45a9-b3e2-bf54a2fcb745","Definition and evaluation of production test validation methods applied to Vx multiphase flow meters","Den Bleker, S.R.","Jansen, J.D. (mentor)","2014","Accurate flow rate measurements are very important in production testing. Originally small and insignificant deviations could propagate in subsequent applications where flow rate data is used as input parameter. Vx multiphase flow meters give much more information compared to conventional test separators. This extra data can be used for extra flow rate validation on the measurements, in order to find out whether it is possible to make sense of the data and if it is applicable on the long term and viable for further applications. Firstly, a comprehensive literature review has been done on current existing validation methods which gave a coherent overview. This work was used to define methods to detect measurement issues which can occur during a production test, defined by experts with considerable field experience. An adjusted choke model is presented which could be run in series with a Vx meter, which is able to detect: a drift in the differential pressure sensor; the under- or overestimation of the calculated gas rate or whether the meter is operating within the designed operation envelope or not. The choke model is tested on 96 data points from actual production tests with satisfactory results for fixed choke data. In addition, a methodology is developed to detect whether a production test has become stable or not. The method is translated into an algorithm which can be run on Vx meter output to decide in an automated fashion if a production test can be concluded, yielding representative production data. The method is tested on 700 production tests in order to define the model thresholds, which showed that the majority of the tests could have been concluded earlier. It has been found that by analyzing the statistical properties of the data it is possible to observe flow pattern transition. Furthermore, by representing certain parameters in the frequency domain, slug flow regimes can be detected and the corresponding slug flow periodicity can easily be subtracted from the data.","multiphase; flow rate; measurement; validation method; signal analysis; stochastic analysis","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Petroleum Engineering","",""
"uuid:e6c72c1e-4c88-4f6a-b966-e5072bb928d2","http://resolver.tudelft.nl/uuid:e6c72c1e-4c88-4f6a-b966-e5072bb928d2","Interactive Remote Rendering","Neven, D.M.","Eisemann, E. (mentor)","2014","In this thesis, we present an interactive remote volume-rendering system. Our system tries to bridge the gap between complex medical volume data and the patient. The user can easily upload their own data, which they receive from the clinician after a scan, which they can then visualize. Our application does not require any medical or volume visualization background, and can run from any device with a working internet connection and an internet browser. We also introduce a technique to use multiple machines in order to combine the computing power into one very fast renderer and the other way around: multiple concurrent users on one machine by distributing the workload efficiently.","Interactive Remote Rendering","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Computer Graphics","","Computer Graphics","",""
"uuid:d5336fda-3b91-40a0-81c0-8931f50759a6","http://resolver.tudelft.nl/uuid:d5336fda-3b91-40a0-81c0-8931f50759a6","Designing artificial companionship through explorative research in order to prevent loneliness in the future elderly of the baby boom generation","Papadopoulou, A.E.","Paauwe, R.A. (mentor)","2014","Buddy, is the result of an explorative research-through-design approach in the field of artificial companions. The main goal of the project was to create a prevention tool for alleviating feelings of loneliness. In order for this to happen the selected target group is people that are not old, yet, but are in transition at the moment, the baby boomers. The most appropriate moment to intervene is the retirement, as it was investigated to be one of the crucial moments in one's life that might lead to a future lonely senior. Since there are not many current robots that deal with that issue, the research had several steps of explorative prototypes and was build using user's insights and feedback. The proposed design is an embodied companion that provides seniors a structured way to segment their long-term goals into short-term ones by motivating them throughout the way, as a buddy would do, via SMS communication. Evaluation of the concept revealed that the existence of an other being, even an artificial one, has an effect in the companionship people feel when executing their tasks, keeping them more motivated.","interaction; social companions; robots; artificial companions; explorative design; prototyping","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Design for Interaction","",""
"uuid:d76455a8-3b02-4578-b126-329e4301fd62","http://resolver.tudelft.nl/uuid:d76455a8-3b02-4578-b126-329e4301fd62","Design of a novel UI Controls for interventional CT radiologists","Yasynetskyy, A.","Boersema, T. (mentor); Goossens, R.H.M. (mentor)","2014","This Graduation project concerns the design of a new UI console aimed for use by radiologists during CT-guided minimally invasive procedures. The assignment was offered by Philips Healthcare and was executed in close collaboration with Philips Design Healthcare team. The final proposal had to be feasible considering the short- term launch in the market, and to be aligned with the current Philips identity. After the problem definition, the design goal was defined as “To de- sign in-room table-side device that support radiologist with full con- trol over the interventional CT medical equipment in a safe, intuitive and efficient way”. Therefore, the main challenge was to design a product that has to be used under sterile conditions, that is being covered with a plastic drape and used with gloved hands. The user-centred design approach has been the core of the project. As a result, the generated designs were tested and evaluated with customers three times with a goal to meet their real needs, plus to ensure a safe, efficient and pleasant use of the product. The final design reflects the application of user-centred design methods and several design iterations, which resulted in a mature concept. During the concept evaluation the Philips customers de- noted the concept as a “very promising” solution. The proposed design with a novel UI controls was seen as a product that is easy to use and that can help interventional radiologist to perform the procedures faster, in a safe and intuitive way. Thus, it can streamline the clinical workflow and improve the customer experience and the clinical outcomes.","user interface; interaction; usability; healthcare; intuitive design; design controls","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Design for Interaction","",""
"uuid:ac1c5b04-6562-423f-94b5-c7364b6afb35","http://resolver.tudelft.nl/uuid:ac1c5b04-6562-423f-94b5-c7364b6afb35","Low-frequency SNR improvement of refracted waves by cascaded correlation and convolution","Velds, C.B.","Campman, X.H. (mentor); Draganov, D. (mentor); Wapenaar, C.P.A. (mentor)","2014","Seismic interferometry is the process where new impulse responses, i.e. Green’s functions, are retrieved between two points by cross-correlation, convolution or deconvolution of wavefield responses. Seismic interferometry is also referred to as Green’s function retrieval. Newly retrieved Green’s function might contain spurious events that arise due to strict requirements for Green’s function representation for seismic interferometry that are not met in practice. Methods exist for the suppression of spurious events; however, it is shown in various studies that spurious events can be very useful. The virtual refraction is a well-known coherent spurious event that arises when refracted waves are correlated. This event can upon stacking be strongly enhanced with sources located post-critically in the stationary-phase region, which complies with typical 2D exploration source and receiver geometries. This event contains information of the velocity and depth of layers that cause waves to be guided along an interface (refraction). Source-receiver interferometry additionally to cross-correlation adds convolution to retrieve a Green’s function between a source and receiver, hereby turning a virtual refraction into a refraction with the same traveltime characteristics as the original refracted wave. This work explains how source-receiver interferometry can be applied to refracted waves. Synthetic seismic data and controlled-source field data shot in the desert in Oman are used to apply source-receiver refraction interferometry. Results show how signal-to-noise ratio for random noise as well as coherent noise refracted waves is improved in long-offset data.","active-source seismic-interferometry; Green's function retrieval","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Applied Geophysics and Petrophysics","",""
"uuid:9f93374b-7f79-4633-a02f-ac81f5e2da33","http://resolver.tudelft.nl/uuid:9f93374b-7f79-4633-a02f-ac81f5e2da33","Prediction of Vehicles' Trajectories based on Driver Behavior Models","Li, Z.","Hellendoorn, J. (mentor); Mazo, M. (mentor); Hoogendoorn, R.G. (mentor)","2014","As a component of Dutch Automatic Vehicle Initiative (DAVI) project, this study aims at improving highway driving safety of autonomous vehicle. It is observed that some misbehaved drivers do not use turn indicators forehead a lane change on highway. For a self-driving car in such situations, a lane change is potentially dangerous without an accurate estimation of other vehicles’ movements .If lane changes can be detected or predicted at its initial phase, DAVI vehicle can be advised in time to perform corresponding maneuvers to avoid collision. In this study, a Support Vector Machine (SVM) based method was proposed to fulfil this task. Predictions are generated through analysing vehicles’ motion parameters. At the first place, a number of driving simulator tests were carried out to set up database of typical vehicle maneuvers features, including heading angle, yaw rate, lateral velocity and lateral acceleration. 14 driver databases were used in SVM training after removal of unrealistic info. An off-line trained SVM was obtained to perform lane change predictions. In addition to offline training, an incremental training SVM was introduced. Compared with off-line learning, its incremental feature enables the classifier to update itself with freshly recorded lane change data in a relatively short time. This enables the vehicle to be ""learning while predicting"" . Based on the databases, SVM based approaches were verified to be feasible of predicting lane changes. With the most optimal parameter combination, this method is able to perform predictions with 100% sensitivity ( predicted all lane changes successfully). Average advance time and average computational time are acceptable for automatic driving. Besides, the performance of sliding window method was evaluated for variation of its size, and a general applicability of overall prediction method was also examined on data from different drivers.","lane change; SVM; incremental training","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Delft Center for Systems and Control","","System and Control","",""
"uuid:4019b6a7-0060-4199-86c6-f1ff9c97dab2","http://resolver.tudelft.nl/uuid:4019b6a7-0060-4199-86c6-f1ff9c97dab2","Theaterakoestiek: Een onderzoek naar het gebruik van de toneeltoren voor de ontwikkeling van variabele akoestiek / Theatre acoustics: A study to use the fly tower for the development of variable acoustics","Scholts, K.","Nijsse, R. (mentor); Schipper, H.R. (mentor); Nijs, L. (mentor); Bijvoet, P.B. (mentor)","2014","When one wants to make use of variable acoustics in a theatre, the volume of the auditorium is often changed by altering the ceiling height of the room. Besides this, an orchestra shell is placed to direct the sound towards the audience and to prevent delayed reverberation from the fly tower. Thus, extra space for the acoustic volume is created in the auditorium while space above the stage remains unused. This study focuses on the possibility of using the fly tower as acoustic volume for symphonic concerts. It researches which space above the stage can be used without the negative side-effects of delayed reverberation. To be able to compare different variations, the acoustic volume will be the same throughout the study. The study will propose to increase the size of the orchestra shell and to thus use more room on the stage. To compensate the extra volume, the ceiling height in the auditorium is lowered and the proscenium arch is increased together with the orchestra shell. The different variations of the study will be compared according to different parameters: the reverberation time (T-30), the early decay time (EDT), the strength (G) and the clarity (C-80). Results show that more space above the stage can be used as acoustic volume instead of creating extra space in the auditorium. The enlarged orchestra shell sometimes even produces an improvement of the acoustic quality of the theatre auditorium. This improvement is largely found in the reverberation time and the strength. In addition, the results are more evenly distributed over the hall. However, one has to take into account that sufficient diffusion is present in the orchestra shell. NB: please note that the study is in Dutch.","variable acoustics; theatre; orchestra shell; fly tower","nl","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Building Technology","",""
"uuid:701ff19f-067b-4fd5-bc17-7db94f6ce6b3","http://resolver.tudelft.nl/uuid:701ff19f-067b-4fd5-bc17-7db94f6ce6b3","Skeleton: The design of a foot-wakeboard mounting system","Weerts, L.F.","Jansen, A.J. (mentor); Jellema, A.H. (mentor)","2014","Manufacturers of extreme sports equipment are constantly seeking to provide the user with both ultimate adrenaline and a feeling of safety and control. These factors drive manufacturers to conducting ongoing research in order to develop the perfect equipment that meets all demands. Wakeboarding is trend sensitive and user demands are high, not only on performance and safety but also on aesthetics. Jobe Sports International is brand owner, manufacturer importer, developer and distributor of watersports equipment. Since the emerging of wakeboarding the Dutch based company has been manufacturing wakeboarding gear. Within the Jobe product category of wakeboarding, several developments took place over the last couple of years such as new shapes of the boards and the use of new core materials. However, the design of the wakeboard bindings did not change during this period of time in contrast to other brands that released different innovations in binding design. Furthermore, sponsored riders of the Jobe wakeboarding team, that are considered as the main source of providing product feedback to the product development team of Jobe, have indicated that the binding does not fulfil their needs. The binding is placed on a baseplate that is thick what creates a distance between the foot and the wakeboard of 40mm, the boot does not provide enough support to the ankle because the shaft becomes weak over time and the binding looks bulky. Besides the problems indicated by the sponsored riders the company faces another challenge: the current design of the binding makes use of a patent, a method of making the binding assembly. As a result Jobe pays a fee to the patent owner for every binding sold in the US and Australia. Above indicators ask for a design proposal that stands out in the wakeboard market and meets, or even exceeds user needs. In order to achieve this the design proposal should comply with a number of formulated criteria: the foot-wakeboard mounting system should get around US Patent 7,766,711 B2, has a sleek and slim appearance, is protective for the feet and ankles and has an improved feeling of control. Through a process of designing and developing many ideas were transformed into three concepts and one in particular showed the most potential. This concept was expected to meet high standards while being suitable for mass-production. Additionally, this concept was most distinct in appearance in regard to the competition. The chosen concept consists of two main parts: an external skeleton combined with a separated sneaker. The skeleton is a uniform body that does not make use of any kind of connection method described in the patent. The sneaker is equipped with stiff heel compartment, a thermo formable liner and a insole following the contours of the users’ feet. A prototype for testing and validation was made and a practical test on a cable way was performed. Results of the test were promising: the binding provided significant control to the rider, the binding was easy to take on and off and did withstand the forces of the landing of a big jump. Further development should focus on increasing the stiffness of the baseplate and improve the aesthetic quality of the design proposal.","binding; wakeboarding; watersports","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Master of Science Integrated Product Design","",""
"uuid:d5c76987-d6a0-4026-ac91-00520d750bd0","http://resolver.tudelft.nl/uuid:d5c76987-d6a0-4026-ac91-00520d750bd0","Philips LifeShield: CPR guidance for (untrained) responders","Römer, B.M.J.","Ruiter, I.A. (mentor); Kooijman, A. (mentor); Mühlsteff, J. (mentor)","2014","This Master graduation project describes the product development of the Philips Lifeshield, a smartwatch that provides cardiopulmonary resuscitation guidance device for (untrained) lay responders. The problem is that every year between 350,000 and 700,000 Europeans suffer and out-of-hospital cardiac arrest. In 51% of the cases these events are witnessed by (untrained) lay responders in a home environment. However these people do not know the guidelines for cardiopulmonary resuscitation (CPR) during these events are require support in assessing the vital signs of a person that suddenly collapsed and instructions on how to perform CPR if this is required. The report describes the complete process from design brief to the embodiment of a first prototype to validate the concept, the Philips LifeShield. The initial focus of the project was on the spouses of the victims, often people with a higher risk of cardiac arrest, since these people have to be able to understand the given instructions and the use of the device. However, it does not mean that the LifeShield cannot be purchased by a victim itself and therefore additional function have been created such as the fall detection, GPS tracking and auto EMS call. The preferred location of the LifeShield was the forehead, since this is easy to locate for lay responders, it is often available and the signal quality was sufficient to detect the breathing and pulse. Additionally it was found that the experience flow could be seperated in 4 phases: the pre-event, preparation, attendance and aftercare phases. Each of these phases had their specific problems focused on the responder. After the problems were identified t different solutions were explored for a device that could be placed on the forehead and was available at all times. The chosen solution was the Philips LifeShield. The LifeShield can be worn by as a watch or key chain due to different modules and can measure pulse and breathing by using an accelerometer and a photoplethysmogram (PPG) sensor. If no pulse and no breathing is detected the device will prompt audio and visual instructions (including a metronome) to provide instructions on how to perform CPR. The strength of the Lifeshield is that it is easily available and still has a daily function as a smartwatch, but has an emergency function in the case of a cardiac arrest. Additionally the device will store data on the performed CPR, such as the duration, compression rate and quality, so it can help the professional responders (EMS) in assessing the situation upon arrival. The LifeShield can either be purchased by the spouse or the victim itself and contains also functionalities such as fall detection, GPS tracking and auto EMS call as long as it is connected to a smartphone. The concept was validated using 3 prototypes: an aesthetic model, a functional model and an interface model. The interface model had to version one with visual instructions and one without. The results among ten participants indicated that the overall shape of the device was favored, but that it still could be improved in the availability of different colors and materials. Additionally a traditional metal-look was preferred and the device was still very fragile and not waterproof. However, the functionality and the detachment mechanism were understood by most of the participants. Lastly it was found that the visual instructions were slightly preferred and that untrained responders performed better than people with prior training. Although the LifeShield did not reduce the stress of the participants it made them more confident in performing CPR and they were capable of doing so without having any experience. Therefore it can be concluded that although the Lifeshield still needs to be improved it can potentially save the lives of many people.","Cardiopulmonary resuscitation; Smartwatch; CPR; Philips; Pulse detection","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Integrated Product Design","",""
"uuid:bfb6a4c7-1c60-472c-858e-bc519fc46521","http://resolver.tudelft.nl/uuid:bfb6a4c7-1c60-472c-858e-bc519fc46521","Influence of Engineered Roughness on the Flow Instabilities in a Centrifugal Compressor","Kapoor, P.","Pecnik, R. (mentor); Javed, A. (mentor)","2014","Centrifugal compressors form an integral part of automotive turbochargers. Strict emission regulations and increased engine downsizing in the automotive industry are pushing the turbocharger centrifugal compressors to provide the charged air at very lower mass flow rates. However, at low mass flow rates, the operation and application of centrifugal compressors for a given turbocharger is limited by the fluid dynamic instabilities. These flow instabilities cause the compressor to enter the state of stall and/or surge. Stall defines the lower limit of stable operating range for the compression system. The suppression of this flow instability is a key research focus of turbomachinery aerodynamics. In this thesis, an attempt has been made to reduce the compressor instability and subsequently increase the surge margin by the application of engineered roughness on different compressor parts. The analysis has been split into two parts. Firstly, CFD analysis have been carried out on several test cases to validate the reliability of the commercial solver. The comparison of the CFD results with the available reference data shows a reasonable agreement in terms of prediction of laminar to turbulent transition location and influence of wall roughness on transition onset location. Secondly, a detailed CFD analysis of the centrifugal compressor has been made in two phases. In the first phase, the overall compressor performance has been simulated from stall to choke over a specific turbocharger rotational speed. In the second phase, a parametric roughness study has been carried out by considering the effects of predefined wall roughness and localized roughness strips on the unstable flow in the compressor at low mass flow rates. For the wall roughness evaluation, the roughness has been applied on the impeller blades, impeller shroud, diffuser and inlet shroud. On the other hand, for the localized roughness strips, roughness have been defined at specific locations at the main blade suction side and the diffuser shroud. The analysis reveals a reduction in flow instability in the compressor domain. The steady state simulations show a significant improvement in the flow structure of the diffuser in terms of the reduction in flow reversal. Furthermore, an improvement in the impeller is observed by reduction in the low momentum wake region.","CFD; Centrifugal Compressors; Performance Optimization; Surface Roughness","en","master thesis","","","","","","","","2016-01-14","Mechanical, Maritime and Materials Engineering","Process and Energy Technology","","","",""
"uuid:822c3df1-5fc4-48d9-b8da-cfd7c3def601","http://resolver.tudelft.nl/uuid:822c3df1-5fc4-48d9-b8da-cfd7c3def601","Electromagnetic & Seismoelectric sensitivity analysis using resolution functions","Maas, P.J.","Grobbe, N. (mentor); Slob, E.C. (mentor); Mulder, W. (mentor); Wapenaar, C.P.A. (mentor); Hruska, M. (mentor)","2014","In the field of exploration geophysics various methods are applied to determine the physical properties of the subsurface of the Earth. Some of the methods most widely used are seismic and electromagnetic surveys, which are each used according to the type of information that is being sought and their ability to provide that information. The method of seismoelectrics is in that regard a promising technique because theoretically it should be sensitive to a wide range of subsurface parameters, spanning both the acoustic and the electromagnetic methods. We aim to perform a parameter sensitivity analysis for the seismoelectric problem, investigating how perturbations in different parameters affect the data and how well these perturbations can be inverted for. We will first study some elements of inverse theory with a special focus on how to construct resolution functions from the basic integral equation of scattering theory. This integral equation can be derived using both superposition and reciprocity principles. This will be shown for both the electromagnetic and the acoustic case, before moving on to the seismoelectric case; it will become clear that the latter poses additional challenges. In addition, the results for the electromagnetic case can be compared directly with the results obtained by [Slob and Mulder, 2011] who performed an electromagnetic parameter sensitivity analysis. The results of this comparison could serve as a validation of the seismoelectric forward modelling code ESSEMOD [Grobbe and Slob, 2013], which will be used to generate synthetic data for this thesis. It is concluded that the superposition principle and the reciprocity theorem provide identical expressions for a scattered field. This conclusion was the basis for deriving the complete reciprocity theorem for the seismoelectric system, which was in turn used to derive resolution functions for a perturbation in bulk density and a perturbation in the seismoelectric coupling coefficient. For the electromagnetic case, we show that the resolution functions computed, using explicit analytical Green's function solutions are identical to resolution functions computed with data produced by ESSEMOD and that this indeed serves as a validation of ESSEMOD. Using the same approach, we have successfully computed a resolution function for inversion for the coupled seismoelectric system for a perturbation in bulk density. It is recommended that this innovative result is used as the basis for the analysis of the seismoelectric sensitivity to more complex parameter-contrasts, which could serve as an assessment of the true potential of the seismoelectric method.","seismoelectric; electromagnetic; resolution-function; sensitivity","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience and Remote Sensing","","IDEA League Joint Master's in Applied Geophysics","",""
"uuid:5cf09033-4da3-420b-8ae3-ac3f3a02cd84","http://resolver.tudelft.nl/uuid:5cf09033-4da3-420b-8ae3-ac3f3a02cd84","Surface-cell interactions: Can PEO topography outsmart surface calcium?","Fernando, J.D.L.","Dankelman, J. (mentor); Fratila-Apachitei, L. (mentor)","2014","Titanium surfaces modified by plasma electrolytic oxidation (PEO) have attractive physico-chemical characteristics that may favor osseointegration of bone implants. This study aimed at delineating the effects of PEO topography and surface calcium on the in vitro pre-osteoblasts response. Two different surfaces were generated by varying the oxidation time of Ti6Al7Nb alloy from 1 minute (PEO-3Ca) to 5 minutes (PEO-9Ca) in a calcium phosphate based electrolyte. These surfaces were compared to another surface without calcium (PEO-0Ca) yet with controlled topography produced by oxidation of Ti6Al7Nb alloy in a phosphorous based electrolyte. The in vitro response of pre-osteoblasts (SV-HFO) on these surfaces clearly indicated that surface calcium is not the main player in influencing cells behaviour as the growth, differentiation and mineralization of pre-osteoblasts were not affected on surface without calcium (PEO-0Ca). Furthermore, at initial stages the pre-osteoblasts response to surface without calcium was even enhanced than on the surface that had high calcium (PEO-9Ca). These findings show that surface calcium is not the key factor in promoting cells response and suggests that PEO topography can be a strong surface cue for modulating cells response.","Ti6Al7Nb; SV-HFO; growth; differentiation; mineralization","en","master thesis","","","","","","","","2017-08-21","Mechanical, Maritime and Materials Engineering","BioMechanical Engineering","","BME","",""
"uuid:aef95685-15b6-4835-b445-2a12ab2e21a3","http://resolver.tudelft.nl/uuid:aef95685-15b6-4835-b445-2a12ab2e21a3","Jacobi polynomen en representaties van SU(2)","Al Mahmoedi, H.","Groenevelt, W.G.M. (mentor)","2014","In deze scriptie beginnen we met het opbouwen van wat algemene Lie-theorie. Om dat te doen leggen we eerst uit wat variëteiten zijn. Ook zullen we enkele eigenschappen van matrix Lie groepen en Lie algebra's bestuderen. Daarna definiëren we Jacobi polynomen door middel van hypergeometrische reeksen. Ook zullen we een aantal eigenschappen van Jacobi polynomen, op een analytische manier, afleiden. In hoofdstuk 4 introduceren we representatietheorie. We zullen laten zien hoe Jacobi polynomen terug zijn te vinden in de representaties van SU(2). Ook bekijken we wat het verband is tussen SU(2) en Schurs orthogonaliteitsrelaties. Vervolgens bekijken we hoe representatietheorie van SU(2) binnen de Lie-theorie past en zullen daarmee enkele eigenschappen voor Jacobi polynomen afleiden.","Jacobi polynomen; representaties van SU(2)","nl","bachelor thesis","","","","","","","","2014-08-26","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","Industrial and Applied Mathematics","",""
"uuid:5025bea2-708c-415d-ae4a-97a0bd05f75a","http://resolver.tudelft.nl/uuid:5025bea2-708c-415d-ae4a-97a0bd05f75a","Design of a flood proof storage tank","Pawirokromo, J.S.W.","Jonkman, S.N. (mentor); Molenaar, W.F. (mentor); Abspoel, R. (mentor); Mooyaart, L.F. (mentor)","2014","Some storage tank terminals located in hurricane prone regions were heavily struck by hurricanes. An example is the storage tank terminal of Stolthaven Terminals (Stolt-Nielsen Limited) which is located in New-Orleans and was severely struck by Hurricane Katrina and Isaac. Damage to the terminal was caused by high wind pressures, but mainly due to flooding of the terminal caused by the overflowing levee. The storage tanks did not possess sufficient weight to counterbalance the buoyancy load generated by the flood. Due to this, storage tanks were lifted off their foundation and damage occurred to the bottom plate and the connections. Chemical liquid stored in the tank had now found its way into the environment. This disaster resulted in high costs and insurance claims from the contamination. The problem can be formulated as: ""How can storage tank damage and chemical spill best be prevented during a flood?"" Alternative solutions for a flood proof storage tank are presented which are applicable to the still-to-be-built new terminal next to the present terminal. Also a combination of the flood proof tank and management of tank operations is considered. 3 of the alternatives seem structurally feasible and are further elaborated in the report. These are: 1. The use of a steel-concrete-steel sandwich slab (SCS slab) inside the tank. This consists of 2 steel plates connected to a concrete core by means of shear studs. The slab should have sufficient weight to counteract the buoyancy load. [Tank alternative A] 2. Anchoring the area of the bottom plate of the tank to the concrete foundation by means of shear studs. [Tank alternative B] 3. Constructing a floating tank. This tank is provided with guiding piles, which allows the tank to go up and down, but keeps the tank at one location. [Tank alternative C] A simplified cost-benefit-analysis (CBA) is done to compare the alternatives to one of the basic solutions like the floodwall. The flood proof storage tank is compared to the basic solution (like the flood wall) a flexible alternative, because the tank does not need to be protected against floods.","storage tanks; flood; hurricane; damage; chemical spill","en","master thesis","","","","","","","","2015-08-21","Civil Engineering and Geosciences","Structural Engineering","","Hydraulic Structures","",""
"uuid:dd6c46f5-8bb2-4b42-b4b9-770ec544dfc7","http://resolver.tudelft.nl/uuid:dd6c46f5-8bb2-4b42-b4b9-770ec544dfc7","Modelling the spectral gamma-ray log: The influence of provenance and selective transport","Van der Boor, M.C.","Weltje, G.J. (mentor); Bloemsma, M.R. (mentor)","2014","In clastic rock, the interpretation of facies from the spectral gamma-ray log should be applied with caution because a consistent relationship with gamma-ray is lacking due to variations in provenance and/or diagenesis. In this thesis the use of the gamma-ray log for the derivation of source rock characteristics and/or diagenesis is examined. This is done by reconstructing part of the history of the sedimentary rock by modelling or minimizing the variance caused by selective transport in the gamma-ray signal and interpreting the residual signal. Two di?erent approaches were studied. In the ?rst approach a model was suggested which simulates the selective transport process. The composition of sediment subject to selective sorting is modelled as a compositional linear trend where the proportion of minerals increase or decrease as function of the settling velocity of the grains. Diagenesis and mixing of sediment sources is neglected in this model. With the forward model characteristics re?ecting the parent lithology such as composition and radio-nuclide concentration can be used to simulate a gamma-ray signature. Iterative forward modelling was used in an attempt to derive provenance characteristics from the gamma-ray signatures. The performance of the model was tested on synthetic and real gamma-ray signatures. With the iterative forward model an excellent ?t with the well log gamma-ray was found however, the resulting radio-nuclide concentrations show an unrealistic large variation. Two conclusions were drawn based on these outcomes, ?rst the model is very sensitive to the noise present in gamma-ray logs and secondly not enough constraints are available to produce realistic results from the model. The second approach is based on simplifying assumption concerning selective transport. It is assumed sediment within a su?ciently small grain-size class is deposited under similar hydraulic conditions and therefore has a comparable (chemical) composition if there are no variation in provenance or diagenesis. If this is the case, the gamma-ray log can be reconstructed from a grain size record if we take into account the variation caused by the averaging e?ect of the detector. The detectors response was approximated based on attenuation e?ects in the formation and allows us to degrade the high resolution gamma-ray log derived from the grain size record to a resolution matching the well log gamma-ray. Application to carboniferous core E10-3 resulted in a good ?t and realistic gamma-ray signatures for the grain size classes. Thorium showed the highest dependency with grain size, potassium and uranium show a comparable and less pronounced correlation. In case of core E10-3 the residual variance is expected to be mainly caused by diagenesis (formation of kaolinite), degree of sorting and organic content and it was concluded that in this case the residual signal is hard to interpret. The model was also applied to the point bar deposits of the Huesca dataset. Again the thorium content showed the highest dependency with grain size, the uranium content showed less strong correlation and no clear relationship of the grain size record with the potassium content was found. Individual processing of the point bar deposits clearly showed an increased potassium content in the point bar at the depth interval 57m - 61m. Several plausible explanations can be posed for the increased potassium content, for example the potas- sium content could be present as a solution in the pore structure, higher proportion of K-feldspar or increased radio-activity of the potassium bearing minerals.","gamma-ray logging; provenance analysis; compositional data analysis","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Petroleum Engineering","",""
"uuid:328250df-6038-4582-97d8-e7ba743e0761","http://resolver.tudelft.nl/uuid:328250df-6038-4582-97d8-e7ba743e0761","Modelling sediment sorting near the large scale nourishment 'The Sand Motor': Understanding cause and impact of sediment sorting processes","Van der Zwaag, J.","Stive, M.J.F. (mentor); Huisman, B.J.A. (mentor); Luijendijk, A.J.L. (mentor); Van Prooijen, B.C. (mentor)","2014","The sediment composition of the sea bed is of relevance for various coastal properties such as bed forms, beach slopes and marine ecology. Furthermore it may significantly influence the morphological evolution of the coast. Knowledge about the processes forcing the spatial distribution of a certain grain size is therefore of great importance. Examining these processes requires good quality data sets of bed sediment composition with high temporal and spatial coverage and for many research questions the aid of numerical modelling. However, these aspects have been lacking in many studies and need additional research This research investigates the sorting of sediment at a a large coastline disturbance: the Sand Motor. For this purpose (1) five field campaigns are analysed to examine the evolution of the bed composition near the Sand Motor, (2) the existing Delft3D 2DH hindcast model of the Sand Motor is extended with five sediment fractions to hindcast the sediment sorting with respect to the data and (3) single processes are assessed with a 3D extension of the 2DH model, to be able to account for undertow processes. The hindcast of the sediment composition proved that Delft3D is well capable of hindcasting characteristics such as fining and coarsening of areas: the Brier skill score increased from 0 to a value of about 0.45. However, precise values of the sediment composition appeared to be inaccurate, as an average error of approx. 50 mu and local errors up to 180 mu between field- and model data remained. In addition, alongshore gradients were underestimated with respect to the field data. It is noted that quite a bit of the mentioned errors may be related to small shifts in the predicted and measured spatial distribution (double penalty effect). Model results including maximum gradients, the size of fine patches and the location of the minimum/maximum D50 showed that storm events cause rapid coarsening of the swash zone, while forcing finer sediments both offshore and towards less energetic areas located north and south of the Sand Motor. Furthermore, a spatial pattern of the bed sediment distribution will develop. The time scale of this distribution differs per processes and per location: from an almost instant response (O(day)) at the swash zone to a period of weeks for the offshore tidal influence. The spatial characteristics appeared to be in a dynamic equilibrium after a few storm events: only more severe hydrodynamic conditions than before, or from a non-westerly (e.g. non-dominant) direction could cause major shifts in the spatial distribution. Since the mentioned features are persistent in space and time, a coupling between the spatial distribution of grain sizes and the morphological active zone is possible, enabling an estimate of the morphological characteristics with a single spatial D50 measurement. The modelling consequences of applying a multifraction model compared to a single fraction model include a significantly faster morphological response: eroded volumes were 1.8 times that of the data and 2.4 times that of the single fraction model. Scaling of the cumulative erosion curve with the mentioned factor 1.8 provides a perfect fit on the data, indicating that the relative impact of conditions in time is in agreement with measured bathymetry changes. Beach profiles in the multifraction model steepened between 8 and 4 meters depth, while becoming slightly more gentle between at depths between 4 and 0 meter. Although including sediment fractions is theoretically closer to reality, it also includes more assumptions. In general it will depend on the aim of the applied model, required data and available time if modelling with a multifraction sediment composition is beneficial.","Sand Motor; Sediment Sorting; Delft3D; Morphology; Coastal Engineering","en","master thesis","","","","","","","","2015-02-21","Civil Engineering and Geosciences","Hydraulic Engineering","","","","52.052285, 4.184252"
"uuid:727ec48a-1598-4cd5-91dc-0c86814abc71","http://resolver.tudelft.nl/uuid:727ec48a-1598-4cd5-91dc-0c86814abc71","Performance improvement of motion control applications using GPPs and ASIPs on FPGA","Jambekar, S.W.","Al-Ars, Z. (mentor)","2014","ASML is a world leading supplier of complex lithography machines for the semiconductor industry. A lithography machine consists of many subsystems, e.g., Light Source, Lens, Reticle handler, Reticle stage, Wafer handler and Wafer stage, which synchronize together to make the machine work. The Reticle stage holds the circuit pattern, also known as reticle and the Wafer stage module holds the wafer. The UV light from the light source is projected on the circuit pattern, which is then passed through the lens to imprint the pattern on the wafer. Since the circuit pattern has to be imprinted on the wafer, the movement of the modules; Reticle stage and Wafer stage should be synchronized in six degrees of freedom (DoF) with nanometer accuracy. To employ the movement of the subsystems, motion controllers are used in ASML, and Long Stroke and Short Stroke controllers are responsible for the movement of a part of the Wafer stage subsystem. It has been envisioned that future lithography machines, because of its high precision mechatronic requirements, will need motion control algorithms, that run at higher sampling frequencies with a severely reduced IO latency budget. Current hardware architectures will not be able to meet the demands of these future motion control algorithms. In this thesis, we propose an architecture, that uses a multi-ASIP in FPGA as an accelerator in conjunction with a CPU, which acts as a master to run the motion control applications. The proposal of using multi-ASIP FPGA in conjunction with CPU is based on the analysis carried out previously in ASML. It was observed that a sampling frequency exceeding 100 KHz can be obtained after deploying the Long Stroke controller and Short Stroke controller on a multi-ASIP platform in FPGA. However, this work considered only the data flow and not the supervisory control. After carrying out detailed analysis, we could predict that a sampling frequency of 40 KHz could be achieved by offloading the compute intensive blocks present in the Long Stroke and Short Stroke controller from the CPU to FPGA. The sampling frequency of 40 KHz can be achieved by considering, both the data flow and supervisory control, and the communication between the CPU and FPGA. Finally, after offloading the compute intensive blocks from the CPU on the multi-ASIP FPGA, and after implementing the data flow and supervisory control and communication mechanism between the CPU and FPGA, we can justify that the sampling frequency of 40 KHz can be achieved.","","en","master thesis","","","","","","","","2015-08-21","Electrical Engineering, Mathematics and Computer Science","Computer Engineering","","","",""
"uuid:82d41245-bad6-4e98-a4af-0335c4f78c8f","http://resolver.tudelft.nl/uuid:82d41245-bad6-4e98-a4af-0335c4f78c8f","Integrated re-design of a clinical hyperthermia head and neck applicator, HYPERcollar","Bi, D.","Hajian, M. (mentor); Goossens, H.M. (mentor)","2014","This project is for Erasmus MC-Daniel den Hoed Cancer Center about a clinical hyperthermia head and neck applicator, HYPERcollar. The main focus of this project is solve the problem of treatment extension to realize the possibility of treatment at the neck area of the patients. After research, analysis and conceptualization phase, a final design was made and evaluated through user tests. The exploration and designing process as well as the outcomes are introduced in this thesis.","Medisign; cancer treatment; HYPERcollar; treatment extention","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Integrated Product Design","","","",""
"uuid:743fb1d4-350a-410d-9053-414ab7fafbef","http://resolver.tudelft.nl/uuid:743fb1d4-350a-410d-9053-414ab7fafbef","Use of Modified Hydrotalcites (MHTs) as a New Type of Smart Additive of Reinforced Concrete for Improved Corrosion Protection: An Electrochemical Performance Assessment in Simulated Concrete Pore Solution","Mao, M.","Mol, J.M.C. (mentor); Yang, Z. (mentor)","2014","MHTs (MHT-p, MHT-N) represented superior corrosion inhibition effect against chloride induced pitting corrosion in simulated concrete pore solution when compared with the pure inhibitors (pAB, NaNO2). Among them, MHT-p exhibited a better improvement of inhibition effect than MHT-N. This result is probably caused by the bigger ion exchange capacity between pAB ion and chloride ion in MHT-p. MHT-p was almost as effective as NaNO2.","MHT; Modified hydrotalcites; corrosion","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Materials Science & Engineering","","electrochemical and corrosion","",""
"uuid:68c13b85-9dfe-42e0-bb9f-7982d0a1a108","http://resolver.tudelft.nl/uuid:68c13b85-9dfe-42e0-bb9f-7982d0a1a108","Descent, Touchdown and Repositioning of a hopping planetary lander on Enceladus","Holtkamp, G.C.","Mooij, E. (mentor)","2014","This report deals with the design of a complete guidance, navigation and control system for a planetary lander on Enceladus, for both descent and repositioning. A basic lander model with a main engine, attitude thrusters and a landing gear is presented, for which the equations of motion in different reference frames are derived, including the effects of third body perturbations and non-homogeneous gravity fields. The guidance system incorporates a gravity-turn guidance logic for a flat and a spherical moon model for the initial descent phase, a quadratic guidance logic for both pinpoint landing and repositioning, a velocity nullifying logic for the terminal guidance phase and a ballistic guidance logic for a more fuel-efficient repositioning. The control system consists of a linear quaternion controller combined with a pulse-width-pulse-frequency modulator. The navigation system is build around an Inertial Measurement Unit with an extended Kalman filter to fuse the attitude and position measurements. The on-board software incorporates a basic hazard avoidance system, which uses a simulated LIDAR scan of the target area to generate a hazard map. The retargeting is based on a reachability and fuel consumption analysis. The spacecraft is capable of fully autonomous landings. This guidance, navigation and control system is combined in a simulation software written in C++ to test the system performance in presence of various error sources. All program elements have been tested with results from literature. The Monte Carlo simulations of the full GNC system include variances of the lander's state vector and of the GNC configuration parameters. The success rate is 90% for the descent phase, and 98% for the repositioning phase. The mean landing precision is in the order of 1m, with velocity and pointing errors of 0.2 m/s and 1.4°, respectively. Stricter requirements on the lander's mass distribution, and the implementation of a feedback velocity nullifying guidance scheme can increase the mission success rate even further. The thesis work shows, that a landing mission to Enceladus is possible with current technology. The Enceladus Lander Simulator is comprehensive software package for descent and repositioning simulations, and its modularity allows extensions in the future.","guidance; navigation; control; repositioning; lander; hazard avoidance; GNC; enceladus; touchdown; descent; simulator","en","master thesis","","","","","","","","","Aerospace Engineering","Earth Observation and Space Systems","","Astrodynamics and Space Missions","",""
"uuid:06c25338-de69-4dc2-b8e4-c9e32423361a","http://resolver.tudelft.nl/uuid:06c25338-de69-4dc2-b8e4-c9e32423361a","Bed level changes in the Waal during floods","Van Denderen, R.P.","Uijttewaal, W.S.J. (mentor); Blom, A. (mentor); Giri, S. (mentor); Sieben, A. (mentor); Stecca, S. (mentor)","2014","Bed level changes during a flood can have large influence on the safety against flooding and the navigational function of a river. In 1997 measurements were carried out in the Waal during a flood. These measurements present an average decrease of the bed level in the order of 10 cm over a 10 km reach which is much larger than expected from the current morphological models. Two reasons for this bed level decrease are suggested: the unsteady sediment load and the influence of a measuring error. The goal of this thesis is to find the main processes which affect the average bed level during floods in rivers like the Waal. The maximum influence of the unsteady sediment load is estimated using multiple empirical relations for the bed load transport, the bed particle velocity and the suspended load transport. The analysis shows that the maximum change of the sediment load can cause a bed level change in the order of 0.7 mm during the 1997 flood in the Waal. Therefore it is concluded that the influence of unsteady sediment load is too small to significantly affect the bed level and to explain a 10 cm decrease of the bed level. The bed level measurements in the Waal during the 1997 flood were carried out with a single-beam echosounder. This means that the water depth is measured and that the water level is used to estimate the bed level. During the 1997 flood the water level was based on a linear interpolation between station Dodewaard, which is in the upstream part of the measuring reach, and measuring station TielWaal, which is downstream of the reach. In addition, the water level at station Dodewaard was not measured but estimated based on a regression relation. Both the linear interpolation and the regression relation are a source of inaccuracies. Therefore these water levels are compared to WAQUA-results for the 1997 flood and water level measurements during the 2011 flood. From this comparison is concluded that a combination of both sources of inaccuracies can be responsible for an average bed level decrease of 10 cm. The incorrect estimation of the water level is therefore assumed to be the main contributor to the large-scale bed level decrease during the 1997 flood in the Waal. The WAQUA-result of the 1997 flood is used to correct the bed level. The corrected measurements are compared with results from a Delft3D model. The model shows similar trends to the measured bed level but the quantitative differences are large. These large differences could be caused by the inaccuracies in the measurements or by the assumptions made in the Delft3D model. The model and the measurements show that the spatial variation of the river geometry has the largest influence on the bed level changes during floods. As a reference case the bed level changes at the Pannerdensche Kop during the 1997 and the 1998 flood are studied. During neither of the floods the measured bed level shows a large-scale bed level change. However, local bed level variations are large and are caused by spatial variations of the river width. Therefore the bed level measurements at the Pannerdensche Kop confirm that the spatial variation of the river geometry has a large influence on the bed level changes during a flood. The main process which affects the average bed level in the Waal is the river geometry. The bed level measurements and the model result show that a spatial variation of the river width has a large effect on the bed level during a flood. A new bed level measuring campaign has to be carried out to be able to validate the morphological models during floods. The current measuring techniques and measuring guidelines make it possible to capture the bed level changes during a flood in the Waal more accurately.","Waal; flood; bed level changes; single-beam echosounder; 1997 flood; 1998 flood","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Hydraulic Engineering","","","",""
"uuid:97c605ab-6dcb-40ef-90ff-f4921e85a403","http://resolver.tudelft.nl/uuid:97c605ab-6dcb-40ef-90ff-f4921e85a403","Universal aspects of small-scale motions in non-equilibrium turbulent channel flow","Arbelaez, D.","Elsinga, G.E. (mentor)","2014","Direct numerical simulations of transient turbulent channel flow were conducted in order to study and characterize the large-small scale interaction in this type of flows. This was achieved by analyzing some well-known universal aspects of turbulence. Additionally, the so called strain-rate-eigenframe analysis was applied to study the local flow topology during the transient conditions of the flow evolution.","DNS; turbulent channel flow; large-small scale interaction; non-equilibrium flows","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Process and Energy","","Solid and Fluid Mechanics","",""
"uuid:a1c859ab-41f5-4ee4-93fe-6c5bdafdd0a4","http://resolver.tudelft.nl/uuid:a1c859ab-41f5-4ee4-93fe-6c5bdafdd0a4","De ongelijkheid van Khintchine / The Khintchine inequality","Amersfoort, M.P.","Veraar, M.C. (mentor)","2014","First, the Khintchine inequality and several proofs of it will be investigated, then the proof for the best constants on the Khintchine equality by Uffe Haagerup, after which a study is done on generalisatioens of the Khintchine equality and new optimal constants are found.","Khintchine","nl","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","","",""
"uuid:73bd40eb-4d01-4973-b052-06d775b07985","http://resolver.tudelft.nl/uuid:73bd40eb-4d01-4973-b052-06d775b07985","In Search of Strategic Capacity: An evaluation of the effectiveness of collaborative spatial planning in the southern Randstad as reflected by the performance of the Adaptive Agenda Southern Randstad 2040","Harteveld, E.","Zonneveld, W.A.M. (mentor); Waterhout, B. (mentor); Broekhans, B. (mentor); Van den Beuken, F.T. (mentor)","2014","In the face of geographic, social and economic dynamics, Dutch spatial planning has underwent a significant change from prescriptive and regulatory top down planning to collaborative spatial planning (CSP) in networks of like-minded governments. Such CSP initiatives, or regional collaborations, seek to align their efforts to steer regional development to their joint benefit. The CSP effort is one of defining common ambitions across different tiers of government and integrating policy fields and territories. In the last few years, regional collaborations between different tiers of government and even external parties have emerged as the contemporary spatial planning practice. The changes in spatial planning practice have made old roles of government obsolete and responsibilities have shifted. Numerous regional collaborations, all attempting to find the right organization, size and scope, have popped up across the Netherlands. However, best practices have not yet been identified. The evaluation of the effectiveness of regional collaborations is key in developing a frame of reference for best practices for the institutional arrangements within regional collaborations. However, an appropriate evaluation framework is not yet available. This thesis offers a comprehensive framework for the evaluation of regional collaborations which is then used to evaluate a CSP initiate in the southern Randstad, namely the regional collaboration between the national government and the Zuidvleugel partners.","planning evaluation; collaborative spatial planning; network governance; strategic capacity; southern Randstad","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","OTB Research Institute for the Built Environment","","Urban and Regional Development","",""
"uuid:80a8b10e-5eb5-4c8c-b3c7-cbc041b39f27","http://resolver.tudelft.nl/uuid:80a8b10e-5eb5-4c8c-b3c7-cbc041b39f27","Evolution of beach extensions: Numerical modelling of large scale nourishments using UNIBEST & Delft3D","Stam, G.N.","Stive, M.J.F. (mentor); Tonnon, P.K. (mentor); Huisman, B.J.A. (mentor); Luijendijk, A.P. (mentor); De Boer, G.J. (mentor)","2014","Recently, nourishments have been carried out on a large scale to counteract the on-going erosion along the Dutch Coast. The main advantage of these large beach extensions is that large stretches of coastline are protected for a long time scale (e.g. 20 years), which decreases the frequency of nourishing significantly. This is not only cost effective, but also positive for preserving local ecology. In this research two types of large scale nourishments can be distinguished: The ‘permanent type’ which is applied locally and has the form of a land reclamation which needs to be maintained in time (Hondsbossche Sea Defence). The other one being the ‘temporary type’, which is expected to diffuse along the coast in order to strengthen a larger stretch of coastline (Sand Motor). One of the most challenging issues in the design of large scale nourishments is estimating the erosion rates in time and consequently the lifespan of such nourishments. This is relevant because it can lead to a more efficient design or provides more control over maintenance. The problem definition reads: “Currently it is not known how the erosion rates of large scale nourishments are related to their size, shape and sediment characteristics”. The final research goal is to develop design graphs for the erosion rates and lifespans of beach extensions at the Dutch coast. For this research use has been made of two numerical models; the equilibrium based UNIBEST model and the process based Delft3D model. Various nourishments are implemented in both models in which variations are made in the seaward extent (=width of nourishment), L/W ratio and the net annual alongshore transport (indicates the wave climate’ intensity in this research). Both models are validated by using measurements at the Sand Motor. The main conclusion of this research is that the wave-induced alongshore transport is considered the most important driving force for the diffusion of nourishments. Tidal forcing does also play a role but the effect on the alongshore transport is a factor 10 less compared to the sediment transports for waves and tide combined. This conclusion is reinforced by the large resemblance between the model results of Delft3D (wave + tidal forcing) and UNIBEST (tide only). From using UNIBEST in combination with a time series wave climate (2 years) applied at the Sand Motor, it can be concluded that the sediment loss at large scale nourishments is event driven (i.e. storm events) just as can be observed in reality. The time series wave climate provides a near perfect fit of model results on measurement with respect to volume decrease in time. This research shows that the dynamic boundary within UNIBEST has a very large effect on the alongshore sediment transports. The dynamic boundary defines which part of the coast rotates in the same way as the coastline and can therefore have a significant effect of refraction. By using the Delft3D offshore wave climate while keeping the dynamic boundary close to shore, similar results can be obtained with UNIBEST as with Delft3D. Because of the presence of a dynamic boundary UNIBEST can be considered a more advanced coastline model. Furthermore, it can be concluded that when the alongshore length is increased, the erosion rates in the first years remain approximately the same. Extending a nourishment in alongshore direction simply protects an additional stretch of coast equal to the length of the additional nourishment length itself. The amount of seaward extent appears to have much more influence. The erosion rates rapidly increase when the nourishment is extended further into sea. With the UNIBEST results the half-life (amount of time it takes for the nourishment to reduce to 50% of its initial volume) is compared to the initial volume of each nourishment. The relation seems to be very linear in which each L/W ratio shows a different slope.","large scale nourishments; erosion rates; beach extensions; lifespan; UNIBEST; Delft3D; Sand Motor","en","master thesis","","","","","","","","2015-02-12","Civil Engineering and Geosciences","Hydraulic Engineering","","Coastal Engineering","",""
"uuid:9a62de93-4b92-4076-90be-bd4789e5d9be","http://resolver.tudelft.nl/uuid:9a62de93-4b92-4076-90be-bd4789e5d9be","Strategy for senz° to become a lifestyle brand","Nieto Toro, K.D.P.","van den Hende, E.A. (mentor); Hultink, H.J. (mentor)","2014","Currently, senz° is directed linked with wind-proof umbrellas in the customers’ mind. Therefore, there is a need to change the image of senz° from a product focused company to a lifestyle brand, using the laptop sleeve launch and its market positioning as a case study. However, it was needed to optimize the product first since it is not finished yet. On the other hand, based on a previous research potential customers see the laptop sleeve as a “cool” product when someone wears it, however they do not see themselves using it yet. This means that there is still a boundary to be crossed unlike the umbrella which is in its mainstream market. Therefore it is highly important to design a communication strategy that clearly shows the added value of the product aligned with the communication of the brand, in order to assuage customers´ doubt involved in product adoption. This project addressesed the problem that senz° is facing right now, from two different angles. First, the need of a roadmap strategy for the company aligned with its new vision to become a lifestyle brand, considering a laptop sleeve as starting point. Second, the need of a strategy to create an emotional attachment to the brand, products and customer, by exploring the role of social media. This research showed that the most logical step to become a lifestyle brand would be to turn into an iconic brand and then a lifestyle brand Positioning the brand within the context of commuting by using the 2 steps proposed here, will create value for senzº in four ways mainly as Aaker & Keller (2012) would argue. First, it will provide extension options for senzº in the future and therefore it will increase its leverage potential. Therefore senzº will be able to launch new accesories for commuters without harming the core brand. Second, it will improve brand memorability since a coherent brand identity and position will be easier to remember than the current personality of senzº brand. Hence it is very important to be consist across different touchpoints of the brand. Due the variety of channels in which the customer will have contact with the brand, senzº will come to customers minds first than the brands that have fewer touchpoints. Third, it will provide meaning and focus to the company. When the brand strategy is clear, all senzº employees will know how to align their actions in terms of a central strategy. Moreover, a strong brand identity and position could also create a sense of pride that motivates employees and even suppliers, far beyond short-term financial performance goals. Finally, future senzº products, including the laptop sleeve will use the brand as a competitive advantage that creates a high entry barrier for competitors. Therefore, the brand equity will most likely increase. As a result, a strong brand asset will be the basis of a business with a real competitive advantage. The core of the iconic brand will be to develop a vision of the ultimate identity that the brand will possess, and the product lines that the brand will support. On the other hand, community affiliation is changed from a pasive role to an active role (Fournier & Lee, 2009). This means that the content that is on senzº social media channels is not just created by the brand itself and hopefully seen by customers, but is co-created between customers and the brand instead. As a result, brand awareness will be created and at the same time customers will engage on emotional levels with senzº since they will own the content by being the storytellers themselves. This is certainly a starting point of creating a community around the brand which it becomes a value driver in the third year of the roadmap in order to become an iconic brand.","Roadmap strategy; Storytelling; Communication strategy; Lifestyle brand","en","master thesis","","","","","","","Campus only","2015-08-20","Industrial Design Engineering","Strategic Product Design","","Strategic Product Design","",""
"uuid:bb86f4e7-267c-4971-86a9-e56fc5f94f81","http://resolver.tudelft.nl/uuid:bb86f4e7-267c-4971-86a9-e56fc5f94f81","Design of a Simulation Platform to Support Operation Decisions in a Petrochemical Network","Rognvaldsson, H.H.","Rueda, J.L. (mentor)","2014","This master’s thesis project is considered to be a starting point for further research in the field of intelligent electrical power grids with the main goal to increase the reliability in real-time operations of electrical power systems. The increased reliability will consequently increase the confident level of electrical power system operators when they have to make switching actions. Suggestions will be made on how to structure the communication design of a real-time assessment platform for the operators. One step to increase the intelligence of such system is to link it with a typical power system calculation tool in order for the operator to make a real-time simulation of power flow in the network before a switching sequence is made on the live network. Therefore, the prospective consequences of switching actions can be observed beforehand that in result can avoid inadvertent outages of the plant and also, protect equipment and personnel. First, an introduction will be made to the world of power system automation where various aspects will be examined, such as different electrical power systems, overview of various industrial control systems along with their most common processing instrumentation and control devices, followed by an overview of communication protocols and substation’s architecture in power systems. The overview will be concluded with the prospective future trend of these control systems and communication devices. Next, a study case will be introduced where an overview of a single-line diagram of a real world engineering petrochemical electrical network is covered along with several block diagrams of a communication architecture of an Electrical Network Monitoring and Control System (ENMCS). Also, the main functionalities of power system simulation tool is covered where the main focus will be on the power flow analysis. Finally, the communication design of the real-time assessment platform will be introduced and analyzed, together with the major technological challenges for the design. The main goal of the thesis is to increase the reliability of a petrochemical network by increasing the situational awareness and monitoring level of electrical power system operators.","","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Electrical Sustainable Energy - Intelligent Electrical Power Gr","","Electrical Power Engineering","",""
"uuid:d4e21d44-fcef-498b-b2e5-83df3b0e0c47","http://resolver.tudelft.nl/uuid:d4e21d44-fcef-498b-b2e5-83df3b0e0c47","Modelling sediment transport and morphology during overwash and breaching events","De Vet, P.L.M.","Stive, M.J.F. (mentor); Den Bieman, J.P. (mentor); McCall, R.T. (mentor); Talmon, A.M. (mentor); Visser, P.J. (mentor); Yuan, J. (mentor)","2014","Currently, morphodynamic models as XBeach show substantial overestimations of the erosion rates during breaching and overwash events at barrier islands. The presently used limitations on the Shields parameter and the sediment concentration do hinder erosion, but have undesirable side effects, e.g. the breaching process is suppressed. By implementing additional physics, e.g. the erosion hindering effect of dilatancy and a proper bed slope effect, substantial improvements are achieved for idealised cases. However, two hurricane case studies showed that these model improvements do not hinder erosion sufficiently to achieve reasonable results. A proper description of bed roughness, which is preferably depth dependent and accounts for vegetation, together with calibration of the wave skewness and asymmetry is found to be very important. If this knowledge is applied on a newly introduced case study of Fire Island (hurricane Sandy, 2012), both breaching and overwash are modelled much more in line with reality. However, the complexity of having various morphodynamic processes within one model domain makes calibration a challenging task, requiring a more advanced bed roughness formulation.","Breaching; Overwash; Modelling; Fire Island; Hurricane; Sandy; XBeach","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Hydraulic Engineering","","NUS-TUD Double MSc Degree Programme","","40.723521, -72.896395"
"uuid:d0791b9a-aad0-4cf0-8529-574a32c70023","http://resolver.tudelft.nl/uuid:d0791b9a-aad0-4cf0-8529-574a32c70023","Buckling Behavior of Spirally Welded Steel Tubes","Pueppke, N.B.","Gresnigt, A.M. (mentor); Bijlaard, F.S.K. (mentor); Hendriks, M.A.N. (mentor); van Es, S.H.J. (mentor)","2014","This report deals with the buckling behavior of spirally welded steel tubes. First, an existing analytical solution and the results of an extended experimental investigation are investigated. The imperfections measured during testing are investigated and classified, and methods are proposed to incorporate them into finite element models. Buckling analyses are carried out using finite element software, the resulting eigenmodes are characterized, and the response of tubes to various combinations of buckling modes is investigated. Next, the tubes themselves are modeled, incorporating these imperfections, full material models, and residual stresses. The results are compared to the results of the experimental program. Statistical analyses are also performed to investigate the accuracy of the models. Finally, parameter studies are carried out in order to investigate the effect that various parameters have on the response of the tubes, both in terms of critical curvature and maximum moment. The parameters are characterized based on their significance, and recommendations are made for future research.","buckling; shell; tube; pipe","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Structural Mechanics","",""
"uuid:6e75b04c-6cfa-43b6-928b-0f4a8ce4af01","http://resolver.tudelft.nl/uuid:6e75b04c-6cfa-43b6-928b-0f4a8ce4af01","Improving the controllability of the parcel flow for depots at PostNL Parcels by use of real-time forecasting","van Dooijeweert, J.","Beelaerts van Blokland, W.W.A. (mentor); Pruis, A. (mentor)","2014","PostNL Parcels has 18 depots that are being used for the processing of parcels. The parcels are collected during the day. After delivery of the parcels to the depots, the sorting of the parcels takes place during the evening and night. This process is called the send sorting. The processing capacity that is needed during the send sorting at a depot is determined by a forecast of the number of parcels that will be collected that day. PostNL Parcels has a control room that is responsible for the monitoring of the flow of parcels heading towards the depots. When more parcels are collected than the amount that was forecast, the control room has to intervene to solve capacity the problems. Suspected is that there are problems with the monitoring of the amount of parcels entering the send sorting. Therefore capacity problems remain unnoticed during the send sorting. This causes capacity problems during the send sorting to remain unnoticed. As a result parcels remain unsorted. The research question is: How can the monitoring of the parcel flow entering the send sorting be improved? During this research the DMAIC framework is used. After defining the problem area, the problems are measured. After the measurements the found problems can be analyzed. After the analysis solutions can be developed for the found problems. The implementation is out of the scope of this research. A measurement has been done in which three major problems that cause unsorted parcels have been found. Two of these problems are related to the monitoring of the parcel flows. The monitoring has been modelled using the Delft Systems Approach. Using this model root causes for the measured problems were found. The current forecast method was found to be unreliable on depot level. Therefore the control room has to intervene to solve capacity problems. This intervening is done by monitoring the amount of parcels heading towards the depots and comparing this to the forecast amount of parcels. It was found that this comparison was hard to do in practice caused by the way the current forecast is made...","","nl","master thesis","","","","","","","","2019-09-01","Mechanical, Maritime and Materials Engineering","Marine and Transport Technology","","Transport Engineering and Logistics","",""
"uuid:084f2da6-d554-4b51-b605-e10a0f1d1785","http://resolver.tudelft.nl/uuid:084f2da6-d554-4b51-b605-e10a0f1d1785","Experimental Characterization of a Micro-ramp Wake and its Flow Mixing Properties in Supersonic Flow","Srivastava, A. (TU Delft Aerospace Engineering)","van Oudheusden, Bas (mentor); Schrijer, Ferdinand (mentor); Elsinga, Gerrit (mentor); Giepman, Rogier (mentor); Delft University of Technology (degree granting institution)","2014","Micro-ramps are currently being investigated as a means of reducing negative effects of shock wave-turbulent boundary layer interactions. A micro-ramp enhances the mixing of the ow by introducing vortices in the ow, thus energizing the boundary layer to overcome the adverse pressure gradient due to an impinging shock. The effect of changing micro-ramp height, Mach number and Reynolds number on the mean ow downstream of a micro-ramp's center-line has been studied extensively.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering | Aerodynamics and Wind Energy","",""
"uuid:cf7dbdfc-b144-4961-b9ec-795eb4020996","http://resolver.tudelft.nl/uuid:cf7dbdfc-b144-4961-b9ec-795eb4020996","Machine Movement Prediction for Collision Avoidance","Radhakrishnan, V.","Manuel Espinosa, M. (mentor)","2014","Construction sites are among the most dangerous work environments. Worldwide, thousands of workers are injured or killed while working with or around machinery. For Volvo Construction Equipment, safety of the workers is one of the core values. The company strives for the vision of ""Zero accidents with Volvo Group Products "" through high quality and innovative products that reduce the frequency of accidents as well as their consequences. The purpose of this thesis is to provide a solution towards this vision by developing a collision avoidance system for construction machinery. This is achieved by implementing a model based deterministic threat assessment approach in which the movement predictions of the machine is calculated and evaluated to determine the risk of a collision. The important aspect of generalization has also been considered, in which a new combined machine model has been developed which can be utilized to represent the kinematics of three different types of construction machinery. The results obtained from the combined machine model are compared with true machine models. Kalman filters and their extensions used for state/parameter estimation are investigated. A new method is formulated for predicting the states using Extended Kalman filter which has been proved to be better performing than the usual prediction methods. For collision detection, an algorithm based on the separating axis theorem has been developed. The developed system is investigated and validated using real-world data. The final result obtained from the thesis was an accurate threat assessment system performing for both linear and nonlinear trajectories by utilizing only GPS signals as input and also producing real time collision detection measures.","Collision Avoidance; Advance Driver Assistant Systems; Construction Machines; Threat Assessment","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Systems and Control","","","",""
"uuid:0c6b2600-0b34-40fd-a7a5-6869ecf01bb8","http://resolver.tudelft.nl/uuid:0c6b2600-0b34-40fd-a7a5-6869ecf01bb8","Determination of the Optimal Pipe Configuration and Diameters for a District Heating System","Groot, S.","Van Dalen, J. (mentor); Boersma, B.J. (mentor)","2014","In this report a district heating system is analyzed at the Tata steel site. A case study is made for a number of buildings, which are currently heated with a gas boiler. A computer model is developed to calculate the optimal piping path and diameters for such a network. The heat losses of this network are calculated with the complex potential method. The payback period was found to be around 5 years, depending on the economic conditions.","district heating; Tata Steel","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","SPET","","Energy Technology","",""
"uuid:91b5bf03-b009-475f-bd9e-9e16bab86f99","http://resolver.tudelft.nl/uuid:91b5bf03-b009-475f-bd9e-9e16bab86f99","Investigation of inhibition effect of some amino acids against steel corrosion in chloride-containing alkaline solution","Liu, J.","Mol, J.M.C. (mentor); Yang, Z. (mentor)","2014","The corrosion inhibitory effect against reinforced steel corrosion of four amino acids was evaluated comparing with sodium nitrite which is a widely used commercial inhibitor. The experiments were carried out in simulated pore solutions using electrochemical methods as well as optical microscopy. Electrochemical impedance spectroscopy (EIS) was mainly used to screen the resistance of different inhibitor systems to compare the efficiency of their inhibition against chloride-induced corrosion. Moreover, corrosion current density and corrosion rates were also calculated for each inhibitor at different chloride concentrations. Cyclic voltammetry (CVA) was conducted to analyze the corrosion process on the steel surface. Pitting potentials as well as repassivation potentials were recorded and the difference between them was compared. Optical microscopy was used for observing corrosion spots on steel surface at different time during the measurements. From the images and spectra, information can be interpreted as how chloride concentration influenced corrosion rate and to what extent can the four amino acids inhibit corrosion process. In general, pAB had the best inhibition effectiveness among the amino acids, followed by 11AUA. 6ACA and Gly showed similar performance during the experiments, both of whose corrosion inhibiting ability were not satisfactory. The difference of corrosion inhibition in amino acids may be owing to their carbon chain length and the existence of functional group. In total, the corrosion inhibitive effect of amino acids was not as good as that of sodium nitrite.","corrosion inhibitor; amino acid; reinforced steel","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Materials Science & Engineering","","Materials Science & Engineering","",""
"uuid:cfee567c-425a-4b2d-9550-f7d7eea41b8b","http://resolver.tudelft.nl/uuid:cfee567c-425a-4b2d-9550-f7d7eea41b8b","Quantum logic and the EPR paradox","Molenaar, L.S.","Hart, K.P. (mentor); Coplakova, E. (mentor)","2014","We explore the foundations of quantum mechanics to see how the mathematics of QM was built. After that, we see what the EPR paradox is, why it was posed as a paradox and how it was solved.","EPR; paradox; quantum mechanics; logic","en","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","Bachelor Applied Mathtematics","",""
"uuid:806e91f1-1967-426b-af6c-cb2fbf270985","http://resolver.tudelft.nl/uuid:806e91f1-1967-426b-af6c-cb2fbf270985","Quantifying the impact of loads on connections between segments of an immersed tunnel","Parwani, K.","Braam, R. (mentor); Hordijk, D.A. (mentor); Hooogenboom, P.C.J. (mentor); Dieteren, G.G.A. (mentor)","2014","Immersed tunnels have become an integral part of the modern day society. Their serviceability and maintenance are of prime importance. In recent years, monitoring of immersed tunnels for deformations showed the necessity for the analysis of certain tunnels due to an unexpected and local increase of settlements and rotations. With the Kiltunnel in the Netherlands, settlements observed at a segment joint of the tunnel were higher than expected. This master thesis focuses on the structural behavior of the segment joint of this immersed tunnel. Developing a 3-D FEM model consisting of the two segments of the tunnel coming together at the connection/joint is described in this thesis. The model is fixed on one end and forces are applied at the other end. The forces which are expected to occur are calculated with the available values of settlement and rotation on site. Various schemes of the combination of forces are studied in this work. First, the behavior of the joint is observed when the connection is subjected to a shear force only. It is found that the shear force at the joint is concentrated in the walls and almost equal percentages of force flows through each wall. The shear stress values are highest at the middle wall. The middle wall is less thick than the outer walls making it more vulnerable to damage and cracking. It is also found that in a linear analysis, the tunnel joint is capable of carrying the estimated shear force without the activation of reinforcement. This is applicable to both the top tooth and the bottom tooth of the tunnel. The concrete tensile stresses are far below the concrete tensile strength. It is expected that the actual capacity would be much higher if detailed non-linear analysis is carried out. When a combination of shear force and bending moment is applied, it was noticed that the DIANA model becomes unstable and there is loss of equilibrium. This implies that soil should be modeled as elastic foundation in order to come to a conclusion about the capacity of the tunnel connection.","","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Concrete Structures","",""
"uuid:123edecb-50da-47fa-8bc0-3d82e1dc4666","http://resolver.tudelft.nl/uuid:123edecb-50da-47fa-8bc0-3d82e1dc4666","Steering controller identification and design for human-like overtaking","Zhang, Y.","Mazo, M. (mentor); Hoogendoorn, R.G. (mentor); Hellendoorn, J. (mentor)","2014","","overtake; customization; autonomous vehicle","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Delft Center for Systems and Control","","","",""
"uuid:f28d3cfa-914d-48ec-b71c-462a7eb63304","http://resolver.tudelft.nl/uuid:f28d3cfa-914d-48ec-b71c-462a7eb63304","Long Term Effects of Cyclic Loading on Suction Caisson Foundations","Lupea, C.","Van Tol, A.F. (mentor); Brinkgreve, R.B.J. (mentor); Thijssen, R. (mentor); Luger, H.J. (mentor); Versteijlen, W.G. (mentor); Karreman, W.J. (mentor)","2014","Significant financial investments are made in the offshore wind energy, in a race to reduce greenhouse gas emissions. The trend is to install larger capacity wind turbines in deeper waters, further from shore. DTI (2001) states that 30% of this investment is represented by the foundation costs. Senders (2008) and Byrne & Houlsby (2003) found suction caisson foundations within a multi-footing configuration to be a viable and more economically attractive solution. But, the available norms and standards provide insufficient guidance. It is the aim of this dissertation to provide an additional method to investigate the long term performance of these foundations for their usage as footings for large (6 MW) offshore wind turbines, embedded in sandy soil conditions. Literature revealed significant research being undertaken to better understand the cyclic performance of different foundation types. Three main model types have been found: empirical (does not assess each individual cycle), constitutive (assess each individual cycle) and hybrid (a combination of the first two). The hypoplastic sand model with intergranular strain concept is employed, based on its ability to accurately assess the two main effects of cyclic loading on sand: pore pressure and strain accumulation, provided that a correct calibration is done. This research looks at the usage of a centric three-leg jacket for an offshore wind turbine, located in the North Sea, with a soil profile characterised by medium dense sand. It is shown that suction caissons present a large advantage in lateral resistance. Due to their increased diameter, the problem is reduced to the assessment of vertical cyclic resistance, confirming the theory that multi-footings take the loads through a “push-pull” system. The loading conditions, defined by vertical mean load and cyclic amplitude, found within a certain range of the caisson capacity, produce no significant strain or pore pressure accumulation. The behaviour within the elliptically shaped boundary is dominantly hypoelastic. Outside of the boundary, hypoplastic strains and pore pressure build-up occur, with consequent strength and stiffness degradation. Due to insufficient data for the calibration of the medium dense sand soil volume, an overestimation of the pore pressure occurs. Thus, no conclusion may be drawn regarding the behaviour outside of the defined boundary. Nonetheless, this boundary is conservatively constructed based on the chosen type of soil, medium dense sand that is more prone to pore pressure build-up than the denser sands found in-situ. The period of application of the load is conservatively chosen to be equal to the wave period, regardless of the observed larger values, closer to the wind period, which would allow for more consolidation time. This research provides a basis for the design of suction caisson foundations for offshore wind turbines. It provides a tool for the identification of loading conditions that are potentially dangerous for the long term performance of these foundations embedded in sand and subjected to vertical cyclic loading.","suction caissons; cyclic loading; sand; offshore wind turbines; hypoplastic","en","master thesis","","","","","","","","2015-10-01","Civil Engineering and Geosciences","Geoscience & Engineering","","Geo-engineering","",""
"uuid:5ee6b46e-7ab9-497c-b319-7b3ae0b43cd4","http://resolver.tudelft.nl/uuid:5ee6b46e-7ab9-497c-b319-7b3ae0b43cd4","Do we really need the F in DB(F)MO? An empirical study into the substitutes of the F component in Dutch DBMO building projects and the effects on added value","Van den Assem, S.C.E.","Chao-Duivis, M.A.B. (mentor); Wamelink, J.W.F. (mentor); De Jong, W.M. (mentor); Aalbers, S. (mentor); Gotink, I. (mentor)","2014","Due to the difficulties around the F component, it recently appears that more attention has been paid to exploring the alternatives of bank financing. New forms of integrated contracts are gradually being developed that are funded by public resources, but are directed at producing comparable incentives as produced by the F component. In addition, practice shows that additional measures are built in DBM(O) agreements producing comparable incentives, while simultaneously avoiding the complications of private financing. While new practical experiences have shown that the F component is more often excluded from the contract and that supplementary arrangements are built in the DBMO agreement, it has been noticed that the theoretical knowledge is way behind. In view of these new practical movements, this research is aimed at a better understanding of the mechanisms underlying the role of the F component in DBFMO as well as how the role of the F component can be rebuilt in DBMO without the actual use of private financing. Moreover, as the prevailing view seems to be that DBFMO projects provide real incentives that express themselves in added value, this research will also go deeper into the question whether the same level of added value as under a DBFMO structure can be generated, once the F component is removed from the contract. Based on extensive case study research, nine measures are developed to overcome the absence of the F component in DBMO projects. In addition to the measures proposed, it has been found that leaving the F component out of the building contract has five significant implications for the level of added value. These implications are: (1) transaction cost savings; (2) financial cost savings; (3) reduced size of life cycle optimisations; (4) enhanced probability of time overruns, and; (5) improved service quality.","DBFMO; DBMO; PPP; project finance; added value","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","","",""
"uuid:5457aa18-1a62-4921-b49f-3bceada952d3","http://resolver.tudelft.nl/uuid:5457aa18-1a62-4921-b49f-3bceada952d3","Issue dynamics in the execution phase of large airport terminal adaptation projects","Henry, E.","De Bruijn, J.A. (mentor); Veeneman, W.W. (mentor); Warnier, M.E. (mentor)","2014","","CME","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Construction Management and Engineering","",""
"uuid:a90ad26f-aae9-45e7-afe7-f9d36d2e660c","http://resolver.tudelft.nl/uuid:a90ad26f-aae9-45e7-afe7-f9d36d2e660c","Innovative tendering and procurement for adaptive designs","Vermerris, P.M.J.J.","Taneja, P. (mentor); Zwakhals, J.W. (mentor)","2014","Port infrastructure today is planned under more and more conditions of uncertainty, increasing the challenge to design a well-functioning construction for its entire technical lifetime. The Port of Rotterdam is searching for a strategy to close the timespan between commercial (functional)- and technical lifetime of for (customer-) infrastructure so that the alternative value of the construction increases by a new way of formulating the Program of Requirements. In this thesis the bottlenecks are pointed out in the current tendering and procurement procedures followed by a methodology to compose a more future-proof Program of Requirements.","Port planning; Uncertainty; Risk Management; Program of Requirements","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Hydraulic Engineering","","","",""
"uuid:26a25e1c-e0a2-4566-a4f8-55b0fc7445c1","http://resolver.tudelft.nl/uuid:26a25e1c-e0a2-4566-a4f8-55b0fc7445c1","Improving Decision-making on Carbon Capture and Storage in Energy-intensive Industries in the European Union","De Jongh, J.O.","Cuppen, E.H.W.J. (mentor); Scholten, D. (mentor)","2014","The development of carbon capture and storage (CCS) in energy-intensive industries (EnIIs) in the EU is currently stalling while many recognize its importance for reducing CO2 emissions. The socio-technical system of CCS in EnIIs is characterized by resource interdependencies, conflicting interests and diverging perspectives on problems and solutions. A process management approach, enriched with Q methodology and stakeholder frames , could bring decision-making further. The main conclusions include:  Currently, a decision-making process in which relevant stakeholders discuss the governance of CCS in EnIIs is lacking;  the European Commission is in the best position to initiate such a process;  participation is required by a broad range of stakeholders that should be selected based on their resources and interests, but also based on the frames they hold;  reluctant stakeholders can be convinced to join to process by framing the decision-making issue in a broad way;  DG Industry & Enterprise should make a more explicit choice for CCS in EnIIs and join the process;  public support could be increased by demanding that all stakeholders frames are considered in the argumentation for decisions;  a broad multi-issue agenda should be created with a focus on international competition, stakeholder cooperation and a policy framework for CCS in EnIIs, social acceptance is to a lesser extent important to stakeholders;  deliberation and social learning should be incentivized by making frames explicit in the protected lower organizational structures of the process; the communalities in the frames creates opportunities for that. The main contribution of this study is that it shows that incorporating stakeholder frames in a process management approach can lead to improving decision-making on unstructured problems in which there are resource interdependencies, conflicting interests and different views on problems and solutions.","carbon capture and storage; energy-intensive industries; process management; Q methodology; frames","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Policy, Organisation, Law and Gaming","","Engineering and Policy Analysis","",""
"uuid:f5c6510d-55a7-4c79-be7d-3560804056a7","http://resolver.tudelft.nl/uuid:f5c6510d-55a7-4c79-be7d-3560804056a7","Application of the Quantitative Hierarchical Model to Coordinated Ramp Metering","Zhi, M.","Verbraeck, A. (mentor); Vrancken, J.L.M. (mentor); De Jong, W.M. (mentor); Yuan, Y. (mentor)","2014","Transportation is a basic necessity in human society and it has gained increasing importance during the last decades. The subsequent effect of this development is traffic congestion caused by the tension between expanding demand for transportation and limited infrastructure capacity. At present, the most effective way to alleviate traffic congestion is to fully utilize the available resources via appropriate traffic control measures. Ramp metering is considered as the most efficient approach to the control of freeway networks and coordinated ramp metering (CRM) is the prevalent strategy. Current implemented CRM strategies are based on heuristic rule-based approaches, of which the most prevalent algorithm is called HERO. HERO works by balancing the queues of a consecutive series of on-ramps, which lacks flexibility in assigning priorities to certain ramps. Besides, CRM still works locally within a restricted area, but many traffic problems are network related. A new traffic management framework named Quantitative Hierarchical Model (QHM) inspired from Systems Engineering theory is a potential solution to ramp metering issues. The basic concept of QHM is the network. The key components of this framework are recursive partitioning of networks (hierarchical) and priority settings (quantitative). Therefore, the aim of this thesis is to design a new algorithm by applying the QHM theory to Coordinated Ramp Metering. The research is conducted via simulation. A microscopic traffic simulator, VISSIM, is applied, which is controlled by Matlab via VISSIM COM. The general idea of the algorithm is to distribute inflows among different entries based on the allowed outflow, then examine whether the actual outflow follows the allowed value. Meanwhile, the network should still maintain a desired speed. The main discovery of this research is the feasibility of QHM to CRM in our system settings. To be specific, the distribution of priorities among different entries is possible and the real inflow conforms to the corresponding priority. Beside, by distributing priorities, the allowed outflow can be achieved, while the network can still maintain the desired speed. Though the research objective is achieved in this case, it is still far to go to draw the conclusion that QHM can be a substitute to current CRM strategies. In my research, many assumptions and simplifications have been made, which may deviate from reality. In future research, more realistic system settings should be added and a stepwise bigger network should be built. Moreover, feasibility of this framework in practical deployment should also be investigated.","Coordinated Ramp Metering (CRM); Quantitative Hierarchical Method (QHM); HERO algorithm; priority distribution","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Systems Engineering and Simulation","","Engineering and Policy Analysis","",""
"uuid:5505bd71-33f2-4815-94a3-09c74a3154b3","http://resolver.tudelft.nl/uuid:5505bd71-33f2-4815-94a3-09c74a3154b3","Optimizing methods for hybrid Bayesian Networks applied on maintenance of offshore wind turbines","Pluim, J.","Courage, W. (mentor); Hanea, A. (mentor)","2014","A Bayesian Network can be used to model and visualize a process that includes multiple dependent variables. By graphically displaying the relations it is clear, also for non mathematicians, what the different dependencies are. Bayesian Networks however only contain variables described by probability distributions. Besides this we also want to include the possibility of decisions being made about different actions and we want to attach values to different scenarios. Therefore we introduce Influence Diagrams to be able to include Decision Nodes and Value Nodes. The next step is to be able to perform calculations on Influence Diagrams and utilize algorithms to find combinations of decisions in Decision Nodes which lead to an optimal result in terms of expected loss or expected gain. Therefore we introduce LIMID’s, which belong to the group of Influence Diagrams, to be able to introduce operations to optimize Influence Diagrams. This Bachelor Thesis will mainly focus on the Single Policy Updating algorithm and will look into the problems which arise when introducing continuous probability distributions in LIMID’s. Therefor we focus ourselves in this thesis on different ways of discretizing continuous distributions in order to implement them in LIMID’s.","","en","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied Mathematics","","Applied Probability","",""
"uuid:c162c7df-9981-46ce-b793-9604f474635a","http://resolver.tudelft.nl/uuid:c162c7df-9981-46ce-b793-9604f474635a","Quality Control Tools in Asset Management: Applying Six Sigma and Lean Production to improve the Maintenance Process for Pavements","Tobar Cordovez, S.","Van der Lei, T.E. (mentor)","2014","Asset Management has become an important tool for dealing with risks, costs and performance of large infrastructure systems. Rijkswaterstaat, an agency of the Ministry of Infrastructure and the Environment, faces the challenge of maintaining the highway and waterway networks and water systems in The Netherlands. This research project focuses on the information cycle for the maintenance process of the highway network. The research problem consists of the deltas that appear in the information cycle between the advice, planning and execution of the maintenance activities. In order to solve the research problem, Six Sigma and Lean Production tools were applied to improve the process and find the causes behind the deltas in the information cycle. The study was complemented with a Rough Set Data Analysis to find the causal relationships of these factors and the deltas. The result is an overview of the factors that influence the information cycle and generate the deltas in the various activities of the maintenance process. The research project aims to deliver recommendations on how to overcome these factors and improve the maintenance process at Rijkswaterstaat based on the tools from Six Sigma and Lean Production.","Asset Management; Six Sigma; Lean Production; Maintenance process","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Energy & Industry","","Management of Technology","",""
"uuid:e46e0e29-0174-4b17-800b-8b1c7497e45b","http://resolver.tudelft.nl/uuid:e46e0e29-0174-4b17-800b-8b1c7497e45b","Lightfield adaptable surgical luminaire","Kunst, J.J.","Dankelman, J. (mentor)","2014","The ability of current surgical luminaires to adapt the light field to different wound shapes is very limited. A system that is able to modify the shape of the light field to the actual wound shape should be able to improve the visual performance of the surgeon during a surgical procedure. A luminaire system has been designed that receives an input shape and translates this shape into an improved light distribution that will be projected by the adaptable luminaire.","Light field adaptable luminaire","en","master thesis","","","","","","","","2021-01-05","Mechanical, Maritime and Materials Engineering","BioMechanical Engineering","","BME","",""
"uuid:a9c78f0c-9103-4088-b0ba-255e6466d0e1","http://resolver.tudelft.nl/uuid:a9c78f0c-9103-4088-b0ba-255e6466d0e1","Preventing out of stocks through a holistic supply chain management approach","Versantvoort, G.","Verbraeck, A. (mentor); Van Splunter, S. (mentor); Van Duin, J.H.R. (mentor)","2014","MANAGEMENT SUMMARY Introduction Due to warm weather in the Netherlands in 2013, out of stocks (OOS) on several products occurred in the warehouses at Heineken. Warmer weather than usual caused a more volatile demand, leading to these OOS. An OOS at Heineken, meaning that Heineken is unable to ship an order due to insufficient stock, has negative effects for Heineken as an organisation. The main reaction of the end consumer will be to switch brand (34%), postpone their purchase (23%), choose a different product (19%) or choose a different store (19%). Next to a bad reputation at the end consumer, OOS worsen the relation with the retailer. Heineken has an increasing product portfolio due to a lot of newly introduced products which is in line with the trend found in literature. An increased portfolio complexity makes a risk on a OOS even bigger, making it necessary to learn how to cope with this increasing portfolio. A product segmentation, in order to create product groups with a specific focus, is a possible solution for OOS indicated in literature. More in general, a solution is needed that enables Heineken to cope with a specific product group. Next to an increased portfolio complexity causing a risk on OOS, the interface between supply and demand in the supply chain and within an organisation adds complexity. On the one hand there is the supply chain that must be managed to build up stock and on the other hand it is vital that the sales forecast is aligned with the demand. A continuous trade-off between OOS (due to an under-forecast or production) and obsoletes (due to an over-forecast or production) takes place on this interface between supply and demand. From literature, different frameworks are initiated to cope with volatile demand through volatile supply chain management. One way to become more responsive is through collaboration in the supply chain; Collaborative Planning, Forecasting and Replenishment is an approach that could possibly fit the problem identified. From a risk management perspective it is however interesting to research a possibility of preventing the risk on a OOS caused by volatile demand instead of responding to a risk. Research question The problem identified is: there is currently no strategy on proactive collaboration in order to cope with a last minute increase of demand. The knowledge gap in line with this problem is: what is needed to implement a proactive collaboration in order to cope with a last minute increase of demand? The research question to cope with this knowledge gaps is defined as follows: To what extent can collaborative planning prevent OOS caused by a last-minute increase in demand? In order to answer this question a case study is performed at Heineken, this case study is structured using the following sub questions: 1. How to cope with a complex product portfolio during warm weather in the Netherlands? 2. Where in the supply chain can a last minute increase in demand be accounted for? 3. Can a possible solution on the complex product portfolio be embedded in the supply chain to account for a last minute increase in demand? Approach After an introduction to the problem and the research, a case study is used to research the problem. This case study consists of four main parts, each part will be approached differently. First an empirical analysis based on statistical data is performed to search for a direct solution for Heineken’s problem on how to cope with a growing product portfolio and the problems the large portfolio caused during the warm summer of 2013. The second part contains a stakeholder-, information- and system analysis to gain insight in interdependencies and identifies the critical system. The third part concerns the combination of the solution to the portfolio complexity and the understanding of the organisational complexity of Heineken. Important in this part is also the organisational implications on the short and long term. Finally, the improved system is translated into a workshop to challenge findings of the case study. The workshop is designed in a way that the indicated stakeholders learn and understand the system in which they operate and learn to work with the solution from the first part. The research is concluded with first conclusions and recommendations for Heineken and then conclusions and recommendations for scientific research. The report structure is visualised in Figure 1. FIGURE 1: REPORT STRUCTURE Results A short term straight forward solution to proactively prevent stock-outs during warm weather in the Netherlands can be embedded in a holistic supply chain management approach at Heineken. Before the summer of 2014, the proposed solution has become operational in which Heineken uses scenarios to anticipate on the possible effect of warm weather on the stock levels. The solution is embedded in the organisation involving four different departments who now understand each other’s trade-offs in their daily operations in such a way, that they can together prevent OOS. Until July 2014 no OOS as a result of the warm weather have occurred at Heineken even though there have been some warm periods with the highest demand in years. The solution is respected within Heineken in such a way that it has been introduced to other countries within Europe where Heineken is also facing the same problems. For Heineken periodic modifications, structural improvements, horizontal expansion and general learnings of the solution to be applied broader within the company are proposed. Conclusion and recommendations Based on the fit of the solution found in the case study, in the concept of collaborative planning, forecasting and replenishment the main research question can be answered: Collaborative planning can be used to proactively prevent OOS caused by a last-minute increase in demand through the use of scenarios. In a case study at Heineken it is researched whether Collaborative Planning Forecasting and Replenishment (CPFR) is a good tool to cope with the complexity indicated. CPFR enables a manufacturer to proactively deal with variability and exceptions in demand but is unable to cope with volatility in demand. Using the framework of CPFR, a manufacturer is unable to process solutions to exceptions in the order forecast when they cause a large up lift in demand within the production lead time. The manufacturer might not be able to adjust the production plan since these exceptions in the order forecast are within the frozen forecast period. To cope with this type of exception in demand, an addition to CPFR is proposed. Through intra-organisational collaboration there can be anticipated on different scenarios of the impact the exception has on stock levels. Through these scenarios a choice can be made whether changes in the operational production plan are desired. Through this application CPFR can be used for managing volatility in demand and not only variability in demand. For this research it is recommended to extend this research to a broader field of case studies in order to validate and embed the proposed application into CPFR. The solution can be used in a make to stock environment of perishable goods, but it is feasible that variations on this specific environment can also benefit. Future research, to identify under which conditions this application adds value to the manufacturing company, is recommended.","CPFR; Collaborative Planning; Forecasting and Replenishment; Volatile demand; Supply Chain Management","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Systems Engineering and Simulation","","SEPAM","",""
"uuid:55693dfa-8fce-4b7d-963f-78429c3b185d","http://resolver.tudelft.nl/uuid:55693dfa-8fce-4b7d-963f-78429c3b185d","Amarant: Encouraging the application of humour between informal caregivers and people with dementia","Blom, J.H.E.","Visch, V.T. (mentor); Sonneveld, M.H. (mentor); Aarts, C. (mentor)","2014","Dementia Dementia is a collective term for about fifty diseases, describing a wide range of causes and symptoms associated with cognitive decline. This cognitive decline is caused by the decrease of nerve cells and/or the connections between nerve cells and usually starts with memory loss, followed by difficulties in communication and verbalization. In later stages bodily functions become affected as well. Dementia is progressive and although the process can sometimes be delayed by the use of medication, it cannot be cured. Informal caregiving Approximately 70% of people with dementia live at home and are taken care of by informal caregivers, who on average spend 20 hours a week on caregiving for the duration of five years. Informal care is mostly provided by spouses, but also by other family members or acquaintances. Providing informal care can be very burdensome both emotionally as well as physically. The informal caregiver has a personal bond with the person he takes care of. The person they take care of slowly disappears and meanwhile the care they have to provide gets more and more extensive. Many informal caregivers therefore are overburdened Humour as coping In order to relieve the burden of providing informal care there are several coping possibilities of which a very powerful one is humour. Next to the positive effects humour can have on one’s physical health such as reducing the release of stress hormones as well as massaging one’s internal organs it also has beneficial psychological effects. It can enlighten the emotional burden of the situation and positively influence social relationships. Although humour can be very beneficial, informal caregivers often experience a lack of humour in the care giving relationship. They feel as if there is nothing left to laugh about in the burdensome situation of dementia and informal caregiving. However, research within this project has shown that there actually are quite a few moments of humour between the informal caregiver and person with dementia. It is in this discepancy between the perception of the informal caregiver and the actual situation that the opportunity for design is found. The concept of Amarant By taking the personal humour experience of the informal caregiver and the person suffering from dementia as a starting point the concept of Amarant aims to emphasize the positive experience that is triggered by humour. By doing so it stimulates awareness on the power of humour and the value of sharing a laugh. This awareness stimulates and support the informal caregiver to apply humour as a powerful tool to enlighten the situation for both himself as well as for the person who is suffering from dementia. The concept is based on the model of persuasive game design. It stimulates and facilitates the informal caregiver to capture memories of humour in the form of tokens. These tokens form a visual and tangible representation of the experience of humour. A token can contain the stimulus, such as a funny cartoon from the newspaper but can also form a representation of the stimulus, such as a cap of a coke bottle that represents that time when you opened a bottle and it sprayed all over your face. Furthermore it is possible to create a token yourself by the use of several creative materials that are provided in the concept. The package of creative materials is developed by doing several explorative tests on how people capture memories of humour in the form of tokens. The set of creative materials consists of markers and stickers which are simple, sketchy depictions of elements such as animals, people and objects. The collection of tokens is displayed in the house. By doing so, the user can be triggered to interact with the concept at any time. Additionally, the user is also subtly confronted with it, even when not directly interacting with it. It can unconsciously trigger the positive emotions of the collected memories. Furthermore, it can trigger and inspire them in the application of humour in situations, in which they might not have thought of applying it before. In order to support the informal caregiver and stimulate him to interact with the concept over a longer period of time the concept includes so called ‘inspirational cards’. These cards provide specific questions about the experience of humour. By providing the informal caregiver with a more specific direction every now and then, it is easier for them to recall memories of humorous events. Examples of queestions on the inspirational cards are: ‘What was the last situation in which you wanted to contain your laugh but just couldn’t?’ and “Do you remember having a funny slip off the tongue? What was it?”. The backside of these inspirational cards can be used for token creation. Room is provided to create a visual as well as to write down a short description. The created token can then be connected to the collection object.","","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Design for interaction","",""
"uuid:5054ed6f-84fa-4c5c-aa41-548f54c27212","http://resolver.tudelft.nl/uuid:5054ed6f-84fa-4c5c-aa41-548f54c27212","Rìchu & Rìluò: A light system for Chinese families","Varekamp, T.D.","Van Boeijen, A.G.C. (mentor); Van de Geer, S.G. (mentor)","2014","In the last decades the field of consumer electronics has gone through a revolutionary development and shows no sign of slowing down. Starting with one personal computer per family, electronic devices have become integrated into our daily lives to the point where everybody carries a smartphone and/or tablet with them at all times. And the next step is already taken place with the integration of electronics in products like watches, glasses and in homes. Especially in the field of home automation (integrating electronics in and around the house), electronics can add value by integrating into the lives of users. Living can become more convenient, with lights that automatically switch on when entering a room or energy efficiency can be increased, by lowering the heating when nobody is at home. And there are many more possibilities, but also several thresholds for home automation systems to merge in the living routine of users. Currently a home automation system requires significant interior construction works with a team of technicians installing sensors and other electronics throughout the house. Furthermore, the interaction with current home automation systems is more technically oriented, instead of being suitable for casual daily use. A Chinese furniture company, named Homever, aims to lower these thresholds by integrating electronics in furnishing to make a modular home automation system that can be installed by users themselves and merges into their daily lives. They are exploring this integration with several furnishing and home automation developments, but these are still quite separated. This graduate thesis describes the development of a concept that connects with Homever’s home automation system and is integrated in Homever’s furnishing, thereby strengthening the integration of Homever’s separate developments. To identify the possible added value of home automation in the daily lives of Homever’s target group (young Chinese families) an explorative user research is executed. Based on the acquired insights, ‘Rìch?&Rìluò’ is developed, a luminary that adapts the indoor atmosphere to the living routine of its users: from activating and spacious in the morning to intimate and relaxed in the evening","home automation; furniture; China; context mapping; experiential prototyping","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Design for Interaction","",""
"uuid:2fb7882f-76f6-4870-a882-4ecfca5d5de8","http://resolver.tudelft.nl/uuid:2fb7882f-76f6-4870-a882-4ecfca5d5de8","Retail design for China's first sports bicycle A-brand","Kloos, B.P.","Van Boeijen, A.G.C. (mentor); Christiaans, H.H.C.M. (mentor)","2014","The Chinese sports bicycle market is very promising since the Chinese consumers have growing disposable incomes and the sports bicycles are getting increasingly popular among them. However, China’s domestic bicycle brands as well as international brands have not yet succeeded to successfully obtain their desire and maintain their loyalty. The retail of sports bicycles in China has fallen behind on its consumers, Chinese sports bicycle consumers are looking for an experience preview of the expectations they have of a sports bicycle life style. Sadly, the Chinese sports bicycle market is only offering them a place of transaction. The Chinese consumer will therefore turn to his own sources in his social circles or online. Without professional guidance these sources are not always providing the right information or it is not properly understood. Therefore it is common that Chinese sports bicyclist often own a bike that is not fit to their needs. Observations and focusgroups in Shanghai and Luoyang with inexperienced, beginner and advanced groups of Chinese participants revealed the touchpoints, motivations and needs of the Chinese consumer of sports bicycles. In order to create the retail experience the Chinese sports bicycle consumer is looking for, Triace will be the elderly, experienced and caring brother initiating customers into the secrets of cycling and taking them by the hand, teaching and coaching them in order for them to become a new happy and everlasting member of the cycling peer group. The retail design for the flagship store of Triace bicycle in Shanghai will give it’s customers a better cycling experience through: finding the right products for them and making the right products desirable to them through contextual communication sizing and fitting the products for them help them become a better rider through the Triace community maintain their bike.","retail design; China; sports bicycles","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Retail design","",""
"uuid:44197cb1-3b6e-40c1-b7a4-981475cb1221","http://resolver.tudelft.nl/uuid:44197cb1-3b6e-40c1-b7a4-981475cb1221","Observed soil moisture - precipitation feedback in Illinois: A statistical analysis over different scales","Duerinck, H.M.","Van de Giesen, N.C. (mentor); Van der Ent, R.J. (mentor); Schoups, G. (mentor); Babovic, V. (mentor)","2014","The lack of soil moisture – feedback understanding remains a large source of uncertainty for land-atmosphere coupled models. Better understanding requires observational studies. Observational studies on soil moisture – precipitation feedback in Illinois have shown contradictory results based on different approaches. This paper extends earlier research by providing a more holistic approach to this feedback by considering different scales using a new 11 years hourly soil moisture dataset (2003-2013). This allows us to revisit the previously disputed hypothesis that soil moisture is positively correlated with subsequent precipitation. Statewide, this paper finds a strong positive correlation between late spring/early summer soil moisture at the root-zone depth of 50cm and summer precipitation, in particular in terms of total precipitation for which a maximum R2=0.8 is reached at the end of May. However, in terms of precipitation occurrence this is less clear, except for extreme dry conditions. When considering different climatological regions within Illinois, the correlation between soil moisture and precipitation varies spatially. No significant R2 is found for precipitation in the northwest and southeast explained by soil moisture of the various regions. This might be due to local effects of Lake Michigan in the north and the hills in the south. On the other hand, precipitation variability over central Illinois can be explained by soil moisture variability in the northwest, reaching a maximum of R2=0.81. This can be of practical use for farmers and water resources managers. In addition, this paper separates precipitation induced by soil moisture and precipitation as a mere consequence of precipitation persistence due to non-local effects such as sea surface temperature driving large scale atmospheric circulations. However, no influence of teleconnections on precipitation generation in Illinois is found based on linear correlation tests between climate indices (SOI, MJO(6), MJO(7), NAO, EP/NP, AMO, EA and PNA) and subsequent precipitation. This suggests that precipitation is poorly explained by large scale atmospheric circulation. Hence, this paper demonstrates the observational evidence of a soil moisture - precipitation feedback in Illinois.","soil moisture - precipitation feedback; teleconnections; land - atmosphere interaction","en","master thesis","","","","","","","","2014-08-17","Civil Engineering and Geosciences","Water Management","","Water Resources","",""
"uuid:8c63e6de-865f-4cad-b8be-9cf62ea36f44","http://resolver.tudelft.nl/uuid:8c63e6de-865f-4cad-b8be-9cf62ea36f44","Engineering Model for Automatic Design of Rotor Nacelle Assemblies For Offshore and Onshore Applications","Benlevi, Aksel (TU Delft Applied Sciences)","Zaaijer, M B (mentor); van Bussel, G.J.W. (mentor); Elham, A. (graduation committee); Delft University of Technology (degree granting institution)","2014","","Windenergy","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:ad29420c-9a0d-418f-9151-d8f778850b0e","http://resolver.tudelft.nl/uuid:ad29420c-9a0d-418f-9151-d8f778850b0e","In-situ impedances measurement and influence of 2 k - 150 kHz disturbances on measurement of electrical parameters","Tan, J.","Ferreira, J.A. (mentor)","2014","With the growth of the number of electric appliances which suffer from electromagnetic inference (EMI) in the frequency range 2 k – 150 kHz, the setting up of researches in this field has become more and more popular. Measuring impedances accurately in this frequency range is of great assistance for better understanding of the circuit as well as for EMI filter designs. Thus, this thesis aims to develop a safe, flexible and accurate in-situ measurement approach to measure the source and load impedances at 2 kHz – 150 kHz and then apply it to investigate the influences of the variable impedances on measurements of electrical parameters when experiencing disturbances. In this thesis, the current probe being one of the most important measurement devices is discussed first. To investigate the transfer impedance of the current probes used in the measurements a spectrum analyzer, a vector network analyzer (VNA) and a LCR meter are applied respectively. It is found that the input impedance on the wire side influences the bulk current injection (BCI) probe but not the normal current monitor probe in the transfer impedance measurements at discussed frequency range. The electric models are illustrated. Secondly, an in-situ measurement method – the three-probe method which is verified to be applicable at discussed frequency - is proposed. The measurement accuracy is guaranteed through a proper Fast Fourier Transform (FFT) process by collecting both amplitude and phase information of the measurement. In addition, the three-probe method was compared with its predecessor – the two-probe method which was proposed in 2004 to measure noise source impedance at 150 k – 30 MHz. Then the impedances measurement results of different sources and loads are illustrated by using this three-probe method. At last, by using a variable inductance/capacitance box to simulate different source conditions, it comes out that the loads which property will turn out to be capacitive at certain frequency (2 k – 150 kHz) are sensitive for source impedance variations. Their voltages and currents all are influenced significantly with the resonance between source and load impedances. Fortunately, with further investigation, this effect seems not to interfere with the reading of the smart meter under the test.","current probe; in-situ measurement; frequency 2 k  150 kHz; source impedance; load impedance","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Electrical Sustainable Energy","","Electrical Power Engineering","",""
"uuid:df10f760-6b11-4fea-aa99-309a3f10b4a4","http://resolver.tudelft.nl/uuid:df10f760-6b11-4fea-aa99-309a3f10b4a4","Improving vehicle routing using traffic predictions","Loof, P.C.","Spaan, M.T.J. (mentor)","2014","Vehicle routing through road networks is an important topic of research: time and money can be saved by reducing traffic jams, which would also reduce the burden on the environment. The problem of minimizing the travel time for a vehicle trip is easy to grasp but hard to solve, it is a highly complex shortest path problem. Our goal is to show that routing advice can be improved by using historical traffic data to predict the traffic conditions in the nearby future. We introduce several algorithms that combine historical data with live data in a smart way, our algorithm set contains fixed path algorithms, adaptive path algorithms and policy algorithms. In order to test their performance we create historical scenarios and test scenarios using micro-simulations because they can produce network-wide traffic data. We evaluate the realism of the simulations and highlight the problems that are encountered when trying to mimic reality. The results of the routing algorithms are compared to obtain a good insight in the advantages and drawbacks of the different algorithm types. We show that the best algorithms clearly outperform an algorithm based on the concept of modern in-car routing devices, even when only a limited amount of live data is available, which clearly shows that routing advice can be significantly improved using traffic predictions.","traffic routing; shortest path problem; traffic forecasting; micro-simulation","en","master thesis","","","","","","","","2015-08-14","Electrical Engineering, Mathematics and Computer Science","Software and Computer Technology","","Algorithmics","",""
"uuid:aac71292-e7f7-4e93-bf67-59cfe62229f5","http://resolver.tudelft.nl/uuid:aac71292-e7f7-4e93-bf67-59cfe62229f5","Merging active and passive seismic reflection data with interferometry by multidimensional deconvolution","AlAli, A.","Draganov, D. (mentor); Van der Neut, J. (mentor)","2014","Seismic interferometry, also referred to as Green's function retrieval by crosscorrelation, is a technique with many applications, such as for the reconstruction of surface seismic, VSP, to Ocean-Bottom data using active or passive data. Due to the impurity of the Green's function retrieved in the presence of one-sided illumination or intrinsic losses, multidimensional deconvolution emerged as an alternative. Multidivisional deconvolution addresses the limitations by deconvolving the point-spread function from the crosscorrelation result, which removes the source signature, surface related multiples and takes intrinsic losses into account. The similarity of the inverse problems of interferometry by multidimensional deconvolution applied to active and transient passive data makes it an attractive framework to merge the two datasets and retrieve a broadband Green's function (reflection response). The actual merging is done in the frequency-space domain using simple weighting functions. Numerical validations were carried out to merge active and passive body waves using interferometry by multidimensional deconvolution in a simplified exploration-style environment. The results indicate that sufficient source illumination is need as well as sufficient spatial receiver sampling to ensure that wavefields are properly recorded. Also adequate length of the receiver line must be ensured to properly record the low-frequency wavefields and meet first-Fresnel-zone criterion. The retrieved broadband response is desired for imaging and reservoir characterization purposes. The active seismic survey conducted in the northern Netherlands accompanied by the passive recordings of induced seismicity in the area was an inspiration for the merging idea. Given that the conditions from the numerical models are met in the field, passive and active data can be merged. A simple model was used to investigate the faraway induced-seismicity arrivals and briefly discuss their usefulness.","merging active and passive; interferometry; multidimensional deconvolution","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","IDEA League Joint Master's in Applied Geophysics","",""
"uuid:2be81a26-4e12-4181-b9d0-5ce145ca323a","http://resolver.tudelft.nl/uuid:2be81a26-4e12-4181-b9d0-5ce145ca323a","Measurement and modelling of earthing impedance in ships (DC-30MHz)","Zhao, X.","Ferreira, J.A. (mentor)","2014","Consequence of disturbance due to fault of earthing of on-board systems are not always clear. Second, the military EMC standards are outdated and the rationale behind these standards lacks. Therefore, research into rationale of standards and directives related to system earthing on board is necessary; in addition, develop appropriate on-board earthing models and appropriate method to measure on-board ship earthing impedance is necessary. There are two objectives of the project. From industrial point of view, this focusses on: how to measure and install earthing on board of ships. While scientific objective is how to develop a measurement method from which the DC resistance and HF impedance (up to several MHz) can be measured and finally build a general model which represents the on-board ship earthing. A test set up of measuring earthing impedance regarding to well-defined environment is built in order to get high reproducibly. In addition, for the measurement impedance from DC to 30 MHz, two approaches are done: first, in the company, current supply and voltage meter, LCR meter and spectrum analyser is used to measure DC, low frequency (20Hz to 100 kHz) and high frequency (100 kHz to 30MHz) separately. The loop areas, cross section of wire and length influence on the impedance are studied. In the university, current supply, voltage meter, and impedance analyser are chosen to measure ten groups of wire which one point earthing and multiply earthing are studied. Finally, a general model using curve fitting method and based on ten groups of measurement is built which can be used to further analysis.","measurement; modelling; earthing wire; external inductance; internal inductance","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Electrical Power Engineering","","electrical power processing","",""
"uuid:b0872c00-6116-4b0e-95f9-9bb5d1c14506","http://resolver.tudelft.nl/uuid:b0872c00-6116-4b0e-95f9-9bb5d1c14506","Supply Chain Planning and Simulation at HEINEKEN: Capacity analysis of the bright beer cellar of the brewery in Den Bosch","Van der Niet, F.L.","Verbraeck, A. (mentor)","2014","","DES; Capacity analysis; Bottleneck","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","System Engineering","","","",""
"uuid:1bacb5dc-3605-4323-8112-3082c840c761","http://resolver.tudelft.nl/uuid:1bacb5dc-3605-4323-8112-3082c840c761","User interface of a planning and scheduling tool for oil terminals","Diao, Y.","Boersema, T. (mentor); Pasman, G. (mentor); Chin, R. (mentor)","2014","This graduation project has been designed an interface of a planning and scheduling tool for oil terminals. Oil terminals play an important role in the global energy supply chain. It has a lot of expensive infrastructure and a need for efficient and effective planning. Simulation technology of Systems Navigator offers an opportunity to design an efficient planning tool for oil terminals. Therefore the focus of this project is on how to make this technology easily accessible, useful and usable through a user interface and advanced information visualizations.","Interface; Oil terminal","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Department of Human Information Communication Design","","","",""
"uuid:c61a14c2-4e16-482e-8174-d20c8df6d2d1","http://resolver.tudelft.nl/uuid:c61a14c2-4e16-482e-8174-d20c8df6d2d1","The Effect of Abstract and Specific Mindsets on Energy Tariff Selection","Geerlings, A.D.H.","Rook, L. (mentor); Verburg, R.M. (mentor); Lukosch, H.K. (mentor)","2014","This research investigated the effect of different cognitive styles on decision making. Knowing how someone’s mindset influences choice is important for the development of decision support and guidance tools, and algorithms modelled after the human brain. We conducted two online experiments on first choice in an energy tariff ranking task which tested the effect of three cognitive measures: the Behaviour Identification Form (BIF), the Cognitive Style Index (CSI) and the Rational-Experiential Inventory (REI: consists of FI & NFC). In the first study (N = 191, Mage= 24.27, SDage= 2.410) we found Faith in Intuition (FI) to be the significant main effect on first selected energy tariff, indicating conservative choice behaviour, ? = -1.05, t(177) = -2.41, p < .02, 95% CI = [-2.0859, -0.2084]. This effect could be reversed by statistically significant twoway (FI x BIF and FI x CSI) and three-way interactions (FI x BIF x CSI). Whenever the CSI and BIF measures were aligned, the threeway interaction effect indicated a positive effect of FI on first choice, resulting in less conservative energy tariff choices, ? = 0.002, t(177) = -2.63, p < .01, 95% CI = [-0.0030, -0.0004]. In the second experiment (N = 87, Mage= 23.86, SDage= 3.286) we found that a mindset-manipulation could significantly influence the first selected energy tariff, ? = 2.85, t(73) = 2.25, p = .28, 95% CI = [0.3240, 5.3673]. These results offer possibilities for improving the decision-making process by altering a decision maker’s mindset to fit the decision at hand and to establish either more progressive or more conservative selection of alternatives.","construal level theory; cognitive-experiential self-theory; cognitive style; energy tariff selection; three-way interaction effect; behaviour identification form; cognitive style index; rational-experiential inventory short; decision making; mindset","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Economics of Technology and Innovation","","","",""
"uuid:28335ec2-4055-4a71-a256-af401168aa48","http://resolver.tudelft.nl/uuid:28335ec2-4055-4a71-a256-af401168aa48","Design and Optimization of Volumetric Solar Receivers based on Nanoparticles with Supercritical Carbon Dioxide","Hernandez Aita, D.C.","Pecnik, R. (mentor)","2014","","nanoparticles","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Process and Energy","","Energy Technology","",""
"uuid:c09bd3de-68a7-46ea-8a5b-b6b557429a93","http://resolver.tudelft.nl/uuid:c09bd3de-68a7-46ea-8a5b-b6b557429a93","Application of Monte Carlo Simulation for risk-based decision making in MV distribution networks","Goerdin, S.A.V.","Smit, J.J. (mentor)","2014","Due to the liberalization of the electricity sector and the introduction of regulatory agencies to ensure service reliability, while at the same time controlling costs, distribution system operators (DSOs) are increasingly focusing on the concept of asset management. Asset management involves decision-making for investments where a balance between cost, performance and risk of the system needs to be found. Decisions within asset management are often risk-driven. Risk assessment methods within DSOs are relatively new and the available methods have, up to date, not yet been extensively applied for electric distribution systems. Nonetheless, there is a worldwide increase in interest to do so, which is supported by the specification PAS-55 for a number of years and by the in 2014 released ISO55000 series for asset management. The challenges for DSOs with risk-based methods lies with the size of the distribution system consisting of a wide variety of large numbers of assets, the availability of data, the probabilistic behavior of the power system, dynamic system configuration, ageing of components and environmental influences. The main purpose of this thesis is to study the applicability of the Monte Carlo Simulation (MCS) method, utilizing the currently available failure data recorded at DSOs, and to investigate whether the simulation results can provide guidance in typical risk-based asset management decision-making processes. The MCS method is modelled for a practical application in the distribution network of Stedin. In this thesis the focus is on forecasting costumer interruptions through the MCS method. The study cases consist of 12 randomly selected 10 kV radial feeder systems from a distribution network of Stedin. The significant components contributing to the occurrence of customer outages are investigated by statistical analysis. According to the historic failure records cables and cable joints are found to contribute to majority of MV grid related outages and therefore their behavior is investigated. The strategy applied to the study cases is to initiate a MCS at an earlier point in time (at an initial starting year) and simulate for a mission time up to present time. This strategy is chosen in order to make it possible and realistic to compare the simulated customer outages with the actual occurred amount of customer outages for validation of the model. Moreover, for application of the MCS, the necessary input data of the components in the system are their times-to-failure (TTF) distributions. According to the available information, the TTF distribution of paper-insulated lead-covered cables (PILC) and cross-linked polyethylene cables (XLPE) are assumed to follow an exponential distribution. The failure distributions of cable joints are assumed based on results obtained from a previous research. The failure probability distributions as function of age are found to be, a normal distribution for oil-filled joints and Weibull distributions for resin-filled and synthetic joints. The TTF distributions modeled through the application of truncated distributions at their ages. The MCS algorithm for the study cases in this research is modelled in Matlab. From the validation of the results of the 12 historic radial feeder systems, by comparison of the actual occurred number of outages, it is concluded that 100% of the actual occurred outages were predicted through the simulation, i.e. the actual occurred outages of all the systems were possible outcomes of the simulation. Further, 33% occurred with a probability of less or equal than 0.1 and thus represent extreme events. Through brief investigation of possible causes of extreme events it can be argued that the cable length, number of joints in the system and the soil type contribute to the occurrence of these extreme events predicted though the MCS model. The predictive risk assessment method presented in this thesis can provide the asset manager with inputs to assist in the decision-making process. The conceptual framework for the utilization of the results is presented and a decision tool for the execution of risk-reducing investment plans is provided. This concept is indicated in the flow chart below.","","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","","","","",""
"uuid:2a5e4107-fcbf-49bf-aeb8-286906d719b1","http://resolver.tudelft.nl/uuid:2a5e4107-fcbf-49bf-aeb8-286906d719b1","Bepaling van de State of Charge van de Nuna Zonnewagen","Aantjes, H.; Veldhuisen, P.","Verhoeven, C.J.M. (mentor)","2014","Deze thesis van het bacheloreindproject behandelt een deel van de ontwerpkeuzes en test die gedaan zijn voor het ontwikkelen van een batterij management systeem (BMS) voor Nuna. Het BMS is verantwoordelijk voor het meten van spanning, stroom en temperatuur in de accu en zorgt voor het balanceren van de cellen. Daarnaast heeft het BMS de taak om een bepaling te doen van de resterende energie in de accu. Deze thesis focust ten eerste op de state of charge. De state of charge wordt enerzijds bepaald door middel van stroomintegratie, welke zeer nauwkeurig is op korte termijn, maar onzeker wordt op lange termijn. Anderzijds wordt de state of charge bepaald op basis van een spanningsmeting. Met behulp van een batterijmodel kan aan de hand van de spanning een schatting gemaakt worden van de state of charge. Op korte termijn geeft dit een schatting met veel ruis, maar deze schatting blijf ook op lange termijn nauwkeurig. De schattingen op basis van spanning en stroom worden door een algoritme gecombineerd tot een optimale bepaling. Wanneer de omstandigheden vergelijkbaar zijn met kalibratieomstandigheden, kan een nauwkeurigheid van 1% bereikt worden. Voor het uitvoeren van de stroomintegratie is een nauwkeurige stroommeting noodzakelijk; dit vormt dan ook het tweede kernpunt van deze thesis. Met behulp van een shuntweerstand en een versterkingscircuit is geprobeerd de offset zo laag mogelijk te houden, zodat de state of charge bepaling nog nauwkeuriger wordt. Een offset van 50mA is bereikt, waarvan de oorzaak bekend is. Omdat ook de temperatuur van invloed is op de state of charge vormt de meting en regulatie hiervan een derde onderdeel van de thesis. Met behulp van een thermistor kan een temperatuur gemeten worden met 0.5celsius nauwkeurigheid. Tevens is hardware gerealiseerd om de temperatuur te regelen door middel van een ventilator. De software van het BMS was ten tijde van het schrijven van de thesis nog niet voldoende ontwikkeld, om alle onderdelen volledig te kunnen testen. Voordat het BMS daadwerkelijk geïntegreerd kan worden in de Nuna zullen er nog additionele testen moeten worden uitgevoerd.","State of Charge; Battery management system; Nuna","nl","bachelor thesis","","","","","","","","2019-08-13","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","Electronics","",""
"uuid:4af9c7a0-23a5-44dd-83d9-9331ef7f748e","http://resolver.tudelft.nl/uuid:4af9c7a0-23a5-44dd-83d9-9331ef7f748e","Numerical modeling of wave-current interaction with the use of a two-way coupled system","Cats, G.H.","Uijttewaal, W.S.J. (mentor); Van Vledder, G.P. (mentor); Zijlema, M. (mentor); De Schipper, M.A. (mentor); Adema, J. (mentor)","2014","The Dutch Flood Defense Act prescribes the assessment of the safety level of Dutch primary sea and flood defenses every six years. To asses if the required level of security of the sea and flood defenses is guaranteed, first the Hydraulic Boundary Conditions (HBC) which the sea and flood defenses are exposed to, have to be determined. At the eastern Wadden Sea, nonlinear wave-current interaction is important in the determination of wave fields and the wave set-up contributions to the surge elevation. The Hydraulic Boundary Conditions of the primary sea and flood defenses adjacent to the Wadden Sea are therefore determined with the use of a two-way coupled modeling system, existing of the circulation model Delft3D-FLOW and the wind wave model SWAN, to account for wave-current interaction. An inextricable consequence of modeling is the introduction of errors and the aim always should be to minimize these errors. The goal of this study is to improve the understanding of the two-way coupled modeling system and to increase the knowledge on the reliability of the result. A literature survey is performed with the goal to improve the understanding of the two-way coupled modeling system and to identify the largest sources of uncertainty. The relative importance of all sorts of physical processes is highly dependent on the set-up of the model schematization and the location. The effect on the result due to the applied coupling interval, wind drag parameterization in both Delft3D-FLOW and SWAN and different depth-induced wave breaking parameterizations is investigated at the eastern Wadden Sea, for the storm of 9 November 2007. Results showed that increasing the coupling interval mainly influenced the predicted water level, while the wave conditions were hardly influenced. The advice is to not increase the coupling interval to larger intervals than 30 minutes during storm conditions. The 'fit' wind drag parameterization Zijlema et al. (2012), is compared with Wu (1982) in SWAN and Charnock (1955) in Delft3D-FLOW. The largest differences are observed due to different wind drag parameterization in Delft3D-FLOW, though the effect of wind drag parameterization in SWAN possibly also might have an effect at higher wind speeds. The effect of applying the depth-induced wave breaking by Salmon et al. (2013) is investigated by comparing the results with the results generated when Battjes and Janssen (1978) is applied. Differences in wave set-up were in the order of 8 cm, while wave conditions showed better agreement with measurements in case of Battjes and Janssen (1978), compared with Salmon et al. (2013) with exception of low-frequency wave energy.","wave-current ineraction; SWAN; Delft3D-FLOW","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Hydraulic Engineering","","Environmental Fluid Dynamics","",""
"uuid:8169e9f4-5ba7-4889-a81d-1a943f989cbc","http://resolver.tudelft.nl/uuid:8169e9f4-5ba7-4889-a81d-1a943f989cbc","Trade Terms Renewal 2015: Streamlining Trade Terms for Procter and Gamble in the Benelux","Welten, I.S.C.","Verbraeck, A. (mentor); Warnier, M.E. (mentor); Rezaei, J. (mentor); Doorten, R. (mentor); Tromp, M. (mentor)","2014","The trade terms for Procter and Gamble are renewed, taking into account supply chain trends. At the same time, the trade terms need to be streamlined within the Benelux, as Belgium and the Netherlands have merged into one organization, thereby enabling harmonization on a larger scale. Two elements are of particular importance for this master thesis: the elimination of ex-plant rebates and the transition towards double stacking. Next to these two elements, three other trade terms elements are considered as well: return shipments, weekend service and compliance management. In this thesis, the best way to process these elements in the trade terms is assessed, while continuously taking into consideration customer satisfaction.","supply chain; trade terms; ex-plant rebate; double stacking","en","master thesis","","","","","","","Campus only","2014-08-08","Technology, Policy and Management","Systems Engineering","","Systems Engineering, Policy Analysis and Management","",""
"uuid:1c7957a1-d28b-4ebc-8c97-37542c447d6a","http://resolver.tudelft.nl/uuid:1c7957a1-d28b-4ebc-8c97-37542c447d6a","Stability of a Crown Wall on a Breakwater: A refinement of existing design formulae","Van Heemst, C.","Jonkman, S.N. (mentor); Zijlema, M. (mentor); Van den Bos, J.P. (mentor); Smith, G. (mentor)","2014","This thesis investigates the stability of a crown wall situated above SWL (Still Water Level) on top of a rubble mound breakwater. Crown walls are concrete super structures implemented commonly to provide a flat surface for pipelines and to make the breakwater accessible for vehicles. The vertical distance between SWL and the bottom of the crown wall is referred to as the freeboard in this thesis. Current design formulae do not take the freeboard into account when calculating the uplift force on the crown wall. Furthermore design formulae assume that the maximum of the horizontal and vertical force occur at the same time. Previous research noticed that these two maxima might not occur simultaneously. The time difference between both maxima is referred to as phase lag. The first goal of this research is to gain insight in the influence of the freeboard on the uplift force and the uplift pressure distribution. The second goal is to quantify the phase lag. A dataset is needed to achieve both study goals. Two approaches are investigated to obtain a dataset. The first is a numerical model, the second is a physical scale model. The research question is: to determine in what way a numerical model or a physical scale model can be used in order to gather a reliable dataset to realise the project goals. The selected numerical model is the IH-2VOF-model. Currently the VOF-model is only validated when the crown wall is (partly) situated below SWL. An experimental dataset was acquired to validate the model. Because the dataset did not provide the exact water depth, it cannot be used to validate the model. For this research physical scale model tests are conducted, in which wave pressures were measured. The recorded pressure data contain a significant amount of noise. Therefore the data are unsuitable to obtain the actual wave force and the exact pressure distribution on the crown wall. It is concluded that the data are only suitable to partially reach the project goals. Current design formulae assume that the uplift pressure reaches the rear end of the crown wall. However, the measured pressure data indicate that the uplift pressure does not reach the rear end. A correlation is found between the relative freeboard and the location at which the uplift pressure becomes 0. A conceptual model is proposed which explains what part of the crown wall experiences an uplift pressure. Furthermore the pressure data are analysed to gain insight in the phase lag. The phase lag appears to be dependent on the relative freeboard and seems to increase with a higher relative freeboard. This finding is explained by a conceptual model which assesses the vertical distance the water travels through the breakwater. This study shows that current design formulae appear to overestimate the uplift force on a crown wall for situations with a freeboard. It also indicates the presence of a phase lag. Furthermore it points out that there are uncertainties about the uplift force on a crown wall. Hence, it is recommended to perform scale model tests whenever a crown wall is designed to gain insight in its stability. Based on investigated articles the VOF-model seems to be a promising tool to perform a stability analysis. However a phase lag was not present in the results of the VOF simulations. Furthermore, options to reduce computation time should be investigated.","crown wall stability; rubble mound breakwaters; wave load; physical scale models; numerical modelling","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Hydraulic Engineering","","","",""
"uuid:877df63c-b1e2-4c5a-9919-cfd4efe75243","http://resolver.tudelft.nl/uuid:877df63c-b1e2-4c5a-9919-cfd4efe75243","EXO-L Foot Attachment: Designing a more universal foot connection","Janssen, D.I.","Hajian, M. (mentor); Albayrak, A. (mentor); Fleuren, M.J.D. (mentor)","2014","This thesis describes the analysis and design of a more universal connection for the connection of EXO-L to the foot. EXO-L is a product is a product that prevents ankle sprains with the foot rotating towards the inside (lateral ankle sprains). EXO-L works by connecting the foot to a 3D printed part around the ankle in a particular way. In the current design, the part around the ankle is connected to a part that is sewn onto the shoe. This solution works, but has some problems regarding aesthetics, process and costs. This project is about finding a new solution for the connection to the foot based on the situation where bigger numbers are being sold. The main question is thus what the next steps are for the connection to the foot. To answer this question, a design was made based on analysis of anatomy, biomechanics, spraining prevention and shoe design. The design was evaluated with some tests including a user test.","ankle spraining; EXO-L; exoligament; footwear","en","master thesis","","","","","","","Campus only","2015-08-07","Industrial Design Engineering","Design Engineering","","Master of Science Integrated Product Design","",""
"uuid:aff46eb6-09b4-4ca5-b9b3-7ce7d032dfcf","http://resolver.tudelft.nl/uuid:aff46eb6-09b4-4ca5-b9b3-7ce7d032dfcf","Design of Photovoltaics e-bikes charging station","Zhao, Y.","Silvester, S. (mentor); Zijlstra, J.J.M. (mentor)","2014","It is a project about designing a photovoltaics charging station for electrical bikes and scooters, which can facilitate electrical bike user and promote sustainable way to commute. This report contains a complete design process including design research, conceptual design, embodiment design, interaction design, design evaluation and recommendations. Why the system is designed, how the concepts are generated, what material and components are needed, how the the sub-systems are connected in construction and how people interact with the system can be found in the report.","e-bike; charging; photovoltaics; design","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Integrated Product Design","",""
"uuid:40c18b6c-69a4-4365-afbd-4c61f390a522","http://resolver.tudelft.nl/uuid:40c18b6c-69a4-4365-afbd-4c61f390a522","Design Framework for Trailing Edge High-Lift Systems: A Knowledge Based Engineering Application","Zaccai, D.","Vos, R. (mentor)","2014","In today’s highly competitive aviation industry, continuous efforts are being directed towards reducing design time and simplifying systems. One of the prime aspects of aircraft design is the development of high-lift systems, which are used to obtain satisfactory performance in low-speed flight. The associated design and integration of high-lift systems is highly multi-disciplinary and iterative in nature, due to tight dependencies between aerodynamics, mechanism kinematics and structures. Therefore, these systems should be considered early in the design process. Current methods for weight and power estimation of high-lift systems rely on empirical methods which are not sensitive to design variables and load cases. To improve the current design process, a new methodology has been developed, employing a Knowledge Based Engineering (KBE) application (inGDL) that integrates the preliminary wing designwith trailing edge high-lift systems and accounts for three-dimensional flap kinematics. The high-lift system in the developed application includes the kinematic synthesis of four commonmechanisms, an initial actuation architecture, weight and power estimate. The development scope has been limited to single-slotted flaps. The developed application works as follows: a clean wing geometry is first generated, after which the designer can assume an initial trailing edge flap layout. By subsequently specifying the required flap settings, the kinematic mechanisms are synthesized. When a feasible design is obtained, a SimMechanics multi-bodymechanism model is generated and then simulated to obtain the internal loads and actuation torque. An initial aerodynamic load of the flap has been determined using an empirical normal load estimation method by ESDU. Next, the mechanisms and actuating drive train are sized, leading to a determination of system weight and drive motor power. The link between the application and sizing module is completely automatized. After a design cycle has beenmade, an automatically generated report presents the obtained feasible design. In order to get an indication of the applied sizing method accuracy, a measurement of the outboard hooked-track mechanism of a VFW-614 flap has been carried out. The measured weight is compared to a modeled hookedtrack mechanism, synthesized and sized specifically for the VFW-614 wing. The results show a 13% underestimation ofmechanism weight, which is caused by modeling simplifications, assumption during sizing and likely the normal load prediction error. The developed application provides designers with the possibility to combine the aerodynamic, kinematic and mechanical aspects in one design environment. By quickly obtaining geometrical and sizing estimates, in addition to identifying design sensitivities, trade-offs can be made earlier in the design process. The application has been made such, that it can be expanded with higher-fidelity analysismodules and additional functionalities. By improving the current modeling concept and sizing method, more accurate results can be obtained and more load cases accounted for.","high-lift; flap mechanism; system design; flaps; kbe; trailing edge; high-lift systems; flap track","en","master thesis","","","","","","","","","Aerospace Engineering","Flight Performance and Propulsion","","","",""
"uuid:dda62e5e-867b-4372-ad87-cdd1b2241f21","http://resolver.tudelft.nl/uuid:dda62e5e-867b-4372-ad87-cdd1b2241f21","Reducing the time-to-market of investment castings through additive manufacturing & casting design sessions","Steenbergen, P.J.","Tempelman, E. (mentor); Deen, H.J.J. (mentor); Rahusen, M.H. (mentor)","2014","Investment Casting (IC) is one of the oldest manufacturing process known to mankind. It is used within a wide variety of applications and it is possible to cast almost any metal. Additive Manufacturing (AM) is one of the newest ways of making products and recent advancements have made it possible to manufacture single parts and prototypes via AM. This could be an economical interesting alternative for other rapid prototyping methods. The time-to-market of investment castings is for many companies too high and engineers are often unaware of the possibilities and difficulties of casting processes. Prototypes are often needed for testing and evaluation before production can be started. A research study was set-up to explore the main challenges during the design of investment castings and to find possible applications of AM in this stage of the development process. An analysis of the current available prototyping methods was performed. An interview with an enthusiastic AM-expert was conducted and industrial fairs as the Hannover Messe were visited to explore the state-of-the-art. Companies that offer AM-services were analysed and the positive and negative aspects of additive manufactured parts were compared with regular cast parts. Sixteen interviews with R&D managers and engineers were completed in order to find out how the current development process of investment castings is structured. The applications of AM in each of the design stages was hypothesised and the development process was coupled to insights from scientific research. A decision tree and time-line were made that guide ignorant designers and engineers towards the right type of prototype and prototyping method for investment cast parts during the design stage. Throughout the project it was discovered that engineers often simply do not know how to design castings and that information is often stored implicitly in people, products and processes. A second research study was set-up to assess the usability of a new design approach in the conservative world of manufacturing. In this study the impact of fast and successful tacit knowledge transfer was investigated. Three successive case studies with Original Equipment Manufacturers (OEMs) were performed and thoroughly analysed. Output of each session was used for optimisation of the next session. Guidelines for the design sessions were created and the ideal scenario for rapid, faultless design of investment castings was made. Through this research project it was concluded that additive manufacturing can make a difference in the development op investment castings. It is easy to make prototypes. However, prototyping covers an underlying, more serious problem. Prototypes are made because the design specifications are either unknown or possibly invalid. Testing results in verification and makes sure no aspects are missed. The number of expensive and extensive testing iterations can be reduced and deferred by conducting casting design sessions in the early stage of product development. Transfer of implicit information seems to result in better designed products and suggests a reduction of the time-to-market of investment castings.","investment casting; additive manufacturing; time-to-market; tacit knowledge; co-design","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Master of Science Integrated Product Design","",""
"uuid:abedd30e-1a91-4a95-b80d-f77b4c7f46ef","http://resolver.tudelft.nl/uuid:abedd30e-1a91-4a95-b80d-f77b4c7f46ef","Improving operations in the SSDZ materials supply chain: Decision enhancement in Dutch medical diagnostics logistics","Van Langelaar, H.J.C.","Kortmann, L.J. (mentor); Lukszo, Z. (mentor); Verbraeck, A. (mentor)","2014","The field of Dutch medical diagnostics is changing. New regulations and competition create a need for optimization of the business processes. The logistics in the medical diagnostics business have to meet demands from both the clients and the medical labs. Because of these strict demands, decisions on big changes are difficult. A lack of information on the effects of decisions to improve the logistics, and a lack of information on what other units in the logistic chain are doing, result in vague discussions. This study focuses on group support and better use of available information in simulation based software, as a possibility to improve the decision process on the logistics. The expected benefits are to find a better way to explore decision options that improve client service quality and flexibility on both sides, as well as saving costs. However, making better use of information in the decision process is not so easy. Incomplete information, the nature of the information, system complexity, and the endless possibilities created a situation that is difficult to optimize using conventional optimization methods. Methods that focus on an analytical approach to isolated problem solving have limited relevance for the business, as the problem is not isolated and there is no single solution. The use of simulation-based Decision Enhancement methodology is a way to explore the complexity of the system and the dynamics of the organizational units represented by the stakeholders. The DE methodology is strongly focused on creating understanding of the system as a whole, and facilitate actual decision forming. A case study was performed at the SSDZ diagnostics labs, in order to find out more about the information needs of the stakeholders. The organization's logistics have an important role in getting materials (sample tubes) to the different diagnostics labs inside the building. The study helps us to understand the issues that medical diagnostics logistics face, and how IT could be used to improve them. The goal of the project was to evaluate the use of Decision Enhancement methodology, in the form of a simulation-based Decision Enhancement Studio to give insight in existing data, to support changing business inter-actor workflow planning questions, suitable for the use in a Dutch medical diagnostics environment. The research has used a prototype DE Studio, that facilitates and enhances decisions on logistics. For creating this type of IT tooling, a literature review has come up with a number of important practical design concepts for creating tooling in a multi-actor healthcare environment. Knowledge and information about actual issues in medical diagnostics logistics were obtained by means of interviews and document gathering. This resulted in a description of the relevant environment of the lab, relevant processes within the lab, a set of data to base simulation runs on, and KPIs that provide actors in the decision process with some information relevant to them. The availability of data, and the KPIs, clearly shaped the actual implementation of the DE Studio. The use of scenarios was chosen to explore different logistic policies. By making these scenarios operational, they had the function of an example, of what the effects of larger decisions could look like. The evaluation of the DE methodology was performed by means of individual interviews, backed by the analysis of audio and video recordings of the DE sessions. Insights obtained from the DE Studio evaluation included that participant involvement in the decision process, and understanding of the logistics system, had increased. Also, the integration of data provided by the DE Studio contributed to a better way for the participants to communicate ideas, and focus their combined attention as a group. The conclusion of the research is that the DE approach is usable and useful in facilitating challenging decisions on the future of the logistics in the context of the research. However, the DE approach does pose some requirements on the attitude of the organization towards change. If change is welcomed across organizational units and levels, the DE Suite can be improved and expanded, in order to add more resolution of the simulation results. This research into the design of components would be useful for adapting and customizing DE methodology in similar organizations.","Decision Enhancement Services; multi-actor; logistics; knowledge gap; Discrete Event Simulation","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Multi Actor Systems","","Systems Engineering","",""
"uuid:7bb8040d-2f43-4587-a8b7-868a76b194ce","http://resolver.tudelft.nl/uuid:7bb8040d-2f43-4587-a8b7-868a76b194ce","Continuous Risk Management of Customers, Application at the ING Arrears Department","Van den Bos, G.","Verbraeck, A. (mentor); Oey, M.A. (mentor); Behdani, B. (mentor); Weijers, R.E.R.M. (mentor)","2014","Continuous Risk Management (CRM) is a practice in which there is a continuous assessment of the risks that exist or could arise. In addition, in CRM it is determined which risks have priority to be dealt with and strategies are considered that could be implemented to deal with the risks. This thesis demonstrates how CRM of (mortgage) customers can be implemented, based on a case study conducted at the ING Arrears Department. As a proof of concept, the thesis shows how CRM can be combined with Data Mining to create a powerful approach that can enable a reduction in risk costs to be achieved. The central research question that is answered in this thesis is: How to reduce the risk costs for ING through the implementation of Continuous Risk Management of customers at the ING Arrears Department, to identify customer risk categories to be handled with a differentiated approach? In this thesis a first iteration of the CRM cycle at the ING Arrears Department is described, in which a differentiated approach is devised for different customer risk categories. The thesis shows how a risk score as calculated by a logistic regression classifier can be used to define a number of distinct customer risk categories, each of which corresponds to a different amount of average resulting risk costs. Based on this, a stacked set of affordable mitigation actions, which each correspond to a positive business case for ING (on average), is defined for the customers in each customer risk category. A further differentiation in approach is obtained by specifying applicable mitigation actions depending on the type(s) of payment problem(s) of a certain customer. Together, the affordable and applicable mitigation actions result in a risk mitigation strategy that is proposed for ING based on the first iteration of the CRM cycle. As part of this first iteration, part of the proposed risk mitigation strategy is piloted on one specific group of customers to give an indication of the potential results and to be able to show how this information can be used to learn and improve the approach in consecutive Continuous Risk Management cycles. The same approach presented in this thesis can potentially be applied in other application areas of (Continuous) Risk Management. It is expected to be particularly useful in areas with a large number of potential risks or risk events (requiring classification) and sufficient data available on these risk events (to enable Data Mining). Beside the financial sector, these areas include (i.a.) logistics and supply chains, the automotive industry, the aviation industry, consumer products manufacturing and telecommunications.","Continuous Risk Management; data mining; mortgage arrears; risk mitigation strategy; logistic regression classifier","en","master thesis","","","","","","","","","Delft University of Technology","TPM: Systems Engineering, CITG: Transport & Planning","","Transport, Infrastructure and Logistics","",""
"uuid:87bc9f46-5f40-4a87-9716-65f7e3ac7c29","http://resolver.tudelft.nl/uuid:87bc9f46-5f40-4a87-9716-65f7e3ac7c29","Design, manufacturing and characterisation of a water fed CubeSat micro-resistojet (Dondersteen)","Poyck, R.M.A.","Cervone, A.C. (mentor)","2014","To further the applicability of nano-satellites in large scale relevant missions, it is necessary that they have their own propulsion system for manoeuvring. Multiple nanosatellites flying in formation or even a constellation, with a distributed network of instruments can obtain simultaneous, distributed and guided measurements, which are not possible with conventional single-spacecraft architectures. A cubesat propulsion system technology demonstration has been shown on the Delffi-N3Xt satellite. Demonstrating cold gas generators, which generate self-pressurising nitrogen propellant from solid material. Now comes the time for an operational demonstration of powerful, innovative and effective propulsion for adequate manoeuvrability potential. This operational demonstration will be undertaken by the DelFFi mission, by having two nano-satellites demonstrating formation flying capabilities, such as inter-satellite distance maintenance. The DelFFi satellites will operate in a network of 50 nano-satellites, called the QB50 mission, with the goal to take multi-point in-situ measurements of the lower thermosphere and research re-entry. The gas generator based cold gas system have however been shown to be unable to produce the necessary total impulse within the stringent mass and volume constraints. The formation flying objective requires a new high performance propulsion system, which is designed during this master thesis. In order to design this propulsion system a number of tests were conducted on the candidate components and assemblies. After a survey of all commonly mentioned reaction engines, a resistojet was found to best meet the needs of this mission. Mainly because resistojets are relatively uncomplicated, do not require combustion and have a relatively low power consumption per amount of impulse generated. The best propellant for resistojets, selected from a large number of possibilities, was found to be water. Water was chosen because it is liquid around room temperature, It has a high potential impulse bit per unit of mass, it is benign, cheap and readily available. Based on the requirements on the propulsion system the following necessary design parameters were found: a water propellant mass of 50 [g], a nitrogen pressurant mass of 0.2 [g], a storage pressure of 4.5 [bar] to 2.5 [bar], a nozzle throat diameter of 25 [?m], a nozzle area ratio of 20 [-] and a final propellant heating temperature of 500 [°C]. The resulting propulsion system performance is: a total velocity increase ?V of 21.01 [m/s] (with a satellite mass of 3 [kg]), a total thrusting time of 17 [h] and 56 [min], a power consumption of 6.8 [W] to 3.7 [W] and a thrust force of 1.4 [mN] to 0.8 [mN]. A resistojet propulsion system requires pressure to transport the propellant from the storage tank to and through the thruster. Because pre-pressurisation is generally not allowed in CubeSats, gas generators were found to be the best option. These gas generators can be electrically initialised in orbit, where they produce gas from a solid. Gas generators used for airbag initiation in the automotive industry were found to be unsuitable for this mission because of the high shock pressure of possibly up to 95 [bar]. Additionally, three out of four gas generators that were tested malfunctioned. The reason for this malfunctioning is still unknown. For the DelFFi mission a waiver was granted, allowing pressurisation before launch. Therefore pre-pressurisation is considered to be the best option for propellant pressurisation. The most innovative part of this thesis is the development of the MEMS micro-thrusters called Dondersteen. These consist of an integrated fluidic inlet channel, heating chamber and rocket nozzle, which are all etched in silicon. The propellant is heated using heating elements made out of the very strong material silicon carbide. These elements are suspended in the middle of the fluid flow in order to maximise the heat transfer to the propellant, and minimise the heat loss to the surroundings. The novelty not only lies in the geometry, but also in the manufacturing process. Hereby the fluidic channels and suspended heating element are both etched out of the silicon carbide covered silicon wafer in the same two etching steps. The developed thruster consists of the following three distinct sections: inlet, heating chamber and nozzle. Multiple designs were made for each of these sections. The production process was chosen such that any combination of these sections can be etched behind one another. This creates the flexibility of being able to produce and test multiple thruster layouts, in order to find the one which best fits the requirements. Different heating chamber geometries were designed and tested. These enable the assessment of the geometrical influence on heat loss, pressure drop and propellant heating capabilities. Both the manufacturing process and the resulting heating chambers show great potential. The heating elements have been shown to be robust during the rough testing process. The propellant channels have very favourable rounded edges which reduce pressure and heat losses, while maximising the heating contact and propellant mixing. Due to the experimental nature of the manufacturing process the fluidic channel dept was found to be too large and the nozzle throat diameters were too large. The performed analysis of these discrepancies will be used to improve the manufacturing process. The tested resistance values of the resistive heater modules were found to be 200 to 600 times larger than designed. This increases the required input voltage from 5 [V] to the range from 70 [V] to 120 [V]. For the current testing phase this is not a problem since these supplies are available. The flight models will however have to be redesigned in order to comply with the 5 [V] requirement of the satellite power supply. The main reason of this discrepancy was found to be a calculation error. Some adjustments have already been listed with which this resistance can be decreased by a factor of 144. Further design efforts will have to increase this factor to obtain the real design value of the resistance. There are some tasks that still have to be performed by a succeeding master student to consolidate the work done in this master thesis to a propulsion system flight model. The developed thrusters have to be performance tested with propellant in multiple operating conditions. The results of these tests lead the final redesign of the developed thrusters. The propellant storage system needs to be built and tested. Finally the complete in flight propulsion systems has to be defined, built and integrated into the satellites.","","en","master thesis","","","","","","","","","Aerospace Engineering","Space Engineering","","Space Systems Engineering","",""
"uuid:473fb886-56c1-4750-b57f-d2be8c8e7566","http://resolver.tudelft.nl/uuid:473fb886-56c1-4750-b57f-d2be8c8e7566","Structural Analysis of Polyurethane Bonded Aggregate on Block Revetments","Kruis, M.C.","Jonkman, S.N. (mentor); Verhagen, H.J. (mentor); Van de Ven, M.F.C. (mentor); Bijlsma, E. (mentor)","2014","For centuries dikes in the Netherlands have been protected against wave attack by revetments constructed of pitched blocks. Due to new insights into the behaviour of pitched blocks and increased hydraulic boundary conditions, a significant part of those dikes does not meet the current prescribed standards and safety norms anymore. As a result, large parts have to be reinforced in the coming years. The main failure mechanism of a placed block revetment is uplifting due to water overpressures. This happens when the upward pressures, caused by a hydraulic head difference over the revetment, exceed the dead weight of the structure. The concrete elements are lifted up and the waves subsequently induce erosion of the dike body. Therefore, the renovation of these revetments is currently done by adding more weight to the structure by covering the block revetment with large rocks, or even completely replacing the elements by bigger concrete blocks. In view of the large renovation areas, replacing the concrete elements is a time consuming process and will require considerable financial efforts. Therefore, innovative refurbishment techniques are desired and researched. A relatively new type of revetment is the polyurethane bonded aggregate (PBA) which consists of aggregate glued by the adhesive polyurethane (PU) and is currently marketed under the brand name Elastocoast. This study focuses on the use of PBA in strengthening pitched stone revetments. In this report an effort is made to describe the mechanical behaviour of refurbished block revetments under wave loading. A PBA refurbishment layer adds coherence to the revetment and will prevent the blocks from uplifting. Another notable advantage is its high permeability. Firstly, an analytical model was elaborated to gain a first general insight into the structural behaviour of a composite PBA/block revetment. In the analytical model, the interaction and stress distribution between the revetment and subsoil were modelled as an elastically supported beam (Winkler model). Furthermore the structure was modelled with a finite element package. Although this research is based on multiple assumptions, it is possible to formulate some qualitative statements that resulted from this study.  The findings suggest that a rigid connection between the PBA layer and the existing block revetment is most effective in reducing the bending stresses in the PBA layer.  The results of this study support furthermore the idea that the composite PBA/block revetment could be schematized as an Euler Bernoulli bending beam.  The findings also indicate that the current design method is conservative. In this design method it is assumed that only the PBA cover layer contributes to the flexural strength of the structure. The results of this thesis indicate that this design approach is conservative and therefore resulting in thick PBA layers.  Lastly, two conventional refurbishment techniques (Open Stone Asphalt (OSA) and hydraulic asphalt concrete) were compared with the PBA. Calculations were performed what the most effective approach would be. On the one hand, an impermeable cover layer constructed by asphalt concrete resulting in higher water pressures but increasing its dead weight (asphalt concrete), or on the other hand, applying a permeable refurbishment layer (PBA and OSA) which is less heavy but resulting in lower water overpressures. The results suggest that it is more effective to use a less heavier but more permeable material as a refurbishment than the other way around. It must be noted that this greatly depends of its permeability. If its leakage length is increased by clogging or when applying the refurbished material, it results in a significant increase of the maximum bending stresses. In this case the refurbishment techniques with asphalt concrete becomes more effective since it is heavier.","elastocoast; Pitched Stone Revetments; PBA; refurbishment techniques","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Hydraulic Engineering","","Structural Engineering","",""
"uuid:f4508359-a1ea-4df0-a9c3-4264a2cd9dfe","http://resolver.tudelft.nl/uuid:f4508359-a1ea-4df0-a9c3-4264a2cd9dfe","On the correlation between Turbidity, Conductivity and COD","Tommassen, G.","Clemens, F.H.L.R. (mentor); Korving, J.L. (mentor); Luxemburg, W.M.J. (mentor)","2014","Introduction COD is one of the most important parameters for wastewater quality. Measuring COD is an expensive and time consuming process. There is a need for an inexpensive, accurate, reliable and continuous technique to monitor COD. Turbidity can be used as a proxy for COD, but is not accurate enough for some applications. Some research suggests that conductivity measurements can be used to improve the turbidity prediction of the COD. This has led to the research question: “Can combined turbidity and conductivity measurements be used to accurately estimate the COD of wastewater in a Dutch sewer?” Research To research this fifty samples were taken from the sewer system of Ulvenhout, The Netherlands during three storm events in 2012. The samples are analyzed in a laboratory for COD concentration, turbidity and specific EC. The results are analyzed with MATLAB to find a correlation between turbidity, conductivity and COD. Twelve different fitting formulas were tested using a Levenberg-Marquart algorithm to find the best relation. Conclusions and Recommendations It is concluded that measurements of conductivity and turbidity can be used to estimate the COD of wastewater to some extent. The r2 of the correlation found during this research is about 0.65-0.69. The turbidity is dominant in the estimation of the COD and the added value of the conductivity measurements is limited. Although the conductivity could be used to make the fit a bit better, the improvement is normally not worth the effort of the additional measurements and may even be insignificant. The highest correlation is found with quadratic fits, but the r2 of linear fits is only slightly lower then the r2 of quadratic fits. Since the linear fit of turbidity to COD (without conductivity) has a similar r2, but is simpler, the use of the linear fit is preferred in many cases. The results of the study are only partly in line with literature.","Turbidity; Conductivity; COD; sewer; CSO; correlation","en","master thesis","","","","","","","","2014-08-07","Civil Engineering and Geosciences","Water Management","","Sanitary Engineering","",""
"uuid:5daad8de-f87d-45f8-8e0e-7045f2c8b1cf","http://resolver.tudelft.nl/uuid:5daad8de-f87d-45f8-8e0e-7045f2c8b1cf","Improve the Walko Workbench system with a focus on functionality and efficiency for the user, what will lead to a more attractive line of products","Minjon, J.","Van Heur, R.J.H.G. (mentor); Bilow, M. (mentor); Groot, B. (mentor)","2014","The current Walko workbench has a great set of features that help a (semi)professional user to work comfortably with building materials on site. The level of adaptability of the workbench is already unsurpassed amongst its competitors. Adapting the workbench, rather than the user adapting his posture, greatly reduces the risk of fatigue and work related illnesses. This results in higher yield and quality of work. The current system works pretty well, but it takes quite some effort, time and insight to adapt the workbench during set up and work transitions. The first objective of this project is to reduce these variables, what should ultimately result in a better workflow. The results are several improvements of the current system. These include quick locking hinges, visual cues and reduction of sound. The second objective is the design of an additional accessory that focusses on expanding the functionality of the current system. Eventually, a promising niche was found in organizing tools and consumables in the workstation. The result is a product that has a level of organizing possibilities only seen in stationary workshop benches, while maintaining the original values for mobility. This organizing accessory also further improves the workflow: no more reaching on the ground for screws and tools while working on your preferred height..","handtools; workbench; walko; diy","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Integrated Product Design","",""
"uuid:87d5c245-2cfe-4117-8b0b-2d937f86f93d","http://resolver.tudelft.nl/uuid:87d5c245-2cfe-4117-8b0b-2d937f86f93d","The networked brand identity: Management support tool for tension analysis in brand identity networks concerning privacy","Van den Berg, R.P.","Van der Sanden, M.C.A. (mentor); Wehrmann, C. (mentor); Ramakers, J. (mentor)","2014","A corporate brand is a complex construct, which might be difficult to manage because of a lack of insight into the network of relevant influencers. Sense Observation Systems (Sense) is a small software company developing software that helps users to get information from the sensor data of their telephones. Sense is aware of the possible threats to privacy users of their products might perceive and wishes to express their vision on privacy in the corporate brand. The communication manager aiding Sense in their external communications works for their parent company Almende. Almende advocates self-organization and the bottom-up approach that goes with it. Sense therefore wishes to manage their corporate brand with as little management as possible. The proposed self-organizing approach is a novelty in corporate brand management. This research aims to aid the communication manager of Almende in managing Sense’s corporate brand. To help the communication manager in this management task, we defined the following research question: How to manage the corporate brand of Sense Observation Systems so as to encompass the principles on end-user privacy present within the corporation? --Method-- Semi-structured interviews were used to gather insight into how principles on end-user privacy are present within the corporation. A total eight respondents were interviewed: six employees of Sense, and two of the parent company Almende. The respondents cover different functions in the company: four software developers, two managers, and two other members of staff. A conceptual model for brand management was developed from relevant literature and used to structure the interviews. Six identity types were linked to the corporate brand to distinguish between personnel, products, corporate communication, clients, market, and vision. In the interviews was searched for Sense-specific actors (humans, artefacts, policy, organizations, etc.) represented in these identity types. The interviews provided the following information needed for the conceptual model:  75 actors from all identity types influencing the corporate brand;  7 aspects of privacy relevant for Sense; and  the distribution of privacy aspects over the actors. --Results-- From the 75 actors we defined 10 representative actor clusters, each cluster consisting of actors with similar associated privacy aspects and from identical identity types. For each of the privacy aspects, we visually analysed the tension within the actors network using the privacy landscapes defined in the conceptual model. Based upon the preference of Sense employees and network analysis results, we advised Sense to focus on the privacy aspect use limitation. We also advised to add more stable elements to the actor network, so that core values become more embedded in the network. The practical suggestions of such stable elements were to develop a corporate slogan, build a product showcasing the corporate values, develop a market strategy leading to clients fitting the corporate values, write out the corporate vision so that it becomes more public. --Conclusion and discussion-- The developed privacy landscapes enable us to indicate points of attention in the actor network attributing to the corporate brand of Sense. Also, the advice to manage the company brand using stable elements increases the practical applicability; the effort for the communications manager at Almende can therefore decrease over time. The developed method is a novelty in brand management because of its ability to visually point out actors unaligned to the (preferred) corporate brand. Furthermore, the method provides insight not only in misalignments between but also within identity types by the use of actor clusters. Information privacy research might benefit from the observation of the following privacy aspects that were not found in literature: ownership of the data collected about a person, restriction of access to user data for the company where data is stored, how ownership is distributed in issues concerning multiple parties, and the depersonalisation of data so that it can not be traced back to an individual. We believe that the developed method and resulting privacy landscapes can be applied to other companies using different concepts in order to find points of attention within the corporate actor network. We recommend to reduce the possibilities for observer bias in the methodology by replacing the individual semi-structured interviews with group sessions. with Participants in such sessions have limited observer influence and can determine concepts for the brand identity and label and cluster actors. Instead of a research approach, the group sessions would be more similar to creative sessions.","network; brand; identity; management; tool; analysis; privacy; corporation; end-user; actor network theory; ac3id model","en","master thesis","","","","","","","","","Applied Sciences","Science Education and Communication","","Science Communication","","51.903598, 4.45994"
"uuid:033c4238-62e8-4ef7-b43d-b43f3b97856f","http://resolver.tudelft.nl/uuid:033c4238-62e8-4ef7-b43d-b43f3b97856f","Multi-Agent Actor-Critic Reinforcement Learning for Cooperative Tasks","Bayiz, Y.E.","Babuka, R. (mentor)","2014","For single-agent problems, Reinforcement Learning (RL) algorithms proved to be useful learning optimal control laws for nonlinear dynamic systems without relying on a mathematical model of the system to be controlled. With their ability to work on continuous action and state spaces, actor-critic RL algorithms are especially advantageous in that manner. So far, actor-critic methods have been applied to several single-agent control problems often with impressive results. A Multi-Agent System (MAS) distributes computational resources and capabilities across a network of interconnected agents. The main advantage of using such an approach is to distribute a globally complex problem to simpler sub-problems, which is a more natural way to address source allocation and team planning. Application of MAS to domains, such as robotics, distributed control and telecommunications, gained popularity in last two decades. From the control point of view, cooperative MAS have a special importance since agents in control problems frequently seek to achieve a joint goal. So far, a significant amount of research has been dedicated to Multi-Agent Reinforcement Learning (MARL) for both cooperative and non-cooperative tasks. Yet, the actor-critic methods in MARL context have not been examined in detailed. The aim of this project is to implement actor-critic RL methods to cooperative MAS to combine the advantages of these two approaches and apply the resulting methods to a real-life control problem as a proof of concept. To achieve such task Model Learning Actor-Critic (MLAC) algorithm is extended to two of the Independent Learners (IL) based methods: optimistic learners and lenient learners. The resulting algorithms are tested on 2-link manipulator problem. The results indicate that, the initial learning speed of the proposed multi-agent MLAC algorithms is similar or faster than the centralized MLAC at the start of learning experiments, and the end performance is acceptable compared to the centralized MLAC.","Reinforcement Learning; Multi-Agent Systems","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Delft Center for Systems and Control","","","",""
"uuid:b8153666-4653-4e14-b476-3359d797c2ed","http://resolver.tudelft.nl/uuid:b8153666-4653-4e14-b476-3359d797c2ed","Influence of the performance of hinterland transportation in port choice decision making","Piccot, C.L.","Tavasszy, L.A. (mentor); Van Ham, J.C. (mentor); Vleugel, J.M. (mentor)","2014","Application on the balance between the seaports of the North Sea and those of the Mediterranean Sea.","","en","master thesis","","","","","","","","","Technology, Policy and Management","Engineering, Systems and Services","","Transport, Infrastructure & Logistics","",""
"uuid:aa8f44dc-14c7-496b-870b-632122378492","http://resolver.tudelft.nl/uuid:aa8f44dc-14c7-496b-870b-632122378492","The balance between environmental impacts and traffic safety on roads","Elias, M.","Scarpas, A. (mentor); Haas, E.M. (mentor); Houben, L.J.M. (mentor); Van Gurp, C.A.P.M. (mentor)","2014","The goal of this study was development of two predictive programs. The first program predicts the traffic safety on municipal roads. The second program that is developed in the framework of this thesis is a predictive program correlating durable, sustainable and social aspects on roads based on a cost estimation.","","en","master thesis","","","","","","","","2014-08-05","Civil Engineering and Geosciences","Structural Engineering","","","",""
"uuid:be2c73ad-ceb1-4f4c-b50c-1b7b84cde699","http://resolver.tudelft.nl/uuid:be2c73ad-ceb1-4f4c-b50c-1b7b84cde699","Hydrodynamic modelling for mangrove reforestation at Tanjung Piai, west coast peninsular Malaysia","Gan, S.W.","Stive, M.J.F. (mentor); Cheong, H.F. (mentor); Verhagen, H.J. (mentor); Visser, P.J. (mentor); Ooi, S.K. (mentor)","2014","Coastal erosion is greatly accelerated by the presence of agriculture and aquaculture activities (oil palm plantation or shrimp farming involving the construction of earth bunds) in the natural process. Earth bunds or dykes are constructed to prevent entrainment of seawater into the agriculture area behind the bunds so as to protect these valuable crops and plantings. Coastal erosion and mangrove belt depletion have exposed the earth bunds to direct wave impact. To prevent earth bund breaching and flooding of the area behind the bunds, the requirement arises to strengthen the earth bunds along the eroding coastline. Projects are carried out to replant the mangrove on the mud flats in front of the newly constructed earth bunds for its effective wave dissipating capability and environmental values. The replanting of mangroves on the mud flats in an open coast area requires protection from waves attack during the initial stage when the mangrove seedlings are still young and weak. In view of rather calm wave conditions along the west coast of Peninsular Malaysia, a settlement field made out of soil for mangrove seedling planting and temporary breakwaters built out of bamboo poles with stone filling as a line of protection is one of the possible methods to be studied for its possibility to be applied on the study area. This study aims to analyse the severity of coastal erosion and the hydrological aspects of Tanjung Piai; to identify the causal factors contributing to coastal erosion issue using numerical hydrodynamic modelling tool Delft3D; to identify existing or on-going restoration effort on site; and to explore restoration options that fit in the local condition. This report acts as a hypothesis analysis of erosion/sedimentation pattern at the study area.","mangrove; reforestation; siltation","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Hydraulic Engineering","","","","1.265514, 103.511191"
"uuid:f4b7e1da-4c1c-4526-beb8-52e2c754b0b3","http://resolver.tudelft.nl/uuid:f4b7e1da-4c1c-4526-beb8-52e2c754b0b3","Optimal distributed point control of linear elliptic equations","Sereeter, B.","Tröltzsch, F. (mentor)","2014","In this master thesis, we consider the optimal function and point control problems governed by linear elliptic partial differential equations together with bilateral control constraints. The aim of this work is to choose a control function by linear combination of the Dirac delta and solve the optimal distributed point control problem. In this work, optimality systems of point and function control problems are derived by Lagrangian principle and reduced functional respectively. The optimality system is discretized by the finite element method (FEM) and finite volume method (FVM). We apply a semismooth Newton (SSN) method which is equivalent to a Primal dual active set strategy (PDASS) to solve the discretized optimality system. As a second solution method, we propose Projected gradient (PG) method for the same problem. For each method, we compare the result of FEM and FVM and give a preference. In order to have the best solution method, we compare the results of PDASS and PG methods to the results of matlab command QUADPROG. We have to solve two partial differential equations in every iteration, namely the state and the adjoint equations. Therefore, we develop a Multigrid Preconditioned Conjugate Gradient (MGPCG) method for solving the discretized optimality system as fast as possible. Finally, we consider the linear elliptic optimal control problems with L1 norms in the cost functional which results sparse control problem. Due to L1 norm, objective functional becomes non-dfferentiable and the optimal controls are identically zero on large parts of the control domain. Using an appropriate smoothing of the non-differentiable terms for the cost functional, we solve the optimal sparse control problems theoretically and numerically.","optimal control of PDE","en","master thesis","","","","","","","","2015-02-01","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","COSSE Erasmus Mundus","",""
"uuid:49cb0926-bad4-4455-8a49-0a219126c58b","http://resolver.tudelft.nl/uuid:49cb0926-bad4-4455-8a49-0a219126c58b","The phosphorus cycle of Berlin-Brandenburg: From the present towards possible futures","Schipper, M.","Quist, J.N. (mentor); Van der Voet, E. (mentor)","2014","","","en","master thesis","","","","","","","","","Technology, Policy and Management","Engineering, Systems and Services","","","",""
"uuid:f4e359b0-fbba-4290-aa86-c3a4d83e7bb1","http://resolver.tudelft.nl/uuid:f4e359b0-fbba-4290-aa86-c3a4d83e7bb1","Incorporating flexibility in terminal design: Planning vs. Reacting, A Cost Comparison","Leo, P.M.C.","Wiegmans, B. (mentor); Taneja, P. (mentor); Schott, D (mentor); Visser, W. (mentor)","2014","","","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Marine and Transport Technology","","Transport Engineering and Logistics","",""
