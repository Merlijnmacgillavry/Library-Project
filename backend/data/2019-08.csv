"uuid","repository link","title","author","contributor","publication year","abstract","subject topic","language","publication type","publisher","isbn","issn","patent","patent status","bibliographic note","access restriction","embargo date","faculty","department","research group","programme","project","coordinates"
"uuid:4a7f8ee9-c354-4e3e-997c-cc2652f54731","http://resolver.tudelft.nl/uuid:4a7f8ee9-c354-4e3e-997c-cc2652f54731","Creating value through opening up data by commercial companies: A case study at PostNL Data Solutions","van der Wielen, Michael (TU Delft Technology, Policy and Management)","Warnier, Martijn (mentor); Zuiderwijk-van Eijk, Anneke (mentor); Beekenkamp, Ellen (mentor); Delft University of Technology (degree granting institution)","2019","In recent years the growth in the amount of available data has increased enormously. More and more companies, government organizations and citizens are becoming data dependent. Simultaneously with this growth in the availability of the amount of data, there is increasing interest in opening up this data. Open data is data that is freely available to everyone, can be reused by everyone and can be redistributed by everyone again. Up to now, it is mainly government organizations that make the data publicly available or use open data sources themselves. However, various studies have indicated that a great potential for open data is still unused. If a larger part of the current available data were to be opened up, much (economic) value could be achieved. However, these studies do not determine for commercial companies. These companies are currently lagging behind in opening up their data because they do not see the potential of this. Opening up data is seen as unnecessary insight for the competition and a loss of the market position and the annual turnover. To show companies the value of open data, this research aims to design a method that companies can apply. By applying this method it becomes clear to companies which data in the current structure of their business system has the potential to be opened up and subsequently what value this opened-up data yields for the company.<br/><br/>This methodology, named ""Open Data Implementation Methodology (ODIM)"" in this study, was designed using the design science research approach. The various phases in this approach made it clear which factors are important of open data at commercial companies and, among other things, offered a framework for setting up the method. By going through all the phases in the design science approach, the methodology could be designed, tested and evaluated.<br/><br/>In the first phase, the identification of the problem and the motivation, an extended literature review showed, among other things, that most research into open data focuses on government organizations. From these investigated projects the most striking challenges have been identified to be included in the design of the method. These challenges within open data projects are in the technical, social, legal and economic areas. Analyzing the literature also confirmed that conducting a case study is a suitable method to test open data projects. All these elements were then included in the design of the ODIM. Because analyzing the value of open data projects at companies has to do with the design and organization of new systems at companies, it was investigated what a suitable design method was for the ODIM. Due to the iterative nature and previously proven functions, the design engineering approach has been chosen according to Dym and Little. This method was used to subsequently adjust it so that it is suitable for open data implementation projects at companies. The method, the artefact in the design science aproach of this study, follows different phases that companies can go through. By mapping the current system in detail, determining requirements of open data in the new system and analyzing for example the costs, revenues and use of the data by current users, a concept system design can be drawn up with a central role for open data. This design shows which datasets are suitable for opening up and what changes this entails within the business processes. By testing this new system with experts currently working with the system, the value of the open data in the new system can be determined and changes can be added. The results of the method for a company are ultimately insights into current systems and the value of open data in a newly designed system.<br/><br/>This open data implementation methodology was demonstrated in this study at the commercial company PostNL Data Solutions in the Netherlands. The new open data system and the ODIM have been validated through an expert panel workshop. The results were that open data was seen as a very valuable change compared to current business processes. The value of open data was primarily recognized in the economic, cultural and organizational area. According to the experts who participated in the workshop, opening the data ensures that innovation is stimulated and new and better products and services can be built. The transparency of the company and the accuracy of the data will also increase in this new system. Risks are that it can cost a lot of money and time to set up current IT systems for open data and that privacy can pose risks to users. To be able to apply this method to other companies as well, the benchmarks for value creation must be made more specific to companies. Value creation is very context dependent, which makes it difficult to apply the ODIM broadly. By means of the ODIM, it is possible to make clear how current data systems are structured at companies and determine which data sets are suitable for being opened up.<br/><br/>The conclusion of this research is that open data can create value at commercial companies by reorganizing current systems. The open data implementation method helps companies to gain insight into this and to determine the value of open data for their company. Further research is needed into the broad applicability of the method by examining multiple cases and into benchmarks for value creation. In addition, an implementation plan must also be developed in order to successfully build the developed system with open data.","Open data; Value creation; Commercial companies; Design Science Research","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:393d2261-8f01-406f-acd3-9bb813dc430c","http://resolver.tudelft.nl/uuid:393d2261-8f01-406f-acd3-9bb813dc430c","Thermotion: an exploration of facilitating emotion perception with wearable thermal displays","Yang, Xingyu (TU Delft Industrial Design Engineering)","Jansen, Kaspar (mentor); Hartcher-O'Brien, Jess (graduation committee); Ali, Abdallah (graduation committee); Delft University of Technology (degree granting institution)","2019","The project aims at exploring tangible ways to communicate emotion. To narrow down the scope, I lay the focus on emotion communication in remote settings, a context when nonverbal communication is usually limited. From interviews, the neutral expression is found to be the main factor hindering a sufficient understanding of others' emotional state. Therefore, the scope is narrowed down to a topic related to the real-world problem: Contributing to the emotion interpretation from the neutral verbal expression.<br/>While verbal communication cannot convey emotion sufficiently, tangible modalities like haptics, thermal feedback are promising extra channels to explore. Communicating affection with the physical stimulus is not only supported by theoretical studies like embodying emotion theory but also practiced through prototyping and experimenting from HCI filed. Within this project, thermal stimulus, a modality highly related to emotional experience without causing privacy issue, is selected for the study. Thus, the research can be further framed as: How thermal stimulus contribute to emotion interpretation from the neutral verbal expression? Considering the application perspective and the requirement about wearables from CWI, the thermal stimulus should be designed as wearables. The research is conducted in the path of the controlled experiment to generate solid findings. Voice message, a medium less explored in the area of remote communication, is chosen as the case for study. Therefore, the final research question is formulated as follows: How can wearable thermal display contribute to emotion interpretation from the neutrally spoken voice messages?<br/>The project follows the path of research through design. First, through literature review and quick user test, a pre-study leads to some initial decisions for the experiment: 1) using the upper chest as the body location. 2) using woven silk as the contact medium. 3) setting four thermal stimuli (high intensity warm 38°C, low intensity warm 35°C, high intensity cold 26°C, low intensity cold 29°C).<br/>Afterward, the first experiment is conducted to find the recognizable and acceptable on-body thermal stimulus with a suitable contact medium (skin or fabric) for the second experiment. The study with 12 participants collects the ratings in terms of subjective intensity and comfort. The findings indicate that low intensities cannot be used if the thermal stimuli should be detectable for most people. For the cool stimuli, the intensity is decreased from -6°C to -4°C to ensure participant comfort. Besides, the fabric is not used for the second experiment because of its delay effect on thermal sensation.<br/>Between the two experiments, a study is conducted to validate that the neutral tone can make a normal voice message perceived more neutral. Twelve neutrally spoken voice stimuli are generated by an AI voice generator and compared with the original normally spoken voices (from a validated database) in terms of valence and arousal. The result shows that the neutral expression does make a sentence with either positive or negative content perceived more neutral.<br/>The second experiment is to explore how thermal stimulus can affect emotion perception from nuetrally spoken voice messages. Participants listen to eight voice messages and experience the thermal stimuli at the same time. Afterward, they give their ratings in terms of valence and arousal from the voice messages. Each voice message is paired with three thermal conditions (warm, cold, baseline). The result shows that warm stimulus augments the perceived positiveness of positive messages while cold stimulus augments the negativeness of negative messages.<br/>However, augmenting the emotion perception doesn't necessarily mean the accuracy of emotion perception. The contribution and limitation of the project are discussed in the end.","Thermal display; Tangible Interaction; Affective computing; Wearables; Fabrication; Communication","en","master thesis","","","","","","","","","","","","","",""
"uuid:6edb3603-31e3-4c21-8fed-774bc4ea54d4","http://resolver.tudelft.nl/uuid:6edb3603-31e3-4c21-8fed-774bc4ea54d4","Port of Rotterdam Intertidal wetland: Final Report","Bushell, Terry (TU Delft Civil Engineering and Geosciences); Jin, Yueyuan (TU Delft Civil Engineering and Geosciences); Huang, Haoxi","Delft University of Technology (degree granting institution)","2019","The Port of Rotterdam has many old harbours located close to the Rotterdam city center that are no longer suitable to be used for industrial purposes. Meanwhile due to expansion and population growth of the city, more recreational spaces are needed. The idea is to use the abundant dredged material from the Port of Rotterdam to fill in and construct intertidal wetland parks in some of these old harbours. They will serve as natural habitats for different types of flora and fauna such as migratory birds. These intertidal parks are also ideal recreational spaces for residents. This multidisciplinary project aims to provide a conceptual design of a tidal wetland in the Maashaven harbour. In this report, a general design is presented, and special attention is paid to technical issues that may occur in the construction process.","dredged sediment consolidation; wetland construction; conceptual design","en","student report","","","","","","","","","","","","","MDP291",""
"uuid:643e59e3-403a-4159-b3e4-bdde272610e4","http://resolver.tudelft.nl/uuid:643e59e3-403a-4159-b3e4-bdde272610e4","Optimization of heat extraction within sedimentary reservoirs for CO2 Plume Geothermal (CPG) electricity generation","Ravilov, Marat (TU Delft Civil Engineering and Geosciences)","Adams, Benjamin (mentor); Saar, Martin (graduation committee); Delft University of Technology (degree granting institution); ETH Zürich (degree granting institution); RWTH Aachen University (degree granting institution)","2019","The primary goal of the present work is evaluation and comparison of vertical and horizontal well placements and their impact on the power output of a CPG (CO2 Plume Geothermal) system. Performances of vertical and horizontal wells are evaluated for a repeated five-spot pattern. Six numerical models were developed in MOOSE (Multiphysics Object Oriented Simulation Environment), tested and compared against each other and a benchmark study. Simulations show that the reservoir will respond differently to different well configurations, with buoyancy playing a major role in its response. The study concludes with recommendations on ways to improve the accuracy of present models and directions for future research on optimal well placement for CPG systems","","en","master thesis","","","","","","IDEA League - Joint Master's in Applied Geophysics","","","","","","Applied Geophysics | IDEA League","",""
"uuid:403b5bd5-8761-4c34-b132-2e83050775e2","http://resolver.tudelft.nl/uuid:403b5bd5-8761-4c34-b132-2e83050775e2","Corrosion in Submerged Offshore Slip Joints","de Bruin, Koen (TU Delft Mechanical, Maritime and Materials Engineering)","Hoving, Jeroen (mentor); Veljkovic, Milan (mentor); Gonzalez Garcia, Yaiza (mentor); Delft University of Technology (degree granting institution)","2019","In order to connect a monopile to a transition piece of an offshore wind turbine efficiently, a new connection method called the Slip Joint is being developed. The Slip Joint is made out of a conical section at the top of the monopile foundation and a conical section at the bottom of the transition piece which are slid over each other to form a connection. Van Oord is currently getting the Slip Joint connection certified by DNVGL, requiring that the structural integrity must suffice during the total lifetime. Offshore with harsh salty conditions, corrosion important to be aware of. The interface between the cones of the Slip Joint creates a local environment with crevices that has a unknown corrosion behavior. Because it is necessary to know the corrosion behavior within the Slip Joint, the following research question has been formulated: What corrosion behavior can be expected in offshore submerged Slip Joint crevices?<br/>Because research towards steel crevices of large geometries was not carried out before, a test method had to be developed. This required multiple innovative methods, and thus trial tests to confirm the feasibility of the test method. Chosen is to use specimens with multiple crevice geometries and test them during a 60 days immersion test. In total 260 steel plates and 37 different crevice geometries have been studied on their corrosion behavior. To monitor the corrosion behavior during the test period, open current potentials have been measured. After the test period the specimens were cleaned and weight losses have been measured. With the weight loss measurement, the corrosion rate of each specimen has been calculated. Additionally to testing the corrosion behavior in crevices, the usability of Impressed Cathodic Corrosion Protection on a crevice is tested by applying a current on the specimens using a potentiostat.<br/>The data of the tests show that the test was carried out in a consistent manner and that the test method gives reproducible results. The test indicate that local corrosion attack in the crevices of the Slip Joint can occur and that the corrosion behavior is correlated with the crevice geometry. A model has been formulated which can be used to estimate corrosion rates in crevices for design purposes.","Corrosion; Slip Joint; Crevice; Offshore","en","master thesis","","","","","","","","2024-08-30","","","","","",""
"uuid:229b0db1-06e9-4cbd-9e90-e2e16bd162bb","http://resolver.tudelft.nl/uuid:229b0db1-06e9-4cbd-9e90-e2e16bd162bb","Formal verification of upper bounds on translative packing densities","Mulder, Ike (TU Delft Electrical Engineering, Mathematics and Computer Science)","de Oliveira Filho, Fernando (mentor); Aardal, Karen (graduation committee); Hart, Klaas Pieter (graduation committee); Delft University of Technology (degree granting institution)","2019","Packing problems are concerned with filling the space with copies of a certain object, so that the least amount of space stays unoccupied. The famous Kepler conjecture asserts that the cannonball packing of spheres is the most efficient packing achievable, and was recently formally proven by Hales.<br/><br/>Dostert, Guzman, Oliveira Filho and Vallentin investigated the packing problem for other shapes. They focused on translative packings, in which all objects are oriented in the same direction. They proved several new upper bounds on translative packing densities of various Platonic and Archimedean solids. However, their results rely heavily on complex computer calculations to ensure they satisfy the conditions of a theorem.<br/><br/>In this thesis, proof assistant Coq is used to formally verify these conditions. An introduction to Coq is provided, aimed at the working mathematician. Then, the theorems required for the proof are developed. Several results from multivariate calculus and convexity were required for the proof, but not available in Coq. The proof also requires a large amount of floating point calculations. A method is developed to efficiently perform floating point calculations on a large scale in Coq.<br/><br/>Using the developed techniques, the improved upper bound of Dostert et al. on the translative packing density of the truncated tetrahedron is formally verified. These techniques can be reused to formally verify the other improved upper bounds of Dostert et al.","Formal verification; Packing densities; Tetrahedral symmetry; Truncated tetrahedron; Coq; Proof assistant","en","master thesis","","","","","","","","","","","","","",""
"uuid:6011234f-ce54-43f2-b254-0f8d65747291","http://resolver.tudelft.nl/uuid:6011234f-ce54-43f2-b254-0f8d65747291","Simulating smart charging optimization for electric vehicles: A quantification and statistical analysis of the cost reduction and emission reduction potential of an aggregated Dutch EV fleet","Paanakker, Marnix (TU Delft Electrical Engineering, Mathematics and Computer Science)","Ghotge, Rishabh (mentor); Westerhof, Oscar (mentor); van Wijk, Ad (graduation committee); Nane, Tina (graduation committee); Homem de Almeida Correia, Goncalo (graduation committee); Delft University of Technology (degree granting institution)","2019","The objective of this research is to understand what smart charging can bring business and society at large. In close collaboration with the largest fleet operator in the world and a commercial aggregator, the impact of smart charging on both cost reduction and carbon reduction was simulated for an electric vehicle (EV) fleet in 2018. The simulation is designed to quantify the cost reduction of EV smart charging in The Netherlands as realistic as possible. Besides cost reduction quantification, the objective is to create a better understanding of what variables influence smart charging cost reduction. This is done via a statistical analysis of the smart charging simulations output. Furthermore, this research also has the objective find the direct impact of smart charging on carbon intensity of the electricity used for personal transport.<br/>In this research, an EV aggregators perspective is leading. The EV aggregators could utilizing available flexibility in an EV fleet to deliver flexibility services. The strategy chosen to simulate is based on day ahead market optimization and passive balancing on the imbalance market. The EV fleet is assumed to be an isolated portfolio handled by the balance responsible party (BRP). The average synthetic load profile over 2018 was €41,56 per MWh and this is used as benchmark to quantify the smart charging savings in the simulations. <br/> Different smart charging simulation set-up scenarios are designed and executed. In all simulations a real-world charging data set with 300.000 historic charging sessions was used. For each session, a new smart charging profile is determined by the optimization algorithms. The session price and session carbon intensity is calculated for both the smart charging scenarios as the business-as-usual scenarios. To compare the results of the different smart charging set-up scenarios, the average session price of all session in that simulations is used. At the same time, the smart charging savings is calculated based on the defined benchmark. The findings within this thesis support the conclusion that the used smart charging algorithms work properly and could decrease the electricity purchase price in The Netherlands. Additionally we found that the carbon intensity of the charged electricity during the smart charging schedule decreases compared to a business as usual scenario. This is a direct result of a correlation between the carbon intensity in the grid and day ahead prices in The Netherlands. EV aggregators are able to add flexibility to the demand side of the electricity system by means of smart charging, if a strong price incentive is provided. If stakeholders across the mobility and the energy sector work together, a real-world commercial implementation based on the price incentives on day ahead market and imbalance market in The Netherlands is possible. In the statistical analysis, multiple regression models show a linear relation between three independent variables (the session duration, session volume and maximum power of the charge point) and two dependent variables (the average session purchase price and savings per session). The key insights from the models empowered three main recommendations to EV aggregators to optimize the smart charging savings in the future: 1) Encourage longer session length. 2) Encourage regular overnight charging sessions behaviour, independent from the charging needs. 3) Stimulate access to high charging power. The data showed compelling differences between the 20% BEVs and the 80% PHEVs and their results were separated accordingly in this research. In all simulation set-up scenarios are the PHEVs outperforming the BEVs in terms of a lower average session price and higher cost reduction. If the smart charging strategy is executed as proposed in this thesis, the EV aggregator is exposed to the day ahead market and imbalance settlements for its portfolio. The EV aggregator is able to decrease the electricity purchase price, while acting as BRP. The exposure to the markets brings significant risk. Collaboration with an electricity supplier or BRP could potentially increase the smart charging savings for the EV aggregator. Furthermore, other revenue streams to utilize flexibility could be investigated. If stacking different flexibility strategies is possible, it could increase the smart charging value in the future.","Electric Vehicle; Smart Charging; optimization algorithms; Aggregator; carbon reduction; cost reduction; flexibility","en","master thesis","","","","","","","","2023-09-01","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:0ad25d1e-ecc4-47d3-b5f4-35086fba1652","http://resolver.tudelft.nl/uuid:0ad25d1e-ecc4-47d3-b5f4-35086fba1652","Exploring fairness in visual employment contracts","Montella Lavin, Andrea (TU Delft Industrial Design Engineering)","Baha, Ehsan (mentor); Wijntjes, Maarten (mentor); Beleen, Lieke (mentor); Delft University of Technology (degree granting institution)","2019","The current thesis explores the impact that the use of visual contracts has from the fairness perspective. The project developed in collaboration with the company Visual Contracts, a start-up specialized in Legal Design Thinking, aims to provide an added value and evidence that supports the relevance of their activity. A design process that combined research with a practical approach was the chosen approach for the development of the project. The project focused on the context of employment contracts due to its big social relevance and its potential for business opportunities. Several conflicts which seriously compromise the well-being of the parties, the employer and the employee, arise as a consequence of misunderstandings in the employment contracts. To prevent these conflicts and to offer and added value to the company Visual Contracts, the exploration of the impact of visual contracts is addressed from the fairness perspective. Three design cycles were pursued during this thesis. The first cycle, had as a goal to create an in-depth understanding of the project scope (contracts, understandability, and fairness) and to design the first visual contract. The second cycle was focused on improving the user experience and the implementability in the real context. Finally, the third cycle aimed to detail the visual contract and validate it in the real context. Along this process, a combination of desk and empirical research with the stakeholders of contracts, was conducted to gain more understanding of the scope of the project. It was also developed a framework which aimed to ease the creation of fair employment contracts and set the basis for a good relationship between the parties. Finally, one contract was designed on each cycle and afterwards tested to generate knowledge and insights for improvement. The final result iterated from an initial interactive document to a platform where the user can perform all the tasks related to their hiring and onboarding process, from reading the contract to uploading the necessary documents for the formalities. The results of the project provided the company Visual Contracts with a business opportunity in the context of employment contracts, along with evidence and tools for the further development of this project. As an overall conclusion, it was stated that the use of visual contracts contributes to fairness and generates a positive impact by improving understandability and fostering evaluation. The impact is demonstrated in the following way: visual contracts support and empower the stakeholders during the decision making process and negotiation of the agreement, they improve the relationship between the parties, by fostering trust and open communication, and finally, they prevent conflicts and set realistic expectations.","Contracts; Legal Design; User Experience; Law; Employment; Design","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:3ee232d0-17aa-4f95-92cb-d1a9453cfe7c","http://resolver.tudelft.nl/uuid:3ee232d0-17aa-4f95-92cb-d1a9453cfe7c","Semio.Soles: A Smart Garment for Covert Police Operations","Balk, Otmar (TU Delft Industrial Design Engineering)","Sonneveld, Marieke (mentor); Petreca, Bruna (graduation committee); Delft University of Technology (degree granting institution)","2019","This project is an exploration of the application opportunities for the next generation of smart textile products in the niche context of high-pressure police operations. This target group is chosen as the current communication media enable concrete and clear communication, but are also bulky and obtrusive, to the extent that they are visible and distinguishable to the attentive criminal or bystander. Yet, their line of communication is paramount for a good result, i.e. clear and concise communication at all times are critical factors during operations. Both the context and timeline of observation operations are researched, as well as the current state of smart textiles in modern society. As conclusion of the research, a future vision of smart textiles is formulated and a design space for ideation is outlined. The goal of the product is to re-establish a connection between covert agents in situations where conventional communication (visual or auditive) is not possible. Semio.Soles is a product concept that enables observation agents to notify their colleagues that they are ok, while operating in a no-contact situation. Agents can send basic status information about themselves and the situation that they are in, to other agents that are on standby in the vicinity. This helps agents standing-by to maintain situation awareness of a situation that they are not in and cannot see or hear.<br/>Concluding the project, a final evaluation is done and recommendations for future development and research are formulated.","covert operation; hapticshoe; Semio.Soles","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:76393137-cadf-4f0f-8e2b-9a5676e85d91","http://resolver.tudelft.nl/uuid:76393137-cadf-4f0f-8e2b-9a5676e85d91","Process standardization in the construction industry: An explorative study into the right balance between standardization and flexibility","Peponi, Nefeli (TU Delft Civil Engineering and Geosciences; BAM � Royal BAM Group nv)","Bakker, Hans (mentor); Lousberg, Louis (graduation committee); Liu, Yan (graduation committee); Delft University of Technology (degree granting institution)","2019","Today’s rising project complexity in combination with the changing economic environment has led to an increased interest in improving organizational business processes. Large multinational companies were always affected by those two factors in a greater extent than other smaller more localized competitors, rendering process reengineering an indispensable need for their continuous thrive. Determining best-practice approaches and integrating scale and knowledge into business process management may improve business performance by reducing error potential. This could be achieved through process standardization according to best-practice approaches. However, the proclaimed uniqueness of construction projects in combination with the numerous uncertainties that the industry is facing is rendering process standardization in the construction industry more complex. This research aims to explore the implications, opportunities and barriers of standardization in the construction industry and the implementation of previously gained knowledge – marked as best practices.","process standardization; construction industry; critical factors; perspectives","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:a7b5241d-5002-446f-bd23-b69c78549ea8","http://resolver.tudelft.nl/uuid:a7b5241d-5002-446f-bd23-b69c78549ea8","Real-time Lipreading: Effects of Compression and Frame-rate","Maan, Riya (TU Delft Electrical Engineering, Mathematics and Computer Science)","Broekens, Joost (mentor); Delft University of Technology (degree granting institution)","2019","Speech recognition systems can be found all around us. From personal assistants in mobile phones and smart speakers to robots, we use speech recognition systems everyday. However, communicating with them can be troublesome in noisy environments because they only use audio signals for speech recognition. This problem can be solved by using visual speech recognition or lipreading systems. Research on lipreading systems has been going on since the 1980s but such systems are not being used in real-time systems yet. This can be attributed to the fact they need to process significantly higher amounts of data than audio speech processing which takes a lot of time and hence, they cannot be used in real-time. This thesis aims at finding out if frame rate, jpeg compression or presence of noise have any impact on the performance of lipreading system. The LipNet system is used for this thesis and the Lip Reading in the Wild (LRW) dataset is used for the purpose of experiments. The frame rate of videos of the dataset is varied from 11 to 25, with an increment of 2 for each experiment. Also, compression ratio is varied between no compression and 30 % quality, to find out how compression affects the performance of lipreading systems. Also, salt and pepper noise is artificially added to the dataset for the purpose of experiments. The results from the experiments showed that performance is not affected till frame rate 21, but it starts degrading gradually from frame rate 19 to 13 and after that there is sudden drop in the accuracy of LipNet. With compression of frames to 30 percent of their original quality, there is only a slight decrease in accuracy. However, there is a huge reduction in data size, which makes it easier to transmit data for cloud processing. We found substantial degradation in performance with the presence of noise with a probability of only 3 percent.<br/>This means that if we decrease frame rate to 21 and compress the frames to 30 % quality, memory usage can be decreased to 25 % without much impact on performance of the system. However, quality of video capturing cameras and data transmission to cloud needs to be monitored to avoid noise.","Lipreading; AVSR; deep learning","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:17569a32-8763-4a5a-95d4-a75b776c8276","http://resolver.tudelft.nl/uuid:17569a32-8763-4a5a-95d4-a75b776c8276","Sitting Up System: A novel concept for large integrated offshore wind turbine installation","Groen, Maarten (TU Delft Mechanical, Maritime and Materials Engineering)","Metrikine, Andrei (mentor); Hoving, Jeroen (graduation committee); Lanser, Jan (graduation committee); Delft University of Technology (degree granting institution)","2019","It is expected by the EWEA that in the North Sea only the wind energy capacity will increase to 45 GW. In 2015 the capacity was only 5.2 GW. Offshore contractors should be capable of installing lots of turbines and just that is a problem. As turbines increase in size installation vessels need significant upgrades. Therefore, most contractors look for cheaper and better solution for installing these large offshore wind turbines. The Sitting Up System or SUS is a new concept designed by Marine Innovators B.V. and installs fully assembled wind turbines with their foundation. It decreases offshore installation time and decreases operational cost significantly.<br/>The SUS is designed to transport and upend wind turbines to a vertical position while anchored to the seabed. For now, the SUS is a concept and has multiple design possibilities, using either a hydraulic or a buoyant lifting system. Analysis on these lifting methods and their operational functionality resulted in a buoyant type lifting system. The SUS 3: 'Buoyant upend 2' concept consists of latticed structure and two buoyant modules. The large module is sunk to anchor the SUS and the small buoyancy module is pulled along the lattice to create an upending moment.<br/>Using the software Matlab the upending motion of SUS 3 is modelled as a rigid body to find limiting wave conditions. The model uses second order stokes theorem and Jonswap to simulate waves on the structure. Loads on the structure are calculated using the Morison equation. Two DOFs are considered as the SUS can rotate around a hinge at the seabed and move the buoyancy module. <br/>In the simulation a wind turbine of 200 meters height is upended in 30 minutes, while operating at 40 meters water depth. The first phase of the upending wave loads is most critical. The criteria for the SUS to operate depends on the acceleration of the top tower assemble of the wind turbine, these cannot exceed 0.1 g. In this case the limiting sea state is a Hs of 1 m with a Tp of 4.5 s, leading to a workability of about 16 percent. During the beginning stages of upending the natural frequency of the system operates around 10 seconds. This is critical as waves oscillate near this frequency. Though the simulation does not account for radiation or diffraction, the performance in later stages of upending gives a better result. Here, it can operate with a Hs of 2.5 meters resulting in a workability of 75 percent. <br/>The SUS 3 is anchored with spudcans during upending and shear loads are most significant. These spudcans can experience a shear load of 24 MN, when considering a Hs of 3.5 with a Tp of 8.5. Therefore, anchoring method should be designed such that it can comprehend these shear loads more efficiently. <br/>The work done by the winches pulling the buoyancy module is 13 percent more than the potential energy gained after upending with no waves. When waves are applied, energy is gained due to the uplifting force of waves. As the structure is lifted, resistance of pulling the buoyancy module decreases and can move more efficiently. Considering a Hs of 1.5 m and a Tp of 5.5 s will results in an energy gain of 5 percent. Therefore, this method is quite efficient in upending wind turbines offshore.<br","Offshore energy; Wind Turbine; Dynamic modelling; Concept Design; Installation design","en","master thesis","","","","","","","","2024-07-30","","","","Offshore and Dredging Engineering","",""
"uuid:5707afdb-96bb-4aa9-a654-05f65a535b62","http://resolver.tudelft.nl/uuid:5707afdb-96bb-4aa9-a654-05f65a535b62","Participation for a people–centered Delft: Enabling the municipality of Delft to design people–centered cities with the local communities using participatory approaches","Shah, Ashni (TU Delft Industrial Design Engineering)","Mulder, Ingrid (mentor); Guerreiro Goncalves, Milene (graduation committee); Delft University of Technology (degree granting institution)","2019","This graduation project is a collaboration between the Inclusive City Hub (part of Delft Design Labs) and the Gemeente Delft. This project focuses on the topic of participation for creating people–centered cities. The initial problem definition of the project was to understand how the municipality of Delft can design with the people of the city by moving towards a participatory approach such that they can address the needs of people at optimal moments during the process. <br/><br/>Based on the analysis and findings from research the problem addressed by this project was redefined. The redefined problem was how can we reduce the threshold of the municipality to embrace and adopt participation as a part of their daily way of working. From this question the two problem areas to be addressed were defined as; one, a lack in ability of the municipality to act on participatory frameworks and two, a lack of willingness of the municipality to make participation a part of their culture. <br/><br/>The resulting solution and final outcome proposed was to design a sensitizing participation journal or booklet for use by the people working in the municipality. The main goal of this journal is to equip folks at the municipality to act on the participatory framework of Delfts Doen by means of the tools provided in it. The journal also hopes to inspire and sensitize the municipality about participation, paving the way to increase the willingness and bring about a culture change in the municipality regarding participation. <br/><br/>To conclude, the challenges with participatory design lie in the adoption of a new mindset within large organizations such as municipalities, since this mindset strongly challenges the existing power structure and hierarchy within an organization. It is expected that the findings of this thesis can contribute to this knowledge by building on how these challenges can be overcome by focusing on the needs that must be fulfilled for people working in organizations such as municipalities.","Participatory design; Social Design; inclusive city; User-centered design; Social design intervention","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:acf934e3-ceeb-49ba-b98e-11f384324aea","http://resolver.tudelft.nl/uuid:acf934e3-ceeb-49ba-b98e-11f384324aea","Prediction of Fuel Consumption of Long Haul Heavy Duty Vehicles using Machine Learning and Comparison of the Performance of Various Learning Techniques","Bhoraskar, Akshay (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Cognitive Robotics)","Pan, Wei (mentor); Wisse, Martijn (graduation committee); Knoop, Victor (graduation committee); van Eijk, Emiel (graduation committee); Delft University of Technology (degree granting institution)","2019","This study aims at a possible solution to predict the fuel consumption of heavy duty diesel trucks, particularly, the tractor semitrailer for their long haul operations using various machine learning techniques. It intends to provide a possible alternative to simulation or physics based models, which often are very complicated. The stringent laws on emission control set by the Paris Agreement and the fact that heavy duty trucks contribute to almost 27% of CO2 emissions from road transport and their dependence on diesel for operations (in long haul) makes it the need of the hour to first, have an estimate on the emissions being produced and second, to develop technologies to reduce those emissions. <br/><br/>This study focuses specifically on the first part i.e., estimating the amount of fuel consumed by heavy duty trucks in the European Union and thereby determine the emissions being produced. The main objective is to examine whether an approach of machine learning could be a viable option to predict fuel consumption. This thesis is part of the AEROFLEX project and was done in collaboration with TNO, which provided all the data-sets required for the study.<br/><br/>The idea was to explore the regime of machine learning for one time step ahead prediction of fuel consumption. Furthermore, this study also focused on the development of another model by not using any variables affected by the driver as input into the training model. This exclusion was necessary to make sure the model remained adaptive to new routes and new trucks, especially because large scale on-road testing of the newly developed trucks is impossible and also because this way would help predict the fuel consumed by a truck without the necessity of it driving on a road. The study concludes with a comparison with an existing simulation model at TNO and provide an alternative machine learning solution. It also provides a comparison between different machine learning techniques and suggest the most accurate one. <br/><br/>It was found that machine learning could potentially be used to predict the amount of fuel consumed by a long haul heavy duty truck driving on a motorway. It was also found that engine torque was the variable that affected the fuel consumption of the truck the most. Furthermore, Neural Network was the most potent algorithm among all the other learning techniques for both the models developed in this study with it performing better than the simulation tool by a factor of approximately 3.8 in the model where the driver/drive influenced inputs were not considered in the training data-set. The results obtained from this work at a sampling frequency of 10 Hz. (i.e., 0.1 seconds) are comparable to the ones reported by other sources at a sampling rate of 0.016 Hz. (i.e., 1 minute) or 0.0016 Hz. (i.e., 10 minutes). This goes on to say that the machine learning algorithms are also potent at much higher sampling frequencies.<br","Fuel Prediction; Machine Learning; Heavy duty vehicles","en","master thesis","","","","","","","","","","","","","",""
"uuid:59001df2-9b47-47c2-bfbe-d1c016902795","http://resolver.tudelft.nl/uuid:59001df2-9b47-47c2-bfbe-d1c016902795","S-Net, A Neural Network Based Countermeasure for AES","Venkatachalam, Pradeep (TU Delft Electrical Engineering, Mathematics and Computer Science)","Taouil, Mottaqiallah (mentor); Hamdioui, Said (graduation committee); van Leuken, Rene (graduation committee); Delft University of Technology (degree granting institution)","2019","Hardware implementations of encryption schemes are unprotected against side-channel analysis techniques. Physical realizations of secure algorithms leak side-channel information through power, noise, time, sound and electromagnetic radiation. Data-dependent correlations with this leakage are exploited to obtain secret information. Power analysis techniques are powerful, undetectable and non-intrusive attacks that allow an adversary to extracts the secret key of the encryption scheme. These techniques rely on analyzing the power consumed by these physical realizations using leakage models and statistical techniques. <br/><br/>Implementing a countermeasure against power analysis attacks require a thorough understanding of the attack, encryption algorithm and it's implementation on hardware and software. Conventional countermeasures for AES against power analysis techniques minimize the side-channel information by implementing masking and hiding strategies at different abstraction levels. This thesis investigates a new class of countermeasures known as ""breaking"" through the implementation of the Substitution Box transformation using a neural network (S-Net). The inherent properties associated with the neural network architecture is expected to remove the correlation between the power consumed and the secret key used for encryption by breaking the linear power characteristics assumed by the leakage model. <br/><br/>The proposed approach was implemented in software and an attack framework is used to run side-channel attacks and quantify information leakage. The effectiveness of the implemented countermeasure is measured by checking and quantifying it's security against Differential and Correlation Power Analysis, Template and Deep Learning based techniques. The results indicate that the implementation is secure against these attacks. <br/><br","Side-Channel Attacks; Hardware Security; Cryptography","en","master thesis","","","","","","","","2019-12-31","","","","","",""
"uuid:1c3bce83-ef64-43bc-becc-dcd5672bd0d9","http://resolver.tudelft.nl/uuid:1c3bce83-ef64-43bc-becc-dcd5672bd0d9","Modeling Artificial Personalities through the Expression of Emotions in Narrative Games","Otte, Marijn (TU Delft Electrical Engineering, Mathematics and Computer Science)","Broekens, Joost (mentor); Bidarra, Rafa (graduation committee); Jonker, Catholijn (graduation committee); Delft University of Technology (degree granting institution)","2019","Personality modeling is important in order to create character variation in<br/>games. Character variation favors replayability and is an important aspect<br/>of game design. The eect of articial personalities through the expression of<br/>emotions is evaluated in this research. To do so, a prototype game is developed<br/>in the context of training in bad news conversations. Replayability through<br/>character modeling is important in a game in which people can train to deliver<br/>bad news. By training with multiple personalities one can learn to deal with<br/>the dierent reactions that people can give. In this thesis, the eect of arti-<br/>cial personalities through the expression of emotions on the replayability of the<br/>game, believability of the non-playing character and immersion of the player is<br/>researched. It is expected that articial personalities have a positive eect on<br/>the replayability of the game and believability of the non-playing character, but<br/>not on the immersion of the player. Experiments show that there is a positive<br/>trend in the replayability of the game and the believability of the non-playing<br/>character.","personality; emotion; narrative; games; modeling; dialog; believability; replayability; immersion; bad news","en","master thesis","","","","","","","","","","","","","",""
"uuid:32b0ddaf-b27c-4de2-97b6-a14d93d60426","http://resolver.tudelft.nl/uuid:32b0ddaf-b27c-4de2-97b6-a14d93d60426","Explore the untapped digital data of neglected tropical disease, and provide insights for stakeholders to take strategic actions","Dai, Jiun-Tyng (TU Delft Industrial Design Engineering)","Diehl, Jan-Carel (mentor); Bourgeois, Jacky (graduation committee); Delft University of Technology (degree granting institution)","2019","People have been using the digital technology domain to seek solutions to combat neglected tropical diseases. Aside from feasibility and effectiveness, WHO has pointed out the importance of having an overview that pinpoints the lacking infrastructure for scaling up and sustaining digital proposals. This research demystifies the untapped digital data in combating neglected tropical disease and aims to provide an overview for people to take strategic action. Who are all the stakeholders in this elimination procedure? What are the needed data to tackle this disease? How can digital innovation best interfere with the current disease elimination flow?<br/><br/> The researcher has chosen the content of Kenya and the neglected disease of Schistosomiasis as the subject. Building on numerous expert interviews and the literature review, the footprint of disease combating related data has been systematically analyzed from different angles. With a holistic view, this series of analyses poses as a step-by-step guide for the strategic planning of complicated neglected disease or health-related issue in low-resource setting countries. An example of a new Schistosomiasis diagnostic device, SODOS, is presented at the end to showcase the effectiveness of the analyzing approach.<br","Neglected tropical disease; Schistosomiasis; Low resource settings; Digital data; Data footprint; Strategic action; Sustainable interventions; Scalable impact; Kenya","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:94823249-e114-4fc0-bae9-4c80d503296f","http://resolver.tudelft.nl/uuid:94823249-e114-4fc0-bae9-4c80d503296f","Quantum Error Correction: Decoders for the Toric Code","Leijenhorst, Nando (TU Delft Applied Sciences; TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Analysis)","Caspers, Martijn (mentor); Elkouss Coronas, David (mentor); Ruszel, Wioletta (graduation committee); Blaauboer, Miriam (graduation committee); Delft University of Technology (degree granting institution)","2019","Quantum error correction is needed for future quantum computers. Classical error correcting codes are not suitable for this due to the nature of quantum mechanics. Therefore, new codes need to be developed. A promising candidate is the toric code, a surface code, because of its locality and its high error correcting capability and thresholds (the error probability below which increasing the size of the code decreases the failure rate). This thesis provides an introduction to quantum error correction and the stabilizer formalism, which is used to introduce the toric code. Several decoders are looked at, including the Minimum Weight Perfect Matching (MWPM) decoder and a recently developed decoder, the Union-Find (UF) decoder. The UF decoder is useful because of its almost-linear time complexity, while only reducing the threshold by a marginal amount compared to the MWPM decoder. In this thesis, the time complexity of the weighted growth version of the UF decoder is analysed. The toric code and the decoders have been implemented and simulated, and the thresholds have been determined. For the MWPM decoder, the threshold was determined to be 11.5±0.2%, which is not in agreement with the threshold in literature of 10.3%, and should not be possible according to the optimal threshold of about 11%. This probably is a result of the low grid sizes (up to a gridsize of 11) of the code used due to the time needed to simulate the MWPM decoder. For the UF decoder, the threshold found was 9.7 ± 0.9%, which is in agreement with the threshold of 9.9% found by N. Delfosse and N. Nickerson. The time complexity of the UF decoder has also been determined, and is indeed almost-linear as expected by the analysis.","Quantum Computing; Quantum Error Correction; Quantum Mechanics","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics | Applied Physics","",""
"uuid:810db9a6-9718-4451-8f8f-67ad0cdccad9","http://resolver.tudelft.nl/uuid:810db9a6-9718-4451-8f8f-67ad0cdccad9","Enhancing Consumer Product Repairability: A case study on vacuum cleaners","De Fazio, Francesco (TU Delft Industrial Design Engineering; TU Delft Design Engineering)","Bakker, Conny (mentor); Flipsen, Bas (mentor); Delft University of Technology (degree granting institution)","2019","The European Commission pointed out in 2015, with “An EU action plan for the Circular Economy”, the importance of energy and resource preservation, by respecting Earth’s resilience and renewability (European Commission, 2015). A transition towards Circular Economy is necessary in this sense to create new sustainable advantages, protecting businesses from future potential resource scarcity and boosting the economy. In order to enable this transition, the way products are designed must change by taking into account product life-extension, reuse, refurbishing and recycling. In recent years, Philips has expressed a growing interest in circular economy, becoming global partner of the Ellen MacArthur foundation (Ellen MacArthur Foundation, 2017), and setting the target “Healthy people, sustainable planet”, committing itself to reach 15% of turnover coming from solution respecting circular principles by 2020 (Philips.com, 2016). This pushed the company to investigate the current state of their product portfolio and new ways of designing consumer goods. In this sense, product repairability and disassembly represent some of the most important design requirements in order to enable circular business models. Carried out in collaboration with the company, this research project practically investigates design features which influence positively and negatively product repairability, eventually proposing new design guidelines and methodologies for design for repairability and product retirement. The European Commission Joint Research Centre released in 2019 a Scoring Assessment System for Repair and Upgrade of Products (Cordella et al., 2019). This system has been applied on seven consumer products, part of the vacuum cleaners product group, assessing more than 260 disassembly operations. Firstly, insights gathered during this analysis have resulted in a list of practical design recommendation for the manufacturer and remarks on the assessment system itself. Additionally, a new design tool for product architecture mapping, called Disassembly Map, was created. This is an effective method to represent the architecture of a product, showing disassembly depth of all the product components and the intricate logic connections which link them to each other. The most important components for product repairability and retirement are spotted using special indicators, guiding the attention of designers towards these products’ “hot-spot”.This design tool, together with the insights collected from the repairability assessment, were tested by redesigning a representative consumer product, together with the Philips I&amp;D department. During this process, the following design methodologies have been explored: Redesign for disassembly time optimization through clumping methodology, Redesign for hotspot components accessibility through bottom-up assembly, Redesign for legislation compliance and use of common tools and Redesign for sequential independent disassembly and safer self-repairs. The results achieved convinced the manufacturer to define together new serviceability design requirements, which will be implemented in the development of future Philips canister vacuum cleaners. This research concludes suggesting new assessment values for a discrete rating system of canister vacuum cleaners, which could be used by the European Commission Joint Research Centre for possible future iterations of the Scoring System for Repair and Upgrade of Products.","Consumer Products; Repairability; Disassembly; Circular economy; Product architecture; Disassembly Map","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:339a8ea1-a297-49d2-9dd9-1da60b43b9fc","http://resolver.tudelft.nl/uuid:339a8ea1-a297-49d2-9dd9-1da60b43b9fc","A low-noise amplifier for ultrasound imaging with continuous time-gain compensation","Jiang, Qiyou (TU Delft Electrical Engineering, Mathematics and Computer Science)","Pertijs, Michiel (mentor); Alavi, Morteza (graduation committee); Vollebregt, Sten (graduation committee); Kang, Eunchul (graduation committee); Delft University of Technology (degree granting institution)","2019","This work presents a low-noise amplifier (LNA) for ultrasound imaging with built-in continuous time-gain compensation (TGC), which compensates for the time-dependent attenuation of the received echo signal and thus significantly reduces its dynamic range (DR). The proposed design combines the LNA and TGC functions in a single variable-gain current-to-current amplifier. Compared to conventional ultrasound front-ends, which implement the TGC function after an LNA that needs to handle the full DR of the echo signal, this approach can highly reduce the power consumption and the size. Compared to earlier programmable-gain LNAs with discrete gain steps, the continuous gain control avoids switching transients that may lead to imaging artefacts. The TGC function is realized by a novel feedback network consisting of a double differential pair that feeds a fraction of the output current back to the input. This fraction can be changed continuously using a control voltage that is applied to the gates of the differential pairs, to realize a gain range from -20 dB to +20 dB. To achieve an approximately constant closed-loop bandwidth in the presence of the changing feedback factor, a loop amplifier has been implemented whose gain is changed along with the feedback factor by dynamically changing its bias currents. This loop amplifier employs a current-reuse architecture to achieve high power-efficiency. In addition, a variable bias current source has been designed to appropriately bias the TGC feedback network. By employing a similar double differential pair topology as in the feedback network, this current source provides the required low noise at the highest gain setting and high current at the lowest gain setting within the available headroom. The LNA with built-in TGC function has been realized in 180nm CMOS technology. It has been optimized to interface with a 7.5 MHz CMUT transducer. Simulation results show that it achieves a 3dB bandwidth higher than 40 MHz across the full gain range. At the highest gain setting, its input current noise is 0.96 pA/sqrt(Hz). This leads to an input dynamic range of 93 dB, which is compressed into an output dynamic range of 53 dB by means of the 40 dB variable gain. The amplifier consumes 10.8 mW from a 1.8V supply, and occupies an estimated 302 x 320 um2 die area.","Ultrasound ASIC; low-noise amplifier; time-gain compensation; current-steering differential pair; variable bias current source","en","master thesis","","","","","","","","2020-09-01","","","","Electrical Engineering | Microelectronics","",""
"uuid:20e84104-201e-42b5-a67e-a91b6f9c5557","http://resolver.tudelft.nl/uuid:20e84104-201e-42b5-a67e-a91b6f9c5557","Computational Method for Early-Stage Design Optimization of Naturally Ventilated Terminals","Türkcan, Okan Fehmi Saban Fred (TU Delft Architecture and the Built Environment; TU Delft Architectural Engineering +Technology)","Nourian, Pirouz (mentor); van den Engel, Peter (graduation committee); Tenpierik, Martin (graduation committee); Delft University of Technology (degree granting institution)","2019","This thesis focuses on the development of a computational model for early-stage design decision support of naturally ventilated terminal structures. The model is developed in a parametric Rhino Grasshopper environment paired with Python coding and CFD analyses through OpenFOAM. Optimization of air distribution parameters is performed with Galapagos evolutionary solver, while optimization of the subsequent geometry is done manually by means of the CFD results of the best-performing variant. Within the thesis a background study is made by means of an interview and literature review, after which analytic calculations and CFD studies are used to test various options and narrow down the domain of solutions for the case of the design of a naturally ventilated terminal structure. Finally, the method itself is developed and validated with a case study that is also used during the development of the model. The result of the thesis is a rapid computational model that allows for the integration of CFD studies into the early-stage design of naturally ventilated terminals with an optimization for the stated objective function. Secondly, the CFD results can be used to give an indication of a more optimal geometry of the hall. The final selection of geometry and the validation are left up to the user to perform afterwards.","optimization; CFD; parametric; airport; natural ventilation; thermal buoyancy; ground duct; air distribution; genetic algorithm; Evolutionary Algorithms; evolutionary solver","en","master thesis","","","","","","","","","","","","","",""
"uuid:200f1df0-adda-47a1-894c-baf54133035a","http://resolver.tudelft.nl/uuid:200f1df0-adda-47a1-894c-baf54133035a","Designing the future identity: authentication and authorization through self-sovereign identity","Gerard, Valentin (TU Delft Electrical Engineering, Mathematics and Computer Science)","Epema, Dick (mentor); Delft University of Technology (degree granting institution)","2019","The apparition of the Internet was a revolution that allowed to connect people all around the world. It was a disruptive technology that helped to shape the modern society as we know it today. However, to trust a person we interact with but we are not able to see is difficult. In order to trust people in this huge network, different digital identity models have been built to attempt to authenticate its users. Still, as the technology and our use of it evolved, the complexity of digital identity increased and problems started to appear. The two main problems are the aggregation of personal information in the databases of powerful IT companies and the user experience that is more complicated than it should be. Those two problems are linked and are caused by identity models that were not designed in a user-centric approach. Each organization uses its own identity system to authenticate their users, which causes the fragmentation of the user’s digital identity that have to register and create identity for all the organizations he is interacting with. Self-sovereign identity is an emerging identity model that makes use of distributed ledger technologies and cryptography to solve these problems. The goal of this model is to return digital identities in the hand of users by placing them at the center of the model. Unifying all their personal information under one identity would greatly improve their experience and help them to have a better control on how it is used by the organizations they’re interacting with. In our first research question, we first examine if the self-sovereign architecture can provide an identity that can be trusted by people and organizations alike. We found that the trust that we can accord to this model is highly related to our capacity to safely manage the different cryptographic keys that are used to secure wallets where user’s information is stored and to secure the communication channels between the different identity owners. The storage of these keys is the subject of our second research question. To understand better the mechanisms, we implement a prototype using the Hyperledger Indy blockchain to discover how these keys and the credentials associated to the digital identity are stored and managed in this ecosystem. We then use the prototype to authenticate a user and make use of its credentials to authorize or deny the access to specific resources on the system to make the link with identity and access management in our third research question.","Identity; Blockchain Use Cases; Distributed Systems","en","master thesis","","","","","","","","","","","","","",""
"uuid:0eb7f833-9be5-4482-b2a7-64ac8a2c230e","http://resolver.tudelft.nl/uuid:0eb7f833-9be5-4482-b2a7-64ac8a2c230e","Design Space for Heat Network Systems: Learning from the Electricity, Gas, Water and Wastewater Network Systems","Sharma, Abhinav (TU Delft Technology, Policy and Management)","Stikkelman, Rob (mentor); Correlje, Aad (graduation committee); Delft University of Technology (degree granting institution)","2019","As a move away from the natural gas based heating, the Dutch government identified district heating networks as most economical alternative to the natural gas. However, the future plans for the district heating sector have faced challenge on the question of the design of heat market and management of factors such as ownership, network access, tariffs and pricing. This thesis draws learning from the existing networks of Electricity, Gas, Water and Wastewater for formulating the design space of the heat network.","systems thinking; design space exploration; comparison; District heating","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:3f5972cb-8bcc-4797-b0f3-0ae296e8d824","http://resolver.tudelft.nl/uuid:3f5972cb-8bcc-4797-b0f3-0ae296e8d824","A study of the urban village and its regeneration in China: the case of urban villages in Harbin","Zhang, Yushan (TU Delft Technology, Policy and Management)","Hoppe, Thomas (mentor); Sun, Baiqing (mentor); De Jong, Martin (graduation committee); Delft University of Technology (degree granting institution)","2019","Recently, with the rapid development of the economy in China, the process of urbanization is accelerating. However, in the fast urbanization process, the government's rapid expansion of the space has resulted in a large number of urban villages emerging. These urban villages locate inside the downtown area but the situation in there is different from the surrounding urban areas. These urban villages cause problems to the social security and community environment.<br/>The intelligent management and regeneration of urban village helps to optimize the urban land resources, improving urban appearance, and enhance the quality of life in villages and the city.<br/>Harbin is one of the largest cities in China. Since the reform and open-up in the 1970s in China, Harbin has developed rapidly. With the rapid development of the economy and urbanization process, the problem of the urban village appears in Harbin.","","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:22800366-3213-43f8-9443-00f0949494a1","http://resolver.tudelft.nl/uuid:22800366-3213-43f8-9443-00f0949494a1","Design as a product care enabler: Increasing consumers’ motivation to care more of their products","Acevedo Olaya, Sebastían (TU Delft Industrial Design Engineering)","Schoormans, Jan (mentor); Hultink, Erik-Jan (mentor); Delft University of Technology (degree granting institution)","2019","The relevance of persuasion for product care. Aiming at increasing users’ interest in sustainable consumption, different lines of research and initiatives ranging from frameworks for design to community-based approaches, have presented routes to support a transition from a linear economy to a circular economy. These models intend to extend the performance of products through its lifetime as a means to reduce the environmental drawbacks of excessive consumption. Product care focuses on the immediate actions consumers can conduct to maintain products in sound condition. Persuasive strategies and techniques can provide product care with an additional source of motivation drivers while engaging consumers with care activities. The project. Current research in design for product care has addressed different strategies and possibilities while promoting care behaviour, which requires consumers to be active and willing to perform maintenance and repair regularly.  These strategies and methods have been useful to explore the inner drivers of consumers and undercover influential factors that make people act in a certain way. Aiming at further exploring these relations between users and products, this project addresses the influence of cultural background on care, by focusing on human behaviour to design a persuasive system to make people care more. The research. A cross-cultural study was conducted including three different countries, Austria, The Netherlands, and Colombia, aiming at exploring the influential drivers of care. The sample consisted of 160 participants from different backgrounds who took part in a set of questionnaires and interviews to identify the specific context of product care. The findings from the research study were used to design a persuasive strategy which includes a phased-implementation. Former research has addressed cultural differences in fields such as marketing and design, but since the studies are mainly focused on marketing strategies, this research extended the scope towards persuasive strategies to influence people to act upon care. Psychology behavioural economics and design strategies. Different lines of research have studied human behaviour as a means to tailor propositions that are relevant to the target audience, and use the factors that influence the decision-making process, to present framed content which is aligned to the individuals’ interest and mindset orientation models, while convincing patients to carry on scanning procedures, or consumers to buy offers that include products which were not needed at the beginning of the consideration phase. This relates to the cognitive interest that people have concerning certain activity, product, or topic, which if high can lead them to make conscious decisions and reduce the external influence while making a choice. Behavioural economics aims at understanding the reasoning behind consumers acts, which can be shaped by the context and former experiences. The intention an individual has when setting and attaining a particular goal has been a focus of research through the time, since people say they want to commit to a certain activity such as exercising, but their actual performance falls short to reach that goal. Persuasion in design. Regarding research in design, the interaction between people and products has been addressed identifying factors that influence users’ behaviour, such as product attachment and the actual interaction with products which can lead consumers’ actions in multiple manners. Understanding the intention of our propositions can be of help while designing products, services, and spaces that can make people act accordingly.  A guideline for tailoring a persuasive system to convince people to care more was designed in this project. The persuasive strategy. This project resulted in a persuasive system composed of two elements which are as follows and APP and a website are presented, together with initial lines of a service proposition which can be the result of the phased-implementation strategy. The app and the website were designed following a set of guidelines resulting from the cross-cultural study, and the current literature in the overarching fields that set the foundation of this project. The persuasive system was tested in two different iterations with designers and experts from other areas. To devise the impact of this system, it is necessary to extend the intervention in the future by introducing the means presented in a formal setting to validate the long-term impact and how the intervention can be relevant to the users.","product care; Consumer Behaviour; Circular economy; Sustainable behavior change; Behavioural design; App","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:c74a8b3a-b810-413a-b5fd-f307f030837c","http://resolver.tudelft.nl/uuid:c74a8b3a-b810-413a-b5fd-f307f030837c","Design of Integrated Electricity and Heating Systems: An Optimization Study for the Netherlands","Karabulut, Merih (TU Delft Technology, Policy and Management)","Kwakkel, Jan (mentor); Chappin, Emile (mentor); Lukszo, Zofia (graduation committee); van Staveren, Rick (mentor); Delft University of Technology (degree granting institution)","2019","","","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:b3cafe53-e2c1-4945-82c7-59fb68b5eb46","http://resolver.tudelft.nl/uuid:b3cafe53-e2c1-4945-82c7-59fb68b5eb46","Smash it or crack it: Designing interventions for emotional eaters to engage in behavioral expressions of emotional distress","Bozbay, Alara (TU Delft Industrial Design Engineering)","Romero Herrera, Natalia (mentor); Schifferstein, Rick (mentor); Delft University of Technology (degree granting institution)","2019","All human beings eat food, but not always with the same intention. For many people, food can bring a feeling of comfort, at least in the short-term. As a result, some people turn to food in an attempt to heal emotional problems. The term ‘emotional eating’ has been defined as eating in response to emotional cues, often as a coping response to negative emotions like stress, boredom, loneliness, chronic anger, anxiety, frustration, and so on. Emotional eating behavior can affect the overall healthiness of a person in both the short and the long-term. If untreated, it may lead to food addictions and even obesity. The aim of this project is to transform the current mindless and impulsive eating practice into an experience that cultivates awareness regarding emotional responses and eating behavior. The human-centered design approach will lead to come up with design interventions creating attitudinal and behavioral change on emotional eaters. As a result of this self-initiated research &amp; design project, two interventions were designed to tackle emotional eating behavior; Smash &amp; Crack. These are special snack containers which work as mediators between impulsiveness and food by bringing a physical interaction. They aim to enable emotional eaters to express/alleviate current emotional distress before reaching craved food via behavioral expressions. Thanks to interactions, impulsiveness is transformed into mindfulness. As a conclusion, 'a mindful moment of indulging' prevents overeating of comfort foods and eliminates accompanying negative feelings.","Emotional eating; Comfort foods; Behaviour change; Interventions; Prevention; Emotion","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:7b575932-53d6-40fe-92b8-1a4703dddc44","http://resolver.tudelft.nl/uuid:7b575932-53d6-40fe-92b8-1a4703dddc44","Fostering an innovation culture at KLM’s Digital Factory","Arellano Coria, David (TU Delft Industrial Design Engineering)","Kuipers, Henk (mentor); Klitsie, Barend (graduation committee); Ünlü, Oya (graduation committee); Delft University of Technology (degree granting institution)","2019","This thesis report represents the result of a graduation project for the master programme Strategic Product Design at the Delft University of Technology in collaboration with the Digital division of KLM Royal Dutch Airlines. <br/>This project aimed at changing the Organizational Culture of KLM Digital. This due to the perceived lack of innovation, especially radical innovation, coming out of KLM Digital. The current workflow helped create this issue by separating the divisions responsible for the development of digital products. The current setup is known as the Digital Factory, which is mainly focused on developing incremental innovations. The way the change was attempted was by changing the structures, processes and organizational identity. All of that by using design methodologies and practices. <br/>The design proposal consists of two big elements: the Final Destination and the Runway. The first one includes a future vision representing a scenario where KLM Digital achieves the changes team members wanted to see. As part of this scenario, a new Organizational Identity was created. This new Identity aims to bring the team members together under a shared beliefs and values system, working towards Digital’s Vision. The Runway is the collection of actions that Digital can take in the short-term to kick start the change process. More specifically, the Runway includes a number of activities that promote collaboration, creativity and communication among the people of Digital. This way, the proposal covers actions the organization can take in the near future to start testing ideas and learning from them, and a long-term vision to work towards.<br","organizational culture; Strategic Design; organizational ambidexterity; Organizational design; KLM digital","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:037d8aca-6826-42ec-b9d0-42cb31961404","http://resolver.tudelft.nl/uuid:037d8aca-6826-42ec-b9d0-42cb31961404","Modelling Short-Range Stiffness: Comparison Between Hill- and Huxley-type Muscle Models","Franzen, Thijs (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Biomechanical Engineering)","van der Helm, Frans (mentor); Mugge, Winfred (mentor); Delft University of Technology (degree granting institution)","2019","Musculoskeletal models often use Hill-type models to study and simulate muscle behaviour. Due to fast simulation time and ability to simulate large and slow movements Hill-type models have remained largely unchanged throughout recent years. Large and slow movements spend a large part in steady state behaviour and thus experience limited influence of transitional behaviour. However, during small and fast movements, transitional behaviour has more influence and causes inaccuracies in Hill-type models, which can cause an overestimation of muscle force. One characteristic of transitional behaviour is short-range stiffness (SRS). This property is a result of crossbridge dynamics and causes an increase in stiffness when muscle velocity changes. Huxley-type models are capable of simulating transitional behaviour, but are computationally expensive. The goal of this article is to identify the optimal parameter values for two Hill- and one Huxley-type model using a surrogate optimization algorithm and determine if these models can simulate general behaviour and SRS. The parameters are fitted to one soleus and medial gastrocnemius muscle of a cat. All models were able to simulate the experimental data with an average RMS of 6.6N and 4.8N for the Hill models and 5.5N for the Huxley model. However, all three models were not capable of predicting SRS during isometric contractions and the method of determining SRS during non-isometric contractions proved unusable. Thus, the Huxley model that was used had no advantage over the used Hill-type muscle models. Furthermore, it was concluded that the simplest Hill was the only model viable for real-time application.","short-range stiffness; Hill; Huxley; Skeletal muscle; muscle model; Cat","en","master thesis","","","","","","","","","","","","","",""
"uuid:68178afe-5e7c-44a6-a5cf-5790cdb2628f","http://resolver.tudelft.nl/uuid:68178afe-5e7c-44a6-a5cf-5790cdb2628f","De statistische achtergrond van de vuistregels op het havo eindexamen wiskunde A","Baaij, Frédèrique (TU Delft Electrical Engineering, Mathematics and Computer Science)","Hart, Klaas Pieter (mentor); Jongbloed, Geurt (graduation committee); Spandaw, Jeroen (graduation committee); Delft University of Technology (degree granting institution)","2019","Sinds 2015/2016 krijgen de leerlingen op de havo met wiskunde A op hun eindexamen een blad met enkele vuistregels. In deze thesis heb ik de achtergrond van deze vuistregels onderzocht en de vuistregels zelf tegen het licht gehouden.","Mathematics; High School; Statistics; education","nl","bachelor thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:e6100480-27ff-40e2-92a9-815011f7c6ce","http://resolver.tudelft.nl/uuid:e6100480-27ff-40e2-92a9-815011f7c6ce","Identifying opportunities in large infrastructure projects for enhancing project value","Adhikari, Sharad (TU Delft Civil Engineering and Geosciences)","Hertogh, Marcel (graduation committee); Leijten, Martijn (graduation committee); Molaei, Maedeh (mentor); Oijevaar, Kenzo (mentor); Delft University of Technology (degree granting institution)","2019","This study explores towards the positive side of project uncertainties i.e., opportunity. Opportunities occuring in such projects has the potential to enhance the project’s initial objective and could add more value to the project. However, due to lack of an effective approach for opportunity identification and several constraints prevailing in such large projects, opportunities are not being identified properly. This study investigates the concept of opportunity in infrastructure projects and crucial factors that could stimulate opportunity identification in such projects along with constraint’s study that hinders such identification process. Here, a roadmap is developed for opportunity identification consisting of a procedure for identifying opportunity during tender phase with an assessment model that could help in identifying value-creating opportunities for the project. This identified opportunities could be then used by the project team to exploit benefit for the contractor involved in execution but also to the client for whom the project will be delivered.","Opportunity; Project value; Opportunity Management; Infrastructure; Tender; Design & Construct; Contractor","en","master thesis","","","","","","","","","","","","","",""
"uuid:548d4b5b-bdee-4526-9393-8889ef61c380","http://resolver.tudelft.nl/uuid:548d4b5b-bdee-4526-9393-8889ef61c380","Landens transformatie: De verbinding tussen π, het RMG en de bètafunctie","Frank, Abel (TU Delft Electrical Engineering, Mathematics and Computer Science)","Spandaw, Jeroen (mentor); Dubbeldam, Johan (graduation committee); van Elderen, Emiel (graduation committee); Delft University of Technology (degree granting institution)","2019","Eerst introduceren we het rekenkundig-meetkundig gemiddelde (RMG), een snel convergerend algoritme dat een verband heeft met π en nog veel meer constanten en functies. Hoffmann toont dit in een bewijs aan, echter is deze niet waterdicht en amper onderbouwd. Daarom gaan wij ons verdiepen in dit bewijs en met name een stap die twee ogenschijnlijk verschillende integralen aan elkaar gelijk stelt. Het blijkt dat hiervoor Landens transformatie gebruikt kan worden. Om hier op te komen en hem ook nog eens te bewijzen moeten we de wereld van elliptische functies induiken. We gaan vooral werken met de zogeheten thèta-functies die we grondig gaan onderzoeken. Vervolgens gaan we toewerken naar de Landen-transformatie-relaties die de basis zullen vormen voor Landens transformatie. Hiervoor moeten we veel eigenschappen en identiteiten aantonen. Dan stappen we over naar Jacobi's elliptische functies die de brug vormen naar elliptische integralen. Aan de hand van deze integralen en de Landen-transformatie-relaties kunnen we bewijzen dat het RMG inderdaad verborgen zit in een elliptische integraal van de eerste soort. Ook volgt hieruit dat er een verband is met π. Tot slot kijken we nog naar een aantal toepassingen van het RMG.","Landen; theta; RMG; transformation","nl","bachelor thesis","","","","","","","","","","","","","",""
"uuid:7c9d4cc4-3d3a-446d-8b41-5f205733e86e","http://resolver.tudelft.nl/uuid:7c9d4cc4-3d3a-446d-8b41-5f205733e86e","Operationalizing Urban Resilience: A Machine Learning Approach","Sirenko, Mikhail (TU Delft Technology, Policy and Management)","Cunningham, Scott (mentor); Huang, Yilin (mentor); Verbraeck, Alexander (graduation committee); Delft University of Technology (degree granting institution)","2019","","Resilience; Machine Learning; Urban; Heatwave","en","master thesis","","","","","","","","","","","","","",""
"uuid:0568be5a-b79f-4869-be45-5b95a695cd16","http://resolver.tudelft.nl/uuid:0568be5a-b79f-4869-be45-5b95a695cd16","Hydraulic functioning of bioswales under polder conditions: A field-survey in Rotterdam","Mobron, Nadia (TU Delft Civil Engineering and Geosciences; TU Delft Water Management)","van de Ven, Frans (mentor); Nelissen, Joost (graduation committee); van der Hout, Gruella (graduation committee); ten Veldhuis, Marie-Claire (graduation committee); Askarinejad, Amin (graduation committee); Delft University of Technology (degree granting institution)","2019","Bioswales contribute to climate resilience, as they positively impact the urban water infrastructure by improving the water balance and water quality. However, current bioretention design ignores the facts that different designs in different soils and climatic locations produce different performance results.<br/>The effect of polder conditions on the hydraulic performance, as well as the effect of different storm-types and initial conditions will be researched in this report. To this end, 5 bioswales located in Rotterdam, The Netherlands are monitored on their hydraulic behaviour. The discharge of the drain, groundwater levels in and at the edge of the bioswale and the water level in the bioswale are monitored for 4 of the bioswales. One bioswale only has groundwater and surface water measurements. The polder conditions resulted in a low volume reduction and faster and stronger reacting drain. However, the peak reduction and peak delay were still quite good due to the low permeability of the top-soil. For smaller storms, even the goal for volume reduction could be met. It was found that the structural porosity governed the infiltration, but large plants can increase the permeability too much. In addition, the textural porosity should start high enough to allow for vegetation development.","Bioswales; sustainable urban water engineering; infiltration facilities","en","master thesis","","","","","","","","","","","","Civil Engineering","Water Sensitive Rotterdam","51.879984, 4.525932"
"uuid:4119d5b6-1194-489f-a349-7c216aa146a0","http://resolver.tudelft.nl/uuid:4119d5b6-1194-489f-a349-7c216aa146a0","Re[Mod]: reuse plastic &amp; robotic modification","Nazzarri, Ginevra (TU Delft Architecture and the Built Environment)","Bier, Henriette (mentor); Veer, Fred (graduation committee); Mostafavi, Sina (graduation committee); Delft University of Technology (degree granting institution)","2019","It is known that the global impact of solid waste is becoming more worrying day by day; however, the application of reused materials in the built environment is not yet fully embraced. In particular, plastic composites are now fundamental for the global world economy but the organization of their end life needs to be improved. <br/>Therefore, the research investigates the possibility of reusing plastic in the built environment through means of robotic fabrication and computational design. Thus exploring different design possibilities based on reclaimed plastic objects, testing their structural stability and robotically modifying them. In order to create a design system for a pavilion made of reclaimed materials, based on a computational workflow. <br/><br/>Throughout the course of the research project, physical testing and software simulations have been performed to assess the properties of the robotically fabricated geometry, in order to retrieve design guidelines. Moreover, a digital workflow was developed including performance-driven design, performance evaluation and geometry generation for robotic fabrication. <br/><br/>To conclude, the study emphasized how rather than employing new resources in the fabrication of a pavilion structure, it is possible to promote the use of reclaimed material using digital techniques and reversing the design process. Instead of designing a shape and consequently choosing a material, the design will start from the choice of a reclaimed material and the analysis of its potential, in order to originate a structure according to it. Besides the research project aims to facilitate the process through the creation of a computational workflow that can be applied to multiple reclaimed objects and shapes.","Robotic Building; Reuse; Plastic; Pavilion; computational design; Waste","en","master thesis","","","","","","","","","","","","","",""
"uuid:192ce15f-f41d-4f22-88e7-7fd9b5dbc483","http://resolver.tudelft.nl/uuid:192ce15f-f41d-4f22-88e7-7fd9b5dbc483","Ambient Lighting Design for Persuasive Environments","Mavvaj, Yasaman (TU Delft Industrial Design Engineering)","Pont, Sylvia (mentor); Kortuem, Gerd (mentor); Delft University of Technology (degree granting institution)","2019","As we move towards a world in which the lines between the physical and the digital are increasingly blurred, we see a maturing vision for architecture that actively participates in our lives. Our architectural surrounding has become so closely tied to technological trends that the two ultimately define each other. The push for ubiquitous networking and device inter-connectivity in buildings is fueling the development of a new wave of smart devices with embedded electronics, sensors and wireless connectivity that can collect, process and exchange vast amounts of data. This data can be used to inform and ultimately enhance the experience of the occupants and users of built environments. It is thus understandable that, the more recent trends in lighting design, has been to use it as a form of ambient light communication to create more lively and dynamic environments based on live data. This thesis project focuses on exploring the use of this technology in architectural environments in order to enrich the experience of users of public architectural environments with the aid of ambient light communication to inform them of relevant information and entice them to perform desired actions.<br/>Specifically, this project set out to answer two questions: Can ambient light communication be used to convey information without the need of a priori knowledge or training? Can ambient light communication be used as an effective means of triggering a desired behavior in humans? To answer these questions, two experiments were designed and carried out. The results of the first experiment showed that most participants did indeed have a common perception of the selected data categories. This means that the participants shared a common understanding of these visualizations which suggests that in more general terms, light visualization can be used to form a very basic language to transfer information. Similarly, after the conducting the second experiment, it was concluded that ambient light communications can be used effectively to trigger certain desired behaviors and actions in humans (specifically, direct the attention and gaze of humans using directional cues).<br/>4 different novel applications of ambient light communication concepts within office environments were presented which combined its aesthetical value, its ability to convey meaningful information and trigger desired behaviors. Specifically, we explored how the results of the experiments could be used in order to find more concrete solutions in a specific scenario. It was shown that the conclusions drawn from the first experiment could be used effectively to determine the best visualization to communicate a particular information. Based on the results, we saw that the proposed concepts can take advantage of various light characteristics and their effects on human physiology as well as psychology to create persuasive environments which are intended to improve the experience of the occupants and users. In summary, the concepts provided in this project are merely a demonstration of the capabilities and benefits of ambient light communication and its ability to provide useful information and create persuasive environments which enhances the experience of the users of built environments","Ambient light; Ambient communication; Light visualizations; Persuasive Environments","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:8d5fa392-d020-42e4-a9a2-1b0e5db2d857","http://resolver.tudelft.nl/uuid:8d5fa392-d020-42e4-a9a2-1b0e5db2d857","Designing for product presentation: Improving amateur secondhand product presentation on Marktplaats","de Kok, Mendel (TU Delft Industrial Design Engineering)","Wijntjes, Maarten (mentor); Delft University of Technology (degree granting institution)","2019","This thesis report describes the process and the result of a graduation project for the master programme Integrated Product Design at the Delft University of Technology. The project is carried out in collaboration with Marktplaats, a classified advertising service. This project aims to improve amateur product presentation on Marktplaats.<br/><br/>Marktplaats is an online resale service that allows consumers to buy and sell second-hand products. Marktplaats connects buyers and sellers for stimulating a sustainable use of products. However, the way in which users can present their products on Marktplaats’ often generates low quality product presentation and fosters miscommunications of the presented product. <br/><br/>Therefore the goal of this thesis is: Improving the online product presentation of users on Marktplaats: to design for improved visual communication of product aesthetics (appearance), semantics (function) and symbolics (meaning). <br/>Online shopping is linked to high levels of perceived risk because of its intangible nature. Shopping on Marktplaats can be considered even more ‘risky’, since information on these products is often incomplete, and the presentation is usually less salient compared to professional webshops. Consumers respond to a high perceived risk by developing a purchase strategy which is is dependent on the perception and liability of presented product information. .<br/><br/>Due to the absence of a framework in literature, a framework has been created to design for- and measure product understanding. In this model six instruments are presented that help in designing for improved product understanding either through helping the consumer create a better mental model of the product, or by increasing its vividness (medium). <br/><br/>Depending on the nature of the product, a high quality product presentation is one that accurately represents the product at semantic, aesthetic and symbolic level (measure). <br/><br/>With the help of this framework, ideas have been developed and a final concepts have been presented. Validated by qualitative testing, a final concept is presented that more concretely presents semantic, symbolic and aesthetic information, thus increasing the overall quality of product presentations on Marktplaats. The final concept also assists consumers in deciding what valuable information is missing from the listing. <br/><br/>A quantitative study has shown that providing a list of information that is provided and left out by the seller, makes consumers more aware of missing information in a listing. This knowledge influences consumers perception and liability of a listing, aiding them in forming a risk assessment and developing a purchase strategy. This will likely decrease miscommunictions amongst users and lower negative outcomes of Marktplaats service interaction.<br/><br/>This thesis is concluded with and aesthetic representation of the final design, and a roadmap suggesting further improvements on the short- and long term.","Product Presentation; Marktplaats; Presentation; Second-hand; Webshops; Product understanding; Ebay","en","master thesis","","","","","","","","","","","","","",""
"uuid:bb3add5b-3acb-4365-98da-74ed823bb76a","http://resolver.tudelft.nl/uuid:bb3add5b-3acb-4365-98da-74ed823bb76a","Design For Workflow Intelligence In Cardiology: Prompt User Liaison Service Experience system","Liu, Hao (TU Delft Industrial Design Engineering)","van Heur, Rudolf (graduation committee); Boru, Asli (mentor); Delft University of Technology (degree granting institution)","2019","Workflow orchestration in healthcare is a desirable field with massive opportunities. Healthcare providers are under pressure to deliver greater value and even faster than ever before. They have to deliver better care at lower cost while serving more patients. A number of integrated solutions are present in the field. However, the need for the medical staff to get the right information at the right time and the right place is prominent.<br/>In Cardiology, cardiovascular disease now heads the World Health Organisation list of biggest killers in the world and is rapidly increasing in prevalence. On the face of it, cardiovascular disease should be ideal for developing innovative models of care that will improve the well being of the population and the sustainability of their healthcare systems. <br/>Not connected and with multiple data entry points – the potential for human error is greater. One important step is the development of integrated solutions that streamline workflow and make procedures easier.<br/>We tackle these problems by addressing the unmet needs from research, and translate them into requirements. The requirements are the principles that lead to a strategic design solution – PULSE – Prompt User Liaison Service Experience system. <br/>The PULSE system is designed for the Cardiology domain. Further, the target users are in the categories of doctors, physicians and nurses. It helps the Cardiology staff to plan the right actions and make the best decisions. Moreover, it supports the Cardiology staff to collaborate with other professionals more effectively. Furthermore, PULSE is designed to hover above existing systems in hospitals that integrates information a professional needs. It is believed that PULSE can help in accomplishing effective planning, and ultimately leads to more time in better patient care. PULSE is not merely a digital product. It is a hybrid of product and service that brings workload efficiency and flexibility to the medical professionals. The vision we have for PULSE is connected well-being. It aligns to the mission of Philips: to improve the lives of billions of people in the near future.","Workflow Orchestration; Cardiology; Artificial Intelligence and Design; Service Design; Strategic Roadmap","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:f0aacaf5-fd96-4f3a-bb1b-11125138635f","http://resolver.tudelft.nl/uuid:f0aacaf5-fd96-4f3a-bb1b-11125138635f","Online Vehicle Inertial Parameter Estimation: Testing Rozyn’s Algorithm Under More Realistic Conditions","Dijkhuizen, Joël (TU Delft Mechanical, Maritime and Materials Engineering)","Wisse, Martijn (mentor); Shyrokau, Barys (graduation committee); van Hoof, Charel (graduation committee); Delft University of Technology (degree granting institution)","2019","The inertial parameters of a vehicle, which include the mass, centre of gravity position and the moments of inertia, influences the dynamics of the vehicle. Currently, the modelling of the vehicle is done by assuming fixed, conservative, values for the inertial parameters. Knowing the exact values may increase the performance, safety and comfort of the vehicle. A literature review has been conducted, where different methods for online inertial parameter estimation have been graded based on the amount of parameters it is able to estimate, the sensors used and the accuracy of the methods. Rozyn's method seems best for online inertial parameter estimation. Rozyn proposes a method which can estimate the inertial parameters from vertical acceleration data using a state variable method, modal analysis and a simple vehicle model. Rozyn's method can be summarised in four steps: •Extract the free decay response from acceleration data. •Construct the state transition matrix. •Construct the system characteristic matrix. •Estimate the inertial parameters using the constructed characteristic matrix and simplified vehicle model. The main shortcoming of Rozyn's method is the road profile which is used for the simulation, which is described in the ISO 8608 norm. The ISO 8608 description is a stationary Gaussian process. This means that the road profile random variables are normally distributed. Furthermore, the properties of the road profile (mean and variance) does not change over time. In practice however, road profiles never follow a stationary Gaussian process, but are much more random, with more variance between different sections. Another, more realistic, road profile description is proposed by Bogsjö where the road profile follows a non-stationary Laplace distribution. Another shortcoming of Rozyn's paper is that it only shows results for only one condition. For the simulation, the vehicle is driving 100 km/h and a measurement period of 1,000 seconds is used. Unknown is the influence of the velocity of the vehicle on the results. It is to be expected that the accuracy decreases for shorter measurement periods, but by how much is also unknown. In this thesis, Rozyn's algorithm is explained and implemented using a half car vehicle model. Rozyn's algorithm is validated using the ISO 8608 road profile description on similar conditions. The algorithm is then tested using the ISO 8608 road profile description where the velocity of the vehicle is varied between 30 and 100 km/h and the measurement periods between 30 and 120 seconds. This is done 100 times for each condition. This results in 100 estimates of the inertial parameters of each condition. From these results, the average and standard deviation between the estimates can be calculated. This is also done for the alternative Laplace road description. The resulting standard deviations are plotted in surface plots, as function of the varying velocity and measurement period. The results show that the standard deviation between the different estimated parameters when using the Laplace description for the road profile are up to 5 times higher compared to the ISO 8608 road profile description. The results also show that the performance of the algorithm is heavily dependent on the measurement time. A measurement time of at less than 60 seconds is not recommended, due to the large deviation in the estimated parameters. For the mass and centre of gravity position, the performance is independent of the velocity of the vehicle. However, the pitch moment of inertia shows a slight dependency on the velocity, with lower deviations between the different estimates for higher velocities. The algorithm can still be used on non-stationary road profiles. However, more and longer measurements are needed for the algorithm to return with an accurate estimation of the inertial parameters. Even then, some errors in the estimated parameters in the order of 10% are present.","Rozyn; Online; Inertial; Parameter Estimation","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Vehicle Engineering","",""
"uuid:f7f1b914-c1a9-46f4-aee7-5eadaac5c536","http://resolver.tudelft.nl/uuid:f7f1b914-c1a9-46f4-aee7-5eadaac5c536","Characterisation of a functionally graded duplex stainless steel: fabricated by Gas Tungsten Arc Welding","van Utenhove, Laura (TU Delft Mechanical, Maritime and Materials Engineering)","Hermans, Marcel (mentor); Goulas, Constantinos (graduation committee); Ayas, Can (graduation committee); Delft University of Technology (degree granting institution)","2019","Functionally graded materials (FGM) are a class of materials in which the chemical composition or microstructure varies as a function of position, offering unique material properties. In this study, a functionally graded structure was manufactured using Gas Tungsten Arc Welding and a double wire feed device. The wire feed rate was changed step by step of the austenitic AISI 316L and ferritic AISI 430L stainless steel wire, creating a chemically graded duplex stainless steel structure. The structure, approximately 30 mm in height, was investigated using Optical Microscopy, X-Ray Diffraction, X-Ray Fluorescence and Energy Dispersive X-Ray Spectroscopy. The transverse section is composed of large elongated grains. The chemical analysis revealed a relatively smooth change in Nickel and Molybdenum composition over the section, due to remelting of previously deposited layers. The graded material showed a gradual transition in phase fractions from mainly austenite and some ferrite to mainly ferrite and some austenite, to fully ferric structure. There were no brittle phases detected in the structure.","GTAW; Welding; FGM Functionally Graded Material; WAAM; Stainless Steel; AISI 316L; AISI 430L; Chemically Graded; EDS","en","master thesis","","","","","","","","","","","","","",""
"uuid:9ffd28f4-2cb8-4bac-a418-40414cf15aa0","http://resolver.tudelft.nl/uuid:9ffd28f4-2cb8-4bac-a418-40414cf15aa0","The future of ports in the Physical Internet: Developing future scenarios of the PI and their influence on maritime ports","Martinez De Ubago Alvarez De Sotomayor, Manuel (TU Delft Civil Engineering and Geosciences; TU Delft Transport and Planning; TU Delft Technology, Policy and Management; TU Delft Engineering, Systems and Services)","Tavasszy, Lorant (mentor); Rezaei, Jafar (graduation committee); Fahim, Patrick (graduation committee); van Binsbergen, Arjan (graduation committee); Nijdam, M (graduation committee); Delft University of Technology (degree granting institution)","2019","The Physical Internet (PI) is a novel vision that aims to reshape and improve efficiency of transport and logistics. A game-changing vision is expected to have a profound effect on all actors involved in freight transport systems. However, the concept is still in early stages, and the study of the PI in the context of maritime ports has remained unexplored. With maritime ports considered as key global trade enablers, the proposed research aims to provide insights into possible scenarios for the evolution of ports under the development of the Physical Internet. Firstly, a framework that shows the categorical evolution of ports under the influence of three developing PI characteristics is generated, by means of literature review, interviews with experts and brainstorming sessions. Secondly, a scenario logic approach is used to generate hypothetical futures. Both the framework and the hypothetical futures are then used as input for a Delphi-study in which experts in the field of PI assess the level of development of each of the PI characteristics for the years 2030 and 2040. The results from the questionnaire are used to generate the evolution path of maritime ports through the lenses of the proposed framework, for each scenario. An important finding from the survey is that a governance dimension, which entail a set of rules and protocols for a cooperative, safe and reliable PI environment, can lag behind and delay the development of ports towards ""PI ports"" in the upcoming years. Also, under the most optimistic scenario, the Physical Internet scales up to the regional level at most by the horizon year 2040, with ports not reaching the level of global hub hyperconnectivity by this period, as per the opinions of the PI experts.","Physical Internet; maritime ports; scenarios; Delphi","en","master thesis","","","","","","","","","","","","Transport, Infrastructure and Logistics","",""
"uuid:9de83491-9dfe-475b-b045-36d454ead850","http://resolver.tudelft.nl/uuid:9de83491-9dfe-475b-b045-36d454ead850","Thermal management of photovoltaics using phase change materials","Verheijen, Mario (TU Delft Electrical Engineering, Mathematics and Computer Science)","Ortiz Lizcano, Juan Camilo (mentor); Isabella, Olindo (mentor); Delft University of Technology (degree granting institution)","2019","While there are many factors influencing the efficiency of photovoltaic (PV) cells one of the most important ones is temperature. Module temperatures can get significantly higher than the ambient temperature, increases of up to 30°C have been reported in literature. An increase in temperature has an adverse effect on the module’s efficiency, literature has reported a drop of 0.40−0.65%/°C. Therefore, it is not uncommon that during warmsunny days PVmodules operate at a much lower efficiency than advertised by the manufacturer. Different methods of thermal management can be applied. In this research, the effect of phase change materials (PCM) to passively lower the operating temperature of PV panels was studied. During the phase change of a material heat is absorbed as latent heat instead of sensible heat, this does not cause the temperature of the material to increase. Using this process a PCM can keep a relatively stable temperature until it has completely changed its phase. This can be utilised by placing PCM behind a PV module, so that the heat generated in the panel can be absorbed by the PCM while remaining at a stable temperature. The scope of this research was to performmeasurements with a PV-PCMsystem under real weather conditions. Additionaly, a thermalmodel was build using ComsolMultiphysics, to make predictions for the optimal PCM parameters. This thermalmodel was validated with the results from the measurements. Measurements for a free rack situation showed surprisingly a slight increase in temperature of the PVPCM module compared to a reference PV module. Most likely due to convective cooling caused by the wind. And indeed, after installing insulation material at the back of the modules to emulate building integrated photovoltaics (BIPV) a significant decrease was found. For a two week period of measuring a −6.69°C temperature reduction was found, with a peak difference of −21.7°C. This resulted in an energy yield increase of 2.8% compared to the reference panel over this period. From this work, it can be concluded that PCM thermal management is not advisable for free standing modules due to the large influence of convective cooling caused by the wind. However, this method of thermal management can have significant benefits in BIPV situations where convection is not relevant.","","en","master thesis","","","","","","","","2020-08-30","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:448b9a3d-1ee1-41f6-8d96-9a406f96d088","http://resolver.tudelft.nl/uuid:448b9a3d-1ee1-41f6-8d96-9a406f96d088","Real-time simulation based analysis of Fast Active Power Regulation strategies to enhance frequency support from PE interfaced Multi-Energy system","Veera Kumar, Nidarshan (TU Delft Electrical Engineering, Mathematics and Computer Science)","Rueda, José L. (mentor); van der Meijden, Mart (graduation committee); Rakhshani, Elyas (graduation committee); Ahmad, Zameer (graduation committee); Batista Soeiro, Thiago (graduation committee); Delft University of Technology (degree granting institution)","2019","Until recent times, electrical power grids have been dominated by conventional power plants run by fossil or nuclear fuels in order to cater to the electrical load demand. These power plants employ large generators that operate in synchronous with each other to maintain a stable frequency and voltage across the power grid. The frequency and voltage stability, which are respectively linked to active and reactive power serves as a backbone for a secure operation of the power system. Furthermore, since these classical generation sources promised support of ancillary services during unstable conditions, along with power generation, they were characterized as a reliable solution for maintaining the security of the power system. But, due to the high emission of carbon by-products from these fossil-fuelled generators, challenges of global warming and climate change have made it inevitable to decommission them. And more emphasis has been embarked on the adaptation of renewable energy sources (RES) which offer minimum carbon footprint. Geothermal heat, wind, sunlight, and tides constitute some of the Renewable energy sources since their availability are unlimited and involve the least emission of greenhouse gasses, hence Renewable Energy Sources have a minimal impact on the environment compared to traditional energy sources and can effectively tackle the problems which arise with fossil fuel usage. For all these reasons, during the last decades, there is fierce research on finding ways to produce the needed energy in a sustainable fashion. Synchronous Generators, which are dominant in the existing power grid, have the inherent characteristics to relate system’s frequency with load balance. This considerable advantage is found missing from Power Electronic interfaced renewable energy resources due to the following reasons. Firstly, since active power support was earlier the main purpose of using these devices, they were operated at Maximum power point tracking (MPPT). Secondly, in wind energy technology, isolation between electrical and mechanical circuits had to be introduced due to their variable behavior of energy production, and this has led to no inertia backing from the synthetically produced frequency. So with high penetration of RES in the future grids, the aforementioned problems pose huge risks for grid stability and reliability. The current research mainly focuses on the development, implementation, testing, and validation of frequency regulation strategies under the umbrella of Fast Active Power Regulation controllers specifically to support during large load frequency variation in low inertia power system grid. These controllers developed are very generic and can be implemented with slight modifications in all the renewable energy devices with ease. In order to simulate more real-time behavioral conditions, dynamic simulation studies are performed in RSCAD software interfaced with a Real-Time Digital Simulator (RTDS). Two Test benches have been considered in this thesis, one being an IEEE 9 bus system modified with 52% wind share and another is the North of Netherlands Network. In the first stage of the project, FAPR controller’s proof of concept has been tested on a Type-4 Wind generator setup connected to the modified IEEE 9 bus system. Here wind penetration is scaled up to 52% and a low inertia grid have been simulated. Later, the results obtained here were validated by Hardware in Loop setup utilizing a mock-up grid side converter. The next stage of the project aims at making FAPR controllers more generic. For this the North of Netherlands network was modified by adding FAPR integrated 300MW solar farm, FAPR integrated 82MW full converter based Type-4 Wind Turbine and lastly, a responsive load (Electrolyser) was modified to accommodate FAPR controllers. All together formed a Multi-Energy Hub and simulations were performed to check the practical feasibility and boundaries of operation of FAPR controllers in the future power grid. The results prove that the proposed topology and control strategies can effectively provide frequency ancillary services to the grid by providing support during dynamic load frequency variations.","FAPR; Inertial Response; Fast Active Power Injection; Virtual Synchronous Power based controller; Electrolyer; Solar Farm; Type-4 Wind Turbine; Kinetic Energy Extraction","en","master thesis","","","","","","","","2024-06-19","","","","Electrical Engineering | Electrical Power Engineering","IEPG",""
"uuid:fbc96aa7-a794-49af-b510-861a730ad001","http://resolver.tudelft.nl/uuid:fbc96aa7-a794-49af-b510-861a730ad001","Adaptive feedforward for reset control systems: Application in precision motion control","Brummelhuis, Karst (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Delft Center for Systems and Control)","van Wingerden, Jan-Willem (mentor); Hossein Nia Kani, Hassan (mentor); Saikumar, Niranjan (mentor); Delft University of Technology (degree granting institution)","2019","","","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:4a1ea237-2857-4c26-aad5-1f523fdde58a","http://resolver.tudelft.nl/uuid:4a1ea237-2857-4c26-aad5-1f523fdde58a","Deep Learning-based identification of human gait by radar micro-Doppler measurements","Papanastasiou, Vasileios (TU Delft Electrical Engineering, Mathematics and Computer Science)","Yarovoy, Alexander (mentor); Tax, D.M.J. (graduation committee); Trommel, R.P. (mentor); Delft University of Technology (degree granting institution)","2019","The radar micro-Doppler (m-D) signature of human gait has already been used successfully for a few classification tasks of human gait, for instance walking versus running and determining the number of humans under observation. owever, the more challenging problem of personnel identification has not been solved yet. The aim of this study is to prove that the human walking gait differs between individuals and that it can be used for personnel identification using CW X-band radar measurements. This study investigates the effect of human walking gait characteristics such as speed and stride as well as the gender on leading to distinctive m-D signatures. Both simulated data and measurements of 22 subjects walking from and towards the radar were used. Unsupervised earning based on Adversarial Autoencoders was used to map the m-D ignatures to a latent space. T-Distributed Stochastic Neighbor Embedding and Uniform Manifold Approximation and Projection were then used for clustering and visualization. This study shows that even very slight changes in the walking gait characteristics mentioned above lead to distinctive m-D signatures mapped into closely located points in the latent space. A VGG-16 convolutional neural network was used to identify the walking subjects based on their easured m-D signature. Accuracy of above 93.5% was achieved, proving that CW X-band radar m-D signature of human walking gait can be used for accurate personnel identification which is reliable for 22 participants.","identification; micro-Doppler; Deep learning","en","master thesis","","","","","","","","2020-08-31","","","","Electrical Engineering | Signals and Systems","",""
"uuid:4ee059f8-6923-4b9e-b807-08944027d2d5","http://resolver.tudelft.nl/uuid:4ee059f8-6923-4b9e-b807-08944027d2d5","Creating a bias in inspection data: Exploring the medium- to long-term effects of data-driven risk-based regulation","Sedee, Ivo (TU Delft Technology, Policy and Management)","van der Voort, H.G. (mentor); Cunningham, S. (graduation committee); Booijink, Tom (graduation committee); van der Vaart, Elske (graduation committee); Delft University of Technology (degree granting institution)","2019","Monitoring organisations are currently in a transition phase towards risk-based inspections using data models and algorithms in order to increase their efficiency and transparancy. The use of data by monitoring organisations has several benefits, but can at the same time have negative effects in the medium- to long-term. This study explores these effects when monitoring organisations choose to perform their inspections based on data collected during their own inspections.","data-driven risk-based regulation; data-driven inspections; Agent-Based Modeling","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:0cb03a83-148a-48b6-bb14-32a46fdb4e01","http://resolver.tudelft.nl/uuid:0cb03a83-148a-48b6-bb14-32a46fdb4e01","Dutch electric vehicle drivers' preferences regarding vehicle-to-grid contracts: Examining the willingness to participate in vehicle-to-grid contracts by conducting a context-dependent stated choice experiment taking into account the EV recharging speed","Meijssen, Aart (TU Delft Technology, Policy and Management)","Lukszo, Z. (mentor); Annema, J.A. (mentor); Huang, B. (mentor); Delft University of Technology (degree granting institution)","2019","Vehicle-to-grid (V2G) could turn an electric vehicle (EV) into a potential source of flexibility, in order to deal with the variability and uncertainty in electricity supply brought about by renewable energy sources and the load increase caused by the adoption of EVs. However, only a few studies have focussed on the complexity of EV drivers’ motivations towards V2G contracts. The main objective of this research was to address this lack of empirical evidence in the V2G literature by conducting a stated choice experiment among Dutch EV drivers’ to obtain their preferences regarding participating in V2G contracts with an aggregator, an intermediary party that would bundle the batteries of the EVs virtually. These preferences were measured from the perspectives of both current and increased recharging speeds of EVs. Therefore, the impact of an increased recharging speed on the potential success of V2G was also measured. In particular, the effect of an increased recharging speed on the guaranteed minimum battery level, one of the contract attributes used in both former as well as in this research, was quantified. A total of 1,332 choice observations was gathered and used to estimate an Multinomial Logit (MNL) model. The results showed that Dutch EV drivers based their decisions to choose for a particular V2G contract on a required plug-in time, a financial compensation, a number of discharging cycles and a guaranteed minimum battery level. However, the relative importance of these contract attributes depended on the recharging speed of the EVs. In fact, Dutch EV drivers valued the guaranteed minimum battery level half as important within the context of a fast recharging speed, relative to recharging speed of their current EVs. The results are compared to the few previously conducted stated choice experiment on V2G contracts, indicating that the demanded financial compensation for the significant contract attributes seems to decrease.","Vehicle-to-Grid; V2G; Electric Vehicles; EV; Stated Choice; Choice Modelling","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:7a2b00c0-663b-4334-b2f2-98bc2a39cb32","http://resolver.tudelft.nl/uuid:7a2b00c0-663b-4334-b2f2-98bc2a39cb32","Marketing intelligence system implementation in B2B service marketing environment: An explorative case study","Kowlesar, Kavish (TU Delft Technology, Policy and Management)","Rook, L. (mentor); Cunningham, S. (graduation committee); Delft University of Technology (degree granting institution)","2019","PROBLEM The business and marketing environments of today are rapidly changing due to several trends in society and in the market (Kotler &amp; Keller, 2016). To maintain their position, companies must continually renew their knowledge management systems. The emergence of information technology (IT)-based intelligence systems suggests more possibilities for gathering knowledge than ever before. These possibilities can help to better meet the information needs of marketers in corporate setting. Sparked by implementation of such technologies in the business-to-consumer (B2C) marketing environment, business-to-business (B2B) marketers of the case firm (an IT consulting company) were interested in the possibilities that implementation of state-of-the-art IT based intelligence systems would offer for meeting their information needs. The objective of this research was, therefore, to explore the possibilities of intelligence systems that could add to the marketing information system of B2B marketers. This resulted in the following research question: How should an intelligence system look like to effectively add to the B2B marketing information system of an IT solution consulting company? The literature suggests that differences exist between B2B and B2C marketing. These differences point to different intelligence needs in B2B, which should be met with a different marketing information system. However, literature on the specific intelligence needs of B2B marketers and their marketing information system was not available. Furthermore, the existing literature provides enough knowledge on intelligence systems, but lacked on specific knowledge on IT based marketing intelligence systems, let alone marketing intelligence systems designed specifically for B2B marketing. Based on the available literature on overall intelligence systems, a framework was made that combined several methods and possibilities for intelligence systems. By adding challenges for implementation, this framework could help in determining how an intelligence system for specific purposes would look like. The identified gaps of the literature, combined with the challenges for implementation for intelligence system provide an overview of what information is needed about the B2B marketing environment to answer the research question. METHODOLOGY The information needed for answering the research question was extracted by means of an embedded case study on an IT consulting company. Several units of analysis were distinguished, based on general approaches to B2B marketing. In-depth semi structured interviews with the marketers within the case company were used to gather data. The topics were based on the information gaps in the literature, combined with knowledge from several resources about the marketing environment such as observation, available documentary and introductory interviews. The interviews were transcribed and coded using specialized software (Atlas TI). The analysis focused on finding relationships between key concepts found in the interviews.   FINDINGS By using this methodology, three phenomena were found. First, by linking the available marketing information system with the marketing needs that were suggested by the marketers, gaps could be identified, which could be used in the development of an intelligence system tailored to the needs of the case company. Converging evidence was found between the identified units of analysis suggesting the existence of an intelligence gap for knowledge on the people working at their customers. Specifically, the B2B marketing information system does provide information on customers, however does so on (too) high (read: general) an abstraction level. The B2B marketers indicated a need for information on a lower (read: more personal and precise) abstraction level, specifically: interest, hobbies, roles, activities, how they are linked together and whether they are part of a decision making unit. Second, the interviews also produced a list of potential data sources for an intelligence system. Scoping these sources towards the needed intelligence suggest that an intelligence system should make use of user-generated content (i.e. social media, blogs and forums), online published interviews and surveys. These sources might contain relevant information, but they are in textual unstructured format. Finally, the preferences for presenting the intelligence were extracted from the marketers. The marketers would prefer intelligence presentation to be implemented in other systems. They would like to have a search option, and they preferred easy to use display of the intelligence. PRACTICAL IMPLICATIONS Based on the found phenomena, choices could be made using the framework for intelligence system implementation based of the literature. The proposed intelligence system design was built from the following layers: (1) the intelligence system will use user-generated content (UGC) (i.e. social media, blogs and forums), online published interviews, and surveys as data source. (2), Data will be extracted from these sources using natural language processing methods such as named entity recognition, relationship extraction and sentiment analysis. (3) The extracted data will be stored in databases. (4) OLAP servers will be used for slicing and dicing of the data. (5) The data will be presented as intelligence by use of searchable relational graphs. This form of presentation could be implemented in dashboards of other systems such as the marketers’ CRM system. The intelligence system can add to the marketing information system by providing valuable insight on customers on a lower (read: more personal and precise) abstraction level. This form of intelligence is useful to the marketers, but is not currently provided decently by existing B2B marketing information systems.","marketing; intelligence systems; Implementation; B2B; Service marketing; AI; consultan; IT","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:9fb21d06-7027-4d52-ba4c-7160c91bbc30","http://resolver.tudelft.nl/uuid:9fb21d06-7027-4d52-ba4c-7160c91bbc30","Technology assessment and usability study of a steerable needle prototype as a tool in assisting percutaneous liver interventions","de Lange, Danny (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Medical Instruments & Bio-Inspired Technology)","van den Dobbelsteen, J.J. (mentor); van de Berg, N.J. (mentor); Delft University of Technology (degree granting institution)","2019","PURPOSE. The purpose of this thesis is to investigate the possibility of implementing a prototype of a steerable needle in a medical procedure. Therefore the two main research questions are: “Can the intended user perform a steering motion with the steerable needle and reach the target area following a straight and curved trajectory?” and “Does the tip of the cannula maintain its position after the instrument change with a biopsy needle for a straight and curved trajectory?”.<br/>METHODS. Two studies were conducted to answer these research questions. A user study was designed and performed to test the steering properties of the steerable needle for a straight and curved trajectory. A second controlled study with automated insertions was designed and performed to investigate the cannula tip displacement after the instrument change.<br/>RESULTS. The results of both studies show that steering towards a specific target is highly achievable with the steerable needle for insertions with a straight and curved trajectory. Results also show a high success-rate, a low time consumption for the instrument change, and a high satisfactory level on the manual handling of the steerable needle by the interventional radiologists. The results of the second study show that the cannula tip maintains its position after the instrument change for a straight trajectory, and the cannula tip only displaces 1.4 mm back over a deflection of ±25 mm after the instrument change for a curved trajectory.<br/>CONCLUSION. Reaching the target with a steering motion is achievable with the steerable needle and only a small displacement of the cannula tip is seen after the instrument change for a maximum imposed curved trajectory. These results answer the main questions concerning the effectivity of the steerable needle and are promising for future implementation of this prototype in a real medical procedure, containing real patients, and real liver tissue.<br/>KEY WORDS. liver disease – liver biopsy – radiofrequency ablation – steerable needle – polyvinyl alcohol <br","liver phantom; Steerable needle; Biopsy; radiofrequency ablation","en","master thesis","","","","","","","","2021-08-01","","","","","",""
"uuid:e879bd10-863f-4065-b6c3-84ab0a3883f1","http://resolver.tudelft.nl/uuid:e879bd10-863f-4065-b6c3-84ab0a3883f1","Flow Analysis of Physical Vapour Deposition Process in OpenFOAM","Obiji, Chibuikem (TU Delft Mechanical, Maritime and Materials Engineering)","Kenjeres, S. (mentor); Vesper, J.E. (mentor); Pourquie, M.J.B.M. (graduation committee); Boersma, B.J. (graduation committee); Delft University of Technology (degree granting institution)","2019","Tata Steel employs physical vapour deposition (PVD) as a novel galvanization technique in their line production to prevent corrosion. In this process, zinc is evaporated in a vapour distribution box (VDB) and directed via nozzles into a vacuum where it is deposited on a steel substrate. In order to reduce stray deposition, achieve high and uniform mass flow rate from the nozzles and avoid condensation, understanding of the flow phenomena in the VDB and nozzles are necessary. Seeing that the PVD process is carried out at high temperatures in vacuum which makes it infeasible to experimentally characterise the flow for optimization purposes, thus, this research utilizes computational fluid dynamics (CFD).<br/><br/>In this study, the flow behaviour of the zinc vapour in the VDB and nozzles are investigated by solving the fluid governing equations numerically using finite volume method (FVM) in openFOAM. This analysis is done using the pressure-based sonicFoam solver to cope with the subsonic flow in the VDB and supersonic flow in the nozzles. The mass flow rate was compared to the ideal isentropic expression and experimental results. Regions in the set-up with high probability of condensation was investigated using a four coefficient Antoine equation. <br/><br/>A uniform pressure build-up in the VDB enabled uniform deposition. Around the corner of the inlet channel, a stable recirculation pattern affected the nozzle flow, however, this effect reduced as the outlet pressure decreased. The simulated total mass flow rate was greater than the experimental data by a factor of four possibly as a result of numerical errors and experimental stray depositions. And the simulated nozzle mass flow rate was less than the analytical isentropic expression by a factor of five due to the nozzle viscous boundary effect, and VDB wall heating. The mass flow rate from the nozzles decreased with increase in distance from the inlet channel. However, the nozzles far away are less likely to form zinc droplets as compared to those close to the inlet stream. For scale-up under the same conditions, it is expected that non-uniformity would be pronounced and the effect of the small eddies would become more significant. Thus, the simulation of the PVD process gives a qualitative description of the flow and a first approximation for the mass flow rate. To further improve the mass flow prediction, the sensitivity of the mass flow rate depending on the melt temperature and inlet velocity boundary condition should be studied in future works.","","en","master thesis","","","","","","","","2021-08-20","","","","","",""
"uuid:74aa2390-93c4-4978-bdde-8a63b1635a64","http://resolver.tudelft.nl/uuid:74aa2390-93c4-4978-bdde-8a63b1635a64","Managing Information Exchange by Improving Information Flows in a Customer-to-Customer Process","Srivastava, Shivam (TU Delft Technology, Policy and Management)","Ludema, M.W. (mentor); Comes, M. (graduation committee); Tavasszy, Lorant (graduation committee); Krull, Holger (graduation committee); Delft University of Technology (degree granting institution)","2019","This thesis aims to manage information exchange at the case company by designing an information exchange map using a business process model for the customer-to-customer process, together with structuring team meetings and creating ground rules for efficient information exchange. <br/><br/>The Damper Division of ZF Friedrichshafen AG (case company), Schweinfurt (SCW) has recently decided to move the production of<br/>its high running parts to its facility in Pune, India. The project is facing typical Supply Chain Management challenges like delay in serial production and delivery schedules, lack of information exchange, ambiguity over roles and responsibilities, and redundant communication between the two facilities SCW and Pune, thus incurring a high transaction cost and low coordination. The literature review about information flows, business processes and process integration provided four principles that help to integrate the information flow between processes. These principles are – accessibility, transparency, granularity, and timeliness. The analysis pointed that there are information gaps and interrelationship issues<br/>between the stakeholders of the project. The issues identified were the need for an information exchange map which can be relied on by all of the stakeholders, timely information exchange, defined responsibilities and roles, and efficient communication. Standardization of information exchange with the help information exchange map together with information sharing rules emerged out as the main conceptual design. This was followed by a participatory design phase where the design was developed together with the stakeholders of the project.<br/><br/>Based on the final design with information sharing rules (meeting structure and ground rules), a set of recommendations (including an implementation plan) were laid out to help the managers steer the final design to the best of their use. Currently, the case company is about to implement the design together with the meeting structure and ground rules. It was recommended that the future objective of the company should be to achieve a control tower for central data collection and using the data to generate insights.","Information Exchange; Information Flows; Coordination; Supply Chain; Process Integration","en","master thesis","","","","","","","","2021-08-31","","","","","","50.026610"
"uuid:db4ac829-277b-469f-ac92-829e3b6e3e59","http://resolver.tudelft.nl/uuid:db4ac829-277b-469f-ac92-829e3b6e3e59","A predictive model for parcel classification in the context of last-mile delivery","Grace Priskila Kastanya, Grace (TU Delft Civil Engineering and Geosciences)","Tavasszy, Lorant (mentor); Ludema, M.W. (mentor); Atasoy, B. (graduation committee); Menger, Ilse (mentor); Delft University of Technology (degree granting institution)","2019","Last-mile delivery for shipments in the B2B (business-to-business) market make use of two types of last-mile delivery mode, van and truck, as the number of shipments per consignee is various in size, weight, and volume. A parcel classification task exists to make an optimum classification of the parcel, toward which last-mile delivery mode. The classification principally is made by combining rule-based system and human correction, after information of all parcels per consignee is known. In this paper, a parcel classification by using a predictive model is proposed to make classification fully automatic and done without information of all shipments to the same consignee. The parcel classification system in this paper is based on the system of DHL Parcel and the model is tested by using data of last-mile delivery by the company in the area of Den Bosch. The proposed design of a predictive model for parcel classification is made by including information of the parcel characteristics and historical information of the intended consignee that are extracted as features. Furthermore, the model implements the decision tree algorithm as the learning method for the training data. From testing the predictive model, features of consignee address occur as the most important features, however, the piece features cannot be excluded. The decision tree model reaches accuracy 89.5%, given the last-mile delivery of parcel on one-week period. The main advantage of using the predictive model is faster and earlier classification systems which could lead to better last-mile capacity planning.","parcel service provider; parcel classification; predictive model; two last-mile mode; decision tree; predictive model implementation","en","master thesis","","","","","","","","2021-08-31","","","","Transport, Infrastructure and Logistics","",""
"uuid:8ce1316c-1aca-44c1-91ef-96a69827f1fb","http://resolver.tudelft.nl/uuid:8ce1316c-1aca-44c1-91ef-96a69827f1fb","Fundamentals of low-transmissibility aerostatic pads","de Boom, Jeroen (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Precision and Microsystems Engineering)","van Ostayen, R.A.J. (mentor); Langelaar, M. (graduation committee); Lampaert, S.G.E. (graduation committee); Delft University of Technology (degree granting institution)","2019","Air bearings are known for their low friction losses, constant viscosity and cleanliness, making them favourable in numerous high-tech applications. The relatively low aerostatic bearing stiffness is the major topic in state-of-the-art research and some recently proposed concepts are able to create infinite stiffness. This results in a strong coupling between the base and flying mass, enabling unwanted propagation of base vibrations. Why not integrate the vibration-isolation and bearing function? To reduce the out of plane vibrations of a flying mass. A previous study shows the possibility of creating a zero-stiffness bearing with the use of multiple aerostatic pads. However, the effect of the dynamic- thin-film stiffness and damping on the transmission of base vibrations is still unknown. The aim of this research is to optimise and validate the zero-stiffness concept and to study the effect of the static and dynamic pad characteristics on the transmissibility function. It is shown that both the stiffness and damping need to be minimised at equal operating fly height to create a stable system. A stable design is found with the use of a parametric optimisation procedure. The design shows a lower transmissibility when compared to a standard aerostatic bearing, although there are some challenges regarding high design sensitivities and displacement non-linearity. Different manufacturing methods are investigated to build a prototype to validate the concept. The measurements prove the validity of the model, although a clear low-stiffness operating point is not found, due to a combination of manufacturing difficulties and high design sensitivities.","Aerostatic pads; Low-transmissibility; Thrust bearing; Vibration Isolation; Reynolds equation; Parametric optimisation","en","master thesis","","","","","","","","2021-09-16","","","","Mechanical Engineering | Mechatronic System Design (MSD)","",""
"uuid:f733a0f2-bd73-4a04-9441-a24cbb5da63f","http://resolver.tudelft.nl/uuid:f733a0f2-bd73-4a04-9441-a24cbb5da63f","Biomedical evaluation of magnesium based biodegradable osteosynthesis implants","Nambiar, Malavika (TU Delft Mechanical, Maritime and Materials Engineering)","Zhou, J. (mentor); Berger, Leopold (mentor); Delft University of Technology (degree granting institution)","2019","Biodegradable materials such as polymers and magnesium and its alloys are gaining attention and approval for clinical use as osteosynthesis implants. However, polymers often lack the required mechanical strength and commercial Mg systems contain elements that are not naturally occurring in the body. Extra-high purity magnesium alloyed with 1 weight % zinc and 0.3 weight % calcium (ZX10) aims to confront these disadvantages to eventually emerge as an optimal material for fracture fixation.<br/>In this thesis, ZX10 has been biomedically characterized using various tools to test its ability to function as a screw plate system in mandibular angle fractures. The material was analyzed after production using metallography techniques. Implants were designed and optimized using finite element techniques and mechanical tests were performed to compare strength against commercially available screw-plate Ti systems of the craniomaxillofacial (CMF) region. Cytotoxicity tests were undertaken to gain an insight into biocompatibility. All results indicate that ZX10 bone plate and screw can be designed within acceptable dimensions to match the flexural strength of a Ti plate in 4 point bending and a Ti screw in pull out tests. Cell cultures in 10 % concentrations of corrosion products show low cytotoxicity, 50 % concentrations show moderate cytotoxicity and 100 % concentrations of corrosion products show severe cytotoxicity. Viable cells were observed in the presence of the implant material. <br/>With a corrosion rate of 1.08 mm/year in simulated body fluid, ZX10 behaves comparably to commercially available degradable systems such as the WE43 alloy and thus bespeaks further development and in vivo characterization to move towards clinical implementation.","Biodegradable; implants; magnesium alloy; fracture fixation","en","master thesis","","","","","","","","2021-08-30","","","","","",""
"uuid:a8dfd4da-268b-4536-b998-40a4ccae1c84","http://resolver.tudelft.nl/uuid:a8dfd4da-268b-4536-b998-40a4ccae1c84","Real time implementation for Grid-forming control of type-4 wind turbines to mitigate voltage and frequency instabilities in high renewable penetration","Sethi, Shubham (TU Delft Electrical Engineering, Mathematics and Computer Science)","Rueda, José L. (mentor); van der Meijden, M.A.M.M. (graduation committee); Oleinikova, Irina (graduation committee); Delft University of Technology (degree granting institution); Norwegian University of Science and Technology (NTNU) (degree granting institution)","2019","The increasing penetration of PE converter interfaced generation units in electrical power systems have given rise to many challenges in the power system operation. Two of the most important challenges are the voltage control and frequency control in the absence of conventional generation units. Furthermore, the PE converters can interact with the power system elements causing the power system to become unstable.<br/><br/>In this thesis, the effect of the wind turbines modified with grid-forming capability is analysed on the transmission networks as well as on the Offshore VSC-HVDC converter station. The dynamic response of the WTs is studied considering the high share of the power electronic converter interfaced generation. <br/><br/>It is shown when the wind turbine power converters are equipped with the implemented control strategy, they can provide voltage and frequency stability to the system and further upgrades can be added to enhance the system response. The control strategy implemented employs the direct voltage control which is upgraded with voltage dependent active current control for improving the transient voltage recovery of the system. The inertial response based on modifying the machine side converter is also added which extracts kinetic energy from the wind turbine rotor that improves the frequency response of the system following load change.<br/><br/>In the end, an offshore wind farm network is modeled which includes the offshore wind park connected to an offshore MMC HVDC converter station for delivering bulk power to the DC source connected via the HVDC cable. The developed wind turbine model is employed for integration in the offshore wind farms which has shown to eliminate the transient overvoltages occurring in the offshore network during the blocking of the HVDC converter.","grid forming; renewable integration; HVDC technology","en","master thesis","","","","","","","","2021-08-30","","","","European Wind Energy Masters (EWEM)","",""
"uuid:36f8fe7f-e102-44b9-af43-f4459944c257","http://resolver.tudelft.nl/uuid:36f8fe7f-e102-44b9-af43-f4459944c257","In situ laparoscope lens shielding device to ensure constant clear vision","Patel, Sonali (TU Delft Industrial Design Engineering; TU Delft Design Engineering)","Goossens, R.H.M. (mentor); Paus-Buzink, S.N. (mentor); Delft University of Technology (degree granting institution)","2019","The focus of this master thesis is to design a holistic solution to the problem of laparoscope lens tip contamination during the surgery while complying to the complex contextual factors. The stakeholder needs and the environment of the operating room were the key considerations during the design process.","laparoscopy; Medesign; clean; Tip contamination","en","master thesis","","","","","","","","2021-08-30","","","","Integrated Product Design","",""
"uuid:edc2ffd6-00fd-4cd6-883b-13b14528cb72","http://resolver.tudelft.nl/uuid:edc2ffd6-00fd-4cd6-883b-13b14528cb72","An Idealised Morphodynamic Model of a Tidal Inlet and the Adjacent Sea","Rozendaal, Marco (TU Delft Electrical Engineering, Mathematics and Computer Science)","Schuttelaars, Henk (mentor); Dubbeldam, Johan (graduation committee); Möller, Matthias (graduation committee); Delft University of Technology (degree granting institution)","2019","Tidal inlet systems are often highly valuable and sometimes even unique ecosystems. However, field measurements show that tidal inlet systems are sensitive to changing exogenous conditions, such as rising sea levels. This thesis aims to investigate to what extent the adjacent sea influences the stability and equilibrium state of the tidal inlet. A one-dimensional idealised model is used to model the interaction between the sea and the inlet. The water motion is forced by the tide and the inlet is assumed to be narrow and short. At equilibrium, an increasingly sloping bottom is found in the sea and a constantly sloping bottom in the inlet. This equilibrium bottom profile seems to be in reasonable agreement with observations. The sea-inlet bottom profile is less stable than the inlet bottom profile, nevertheless, the sea-inlet bottom profile is still asymptotically linear stable. Moreover, the results in this thesis suggest that for one-dimensional idealised models consisting solely of a tidal inlet, the correct seaward boundary condition is a properly chosen fixed entrance depth. For a two-dimensional semi-infinite sea, it is shown that a Perfectly Matched Layer is a convenient method to incorporate the Sommerfeld radiation condition and that the narrow tidal inlet cannot be modelled as a point source forcing in the two-dimensional sea domain.","Morphodynamic model; Idealised model; Tidal inlet system; Tidal embayment; Morphodynamic equilibrium; Equilibrium bed profiles; Stability analysis","en","master thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:68154b05-bb0e-4e94-b92a-40b5b8bd4909","http://resolver.tudelft.nl/uuid:68154b05-bb0e-4e94-b92a-40b5b8bd4909","Designing a locomotive device driven by a shape memory alloy composite: a mimicry of the caterpillar movement","Atmopawiro, Naomi (TU Delft Industrial Design Engineering; TU Delft Design Engineering)","Ghodrat, Sepideh (mentor); Sakes, Aimée (mentor); Barati, Bahar (mentor); Delft University of Technology (degree granting institution)","2019","The materials we encounter in our every day lives already extend beyond the traditional materials of wood, metal, ceramics and glass. The characteristics and behavior of materials and material composites are continuously being tweaked. The introduction of new materials that can respond to inputs from the environment has brought about a new movement for material development and interaction design: computational composites. A computational composite is capable of sensing inputs from the environment, processing and controlling the consequent expression or formation of the material.<br/>The aim of the thesis was two-fold: to design and develop a soft bodied mechanism inspired by the movement of a caterpillar, using a Shape Memory Alloy-based (SMAs) composite, and to design material concepts based on the qualities of the composite.<br/>This was an explorative project, investigating the application of a bio-inspired approach and the Material Driven Design (MDD) approach to the development of a moving material.<br/>The first phase of the project focused on uncovering the technical aspects of a SMA-based composites and its relation to a computational composite. To understand caterpillar locomotion, a thorough study on its anatomy and locomotion strategies was performed. A qualitative study on how<br/>designers interpret caterpillar-like motion lead to four interesting movements, which were further developed in moving SMA-based composites from silicone and 4D printed textile.<br/>One SMA-based composite was selected for further improvement of the mechanism to be capable of translational caterpillar-like motion.<br/>The mechanism can also be interpreted and applied in other ways, and thus the experiential characteristics of the material were uncovered to define a material experience vision for further applications. Through a creative session and ideation phase three material concepts were proposed, suited for three types of user input on the computational composite: none, indirect and direct.<br/>The ultimate purpose for the material would be to sensitize people to the idea of a world where materials move from passive objects to active elements in our daily lives. It is recommended to do more research on the composite and to apply the materials experience vision to applications beyond every day objects and into the more innovative field of computer interface design and human-material interaction.","Shape Memory Alloys; Composite material; Bio-inspired design; MDD; Computational Composite","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:e60ae39e-6044-4acd-b577-31726bfb858c","http://resolver.tudelft.nl/uuid:e60ae39e-6044-4acd-b577-31726bfb858c","Dimmable fenestration and incorporated photovoltaic design: Smart Window design with PDLC and AL-BSF cells","Cordoba Parra, Mariana (TU Delft Electrical Engineering, Mathematics and Computer Science)","Isabella, Olindo (mentor); Ortiz Lizcano, Juan Camilo (graduation committee); Delft University of Technology (degree granting institution)","2019","The built environment contributes with 39% of the CO2 emissions in the world [3]. At the same time it is a sector that is expected to grow from US$10.9 trillion (2017) to US$12.9 trillion (2022) [4]. A sector with such an economic growth but with a negative environmental impact needs to innovate in order to reduce its carbon footprint. These are the reasons why, along this project, one of the most traditional components of the building façade will be re-designed. Glazing is a key component for the transformation of the built environment into a cleaner sector. Through glazing, radiation and natural light are received. With smarter window designs that make use of switchable films (films that change their transparency with different impulses) this reception could be done in a more efficient way. This can reduce the need of other artificial devices like air conditioning and light bulbs inside the buildings. Furthermore, if glazing is coupled with solar energy harvesting technologies like solar cells, an autonomous device can be created. A smart window that includes photovoltaic solar cells and an electrically switchable film is prototyped through this project. The selection of materials and construction of the window are explained through this document. Software modelling to recreate real life scenarios during a whole year are performed and the results are encouraging. An off-grid photovoltaic system that supplies energy to an electrically switchable film, all coupled in a glazing for building façade is technically possible, even in challenging environmental conditions.","fenestration; dimmable; photovoltaic; solar cell; energy; sustainabilty; built environment; building component","en","master thesis","","","","","","","","2020-08-30","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:06572701-d9be-4c72-939e-7f0835333436","http://resolver.tudelft.nl/uuid:06572701-d9be-4c72-939e-7f0835333436","Classification of Damages on Aircraft Inspection Images Using Convolutional Neural Networks: Kick-starting a Deep Learning project with limited data","Freiherr von der Goltz, Julian (TU Delft Mechanical, Maritime and Materials Engineering)","Pan, Wei (mentor); Kober, Jens (graduation committee); Pool, Ewoud (graduation committee); Nunez Vicencio, Alfredo (graduation committee); Delft University of Technology (degree granting institution)","2019","Aircraft inspections after unexpected incidents, like lightning strikes, currently require a timeconsuming and costly inspection process, due to the small size of the lightning strike damages. Mainblades Inspections is working on an automated, drone-based solution, that scans the aircraft hull with a high-resolution camera. The objective of this project is to assess the<br/>feasibility of using a deep Convolutional Neural Network (CNN) for (semi-)automated damage detection, with the goal of achieving a high recall (low False Negative Rate (FNR)) on the small damages. The problem is framed as a classification problem on limited and imbalanced data. However, it is not pre-defined if single-label or multi-label classification should be used,<br/>and both approaches are investigated.<br/>The main contribution of this work is to show experimentally how common deep CNN architectures and Deep Learning practices can be used to train classifiers that recognize damages in a specialized domain, with application-specific metrics. We present methods for synthesizing, pre-processing and re-sampling of the necessary dataset. It is shown that pre-trained, parameter-efficient CNN architectures that implement skip-connections, complemented by<br/>global max-pooling before the final layer, are well suited for that dataset. The Xception architecture has been chosen as backbone for the classifier due to its high recall and fast convergence. To mitigate the detrimental influence of imbalanced training data, training data re-sampling that equalizes the class distribution is implemented. It has a positive effect recall, especially<br/>when applied to multi-label classification. When using re-sampling and data augmentation, the performance of multi-label and single-label classification can be brought to the same level. However, the best achieved FNR is 5.4%, with a softmax classifier, combining all regularization methods.<br/>Finally, we investigated how regularization can be used to increase generalization capability with limited training data. Data augmentation is the most effective regularization method, even though its full potential has not been explored yet. Dropout benefits single-label classification<br/>but not multi-label classification. L2-regularization has a moderate positive effect on both. Naively combining the regularization techniques without an exhaustive grid search or automated search on average does not yield any additional gains and shows the limit of manual hyper-parameter tuning.","damage detection; deep learning; class imbalance; classification; convolutional neural networks","en","master thesis","","","","","","","","2024-08-30","","","","","",""
"uuid:87a82730-ebf5-47f2-a7ae-014275e51d02","http://resolver.tudelft.nl/uuid:87a82730-ebf5-47f2-a7ae-014275e51d02","Estimating the effects of technological progress: A data-analytic and agent-based approach","Ingwersen, Mylène (TU Delft Technology, Policy and Management)","Storm, Servaas (mentor); Nikolic, Igor (graduation committee); van Beers, Cees (mentor); Delft University of Technology (degree granting institution)","2019","This thesis investigates the effect of technological progress on the Dutch labour market. For this, a replication of the Frey and Osborne (2013) study on Dutch data is conducted. The application of the FO model has shown that approximately 12\% of the Dutch workers are at high risk of being replaced due to technological developments. Moreover, when simulating this risk, this study found that on average, 36\% of the Dutch workers can lose their jobs within 20 years due to technological progress. <br/>However, this analysis did not account for the possibility of retraining of workers and the strategic behaviour of workers and firms stemming from their uncertainty due to technological progress. To take these factors into account, an agent-based model was developed. By experimenting with this model, the average unemployment rate after 21 years dropped to 3\%. However, due to policy and scenario testing, the underlying unemployment rates of this average unemployment rate of 3\% varies greatly.","technological change; skill-demand; Employment; Dutch jobs","en","master thesis","","","","","","","","","","","","","",""
"uuid:5efbbf13-76b0-4fcf-848c-a7971c92e499","http://resolver.tudelft.nl/uuid:5efbbf13-76b0-4fcf-848c-a7971c92e499","Diffusion based temporal network embedding for link prediction","Li, Ziyu (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Multimedia Computing)","Wang, Huijuan (mentor); Zhan, Xiuxiu (mentor); Delft University of Technology (degree granting institution)","2019","Link prediction in complex networks has attracted increasing attention. The link prediction algorithms can be used to retrieve missing information, identify spurious interactions, capturing net- work evolution, and so on. Recently, network embedding has been proposed as a new strategy to embed network into low-dimensional vector space. By embedding nodes into vectors, the link pre- diction problem can be converted into a similarity comparison task. Nodes with similar vectors are more likely to connect. Some traditional network embedding methods include matrix factorization, random walk paradigm and deep neural network models. <br/>In this thesis, we propose SISNE, a diffusion based paradigm for node embedding, applying Susceptible-Infected-Susceptible (SIS) model to extract node neighborhood structure. Both random walk based algorithms and our proposed method sample node sequences as input and feed them into a Skip-gram model, a representative language model that embeds words into vectors. Specially, our proposed model provides flexibility to explore the network topology by operating in- formation spreading on networks. Another contribution of the proposed model is that SISNE takes into the account of the evolving nature of complex networks. To verify the efficacy, we conduct experiments on missing link prediction task and show that our SIS diffusion based model outperforms other state-of-the-art network embedding algorithms across all four empirical datasets, reaching a maximal 7% improvement. Importantly, even when the input size is small, the performance remains stable whereas other baseline models drop dramatically, which indicates that our proposed model is less sensitive to input size and suggests that the model is applicable to large-scale networks. Moreover, we further show that as long as the infection probability β is larger than the threshold value of the diffusion model, we can obtain a relatively high performance for link prediction task. Taken together, our work has shown great effectiveness and efficiency in learning embeddings in temporal networks.","Temporal Network Embedding; Link Prediction; Complex Network Analysis; Information Spreading","en","master thesis","","","","","","","","2020-12-31","","","","","",""
"uuid:75f3e25a-b991-4e85-ab8a-736a32383bb5","http://resolver.tudelft.nl/uuid:75f3e25a-b991-4e85-ab8a-736a32383bb5","Mesh Deformation Using Radial Basis Function Interpolation With Sliding Boundary Nodes","Mathew, Maria (TU Delft Aerospace Engineering)","van Zuijlen, A.H. (mentor); Delft University of Technology (degree granting institution)","2019","This thesis studies a novel mesh deformation method based on radial basis functions to improve mesh quality in regions with small wall clearances. For fluid-structure interaction problems or imposed motion CFD problems, the usually fixed Eulerian fluid meshes have to undergo deformation to conform to the deforming structure. In such cases, it is important that the fluid mesh retains a reasonably good mesh quality after deformation, since otherwise it can introduce additional errors to the numerical simulation. A suitably robust mesh deformation algorithm is required for this. A variety of mesh deformation methods exist, and the radial basis function (RBF) interpolation method is one of the most robust among these. However, in cases with large deformations in areas with small wall clearances, this method can still fail and the chances of degenerate or low-quality skewed cells occurring is high. If a poor quality mesh results, the domain might have to be re-meshed which is a tedious and computationally expensive procedure. <br/><br/>This thesis aims to combat this potential failure for low wall clearance test cases by modifying the RBF interpolation method to allow for sliding of the usually fixed boundary nodes along the boundary edges/surfaces. The additional degrees of freedom of the boundary nodes reduces skewing in meshes and allows for higher quality meshes in these types of test cases. In this thesis, the sliding method was first created to work on straight edges and planar surfaces, and then further extended to be able to work on any arbitrary surface. Tests were done with both 2D and 3D meshes. <br/><br/>Two sliding algorithm alternatives were tried during this project, with the first one having the sliding conditions built into the RBF interpolation system directly, while the second one performed the sliding in a more indirect manner by using a projection algorithm which ensures that the points remain on the surface. The first direct sliding method results in the interpolation calculations of the spatial directions being coupled to each other, which is not the case with the classical RBF method. This results in an interpolation system that is up to nine times as large (3Nx3N for N boundary points), and much less computationally efficient. The second pseudo-sliding method continues to use the decoupled system and is computationally faster to use. While it initially appeared to be promising, giving good final mesh qualities at low computational speeds for simple 2D cases, this second method was ultimately found to be less robust than the direct coupled method, failing especially with 3D meshes and irregular mesh boundaries. <br/><br/>The direct sliding RBF method was found to be more robust compared to the regular RBF method. The method gives good results with straight edges and planar surfaces, as well as smooth curves. However, when used with non-smooth irregular surfaces, the magnitude of sliding was affected, often resulting in almost no sliding. The method should be avoided in such cases as it is unprofitable. Apart from these cases, the method was able to achieve good improvements in mesh quality compared with the classical RBF method. For applications that have smooth surfaces without large surface irregularities, this method can be used to produce high quality deformed meshes.<br/><br/>Despite its robustness, the direct sliding method is not practical to use due to its large interpolation matrix unless some additional efficiency optimisation method is used. In this case, a control point selection algorithm was used such that fewer points were used to find the interpolation, resulting in a smaller system. With this algorithm, the computational time of the method was considerably reduced to being almost comparable with the classical RBF method (also with the same optimisation applied) particular for large test cases. Another method to reduce the total solution time of the direct sliding method is to use a reduced interpolation system that requires coupling of the interpolation coefficients thereby reducing the size of the interpolation matrix. This has only been briefly investigated but shows large improvements in solution time, while still effectively solving the same system without any reduction in control points.<br/><br/>This means that with the new method, much larger displacement steps can be used to arrive at the same or usually better final quality as obtained with the original RBF method, which results in faster computations. Of course, the time-step size is restricted by the maximum step of the CFD simulation itself. If the magnitude of the deformation is not too high, absolute deformation can also be used instead of relative deformation. This means that the interpolation system will need to be constructed and solved only once at the start of the run based on the initial mesh, resulting in large time savings for the deformation calculation. In conclusion, this method has great potential to be used for mesh deformations, since it can result in an improvement in both computation time and mesh quality.","mesh deformation; radial basis functions; sliding boundary; fluid-structure interaction; CFD","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:cc607dbb-7116-4c9f-991f-988d832833a9","http://resolver.tudelft.nl/uuid:cc607dbb-7116-4c9f-991f-988d832833a9","Wing deformation measurements of the DelFly II in different flight conditions","Heitzig, Dorian (TU Delft Aerospace Engineering)","van Oudheusden, B.W. (mentor); De Breuker, R. (graduation committee); de Wagter, C. (graduation committee); Olejnik, D.A. (mentor); Delft University of Technology (degree granting institution)","2019","This study investigates the wing deformation of the flapping-wing micro air vehicle (MAV) DelFly II in various flight configurations. Experiments were carried out with the MAV tethered in a windtunnel test section. To determine the best suited measurement approach, a trade-off study was carried out which showed that a point tracking approach with background illumination is most suitable. The therefore used high-speed camera pair and illumination were mounted on the same rotating frame with the DelFly, which allowed adequate viewing axes of the wings at for all pitch angles. Processing was done a purpose-build algorithm, allowing 136 points per wing to be measured simultaneously with an average lost point ratio of 3.4 % and an estimated accuracy of 0.25 mm. Results of hovering flight show some previously unnoticed behaviors. First, it was noted that the upper and lower wing on each side do not deform purely symmetric but show some considerable asymmetric behavior like heave and camber production. Furthermore, the upper wing shows a torsional wave and recoil behavior at faster flapping frequencies, which was shown to be beneficial in insect flight. Lastly, it was found that an air-buffer remains present between the wing surfaces at all times of the clap-and-peel motion (apart from the root trailing edge). This air-buffer increases once freestream velocity is added, which is investigated during the climbing flight study. Here, the reduced angle of attack of the wing is assumed to reduce the wing loading at faster climb, resulting in lower deformations outside the clap-and-peel motion. The isolated effect of a body pitch angle is also studied. Here, the asymmetrical freestream direction results in larger asymmetries such as wing alignment with the freestream direction and reduced camber and even camber reversal during the upstroke. In forward flight the pitch angle is changed simultaneously with the flapping frequency and freestream velocity. Due to the non-linear properties the wing deforms not directly as a superposition of the individual effects. Deviations are mostly present in increased asymmetry in incidence angle, while the camber behaves more linear and the clap-and-peel motion also remains relatively unchanged. The torsional wave and recoil are here however reduced. Descending flight was also tested. Velocities below 1m/s result in relatively minor deformation changes, while faster descent leads to large flapping frequency fluctuations, making interpretation of the results impossible.","DelFly; Flapping Wing; Deformation; Fluid Structure Interaction","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:b2215b25-3ae7-4f59-b1ae-4570787f12d3","http://resolver.tudelft.nl/uuid:b2215b25-3ae7-4f59-b1ae-4570787f12d3","Neural Network Modelling for Composite Damage Pattern Generation","Venkatesan, Karthik (TU Delft Aerospace Engineering)","Chen, B. Y. (mentor); Delft University of Technology (degree granting institution)","2019","This research project was initiated as a result of a curiosity and desire to investigate the applicability of surrogate modelling to analyse complex non-linear behaviour in aircraft structures. The study chose to focus on modelling damage in composite plates, and through a literature review, deemed that the generation of graphical outputs was a domain worthy of attention. Thus, the research questions subsequently formulated were centred around the modelling of artificial neural networks for the generation of damage patterns on composite plates.<br/><br/>Data for training and evaluating these neural networks was first generated through 20 finite element models solved using Abaqus 2017. Standard neural networks trained to directly reproduce these damage patterns, as well as reduced-image neural networks trained to reproduce a reduced formof these patterns (obtained using convolutional neural networks) were analysed, and both were found in want ofmore training data. The generation of a further 421 finite element models resulted in a striking improvement in the performance of both networks, but with the standard neural network outperforming the reduce-image neural network. Thereafter, it was discovered that a hybrid network that combined facets of the standard and convolutional neural networks performed superior to both.<br/><br/>In the process of training these networks, it was recognised that while the performance metrics served as an indicator of the resemblance between the predicted and actual outputs in terms of colours and contours, the same trends did not apply to the image quality. In order to improve the visual quality of outputs from the hybrid network, the use of the Structural Similarity Index (SSIM) was explored. It was eventually determined that pre-training the network using the Mean Square Error (MSE) as its optimising metric before then doing the final training using SSIM resulted in a model with impressive results. This fine-tuned model carried out predictions with a mean error of 0.0014 on theMSE metric and 0.9804 on the SSIM metric when evaluated on an independent dataset. Finally, the reliability and computational efficiency of the hybrid model was measured. It was found that approximately 95% of the MSE values on the independent dataset were within a value of 0.0040, while the same percentage of SSIM values were over 0.9100. The computation speed, meanwhile, improved by a factor of roughly 34 times on average, with the figure rising to over 443 on specific models.","structural; mechanics; machine; learning; artificial; neural; networks; damage; modelling; finite; element; method; analysis; image; output; graphical","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:687cf3e2-9287-4554-a233-864ed12ce9c6","http://resolver.tudelft.nl/uuid:687cf3e2-9287-4554-a233-864ed12ce9c6","Utilizing Martian Regolith for 3D Printing in Martian Conditions","Stulova, Victoria (TU Delft Aerospace Engineering)","Hedayati, R. (mentor); Delft University of Technology (degree granting institution)","2019","","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:737cc179-25c9-45dc-a220-d979d88b8818","http://resolver.tudelft.nl/uuid:737cc179-25c9-45dc-a220-d979d88b8818","Predictive Maintenance for Aircraft Systems: Using textual elements as covariates","Oudkerk, Thijs (TU Delft Aerospace Engineering)","Verhagen, W.J.C. (mentor); Delft University of Technology (degree granting institution)","2019","Unplanned maintenance is a costly factor in aircraft operations. Predictive Maintenance aims at reducing the surprise effect of unplanned maintenance and thereby its associated cost. A variety of statistical models are used to estimate the remaining life, as well as sensors to gauge component condition. The application to statistical models of sensory information coming from the pilot, in the form of pilot complaints, appears to be an overlooked option worth investigating. In other words: What is the effect of pilot complaints on the predictability of component removals? This question is answered by determining relevant words in the pilot complaints using a TF-IDF analysis and use the presence of these words as covariate in the well known Proportional Hazards Model. Left truncation and right censoring is applied to limit the time-invariant nature of these covariates. The results in the form of hazard ratios indicate a hazard increase of several orders of magnitude with respect to baseline hazard. These results are put into perspective when compared when compared to the known outcome of the pilot complaints, making their added predictability seem marginal. Another adverse indication is the violation of the proportionality assumption. The magnitude of the hazard ratios do suggest that additional<br/>measures in the from of a more in depth natural language processing and the application of time-varying covariates could bring the concept closer to practical application.","predictive maintenance; proportional hazards model; pilot complaint; covariate; hazard ratio; natural language processing; TF-IDF","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:8e6b1931-6d34-4b19-9beb-e26e20897ef4","http://resolver.tudelft.nl/uuid:8e6b1931-6d34-4b19-9beb-e26e20897ef4","Algorithm for Determining the Hosting Capacity of Independent PV, or EV Charger Systems: In Industrial and Commercial LV Networks, with Respect to Slow Voltage Variations and Voltage Unbalances","Christiaanse, Jennie (TU Delft Electrical Engineering, Mathematics and Computer Science)","Cobben, Sjef (mentor); Tindemans, Simon H. (graduation committee); Vaessen, P.T.M. (graduation committee); Delft University of Technology (degree granting institution)","2019","In this thesis, an algorithm that calculates the hosting capacity of independent PV, or EV charger systems was created. The hosting capacity is based on slow voltage variations and voltage unbalances caused by worst case PV generation and EV charging scenarios. The algorithm was run for four different commercial and industrial networks, and a range of network impedances. The outcome of the algorithm resulted into two figures for each of the networks, representing the possible installed capacity of PV and EV charger systems, respectively.","Voltage Variation; Voltage Unbalance; PV System; EV Charger System","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:ce520f94-bd3c-41a5-9ddd-edfdf6ead35e","http://resolver.tudelft.nl/uuid:ce520f94-bd3c-41a5-9ddd-edfdf6ead35e","Monocular Optical Flow based Attitude Estimation in Micro Aerial Vehicles: A Bio-Inspired Approach","Chatterjee, Abhishek (TU Delft Aerospace Engineering)","de Croon, G.C.H.E. (mentor); Olejnik, D.A. (graduation committee); Delft University of Technology (degree granting institution)","2019","The exceptional flight capabilities of insects have long amazed and inspired researchers and roboticists striving to make Micro Aerial Vehicles (MAVs) smaller and more agile. It is well known that optical flow plays a prominent role in insect flight control and navigation, and hence it is being increasingly investigated for applications in flying robots as well. However, optical flow based strategies for estimation and stabilization of orientation remain obscure in literature. In this report, we introduce a novel state estimation algorithm based on optical flow measurements and the knowledge of efference copies. The proposed technique estimates the following states of a flying robot (constrained to move with three degrees of freedom): roll angle, rate of change of roll angle, horizontal and vertical components of velocity and height. The estimator only utilizes the knowledge of control inputs and optical flow measurements obtained from a downward looking monocular camera. Through non-linear observability analysis, we theoretically prove the feasibility of estimating the attitude of a MAV using ventral flow and divergence measurements. Based on the findings of the observability analysis, an extended Kalman filter state estimator is designed and its performance is verified in simulations and through flight data recorded on a real flying robot. To the best of our knowledge, the introduced strategy is the first attitude estimation technique that utilizes monocular optical flow as the only sensory information.<br/><br/>Besides the investigation on optical flow based attitude estimation technique, this thesis presents a comprehensive literature survey on the main topics relevant to the work.","Bio-inspiration; Optical Flow; Insect flight; Attitude Estimation; Micro Aerial Vehicle","en","master thesis","","","","","","","","2022-09-01","","","","Aerospace Engineering","",""
"uuid:23459faa-2930-40c2-8463-bd4db1aa17cf","http://resolver.tudelft.nl/uuid:23459faa-2930-40c2-8463-bd4db1aa17cf","A Process Map for Applying BIM to Design for Deconstruction: Dutch Pavilion at Expo 2020 Dubai Case Study","Asgharzadeh, Fatemeh (TU Delft Civil Engineering and Geosciences)","Chan, P.W.C. (graduation committee); Koutamanis, Alexandros (mentor); Jonkers, H.M. (graduation committee); Hotchandani, Rajiv (graduation committee); Delft University of Technology (degree granting institution)","2019","Construction industry is the biggest waste producer industry in the world. Circular economy introduces methods to increase the recovery of materials’ value by returning them back to construction cycles; as its cornerstone, deconstruction is introduced to eliminate demolition. Design for Deconstruction (DfD) facilitates deconstruction at the end of building's lifetime by designing and planning. Availability of buildings’ information is also vital to achieve DfD goals. BIM is a suitable solution for interoperability of different information through different phases of a building lifetime, and between different participants. However, lack of standards for using BIM hinders its utilization. Desk research and case study provide theoretical and practical input to the research. By investigating the requirements of DfD and the practical issues that hinder the use of BIM, a process map is developed for applying BIM to DfD.","BIM; DfD; Deconstruction; Circular Economy; Process Map; Built Environment","en","master thesis","","","","","","","","2022-08-30","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:9255ff17-a051-4914-906a-91da6277880d","http://resolver.tudelft.nl/uuid:9255ff17-a051-4914-906a-91da6277880d","Designing and evaluating a social VR clinic for knee replacement surgery","Chen, Guo (TU Delft Industrial Design Engineering)","de Ridder, H. (mentor); Cesar, Pablo (mentor); Li, Jie (mentor); Delft University of Technology (degree granting institution)","2019","Knee osteoarthritis, the most common form of arthritis, which results in stiffness, pain, and impaired movement, is a major cause of disability in elderly populations around the globe. In the course of treating this disease, patients have to endure enormous pains travel to hospitals to meet medical professionals. The motivation behind this project is to support those patients with limited physical mobility to travel fewer times to the hospital but still, communicate well with doctors and nurses. The goal is to build a VR clinic that simulates the real consultation room and facilities in the hospital. <br/>An ethnographic study was conducted at a local hospital in Delft to map the patient treatment journey from the first consultation meeting to the last meetings after surgery. The patient education part of the patient journey was chosen as the focus of this thesis since it involves most of the patient-nurse communications compared to other parts of the journey. Based on the results of the ethnographic study, a social VR clinic was designed and implemented to assist the nurse in explaining the treatment process, and to show the anatomy models and the surgery room to the patient. <br/>The main contribution of this thesis is the design and evaluation of a social VR clinic, based on the use case of knee pain treatment. Future research can expand the consultation to other diseaseses, explore the impact of using more realistic avatars on the VR clinal experience. Other perspectives can be probed into to describe user portraits on their attitude of having VR consultations.","Social VR; Medisign; Medical communication","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:a242d5b5-ff2a-4216-b04c-6de185a1044d","http://resolver.tudelft.nl/uuid:a242d5b5-ff2a-4216-b04c-6de185a1044d","Validation of Sequentially Linear Analysis for Quasi-Brittle Behaviour of Reinforced Concrete Structures under Proportional and Non-Proportional Loading","Danks, Brigitte (TU Delft Civil Engineering & Geosciences)","Hendriks, M.A.N. (mentor); Rots, J.G. (graduation committee); Pari, M. (graduation committee); Yang, Y. (graduation committee); Delft University of Technology (degree granting institution)","2019","The aim of this thesis was to objectively and quantitatively assess the accuracy and robustness of two-dimensional sequentially linear analysis (SLA) in comparison to nonlinear finite element analysis (NLFEA), for a range of experiments of reinforced concrete structures with proportional and non-proportional loading schemes. Non-proportional loading refers to when two or more load cases act on a structure that do not increase or decrease in a proportional way. Accuracy was defined as the degree to which the finite element model's results match the experimental results. Robustness was defined as the method's ease of completing the computation and objectivity with respect to user-specified input. In selecting the benchmarks, experiments with brittle or quasi-brittle failures were targeted. Two experiments with proportional loading (a shear beam and a corbel) and three with non-proportional loading (a shear wall, a flexural beam, and a frame) were selected as the benchmarks. The frame is a single-span, double-storey frame, and thus consists of more structural elements than the other benchmarks. Each experiment chosen had previously been analysed using NLFEA by either the experiment conductor or another in academia. The five benchmark cases were modelled with SLA using a consistent solution strategy. The material constitutive models were discretised using the (standard) ripple band width saw-tooth law, which defines an upper and lower band of the softening and plasticity relations via a factor (p) of the material strength. Four performance parameters were devised to assess the performance of the SLA and NLFEA for each benchmark in the pre-peak, peak and post-peak stages, by comparing the modelling of the structural stiffness, peak load, ductility and ability to model post-peak behaviour to experimental results (where applicable). Inhibitors to the method's accuracy include the inaccurate modelling of stress reversal, which creates unrealistic crack openings and closures; delayed and limited yielding of reinforcement due to the discretisation of the Von Mises plasticity, resulting in overestimation of structural capacity and underestimation of ductility; lack of consideration of geometrical non-linearity; and small inaccuracies in the modelled saw-tooth relations resulting in some overestimation of reduced strength values during material softening and spurious transverse crack strains. Additionally the accuracy was limited by the simplification of the concrete material model and use of the linear tensile softening relation. Inhibitors to the robustness of the SLA included lack of objectivity to some user-specified input and intermittent proportional loading limiting the amount of post-peak behaviour successfully modelled in the non-proportionally loaded benchmarks. Overall, SLA was found to have a comparable level of accuracy with NLFEA in modelling reinforced concrete structures in both proportional and non-proportional loading scenarios, with many benefits observed in terms of increased robustness. The inaccurate stress reversal algorithm can severely affect the robustness of non-proportionally loaded cases and resolving this inaccurate formulation of crack closure in SLA should be a priority in future developments.","Sequentially; linear; analysis; finite; element; non-proportional; loading; reinforced; concrete; structures; accuracy; robustness; objective; validation; DIANA","en","master thesis","","","","","","","","","","","","Civil Engineering | Structural Engineering | Structural Mechanics","",""
"uuid:29c3fce7-cc34-4655-a98f-42bcf17f8e82","http://resolver.tudelft.nl/uuid:29c3fce7-cc34-4655-a98f-42bcf17f8e82","Adding QUIC support to the Tor network","Sabée, Wendo (TU Delft Electrical Engineering, Mathematics and Computer Science)","Pouwelse, J.A. (graduation committee); Roos, S. (mentor); Yorke-Smith, N. (graduation committee); Delft University of Technology (degree granting institution)","2019","Privacy in the Internet is under attack by governments and companies indiscriminately spying on everyone. The anonymity network Tor is a solution to restore some privacy, however, Tor is slow in both bandwidth and latency. It uses a TCP-based connection to multiplex different circuits between nodes and this causes different independent circuits to interfere with each other. To solve this, we propose a transport layer implementation using the UDP-based protocol QUIC, as it allows independent streams over a single connection. We built a Tor prototype that uses this protocol and evaluated its performance using a custom network simulator, as existing simulators were shown to be incompatible. We show that the QUIC-based implementation increased performance in several of the use case scenarios, mainly outperforming on the ‘time to first byte’ metric.","tor; quic; anonymity; privacy","en","master thesis","","","","","","","","","","","","Electrical Engineering | Embedded Systems","",""
"uuid:25161e10-eb44-4e2f-95c2-25829f4aeda9","http://resolver.tudelft.nl/uuid:25161e10-eb44-4e2f-95c2-25829f4aeda9","Thermal and flow characterisation of a small scale alkaline electrolysis system for hydrogen production","Sriram, Karthick (TU Delft Mechanical, Maritime and Materials Engineering)","Haverkort, J.W. (mentor); Breugem, W.P. (graduation committee); Henkes, R.A.W.M. (graduation committee); van Kranendonk, J. (mentor); Delft University of Technology (degree granting institution)","2019","Zero Emission Fuels (ZEF B.V.) is a start-up working to build a sustainable methanol micro-plant. Carbon dioxide and water are obtained from atmosphere. Hydrogen is obtained from captured water through alkaline electrolysis and the hydrogen is used for methanol production. The alkaline electrolyser should run at 50 bar and 90°C with 30% KOH as the electrolyte. It is a multi-cell design and the electricity supplied to the electrolyser leaks within the system through the electrolyte. This is the energy supplied to the system not being used for splitting water into hydrogen and oxygen. Leaking current and flow scale with the length and the radius of any channel in the system and contradict each other in terms of requirements.<br/>This study focuses on characterising the electrolyser to validate a modified version of the existing Matlab model at a channel in the system for two different dimensions of the channel. The Matlab model predicts<br/>the flow and the leaking currents in the system. Estimating the flow in the system is essential to validate the model and using the model, the leaking currents are estimated. Experiments were performed on a single cell version of the electrolyser at atmospheric pressure to obtain the flow and thermal characteristics. Comsol simulations were ran on the single cell system to support the Matlab results. <br/>The heating curve of the system was obtained at four different points in the system to check for the necessity of insulation. The system went up to 56°C at the hottest point in the system after 2 hours. This confirmed for the necessity of insulation. The diameter of the bubbles at the electrode were measured and compared to the estimated diameter in Matlab. They were 34% off. The flow part of the experiments were done at a lower current density to simulate 50 bar flow at 1 bar. The flow rate of the electrolyte was estimated using high speed cameras and tracking fluorescent particles at one of the channels in the system. The values of the flow rate from Comsol, Matlab and Comsol were 25% away from each other whereas Matlab and experiments were 65% away from each other. The mass flow rate predicted by Comsol was in between Matlab and experiments. The absence of a temperature network to estimate temperature at every part of the system, the approximate geometry and ignoring smaller resistances to flow in the Matlab model are responsible for the offset.<br/>Leaking currents were estimated in the single and multi-cell system using Matlab. The power lost due to leaking currents were higher in the multi-cell system as compared to the single cell system. The reduction in leaking currents by using gas slugs was estimated and the current design achieves the electrical efficiency of 99%. Recommendations were to make the channel diameter larger and remove the part of the channel that is in the cell. Further modifications to the Matlab and Comsol model were suggested to improve the prediction. Experiments related to multi-cell setup have to be done to estimate the actual electrical efficiency of the system and validate the Matlab model.","Electrolysis; thermal; flow; Alkaline electrolysis; Alkaline Electrolyzer; COMSOL Multiphysics; Multiphase Flow","en","master thesis","","","","","","","","2021-12-31","","","","Mechanical Engineering | Energy and Process Technology","Zero Emission Fuels",""
"uuid:466c4795-5a77-4411-ae80-7f38f6f15c25","http://resolver.tudelft.nl/uuid:466c4795-5a77-4411-ae80-7f38f6f15c25","Design of a new terminal device combining voluntary opening and voluntary closing","Peeters Weem, Froukje (TU Delft Mechanical, Maritime and Materials Engineering)","Plettenburg, D.H. (mentor); Delft University of Technology (degree granting institution)","2019","Upper limb amputees, using a body-powered prosthesis, generate energy with their shoulders which leads to opening or closing of the prosthesis. The preference for one of these types, voluntary opening (VO) or voluntary closing (VC), differs for individuals and for task specifics. Research is, therefore, done regarding terminal devices which provide both types. Earlier presented hybrid devices are heavy, do not provide mechanical advantage or present a difficult switching procedure. A novel VO/VC device was presented, with the promising features of easy switching and good mechanical performance. However, in user tests this device did not perform well, mainly because of its finger shape. <br/>The goal of this study is to improve the grasping performance of the VO/VC device. Changing fingers did not create a device which could fulfil all the requirements. Instead, another idea was embodied, prototyped and tested. <br/>This device is able switch between VO and VC, by the use of two separate pivot points. Switching between the two is done with a bi-stable mechanism, which is activated by the intact hand. Results show that the device can be used in both modes and that users are able to switch with the bi-stable mechanism, but the mechanical properties do not meet the requirements. Additionally, the device performs less than expected on the user test, due to the bad mechanical properties and misalignments in the 3D-printed prototype. The device created is a good proof of principle for using two pivot points to shift between VO and VC. However, the bi-stable mechanism did not function as expected and a lot of friction is present leading to high forces in the cable. It is recommended to change the material, focus on using other springs which allow for larger opening widths and generate less friction and change the switching system to increase usability and safety.","prosthesis; terminal device; voluntary opening; voluntary closing; body-powered; upper limb","en","master thesis","","","","","","","","2022-04-12","","","","Mechanical Engineering","",""
"uuid:1b6037cf-6cb9-4ebf-b9c2-25e7fa6cf575","http://resolver.tudelft.nl/uuid:1b6037cf-6cb9-4ebf-b9c2-25e7fa6cf575","Numerical investigation of nearshore wave transformation and surf zone hydrodynamics","Patil, Akshay (TU Delft Civil Engineering and Geosciences)","Reniers, A.J.H.M. (mentor); Bricker, J.D. (graduation committee); Lashley, Christopher H. (graduation committee); Jacobsen, Niels G. (graduation committee); Lowe, Ryan J. (graduation committee); Oosterlo, P. (graduation committee); Delft University of Technology (degree granting institution)","2019","Rapid climate change and the corresponding estimated sea level rise can affect the performance of the coastal defense structures such as breakwaters, seawalls, and dikes. In order to improve these coastal defenses, a detailed understanding of the processes which contribute to wave run-up and overtopping over the coastal defenses needs to be established. Following the exponential growth of computing capacity around 1970’s, a wide variety of computational models were developed to study fluid flow. Traditionally, three computational paradigms have existed in order to study wave transformation and surf zone hydrodynamics: phase averaged models, phase resolving models, and Computational Fluid Dynamics (CFD) models. Limitations posed by the underlying linear wave theory in phase averaged and other simplifications in the phase resolving models, may not provide sufficient detail in wave breaking, wave energy dissipation, wave run-up, wave overtopping, and potentially other detailed hydrodynamic processes. This lack of resolution in depth averaged models for wave-breaking, wave run-up, and wave overtopping processes motivates a detailed investigation using CFD based models, which can correctly mimic wave-breaking and other hydrodynamic processes.<br/><br/>The recent growth in available computational capacity has greatly improved the applicability of CFD based models for large scale transient flows such as waves near a coast. Additionally, the developments in wave generation and wave absorption boundary conditions by Jacobsen et al. [2012] in the open-source CFD toolbox OpenFOAM, have facilitated the use of OpenFOAM in coastal engineering applications. This encourages investigating the coastal environment using relatively complex models, thus providing insights into fundamental processes which contribute to coastal safety. To that end, this thesis focuses on investigating wave overtopping and the underlying processes which contribute to the aforementioned hydrodynamic aspects.<br/><br/>Overtopping demands accurate capture of the free surface (interface between water and air). The waveFoam solver suffers from numerical diffusion of the interface, consequently requiring a different approach to mimic the sharp interface. In order to cater to this deficiency, a new solver which combines the capabilities of waveFoam [Jacobsen et al., 2012] and isoAdvection [Røenby et al., 2016] which has the ability to capture sharp interfaces by means of a sub-grid approach has been integrated (waveFlow) and used in this study. In addition to the new solver, a new set of Reynolds Averaged Navier-Stokes (RANS) closures developed by Larsen and Fuhrman [2018] for wave modeling applications have been employed to correctly capture turbulence levels under breaking waves. The preliminary steps include calibrating and assessment of the newly integrated waveFlow solver. Using a relatively simple conceptual test case, a comparison of the free surface behavior and overtopping discharge was carried out. This calibration test was followed by a comparison of numerical results with the experimental investigations carried out by Ting and Kirby [1994]. Following this benchmarking study, experimental studies carried out by Flanders Hydraulics investigating wave overtopping over dikes in shallow foreshore environments was validated. A comparison of waveFlow and waveFoam was made to assess the qualitative and quantitative differences between the two interface capture methods on overtopping. Using this new solver, OpenFOAM was able to reproduce the surface elevation and significant improvement in the overtopping results were obtained for identical model setup in comparison to the waveFoam solver. A coupled approach using a potential flow solver named OceanWave3D aided simulation of large domain wave propagation and helped to cut down the computational time.","OpenFOAM; isoAdvection; Wave Breaking; Overtopping; CFD; Turbulence","en","master thesis","","","","","","","","","","","","Civil Engineering | Hydraulic Engineering","",""
"uuid:21d5278f-2c57-4fa4-9078-299512e6ee04","http://resolver.tudelft.nl/uuid:21d5278f-2c57-4fa4-9078-299512e6ee04","Wave runup on fringing reefs with paleo-stream channels","Rey, Annouk (TU Delft Civil Engineering & Geosciences)","Reniers, A.J.H.M. (mentor); Tissier, M.F.S. (mentor); de Schipper, M.A. (mentor); van Dongeren, Ap (mentor); Storlazzi, Curt (mentor); Delft University of Technology (degree granting institution)","2019","Many tropical coastlines are fronted by coral reefs and are increasingly exposed to wave attack and wave-driven marine flooding. This problem demands immediate attention as safe habitability of and social and economic activity in reef-lined coastal regions are under serious threat, while these regions are known to have some of the world’s highest population densities.<br/>High runup events and flooding on coral reef-lined coasts have been subject of recent studies, and some valuable insights are gained. It was found that the recent increases in wave attack, high runup events, and coastal flooding are primarily due to high offshore water levels coinciding with high energy swell events, circumstances which will become more frequent with sea-level rise. Increasing water depth over the reef changes the hydrodynamics across the reef in such a way that larger incident-band and infra gravity-band waves reach the shoreline, causing high runup levels and flooding of the land behind the shoreline.<br/>However, little is known about the influence of longshore variations on runup and flooding of reef-lined coasts, while most show significant longshore variations, of which shore-normal paleo-stream channels are a prevalent one. This study aims to fill in that knowledge gap by examining the influence of paleo-stream channels on runup along reef-fronted shorelines, specifically during extreme wave conditions. <br/>With a system analysis we determine the range of naturally occurring topographies of reef-channel systems and determine a representative reef. Results of this analysis are a useful starting point for future studies on this subject. <br/>With a parametric study using the numeric model XBeach, we show that the presence of a channel results in a strong circulation on the reef flat and significant longshore variation of runup. Depending on the geometry and forcing, runup levels are increased next to the channel or inside the channel. This impact of the channel increases for higher incident waves, lower incident wave steepness, wider channels, a narrower reef and shorter channel spacing. Longshore variation of infragravity wave height is responsible for large scale variations in runup, while setup, short waves and very low frequency wave heights cause a local increase of runup inside the channel.<br/>Results of the parametric study are valuable as they provide insight in which locations on a coast are most vulnerable to high runup events, using only widely available data such as reef geometry and offshore wave conditions. This is relevant for prediction of coastal hazards and to guide coastal management policies. Furthermore, this study provides insights for future studies on flood risk of reef-lined coasts, as it illustrates the importance of accounting for longshore variations while schematizing a coastline to predict high runup and coastal flooding, for instance to assess when a 1D schematization is sufficient and when a 2D model is required.<br","Fringing coral reefs; runup; paleo-stream channels; XBeach Non-hydrostatic","en","master thesis","","","","","","","","","","","","Civil Engineering","",""
"uuid:b2af9a8c-d96f-4e01-b668-fe001a9dbae5","http://resolver.tudelft.nl/uuid:b2af9a8c-d96f-4e01-b668-fe001a9dbae5","Smart controlled-release of corrosion inhibitors for improved corrosion performance of coated metallic parts in automotive","Rath, Vineet (TU Delft Mechanical, Maritime and Materials Engineering)","Gonzalez Garcia, Yaiza (mentor); Schoukens, Ine (graduation committee); Delft University of Technology (degree granting institution)","2019","Corrosion on the car underbody can damage critical parts, which poses safety risks. The current corrosion protection methods such as wax, sealers and coatings are not effective enough and an advanced form of corrosion protection is desired. Implementation of smart coatings containing corrosion inhibitors can be an effective solution. These corrosion inhibitors should be available at the onset of corrosion and should not react with the coating matrix. The present study deals with implementation of a corrosion inhibitor into a coating over two metallic substrates used in the car underbody. After the initial breakdown of inhibitor particles into finer sizes, encapsulation using a novel technique was performed to prevent interaction of inhibitor with the coating matrix. This encapsulated inhibitor was further studied to understand its release characteristics under the influence of corrosive pH. Finally, electrochemical performance (EIS and SST) of coated samples containing encapsulated inhibitor was studied with respect to bare inhibitor and no inhibitor coatings. Addition of the encapsulated inhibitor improved corrosion performance. Differences were found in the inhibitor release and protection efficiency for both the substrates.","corrosion; car underbody; smart coatings; inhibitors; encapsulation; EIS; SST","en","master thesis","","","","","","","","2023-09-01","","","","Mechanical Engineering","",""
"uuid:feac6e55-43a7-4829-9aea-a9626a01eb63","http://resolver.tudelft.nl/uuid:feac6e55-43a7-4829-9aea-a9626a01eb63","Synchronized quantum network emulator using discrete event simulation","Wubben, Leon (TU Delft Electrical Engineering, Mathematics and Computer Science)","Wehner, Stephanie (mentor); Dahlberg, Axel (mentor); Delft University of Technology (degree granting institution)","2019","","quantum; QNetSquid; simulation; simulaqron; emulation; Quantum information; network; quantum internet; NetSquid; discrete event simulation; synchronization","en","master thesis","","","","","","","","","","","","Computer Science | Software Technology","",""
"uuid:7a6c86f0-37a9-46a4-b75d-253dfe62fe3a","http://resolver.tudelft.nl/uuid:7a6c86f0-37a9-46a4-b75d-253dfe62fe3a","Design of a Fully Electric (Battery/Fuel Cell) Submarine","Venema, Menno (TU Delft Mechanical, Maritime and Materials Engineering)","Boogaart, Rolf (mentor); de Vos, Peter (mentor); Visser, Klaas (graduation committee); Wellens, Peter (graduation committee); Delft University of Technology (degree granting institution)","2019","To improve the submerged time of diesel-electric submarines (SSK), air independent power (AIP) systems have been developed in the past. So far only submarines with AIP systemsin combination with one or more diesel generator (DG) sets are designed and built. The increased technological readiness level of modern fuel cells (FC) and the energy density of modern lithium-ion (li-ion) batteries trigger the possibility of a fully electric submarine. This concept of hybrid FC-battery energy storage and generation could eliminate the requirement for DG sets and a snort system to charge the batteries. The operational advantages in terms of improved indiscretion rate, reduced maintenance and smaller crew, silent energy conversion and reduced complexity of the ship systems design could have a great impact on conventional submarine design. In this thesis the design changes due to a switch to a fully AIP plant are described and a submarine concept design is created. The design should have the same submerged displacement and sprint capacity as a set reference design. The selected AIP plant uses a proton exchange membrane fuel cell (PEMFC), lithium iron phosphate (LFP) batteries and hydrogen stored in high pressure bottles. The design is based on a reference design from which the diesel related systems and batteries were removed. Since the new power plant requires less maintenance also the crew size was reduced, which resulted in a smaller accommodation. The removal of systems and the smaller accommodation resulted in a freed up volume for the new power plant. Using a matlab program that systematically generates power plant configurations within the available volume an ideal power plant is selected. The selection criteria is set to maximum<br/>range, while still satifying the speed requirements. Subsequently, this power plant is integrated in the design. Other aspect that are considered during the design are the electric load balance, the heat balance, air quality and the type<br/>of main electric motor. Also the trim and stability are considered. This results in a concept submarine design. Finally, the new concept design is compared with the reference design on the aspects mentioned earlier. For the range and endurance a fully battery powered submarine is also included in the comparison. The results show that the reference design has a three times higher maximum range and endurance than the concept design. However, when the indiscretion rate (IR) was taken into account the full potential of the concept design became clear. The IR of the concept design is 0%, which means it can operated underwater for the entire range and endurance. This is a large improvement over the reference design, which has to snort on regular intervals. When the concept is compared with the fully battery power submarine the maximum range and endurance are approximately doubled. As always, it all depends on the desired operational profile of the user whether the design is the most suitable option; however, it is expected that for most navies the created design is a significant<br/>improvement over the diesel-electric alternatives. Considering all aspects above it can be concluded that the concept design with PEMFC, LFP batteries and compressed hydrogen is capable to perform short to middle long missions, while provided their operating navies with significant operational advantages like 0% IR, lower acoustic signature and smaller crews.","Submarine; Air Independent Power (AIP); PEMFC; Indiscretion rate; Submerged time; Diesel electric","en","master thesis","","","","","","","","2024-08-28","","","","Marine Technology | Marine Engineering","",""
"uuid:fcdd6b06-ecb5-4d4f-9795-f4130c3ab7f6","http://resolver.tudelft.nl/uuid:fcdd6b06-ecb5-4d4f-9795-f4130c3ab7f6","Quantum correlation matrices and Tsirelson’s problem: Previous work and three-player considerations","Vos, Gerrit (TU Delft Electrical Engineering, Mathematics and Computer Science)","Caspers, Martijn (mentor); Delft University of Technology (degree granting institution)","2019","Tsirelson once claimed that the set of quantum correlations, defined by strategies of non-local two-player games, does not depend on which of two possible models is chosen: the tensor product model or the commuting operator model. He later came back from this claim, and the resulting conjecture is now known as Tsirelson’s problem. The problem has since been proven equivalent to notoriously hard problems in operator theory, such as the Connes’ Embedding Problem and the QWEP conjecture. In this master thesis, we look at the finite dimensional case of Tsirelson’s problem, working out all the details of an existing proof and giving a new, shorter proof which also extends to the nuclear case. Moreover, we give an overview of the equivalence of Tsirelson’s problem and two of Kirchberg’s conjectures, including the QWEP conjecture. Finally, we give some results and considerations for the three-player case of Tsirelson’s problem.<br/>The appendix contains proofs of many related results used throughout the thesis, and also a beginner’s introduction to quantum mechanics.","Operator Algebras; Quantum Information Theory; Tsirelson's problem","en","master thesis","","","","","","","","","","","","","",""
"uuid:1b9e8cce-bdfa-42df-9730-7846bdbaaa39","http://resolver.tudelft.nl/uuid:1b9e8cce-bdfa-42df-9730-7846bdbaaa39","The Employee Experience Pyramid: transforming organizations into places people want to work","Storm, Rosa (TU Delft Industrial Design Engineering)","Guerreiro Goncalves, Milene (mentor); Klitsie, Barend (mentor); Timmer, Jelte (graduation committee); Delft University of Technology (degree granting institution)","2019","Over the past decades, multiple HR constructs have emerged that organizations strived to adopt and integrate into their daily businesses. The most recent development is Employee Experience (EX). EX is essentially a framework for creating engaged employees. Engaged employees have been linked to multiple desirable business outcomes, such as smoother employee recruitment, increased employee retention, increased employee efficiency and higher organizational profitability. EX can be defined as the sum of perceptions employees have about their interactions with the organization, and how this aligns with their expectations. This graduation project aims to explore how organizations can improve EX. It was carried out for Livework, a Rotterdam based Service Design studio. The project explores how organizations are currently working on EX, what creates excellent EX and how organizations can receive the tools to understand and improve EX. A literature review is conducted on the evolution of HR constructs. Relevant insights from established constructs, such as motivation and job satisfaction are collected and related to EX. To understand how organizations understand and currently address EX, a set of interviews is conducted. This set of interviews yields a three-step model that describes what needs to be done to improve EX. The three steps are: <br/>1. Learning about the value of EX<br/>2. Learning how to improve EX<br/>3. Measuring impact.<br/>To structure the large amount of information available on EX, a model is selected. First, six different models are compared to assess their suitability for structuring EX. Finally, one model is selected and further adapted to create the EX pyramid. The pyramid depicts five employee needs that organizations need to satisfy to create excellent EX: Safety/Security, Rewards, Connection, Growth and Work/Life harmony. The EX pyramid and the EX cycle provide all the information an organization needs to improve EX. Ideas are generated to design the way this information is communicated to Livework, who this project was carried out for, and their client organizations. The problem statement used to guide the phase of idea generation and prototyping is: How can organizations adopt fitting EX strategies? The final design is the EXcellent process: a process towards excellent EX. This process consists of three phases: prepare, understand, and imagine. During the prepare phase, Livework consults the EX pyramid to create a better understanding of the model, which is used throughout the process. During the understand phase, Livework and the client conduct qualitative and quantitative research to understand how well the organization is satisfying their employees’ needs. In addition, the business objectives of the organization provide direction for the pyramid levels that needs to be improved. During the imagine phase, Livework and the organization define interventions that will be used to improve specific levels of the pyramid. A digital slide deck of over seventy interventions provides inspiration for these improvements. The outcomes of the EXcellent process are a better understanding of employee needs, business objective and how they together deliver concrete steps an organization can take to improve EX.","Employee Experience; Human Resources; Service Design; Motivation","en","master thesis","","","","","","","","","","","","","",""
"uuid:7040e7e9-5547-4294-8dd2-ffb9486e5b74","http://resolver.tudelft.nl/uuid:7040e7e9-5547-4294-8dd2-ffb9486e5b74","Design of CMOS Voltage References for Ultra-Wide Temperature Ranges","Padalia, Pinakin (TU Delft Electrical Engineering, Mathematics and Computer Science)","Sebastiano, Fabio (mentor); Charbon, Edoardo (graduation committee); Fan, Qinwen (graduation committee); Delft University of Technology (degree granting institution)","2019","Voltage references are one of the fundamental building blocks for designing any analog processing circuit. It serves as a reference for Analog to Digital Converters (ADCs), Digital to Analog Converters (DACs), power/voltage regulators and other measurement and control circuits. The performance of all these circuits cannot be better than the performance of the reference. Hence, it is very important that the voltage reference is very robust and performs reliably under process, supply, temperature or noise variations (PVT &amp; N). Today, with the development of scalable quantum computing, there is a need for such a reference operating at cryogenic temperatures. Currently, the state of the art quantum circuits operates at ∼20 mK. To process and control the information flow, to and from these quantum processors, one requires an analog circuit to operate as close as possible to the quantum circuit, so as to make the full system scalable and more reliable since no line interconnect to room-temperature electronics would be required. As a step towards that idea, it is desired to push the operating temperature of the classical circuits as low as 4 K where enough cooling power is available without disturbing the operation of the quantum circuit. One of the basic blocks to be shifted to cryogenic temperatures is the voltage reference circuit. This thesis presents a systematic design of such a cryogenic voltage reference block, taking into account the device and circuit performance at 4 K. The targeted specifications are comparable to the references designed for standard industrial temperature range (233 K to 400 K). However, it is designed to work over an extremely wide temperature range (4 K to 400 K) to understand how far one can stretch the circuits designed with conventional CMOS. Two different variants of references are presented with the simulated performance of both over the industrial temperature range. A novel approach towards higher-order compensation is also presented which is expected to perform better than conventional CMOS reference over a wide range. To test their performance over the entire operating range (4 K to 400 K) and verify the designs, a tape-out is planned for October 2019.","Cryo-CMOS; Voltage Reference; 40-nm; Cryogenic electronics; Ultra-wide temperature range; Quantum Computing","en","master thesis","","","","","","","","2024-08-31","","","","","",""
"uuid:2e793ece-4572-4bb6-83e3-541be467cb4f","http://resolver.tudelft.nl/uuid:2e793ece-4572-4bb6-83e3-541be467cb4f","Multi-task learning of transcriptomic signatures underlying cancer gene dependencies","Rentroia Pacheco, Barbara (TU Delft Electrical Engineering, Mathematics and Computer Science)","de Pinho Gonçalves, Joana (mentor); Delft University of Technology (degree granting institution)","2019","Due to their altered genetic context, cancer cells can become dependent on specific genes for their survival. Such cancer-specific dependencies may represent promising therapeutic targets. However, knowledge on which molecular features of cancer cells induce specific dependencies is still limited and hampers the development of effective targeted therapies. Several large scale studies have systematically measured the dependency of hundreds of known cancer cell lines on thousands of genes using gene silencing. These data have enabled the learning of supervised models to predict dependencies of cancer cells on each gene based on molecular features of the cells. In particular, linear regression with regularization, such as Elastic Net, has been used to select molecular features associated with such dependencies. Since these approaches model dependencies for each gene independently, the selected features provide limited insight into common mechanisms underlying gene dependency. Moreover, they may fail to identify robust associations with gene dependency due to the small size of the available training data. In this work, we apply a multi-task learning approach (Macau) to learn the relationship between transcriptome and gene dependency in cancer cell lines for multiple genes simultaneously. To do so, Macau projects genes, cancer cell lines and their features into a shared latent space. We explore this latent space to go beyond linking individual transcriptomic features with dependencies, and further associate pathway changes with functionally related genes without enforcing prior knowledge on pathway structure. Although Macau and Elastic Net yield similar predictive performance, they find different kinds of associations. First, Macau favors features that are relevant for predicting dependency across multiple genes. Second, Macau captures inherent functional relationships between genes and leverages these to predict cancer gene dependencies. Additionally, Macau can recover similarities between cancer cell lines belonging to the same cancer type based on their dependencies only. In summary, modelling cancer dependencies simultaneously for multiple genes can reveal underlying mechanisms shared by functionally related genes, which would be missed when learning models independently per gene.","bioinformatics; multi-task learning; cancer dependencies; cancer genomics","en","master thesis","","","","","","","","","","","","Computer Science | Data Science and Technology","",""
"uuid:e14d3c49-423e-4fd4-b729-1341ea380714","http://resolver.tudelft.nl/uuid:e14d3c49-423e-4fd4-b729-1341ea380714","Smarter Charging: Modeling optimal EV charging in solar parking lots for reducing peak demand, considering uncertainty in solar power forecasting and EV energy demand","Snow, Yitzi (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Wijk, Ad (mentor); Ghotge, Rishabh (mentor); Delft University of Technology (degree granting institution)","2019","Smart charging offers the potential for electric vehicles to use renewable energy more efficiently, lowering costs and improving the stability of the electricity grid. Many computer models have been developed to simulate the behavior of smart charging. Yet these models often assume that future information is known perfectly, including when vehicles will begin charging and how much solar energy will be available at that time. In reality, this information is subject to uncertainty, meaning the performance of smart charging may be worse than predicted by these models. This report details the development of an improved model which considers future uncertainty in smart charging behavior. It is determined that uncertainty does decrease the effectiveness of smart charging, but with strategies that are able to robustly consider this uncertainty smart charging can still offer tremendous benefits over traditional uncoordinated charging.","Solar; Electric Vehicle; Smart charging; optimization; forecasting; modeling; Smart grid; Uncertain systems","en","master thesis","","","","","","","","","","","","","",""
"uuid:ed146063-59c1-4175-88d4-64b452d617db","http://resolver.tudelft.nl/uuid:ed146063-59c1-4175-88d4-64b452d617db","Evaluating Explanations for different Relationship Strengths","Prasad, Nivedita (TU Delft Electrical Engineering, Mathematics and Computer Science)","Tintarev, Nava (mentor); Bozzon, Alessandro (graduation committee); Scharenborg, Odette (graduation committee); Najafian, Shabnam (mentor); Delft University of Technology (degree granting institution)","2019","People like to travel in groups to visit places. Group recommendation systems can be used to recommend an itinerary of ""places of interests"" (POIs) in an ordered sequence. The order of POIs in the sequence can be explained to group members to increase acceptance of the recommended items. There is a possibility that explanations which reveal names and rating preferences could create a threat to privacy. The main study in this work uses two group types - a primary group consisting of closely-related members, and a secondary group consisting of loosely-related members. Explanations with either complete information or privacy-preserving information are offered alternatively to these groups. The purpose of this study is to evaluate whether different group types need different types of explanations to improve their satisfaction. These explanations explain the entire recommended sequence of POIs with regard to possible conflicting situations that could occur due to disagreement with the order of the sequence. A total of 25 participants took part in the evaluation. There was no significant difference identified between the explanation types preferred by each group type. To understand the underlying reason for this result, a post-hoc analysis was done. We identified a participant's most frequently used conflict-handling modes using the Thomas-Kilmann personality assessment test. We then analyzed the user comments provided during the questionnaire. The analysis potentially suggests that different conflict-handling modes could be a factor affecting which explanation type was preferred by a person when they are in a particular group (e.g. primary vs secondary).","Explanations; Group Recommendation; Relationship Strength; Privacy; Sequences; User Satisfaction","en","master thesis","","","","","","","","","","","","Computer Science | Data Science","",""
"uuid:6b671bde-80ca-4852-b626-dc290f0ab652","http://resolver.tudelft.nl/uuid:6b671bde-80ca-4852-b626-dc290f0ab652","Super-resolution Algorithms for Target Localization using Multiple FMCW MIMOs","Zhang, Jiadi (TU Delft Electrical Engineering, Mathematics and Computer Science)","Yarovyi, Olexander (mentor); Wang, Jianping (mentor); Kooij, Bert (graduation committee); Lopez Dekker, Paco (graduation committee); Delft University of Technology (degree granting institution)","2019","In this thesis, the joint DOA-range estimation of stationary targets is investigated using multiple FMCW MIMOs with super-resolution capability. To address the low azimuth resolution problem of single small MIMO, a novel topology of array is used, which consists of multiple MIMOs arranged along the azimuth to increase azimuth resolution by extending the effective aperture size. According to such topology, signal models are formulated using FMCW waveform. To accurately model the scenarios, targets are considered as near-field objects for the system, but they are treated as far-field targets for each MIMO. <br/><br/>After formulating signal models, two algorithms are investigated and tested to localize targets in the observing domain. The generalized 2D-MUSIC algorithm is applicable for both multi-static and mono-static configurations of the system. The FBSS technique is used to tackle highly correlated signals. Though this algorithm provides super-high resolutions, it requires prior knowledge of the number of targets (model order). The performance would drop significantly by incorrect estimation of model order. To avoid this limitation, an augmented Lagrangian method is introduced for the first time to address the localization problem, which is named extended C-SALSA. This method casts target localization problem as a sparse representation problem, and then the problem is transferred from estimating targets' locations to the problem of sparse spectrum estimation. It utilizes variable splitting and augmented Lagrangian to handle objective functions. For both algorithms, with the accurate positions of sensors in the system, geometrical constraints of the system can be maintained by applying the same search grid to all virtual arrays, consequently, data association is avoided. <br/><br/>The feasibility of both proposed methods are analyzed with numerical simulations of point targets and electromagnetic simulations of an extended target. MATLAB simulation results demonstrate that the azimuth resolution is increased using multiple MIMOs with both proposed algorithms. Besides the resolution, the accuracy of the generalized 2D-MUSIC is also compared with the derived CRLB. Moreover, CRLB is used to analyze the potential accuracy for the estimation results of the mono-static configuration. In spite of the requirement of model order, the generalized 2D-MUSIC outperforms the extended C-SALCA for extended targets and is more robust for off-grid targets.","Target localization; MIMO radar; 2D-MUSIC; ADMM","en","master thesis","","","","","","","","","","","","","",""
"uuid:f5588df3-626d-42cc-8059-32e5bb16d852","http://resolver.tudelft.nl/uuid:f5588df3-626d-42cc-8059-32e5bb16d852","Exploring normalizing flow for anomaly detection","Pathak, Chinmay (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Gemert, Jan (mentor); Reinders, Marcel (graduation committee); van Genderen, Arjan (graduation committee); Delft University of Technology (degree granting institution)","2019","Anomaly detection is a task of interest in many domains. Typical way of tackling this problem is using an unsupervised way. Recently, deep neural network based density estimators such as Normalizing flows have seen a huge interest. The ability of these models to do the exact latent-variable inference and exact log-likelihood calculation with invertible architecture makes them interesting for the task of anomaly detection. In this work we explore the such normalizing flow-based model approach for anomaly detection in the novel BoroscopeV1 dataset which contains videos of the actual industry boroscope video material and has large noise. We verify the correctness of the models on a toy dataset. We found that the black pixels and high frequency in the image affect the model likelihood adversely. The experimental evidence shows that the normalizing flow-based approach can be used for the task of anomaly detection","Anomaly Detection; Outlier detection; Autoencoder; Generative Algorithms; unsupervised learning; one-class classification; GLOW; Normalizing flows","en","master thesis","","","","","","","","","","","","Electrical Engineering","",""
"uuid:8cad6b3f-15c6-4f4a-84a7-8adea0a3e5a2","http://resolver.tudelft.nl/uuid:8cad6b3f-15c6-4f4a-84a7-8adea0a3e5a2","Verbeterde beeldreconstructie bij CT-scanners","Waling, Manon (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Numerical Analysis)","van Gijzen, Martin (mentor); Keijzer, Marleen (graduation committee); Dubbeldam, Johan (graduation committee); Delft University of Technology (degree granting institution)","2019","De CT-scanner heeft een belangrijke rol in de medische wereld. Helaas gebruikt de CT-scanner voor het opstellen van een scan schadelijke straling. In dit onderzoek is nagegaan of er een betere beeldreconstructietechniek te vinden is voor het opstellen van een CT-afbeelding met gebruik van minder straling.<br/>De standaard voor het opstellen van een CT-afbeelding is het gebruik van de 2-norm. Vergelijken we de CT-afbeeldingen geconstrueerd met de 2-norm met CT-afbeeldingen geconstrueerd met de 1-norm en 0.5-norm dan zien we dat de 1-norm visueel het beste resultaat oplevert.<br/>Naast het vergelijken van de verschillende normen hebben we ook verschillende epsilon-regularisatiemethodes bekeken. De numerieke experimenten met de verschillende epsilon-regularisatiemethodes hebben we uitgevoerd op een systeem met 0%, 3% en 10% ruis, om te onderzoeken welke methode het beste toepasbaar is in de praktijk. Van de door ons geteste epsilon-regularisatiemethodes bleek de epsilon-regularisatie met epsilon := epsilon/2 met startwaarde epsilon = 10^(-8) en gebruik van de 1-norm de meest geschikte methode om een onderbepaald CT-probleem op te lossen.","CT; Image Reconstruction; Norms","nl","bachelor thesis","","","","","","","","","","","","","",""
"uuid:031c1820-a249-45ce-a691-44d7aa7f75aa","http://resolver.tudelft.nl/uuid:031c1820-a249-45ce-a691-44d7aa7f75aa","Food Waste through the Food-Water-Energy Nexus Lenses: A Case Study of Amsterdam","Coudard, Antoine (TU Delft Technology, Policy and Management)","de Koning, Jotte (mentor); Delft University of Technology (degree granting institution)","2019","Food waste is a global issue that causes various but significant global impacts, wasting millions of hectares of arable land, 0.75 to 1.25 trillion of cubic meter of water per year, and about 1.5% of the global energy production. In developed nations, food waste occurs mainly at the retail and consumer stage. By 2050, 80% of the global food consumption will take place within cities. Cities are also a key nexus of energy, water, and food flows. Amsterdam offers an interesting case study as the city does not have any comprehensive strategy to tackle the food waste produced within its boundaries. Yet, the city has shown ambitions in transforming itself into a sustainable metropolis with strong renewable energy and circular strategies. This study uses the Food-Energy-Water (FEW) Nexus approach, particularly suited to understand the interactions and interconnections between Amsterdam’s food flows and the energy and water systems. This study performs a Material Flow Analysis to quantify the different food waste (FW) flows and their origins. It finds that households are the main producers of food waste compared to FW-producing businesses in Amsterdam. Bread, dairy, vegetables, and fruits are the largest avoidable FW, while vegetable peels, fruits peels, coffee grounds, and potatoes peels constitute the bulk of unavoidable food waste. It then quantifies the embedded energy and water present within these food flows. Using the latest developments in the field of bio-based economy regarding food waste valorization, it provides an inventory of the potential technologies available to valorize Amsterdam’s FW. The study then quantifies the energy and water inputs of 12 of these food waste-valorizing technologies. This step confirms the large knowledge gap regarding the water and energy intensities of the latest bio-based technologies. The type and amount of recovered resources through these technologies are also quantified. In addition, this study provides a review of the current social and commercial initiatives based in Amsterdam tackling this issue of food waste. It offers a six-category qualitative framework to assess their food waste rescue potential. Then, a new food waste management and valorization framework is proposed, based on the Value Pyramid model from the bio-based economy, the Food Waste Management Hierarchy framework, and the FEW nexus insights developed in this study. This new framework enables to outline strategies for both Amsterdam’s avoidable and unavoidable food waste flows. It suggests anaerobic digestion, Black Soldier Fly bioconversion, and composting as potential FEW-efficient solutions for Amsterdam’s unavoidable FW. Last, Amsterdam’s FW stakeholders are analyzed through their importance, interests, and potential roles in a future FW scheme. It suggests that the municipality and AEB, Amsterdam’s Waste-to-Energy plant should be at the center of a future FW valorization scheme. Overall, this study combines the FEW nexus perspective and the bio-based economy approach to identify the best options to manage and valorize Amsterdam’s food waste.","Food Waste; Amsterdam; Urban Metabolism; Industrial Ecology; Food-Energy-Water Nexus; bio-based economy","en","master thesis","","","","","","","","","","","","Industrial Ecology","",""
"uuid:62d37d3c-040a-4ea3-ba9d-91fa8a2f1144","http://resolver.tudelft.nl/uuid:62d37d3c-040a-4ea3-ba9d-91fa8a2f1144","Digitalization of Retailing with Machine Learning: A Service-Product Design for Digital Merchandisers to Implement Machine Learning","Gu, Nien-Hua (TU Delft Industrial Design Engineering)","Kortuem, Gerd (mentor); Stoimenova, Niya (graduation committee); Wang, Albert (graduation committee); Delft University of Technology (degree granting institution)","2019","The thesis addresses the implementation challenges of Machine Learning (ML) for merchandisers in the scenario of digitalization of retailing, and proposes a product-service design as the solution. The digitalization of retailing is defined as an on-going process to integrate Internet-connected digital technologies into interfaces between retailers and consumers. The researcher collaborates with Bloomreach, who provides an ML-powered merchandising tool called Bloomreach Search &amp; Merchandising (brSM), and uses the context as an example of digitalization of retailing with ML. brSM helps merchandisers to improve the search and category experiences by optimizing the ranking of products, improving search results and curating recommendations on e-commerce platforms. The project presents a comprehensive analysis of the product, service, and merchandiser. In the product analysis, it is suggested that brSM doesn’t facilitate the interaction between the merchandisers and algorithms. Due to the knowledge gap, merchandisers have difficulties to align the expectation of the product at the beginning. Furthermore, the product doesn’t provide proactive feedback that improves the supervision of the user. In the service analysis, the misalignment of the internal feature communication leads to the confusing implementation service for the merchandisers. Specifically, the internal workflow and communication during the new feature introduction are confusing internally and externally. In the merchandiser analysis, it identifies two personas of merchandisers during the implementation of ML due to different business contexts and product characteristics. It thus is suggested to provide customized implementation supports according to their different needs.To address these challenges, the design solution aims to improve the (new) feature communication by adopting a use-case oriented approach for merchandisers and internal stakeholders with supportive tools. Based on the implementation framework of service design, the solution will be addressed on three levels, experience, service and strategy. At the experience level, brXtrategy family, supportive tools that provide merchandising inspirations, is introduced. It provides customized implementation information according to merchandisers’ business context. Also, it simplifies the product information by the adopting use-case oriented approach, which provides example-based explanations. Moreover, it improves the interaction between the merchandisers and algorithms by an interactive education tool and proactive notification of algorithmic performance. The front-stage and back-stage services are illustrated by the user journey map and service blueprint, which specify methods to improve the intra-company collaboration and the customer services in the critical moments like new feature introduction, onboard, and re-training. On the strategy front, a roadmap and a transitional workflow are introduced to facilitate the product strategy and the solution implementation. The workflow, called Use-case oriented development workflow, bridges the gaps of product/merchandiser understandings between the field teams and the R&amp;D teams during feature developments. With comprehensive research and three aspects of the design solution, the thesis contributes to the company and academic domain. It contributes to a better understanding of merchandisers in the process of digitalization of retailing. Also, the solution improves brSM’s services and facilitates the implementation of ML. Last but not least, it demonstrates a design approach that designers can perform that improves ML-powered products.","Machine Learning; retail; merchandiser; service-product design; ecommerce; interactive machine learning; Digitalization of Retailing","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:bddf7f3d-6d97-4ea9-b69e-c5b7cc693e51","http://resolver.tudelft.nl/uuid:bddf7f3d-6d97-4ea9-b69e-c5b7cc693e51","Dynamic Urban Land Use: An explorative study on the implications for transport and spatial planning","Carreiro Matias, Marcelo (TU Delft Civil Engineering and Geosciences; TU Delft Transport and Planning)","van Nes, Rob (mentor); Harteveld, Maurice (graduation committee); van Wee, Bert (graduation committee); Delft University of Technology (degree granting institution)","2019","The urban agenda is demanding new approaches for urban development. Urban flexibility has been recognized as crucial for coping with uncertainty and smart growth has been advocated as a sustainable urban practice. Urban flexibility and smart growth combined lead to a more dynamic land use, in which building adaptation leads to intensification of existing built areas. However, the impacts of such large-scale and faster intensification on transport and accessibility remain unknown, as well as the required policies to respond to those impacts. This study applies scenario planning and transport modelling to explore the implications of dynamic land use for transport and spatial planning, using the city of Eindhoven as case study. Results show that central areas are suitable for dynamic land use, where intensification does not demand any road infrastructure upgrade. Directed development to central areas can increase bike share, but no form of dynamic land use leads to higher shares of public transport. Finally, spatial randomness is the dominant variable on transport and accessibility performance. Further research should look at the interaction between dynamic land use and transport over time and the design of adaptive transport policies in a dynamic land use context.","Dynamic land use; Urban flexibility; Urban intensification; Transport planning; Spatial planning","en","master thesis","","","","","","","","","","","","Transport, Infrastructure and Logistics","City of the Future",""
"uuid:c5b222e7-fb93-4c63-9796-251e56ef8ca0","http://resolver.tudelft.nl/uuid:c5b222e7-fb93-4c63-9796-251e56ef8ca0","Model Uncertainty of Non-Linear Finite Element Analysis of Reinforced Concrete Beams without Shear Reinforcement: Examining the Effect of Modelling Strategies and Modes of Failure","Teshome, Tihitina Tilahun (TU Delft Civil Engineering and Geosciences)","Hendriks, Max (graduation committee); Rots, Jan (mentor); Yang, Yuguang (graduation committee); Engen, Morten (graduation committee); Delft University of Technology (degree granting institution)","2019","The aim of this thesis project is to investigate the model uncertainty of non-linear finite element analysis of reinforced concrete structures at ultimate limit state by focusing on concrete cracking model, concrete-reinforcement interaction model and mesh size. Following this, eight finite element modelling strategies are developed and 67 benchmark experiments on reinforced concrete beams without shear reinforcement are analysed.The measure of model uncertainty is using the ratio of experimental to numerical failure load and comparing predicted and experimental failure behaviour. A ratio that deviates form 1 indicates high model uncertainty with values &lt;1 representing non-conservative predictions and values &gt;1 representing conservative predictions.The eight modelling strategies are categorized into three groups. The first group is used to select shear retention model for the fixed crack concept and to study the behaviour of fixed and rotating crack concepts in combination with embedded reinforcement. The damage based and aggregate-size based shear retention models are investigated resulting in a mean model uncertainty ratio of 0.86 and 0.82 respectively. This indicates that on average both predict higher ultimate capacity when compared to experimental results with the aggregate size based shear retention model exhibiting higher model uncertainty. The aggregate size based model is not capable of predicting shear and mixed failure types while the damage based predicted accurate failure modes. On the other hand, the rotating crack model with embedded reinforcement shows failure due to delamination of the concrete cover. Replacement of the perfectly bonded embedded reinforcement by reinforcement with bond-slip demonstrated to predict accurate failure modes.The second group has the fixed crack model with damage based shear retention model and embedded reinforcement, which is referred to as F-EB-2-D and rotating crack model with bond-slip reinforcement named R-BS-2. Both modelling strategies have 50mm mesh size and result in mean model uncertainty ratio of 1.11 and 1.06 respectively which implies that on average both give conservative predictions of the ultimate capacity with R-BS-2 showing a better prediction. Both modelling strategies give higher model uncertainty for experiments with shear failure with F-EB-2-D and R-BS-2 predicting accurate failure modes for 48% and 51% of the experiments respectively. The beams with reinforcement ratio of ≤ 0.6% showed on average less model uncertainty in F-EB-2-D and R-BS-2. The third group is made by refining the mesh size of F-EB-2-D and R-BS-2 from 50mm to 25mm in critical section of the beams to formulate the modelling strategies F-EB-3-D and R-BS-3 . 16 experiments are re-analysed using this group and a lowered mean model uncertainty ratio of 0.93 and 0.95 is obtained for F-EB-3-D and R-BS-3 respectively although this is slightly non-conservative with accurate predictions for 81% of the 16 experiments. The correlation between model uncertainty and numerical failure mechanism is made using a ductility index which is defined as the ratio of the plastic dissipated energy in the reinforcement and the system. However the ductility index should be used together with model uncertainty if it is verified that the correct equations are solved accurately in the finite element analysis.","Non-Linear Finite Element Analysis; model uncertainty; Reinforced Concrete structures","en","master thesis","","","","","","","","","","","","Civil Engineering","",""
"uuid:d6d23c26-9ce6-487e-9a9b-d2aa809d3ba1","http://resolver.tudelft.nl/uuid:d6d23c26-9ce6-487e-9a9b-d2aa809d3ba1","Analysis of a streaming video feed of a pulverized coal injection system","Smilde, Elsemiek (TU Delft Electrical Engineering, Mathematics and Computer Science)","Budko, Neil (mentor); Lahaye, Domenico (graduation committee); van Elderen, Emiel (graduation committee); Delft University of Technology (degree granting institution)","2019","Danieli Corus supplies tailor-made solutions for the global steel industry. Cameras are used in tuyeres of blast furnaces to detect physical aspects and irregularities. No operator could monitor those videos all day, which is why video analyses are needed. A program is written to analyse a test video and give information about the temperature, the injection of pulverized coal and the movement of rocks. The mathematical background of these calculations is presented, which depend on the transport of light from the blast furnace to the camera through the tuyere. Also the implementation of the calculations can be found. The results are interpreted and discussed and further improvements are suggested.","Video streaming; Image analysis; Blast furnace; Pulverized coal injection system","en","bachelor thesis","","","","","","","","","","","","","",""
"uuid:fdf985c6-88bd-4fa7-bf18-84a617c7b9a3","http://resolver.tudelft.nl/uuid:fdf985c6-88bd-4fa7-bf18-84a617c7b9a3","Design and Validation of a Collimator Alignment Assembly for a High-Power Bulk Multiplexer used in Ground-to-GEO Laser Communication","Lutgerink, Jochem (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Precision and Microsystems Engineering)","Cacace, Lennino (mentor); de Vreugd, Jan (mentor); Pettazzi, Federico (mentor); Spronck, Jo (graduation committee); Vdovine, Gleb (graduation committee); Rommers, Jelle (graduation committee); Delft University of Technology (degree granting institution)","2019","The average worldwide internet traffic demand in 2022 is projected to be over 1200 Terabits per second. A fifth of this data would be transmitted using mobile networks. One of the technologies used for this is radio frequency (RF) telecommunication, but this technology is reaching its limits. Despite ongoing development, typical data rates are still in the order of Gigabits per second per link.<br/><br/>TNO is working on a telecommunication link (called TOmCAT) that can reach data transfer rates of a Terabit per second. The high data rate is achieved using a very promising alternative to RF telecommunication: optical telecommunication, which is also known as laser communication.<br/><br/>In order to reach the intended data rates, the data needs to be spread over multiple optical frequencies. These signals need to be combined into one transmitted beam using a free-space optical bulk multiplexer. <br/><br/>The laser beams that are transmitted by their collimators need to be aligned with respect to each other in order to reach the satellite as one beam. The footprint available for the required alignment mechanisms is very limited. Furthermore, the system needs to achieve a good thermal and mechanical stability in order to meet the strict specifications.<br/><br/>The aim of this thesis is two-fold: to show the need for achieving state-of-the-art alignment specifications with strict footprint constraints, and to defend the steps taken to achieve these requirements. The research spans the entire design process of the alignment assembly: from higher/system level trade-offs and calculations, to the derivation of the design specifications, to the conceptual and detailed design, and concluding with the manufacturing and testing of the first prototype. <br","TNO; Laser Communication; Optical bulk multiplexer; High-power collimator; Alignment mechanism; Rapid prototyping; Thermal stability","en","master thesis","","","","","","","","2024-08-31","","","","","",""
"uuid:1347feeb-dce7-44c7-b8b7-3f58f2dd254b","http://resolver.tudelft.nl/uuid:1347feeb-dce7-44c7-b8b7-3f58f2dd254b","Value Drivers and Inhibitors in Municipal Open Government Data Ecosystems: An in-depth analysis of stakeholder perceptions on values, barriers and success factors in open government data initiatives in Dutch municipalities","Hablé, Jesse (TU Delft Technology, Policy and Management)","Janssen, Marijn (mentor); Zuiderwijk-van Eijk, Anneke (mentor); Hermans, Leon (mentor); Kunzler, T. (mentor); Delft University of Technology (degree granting institution)","2019","Research context<br/><br/>Open government data (OGD) publication and use is an important feature of an open government. However, In Dutch municipalities, the presumed created value from municipal OGD fails to live up to its potential, despite various OGD initiatives. Furthermore, there is a lack of knowledge about how value creating mechanisms work and how they can be stimulated in municipal contexts.<br/>The objective of this study is therefore to identify value drivers and inhibitors in municipal open government data ecosystems. In order to do so, an in-depth analysis is conducted into the stakeholder perceptions regarding values, barriers and success factors related to these systems.<br/><br/>Research approach<br/><br/>In order to find an answer to the central research question how can the creation of value in municipal open government data ecosystems be facilitated? the ecosystem is approached using actor and strategy models (ASM). This methodology allows in-depth analyses of the stakeholder perceptions throughout the entire ecosystem, and in doing so opens up what is known in ASM as ”the actor dimension” in policy making. By applying the ASM method to open government data ecosystems, this thesis argues for a re-evaluation of the actor dimension in policy making decisions. Furthermore, this thesis seeks to contribute to current OGD theorizations by showing how an in-depth analysis of stakeholder perceptions throughout open data ecosystems not only strengthens policy making decisions down the line, but also expands various forms of value creation through OGD publication and usage.<br/><br/>Findings<br/><br/>The research question is divided into four sub-questions. The first question is: what does the municipal OGD ecosystem look like? Using a systematic literature review a conceptual model is developed of a municipal open government data ecosystem, portrayed as an actor arena, which is central in an ASM-approach. The ASM- approach allows an assessment of social/political, operational/tactical, and economic value creation. The actors in this model are municipalities, infomediaries, and citizens, who interact by performing tasks, which leads to value creation. Value creation is thus not inherent in specific groups of actors, but created in interactions and dispersed outside the OGD ecosystem itself throughout society. Furthermore, a distinction is made between active and passive interaction executed by citizens. This allows identification of four ecosystem categories: in the administrative domain (1) citizen informing and (2) citizen sourcing; and in the political domain (3) transparency/accountability and (4) collaborative democracy. Lastly, an overview of seven categories of barriers and success factors is presented.<br/>This conceptual model was evaluated in an expert review, which led to the second sub-question: to what extent is the conceptual model of the municipal OGD ecosystem accurate, insightful and useful?. The conceptual model was perceived as too data-central, which led to the addition of a societal incentive in the ecosystem as a starting point. Secondly, the distinction between active and passive citizens tasks was perceived as novel insight, which underscored the importance of this viewpoint. Thirdly, the policy context was lacking in the experts’ view, hence it was taken into account by the identified success factors, which included policies.<br/>Subsequently, the conceptual model was examined empirically in two case studies concerning a citizen inform- ing OGD initiative and a citizen sourcing OGD initiative. Stakeholder perceptions of infomediaries, municipalities and citizens were measured in order to answer the third sub-question: what are stakeholder perceptions on values, barriers and success factors of data initiatives in municipal OGD ecosystems? This led to several insights.<br/>1.Stakeholders tend to perceive social/political and operational/tactical value of municipalities partaking in OGD initiatives more than economic value. In open government data initiatives for administrative purposes that consist of active citizen interaction mechanisms, additional value is created. This is the case because this research has shown that in such initiatives citizen sourcing benefits account for additional operational/tactical value and responsive governance benefits account for additional social/political value.<br/>2. Infomediaries that were categorized as typical technical initiators of OGD initiatives tend to seek institu- tional support from municipalities or supra-municipal governmental organizations to implement OGD initiatives. Infomediary initiation is effective to ensure a societal incentive for these initiatives.<br/>3. Municipal motives for participating in initiatives were assessed. Whereas some municipalities enthusias- tically participate, others are less willing to do so when OGD initiatives do not fit their perceived institutional contexts. This is especially the case if cross-municipal data-standards are embedded in municipal procedures that do not add value for that municipality. Sometimes municipalities expect infomediaries to generate data technically and are therefore, sometimes municipalities are less dedicated to perform their ecosystem tasks.<br/>4. This research has shown that citizens need to be made aware of their interests in open government data initiatives, and actively encouraged in order for value to be created.<br/>The results of the three analyses (literature, expert review, and case studies) insist on a revision of the conceptual model of the municipal ecosystem and generate answers to a fourth sub-question: what factors need to be incorporated in the model in order to increase the creation of value? Four value drivers have therefore been added: (1) institutional support for infomediary initiation, (2) technical support for implementation, (3) reaching out to citizens by engaging re-use platforms, and (4) mobilization of citizens by user-friendliness in OGD applications. Policy recommendations have been formulated to infomediaries, municipalities, and supra-municipal governmental organizations related to coordination and encouragement of value creation in OGD initiatives.<br/><br/>Scientific contributions<br/><br/>This study contributes to the open government data literature by identifying factors that stimulate value creation in the municipal OGD ecosystem (value drivers) and factors that reduce value generation in this ecosystem (value inhibitors). In contrast to many studies throughout open data literature, this study obtained in-depth insight into the actor dimension underlying municipal OGD ecosystem interactions and revealed some of the structuring mechanisms that influence OGD value creation. Moreover, tasks related to value creation in citizen centered open government data initiatives have not only been made explicit but are specifically attributed to various stakeholders. This study is among the first to apply an ASM approach to open data research, and its findings suggest ASM can be a fruitful method for analyzing open data ecosystems.<br/><br/>Societal contributions<br/><br/>Value creation in municipal OGD ecosystems should be encouraged by considering the suggested policy recom- mendations for infomediaries, municipalities and supra-municipal governmental organizations. Additionally, the conceptual model of municipal OGD ecosystems developed in this thesis can potentially be used in order to design more valuable OGD initiatives.<br/><br/>Future research<br/><br/>In future research, additional case studies of OGD initiatives are advised to use an ASM-approach in order to better take stakeholder perceptions into account. Future research should also consider examining OGD initiatives with a more economic focus, as well as those initiated by other categories of infomediaries such as media organizations or academic institutions. Lastly, citizen perspectives could be further evaluated using surveys and this aggregated citizen perspective could then be integrated into the ASM-model.","open government data; data ecosystem","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:b9e0db37-97a1-4c7a-aa9f-09514ca49438","http://resolver.tudelft.nl/uuid:b9e0db37-97a1-4c7a-aa9f-09514ca49438","Using Electric Vehicles to Store Solar Energy: The Spatial Distribution Problem: A quantitative analysis on the effects of the spatial distribution of solar panels and electric vehicles on the cost-effectiveness of the Vehicle-2-Home concept.","Sturmans, Simon (TU Delft Technology, Policy and Management)","Annema, Jan Anne (mentor); Lukszo, Zofia (graduation committee); Farahani, Samira S. (graduation committee); Delft University of Technology (degree granting institution)","2019","Vehicle-2-Home (V2H) is a concept in which an electric vehicle (EV) is able to charge and discharge its battery pack to the building it is connected to. This concept enables EVs to store surplus solar energy, which is produced during the daytime and return in to buildings during the night time. For this system to work (cost) efficiently, the EVs location during the day must match the location of surplus solar energy. Also, at night, the EVs must discharge this electricity evenly over an area to reduce the strain on the electricity distribution grid. This thesis has analysed whether there exists a match between the spatial distribution of solar panels and EVs in the Amsterdam region under growth scenarios until 2040.","V2H; Spatial distribution; Solar energy; Electric vehicles; Case study; Cost analysis","en","master thesis","","","","","","","","","","","","","",""
"uuid:8f4460c2-dd09-4b54-9a06-9cd6327cc69b","http://resolver.tudelft.nl/uuid:8f4460c2-dd09-4b54-9a06-9cd6327cc69b","Quasi-1D Modelling of Particle-Laden Internal Turbulent Flows with Nucleation, Agglomeration and Breakup: Application to Asphaltenes Deposition in Oil Wells","Moghadasi Barazandeh, Mohsen (TU Delft Civil Engineering and Geosciences)","Portela, Luis (mentor); Delft University of Technology (degree granting institution)","2019","Particle-laden internal turbulent flows are very commonplace, for example, in petrochemical flow lines, oil wells and so on. From an engineering view point, modelling such flows in a 3D or even 2D fashion may not be reasonable in terms of computational cost, especially when the flow domain is sufficiently long, and a large number of grid cells are needed to resolve the flow field. On the other hand, ID models are quite fast but only take into account the stream-wise variations of the flow characteristics, without providing any information on their cross-sectional distribution. In this work, a novel quasi-ID modelling framework was introduced, which is able to capture the flow field in both stream-wise and cross-stream directions and yet stay computationally more efficient than the 3D or 2D models. The quasi-ID modelling framework was developed based on the one-way coupling of a RANS model for the single-phase turbulent flow with an Eulerian model for the transport of the dispersed particle phase. The nucleation, agglomeration and breakup events were also taken into considera¬tion through the generic population balance equation, the solution of which was provided using the direct quadrature method of moments. The results of the quasi-ID single-phase flow model were verified and shown to be in accordance with those of the AN SYS Fluent 2D model for different test cases. The computational cost analysis revealed that the simulation CPU time of the quasi-ID model increases linearly with the number of streamwise grid cells (Nx), whereas that of the 2D model scales with Nx1.6, implying that the quasi-ID model will perform faster than the 2D model from a certain number of grid cells on. The quasi-ID multi-phase-flow tool was then used to address the transport and deposition of asphaltenes in oil wells, as an example of particle-laden internal turbulent flows. To this end, a simulation test case was set up with several simplifications, and the results were compared with those of a simpler ID model in the literature, as the benchmark. Due to the lack of an appropriate model for the collision efficiency of asphaltene particles, a model associated with liquid droplets was adopted and tuned to obtain a match between the results of this study and the benchmark. The outcome of the sensitivity analysis demonstrated that the collision efficiency plays an important role in determining the asphaltenes deposition profile along the well bore and needs to be modeled accurately.","Quasi-one-dimensional; Particle-laden flow; Asphaltenes; Population Balance; quadrature method of moments","en","master thesis","","","","","","","","","","","","","",""
"uuid:b6e2483a-ba08-4969-ac20-4692d24dc3ab","http://resolver.tudelft.nl/uuid:b6e2483a-ba08-4969-ac20-4692d24dc3ab","SCL-T: Template programming for Siemens SCL","Goderie, Jeffrey (TU Delft Electrical Engineering, Mathematics and Computer Science)","Visser, Eelco (mentor); Poulsen, Casper (graduation committee); Lofi, Christoph (graduation committee); Delft University of Technology (degree granting institution)","2019","Programmable Logic Controllers (PLCs) are used to control large scale systems with thousands of I/O devices. Writing and maintaining the logic for each of these is a cumbersome task, which is well suited to be abstracted through templating. For this purpose, CERN developed the Unicos Application Builder (UAB). While UAB is successful at templating, it provides no guarantees over the validity of the outcome, leading to erroneous generated code. This is where SCL-T comes in. It builds on the foundation of UAB to facilitate meta-programming for Siemens’ SCL. Unlike its predecessor, it guarantees syntactic correctness and also draw conclusions regarding the semantic validity of the generated code. Its architecture has been designed in such a way that support for other PLC languages can be added using the same meta-language, reducing the cost of a having a meta-programming language tailored for a specific PLC language.","programming language; meta-programming; type checking; Spoofax; PLC programming","en","master thesis","","","","","","","","","","","","","",""
"uuid:a4499828-f32f-4408-a131-990405d53d48","http://resolver.tudelft.nl/uuid:a4499828-f32f-4408-a131-990405d53d48","Noise reduction in MRI images using partial differential equations","de Haas, Lyanne (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Gijzen, Martin (mentor); Delft University of Technology (degree granting institution)","2019","MRI machines use superconducting magnets to create an image. However, these magnets are very expensive. It is possible to use weaker magnets in a low-eld MRI, but those will result in a lower signal-to-noise ratio, meaning the images will be polluted. An image can be smoothed by viewing it as the initial condition of a partial dierential equation (PDE) and changing it through time integration. The choice for the PDE determines the way the image changes. This paper compares four PDE's: a second-order equation originally proposed by Perona &amp; Malik, a fourth-order equation as proposed by You &amp; Kaveh, and both aforementioned equations with a delity term added to them. Said delity term ensures the result does not deviate too far from the original image. All methods use a diusion coecient specially desiged to preserve edges. These methods are tested on two versions of the Shepp-Logan phantom, one having been corrupted with 'salt-and-pepper' noise, and the other one having been treated with a Gaussian lter, blurring the image. The salt-and-pepper phantom is improved most by applying the Perona- Malik method with a delity term. This method gives a good balance between removing noise and preserving edges and details within the image. For the blurry phantom the best result is seen using Perona-Malik, where some of the edges become more dened. However, a delicate balance has to be kept between rening the edges and blurring out any lower-contrast detail, and the total eect is limited. The methods are also tested on images that were created using a prototype of a low-eld MRI machine. The noise in these images is mostly the 'saltand- pepper' type. Though the preferred result is somewhat subjective, the Perona-Malik method with delity once again gives the clearest image here.","","en","bachelor thesis","","","","","","","","","","","","","",""
"uuid:3540bdf3-8fa0-4fee-9d93-0666871e9ecd","http://resolver.tudelft.nl/uuid:3540bdf3-8fa0-4fee-9d93-0666871e9ecd","Decline of private investments in the Greek economy and the way forward","Karampekios, Antonios (TU Delft Technology, Policy and Management)","van Beers, Cees (graduation committee); Storm, Servaas (mentor); van Daalen, Els (graduation committee); Auping, Willem (graduation committee); Delft University of Technology (degree granting institution)","2019","Greece was amongst the first countries to be hit after the outburst of the European financial crisis in 2008. The crisis revealed the underlying intra-Eurozone macroeconomic imbalances and turned the attention of the global community and investors towards the very high level of Greek public debt. Private investments in the Greek economy also suffered a heavy downfall since the beginning of the crisis. The level of private gross capital formation kept decreasing since 2008 and forecasts estimate an almost null growth for 2020. This research tries to answer the question of what the main factors behind the decline of private investments are and which policies can re-activate them. To investigate further and answer the question about the link of public and private investments a System Dynamics model of the Greek economy is built based on a traditional macroeconomic approach. With the use of the System Dynamics model for the Greek economy. Next, the Exploratory Modelling &amp; Analysis (EMA) Workbench tool is used to perform the analysis. Two different policies are introduced. The first one concerns a mix of lower taxes and lower government investments and the second one is based on a policy of higher taxes and higher government investment. Sensitivity analysis with the use of SOBOL technique and scenario discovery analysis with the use of PRIM are used to explore the most sensitive factors with regard to private investment.","Exploratory Modelling and Analysis; Sensitivity Analysis; Scenario discovery; Macroeconomic Model","en","master thesis","","","","","","","","","","","","","",""
"uuid:6e5b4ef7-6db9-4161-b810-f01ae0fa00c1","http://resolver.tudelft.nl/uuid:6e5b4ef7-6db9-4161-b810-f01ae0fa00c1","Establishing citizen participation in real estate domain: A case study of Campus &amp; Real Estate division of Delft University of Technology","Kaikittipoom, Parastha (TU Delft Industrial Design Engineering)","van Heur, Ruud (mentor); Calderon Gonzalez, Alicia (graduation committee); de Wit, Rob (graduation committee); Delft University of Technology (degree granting institution)","2019","Universities in the Netherlands are challenged by the changing campus development landscape, as the number of students is outpacing the public funding and the role of universities is shifting towards a city. Universities could function as a city, or even become the city (Heijer and Magdaniel, 2012). The changing role of campuses challenges Delft University of Technology(TUD) to function as a city, governing and addressing its citizens in the same way as the city does. The recent trend in public development is citizen participation. The central government of the Netherlands promotes a collaborative way of working between citizens and local authorities. Several participation related projects have been presented, such as Omegevingswet, Delfts Doen!. Corresponding to the need for a collaborative process in public development, TUD has to ensure to involve its citizens, students, and employees in the campus development. However, to involve citizens in the campus development process is not straightforward. This study aims to design a comprehensive implementation plan for the Campus &amp; Real Estate (CRE) division of Delft University of Technology (TUD) to promote citizen participation in campus development. The initial research question was formulated: ‘How to involve the citizens of TUD in the campus development process?’. In this context, citizens mean people who work, study, and live on campus. The main methodologies applied are literature review, interview, and research through design. The research result shows that participatory design (PD) is relatively new to real estate domain. Several challenges of implementing PD were discovered. The TUD campus development process has limited citizen involvement, as it uses a conventional real estate management approach. The prominent challenge is the misconception about the concept of users, as well as the difficulty envisioning the value that PD can bring.Therefore, the demonstration of participatory design conducted aims to deliver two values; to get CRE closer to citizens and foresee the value of PD through experimental cases with CRE. The experiment cases brought CRE closer to users and showed how citizen participation could help CRE create a a program of requirements in a relatively short time. The functional program that meets the needs and concerns of citizens can eliminate the chance to invest in the irreverent, undesirable spatial solution. The comprehensive participation plan was developed to foster the implementation of citizen participation in CRE over a long timeframe. The ultimate goal of the plan is to gradually establish citizen participation in CRE. The plan consists of an implementation plan, participation framework, and participation toolkits. They provide a practical suggestion and guidelines to systematically follow. On the basic level, it is recommended that CRE use the plan to start implementing citizen participation. Further research and experiments are needed to complete a detailed plan in of every steps. It is advisable for CRE to follow the implementation plan and execute a couple of cases to determine if the PD is a suitable approach for the organization, if the value is worth the investment, and if the organization should sustain the PD in the future.","participatory design; organizational change; framework; implementation plan; campus development; real estate development; participation framework","en","master thesis","","","","","","","","","","","","Strategic Product Design","Participatory city making lab",""
"uuid:f97204a0-037d-4f89-bd5a-f8b003f6944c","http://resolver.tudelft.nl/uuid:f97204a0-037d-4f89-bd5a-f8b003f6944c","Improving the Blade Root Laminate of a Wind Turbine","Chhabra, Arjun (TU Delft Aerospace Engineering)","Alderliesten, Rene (mentor); Delft University of Technology (degree granting institution)","2019","Suzlon's wind turbine blades are connected to the pitch bearing and hence the hub using a T-Bolt (Ikea) connection. The merits of this bolted connection and the experience in its usage has led to its continuous use in the wind industry. Engineers at Suzlon believe that this connection can be optimized by improving the net-tension strength and stiffness of the blade root laminate. <br/><br/>For that purpose, pin-loaded specimens that represent the blade root laminate were tested for different material configurations (different fiber-type, orientation). A novel finite element model of the pin-loaded specimens is developed as a tool to predict the ultimate strengths of the specimens. Material Property Degradation Method is used as the damage evolution method for this model. Keeping the matrix tensile and compressive degradation factors same for all the material configurations give a good correlation with the tested specimens. However, the fiber tensile degradation factor changes with the change in the orientation of the fibers in the laminate. The net-tension strengths are also found to be proportional to the theoretical material tensile strengths.<br","T-bolt; Material Property Degradation Method; Progressive Damage Analysis; Pin-loaded Joints","en","master thesis","","","","","","","","2024-12-31","","","","Aerospace Engineering","",""
"uuid:089cf9d4-0390-430c-8ce4-87415d55b75a","http://resolver.tudelft.nl/uuid:089cf9d4-0390-430c-8ce4-87415d55b75a","Synergies in Liner Shipping: Integrating Quantitative and Qualitative Analysis in the Partnership Decision","Janzen, Pieternel (TU Delft Mechanical, Maritime and Materials Engineering)","Frouws, Koos (mentor); van Hassel, Edwin (graduation committee); Akkerman, Ido (graduation committee); de Beyer, M. (graduation committee); Ens, L. (graduation committee); Delft University of Technology (degree granting institution)","2019","Liner shipping companies engage in strategic cooperation to deal with the market’s overcapacity, capital intensiveness and volatile freight rates. However, these partnerships do not reach their full potential and have lowered the level of service in the industry. To identify how carriers would be able to realise further synergies, this study has investigated the current performance of liner shipping companies and developed a model to identify and assess potential partnership opportunities. This model supports liner shipping companies in their decision of who to partner with and what kind of partnership to pursue. The study has been confined to a single transpacific route. On the basis is an overview of vessels that sail this route over a period of several years. This overview includes information on arrival dates, number of containers on board, capacity and operator for each vessel. This is used to examine local demand and deployed capacity, vessel utilisation and competition. The analysis confirms trends found in literature, such as the growing size of vessels that are enabled by strategic cooperation. Most importantly, it indicates flexibility on the side of vessel operators in their decision of which vessels they deploy per route during the year. A synergy model has been developed based on the findings in literature and the results of this analysis. This model uses the identified flexibility in vessel deployment and builds on the notion that liner shipping companies should pursue more integrated partnerships to realise further synergies. The model was also applied to the case of CMA CGM’s acquisition of APL in 2016. After calculating the costs for sailing each of the available vessels, potential partnerships were identified for the analysed route. This was done by optimising vessel deployment for the cargoes to be transported at minimum cost and with a limited number of partners. A strategic-level assessment was then performed to determine whether a partnership would be feasible among the identified companies and to what extent integration should take place. By including both the companies’ motivations (drivers) and factors that facilitate a positive environment (facilitators) for the partnership, this assessment brings multiple perspectives to the table. The conclusion is that carriers can adjust which vessels they deploy to match transport demand and that they can use this to realise further synergies. By using a model with both a quantitative and a qualitative component, it is possible to identify potential partnerships that result in cost reduction, maintain high vessel utilisation and allow for improvements in the level of service that companies offer to their customers. It is recommended to extend the coverage of the model to include more routes, ports and vessels for a more comprehensive analysis. Furthermore, using variable transit times in the model to determine when vessels are available would make the model more realistic and would also allow changes in vessel speed to be included in the analysis. It is also advised to explore opportunities for regulatory bodies to apply this model for monitoring and assessment of the effects partnerships have on competition per route.","","en","master thesis","","","","","","","","","","","","","",""
"uuid:2cf26a3e-15d1-485b-9d6b-e575ef72cd9a","http://resolver.tudelft.nl/uuid:2cf26a3e-15d1-485b-9d6b-e575ef72cd9a","A user centered, edge based interaction between humans and autonomous vehicles","Rakas, Nick (TU Delft Technology, Policy and Management)","Ding, Aaron (mentor); Warnier, Martijn (graduation committee); Janssen, Marijn (graduation committee); Delft University of Technology (degree granting institution)","2019","Autonomous vehicles have advanced rapidly in the last decades. The automotive industry is making valiant efforts to strengthen autonomous vehicle technologies and improve overall road safety. Besides actual safety, feeling safe is equally important. In other words, there is also a socio-technical perspective of self-driving vehicles that should not be ignored. Currently, when pedestrians wish to cross the road, they tend to rely on informal communication with drivers. However, this will not be the case with fully autonomous vehicles as the driver or passenger will most probably execute various tasks and will not pay attention to the road. Consequently, this master thesis investigates the loosely coupled relationship between pedestrians and fully autonomous vehicles in crosswalk use cases with no traffic lights. The main research question that is investigated is ""How should the interaction between humans and fully autonomous vehicles be established in order to influence road safety and road awareness?"". To address this research question, this master thesis espouses notions used in the scientific field of Interaction Design and applies the goal-directed design approach.","Autonomous Vehicles; Pedestrians; Human-Computer Interaction; Interaction Design; Goal-Directed design; V2X; Edge Computing; Smart-Crossing system","en","master thesis","","","","","","","","","","","","","",""
"uuid:709e05de-f6f3-4073-aea0-a9a5a4972fcb","http://resolver.tudelft.nl/uuid:709e05de-f6f3-4073-aea0-a9a5a4972fcb","Unobtrusive Monitoring of Fluid Accumulation in the Body Using Ballistocardiography: A Feasibility Study","Suriani, Irene (TU Delft Mechanical, Maritime and Materials Engineering)","French, Paddy (mentor); Serdijn, Wouter (graduation committee); Hunyadi, Bori (graduation committee); Janssen, Gerard (graduation committee); Dellimore, Kiran (graduation committee); Delft University of Technology (degree granting institution)","2019","Fluid accumulation in the human body is, in many cases, a symptom of some underlying pathological condition. Most common examples include edema, ascites, pleural effusion, and internal bleeding. Currently available non-invasive methods to assess fluid accumulation in the body are mainly imaging-based (i.e. ultrasound, computed tomography). This means that monitoring is limited to spot-checks and is only performed when the presence of a particular condition is already suspected from prior clinical evaluation of the patient. There is high clinical interest in the development of a system allowing such monitoring to be performed automatically, continuously over a prolonged period of time, and independently of prior clinical evaluation. For instance, in the case of internal bleeding, hemorrhage indicators such as variation in heart rate and blood pressure are only observable after significant blood loss (up to more than 1 liter) has already taken place, therefore an early warning system can save lives, decrease hospital stay length and significantly reduce complication-related costs. In this thesis, a pioneer solution is proposed for development of such a monitoring system. The hypothesized solution is based on the observation of specific energy-describing features of the Ballistocardiogram (BCG) signal, a measure of the periodic displacements generated on the body as a result of ballistic forces produced by the heart during each cardiac cycle. Because of additional damping generated by the presence of internally accumulated fluid, the energy of this signal is expected to decrease compared to its baseline value. The BCG can be recorded unobtrusively with different sensing modalities on the surface of the body. In order to validate the research hypothesis and assess the feasibility of this novel technique, a custom experimental set-up exploiting several different BCG sensing options has been used to carry out a study on 15 human volunteers. Localized fluid accumulation along the GI tract was induced in a controlled, safe and simple fashion, by means of water intake by the participants, and the BCG signal was recorded before and after intake. Signal feature exploration and performance analysis has been used to develop an optimized feature able to accurately capture the decrease in signal energy due to fluid accumulation, as well as to identify the most suitable sensor type and monitoring body location for the present application. The developed energy-describing feature shows a significant decrease in energy value from baseline to after-intake condition with a p-value&lt;0.001. Moreover, the selected feature was able to correctly identify presence of fluid accumulation with high sensitivity (90% in bed-based, and 100% in standing-position monitoring). Given the promising results of the present study, further research towards improvement and development of the proposed technique is highly encouraged.","ballistocardiography; unobtrusive monitoring; accelerometers; signal processing; feature design; intra-abdominal fluid accumulation","en","master thesis","","","","","","","","2024-08-29","","","","","",""
"uuid:e10c7a47-057f-4cb5-85b9-c63c17c12ea0","http://resolver.tudelft.nl/uuid:e10c7a47-057f-4cb5-85b9-c63c17c12ea0","From cooperation to collaboration: Enhancing team collaboration in partnerships for construction projects","Kotoudi, Anastasia (TU Delft Civil Engineering and Geosciences; TU Delft Geoscience and Engineering)","Bakker, Hans (mentor); Leijten, Martijn (graduation committee); Molaei, Maedeh (graduation committee); de Vos, Sjacco (graduation committee); Delft University of Technology (degree granting institution)","2019","Today’s project complexity is constantly increasing leading to multidisciplinary project teams. Building a truly integrated team in projects where a partnership is necessary in order to achieve the desired outcome isn’t a one-off process that can occur automatically. It’s a procedure that has to be built up over a certain period of time (mostly during the front-end development phase) under a collaboration that will utilize in the best way the benefits of this one-team approach. In international projects cultural differences between the different teams is an important aspect that adds an additional challenge in reaching a successful outcome. It is therefore the project manager’s responsibility to create a team of engaged and committed people that have an aligned project goal and act as a whole and not as a set of wholes. Getting from cooperation to collaboration requires the presence of both a strong project leader and a competent project team.","Collaboration; Partnering; Integration","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:d14b5f60-7000-439b-8785-62e513902bf8","http://resolver.tudelft.nl/uuid:d14b5f60-7000-439b-8785-62e513902bf8","Holistically improving screening decisions under uncertainty in aircraft conceptual design and technology assessment: Insights on bottom-up uncertainty quantification and propagation and integrated socio-technical group decision making","Peerlings, Bram (TU Delft Applied Sciences; TU Delft Aerospace Engineering)","Vos, Roelof (mentor); van der Sanden, Maarten (mentor); Roelofs, Martijn (graduation committee); Wehrmann, Caroline (graduation committee); Delft University of Technology (degree granting institution)","2019","In the highly uncertain environment of conceptual aircraft design and technology assessment and selection, making good decisions is of utmost importance. Aiming to contribute to improving decision quality, the problem was researched from both a technical as well as a socio-psychological perspective. In the technical perspective, the uncertainty associated to three two-dimensional aerodynamic solvers -- following from physical flow model assumptions or numerical solution method differences -- was quantified and propagated. It was found that the influence of flow model clearly outweighs the impact of solution method. Although the aircraft synthesis program used for uncertainty propagation showed very little sensitivity to the effects of the assumptions investigated, these results raise critical questions about the currently observed push for higher-fidelity analysis methods in aircraft conceptual design. In the socio-psychological perspective, document review, interviews and observations were used to define what socio-psychological factors negatively impact group decision making in an international public-private research consortium aiming to contribute to aircraft fuel burn reduction through R&amp;D concept development. Based on vigilant interaction theory and (the conceptual foundations of) effective intercultural workgroup communication theory, a theoretical framework was used to develop the TARE-model, which helps groups balance task (TA) and relationship (RE) outcomes in an uncertain environment. Using a thought experiment, the inherent integration and inseparability of the two perspectives was found. Uncertainty was put forward as the primary variable impacting the interwovenness of the two perspectives. Applying this conclusion to the results from the technical and socio-psychological domains, the question is raised whether increased computational power and additional models are the most effective way to substantially improve the quality of decisions in conceptual design and technology assessment and selection projects.","uncertainty quantification; uncertainty propagation; decision making; decision support; interdisciplinary; group decision; aerodynamics; XFOIL; VGK; MSES; AVL; Aircraft Design Initiator","en","master thesis","","","","","","","","","","","","","",""
"uuid:97c50f56-bdec-4da2-af17-27687666d1d8","http://resolver.tudelft.nl/uuid:97c50f56-bdec-4da2-af17-27687666d1d8","Data Informed Decision Making: Cardiovascular Disease Prevention","Mohammad Ammar Faiq, Ammar (TU Delft Technology, Policy and Management)","Cunningham, Scott (mentor); van der Voort, Haiko (mentor); Kist, Janet (graduation committee); Groenwold, Rolf (graduation committee); Delft University of Technology (degree granting institution)","2019","Cardiovascular diseases are considered as one the deadliest disease and have also been the most prominent health burden around the world and particularly in the Netherlands. Enormously mitigation has been done to reduce the death burden, by improving the quality of health care services and research related to cardiovascular diseases. One prominent strategy to reduce it is to identify early symptoms of cardiovascular diseases among the potential population. Currently, the prevailing cardiovascular disease risk prediction guidelines that used by a general practitioner only taking into account straightforward factors into their risk factors, and significant improvement to the guidelines is needed to include more socio-economic factors into account since many expert realize the fallacy of the systems. This research expands the current cardiovascular risk estimation guidelines with socio-economic factors such as ethnicity, occupation, social deprivation, by utilizing Bayesian network modeling to understand better the nature of socio-economic factors related to cardiovascular disease risk among the Hague population in the Netherlands. This research is collaborative research between Leiden University of Medical Center (LUMC) as the problem owner, the data provider and knowledge expert and TU Delft as an analyst.<br","Cardiovascular disease; Bayesian Network; Survival analysis; Street-level bureaucrats; CRISP-DM","en","master thesis","","","","","","","","2019-10-31","","","","Engineering and Policy Analysis","",""
"uuid:11721a15-d8dc-4e4c-be1a-721785494598","http://resolver.tudelft.nl/uuid:11721a15-d8dc-4e4c-be1a-721785494598","Cryogenic Hardware Considerations Of Neural Network Decoders For Quantum Error Correction Using Rotated Surface Codes","Overwater, Ramon (TU Delft Electrical Engineering, Mathematics and Computer Science)","Sebastiano, Fabio (mentor); Charbon, Edoardo (graduation committee); Bertels, Koen (graduation committee); Delft University of Technology (degree granting institution)","2019","The quantum bits (qubits) at the core of any quantum computers are so fragile that quantum error correction(QEC) schemes are needed to increase their robustness and enable fault-tolerant quantum algorithms. The surface code is one of the most popular QEC schemes, but it requires the availability of an efficient decoder. While neural networks have been shown to be well suited to this task, only software implementations have been studied in prior work. These have shown that neural network decoders can be on par or better than other decoding algorithms, but lack the required speed when running as software. The aim of this thesis is to investigate the hardware implementation of the neural networks for the decoders of surface codes to achieve the required speed. Most electronic hardware employed in quantum computers today operates at room temperature and is connected by bulky wires to the qubits, which are placed in a cryogenic chamber for proper operation. Since any useful quantum computer will comprise thousands or even millions of qubits, this work proposes to also move the QEC hardware to cryogenic temperatures (4 K). However, because at these temperatures the cooling power of cryogenic refrigerators is limited, the hardware needs to be low power, while ensuring enough speed to keep the pace of the QEC. The exploration of this work sweeps multiple parameters of a feed-forward neural network to find what the influence is on the decoder performance and the delay, the power, and the area. The parameters that are swept are the number of hidden layers, their sizes, the type of transfer functions and the number of bits used in the quantization of the weights and outputs. The results show that using the configurations found in this work it is possible to meet the performance and timing constraints using cryo-CMOS on both an FPGA and in a 40-nm technology. Although there are still some limitations in this work, such as the scaling in the power consumption and decoding performance for larger distances, there are multiple proposed improvements, making this is a stepping stone towards a future scalable implementation of QEC.","Cryogenic; Cryo-CMOS; Neural Network; Neural Network Quan; Quantization; Surface Code; Quantum Computing; Quantum Error Correction; Decoding; 40-nm; FPGA; Quantum Error Detection","en","master thesis","","","","","","","","2024-08-22","","","","","",""
"uuid:6393b42e-26a5-4479-98ef-c7758f2b896f","http://resolver.tudelft.nl/uuid:6393b42e-26a5-4479-98ef-c7758f2b896f","Experimental and simulated investigations of marine diesel engine performance against dynamic back pressure at varying sea-states due to underwater exhaust systems","Singh, Jaswinder (TU Delft Mechanical, Maritime and Materials Engineering)","Sapra, Harsh (mentor); Visser, Klaas (mentor); Delft University of Technology (degree granting institution)","2019","The innovation of underwater exhaust systems on ships increases onboard space, reduces noise emission and allows for zero direct emissions. For defense vessels, stealth is increased as the heat signature reduces due to underwater exhaust. However, there is a disadvantage of dynamic back pressure at the exhaust outlet which deteriorates the performance of the engine. The waves at the exhaust outlet are dynamic consisting of different wave heights depending on sea state and period. These waves cause dynamic back pressure at the exhaust outlet. Experimental and simulation investigations on the effect of externally applied static back pressure due to submerged exhaust is already carried out. It was found that there is an increase in fuel consumption and thermal loading with an increase in static back pressure. But, the sea waves acting at the exhaust outlet is dynamic with fluctuating amplitude and wave period. No experimentally validated research is available in the public domain to understand the effect of externally applied dynamic back pressure due to sea waves on the diesel engine performance. Thus, in this master thesis, the effect of the externally applied dynamic back pressure due to underwater exhaust on the performance of the diesel engine is investigated. Experiments are performed on a pulse turbocharged 4-stroke marine diesel engine at the Netherlands Defence Academy. Effects of dynamic back pressure on engine performance at different sea-states are investigated. The impact of wave significant height and wave period on the performance of the diesel engine is examined separately. Along with the performance of the diesel engine, the effect of back pressure on the emissions are also investigated. In this research experiment, the diesel engine under selected load points is subjected to single and continuous waves of back-pressure with changing amplitudes of 45 mbar, 35 mbar and 25 mbar(Gauge) while the periods were varied between 2, 4, 6, and 8 seconds. The back pressure is replicated with the help of an electronically controlled butterfly valve turbine outlet placed after which controls the resistance to exhaust gas flow to the atmosphere. A Diesel Engine - B model developed at TU-Delft is adopted and verified with the help of measured data from the experiments. The adopted model is a mean value engine model implemented in MATLAB/Simulink environment. Current literature lacks studies on experimental validation of the effects of dynamic back pressure on a marine diesel engine. The verified model is used to simulate the performance with higher sea states which may not be possible to simulate on a test bench. This research showed that exhaust side parameters (e.g Exhaust receiver temperature) are more critical than the inlet side parameters (e.g. Inlet receiver temperature). Moreover, there is an increase in parameters progressively with increase in the amplitude of back-pressure. Above a wave period value, the engine performance parameters changed by approximately equal values irrespective of varying periods above it. The impact of steady state back pressure is found more severe on the diesel engine’s parameters and fuel consumption compared to externally applied dynamic back pressure of the same amplitude. The recorded emissions show an increase in the concentration of carbon monoxide (CO), carbon di-oxide (CO2), nitrous oxide (NO) and sulphur di oxide (SO2) in the exhaust with an increase in back pressure. On the other side, the oxygen concentration decreases with increase in the applied steady state and dynamic back pressure. Simulations suggested that the governor plays a crucial role in tackling the effects of dynamic back pressure by controlling the fuel flow to the diesel engine. The simulation results are also used to provide the applied back pressure ceiling limits in terms of air excess ratio and exhaust valve temperature for the test engine.","Underwater exhaust; Diesel Engine","en","master thesis","","","","","","","","","","","","Marine Technology | Ship Design, Production and Operations","",""
"uuid:3c7bf465-7bd9-4ce2-b695-cf90569a7b19","http://resolver.tudelft.nl/uuid:3c7bf465-7bd9-4ce2-b695-cf90569a7b19","Fostering a Culture of Research within Agile Processes","Romero Valdes Victoria, Daniela (TU Delft Industrial Design Engineering)","Kuipers, Henk (mentor); Coelen, Jeroen (graduation committee); Delft University of Technology (degree granting institution)","2019","This project focuses on the integration of User Research in a Qualitative approach into an Agile work environment by conducting an in-house Case Study with Werkspot (Home improvement platform in the Netherlands). Customer expectations have hit an all-time high globally (Salesforce Research 2018) and as such, companies are expected to provide experiences beyond products (physical or digital). This has impacted the way companies must operate going forward, by recognizing and addressing customer involvement throughout the development process. The challenge relies in integrating two seemingly contradicting processes Agile development (fast-paced) and Qualitative Research practices (slow-paced) into a seamless operation. The objective is to include the end-users early in the development process. In this way, Werkspot is able to increase the chances of success of product features by implementing a validation phase prior to development process. This project makes a research distinction into Validative Research (concept or idea testing in an attitudinal level) and Explorative Research (learning from users on a behavioural level). Through the Research Case Studies (Section 04: ‘Research in practice’), Validative and Explorative research methods are tested and accelerated to operate under the Agile work setting from Werkspot. The result is a Qualitative Research Process for Werkspot, through this process, the company can continuously involve users in the development of the platform.<br","research and design process; Research-by-doing; research-type; Agile Software Development; user centric design","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:5eb320b9-1c4c-437f-b734-0ae4ac23d8f1","http://resolver.tudelft.nl/uuid:5eb320b9-1c4c-437f-b734-0ae4ac23d8f1","How to make the carbon offsets mechanism work in the current phase of the EU ETS?: A model-based analysis","Grappin, Marie (TU Delft Electrical Engineering, Mathematics and Computer Science)","Schröder, Enno (mentor); Delft University of Technology (degree granting institution)","2019","Massively reducing Greenhouse Gas (GHG) emissions is one of the biggest challenges of the 21th century. An important deployment of Renewable Energies (RE) can be a key element in attaining this objective. Setting a (high) carbon price would greatly help as it would send a powerful signal to RE investors that it is time to switch from high-emitting firms to free-emitting ones.<br/>Carbon pricing is implemented through the setting of either a carbon tax or an Emissions Trading Scheme (ETS). The European Union (EU) implemented its own ETS, the EU ETS, in 2005. Since then however, it faced low permit prices (partly due to an oversupply of both carbon permits and carbon offset credits), which raises a crucial question: how could the EU ETS and its carbon offsets market be improved to generate higher permit prices, thus promoting RE investment?<br/><br/>Two policy measures seem relevant today: implementing a floor price for permits (not examined in this work) and/or modifying the rules of the carbon offset credits market of the EU ETS. This master thesis will focus on offsets policy instruments the EU ETS could implement, drawn from a paper published by Bento et al. (2015), that aim at better designing its carbon offsets market and resulting in a higher permit price. The policy instruments analyzed are: stricter baselines, trade ratios and limits. This work will then discuss the efficiency (in regard to society welfare optimization) of these measures.","ETS; EU ETS; Offsets market; carbon market; offsets policy policy measures; permits price; SCC","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:6725a374-c44f-402f-8d10-ac63827c3773","http://resolver.tudelft.nl/uuid:6725a374-c44f-402f-8d10-ac63827c3773","Determining the structural evolution and strain distribution of a geologically complex area in SE of France by restoring multiphase deformation","Jones, Cyrille (TU Delft Civil Engineering and Geosciences)","Blom, J.C. (mentor); Abels, H.A. (graduation committee); Delft University of Technology (degree granting institution)","2019","The structural evolution, phases and amount of deformation, and the strain distribution of the sedimentary cover of a geologically complex area of 270 km2 in the French subalpine chains (Southeast of France; in the surroundings of the village La Motte-Chalancon) were deduced from the modelling of two folded and faulted competent layers (Tithonian and Barremian formations) both in 2D and 3D. These models were constructed from collected geological data such as BRGM (Bureau de Recherches Geologiques et Minères) geological maps, previous Bachelor’s fieldwork data, new field data and the study of aerial photographs (Google Earth). A grid of 20 vertical 2D cross-sections (10 N-S, and 10 E-W) was generated which was then imported and digitized in the geological modelling software package Move and the 3D model of the competent layers was built, validated and restored to its initial configuration prior to deformation by first removing each fault displacement (Fault Parallel Flow method) and then unfolding each structure (Flexural Slip method) in Move, showing deformation and shortening in two directions: N-S and E-W. The amount of deformation in both directions was estimated from the 3D model. Major deformation took place in the N-S direction with a maximum of 21% shortening for both layers which corresponds to an absolute shortening of 4067m for the Tithonian layer and 4076m for the Barremian layer. Less deformation took place in the E-W direction with a maximum of 9% to 10% for the Tithonian and Barremian horizons respectively which corresponds to an absolute shortening of 1697m and 1976m respectively. This resulted in an area reduction of 16% and 19% of the original area prior to deformation for the Tithonian and Barremian, respectively.<br/>Two phases of deformation over geological time were deduced from the orientations of the folds and faults present in the studied area. The presence of NW-SE trending folds and thrust faults (e.g. Mt D’Angele fault, Pommerol fault, or Chalancon fault) along with a conjugate strike-slip system (of one oriented N-S and one NE-SW) reflects the NE-SW compressional stress regime of the first stage of deformation which is related to the Pyrenean phase of the Alpine Orogeny. The second stage, the Alpine phase, which resulted in E-W contractions, is associated with the formation of domal/basinal structures as well as folds with plunging fold axes within the studied area. The northeastern part of the studied area exhibits different fault trends. Two tear faults (L’Aiguille and Ruelles fault), a dextral N-S strike-slip fault (Establet fault), and two E-W trending reverse faults (Peyssias and Hidden fault) resulted from N-S compression. These are related to the first phase of the Pyrenean stage, and then later partly rotated during the latter phase of the Alpine stage. <br/>The strain maps produced from the 3D model displaying the high-/low-strain zones of the area mainly show E-W and NW-SE trending strain zones which confirm the direction of the main stress regime of the Pyrenean compressional phase oriented NW-SE. <br","3D Modelling; Structural Geology; 3DMove; AES; Strain distribution","en","master thesis","","","","","","","","","","","","Applied Earth Sciences","",""
"uuid:56bdde1b-e3bd-4578-bd75-057d50d7a07d","http://resolver.tudelft.nl/uuid:56bdde1b-e3bd-4578-bd75-057d50d7a07d","Radial Piston Pumps: Performance and Efficiency","Bekker, Johan (TU Delft Mechanical, Maritime and Materials Engineering)","Polinder, Henk (mentor); van Ostayen, Ron (mentor); Gao, Zhen (mentor); Jarquin Laguna, Antonio (mentor); Nijssen, Joep (mentor); Diepeveen, Niels (mentor); Delft University of Technology (degree granting institution); Norwegian University of Science and Technology (NTNU) (degree granting institution)","2019","The modeling method for the performance of positive displacement pumps of hydraulic pumps is based on collecting operational data of the pump for its operational envelope and using equations with empirical fitting parameters and fit these equations to the data. This way values for the fitting parameters are obtained, with which the equations can be used as model for the operating performance of this specific pump. By implementing this modelling method no information about the contribution of each component present in the pump to the performance losses is obtained. A model which analyzes each component and estimates its contribution to the total power losses would be beneficial in the design of pumps. Therefore the answers to the following research questions are sought after in this work:<br/><br/>- What are the components critical to performance within hydraulic pumps?<br/>- To what accuracy can a component-wise, analytical model for pump performance be created?<br/>- How sensitive to certain parameters used in the equations is the model?<br/>- What are the possibilities of implementing this model into pump design?<br/><br/>After the pump system was analyzed and the internal interactions found, the components which effect pump performance the most were identified. These include bearings, rollers, seals, springs, valves and leakage flow which is dependent on gap size, piston movement and viscosity of the hydraulic fluid. For these components analytical equations are presented which are incorporated in the model.<br/><br/>The accuracy of the model is tested by comparing its results to test data of an experimental camring driven radial piston pump. The model predicts leakage flow to an average difference of 3% relative to the data, but outliers up to 49% for high pressures and -35% for low pressures are observed. Input torque is predicted to an average difference of -19% relative to the data. This difference is mainly caused by the inaccuracy of the predictions below 30 bar operating condition, where outliers up to -61% are observed. These results are compared to an empiric modelling method and are found to be more accurate for leakage flow for the entire operational envelope, yet on average less accurate for input torque.<br/>The sensitivity of the model to certain parameters is tested. The parameters investigated are the rolling resistance coefficient of rollers and bearings, bearing lubricant viscosity, hydraulic fluid temperature, piston-cylinder alignment and the corresponding forces resisting piston motion and the assumption of laminar leakage flow.<br/><br/>To show the possibilities of the model in pump design the rollers and appurtenant bearings present in the pump are replaced with hydrostatic bearings. The design is discussed and a hydrostatic bearing with an orifice restrictor is designed of which implementation will approximate the total efficiency of the pump with rollers. The Reynolds number of the flow necessary is found to be too high for capillary restrictors. To approximate the same total efficiency for each operating condition the average bearing flow is found to be 0.0016 L/s, which corresponds to an average fluid film height of 12 μm. The orifice restrictor diameter which allows this flow is found to equal 0.24 mm.<br/><br/>This work shows the possibilities of such a model, yet there is plenty room for improvement of the accuracy of the predictions made. Recommendations to this end are given in the conclusion and recommendations of the report.","Radial piston pump positive displacement hydraulic analytical component wise modelling efficiency performance","en","master thesis","","","","","","","","2024-08-29","","","","European Wind Energy Masters (EWEM) | Offshore and dredging engineering | Bottom Founded Structures, Arctic and Wind","",""
"uuid:d9740ddb-c6c0-45a7-9817-e2a7c8a56857","http://resolver.tudelft.nl/uuid:d9740ddb-c6c0-45a7-9817-e2a7c8a56857","A step towards Successful Implementation of Business Model Innovation: Philips Perspective","Neeli, Abhishek (TU Delft Civil Engineering and Geosciences)","Doorn, N. (graduation committee); Khodaei, H. (mentor); Straub, A. (mentor); Delft University of Technology (degree granting institution)","2019","In today’s fast growing and competitive environment, keeping up with changing trends has become a necessity for firms to beat the competition. A relatively new form of innovation with a growing community of people have stated that Business Model Innovation is essentially the key to successful organizations nowadays. Several companies are failing to achieve this in practice particularly in the implementation of new Business Models. This graduation research is carried out to tackle the problems in apprehending the key drivers, key barriers and key enablers along with process of a successful Business Model Innovation within Philips. The main research question is: “How can insights about various drivers, barriers and enablers help in the process of a successful Business Model Innovation transforming business within companies?”To achieve the objectives, the research was segregated into three main stages namely Literature Study, Phase 1, Phase 2.In Literature Study, the basic understanding of Business Model Innovation concepts was made aware. After having a clear comprehension, the literature study forayed into desk research where Secondary Articles like Harvard Business Review in addition to documents from within the companies were reviewed. A list of Drivers, Barriers and Enablers were identified from literature review alone along with several inputs for framework. Thus, Literature Study facilitated the development of questions for conducting interviews in Phase 1 of the research.In Phase 1, semi-structured interviews were conducted to support the findings from a practical perspective. The target group included practitioners from different functional background dealing with Business Model Innovation of some sort and were considered as subject matter experts. A total of 11 participants were interviewed. The recommendations provided by the interviewees along with an in-depth literature helped to identify a total of 16 Drivers, 32 Barriers and 22 Enablers.Following the analysis, the research proceeded with Phase 2. Here a survey was devised. This was done to rank the various Drivers, Barriers and Enablers. A total of 32 participants answered the questionnaire and the top three of each of Drivers, Barriers and Enablers were listedFurther to this, the findings added to the integrative framework. This framework was based on 4I process framework by Frankenberger, Weiblen, Csik, &amp; Gassmann (2013). Inputs from interviews, survey and in-depth analysis went on to adding components to the framework. The proposed framework contributes in two ways: First, it lists a comprehensive list of key drivers, key barriers and key enablers which come up during the process of Business Model Innovation. Secondly, a process model of Business Model Innovation with key tasks have been outlined. As literature suggests so far there has been no process model developed for Business Model Innovation. This integrative framework incorporates the quite dispersed literature and helps to organize existing contributions and in identify any “blind spots” of Business Model research.Among the many other Recommendations, an important one is that the scope of the research in developing the conceptual framework is at a holistic level, since the key focus of the research was to identify key drivers, key barriers and key enablers that incorporates various perspectives. When Business Model Innovation is being undertaken at a rapid pace within the company it would be interesting to analyze in-depth on the individual elements of the framework. It would also be interesting to develop metrics around the drivers, barriers and enablers which could be adopted within projects of any nature.","Business Model Innovation; Innovation; Process Design; Conceptual Framework; Drivers; Barriers; Enablers","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:b4f36050-6b3d-46cc-a4b0-407e71a20742","http://resolver.tudelft.nl/uuid:b4f36050-6b3d-46cc-a4b0-407e71a20742","In search of the barriers and drivers for the implementation of a Circular Economy in Dutch infrastructure projects","van der Sande, Lennart (TU Delft Civil Engineering and Geosciences)","Hertogh, M.J.C.M. (mentor); Schraven, D.F.J. (mentor); de Bruijne, M.L.C. (mentor); Flapper, Jasper (mentor); Delft University of Technology (degree granting institution)","2019","In 2015, the Paris Agreement was established with the aim to strengthen the global response in limiting the increase in the global average temperature. This can be achieved by, amongst other measures, lowering of CO2 emissions. The Paris Agreement was also signed by the Netherlands. Within the Netherlands, the construction sector has the largest environment impact of all sectors; accounting to 36% of the national CO2 emissions, 50% of the national material usage and 40% of the total energy consumption. Research has shown that implementing a CE in this sector may significantly lower these CO2 emissions and material usage. Despite the establishment of several national agreements aiming to accelerate the implementation of a CE in Dutch infrastructure projects, progress is slow. Several barriers are assumed to hamper this transition, while drivers may accelerate the transition towards a CE. This study aims to identify the barriers to and the drivers of the implementation of a CE in part of the Dutch construction sector; the infrastructure sector. The research question is “What are the barriers and drivers that respectively need to be overcome and enhanced in order to accelerate the implementation of a Circular Economy in Dutch infrastructure projects?”<br/><br/>Based on a review of the literature on barriers and drivers for the implementation of a CE in general and in the construction sector, a literature-based framework of CE barrier- and driver-categories was developed. This framework provided the basis in formulating the questions for the interviews. A total of 15 interviews were conducted with respondents from a diverse and balanced group of stakeholders in the infrastructure sector. Respondents were asked what they think are the barriers and drivers for the implementation of a CE in Dutch infrastructure projects. A total of 135 barriers and 72 drivers were identified during the interviews, which could be grouped in the categories of the literature-based framework. The most frequently mentioned barriers relate to the procurement of infrastructure projects, the aversion of risks and the higher costs of secondary or circular materials as compared to ‘virgin’ materials. The most frequently mentioned drivers often require the government to take action, and involved developing more binding legislation and regulation on the use and application of circular materials (at least to an extend) in infrastructure projects. Additionally, as the commissioner of the majority of infrastructure projects in the Netherlands, the government providing more room for circular innovations or pilot projects was mentioned as a driver.<br/><br/>While this study is novel in the sense that it is the first to provide an overview of the barriers and drivers for the implementation of CE in the context of infrastructure project, further search is required to determine how the identified barriers and drivers can respectively be overcome and enhanced. Additionally, further research to validate the applicability of the literature-based framework of CE barrier- and driver-categories in infrastructure projects in other countries is recommended.<br","circular economy (CE); infrastructure projects; the Netherlands; Barriers; Drivers; circularity; sustainability","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:6b353b60-cc29-4c2b-b6ff-e9308414c212","http://resolver.tudelft.nl/uuid:6b353b60-cc29-4c2b-b6ff-e9308414c212","Diagnosing Community-based Management of Groundwater in Peri-urban Areas: A socio-ecological approach","Mittal, Aashna (TU Delft Technology, Policy and Management)","Slinger, J (graduation committee); Gomes, S.L. (mentor); Hermans, L.M. (mentor); van der Voort, H.G. (graduation committee); Delft University of Technology (degree granting institution)","2019","The city of Kolkata in India is undergoing rapid urbanization and expansion. As the city expands and engulfs its neighboring areas, it threatens the sustainability of natural resources in peri-urban areas – spaces that are gradually transitioning from rural to urban areas. One such natural resource, groundwater, forms the lifeline of peri-urban communities near Kolkata, supporting their drinking, domestic, and livelihood needs. However, under conditions of rapid urbanization, industrialization and population growth, peri-urban areas witness over-exploitation of the groundwater resource. Limited capacity of formal government bodies to manage the resource coupled with ongoing trends of decentralization in India provide the basis for exploring new ways of managing groundwater in peri-urban areas. One such approach is community-based management (CBM) where local communities can craft rules and norms to sustainably manage a resource. This research studies two peri-urban areas near Kolkata to understand the groundwater problems faced by peri-urban communities, how they respond to these problems, and what challenges they face in resolving their problems. First, the Socio-Ecological Systems (SES) framework developed by Elinor Ostrom and her colleagues is used to structure and highlight the factors critical for managing groundwater in peri-urban areas. Next, the overall performance of CBM is evaluated using Ostrom’s design principles and 10 second-tier SES variables proposed by Ostrom (2009). The research shows that peri-urban communities at best cope with problems of groundwater scarcity or seek short-term solutions to delay periods of scarcity. The results from this evaluation show that although community-based management is a good strategy in theory, its realization in peri-urban areas will need to overcome barriers such as low predictability of the groundwater resource, lack of community-wide leadership, low autonomy to craft rules for groundwater management, and varied mental models.","Groundwater; Peri-urban; Community-based management; SES Framework","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","","22.5726"
"uuid:291d585c-c73a-46e4-8527-1a848ea07166","http://resolver.tudelft.nl/uuid:291d585c-c73a-46e4-8527-1a848ea07166","Public support for Tradable Peak Credits as an instrument to reduce congestion: A stated choice experiment that is simultaneously used to investigate the influence of content and medium of stated choice introductions","van Bergen, Chris (TU Delft Technology, Policy and Management)","Molin, E.J.E. (mentor); de Vries, G. (graduation committee); Krabbenborg, Lizet (graduation committee); Delft University of Technology (degree granting institution)","2019","Tradable Peak Credits (TPC) is a new instrument to reduce congestion. It is expected to have a higher public support than traditional road pricing. So far, research has mainly been conducted into behavioral effects and effects on the road network of implementing such systems. This study investigates the public support for TPC and how this support is influenced by the design of the TPC system by means of a stated choice experiment. It was shown that TPC does not have a higher public support than a congestion charge and a kilometer charge as was hypothesized. Also, it was shown how different groups of variables influence the support for TPC. Furthermore, public preferences regarding the design of a TPC system were revealed. Recommendations are made for further research on TPC and for policymakers. The stated choice experiment was also used to investigate to what extent variations in communication medium and content influence the outcomes of the experiment.","tradable permits; road pricing; stated choice experiment; panel mixed logit","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:7d46fd9a-3cc9-4814-a242-ec3b5ca18fda","http://resolver.tudelft.nl/uuid:7d46fd9a-3cc9-4814-a242-ec3b5ca18fda","Preparing HGG for its future","van Kampen, Jan (TU Delft Mechanical, Maritime and Materials Engineering)","Schott, D.L. (mentor); Veeke, H.P.M. (mentor); Wijnker, J.A.J. (mentor); Kaarsemaker, D.P. (mentor); Delft University of Technology (degree granting institution)","2019","","DSA; in company cooperation","en","master thesis","","","","","","","","2023-12-31","","","","Marine Technology | Transport Engineering and Logistics","",""
"uuid:d6ff0f02-f140-463f-bdcb-111e32104d1c","http://resolver.tudelft.nl/uuid:d6ff0f02-f140-463f-bdcb-111e32104d1c","The Role of Pilot- and Demonstration Projects in Accelerating Hyperloop: A Multi-level Perspective towards Large-scale Technological Transitions - Maglev as a Case Study","Koerkamp, Hidde (TU Delft Technology, Policy and Management; TU Delft Transport and Logistics)","van Wee, G.P. (mentor); Annema, J.A. (graduation committee); van de Kaa, G. (graduation committee); Marges, Stefan (graduation committee); Delft University of Technology (degree granting institution)","2019","The contemporary transportation system is encountering drawbacks related to air pollution, noise nuisance and traffic congestion. Emerging sustainable alternatives based on magnetic levitation have emerged but failed to successfully breakthrough in incumbent regimes based on high-speed rail and air transportation. Emerging innovation systems face difficulties in obtaining enough momentum necessary to break out of the niche level and induce a technological transition. Therefore, it is important to understand the changing roles that pilot-and demonstration projects have in the build-up processes of emerging innovation systems. As a start, the role of pilot- and demonstration projects together with the state-of-the-art literature on innovation systems and technological transitions is analyzed. A conceptual framework is constructed and empirically tested with a longitudinal case study on the emergence of the high-speed maglev transportation innovation system in Germany and Japan. In conclusion, the recognition of the changing roles of pilot- and demonstration projects along the motors of innovation together with anticipation of the landscape and regime developments could result in enhanced momentum for emerging innovation systems to break out successfully of the niche level.","Pilot- and Demonstration Projects; Technological Transitions; Technological Innovation Systems; Motors of Innovation; Landscape Developments; Niche Developments; Regime; Maglev; Hyperloop","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:fa97e620-63bc-4acb-ae1d-8621ef351860","http://resolver.tudelft.nl/uuid:fa97e620-63bc-4acb-ae1d-8621ef351860","Development of a software framework to assess the potential of adaptive trailing edge flaps on horizontal-axis wind turbines","Vossebeld, Rogier (TU Delft Aerospace Engineering)","Ferreira, Carlos (mentor); Gaunaa, M (mentor); Bott, S. (mentor); Delft University of Technology (degree granting institution); Technical University of Denmark (degree granting institution)","2019","","ATEF; ATEFlap","en","master thesis","","","","","","","","","","","","European Wind Energy Masters (EWEM) | Rotor Design Track","",""
"uuid:7119b306-3317-4b27-927f-a906acfdf30e","http://resolver.tudelft.nl/uuid:7119b306-3317-4b27-927f-a906acfdf30e","Lower limb prosthesis liner design for amputees with diabetes","Broderick, Cathy (TU Delft Mechanical, Maritime and Materials Engineering)","Plettenburg, D.H. (mentor); Delft University of Technology (degree granting institution)","2019","This project investigates the needs of diabetic and vascular amputees to establish design criteria for a new lower-limb prosthesis liner specifically for diabetes and vascular patients. Initially, a literature review was conducted to investigate liner material properties and outcomes during use, as well as how often diabetic and older amputees were used as human subjects or referenced in prosthesis liner research. This literature review drew conclusions specifically for diabetes and vascular patients and proposed design considerations for this patient population. For additional design considerations, a formal contextual inquiry with patients, clinicians, Certified Prosthetists and Orthotists, podiatrists, and physiotherapists was conducted to learn more about diabetes and vascular patients, their prosthesis usage, their exercise routines, and patient care. Additionally, marketing and business perspectives are also included as design considerations, or inputs to the design criteria. It was found that the most important issues for the diabetic and vascular amputee are that liner and socket issues cause decreased prosthesis usage and decreased mobility and health. These liner and socket issues can be categorized into three root causes: the hard socket material, poor liner suspension, and sweat inside the liner. These root causes lead to pain, bruising, and wounds on the residual limb. Due to the decreased wound sensation and healing abilities found in diabetic and vascular patients, these patients cease or greatly decrease their prosthesis usage, leading to less mobility and decreased health. With this information, design criteria were developed. After<br/>formulating design criteria, conceptual solutions were brainstormed, developed and evaluated using the Harris Profile scoring system. Based on this scoring, the most appropriate conceptual solutions were prototyped. These design improvements were quantitatively evaluated against the relevant design criteria and a qualitatively evaluated based on user feedback. Improvements to amputee comfort and knee bending were achieved with the new design. Future work includes further prototyping and implementation of advanced concepts brainstormed in the conceptual solutions.","lower limb; prosthesis; liner; amputee; diabetes; socket","en","master thesis","","","","","","","","2021-08-29","","","","","",""
"uuid:a539b715-0237-4047-a744-1c45d3327150","http://resolver.tudelft.nl/uuid:a539b715-0237-4047-a744-1c45d3327150","Design of a Wideband Wide-Scan Connected Slot Array Antenna Using Artificial Dielectrics","van Katwijk, Sander (TU Delft Electrical Engineering, Mathematics and Computer Science)","Neto, A. (graduation committee); Cavallo, D. (mentor); Babaie, M. (graduation committee); Delft University of Technology (degree granting institution)","2019","","","en","master thesis","","","","","","","","2021-08-29","","","","","",""
"uuid:e7b0322d-2ba7-43c3-9067-80eca365a652","http://resolver.tudelft.nl/uuid:e7b0322d-2ba7-43c3-9067-80eca365a652","Architectured MIcrostructures: The effect of localized laser heat treatment on the microstructure of a FeCNi steel","Breukelman, Hubert (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Materials Science and Engineering)","Hidalgo Garcia, J. (mentor); Santofimia, Maria Jesus (mentor); Hermans, M.J.M. (graduation committee); Sluiter, M.H.F. (graduation committee); Delft University of Technology (degree granting institution)","2019","Laser surface treatments offer interesting prospects for the creation of architectured microstructures formed by distinct phases in metastable austenitic steels. In the present study, a laser-based localised heat treatment was developed to locally create an austenitic region in a quenched Fe25Ni0.2C martensitic microstructure. The highly localised laser heat flux gives rise to high spatial gradients in peak temperature and heating rate. This results in strong variations in the microstructures observed over short distances, which are related to local changes in the martensite to austenite phase transformation temperatures and formation mechanisms, the occurrence of grain growth and recrystallization in the newly formed austenite, and the tempering of the initial martensite. Moreover, thermal stresses and surface effects influence the final microstructure. In this work, effects of heating rates and peak temperatures are studied by dilatometry whereas Electron Backscatter Diffraction (EBSD) and optical microscopy are used to assess austenite grain size and morphology. This information is linked to a Finite Element Model of the local thermal history to investigate the evolution of the local microstructure throughout the zone affected by the laser heat source. This research provides insight into localised microstructural control of steels with laser surface treatment and provides a thermal model for detailed understanding of the mechanisms controlling the microstructural changes taking place during these treatments.","Laser Surface Treatment; Austenite reversion; Thermal modelling; Microstructure","en","master thesis","","","","","","","","","","","","Materials Science and Engineering","",""
"uuid:711543f2-497c-4bfb-abd9-5dcef88d8786","http://resolver.tudelft.nl/uuid:711543f2-497c-4bfb-abd9-5dcef88d8786","Power Efficiency of the Gyroscopic-Pendulum Wave Energy Converter","Anwari, Sherzad (TU Delft Mechanical, Maritime and Materials Engineering)","Masturi, L.M. (mentor); Hendrikse, H. (graduation committee); Metrikine, A. (graduation committee); Delft University of Technology (degree granting institution)","2019","The oceans, which cover nearly 70% of the earth’s surface, can be considered as an inexhaustible energy source for renewable electricity due to its size and predictability. One way to capture ocean energy is by harnessing the energy produced by waves at sea, by means of devices called wave energy converters (WECs).<br/><br/>Delft University of Technology is developing a new floating WEC concept called the ”gyroscopic-pendulum”. This concept is a modification of the so called ”classical vertical axis pendulum”, which is capable of producing mechanical power harvested from the rotations of the pendulum around the vertical axis. <br/><br/>The new concept is proposed by adding a flywheel with the aim to enhance the rotations of the pendulum about the vertical axis. The enhancement comes from gyroscopic precession which is created due to a change in the angular moment of the spinning flywheel caused by the torque originating from the weight of the pendulum.<br/><br/>This thesis starts with a general introduction about wave power followed by the mathematical and numerical model of the gyroscopic-pendulum. Numerical simulations are performed in which the gyroscopic-pendulum and the classical pendulum are both imposed with the same harmonic roll motion, while the gyroscopic-pendulum system also receives some power input to rotate the disk. The main objective is to find out in which ranges of amplitude and frequency of imposed motions, the gyroscopic-pendulum results in an improvement of the power efficiency compared to the classical vertical axis pendulum. <br/><br/>The results obtained from tests performed in the simulated conditions, shows us that the gyroscopic-pendulum has a significantly higher efficiency compared to the classical vertical axis pendulum when the frequency of the imposed roll motion is in the range of 1.4 to 1.75 rad/s and the amplitude is in the range of 0.6 to 0.95 푚.","Wave Energy Converter; WEC; Gyroscopic-pendulum; gyroscopic effect; precession; vertical axis pendulum; rotational motion","en","master thesis","","","","","","","","2021-08-18","","","","","",""
"uuid:7ac41049-3ca8-4722-b853-51f7b1c3e0b3","http://resolver.tudelft.nl/uuid:7ac41049-3ca8-4722-b853-51f7b1c3e0b3","Process Design of the Logistic Process in Fulfilment Centres from an Automation and Operational Perspective","Steendijk, Jasper (TU Delft Mechanical, Maritime and Materials Engineering)","Beelaerts van Blokland, W.W.A. (mentor); Polinder, H. (graduation committee); Delft University of Technology (degree granting institution)","2019","This paper describes the research regarding the process design of the logistic process in fulfilment centres from an automation perspective in order to improve the operation performance. The objective is to provide a new design of the logistic process with substantiated decision in each phase of the process to enable a higher level of automation and improved operation performances. This research is structured based on the methodologies of lean manufacturing, six sigma and the theory of constraints, in order to result in well-structured, substantiated design alternatives. These design alternatives are analytically compared with the current state in order to obtain the most optimal logistic process. This research follows a scientific design approach in order to result in generic conclusions.","","en","master thesis","","","","","","","","2021-09-01","","","","Mechanical Engineering","",""
"uuid:33776fe7-9428-42c0-9390-fcbb192489fe","http://resolver.tudelft.nl/uuid:33776fe7-9428-42c0-9390-fcbb192489fe","The influence of Low Impact Development on rainfall-runoff relationships at catchment scale","Sui, Xinxin (TU Delft Civil Engineering and Geosciences)","van de Ven, F.H.M. (mentor); Hrachowitz, M. (graduation committee); Babovic, Vladan (graduation committee); Rikkert, S.J.H. (graduation committee); Delft University of Technology (degree granting institution)","2019","With rapid urbanization, Low Impact Development (LID) is promoted as an alternative to Conventional Drainage (CD), seeking a natural solution for current urban water problems. The positive effects of LID were the main theme of recent LID researches, but this project aims to deeply explore the hidden troubles about the extreme peak runoffs influenced by LID city on catchment scale.<br/>In this research, the SUPERFLEX conceptual model was adapted to a rural-urban semi-distributed model to simulate the current rainfall-runoff relationship of the catchment where San Antonio city is located in. Besides, the model expressions of 4 representative LID practices (bioretention cells, vegetated swales, green roofs, and permeable pavements) were devised under SUPERFLEX framework. To deal with the prediction uncertainty, three urban development scenarios in 2040 and five LID implementation scenarios were designed for San Antonio city. And their influences on the basin peak runoffs will be quantitively studied.<br/>Research result shows that, the urban runoff tended to swing between extreme flood and extreme drought in the reference situation; And next, the infill urban development strategy, which means developing the vacant or undeveloped land within an existing community, was more helpful on peak runoff and total runoff volume control than sprawl urban development strategy with the same population growth; Thirdly, the bioretention cells, vegetated swales, and permeable pavements had similar good performance on peak runoff reduction, which can be mainly ascribe to the stormwater infiltration process. As for the retention of total runoff volume, the bioretention cells, permeable pavements, and green roofs perform better than vegetated swales since the rapid water transportation character of vegetated swales decrease the water residence time for infiltration;<br/>The runoff reduction function of LID practices performs effective on the large peaks in dry and normal seasons, but it will be restrained significantly in flood season. According to model result, the rural peak runoffs happened 6.5 to 15.5 hours after the urban peaks. And for 4 LID implementation scenarios in which 15% of urban grey areas is covered by LID practices, the urban peaks are delayed between 0.5 and 2.5 hours. And for the scenario with the LID cover areas as 50% of the urban grey areas, the time lag of urban peaks varies from 0.5 to 6.5 hours. For this scenario, since the obvious time delay of urban peaks, more stack of urban and rural peaks is caused by the time approaching of urban and rural peaks, which causes the increases of two total basin peaks in flood season from 3.57 to 3.65 mm/d and from 6.35 to 6.47 mm/d respectively. <br/>In conclusion we may say that the stacking effect of LID implementation on total basin runoff is limited in the case of San Antonio basin, partly due to the fact that only a small part of this basin is urbanized.<br","Low impact development; rainfall-runoff relationship; SUPERFLEX; urbanization; LID; peak runoff","en","master thesis","","","","","","","","","","","","","","29.424349, -98.491142"
"uuid:8a8caaf2-1152-447f-8a02-adba4a713361","http://resolver.tudelft.nl/uuid:8a8caaf2-1152-447f-8a02-adba4a713361","Children's mobile screen use: an intervening loyalty campaign","Janbroers, Joris (TU Delft Industrial Design Engineering; TU Delft Industrial Design)","Pasman, Gert (mentor); Gielen, Mathieu (mentor); Delft University of Technology (degree granting institution)","2019","Nowadays, growing up is quite different from what it was before. Around the globe the larger part of children engage in inordinate time looking at screens (Bucksch et al., 2016). The smartphone enables children to have more screen time, leading to negative consequences. Nevertheless, children still prefer this type of entertainment due to the entertainment values they get from the use. <br/>This thesis examines how a loyalty campaign can intervene with a negative consequence of mobile screen use while utilizing the positive entertainment elements amongst children aged from six till twelve years.<br/><br/>Fourteen problems of smartphone usage accompanied with their consequences are found by literature research. These problems are presented to parents to gauge their opinion on this objective data, forming a first design goal: “Design a playful loyalty campaign that stimulate the engagement of children in active play by utilizing the entertainment values of a smartphone, to spark ones creativity.” Interviews with children accompanied with their parents examines more details on the first design goal. What boundaries need to be set with regard to the context? Which entertainment values of digital play are important to children? What is the influence of the touchscreens’ low threshold usage on active play? And finally; What is the influence on a child’s creativity? As a conclusion to this research, a new design goal is formulated: “The tactilization and experience of digital entertainment. In order to bring a connection between digital and ‘real world’ concepts and make them accessible to children.” The following criteria to this goal form the basis of evaluation for the concepts:<br/>The concept should:<br/>- educate on the subject of food<br/>- be able to be played alone.<br/>- support playing together.<br/>- contain a part of simulation during the play. <br/>- involve the exploration and discover of new elements.<br/>- involve experimentation without social consequences.<br/>- create play which is mostly focussed on a central tangible/touchable object integrated with digital entertainment.<br/>- be able to be played during daytime.<br/>- does not involve any online contact with strangers<br/>- let children experience an unknown real world phenomena.<br/>- not be able to be played without a physically present object.<br/>- can be played without the use of a mobile device.<br/>- has a high level of collect-ability.<br/>- is valuable when only a few gifts are received by the user.<br/>- involves creating something. <br/><br/>The result, called “Body Builders”, is a concept in which children learn about nutrients that come from food. 20 3D characters standing for nutrients can be collected. Together with the application, these characters will come alive and the child will experience what these, previously unknown nutrients, do to your body. User test shows, that the concept brings an intertwined combination between digital gaming and tangible play. In contrast to current mobile screen use, this concept balances between real and digital play by utilizing the play experiences children like. <br","Product Design; User testing; Children; Play; App Design","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:dde4e58f-e109-4e7f-8ecb-ed1734294e5c","http://resolver.tudelft.nl/uuid:dde4e58f-e109-4e7f-8ecb-ed1734294e5c","Model Free Reinforcement Learning with Stability Guarantee","Tian, Yuan (TU Delft Mechanical, Maritime and Materials Engineering)","Pan, Wei (mentor); Zhou, Hongpeng (graduation committee); Delft University of Technology (degree granting institution)","2019","Model-free reinforcement learning has proved to be successful in many tasks such as robotic manipulator, video games, and even stock trading. However, as the dynamics of the environment is unmodelled, it is fundamentally difficult to ensure the learned policy to be absolutely reliable and its performance is guaranteed. In this thesis, we borrow the concept of stability and Lyapunov analysis in control theory to design a policy with stability guarantee and assure the guaranteed behaviors of the agent. A novel sample-based approach is proposed for analyzing the stability of a learning control system, and on the basis of the theoretical result, we establish a practical model-free learning framework with provable stability, safety and performance guarantees.<br/>% Specifically, a novel locally constrained method is proposed to solve the safety constrained problems with lower conservatism. In our solution, a Lyapunov function is searched automatically to guarantee the closed-loop system stability, which also guides the simultaneous learning (covering both the policy and value-based learning methods). Our approach is evaluated on a series of discrete and continuous control benchmarks and largely outperforms the state-of-the-art results concerning unconstrained and constrained problems. It is also shown that the algorithm has the ability of recovery to equilibrium under perturbation using the policy with stability guarantee. (Anonymous code is available to reproduce the experimental esults\footnote{\url{https://github.com/RLControlTheoreticGuarantee/Guarantee_Learning_Control}}.) Since sometimes the constraint is hard to define, we introduce a novel method to learn a constraint by representing the bad cases or situations as a distribution, and the constraint is the Wasserstein distance between the distribution.","Reinforcement Learning","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Vehicle Engineering","",""
"uuid:ca85f3c0-4b67-4dc8-b211-1168e15485a9","http://resolver.tudelft.nl/uuid:ca85f3c0-4b67-4dc8-b211-1168e15485a9","Optimisation based design of an integrated energy system in the Netherlands: A case study at Picnic","Vollering, Frank (TU Delft Electrical Engineering, Mathematics and Computer Science)","Heijnen, Petra (mentor); Lukszo, Zofia (mentor); Tindemans, Simon (graduation committee); Gorte, Frank (graduation committee); Klein, Amy (graduation committee); Delft University of Technology (degree granting institution)","2019","As the share of solar and wind in the energy mix increases, the inherent intermittency of these energy sources pose a great challenge for the Dutch power grid. The occurrence of problems with congestion and balancing power supply and demand are becoming more common. Companies in the Netherlands show potential to implement means for smart use of energy to alleviate these kind of problems. However, the gap between academic solutions and the industry is often too large. This research presents a method to find the optimal design of an integrated energy system in the Netherlands. A use case at Picnic is used to apply the proposed method. A flexible load scheduling optimisation algorithm is presented to explore the financial benefit of an integrated energy system that combines a photovoltaic system, an energy storage system, a cold storage system and a fleet of electric vehicles. The financial performance of different system designs are compared. Results show that the optimised load schedules for the EV fleet and CS system achieve a 2.6% decrease of energy costs with respect to the benchmark of Picnic. A PV system turns out to be beneficial for every size that the grid connection allows. This research finds 600 square meters to be optimal in the case of Picnic. An energy storage system would make optimised load schedules obsolete due to its flexibility. An energy storage system with a capacity of 250 kWh is found to be optimal according to the performance analysis. However, significant limitations in the assumptions of the storage system advise against installing it. Further research is required to elaborate the different elements in the proposed model. Different markets are suggested to use as a basis for load scheduling and a broader set of system designs is suggested to analyse their performance.","Smart grid; Integrated energy system; Smart charging; Optimisation","en","master thesis","","","","","","","","2024-08-29","","","","","",""
"uuid:2f4a3b1b-5f73-456b-af15-b6e855937718","http://resolver.tudelft.nl/uuid:2f4a3b1b-5f73-456b-af15-b6e855937718","Designing Repair Processes by Introducing a Return Quality Control Model: A Method for Sustainable Initial Repair Process Design","Haak, Daan (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Transport Engineering and Logistics)","Beelaerts van Blokland, Wouter (mentor); Beelaerts van Blokland, Wouter (graduation committee); Schott, Dingena (graduation committee); Vleugel, Jaap (graduation committee); Delft University of Technology (degree granting institution)","2019","An increasingly dynamic and competitive market forces MRO businesses to improve on efficiency and sustainability of remanufacturing processes. Present research focus on current process states and recovery, improvement and control of process phases beyond initial design without inclusion of return quality. This research addresses a method for sustainable initial repair process design from a return quality perspective. For this purpose it introduces a return quality control model that provides repair process design guidelines. The aim of the research is to provide a foundation for automated repair process design that incorporates future states and the relation of return quality to the operational process.","Aviation MRO; Engine Repair; Sustainable Process Design; Return Quality Control; Process Upscale Strategy; Repair Design Generator","en","master thesis","","","","","","","","","","","","","",""
"uuid:a1c0e77f-8309-4633-be92-f9b28fc0ec53","http://resolver.tudelft.nl/uuid:a1c0e77f-8309-4633-be92-f9b28fc0ec53","Foster Individual Productivity at the Workplace","Gecaj, Dennis (TU Delft Industrial Design Engineering)","Pasman, Gert (mentor); Xue, Haian (graduation committee); Delft University of Technology (degree granting institution)","2019","This project began with an interest in the productivity of the individual. How does the definition of productivity change when altering the perspective from a team to the individual? The context of this project is very intentionally limited to the individual workplace of an employee. The opportunities of an understanding of individual working techniques and personal strategies that employees develop to cope with mood changes throughout their working day can offer great insights and possibilities to guide and help the individual in accomplishing their personal work goals. The shift of perspective from designing for an entire working environment to the focus of individual productivity is one of the goals in this graduation project.","productivity tracker; phone; distraction free workplace","en","master thesis","","","","","","","","","","","","","",""
"uuid:f19b7b4b-43e4-45e9-82a1-36ed5bb9a0d9","http://resolver.tudelft.nl/uuid:f19b7b4b-43e4-45e9-82a1-36ed5bb9a0d9","Measurement of cooling rate during plunge freezing of sample preparation in cryo electron microscopy","Bikker, Bas (TU Delft Mechanical, Maritime and Materials Engineering)","Ghatkesar, Murali (mentor); den Hoedt, Sander (mentor); Delft University of Technology (degree granting institution)","2019","Plunge freezing is used as a sample preparation method to freeze biological samples in a vitrified thin water layer of &lt;500nm. Typically sample is loaded on thin (&lt;10nm) carbon membranes of a copper mesh grid. The vitrified biological sample is imaged using high resolution cryogenic transmission electron microscopy (Cryo-EM).The common practice of rapidly plunge freezing biological material prepares it to be placed in the vacuum chamber of the Cryo-EM by cooling it to a vitrified state (causing vitrification). In the present sample preparation methods, 90% of the biological materials used experience some form of contamination or damage during the transfer process and end up unusable. While improvements have been made, such as the automation of sample loading into the Cyro-EM, these improvements have brought on their own set of complications. In want of a better solution for the issues surrounding the cryo-sample preparation and loading, the research and experiments of this thesis focused on the question: is it possible for biological material to be vitrified on an Autogrid with plunge freezing? To answer this question experiments were carried out to measure the cooling rate of EM-grid and Autogrids during plunge freezing with a Vitrobot. A small thermocouple was embedded into an EM standard-grid and Autogrid glued in place with cryo-varnish. The EM-grid was then mounted onto Vitrobot tweezers and plunged into liquid ethane (cryogen). The set-up mimics to the best of its possibilities the same conditions and procedure of the standard Cyro-EM workflow and temperature was recorded at a rate of 32000 samples per second. Cooling rates measured with an EM-grid were as expected. The cooling rate of the Autogrid is slower than that of standard grid, which implies that the Vitrobot is not capable of vitrifying biological materials on an Autogrid. Research and experiments showed that the Vitrobot would probably not be capable of achieving vitrification on Autogrid because the measured cooling rate was slower then that of EM-grid. Cooling rates with the Vitrobot could be improved by a faster and deeper plunger.","","en","master thesis","","","","","","","","2020-12-31","","","","","",""
"uuid:43929003-d4e2-4a8d-941e-9f9dd3ad7d50","http://resolver.tudelft.nl/uuid:43929003-d4e2-4a8d-941e-9f9dd3ad7d50","Investigation of methods for Extrapolation &amp; Interpolation of Radial Compressor &amp; Turbine Performance maps","Mandal, Rajarshi (TU Delft Aerospace Engineering)","Pini, M. (mentor); Delft University of Technology (degree granting institution)","2019","The project focuses on developing and implementing a 0D or 1D model for radial compressors and turbines, capable of both interpolating and extrapolating the performance maps. The proposed model will be calibrated using the data points available in the maps provided by the manufacturers to produce accurate mass flow for turbines and pressure ratio for compressors along with efficiency performance data, to be further used in system level simulation of Brayton cycle for power generation and IC engine turbocharger, to name a few. The developed model should be robust, easy to implement, less computationally expensive and at the same time valid for a wide variety of turbines and compressors","radial turbine; radial compressor; performance map; extrapolation; interpolation; modelling","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:178e2496-cf4a-440b-a877-ed34b2206284","http://resolver.tudelft.nl/uuid:178e2496-cf4a-440b-a877-ed34b2206284","A state observer based data assimilation method between RANS and robotic PIV data","Tumuluru Ramesh, Nikhilesh (TU Delft Aerospace Engineering)","Sciacchitano, A. (mentor); Saredi, E. (mentor); Delft University of Technology (degree granting institution)","2019","Experimental fluid dynamics and computational fluid dynamics have traditionally been treated as disparate fields of study. However, each field has its own unique set of advantages and disadvantages. Data assimilation is a field that can be used to leverage some of the advantages each field offers to help compensate mutual<br/>weaknesses. In this thesis, a state observer based data assimilation method is used to assimilate 3-D experimental data obtained in a wind tunnel experiment onto a steady RANS simulation. The experimental data is considered as the ground truth and is used to condition the RANS simulation. An understanding of the working of the method along with a study on the effect of different parameters of the state observer method are gathered by first applying it on the 1-D viscous Burgers equation and a 2-D CFD simulation. For the 3-D case, experimental data is obtained by performing a wind tunnel experiment using robotic PIV to map the time-averaged velocity field around a bluff body following which the data is assimilated onto a steady RANS simulation of the same body. Application of this method helps to recreate topological features and velocity<br/>fields of the flow with better accuracy than a baseline CFD simulation. Finally, the effects of the different parameters on the success of the method along with recommendations for improving the method are provided.","PIV; CFD; Data Assimilation; State observer","en","master thesis","","","","","","","","2021-12-31","","","","Aerospace Engineering","",""
"uuid:a01c0d2b-9f2e-4166-b1bf-05e274bf4411","http://resolver.tudelft.nl/uuid:a01c0d2b-9f2e-4166-b1bf-05e274bf4411","Design of the European Lunar Penetrator (ELUPE) Descent Module Controller","Bouma, Wouter (TU Delft Aerospace Engineering)","Fonod, R. (mentor); Guo, J. (graduation committee); Delft University of Technology (degree granting institution)","2019","To obtain unambiguous ground truth of water-ice residing in permanently shaded regions of the Moon and to characterise the local regolith, ESA considers a mission involving an instrumented penetrator implanted there by high-speed impact. Released into lunar orbit, the European Lunar Penetrator (ELUPE) Descent Module will autonomously traverse a controlled trajectory to its designated target. The associated attitude control problem involves highly nonlinear large-angle slew manoeuvres and unstable minor-axis spin manoeuvres. To establish a benchmark, a controller based on classical control techniques was designed, verified and tested in a simulation. Legacy control algorithms were implemented and extended. A thruster management function was developed to translate the control commands into thruster actions. For the simulator, accurate models of the descent module and its environment were created.<br/><br/>A Monte Carlo simulation was run to determine the success rate of the ELUPE mission from a descent-and-landing perspective, and to assess the performance of the controller under off-nominal conditions. From the results, it was found that the success rate was 58.5% for a surface slope of 20°, and 74.2% for a slope of 10° or lower. Key factors affecting the success rate were identified to be the centre-of-mass offset and the solid rocket motor thrust misalignment angle. As further constraining these parameters would be unrealistic, it was recommended to modify the thrust curve of the solid rocket motor to improve the success rate.<br/><br/>Analysis of the attack angle and the nutation angle just prior to impact, revealed their success criteria were met in 98.7% and 99.8% of all cases, respectively. These successful results confirmed the attitude control problem could be satisfactorily solved by a 'classical' controller. However, despite its good global performance, the proposed controller was found to also exhibit some serious shortcomings. For this reason, it was recommended to explore the possibilities for a different controller.<br/><br/>To the best of the author's knowledge, this thesis represented the first known attempt at designing a comprehensive controller for a fully actuated, thruster-controlled penetrator mission targeted for an airless body. In addition, it was the first known study to provide insight into the feasibility and success rate of such a mission from a descent-and-landing perspective.","Planetary Penetrators; Moon; Attitude Control; Controller Design; Classical Control; Large-Angle Slew Manoeuvres; Denutation Manoeuvres; Thruster Management Function; Descent-and-Landing; Monte Carlo Simulation","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:afd92671-b1e9-4d2e-a4eb-751840e8ddac","http://resolver.tudelft.nl/uuid:afd92671-b1e9-4d2e-a4eb-751840e8ddac","Maintenance and Repair: A Maintenance and Repair Management Performance Model for Tugs","Drenthe, Kevin (TU Delft Mechanical, Maritime and Materials Engineering)","Frouws, J.W. (mentor); van Hassel, E.B.H.J. (mentor); Both, Laurens (mentor); Miedema, S.A. (graduation committee); Hopman, J.J. (graduation committee); Delft University of Technology (degree granting institution)","2019","Maritime transport covers about 90%of world trade and is seen as one of the most cost-effective way of transporting goods. In order to safely accommodate vessels calling into ports, tugs are operated to assist various sized vessels with navigating, manoeuvring and berthing. Competition within the ship handling market has always been fierce. Boskalis Towage, through a network of joint ventures, offers harbour- and terminal towage services around the world, comprised of about 450 vessels. Operating a large fleet comes large Operating Expenses (OPEX). In order to deliver a more cost-effective service, Boskalis turns to business intelligence (BI) to help with the decision-making process. Maintenance is crucial for the operation of the vessels, but also a large part of the expenses. Large deviations in maintenance costs and operational performance exist between the joint ventures. However, the reasons behind these deviations are yet unclear due to the absence of continuous monitoring capabilities. The objective is therefore to increase the management capabilities of detailed performance monitoring of M&amp;R expenses and performance of tugs, through which possible improvements can be determined. The M&amp;R of tugs is influenced by various factors, such as utilisation, operational location and installed equipment. This research has evaluated the current Enterprise Performance Management (EPM) of Boskalis Towage and used literature on Maintenance Performance Management (MPM) in order to erect a multi-criteria hierarchical function-specific framework which is a framework for maintenance performance monitoring. The presented framework covers aspects of alignment with business objectives and plan, strategy and implementation. Moreover, the framework presents the maintenance function and its areas of performance measuring of equipment-, cost- and process performance across the organisational hierarchy. By performing a regression analysis of the maintenance data, this has also resulted in an increased understanding of the relationship between maintenance costs, operational data and vessel characteristics. As a result, an equation with acceptable statistical accuracy for running repairs has been found. The implementing of the MPM framework on the maintenance of tugs has resulted in the MPM model. This model focuses on the running repairs and dry docking direct costs and activities, incorporating basic maintenance types, i.e. Preventive Maintenance (PM) and Corrective Maintenance (CM). Running repairs have been evaluated in the time domain while the evaluation of dry dockings have been evaluated as events due to their relationship with regulatory surveys. The model incorporates operational-, maintenance- and financial data, tug specifications and operational conditions in order to evaluate maintenance performance. Maintenance Performance Indicators (MPIs) have been established to determine deviations and deficiencies among the different aspects of M&amp;R. Challenges were faced on the aspects of data quality and data management, especially in the areas of maintenance process. The model has been validated through a detailed evaluation of five selected tugs. The underlying reasons for the underperformance of these tugs have been found and verified with knowledgable bodies and thus validating the model and its ability to determine underperformance and deviations. An alternative performance analysis method, Data Envelopment Analysis (DEA), has been researched and shows promise. The Slack-Based Measure (SBM) DEA model is a non-parametric frontier approach, based on Linear Programming (LP), to evaluate performance based on slacks (room for improvement) of Decision Making Units (DMUs). The method is capable of determining similarities in inefficiency in maintenance performance, comparing it to results from the MPM model. It, therefore, proves the method is capable of quick evaluation of maintenance performance and of determining new maintenance targets. However, the model is simplistic and requires further detailing and is unable to determine underlying reasons for underperformance. The regression equation and DEA have been used to formulate a so-called performance region which describes the lower- and upper bounds of the running repair costs for individual tugs. Unfortunately, data quality doesn’t allow for the determining of these bounds for all vessels nor for dry docking. New key benchmarking targets have been established through quartile values for respective Maintenance Performance Indicators (MPIs). With this newly obtained knowledge, future maintenance performance evaluation of tugs can now be performed with a higher detail through analysis conducted with the developed MPM model.","performance management; Maintenance; Maritime; Towage; Tugs; Data Envelopment Analysis; Performance analysis","en","master thesis","","","","","","","","2024-08-29","","","","","",""
"uuid:bd3966f1-70d2-4f55-be5b-8c4e8d767a65","http://resolver.tudelft.nl/uuid:bd3966f1-70d2-4f55-be5b-8c4e8d767a65","Real-Time 3D Characterization of Antenna Systems","Musters, Ferry (TU Delft Electrical Engineering, Mathematics and Computer Science)","McCune, E.W. (mentor); Spirito, M. (mentor); Pertijs, M.A.P. (graduation committee); Delft University of Technology (degree granting institution)","2019","The recent development of commercial phased array antennas for 5G at mm-wave frequencies (20 GHz to 60 GHz) introduces new challenges for radiation pattern characterization. Since these systems aim to employ active beamforming to steer the datastream to specific users, a single base station should be capable of deploying multiple beams simultaneously and electronically steer them to track the user. This introduces the need to characterize a large set of parameters and configurations.<br/>As these modules become more cointegrated with the underlying transceiver chain, its internal modules are becoming less accessible and the device should be considered a unique black box for characterization purposes. Since the difficulty of sub-component testing increases, verifying antenna systems must be performed in an over-the-air (OTA) setup for the entire module.<br/>Current antenna characterization utilizes a single probe, which relies on mechanical rotation to move the sensor around the antenna under test (AUT). This is a proven method, but typically takes several hours, depending on the required resolution. This becomes tedious and commercially unaffordable when multiple measurements are required. Furthermore, these systems require additional instruments, e.g. a vector network analyzer (VNA), which significantly increases the cost of the setups.<br/>The concept proposed in this work avoids these drawbacks. It employs a large number of fixed sensing elements, enabling real-time radiation pattern acquisition. This has the potential to significantly reduce measurement time of 5G antenna systems. A key factor is the sampling of the signal right at the antenna probe, in contrast to the expensive VNA commonly used. This results in a lower complexity and cost, since there are significantly less high frequency components compared to other setups.<br/>A prototype of this concept has been developed for two cross-sections of a dome, which provides real-time antenna pattern tracking capabilities. The high level of flexibility allows easy adaptation to different antenna systems. The sensing probes provide direct downconversion at the antenna, eliminating the need for a VNA. Furthermore, an algorithm is made that calculates the required number of sensor nodes depending on the antenna system under test. The high speed, modularity and low cost allow this setup to be an effective option for instantaneous verification of beam-steer capable antenna systems in the development and fabrication. This can ease the predicted antenna measurement bottleneck expected for the broad employment of small-cell 5G networks. The concept can be expanded to include features such as jammer injection and instantaneous error vector magnitude (EVM) measurement.","antenna array; Characterization; millimeter wave measurement; multiple-input–multipleoutput (MIMO); over-the-air (OTA) testing; multiprobe; 5G","en","master thesis","","","","","","","","2022-05-27","","","","Electrical Engineering | Microelectronics","",""
"uuid:aedaf205-6ed9-4ff9-bebd-48660338eb75","http://resolver.tudelft.nl/uuid:aedaf205-6ed9-4ff9-bebd-48660338eb75","Assessing technological alternatives to reduce Energy Poverty in Mexico","Flores Santana, Cynthia (TU Delft Technology, Policy and Management)","Pesch, U. (mentor); Quist, J.N. (graduation committee); Delft University of Technology (degree granting institution); Universiteit Leiden (degree granting institution)","2019","More than half of Mexico’s population is living in a type of poverty, recognized as a multidimensional challenge with a geographical context. Even though Mexico’s poverty is measured in a multifaceted way, the concept of Energy Poverty has not been studied, per se, by governmental institutions. It is until recently that the study of this concept in Mexico has been undertaken by Mexican researchers, focusing on measuring it at a national and subnational level through various energy services at the household level. However, any research has been done until now to identify people’s energy needs in rural areas in the country. Thus, this study objective is to research this situation through a qualitative-exploratory research approach. Focusing on the particular case of rural areas in Mexico, where more poverty is experienced, and less research has been done. Different available and governmental supported technologies in Mexico are analyzed to address Energy Poverty. While translating people’s daily routines into specific energy needs, which could be overcome and satisfied with the evaluated technologies, to reduce or abate this situation. As the used approach comes with some disadvantages, a bunch of different methodologies has been used to carry out this research and reduced drawbacks. In the first place, Geographical Information Systems (GIS) are used to minimize researcher biases and identify the target population at the macro level. In this way, it is diminished the research approach disadvantage of generalization to a broader community. Narrative and thematic analyses are used to investigate in a more refined level people’s energy practices leading to energy necessities, reducing population under-representation by interviewing a larger sample. Finally, Energy Biographies are used to determine participants necessities according to their daily practices concerning energy use in their homes, attenuating researcher biases and increasing research usefulness as a tool for decision making. Additionally, a comparison between people’s energy necessities and different available technologies to tackle them, according to the energy services technologies can provide, are analyzed to see how technologies characteristics fulfill people’s needs. After developing the different methodologies, it can be concluded that many rural communities in Mexico are experiencing Energy Poverty, where the higher is in the Tropical region (south of the country), followed by the Temperate (center of Mexico) and the Extreme Warm one (north of Mexico). Additionally, Energy Poverty in Mexico is mostly related to the fuel that is used for cooking. Whenever technologies are assessed, it will pop up the question if a given technology life’s cycle, is enough to achieve a balance of the benefits against the impacts. Mainly concerning energy poverty, this is highly relevant; because not necessarily having the most up-to-date technology will solve the problem. Instead, having a technology that can be developed with local materials according to user’s needs will reduce the targeted problem and undesired collateral effects. The recommendation for different stakeholders, such as technologies producers, government, and researchers, is to turn around to understand people’s necessities and work towards increasing people’s well-being, instead of creating more needs in these rural communities.","Energy Poverty; Rural Areas; Available technologies; Households; Mexico; Narratives; Practices; GIS","en","master thesis","","","","","","","","","","","","Industrial Ecology","",""
"uuid:9f0da106-82ea-4f2e-9cd5-8bc834885d6f","http://resolver.tudelft.nl/uuid:9f0da106-82ea-4f2e-9cd5-8bc834885d6f","Binary Neural Networks for Object Detection","Wang, Yizhou (TU Delft Electrical Engineering, Mathematics and Computer Science)","Al-Ars, Z. (mentor); Pan, W. (graduation committee); van Genderen, A.J. (graduation committee); Zhu, B. (graduation committee); Delft University of Technology (degree granting institution)","2019","In the past few years, convolutional neural networks (CNNs) have been widely utilized and shown state-of-the-art performances on computer vision tasks. However, CNN based approaches usually require a large amount of storage, run-time memory, as well as computation power in both training and inference time, which are usually used on GPU based machines to ensure the speed for inferences. But they are usually insufficient to be deployed on low-power applications. Although many approaches were proposed to compress and accelerate the CNN models, most of them were only evaluated on relatively simple problems (e.g. image classification), which only support limited real-world applications. Especially, among those methods, binary quantization can achieve very high model compression, but only a few works have been observed to utilize it on more complex tasks. Therefore, the exploration and evaluations of applying binary quantization on more complex tasks like object detection are worthwhile, which can be used in much more applications like autonomous driving and face detection. In this project, we apply and evaluate two different binary quantization approaches, named ABC-Net and PA-Net on object detection tasks. Also, we specify the exact implementation details for the binary convolutional operations in this project. As a result, we can achieve maximally 6.1× (around 16% of the full-precision model) compression, and minimal 2.5% accuracy reduction for weight quantization. The weight quantized models were able to outperform some existing real-time detectors in terms of both accuracy and storage size. Although large accuracy reduction was observed for input quantization, the quantized model could still maintain an acceptable accuracy compared to existing real-time object detectors.","Neural Network Quantization; Deep Learning; Object Detection; Computer Vision; Artificial Intelligence","en","master thesis","","","","","","","","2020-09-01","","","","Electrical Engineering | Embedded Systems","",""
"uuid:2fff02e5-45cb-4cd1-a5c8-38f283c772ec","http://resolver.tudelft.nl/uuid:2fff02e5-45cb-4cd1-a5c8-38f283c772ec","Analysis of Remote Sensing approaches for LoRa coverage estimation","Bhat, Priyanka (TU Delft Electrical Engineering, Mathematics and Computer Science)","Zuniga, Marco (mentor); Langendoen, K.G. (graduation committee); Janssen, G.J.M. (graduation committee); Delft University of Technology (degree granting institution)","2019","LoRa is being widely adopted by industrial communities for its long range, robustness and low power wireless communication capabilities. In fact LoRa is gaining more popularity even amongst the common people as it is an affordable solution and operates in the unlicensed radio spectrum. However, LoRa provides a widely heterogeneous coverage; it can reach hundreds of meters or up to tens of kilometers, depending on the surrounding environment. Determining the coverage of LoRa stations is key to provide a good quality of service. On one hand, the traditional method of expensive measurement campaigns can be employed to estimate LoRa's coverage; but this is impractical due to the large geographical areas involved. On the other hand, popular channel models can be adopted; but many of them are yet to be explored for LoRa or rely entirely on the user predening the type of environment to estimate coverage. Neither of those approach are suitable for thousands of non-expert citizens and organizations around the world looking forward to understanding the coverage of their LoRa stations. The aim of the thesis is to automatically estimate the coverage of LoRa, before the deployment of the gateway and without relying on on-site measurements or the user's perception of the environment. Moreover, the estimation must be carried out in a simple, low cost and low eort approach. Considering that the surrounding environment determines in a fundamental manner, the coverage of wireless technologies including LoRa, we use readily available remote sensing information coming from satellites to estimate the characteristics of an area. In this manner, we free up the user from providing any type of data. Based on this remote sensing approach, the thesis provides two main contributions: First we analyze a group of parametric models (ITU-R 1812 and Okumura Hata model) and determine that the Okumura Hata model is better suited for LoRa. Second we improve the performance of using the basic Okumura Hata model by proposing an automated approach that explores remotely sensed height models and land cover maps to automatically congure channel model parameters. The performance is evaluated based on a relative comparison due to some unknown transmitter setting parameters and assess which algorithm accurately tracks the changes in the real path loss. A validation using a relative comparison approach on 18000+ samples of real LoRa data shows that the modied algorithm gives an improved performance compared to the novel approach in path loss prediction and the ITU model. The modied algorithm could improve the coverage up to a factor of 5 compared to the novel approach in free space ranges. Moreover, in an urban built-up city the modied algorithm could improve the coverage by up to 1.5 km compared to the novel approach.","Remote sensing; LoRa; Coverage","en","master thesis","","","","","","","","","","","","Electrical Engineering | Embedded Systems","",""
"uuid:259c9c49-8dd1-44e5-baa5-c0ef537828ba","http://resolver.tudelft.nl/uuid:259c9c49-8dd1-44e5-baa5-c0ef537828ba","Implementing Symbolic Controllers into FPGAs","Rueda Arjona, Antonio (TU Delft Electrical Engineering, Mathematics and Computer Science)","Mazo, M. (mentor); Mazo, M. (graduation committee); Pan, W. (graduation committee); Kok, M. (graduation committee); Delft University of Technology (degree granting institution)","2019","Embedded control systems are processor-based systems that need to run an application for an extended amount of time, such as months or years. Typically, they implement a realtime function to control a system. Embedded systems are implemented using hardware and software to perform an specific task. This is why they can be optimized to reduce its size and cost and increase its reliability and performance. In embedded control systems, a discrete time embedded system is controlling a continuous time plant. In order to deal with this complex interactions, there are some tools that synthesize symbolic controllers. However,<br/>the size of these controllers is still too large to be widely implemented in embedded systems for real-time applications. Although it is possible to implement them in CPUs with large memory, their time-step is limited by a few GHz. On the other hand, FPGAs can run at a higher frequency (MHz) but they have limited memory. In this project, we propose a tool that automate the process of compressing, determinizing and generating the necessary files to flash a symbolic controller into an FPGA. We propose three different ways of transforming the original controllers and we compare them with another similar tool from the Technische Universität München. We also simulate in real-time the controlled closed-loop of some of those symbolic controllers using a simulated plant to validate the entire process.","FPGA; Symbolic Control; BDD; LabVIEW","en","master thesis","","","","","","","","","","","","Electrical Engineering | Embedded Systems","",""
"uuid:b6637f53-4d37-4e79-a184-240bc2c4f32d","http://resolver.tudelft.nl/uuid:b6637f53-4d37-4e79-a184-240bc2c4f32d","Increasing the Performance of Passive Communication with Ambient Light","Haris Suwignyo, Haris (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Embedded and Networked Systems)","Zuniga, Marco (mentor); Langendoen, K.G. (graduation committee); Al-Ars, Z. (graduation committee); Delft University of Technology (degree granting institution)","2019","Most wireless communication technologies have been using the Radio Frequency (RF) spectrum for decades. Due to the popularity of the Internet of Things (IoT), the RF spectrum has started to become densely populated. Researchers have begun to explore other bands of the electromagnetic spectrum that can be utilized as a communication media. One of the promising choices is the visible light spectrum.<br/><br/>Visible Light Communication (VLC) refers to the wireless communication technology that utilizes the visible light spectrum. This spectrum is thousands of times wider than the Radio Frequency (RF) spectrum and is license-free. In VLC, data is transmitted by turning a light source on and off. However, not every light source can be controlled. Passive light sources such as the sun provide an immense amount of light that can be used for wireless communication if we can develop ways to modulate them. <br/><br/>One of the researches that use ambient light to create a wireless link is LuxLink. LuxLink uses liquid crystal shutters to control passive light sources and provides low energy, reliable, and flicker-free (safe) communication. This thesis addresses several problems that the current LuxLink system has.<br/><br/>We present LuxLink+, an extension of LuxLink that provides two main improvements. Firstly, the data rate of the system is relatively low (80~bps). To increase the data rate, we provide a thorough analysis of the system’s bandwidth. Afterward, we modify the modulation technique, which increases the data rate to 1000~bps at a range of 1.5~m.<br/><br/>Secondly, the system has a static data rate, which means that the system cannot adapt its data rate to changes in the environment. We implement a rate adaptation algorithm that can change its data rate accordingly. LuxLink+ improves the average throughput of the system by up to 85 percent compared to LuxLink.","visible light communication; passive communication; ambient light","en","master thesis","","","","","","","","2020-08-21","","","","Electrical Engineering | Embedded Systems","",""
"uuid:339e94c1-d2ba-4dbd-b8d0-63cb6eeedd69","http://resolver.tudelft.nl/uuid:339e94c1-d2ba-4dbd-b8d0-63cb6eeedd69","A step beyond the food waste hierarchy in FMCG companies: A case of the Kraft Heinz Company","Zamorano de Blas, Ruben (TU Delft Technology, Policy and Management)","Tavasszy, Lorant (mentor); Ludema, M.W. (mentor); Lukosch, H.K. (graduation committee); Delft University of Technology (degree granting institution)","2019","Global population is expected to keep growing in the coming decades. The United Nations claims that food production will need to increase by 70% due to the growth of population. It will be challenging to increase food production to those levels if the amount of food losses in the supply chain of Fast Moving Consumer Goods (FMCG) companies is not decreased. Supply chain losses are the destruction of food which was once produced for human consumption but never reached this purpose. Supply chain losses can happen due to multiple reasons. Incorrect planning, poor forecasting or defective inventory management can be some of the root causes. This thesis proposal aims to carry out a deep analysis of food waste management in FMCG companies. The available literature will be reviewed and compared with current situation in one of the largest food and beverage companies in the world, the Kraft Heinz Company. The knowledge gap will be addressed and series of improvements will be developed to enhance the food loss prevention process in FMCG companies.","","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:e79c9960-8083-4c84-ac75-84b77c6d912a","http://resolver.tudelft.nl/uuid:e79c9960-8083-4c84-ac75-84b77c6d912a","Study of Electrochemical Performance of Lithium and Zinc Metal Anodes for Rechargeable Batteries","Karanth, Pranav (TU Delft Electrical Engineering, Mathematics and Computer Science)","Kelder, E.M. (mentor); Wagemaker, M. (graduation committee); Picken, S.J. (graduation committee); Basak, S. (mentor); Delft University of Technology (degree granting institution)","2019","Metal anode based batteries, considered the ideal upgrade to Lithium ion batteries in terms of energy density, are currently held back by the non-homogeneous deposition phenomenon that leads to the formation of dendrites that short circuit the cell. The solution to this problem is twofold: while it is important to come up with solutions that mitigate/resist dendrite formation, it is more important to fully understand the deposition phenomena in metal anodes through experiments and theoretical analyses. This study aimed to first understand the deposition mechanism in Zinc and Lithium metal anodes, and then study the feasibility of polymer coatings based on Sulfonated Poly Ether Ether Ketone (SPEEK) as a solution to mitigating the dendrites.<br/>The electrochemical performance of Zinc in ZnSO4 electrolyte systems was studied<br/>for a wide range of current densities and for different operating conditions with the help of operando microscopy and ex-situ SEM. Further, the mechanism of initial Zinc deposition was visualized with the help of in-situ TEM. The origins of the different types of morphology observed at these conditions were explained on the basis of competition between the mass transfer and the kinetics for control over the overall process. Further, a proof of concept was established for the use of SPEEK based coatings on Zinc metal, and the electrochemical performance of polymer coated Zinc electrodes was analyzed.<br/>In the case of Lithium, the deposition in carbonate based electrolytes was first studied with the help of operando microscopy for Bare Lithium. Operando microscopy was also carried out to study the influence of the SEI, the separator and a standard polymer coating (PVDF) on Lithium deposition. Further, Lithiated SPEEK was used as a polymer coating on Lithium, and itwas observed that a more even Lithium deposition takes place with the Li-SPEEK coating on Lithium. Slight improvements were observed in the Li+ conductivity of the coating with the addition of TiO2 nanofiller to the polymer. However, performance issues were observed with long term cycling, possibly due to the instability of the polymer coating in carbonate electrolytes over long periods.<br","Lithium metal anode; Zinc metal anode; Dendrite; SPEEK; Operando Microscopy","en","master thesis","","","","","","","","2021-12-31","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:6692a21b-6826-404b-877f-b2d4a29a8464","http://resolver.tudelft.nl/uuid:6692a21b-6826-404b-877f-b2d4a29a8464","A semi-analytical approach to simulate strains in load sensing bearings using FEA","Ravesloot, Jens (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Cognitive Robotics)","Shyrokau, B. (mentor); Wisse, M. (graduation committee); Hernández, Carlos (graduation committee); Delft University of Technology (degree granting institution)","2019","The advancements in driver assistance systems in cars and the development of autonomous vehicles require more states of the car to be known than the conventional sensors can accurately determine. Load sensing bearings (LSBs) are under development that measure the wheel forces under dynamic load. Through sensor fusion, the addition of this sensor can increase the robustness and accuracy of the state estimators used in cars. An algorithm uses the strain measured on the surface of an instrumented LSB to calculate the forces on the bearing. The development of LSBs requires a tool that simulates the strain signals in a fast and accurate manner to gain insight into the bearing behavior.<br/> Due to the complex nonlinear behavior of the bearing, there is not a fast, straightforward tool available that estimates its strains. This thesis presents a methodology that uses finite element analyses (FEA) to construct a model that calculates the strain in the outer ring of a wheel bearing for any given load. The FEA consists of a linear elastic model of the outer ring and a single loaded ball that is modeled by a Hertzian contact. Multiple simulations are done for different positions of the ball, such that a rotating bearing can be approximated. A nonlinear analytical bearing model in conjunction with a, from FEA constructed, outer ring flexibility model calculates the load on each bearing ball. A strain model, also built from the FEA, uses these loads to calculate the strain on the outer ring.<br/> The simulated strains are validated with experiments performed on a bearing test rig of SKF. Measurements from a with strain gauges instrumented bearing show that the model predicts the observed behavior in the signals. Analyses of the simulated and measured signals in the frequency domain show a difference in gain and offset, which can be calibrated. Unexpected discrepancies are observed within the measured signals of symmetrically placed sensors on the LSB, which should give identical signals, that are likely caused by a distortion of the shape of the outer ring introduced by the manufacturing process or installation of the bearing.<br/> The scope for future work should focus on further validation of the model and developing a calibration method to increase the accuracy. It is believed that the uncertainties in the model can be summarized into a small set of parameters that can be calibrated for a specific instrumented LSB with only a few measurements. Once accurate strains can be simulated, the model could be utilized in a state observer to convert actual strain measurements into loads, and it is possible to use it to optimize the design of the LSB and the location of the strain gauges.","Load sensing bearing; strain; Finite Element Analysis; semi-analytical model","en","master thesis","","","","","","","","2022-01-01","","","","","",""
"uuid:f639e5ad-5e09-4556-bf27-f00e4736115c","http://resolver.tudelft.nl/uuid:f639e5ad-5e09-4556-bf27-f00e4736115c","CPT-based method to determine the lateral capacity of monotonically loaded rigid piles in sand","Bascunan Chaparro, Sebastian (TU Delft Civil Engineering and Geosciences; TU Delft Geo-engineering)","Gavin, Kenneth (mentor); Reinders, K.J. (graduation committee); Pisano, F. (graduation committee); Kaltekis, Kostas (graduation committee); van Dijk, Bas (graduation committee); Delft University of Technology (degree granting institution)","2019","Monopiles are commonly used as foundations for offshore wind turbine generators (WTGs). Due to the rapid growth of the offshore wind energy sector, there is increasing demand for WTGs of larger capacities which evidently leads to demand for monopiles with larger diameter. An industry standard approach for assessing pile lateral response is the p-y method; however, this method was initially developed and empirically validated for long slender piles and thus its applicability to large diameter monopiles is doubtful. <br/> <br/>The joint academia-industry project, Pile Soil Analysis (PISA) project resulted in an improved understanding of the lateral loading response of large diameter monopiles. Based on pile load test (PLT) data and numerical modelling, a method was developed to derive all soil reaction components from advanced finite element method (FEM) calculations to be used in a one-dimensional (1D) design framework.<br/><br/>Cone penetration test (CPT) based approaches have been shown to provide excellent predictions for the response of laterally loaded flexible piles where the p-y response dominates. In this thesis an approach to determine the additional components of the soil reaction curves for rigid monopiles, namely the side and base shear and base moment directly from the CPT is proposed. The results are compared to soil reaction curves are extracted from 3D FEM models, and compared to field tests on monopiles in sand<br","CPT-based correlations; large diameter monopiles; Sand; p-y curves; lateral loading; PISA project","en","master thesis","","","","","","","","","","","","Geo-Engineering","",""
"uuid:89ae611d-cf7b-4911-adee-58cbdfccff94","http://resolver.tudelft.nl/uuid:89ae611d-cf7b-4911-adee-58cbdfccff94","A Particle-based Approach for Stochastic Modelling of Waves in the Near-shore Region","Ashirgade, Shriram (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Mathematical Physics; TU Delft Delft Institute of Applied Mathematics)","Verlaan, M. (mentor); Reniers, A.J.H.M. (graduation committee); Heemink, A.W. (graduation committee); van der Lugt, Marlies (graduation committee); Groeneweg, Jacco (graduation committee); Delft University of Technology (degree granting institution)","2019","Processes occurring in the near-shore region operates on a small spatial and temporal scale. Simulations of these processes have long posed challenges for computational science, and to have accurate representations require a higher resolution. This results in computationally expensive models. This project aimed to investigate the possibility of a new stochastic model, simulate these processes with higher computational efficiency, and estimate the energy density and spectral properties of waves in the near-shore region. The gist of the particle model is to discretize the energy flux into several packets of finite energy, propagating in the domain, and governed by the equations derived from the wave dynamics. These particles correspond to a particular wave component at a particular location and, therefore, are defined by these wave properties. The equations of particle motion are derived from the wave dynamics by treating energy density as probability density and the energy balance equation as a Fokker-Planck equation while the energy dissipation is modelled with exponential decay of particle energy with a location-dependent rate. An iterative approach is taken to accommodate the dissipation processes resulting from the wave interactions. These particles were treated as independent to create prospects of asynchronous computation and providing the scope of computational optimization. The phenomena of shoaling, refraction, bottom friction, and depth-induced surf breaking are included in the implementation for both monochromatic waves and irregular waves described by a two-dimensional wave spectrum. The model is tested for its performance and accuracy by comparing with the estimations from other existing models. The ability to provide control over processes in computations made SWAN a perfect candidate as a benchmark. The results showed a high degree of accuracy on comparison while the computational time was of the same order or lower to that of the SWAN model for most of the cases with a great scope of improvement. It was also observed that high computational efficiency could be achieved by sacrificing little accuracy. Additional dominant processes were identified affecting the accuracy in certain conditions by comparing the model with lab measurement data. Non-linear wave-wave interactions play an important role in the evolution of the spectrum, while diffraction becomes dominant for the flow over a shoal in two-dimension. These processes are considered as future scope of the project. The results show that with a stochastic model, it is possible to simulate real-life situations and does need further development to include additional processes and make the model computationally robust.","Wave modeling; Stochastic Simulation; Near-shore; Particles","en","master thesis","","","","","","","","2020-03-01","","","","Applied Mathematics","",""
"uuid:ee54fcce-458c-4537-9ea5-20645662f269","http://resolver.tudelft.nl/uuid:ee54fcce-458c-4537-9ea5-20645662f269","Alternative Cable Laying: A conceptual design for an offshore power cable lay system on non-cable lay vessels","Gijsberts, Bart (TU Delft Mechanical, Maritime and Materials Engineering)","Hendrikse, H. (mentor); Metrikine, A. (graduation committee); van Baalen, Lennart (graduation committee); Delft University of Technology (degree granting institution)","2019","In this thesis, an alternative cable lay system was designed that can be used on existing non-cable lay vessels. This design is conceptualized and analyzed for a specific market, following the steps in the engineering design process. The technical and economic analysis investigates the feasibility and competitiveness of the new cable lay system.<br/><br/>Nowadays, cables are installed over a chute at the aft of a vessel, which makes the operation very sensitive to motions, inducing high cable loads that result in limited workability. Also, load carrying capacity is limited for existing cable lay vessels within the Boskalis fleet, making the application of joints a necessity in offshore export power cable installation.<br/><br/>The design focuses on the international offshore export power cable installation market (both AC and DC), including interconnectors, from shore to substation or shore to shore. This market was selected because of the limited load-carrying capacity of current cable lay vessels, the internationally growing offshore wind market and the relatively low market share of Boskalis in this segment. New concepts were generated and evaluated using multi-criteria analysis, scoring them on technical and economic criteria determined for the selected market.<br/><br/>The concept that has been selected for further development focuses on export power cable laying through a moonpool. A Dockwise semi-submersible heavy transport vessel is targeted for this design because it is being converted into a fall pipe vessel already. This conversion includes the installation of a moonpool, opening up the possibility to make the selected vessel a multi-purpose ship. Making use of static stability software, the maximum load-carrying capacity of this vessel has been determined. From this analysis, it can be concluded that the maximum cable load that can be carried by the selected vessel is 9.000 tonnes of cable equivalent, which is approximately 110 km of currently installed export cable length. Conventional cable lay vessels from Boskalis have load carrying capacity up to 5.000 tonnes. Additionally, a deck-layout with the crucial parts of the cable lay system is designed, taking into account all necessary alterations regarding the conversion of the vessel.<br/><br/>The main technical challenge for the newly designed system is the second end cable pull-in. With limited space in the moonpool and vertical laying of the cable, the conventional pull-in method cannot be used here. Three solutions have been developed, based on a deployment quadrant or bight lay down. Two of these are already proven in the field, making the concept technically feasible.<br/><br/>A model has been made to evaluate both conventional cable lay, and cable lay through a moonpool. With the use of dynamic time-domain analysis, the operational limits have been determined for both methods, keeping the catenary shape of the cable constant. This analysis concludes that cable laying through a moonpool indeed increases the workability for the selected vessel. No significant increase can be seen for moonpool cable laying with a conventional cable lay vessel. This is due to its sensitivity to roll motions, for which the distance towards the center of gravity is equal in both concepts. For the selected vessel, cable laying over a chute is not possible for the chosen catenary shape and sea states because the maximum allowable curvature is exceeded. This is due to the large arm for pitch motions, from the center of gravity to the chute at the aft of the vessel. Cable laying through a moonpool, however, is possible up to 2 meters significant wave height. The limiting factor for all simulations that were done is the maximum allowable curvature.<br/><br/>To investigate the competitiveness of the newly designed cable lay concept, an economic analysis is done. Several recently acquired project cases are introduced to compare project costs for both concepts. This analysis concludes that the newly designed cable lay concept is in average conditions 21 to 40% more expensive for all cases than the conventional way of cable laying. For cable installation during wintertime, the newly designed cable lay system is only 6.5 to 27% more expensive than the conventional cable lay system. <br/><br/>This illustrates that the newly designed cable lay system is technically feasible but not competitive with conventional methods at the moment according to this analysis. However, the costs and installation time of joints with the conventional methods are not taken into account here due to limited available data. Therefore, the new cable lay concept still has the potential to be competitive for the selected market. Further research must be done to substantiate this.<br","Cable installation; Offshore Wind; Export power cable; Conceptual design; Moonpool","en","master thesis","","","","","","","","2024-08-29","","","","Offshore and Dredging Engineering","",""
"uuid:982fb060-cf55-4bf3-a6c9-74fb78b3955b","http://resolver.tudelft.nl/uuid:982fb060-cf55-4bf3-a6c9-74fb78b3955b","Work-ability increase: Using tugger control","Sanders, Nick (TU Delft Mechanical, Maritime and Materials Engineering)","Metrikine, A. (mentor); Hendrikse, H. (graduation committee); Delft University of Technology (degree granting institution)","2019","For the offshore market an increase in renewable projects can be observed. The technological innovations are continuously decreasing the costs of renewable projects. Especially offshore wind is getting more cost effective, and is receiving a lot of attention. However, with the growth of the sector, new challenges arise. Water depths are increasing, soil parameters worsening and greater distances from shore need to be overcome. Whereas prices of installation are under pressure. This drives the market towards larger and more innovative installation vessels. A trend can be observed towards monohull craning vessels which combine a large crane with a large storage space on deck. During lifting the monohull vessel experiences large motions of the lifting configuration at even small wave loading. The large motions are mainly the result of resonance within the system, which results in large crane forces. It is these forces which decreases the vessels work-ability. Applying damping to the system is a way to counter the resonance. The tugger winches can be used to apply damping to the lifting configuration. The aim of the thesis is to investigate the potential damping effect of a tugger damping system for the Bokalift 1 during a jacket lifting operation. With special emphasis on the effect of different control systems of the tugger winches. Two different models are used in the thesis to research the effects of tugger damping on the dynamic behavior of the lifting configuration. Namely, a 2D matlab model, and a more extensive 3D Orcaflex model. The Orcaflex model is build for researching the effects of tugger damping and different control systems. Comparing the responses of the model to airy waves loading. To have control in both longitudinal and transverse direction boom winches on the crane are used, in combination with deck winches. Which are located on both ends of the deck. The hydro static properties of the model are calculated with the program GHs. The hydro dynamic properties are calculated with the help of AQWA. The matlab model is used to enable quick research on the effects of tugger damping and different control systems. The model is based on a 5 degree of freedom (DOF) mass-spring-damper-system. The equations of motion (EOM) are derived using the lagrange formalism with help of the program Maplesoft. The model is validated with help of proven software Orcaflex. Seven different control systems are made and tested in the matlab model. The control systems are examined in two different simulations. Firstly the roll motion is studied when the model is subjected to wave loading. Secondly the damping capabilities for the lifting configuration with initial displacement are tested. The first analysis shows the PID controller has the highest roll motion reduction of the jacket. Linear control system scores higher than quadratic. The results from the second analysis shows that stepwise controller takes the shortest to fully damp the lifting configuration. Following on the results of the 2D model analysis the 3D model will further inspect the effect of tugger winches for the linear, quadratic, and PID controller. A model analysis shows there are 4 important modes within the wave excitation range. The combination of these modes results in the highest crane forces at a wave period of 5.5s. The linear and quadratic control system are once again compared, only now in the 3d model. The assessment shows the linear model as more efficient in reducing the crane tip forces. Lastly the linear and PID control systems are compared towards each other and a model without tugger damping. Based on the results, the linear control system increases the total forces on the crane. Where as the PID reduces all forces. It is shown that tugger damping does not necessarily decrease forces acting on the crane tip for head on waves. From the tested control system the PID controller reduces the forces most effectively and efficiently. However the effect of the PID controller depends on the loading wave frequency and for which it is tuned.","tugger; damping; heavy lifting","en","master thesis","","","","","","","","2022-08-29","","","","Offshore and Dredging Engineering","",""
"uuid:b302eb35-67b2-445d-af8c-c2f339c08257","http://resolver.tudelft.nl/uuid:b302eb35-67b2-445d-af8c-c2f339c08257","Exploring Team-formations And The Evolution Of Network-formations Of High-Tech Academic Spin-offs","Gupta, Rahul (TU Delft Technology, Policy and Management)","Khodaei, Hanieh (mentor); Scholten, Victor (graduation committee); van Beers, Cees (graduation committee); Delft University of Technology (degree granting institution)","2019","As our modern society keeps changing, the role of universities as a source of creating opportunities for academic entrepreneurs to transform their scientific knowledge into a viable business is becoming significantly important. Even though academic institutions and universities have played a big role in the transfer of knowledge into commercialized solutions ever since they were established (Shane, 2004), in the past, more often than not, such inventions have taken place in non-commercial environments. But the commercialization of specific scientific or technical knowledge through novel high-tech academic spin-offs entails unprecedented entrepreneurial challenges (Vohora et. al., 2004). Thus this paper contributes towards the scholars’ and academic entrepreneurs’ understanding of how teams within high-tech academic spin-offs are able to identify, acquire and assimilate novel and needed external knowledge and resources, and how they transform and exploit those resources to fuel the company’s growth. In other words, due to the uniqueness and novelty of the High-tech academic spin-offs they are relatively underexplored (Lazer and Katz, 2004, Khodaei, 2015) and indicating that studying team effects on networks and growth is a very new area. So this paper makes an attempt to explore the how teams and networks in high-tech academic spin-offs evolve the company grows and how each of these parameters affect each other. As has been observed through our multiple case studies accessing necessary and critical resources is a big challenge faced by these specific firms during their initial development/growth stages (Sullivan and Ford, 2004).<br/><br/>By employing Resource-Based theory, Human Capital and Social Capital theory, we investigate how entrepreneurial teams use networks in order to meet varying resource needs in order to grow. Results illustrate how evolution of team formation transform their corresponding network formation that could lead to the accessibility of new, necessary and relevant resources in ways that could impact the growth of these high-tech academic spin-offs. Consequentially, our findings show how founding members and other team members use their network connections to serve as one of their principal means of identifying, acquiring and assimilating these resources in order to grow. However, we have found that different growth stages of the spin-offs indicated different resource dependencies, so we observed how teams and networks change so as to meet the changing resource requirements. This led us to the interesting conclusion that this is a circular process in a loop. Along with that we have also found how companies operating in different geographic locations or dealing with significantly different product lines have tightly packed heterogeneous network channels with homogeneous network partners within each channel leading us to the fact that they are market leaders in niche markets, whereas, for companies operating in the same geographic locations and/or dealing with similar product lines have interconnected links with/between multiple network partners from different network channels, leading us to the fact that these companies operate in highly competitive markets with complimentary services to each other and due to the abundance in availability of partners.","Academic Spin-offs; Team-formation; Network-formation; Entrepreneurial Networksa; Entrepreneurial Teams; Evoltuion of teams; Evolution of networks","en","master thesis","","","","","","","","","","","","","",""
"uuid:7a7fad85-d29d-414e-a254-7b864c4e5042","http://resolver.tudelft.nl/uuid:7a7fad85-d29d-414e-a254-7b864c4e5042","Likelihood-based Inference on Nonlinear spaces: Using Diffusion Processes on Riemannian Manifolds","Corstanje, Marc (TU Delft Electrical Engineering, Mathematics and Computer Science)","van der Meulen, Frank (mentor); Delft University of Technology (degree granting institution)","2019","When data in higher dimensions with a certain constraint on it, say a set of locations on a sphere, is encountered, some classical statistical analysis methods fail, as the data no longer assumes its values in a linear space. In this thesis we consider such datasets and aim to do likelihood-based inference on the center of the data. To model the nonlinearity, we consider the data to be a set of points on a Riemannian manifold. The general approach in this thesis comes from the classical result where the center can be repre- sented as the maximum likelihood estimator for the true mean of the dataset. To model an underlying distribution we will model the data as observations of realizations of Brownian motion on the manifold observed at a fixed time and use the transition density of the Brownian motion to construct a likelihood. The likelihood can then be approximated using diffusion bridges. This thesis thus first focuses on differential geometry as well as Itô and Stratonovich calculus. After that, we will introduce methods to construct a likelihood for the center of the dataset on a manifold before using simulated diffusion bridges to approximate this likelihood. We finish the thesis with some numerical experiments in Julia that demonstrate the results on the sphere.","Diffusion Process; Riemannian manifold; Diffusion Bridge; Stochastic Differential Equations; Stochastic Simulation; Geometric Statistics","en","master thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:8912bf9f-b2d6-47f7-8336-831c5a6caf68","http://resolver.tudelft.nl/uuid:8912bf9f-b2d6-47f7-8336-831c5a6caf68","Blind OFDM Signal Parameter Estimation","van der Mark, Kevin (TU Delft Electrical Engineering, Mathematics and Computer Science)","Voogt, V (mentor); Janssen, Gerard (graduation committee); Mc Cune Jr, Earl (graduation committee); Delft University of Technology (degree granting institution)","2019","OFDM is a common modulation technique applied in the video downlink of drones. In order to eavesdrop on this link, the OFDM signal needs to be demodulated. OFDM demodulators separate orthogonal subcarriers to obtain single carrier signals. This process requires a lot of prior information on the signal parameters. <br/><br/>This thesis presents two techniques in obtaining these parameters blindly. The first approach is based on non-filtered channels, exploiting inherent OFDM signal properties. Although not realistic for practical applications it gives insight in the OFDM techniques. The second approach is based on the autocorrelation function, exploiting the correlation between the Cyclic Prefix and the end of an OFDM symbol. This techniques proves more robust to filtering and noise effects, but does introduce a noticeable error margin even present in the low noise simulations.","OFDM; Parameter; Estimation","en","master thesis","","","","","","","","","","","","","",""
"uuid:d8a3326e-43d1-4797-8799-4b4456b76b18","http://resolver.tudelft.nl/uuid:d8a3326e-43d1-4797-8799-4b4456b76b18","On the effect of laser altimeter crossover observables on orbit determination with the JUICE mission as case study","Villamil, Sebastian (TU Delft Aerospace Engineering)","Dirkx, Dominic (mentor); Vermeersen, Bert (graduation committee); Cervone, Angelo (graduation committee); Delft University of Technology (degree granting institution)","2019","This thesis' work aims to evaluate the potential added benefit to spacecraft orbit determination procedures upon using non-conventional measurements for orbit reconstruction. As a spacecraft orbits a celestial body, its ground tracks will naturally cross previous ground tracks at many points. These locations, known as crossover points, yield valuable information about the orbited body and the spacecraft trajectory using the spacecraft altitude measured during both passages at each crossover location. To evaluate the impact of altimetry crossover measurements on orbit determination, the mission scenario of the planetary mission Jupiter Icy moons Explorer (JUICE) by the European Space Agency (ESA) is used as case study. As the mission's measurements will only be available several years from now, the resulting analysis is done with synthetic measurements obtained through numerical simulations. Herein, the necessary mathematical expressions for the inclusion of crossover measurements into orbit determination algorithms are presented, verified and evaluated. In doing so, it is shown that a first-order approximation of these expressions, as used in previous efforts, is insufficient and a more detailed expression is developed. Furthermore, the used crossover determination algorithm is presented in detail as well as the crossover selection filters in accordance to mission requirements. Finally, the sensitivities and intricacies of crossover measurements are discussed and their added value to orbit determination schemes is shown.","orbit determination; crossovers; JUICE","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:1bb48563-6ef0-4571-aea3-9a0bed34a161","http://resolver.tudelft.nl/uuid:1bb48563-6ef0-4571-aea3-9a0bed34a161","Evaluating an ASR Pipeline for a Social Robot","Sparreboom, Jamey (TU Delft Electrical Engineering, Mathematics and Computer Science)","Scharenborg, Odette (mentor); Hindriks, Koen (graduation committee); Oertel genannt Bierbach, Catharine (graduation committee); Delft University of Technology (degree granting institution)","2019","There has been a big increase in the use of social robots, such as Pepper, which use verbal communication as the main method of interacting with a human. Verbal communication with a robot is performed using Automatic Speech Recognition (ASR) to recognize words from an audio stream containing speech.<br/>These social robots are being more frequently used in noisy environments. <br/>As such, this thesis investigates 1) whether Pepper's built-in keyword spotter can be replaced by an ASR system able to recognize continuous speech in Dutch; 2) whether Pepper's ASR pipeline can be made more robust against noise, without changing its hardware.<br/>To that end, Pepper's built-in keyword spotter and Sound Source Localization (SSL) algorithm are evaluated against an ASR pipeline based on a Delay-and-Sum beamformer, MUSIC Sound Source Localization, and Google Cloud Speech-to-Text.<br/><br/>The proposed pipeline showed a significant decrease in Keyword Error Rate of 6.2\% compared to Pepper's built-in keyword spotter, and a significant decrease of Word Error Rate (WER) of 21.4\% on Dutch continuous speech in clean listening conditions. A decrease in WER of 13.3\% was observed in an SNR of 8 dB, and a decrease in WER persisted throughout lower Signal-to-Noise ratios (SNR).<br/><br/>As such, it has been shown that Pepper's speech recognition can be improved and made more robust against noise by preprocessing the audio using MUSIC SSL and a Delay-and-Sum beamformer, and transcribing the speech (in Dutch) using Google Cloud Speech-to-Text.","ASR; Social Robotics; Beamforming","en","master thesis","","","","","","","","","","","","","",""
"uuid:f41f5255-b58e-46b0-9826-c4c45dd5f3f3","http://resolver.tudelft.nl/uuid:f41f5255-b58e-46b0-9826-c4c45dd5f3f3","Time Domain Modeling of Photoconductive Antennas","Degasperi, Andrea (TU Delft Electrical Engineering, Mathematics and Computer Science)","Neto, Andrea (mentor); Llombart Juan, Nuria (graduation committee); Isabella, Olindo (graduation committee); Delft University of Technology (degree granting institution)","2019","Photoconductive antennas (PCAs) have been extensively utilized for the generation of broadband pulses over very large bandwidths. PCAs rely on a semiconductor (e.g. LT- GaAs) gap pumped by a laser and coupled to a passive structure biased at a certain voltage level. When the laser impinges on the semiconductor gap with an appropriate carrier frequency, enough energy is provided such that free electron-hole pairs are generated from the electrons that move from the valence band to the conduction band. As a result, the resistivity of the material decreases to a few ohms which in turns allows a time-varying current to flow across the gap. In recent year different hybrid equivalent circuits [1], [2], [3] have been developed in order to take into account all these complex phenomena although none of these models account for the frequency dependence of the impedance of the antenna, being formulated in the time domain. This approximation works for non-dispersive antennas such as the bow-tie, but fails in the characterization of more diverse and complex structures. The Norton equivalent circuit’s aim proposed in [4] was to fill the aforementioned gap by introducing an analytical model completely in frequency domain, although the difficulty in the characterization of the generator impedance obstructed the way for a wide acceptance in the community. In this thesis a novel approach based on a commercially available electromagnetic simulator [5] to characterise the biasing of the passive structure, the optical laser excitation and the impulse response of the photoconductor is proposed. The accuracy of the model is verified by calculating the average power radiated by a bow-tie and the results are compared to the measurements in [6]. Moreover, a revised version of the Norton equivalent circuit [4] which describes more accurately the effective generator impedance is presented. While the computer-aided model offers great introspection in the characterisation of voltages and currents and thus in the maximisation of the power radiated, the revised Norton equivalent circuit offers an even better accuracy and reduces significantly the computational time.","THz photoconductive antenna; CST; Equivalent circuit; THz radiated power; THz source; THz technology; Connected Arrays","en","master thesis","","","","","","","","","","","","Electrical Engineering","",""
"uuid:d5836f9d-820a-428e-9ed7-cc8e7c3cbcbb","http://resolver.tudelft.nl/uuid:d5836f9d-820a-428e-9ed7-cc8e7c3cbcbb","Quantum network routing via link prediction","Száva, Antal (TU Delft Electrical Engineering, Mathematics and Computer Science)","Wehner, Stephanie (mentor); Epema, Dick (graduation committee); Elkouss Coronas, David (graduation committee); Chakraborty, Kaushik (graduation committee); Delft University of Technology (degree granting institution)","2019","A network of devices capable of transmitting quantum information called a quantum network has promising applications with vast benefits. One of the most near term achievable application is the quantum key distribution. It could be used for sharing a secret key between two end-users through any insecure authenticated communication channel. Other than sharing a secret key, a quantum network can be used for connecting quantum computers. Quantum computers have the potential to solve computational problems that their classical counterparts would require significantly more time to do so. By connecting such devices, distributed computation problems such as leader election or distributed consensus between nodes can be solved securely.<br/><br/>For such applications to be put into practice on a large scale, there are open practical questions still to be answered. In a quantum network, a data qubit containing quantum information is transmitted by an operation called quantum teleportation. For it, two nodes need to share entanglement. Quantum teleportation then ensures the safe transmission of a qubit by using the shared entanglement and the exchange of two classical bits. This operation, however, consumes entanglement between the nodes, changing the network topology with each served request.<br/><br/>In quantum networks, certain nodes share entanglement between each other. Routing in quantum networks entails determining which of these shared entanglements are used to transmit quantum information. As this proves to be a difficult task, we study quantum networks and in particular consider the problem of routing entanglement in quantum networks. <br/><br/>The average latency for routing entanglement in a quantum network has been studied so far using a distributed routing approach. Thus, we present numerical simulation results of centralised routing for the average latency of demands in two existing entanglement generation models. In the first, shared entanglement between nodes is created on-demand. In the second, certain nodes pre-share entanglement before the demand comes. Our results show the intuition that using a centralised routing approach in the on-demand model results in drastically more average latency than in the model with pre-shared entanglement.<br/><br/>Since some nodes might not be informed about the change in topology, we study the effect of the propagation of information about the network topology to nodes in the network. Our observations based on simulation results show that the average latency is significantly higher if the information about the topology is not propagated well in the network. As propagating information to all nodes in a network would be a significant load for the network, we consider information propagation within a radius and still observe a considerable decrease in average latency.<br/><br/>At last, we present a technique called link prediction which can be performed by any node without the need for information propagation and still achieve a considerable decrease in average latency. It can be effectively used to predict the change of topology in a quantum network by using knowledge about the network topology for a certain future point in time and previous knowledge about the network traffic.","quantum network routing; link prediction; temporal networks; information propagation","en","master thesis","","","","","","","","","","","","","",""
"uuid:250d37a9-bc0d-4f8f-8d1a-d31a98dc22d7","http://resolver.tudelft.nl/uuid:250d37a9-bc0d-4f8f-8d1a-d31a98dc22d7","Attention-Aware Age-Agnostic Visual Place Recognition","Li, Jiahui (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Gemert, Jan (mentor); Khademi, Seyran (mentor); Wang, Ziqi (mentor); Reinders, Marcel (graduation committee); Nan, Liangliang (graduation committee); Delft University of Technology (degree granting institution)","2019","A cross-domain visual place recognition (VPR) task is proposed in this work, i.e., matching images of the same architectures depicted in different domains. VPR is commonly treated as an image retrieval task, where a query image from an unknown location is matched with relevant instances from geo-tagged gallery database. Different from conventional VPR settings where the query images and gallery images come from the same domain, we propose a more common but challenging setup where the query images are collected under a new unseen condition. The two domains involved in this work are contemporary street view images of Amsterdam from the Mapillary dataset (source domain) and historical images of the same city from Beeldbank dataset (target domain). We tailored an age-invariant feature learning CNN that can focus on domain invariant objects and learn to match images based on a weakly supervised ranking loss. We propose an attention aggregation module that is robust to domain discrepancy between the train and the test data. Further, a multi-kernel maximum mean discrepancy (MK-MMD) domain adaptation loss is adopted to improve the cross-domain ranking performance. Both attention and adaptation modules are unsupervised while the ranking loss uses weak supervision. Visual inspection shows that the attention module focuses on built forms while the dramatically changing environment are less weighed. Our proposed CNN achieves state of the art results (99% accuracy) on the single-domain VPR task and 20\% accuracy at its best on the cross-domain VPR task, revealing the difficulty of age-invariant VPR.","Computer Vision; Domain Adaptation; Image Matching; Attention Mechanism","en","master thesis","","","","","","","","","","","","","",""
"uuid:e774df3c-80ac-4068-b4d1-c8f098ac86db","http://resolver.tudelft.nl/uuid:e774df3c-80ac-4068-b4d1-c8f098ac86db","Appraisal of Friction Coefficients Between TBM and Conditioned Soil: A Laboratory Investigation Adopting a Direct Shear Apparatus","Ambrosi, Matteo (TU Delft Civil Engineering and Geosciences)","Glab, Kathrin (mentor); Broere, Wout (graduation committee); Reinders, Kristina (graduation committee); Ngan-Tillard, Dominique (graduation committee); Delft University of Technology (degree granting institution)","2019","During the advance of a tunnel boring machine (TBM), the torque applied to rotate the cutterhead must overcome the resisting moments acting on it. Hence, one of the major concerns of TBM design is to determine the torque and power requirements of the excavation machine. The first empirical approach for torque estimation was developed in the 80’s by JSCE. This estimation fits the recorded mean torque for 5-8m diameter projects, but overestimates torque as TBM diameter increases. Newer approaches estimate TBM torque and thrust requirements as sum of multiple components, focusing on the friction between ground and cutterhead. However, the recommended or selected friction coefficients range between a wide interval (typically 0.05-0.75), depending on soil and operational conditions. Consequently, the torque and thrust estimations relying on the above-mentioned friction coefficients can be considerably imprecise, as well. Previous research regarding soil-machine/steel friction coefficients has been collected and studied. Successively, interface shear tests have been performed at TU Delft, to study whether and how friction coefficients could be determined consistently in the laboratory. Three soil types have been examined, ranging from coarse sand to kaolin clay. A metal plate cut out from a worn TBM cutterhead has been added to a direct shear apparatus to test the abovementioned soils. The latter are either water saturated or treaded with bentonite or foam, to assess the influence of conditioners on soil interface friction. Bentonite slurries and foam suspensions have been prepared in the laboratory using common industry products. Overall, in excess of 60 interface shear tests have been performed, considering various permutations of soil, load and conditioning. Results show that lubricated friction coefficients (i.e. when soil samples are conditioned) are up to 25% and 50% lower than for water-saturated conditions, for sand and clay respectively. A direct shear apparatus proves to be useful to study and select friction coefficients for TBM preliminary design, as it provides satisfactory results for non-conditioned and bentonite-conditioned soils. The same apparatus, however, cannot fully capture the lubricating effect of foam on sand. Improved estimation of friction coefficients requires more advanced equipment, or substantial modifications to the direct shear apparatus.","TBM; Friction; Foam; Slurry; Bentonite; Clay; Sand; Tunneling; Conditioned soil; Wear; Excavation","en","master thesis","","","","","","","","","","","","","",""
"uuid:99146e53-0cef-4e14-9ad6-b1a3d9e098a4","http://resolver.tudelft.nl/uuid:99146e53-0cef-4e14-9ad6-b1a3d9e098a4","Design of a framework to co-create applications in a hangar environment","Todorović, Tea (TU Delft Industrial Design Engineering; TU Delft Product Innovatie Management)","Price, Rebecca (mentor); Dehli, Silje (graduation committee); Delft University of Technology (degree granting institution)","2019","New, innovative technologies are important. More and more companies are using digital technologies to their benefit. The act of leveraging such digital technologies to enable organisational improvements in a strategic way is called a digital transformation. In such transformations, the customer experience, operational processes and business models need to be reconfigured in order to get ahead of the forces for change in the digital age. If a company only focuses on technology, the transformation might fail, as also the daily work of people will change due to the digital transformation. Therefore, also human-centric challenges need to be tackled in a digital transformation strategy. <br/><br/>In order to create value with new digital technologies in a transformation program, it is important to understand needs of the people affected by the new digital technologies. The extent to which needs are met determines what value is attached to the digital artefact. Therefore, many strategies exist for uncovering user needs and involving users in the sense-making of the research topics for new product development. However, no strategies exist that tell how to combine such co-creation with software development to better meet user needs with features of digital artefacts.<br/><br/>This provides new opportunities for the development of a co-creation framework for software development. This thesis explores how to incorporate co-creation in agile software development. This is done for the department of a European-based airline. By involving their users in the creation of digital artefacts, the company will better know what users want and increase the value created with the artefacts of the digital transformation program. <br/><br/>Currently, this airline uses the Scrum framework to develop iPad applications. They find user needs but do not manage to translate those needs into the right product backlog items for the software development. Product backlog items are descriptions of user needs that explain to the development team what needs to be made in the application features. This thesis, therefore, answers the following research question:<br/><br/>How can co-creation be used to give support during the translation of user needs into product backlog items?<br/><br/>This research question is answered by following a double diamond design process, that includes both research activities and design experiments to create insights needed to answer the research question. <br/><br/>A detailed literature review is conducted the understand the current context of co-creation, value creation and software development. Moreover, two ethnographic studies are performed to understand the company’s context and problem that is being faced. The research insights are translated in a co-creation framework outline. Based on this framework a co-creation process and several tools that together serve as a design solution are developed. This process and tools are designed based on several creative sessions and experiments that reveal what design principles do and do not work. Finally, a framework evaluation test is performed in the hangar environment, validating the principles of the design solution. Based on the evaluation insights, the design solution is extended, and recommendations for implementation and further research are given. <br","Co-creation; toolkit; Strategic Design","en","master thesis","","","","","","","","","","","","","",""
"uuid:943680be-ccba-43e8-8394-36e2078f8ed6","http://resolver.tudelft.nl/uuid:943680be-ccba-43e8-8394-36e2078f8ed6","Scour hole formation for lateral non-uniform flow in non-cohesive sediments","Üşenti, Batuhan (TU Delft Civil Engineering and Geosciences)","Uijttewaal, Wim (mentor); Broekema, Yorick (graduation committee); Zoon, Arthur (graduation committee); Muttray, M (graduation committee); Delft University of Technology (degree granting institution)","2019","For a project in the province of Zeeland, The Netherlands, a culvert was installed trough a dike to restore the tidal flow. Shortly after commissioning of the facility a scour hole at the end of the bottom protection developed. Although the scour hole was anticipated in the design, the scour hole was developing more rapidly than predicted. Furthermore, the hydrodynamics of the tidal jet flow from the culvert were different than what was expected in the design. It is expected that the uncertainties in predicting the scour hole process lies probably the most in a lack of understanding of the flow conditions in the vicinity of scour holes.<br/><br/>The scour hole depths can be predicted by the Breusers empirical relations. The development of the scour process entirely depends on the flow velocity and the relative turbulence intensity at the transition of the fixed to the erodible bed. The empirical equations do not account for all the hydrodynamic processes in a scour hole. Furthermore, the scour studies are predominantly considering a two-dimensional vertical situation in which lateral uniform flow is assumed. However, in practice lateral non-uniform flow is the rule rather than the exception.<br/><br/>The objective of this master thesis is to research the scour development under laterally nonuniform flow and to obtain more fundamental understanding of the scour process. Physical experiments were conducted in order to investigate the influence of lateral non-uniformities in the flow field on the scour process. In the scale experiments, the lateral velocity differences originated from two parallel streams with different streamwise velocities.<br/><br/>The scour pattern under laterally nonuniform flow is different than the scour pattern under laterally uniform flow. The scour hole in laterally nonuniform flow is deeper and it develops faster compared to the scour hole development in laterally uniform flow under the same hydraulic conditions. Furthermore, the scour pattern under lateral non-uniform flow shows spatial variations in lateral direction. The larger maximum scour depths are not observed in the zone with high flow velocities, but in the mixing layers.<br/><br/>A horizontal contraction of the flow at the scour hole is observed for lateral non-uniform incoming flow, whereas the presence of the scour hole does not affect the horizontal structure of the flow for lateral uniform incoming flow. The vertical structure of the flow showed relatively high near-bed velocities in the scour hole indicating flow attachment to the bed for laterally nonuniform flow. In addition, the vertical structure of the flow appears to become more depth uniform in the scour hole. The vertical structure of the flow is important of the sediment transport in the scour hole. For vertically attached flow, it was indicated that sediment could not be transported from the scour hole in the direction of the bed protection.","Scour hole; Laterally nonuniform; physical experiment","en","master thesis","","","","","","","","","","","","","",""
"uuid:26ed61ee-8bd6-4571-b529-45c7a94a6b2c","http://resolver.tudelft.nl/uuid:26ed61ee-8bd6-4571-b529-45c7a94a6b2c","Affect expression in social robots: Combining non-verbal affect expression techniques","Prajod, Pooja (TU Delft Electrical Engineering, Mathematics and Computer Science)","Hindriks, Koen (mentor); Tielman, Myrthe (graduation committee); Tintarev, Nava (graduation committee); Delft University of Technology (degree granting institution)","2019","With the advent of social robots which are designed to be 'social', human-like interactions have become a necessity. It is natural for us to use a plethora of emotions to convey additional information or to make an interaction more engaging. But emotion expression is not commonly associated with robots. Many humanoid robots cannot generate facial expressions to portray various emotions. Studies have shown that robots are multi-modal systems which can employ multiple channels to express an emotion. This thesis explores the non-verbal emotion expression techniques and their expressive capabilities. We found that some emotions are easier to express than others, and a single technique cannot express all the emotions. We chose a few emotions and systematically determined the best technique for each of them.","Social Robotics; Emotions; Non-verbal; Parametric model; Valence-Arousal","en","master thesis","","","","","","","","","","","","","",""
"uuid:aae3296a-6e80-4425-a08a-85ef8ef70381","http://resolver.tudelft.nl/uuid:aae3296a-6e80-4425-a08a-85ef8ef70381","Decreasing the exposure of temperature-sensitive cargo to ambient temperature on the tarmac at KLM Cargo","Epe, Gerco (TU Delft Mechanical, Maritime and Materials Engineering)","Duinkerken, Mark (mentor); Negenborn, Rudy (graduation committee); de Vos, Peter (graduation committee); Delft University of Technology (degree granting institution)","2019","Temperature excursions show that goods that are transported from an aircraft to the warehouse are exposed to ambient temperature for too long, affecting the temperature of the cargo. KLM Cargo has a cool chain project that tends to gain more insight in the operational performance. With the exposure as KPI, defined as Degree-Hours, all subsequent operations are quantified and a performance value is appointed to each subsystem. The operations are not occurring in the same amount, therefore a modal and cargo split is applied to determine the exposure of a single ULD when taking into account the chance of any path and any type of cargo. All performances are compared to the performance when improvement opportunities are implemented in the system to reduce the exposure. The cost and performance rate per opportunity are put together to gain an insight in feasible improvements, showing that the use of an animal dolly can decrease the exposure on short-term.","Temperature-sensitive; Cargo; Tarmac; Airport; Exposure; Ambient temperature","en","master thesis","","","","","","","","","","","","","",""
"uuid:ce5060ba-0613-4639-aeb1-4b6fca238c55","http://resolver.tudelft.nl/uuid:ce5060ba-0613-4639-aeb1-4b6fca238c55","Sequential Estimator for Breathing and Heart Beat Frequencies Using Radar","Su, Guigeng (TU Delft Electrical Engineering, Mathematics and Computer Science)","Yarovoy, Alexander (mentor); Petrov, Nikita (graduation committee); Delft University of Technology (degree granting institution)","2019","With an LFMCW automotive radar operating at its center frequency of 77GHz, the sequential estimation of frequency and amplitude for vital signs, namely, respiration and heartbeat, are considered. The radar response of vital signs is described and analyzed. With extraction of the phase history, extended Kalman filter and particle filter are simulated. Extended Kalman filter with a certain number of samples per iteration performs well for sequential estimating the respiratory frequency and amplitude in different scenarios. This sequential estimator is then verified by experimental data.","Vital signs; sequential estimation; EKF","en","master thesis","","","","","","","","","","","","Electrical Engineering","",""
"uuid:3a355145-17cc-4dce-9a30-b3a6af0969e1","http://resolver.tudelft.nl/uuid:3a355145-17cc-4dce-9a30-b3a6af0969e1","The water cycle with climate change: A study on atmospheric moisture transport using GFDL climate forecasts","Post, Umbriël (TU Delft Civil Engineering and Geosciences)","van der Ent, Ruud (mentor); Gruendemann, Gaby (graduation committee); de Roode, Stephan (graduation committee); Winsemius, Hessel (graduation committee); Delft University of Technology (degree granting institution)","2019","Climate change causes temperatures to rise worldwide. Up until now it is unclear what effect this has on the global water cycle. In this study the output of two GFDL model experiments were thoroughly investigated and used in the moisture tracking model WAM-2layers, accounting for model runs in a past case in the end-20th century and future case in the end-21st century, based on RCP8.5. This is done in order to acquire knowledge on what will happen to the global as well as regional water cycle in the future and to find out what processes provide climate change to have an effect on the water cycle. Changes in precipitation and evaporation rates are spatially highly dissimilar, therefore regional differences can be distinguished. Past studies have suggested that a DDWW paradigm - where dry regions dry out further and wet regions get wetter - will take place with climate change. Even though in some regions this might happen, results show that on land this is not necessarily the case - at least, if precipitation rate is the benchmark for a region to get drier or wetter. Processed GFDL data concludes that dry region Western Sahara gets wetter while dry region Middle East gets drier and wet region Indonesia gets wetter while wet region Amazonia gets drier. The DDWW paradigm covers another aspect as well, that there will be a larger spatial variability for variables characterising a region to be wet or dry. However, while everywhere on the globe the temperatures will rise according to the GFDL data, the spread of the yearly mean temperatures over the globe will actually decrease, meaning that mean yearly temperature in the coldest place will lie closer to the mean yearly temperature in the warmest place. This is also the case for mean yearly precipitation and evaporation rates. The mean yearly precipitation and evaporation rate in the driest place will lie closer to the mean yearly precipitation and evaporation rate in the wettest place in the future case. Continents show divergent effects in water cycle due to climate change. The continents with relatively larger sources of terrestrial moisture - North America, Europe and Asia - have an increased water cycle with higher precipitation and evaporation rates in the future. The increases in precipitation rates on these continents will originate from terrestrial evaporation and a higher percentage of evaporation will return as precipitation on land. South America shows a distinct effect, different than all other continents. This continent shows a decreased water cycle with lower precipitation and evaporation rates in the future. Of this precipitation a lower percentage comes from land and the evaporated moisture will return less on land. Africa and Oceania show another pattern. Both these continents will experience more precipitation in the future case, but this moisture will come from oceanic evaporation. Two case study areas are examined in more depth by looking at seasonality effects. A case study in the Amazon forest shows a distinct dry season in the future case, the effect of possible land use change in the Amazon forest. Less evaporation that is an effect of deforestation of the rain forest gives less moisture for clouds to form and precipitate. Moisture evaporates from the oceans on the East of Amazon region but moves over the region before it can precipitate. A case study in Western Africa shows a magnified rain season. The analyses show that during the wet season in the future case there in an increased amount of moisture coming from the oceans West and South of Western Africa and meanwhile there was still moisture coming in from the tropical rain forest East of the area.","moisture recycling; climate change; precipitation; water cycle","en","master thesis","","","","","","","","","","","","","",""
"uuid:c435b8da-f065-498f-a2d1-8d14d903c0cf","http://resolver.tudelft.nl/uuid:c435b8da-f065-498f-a2d1-8d14d903c0cf","An Experimental Approach to Study Drainage in Relation to Geometrical Features of Artificial Adhesives","De Geyndt, Wouter (TU Delft Mechanical, Maritime and Materials Engineering)","Dodou, Dimitra (mentor); van Assenbergh, Peter (graduation committee); Delft University of Technology (degree granting institution)","2019","With growing interest in wet adhesion, animals such as tree frogs are often used as paradigm for creating grippers in wet environments. Tree frogs are capable of attaching to surfaces under several conditions (smooth, rough, dry, wet, and flooded) due to the microstructure of their toe pads. This microstructure consists of pillar-shaped hexagonal cells separated by thin and deep channels. Drainage is an important phenomenon to consider, since too much liquid between the toe pad and surface results in a low adhesive force. Therefore, understanding the relationship between pillar-shaped microstructures and drainage can lead to the creation of adhesive pads that are functional in wet conditions and to other drainage related applications. <br/> <br/>Adhesives with a pillar-shaped microstructure were fabricated and their drainage speed was experimentally studied against a glass substrate. Gathering experimental data was accomplished by using Particle Image Velocimetry, and by using fluid velocity as a proxy for drainage. A custom-made set-up was built to accurately control the speed at which the adhesive and the substrate approached each other. Adhesives with various pillar diameters, pillar spacings, and pillar alignments were tested with fluids of various viscosities. It was found that the pillar diameter most likely has a significant effect on drainage, whereas the effect of pillar spacing and the effect of fluid type could not be determined. Pillar alignment did not have a significant effect on drainage. <br/><br/>In future work, it is recommended to complement the findings of this thesis with adhesion and friction measurements to understand how drainage associates to adhesive force.","Fluid Flow; Particle Image Velocimetry; Artificial Adhesive; Wet Adhesion","en","master thesis","","","","","","","","","","","","","",""
"uuid:f87a002e-b181-4c94-b34c-b89497aaa931","http://resolver.tudelft.nl/uuid:f87a002e-b181-4c94-b34c-b89497aaa931","Multi-channel Waveform Agile Radar: Experimental performance evaluation of ASTAP radar system","Ahmed, Sheeraz (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Microwave Sensing, Signals & Systems)","Yarovoy, Alexander (mentor); Krasnov, Oleg (graduation committee); Alavi, Morteza (graduation committee); Delft University of Technology (degree granting institution)","2019","Recent advancements in Multiple-Input Multiple-Output (MIMO) radar techniques has created a paradigm shift in the overall radar technology to increase degrees of freedom in multi-function radar capabilities. The underlying principle of MIMO transmissions is to transmit independent waveforms from each antenna-element which do not interfere with other transmitted signals and establish wide illuminations which create multiple received signals back-scattered from the same target under observation to provide more information on the target aspects. One other principle is called colored transmission, by simultaneously radiating specific waveforms from each antenna-element/sub-array in different directions to achieve ‘space-time coding’. This can be explained as colored spatial distribution (multiple coded beams to probe the radar environment) instead of the white spatial distribution (single wide beam), such that the transmitted signals are now function of time as well as space. Recently, a novel multi-channel waveform agile demonstrator namely ASTAP (Advanced Space-Time Adaptive Processing) radar system has been designed and developed in Microwave Sensing, Signals and Systems (MS3) group. It consists of eight transmit channels with a single receive channel and hence can also be called as co-located Multiple-Input Single-Output (MISO) radar. The ASTAP radar system is capable of generating and transmitting independent waveforms via multi-channel Arbitrary Waveform Generator(AWG) simultaneously . However, the transmission of different coded waveforms with a radar system such as ASTAP demonstrator has some major challenges to be addressed first. These challenges include the impact of AWG on digital-domain generation of waveforms including limited-bits quantization errors, time- and phase-skew ( and/or jitter), influence of high-frequency up-conversion hardware components such as RF mixers (as non-linear devices) and antenna dispersion effects. First novelty of this thesis work is to investigate the influence of these system imperfections on waveform transmit ambiguity functions, waveform orthogonality in MISO transmissions, received signals separation and beamforming process for the synthesis of target azimuth distributions. It follows that an end-to-end system-level calibration to compensate these system imperfections on transmit side for different waveforms also serves as the second novelty of this thesis work and has been demonstrated with ASTAP radar system. For system performance analysis and beamforming applications, Over-the-Air (OTA) channel measurements have been done to compensate the ASTAP hardware distortions significantly and obtain the near-ideal waveform responses. Furthermore, it is investigated that to what extent it is possible to separate signals corresponding to each transmit channel from the composite received signal in a single receive channel. This study is extended further to generate and transmit two orthogonal beams occupying the same frequency band simultaneously and the corresponding transmit radiation patterns are recovered from the composite received signal matched filtering. Finally, conclusions along with future aspects and recommendations have been discussed.","Waveform Agile Radar; Colored Transmission; MISO Radar; Over-the-air Calibration; Multi-beam analysis; Digital Beamforming","en","master thesis","","","","","","","","2020-08-21","","","","Electrical Engineering | Signals and Systems","",""
"uuid:01acdc8c-7199-4c3b-9cca-4ec64290f23f","http://resolver.tudelft.nl/uuid:01acdc8c-7199-4c3b-9cca-4ec64290f23f","Performance assessment of a “do it yourself” double skin green façade for an existing office building","Ramachandran, Shirish (TU Delft Civil Engineering and Geosciences)","van der Spoel, Willem (mentor); Luscuere, Peter (graduation committee); Schipper, Roel (graduation committee); Öğüt, Mert (graduation committee); Delft University of Technology (degree granting institution)","2019","This project is based on two sustainable construction methods, namely up-cycling (reuse of materials) and vertical farming (green facades). These two concepts are combined to form a ‘Do It Yourself’ double skin façade, a double skin façade made with re-used sliding doors, which is aimed to be capable of developing ‘Edible Green’, which refers to the placement of edible vegetation in the façade of an office building. As two sustainable methods are combined into one project, the investigation of the performance of this ‘Do It Yourself’ double skin façade arose as an objective. Hence the aim of this research was to investigate the climatic performance of the façade for the growth of plants, as well as its influence in the indoor environment of the office. The façade was divided into 6 modules across two floors, capable of accommodating vegetation individually. These modules were assigned different design strategies based on ventilation, shading system, watering system and the placement of plants. Five different types of plants were placed on each module. Three types of ventilation strategies were adopted as parameters for the modules, namely minimally ventilated, naturally ventilated and mechanically ventilated. The configuration of plants were such that all modules had a total of 9 plants, with 7 short growing and 2 tall growing plants. The watering strategy was adopted in the form of drip irrigation system, where the modules in the top floor received constant rate of irrigation whereas the modules in the bottom floor received varied rate of irrigation. A measurement system was developed using a microcontroller, namely the Arduino UNO. The parameters were evaluated by the placement of measurement sensors in each of the modules. The measurement was done over a period of three weeks where the temperature, relative humidity, illuminance, CO2 and Total Volatile Organic Compounds (TVOC) were measured. The obtained values were studied and analysed based on the expected behaviour from the literature. The condition of the plants in the cavities were evaluated by determining the yield produced by each of the module, and also by a visual inspection of the plants. It was observed that the plants play an influential role in increasing the humidity in the cavity, especially in the cavities of the non-ventilated modules. This was evaluated by comparing the relative humidity and absolute humidity of all the modules. It was found that the humidity in the minimally ventilated modules was higher compared to the rest. Moreover, it was found that the shading in the façades highly influence the temperature in the cavity. The performed experiments suggested that the use of plants in the double skin façade, along with an external shading strategy can decrease the temperature in the cavity by up to 13°C and can increase the relative humidity of air in the cavity by 38%. Moreover, the experiments with respect to mechanically ventilated modules show that the cavity preheats the air by up to 6°C during night time and pre cools the air by up to 10°C during high outdoor temperatures (summer afternoons). Based on the theoretical and real time evaluation, it was concluded that the minimally ventilated modules perform relatively better with respect to the condition of the plants, whereas the mechanically ventilated modules perform better with respect to the indoor environment in the office. However, the influence of the double skin façade alone on the indoor environment of the office could not be determined, as there were external influences on the climatic conditions inside the office building. Based on the results, a design strategy was successfully formulated and the performance of each module was investigated. The research answered the question with respect to maintenance of the double skin façade for the growth and health of the vegetation. Moreover, the research helps to provide ideas on different design strategies that can be used, based on different sustainable design requirements.","Double skin facade; Green facade; Sustainability performacne; office building; Indoor environment; Vegetation","en","master thesis","","","","","","","","","","","","Civil Engineering | Building Engineering","",""
"uuid:7a6e09db-2e5e-43bf-8fe5-006f57557bb3","http://resolver.tudelft.nl/uuid:7a6e09db-2e5e-43bf-8fe5-006f57557bb3","Comparison of aggregated models for CHIL validation of PV power plant controllers","Venkateswaran, Srivats (TU Delft Electrical Engineering, Mathematics and Computer Science)","Cvetkovic, Milos (mentor); Rueda Torres, Jose (mentor); Delft University of Technology (degree granting institution)","2019","With the increase in the number of utility-scale PV power plants being integrated into the grid, there has been a rise in interest in the testing and validation of components involved in these power plants. Due to the inflexibility of the current field testing methods, there is an increased push towards validation of the involved components using Hardware-in-the-loop. However, to test components, entire power plants cannot be modelled due to computational constraints. With the help of this masters thesis, there has been an attempt to compare aggregation methods which can be used to reduce the computational burden, for certain kinds of tests such as active and reactive power response. In this study, three different types of aggregated models were compared to<br/>the detailed model - Magnified model, Oversized model and the Frequency Dependent Network Equivalent (FDNE) model. The study modelled a 19.25 MW PV power plant as the base detailed model of which aggregated models have been derived from. These aggregated models have also been implemented in real time to understand their response. It was observed that the models, while deviating from the detailed model in terms of losses, do reach the same steady state. Magnified model can be concluded to have worked the best. However, it is also the slowest among the three aggregated models. In real time, the oversized model was able to run successfully while the magnified model proved to be too slow,computationally. These results can help design a better aggregating algorithms for validation modelling using real-time system hardware-inthe-loop systems.","PV power plant; Aggregate modelling; Control Hardware in Loop","en","master thesis","","","","","","","","","","","","","",""
"uuid:07887f1a-7e44-423c-a769-943fde35d451","http://resolver.tudelft.nl/uuid:07887f1a-7e44-423c-a769-943fde35d451","Optimal Configuration of an Automated Dairy Factory","Gideonse, Pieter (TU Delft Mechanical, Maritime and Materials Engineering)","Schott, Dingena (mentor); Pang, Yusong (mentor); Huang, Yilin (graduation committee); Delft University of Technology (degree granting institution)","2019","Currently a new small and automated dairy factory for the onsite production of cheese at farms is under devel-opment. This new factory aims at the production of cheese without any human interaction, based on the (raw) milk from cows who are milked with a milking robot. At the moment only a small test factory exists, in which human interaction is still present. Of the new factory it was unknown what configuration of processing stations and transportation vehicles would be required to produce cheese. To find the optimal configuration of this new automated dairy factory, first a data analysis was used to determine the characteristics of the milk input of the factory. Next the present test factory was analyzed and a model representing the automated dairy factory was developed. The model was used to identify the opti-mal configuration of the dairy factory. Four different farm groups were researched, per farm group one opti-mal configuration of the dairy factory was identified.","Discrete event simulation; Process analysis; Data analysis; Delft Systems Approach; Modeling; Dairy processing; Tecnomatix Plant Simulation","en","master thesis","","","","","","","","2024-08-28","","","","Mechanical Engineering","",""
"uuid:5afeea39-eabf-4561-832f-35f93e6bcc3e","http://resolver.tudelft.nl/uuid:5afeea39-eabf-4561-832f-35f93e6bcc3e","CC-Spin: A Micro-architecture design for scalable control of Spin-Qubit Quantum Processor","Yadav, Amitabh (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Quantum Computer Architectures; TU Delft QuTech)","Khammassi, Nader (mentor); Bertels, Koen (mentor); Sebastiano, Fabio (graduation committee); Al-Ars, Zaid (graduation committee); Delft University of Technology (degree granting institution)","2019","Quantum Computing is an emerging field of technology with the promise that engineered quantum systems can address hard problems such as, problems with exponential compute complexity in Chemistry, Genomics, Optimization and many more applications. Quantum Computer Architecture is an area of research targeted for the NISQ-era quantum computing and little research has been done for development of a scalable classical control and read-out infrastructure for the quantum processors. The project is aimed at study of SoC-FPGA design methodology and architecture design for control of quantum processor. The targeted quantum hardware is the Spin-Qubit in Semiconductor Quantum Dot Chip. The project is intended for understanding the design and working of a silicon-spin qubit for a computer (architecture) engineer. It further helps identify necessities for an architecture, Instruction Set requirements, bottlenecks and future challenges (specific to Spin-Qubit quantum processor) that would help in better designs for new control architectures.<br/><br/>The objective of this thesis is directed towards addressing the architectural challenges for the quantum-classical hardware for controlling the NISQ-era quantum devices and beyond. We analyze the control infrastructure requirements and propose a micro-architecture and waveform generation methodology to integrate the physical device with the quantum compilation tool-chain.","Quantum Computing; Quantum Control Microarchitecture; Computer Architecture","en","master thesis","","","","","","","","","","","","Computer Engineering","",""
"uuid:6ead1611-990d-40a0-983e-235535c84ce0","http://resolver.tudelft.nl/uuid:6ead1611-990d-40a0-983e-235535c84ce0","Design Optimisation: Computationally Optimised Bridge Design","Nikolić, Momir (TU Delft Architecture and the Built Environment)","Delft University of Technology (degree granting institution)","2019","The computational optimisation process have been used in the structural design for long time now. Even though it occasionally appears in architectural practice, it has not yet been completely developed and its full potential has not yet been recognised.<br/><br/>In order to further explore the potential of computational optimisation in architectural design process, and to establish a well performing work-flow, this thesis researches on use of it, on the case study of a complex bridge design.<br/><br/>Suitable design assignment has been recognised in the south-east area of Rotterdam, with a large crossing over Nieuwe Maas river. Due to complex context and many different groups of stakeholders in this area, this bridge design assignment represents a suitable case study for development and testing of aforementioned design process.<br/><br/>Already established parametric design work-flow serves as a base of this project, while the exploratory spirit of it is recognised in use of architectural parameters and objectives for optimisation, as an improvement on traditional, only structural optimisation. Modern optimisation software and newly developed algorithms are used in order to process enlarged pool of solutions created by introducing larger number of parameters and objectives.<br/><br/>As a result, this project aims to develop a well integrated design proposal for a bridge over Nieuwe Maas. In that way, it explores the potential of using computational optimisation within the architectural design process as it hopes to create a stepping stone based on which further development of this design work-flow can be conducted.","Bridge Design; Multi Objective Optimisation; Architectural Optimisation; Optimisation Algorithms","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences","",""
"uuid:144faea4-8895-465d-afbb-eec2aa97df85","http://resolver.tudelft.nl/uuid:144faea4-8895-465d-afbb-eec2aa97df85","Manufacturing and quality characterisation of pre-preg fibre-placed composite lattice structures","Lee, Joe (TU Delft Aerospace Engineering; TU Delft Aerospace Structures & Materials)","Kassapoglou, Christos (mentor); Delft University of Technology (degree granting institution)","2019","Composite lattice structures (CLS) offer high performance and demonstrate significant mass savings in space structure applications. Local modifications of regular lattice designs have the potential to further improve the lattice performance. This research explored the micro-structural quality features of CLSs manufactured with pre-preg fibre-placement, and how quality is impacted by lattice modifications.<br/>Modifications to a regular lattice for a representative case of an attachment point load are identified using a topology optimisation tool. Three lattice modifications techniques were identified: rib width variations, rib angle variations and additional ribs. A sample lattice with modifications was manufactured and evaluated by C-scan, CT techniques and micro-sections. An explanation of quality features in CLS is described and quantified using a presented characterisation model based on node transition waviness.<br/>Using the presented explanation, a quantitative quality model was developed to relate lattice design geometry to manufactured quality for this process. The model was used to design and manufacture a second panel with improved implementation of lattice modifications. The quality model was improved and shown to explain more than 75% of all observed quality variation in the two panels with a linear regression. Future work and limitations the of the quality model are discussed.","composite lattice; node; isogrid; grid stiffened","en","master thesis","","","","","","","","2024-08-27","","","","Aerospace Engineering | Structures and Materials","",""
"uuid:f61e4103-dfd5-4b4a-bf4f-1351a63d992b","http://resolver.tudelft.nl/uuid:f61e4103-dfd5-4b4a-bf4f-1351a63d992b","A Metric to Quantify the Hazard Avoidance Capability of Vehicles","Hegde, Anoosh (TU Delft Mechanical, Maritime and Materials Engineering)","Tejada Ruiz, A. (mentor); de Winter, J.C.F. (graduation committee); Mullakkal-Babu, F.A. (graduation committee); Delft University of Technology (degree granting institution)","2019","Safety is an important parameter considered during the design of Advanced Driver Assistance Systems and fully autonomous vehicles.<br/>One of the ways to assess the road vehicle's safety is by estimating the likelihood with which the vehicle can react to prevent the danger. <br/>In the presence of an impending collision (hazard), the trajectory planning module in the autonomous vehicle would generate few escape trajectories to avoid the collision.<br/>The escape trajectory is chosen such that it maximises the safety of the vehicle based on certain criteria.<br/>One of these criteria is the vehicle's avoidance capability throughout the trajectory.<br/><br/>This thesis presents an avoidance metric that is constructed using a computational procedure to quantify the avoidance capability of the vehicle in both pure longitudinal (1-D) and, combination of both lateral and longitudinal (2-D) scenario.<br/>The key idea is (a) Propagate forward in time the current state of the host (and the world) using a vehicle model to estimate the host's reachable set of states.<br/>(b) Carefully select a set of samples from the reachable set and repeat the propagation.<br/>(c) At every step, the trajectories that lead to collisions are eliminated.<br/>The ratio of the size of the region spanned by the remaining trajectories to the size of the region spanned by all the trajectories (including those that lead to collision) then constitute the estimate of the host's avoidance capability.<br/><br/>Through simulations on specific use-cases, for a pure longitudinal motion, on comparison with Brake Threat Number (BTN), it was observed that the metric (from the proposed computational procedure) performs very similar to BTN and also takes a low computational time of 380 [ms] for a time horizon of 2.5 [s].<br/>However, in the presence of dynamic obstacles, major differences in performance (such as discontinuities, step-like variation), were observed between the metric and BTN.<br/>In the case of the combination of both lateral and longitudinal motion, the computation time for the proposed procedure was found to be independent of the number of obstacles.<br/>To reason about the accuracy of the approximation of the reachable set for a double integrator model obtained from the proposed procedure, it was compared with the nodes obtained from Rapidly-exploring Random Trees (RRT), an under-approximation, and found that the nodes lie either very close or well within the boundary of the approximation.<br/>However, the computation time for the proposed procedure took around 10.87 [s] which comes as a major drawback.","hazard avoidance capability","en","master thesis","","","","","","","","","","","","Mechanical Engineering","",""
"uuid:e7702bcd-e1dc-4270-9a10-4255c77a1872","http://resolver.tudelft.nl/uuid:e7702bcd-e1dc-4270-9a10-4255c77a1872","Geometry and Stability Analysis of Caves in Bahia, Brazil","Hanif Dinul Islam, Hanif (TU Delft Civil Engineering and Geosciences)","Bertotti, G. (mentor); Blom, J.C. (graduation committee); Rossen, W.R. (graduation committee); Delft University of Technology (degree granting institution)","2019","More than 30% of the world’s hydrocarbon reserves are located in carbonate reservoirs, and this percentage is likely to increase, as a result of discoveries of new giant oil fields in carbonate rocks, generically named “Pre-salt layers”. However, there are still some problems in understanding karst systems that still unresolved. The karst caves are one of the suitable analogs for karstic reservoirs that also spread all over the world. In this study, the mobile LIDAR (Light Detection and Ranging) data is used to characterize the geometries and to analyze the stability of tunnels under several depths from 5 caves in Bahia, Brazil. The studied caves are representing both of the karstification mechanism (Epigene &amp; Hypogene). In general, there are two tunnel shapes among the caves: horizontal ellipse &amp; Vertical ellipse shapes. Several factors could be controlled the shape origin of the tunnels, but from this study mainly caused by lithology or the geology structure factor. By comparing with the structural data, the conduit orientation generally shows the same trend. Therefore, these conditions suggest a geometrical correlation between the fractures and the caves, and that the observed fractures almost certainly acted as conduits for fluid flow. The stability analysis showed that the vertical ellipse tunnels are more stable compared to the horizontal ellipse. However, all of the tunnels are already unstable in shallow depth (on average less than 2 km depth). The sensitivity tests show several parameters that would affect the stability: Rock Properties (Rock Mass strength, Rock mass elastic, density), number of tunnels in the system and the distances between multiple tunnels.","Carbonates; LIDAR; point cloud data; Stability Analysis; Karst; Geology","en","master thesis","","","","","","","","","","","","Petroleum Engineering and Geo-sciences","",""
"uuid:e6d09916-57a0-4112-be0f-67314c6e8098","http://resolver.tudelft.nl/uuid:e6d09916-57a0-4112-be0f-67314c6e8098","How can design for well-being lower the taboo of menstruation in India","Salarić, Petra (TU Delft Industrial Design Engineering)","Diehl, J.C. (mentor); Desmet, P.M.A. (mentor); Delft University of Technology (degree granting institution)","2019","In India, there is an existing taboo of menstruation which has an impact on the well-being of women in different ways - from education, economics, health, religion to different personal aspects. Many activities are happening in India towards improving the situation around menstruation - from governmental activities and plans, provision of sanitary pads in the rural areas, organization of educational sessions in schools, to famous actors using media to spread awareness on these issues. However, there is a need to create a change in the mindset and the behaviour of society to accept the made efforts. <br/><br/>This graduation project is an extension of an elective course of Design for Emerging Markets in the winter semester of 2018 at TU Delft. The field research of this graduation project was conducted in India in order to get closer to the problem and get emerged into the context. The field research included interviews with different experts in the field to understand how this problem has been approached from different angles.<br/><br/>As the topic of menstruation is a sensitive one in India, one must work from a comfortable and safe space of people to create a change, and this lead to the family context. The tests were conducted with 9 families to understand what is the behaviour people have in their homes and how does the conversation go around this topic. <br/><br/>Research brought to a conclusion how pre-menstruating girls are not informed on the subject until they get their first period, which causes them to experience shock, fear and anxiety when they start menstruating. Men are often excluded in the discussion around menstruation, and in the family, the discussion is often occurring between the girl and her mother. <br/><br/>Through research a correlation was found between the positive attitude in girls towards menstruation and their freedom of conversation on menstruation with both parents. <br/>That is why this project has focused on enabling discussion in a family home between all members prior to the girl’s first menstruation. <br/><br/>Even though the problem around menstruation in India is a complex one, enabling discussion can be that one step towards the desired behaviour change to enhance the well-being of the girl. <br/><br/>Gamification came as a solution as it can bring all family members together through an engaging and fun activity. Creating an engaging activity can help in subtly bringing to the surface the otherwise stigmatized topic, and the fun aspect of the game helps in creating a positive atmosphere which makes the discussion more enjoyable. <br/><br/>After testing 4 different designs, the outcome design is a pairing type of card game, Mix-A-Body-Match. As the entire aim is to create funny pairs, the game doesn’t require prior knowledge on the subject, which allows both the pre-menstruating girl and male members of the family to get involved into the game-playing with ease. The game comes with a booklet that contains the rules to the game and explains the content on the cards. The booklet also provides information on puberty and menstruation for the family to learn more. The game intents to normalize menstruation by presenting it as a part of puberty and a normal aspect of growing up. It serves as an ice-breaker. The game creates a positive atmosphere in the home through laughter, and in that way creates the way for the discussion to appear. <br","Design for well-being; Emerging markets; Gender inequality; Gamification; Humor; India; Design for Interaction; Taboo; Stigma; Culture Sensitive Design; Research through design","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:98a156a1-3899-4d7c-86cd-dc223b73ab40","http://resolver.tudelft.nl/uuid:98a156a1-3899-4d7c-86cd-dc223b73ab40","Low-SNR Operation of FSK Demodulators","Šabanović, Armin (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Electronics)","McCune, E.W. (mentor); Babaie, M. (graduation committee); Delft University of Technology (degree granting institution)","2019","This thesis introduces the concept of phase rotation cancellation (PRC) as a previously unknown error mechanism in narrow-band FSK systems, and proposes a new FSK demodulation algorithm to resolve PRC errors. Phase rotation cancellation is defined as an event where the signal phasor rotation in the IQ plane is temporarily cancelled by the rotation of quadrature noise. The PRC errors are the dominant error mechanism in narrow-band FSK due to the small dynamic range at the output of a conventional FSK demodulator. In addition, any pre-modulation filtering further reduces the dynamic range and increases the probability for PRC errors to occur. Based on the discovered characteristics of PRC errors, a novel FSK demodulation algorithm is developed that greatly improves detection accuracy in FSK systems. Furthermore, the novel demodulation algorithm allows for sub-datarate receiver bandwidth operation, which offers improved receiver sensitivity and blocker performance. It is shown that the new demodulation algorithm eliminates nearly all PRC errors, leaving only errors due to clicks. In a GFSK system with BT = 0.5 and h = 0.5, an improvement in receiver sensitivity of up to 4.4 dB is achieved with the new demodulation algorithm.","AWGN; Demodulator; FSK; Low-SNR; Receiver; Algorithm; Digital; Wireless Communication; Low-power","en","master thesis","","","","","","","","2020-08-28","","","","Electrical Engineering | Microelectronics","",""
"uuid:88209c5c-f5f5-42ba-8617-fe17eea04f66","http://resolver.tudelft.nl/uuid:88209c5c-f5f5-42ba-8617-fe17eea04f66","Physics-Based Data-Driven Model for Short-Term Production Forecast","Bļinovs, Arturs (TU Delft Civil Engineering and Geosciences)","Voskov, D.V. (mentor); Delft University of Technology (degree granting institution)","2019","Before performing a field production forecast, an inverse problem has to be solved. Resulting in an ensemble of models that include the integration of real data with a complex physical and geological data describing subsurface processes. For large models, this approach can be very time and computationally expensive, therefore we propose an alternative approach for reservoir forecasting. In this work, we develop a physics-based data-driven model that purely relies on production data of the field and does not require any in-depth knowledge of the reservoir geology and physics. In the proposed approach, we utilize Delft Advanced Reservoir Terra Simulator (DARTS) as a base for our reservoir simulations. DARTS uses an Operator-Based Linearization technique for the approximation of exact physics. It allows us to encounter a more realistic interpretation of physics and is computationally efficient. The physics-based data-driven approach uses sequential regression to the data to increase the fidelity of the model forecast and encounter any significant changes in reservoir dynamics and physics over its history. The model was examined and validated for synthetic and real field production models. We demonstrate that the developed approach is capable of providing accurate and reliable production forecast on a daily basis.","","en","master thesis","","","","","","","","","","","","","",""
"uuid:2e932bb0-98b7-43ac-b6f4-3da4bb869fb4","http://resolver.tudelft.nl/uuid:2e932bb0-98b7-43ac-b6f4-3da4bb869fb4","Coupled reduced order model and adjoint methodologies for proton therapy","kleyn Winkel, Lars (TU Delft Applied Sciences; TU Delft Mechanical, Maritime and Materials Engineering)","Perko, Z. (mentor); van Gijzen, M.B. (mentor); Lathouwers, D. (mentor); Heemink, A.W. (graduation committee); Delft University of Technology (degree granting institution)","2019","The goal of this project is to see if we can improve the treatment plan for proton therapy by using reduced order models and adjoint theory for proton therapy. We shall use a singular value decomposition on a dose distribution matrix to obtain the modes from which we can reconstruct every dose distribution. Using adjoint methodologies for proton therapy, we will define a response from which we can find the sensitivities, or gradient, in order to fit a Hermite interpolation polynomial on multidimensional simplices. The results show that the Hermite interpolation polynomial is a useful tool to find responses for low dimensional problems. For errors in one or two dimensions, the Hermite polynomial was able to reconstruct all dose distributions with R²=1. However, for an error in three dimensions the Hermite polynomial sometimes fails to reconstruct the dose distribution to within acceptable margins. We conclude that the combination of a ROM and adjoint method to find Hermite interpolation polynomial is a promising tool in order to further improve the proton therapy treatment plan. Further research should be done in order to determine whether Hermite interpolation can be used in every scenario, or if it fails if the grid becomes irregular. Finally, the extrapolating qualities of the Hermite polynomial should be tested.","Proton Therapy; Adjoints; ROM; Applied mathematics; Physics; RST","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics | Applied Physics","",""
"uuid:44932b07-20d4-4d1f-bd74-f7e02e1077f4","http://resolver.tudelft.nl/uuid:44932b07-20d4-4d1f-bd74-f7e02e1077f4","Enhancing Solar Energy Integration with Innovative mini-modules","Martinez Lopez, Arturo (TU Delft Electrical Engineering, Mathematics and Computer Science)","Isabella, O. (mentor); Zeman, M. (graduation committee); Ortiz Lizcano, J.C. (mentor); Jansen, K.M.B. (graduation committee); Delft University of Technology (degree granting institution)","2019","As solar energy finds its way into unexpected applications such as buildings or objects, the traditional rectangle-shaped module becomes inadequate. Although traditional modules have been optimized to deliver a large amount of power, they cannot be fitted easily into a façade or a wearable. This is why, new methods for integrating solar power into buildings and products have to be found. These methods should be attractive to designers and architects and must also allow solar energy to reach common people.<br/>The fabrication of mini-modules can help with this task as they can be fabricated with the already mature technology of crystalline silicon solar cells. They can be made lightweight and in different figures.<br/>This work aims to investigate ways to facilitate the fabrication of modules for use in Building Integrated Photovoltaics or Product Integrating Photovoltaics by means of studying the impact of cutting solar cells into different figures and sizes. To prove the suitability of tools of full-sized modules into mini modules, a Cell-To-Module analysis is performed. <br/>The results show that crystalline silicon can be effectively used for making modules in reduced sizes tackling the full integration of solar cells into objects.<br","laser cutting; crystalline silicon; solar energy; Customized design","en","master thesis","","","","","","","","2020-08-31","","","","Electrical Engineering | Electrical Power Engineering","",""
"uuid:13045a6d-59a3-4907-9b8e-7f1e2636e8ce","http://resolver.tudelft.nl/uuid:13045a6d-59a3-4907-9b8e-7f1e2636e8ce","Systematic Design Optimization of grabs handling cohesive bulk materials: Systematisch ontwerp optimalisatie van overslag grijpers voor cohesive bulk materialen","van den Bergh, Arjan (TU Delft Mechanical, Maritime and Materials Engineering)","Schott, D.L. (mentor); Mohajeri, M. (mentor); de Kluijver, W.A. (mentor); Delft University of Technology (degree granting institution)","2019","Grabs are often used for unloading bulk carriers that transport iron ore cargoes around the globe. The unloading process is time-consuming, and terminals strive to maximise their turnover capacity. Grab performance is a combination of maximum crane capacity, grab design and bulk material behaviour. Due to bulk uncertainties occurred by varying physical bulk properties, moisture content and consolidation, grab performance is hard to predict. To incorporate the bulk variability in the design process of grabs, or other large-scale bulk handling equipment, an optimization framework is proposed in which equipment is systematically optimized. With the framework an iron ore grab is optimized for handling iron ore pellets and iron ore fines. By a minimum number of experiments grab design was improved, increasing the turnover capacity for iron ore pellets by 12% and iron ore fines with 8%, and reducing the effect of varying bulk conditions. Optimization methods such as Latin Hypercube sampling,<br/>surrogate modelling and genetic algorithms proved to be successful for grab optimization. Further research of implementing the framework in the design process, and surrogate modelling is recommended.","Optimisation framework; DEM; Grabs; Cohesive bulk materials; Design of Experiments","en","master thesis","","","","","","","","2024-08-27","","","","Marine Technology | Transport Engineering and Logistics","",""
"uuid:845ca9cc-9d11-49f0-9d93-ff1693f23f6c","http://resolver.tudelft.nl/uuid:845ca9cc-9d11-49f0-9d93-ff1693f23f6c","Application of polyvinyl alcohol (PVA) for cycling clothing","Mane, Sanket (TU Delft Industrial Design Engineering)","Jansen, A.J. (mentor); Teunissen, L.P.J. (graduation committee); Bokslag, Rein (graduation committee); Delft University of Technology (degree granting institution)","2019","Cycling in hot and humid environment is demanding for the body. Olympics 2020 will be in Tokyo and the weather is expected to be hot and humid. Performance of the cyclist will be below par if they do not adopt various strategies to keep themselves cool. This project focuses on the development of new jersey with PVA fabric integrated in it to provide benefits to the cyclists.","Tokyo, 2020; Olympic Games; Cyclists","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:87ebdab0-4077-42ed-be7d-2c7a8d3e9e2f","http://resolver.tudelft.nl/uuid:87ebdab0-4077-42ed-be7d-2c7a8d3e9e2f","Applicability of video-based workflow monitoring of interventional cardiac procedures performed in Reinier de Graaf Hospital: Identifying variability of procedure times and associating factors","Kensen, Chav (TU Delft Mechanical, Maritime and Materials Engineering)","van den Dobbelsteen, J.J. (mentor); Hendriks, B.H.W. (graduation committee); Pang, Y. (graduation committee); Delft University of Technology (degree granting institution)","2019","In hospitals, the duration of surgical procedures is susceptible to a number a factors resulting in varying procedure durations of the same procedure. When these procedure times deviate from the predicted surgical duration, scheduling conflicts arise, leading to patient discomfort and inefficient use of hospital resources. Considering the aging population and the subsequent growing demand for healthcare, hospitals are under constant pressure to provide cost-effective care. Indeed, this is also the case for the interventional cardiology unit, where the expected increase of the prevalence of cardiovascular disease is expected to put a strain on hospital human resources. Improving the efficiency has been an area of focus in many hospitals. In fact, advanced methods such as surgical workflow monitoring have been employed to identify points of improvement especially in procedure scheduling. Up until now, this has not been employed in cardiac catheterization laboratories in the Netherland.<br/>The purpose of this study, therefore is identify primarily the factors influencing variability of the procedure time of procedures of the cardiac catheterization laboratory of the Reinier de Graaf Hospital in Delft and secondarily the possible sources compatible with video-based workflow monitoring for phase segmentation of the procedures.<br/>Retrospective data obtained from DoseWise was used to analyze the procedure times and associating factors of coronary angiograms and pacemaker implantation procedures. In addition, process models of the procedures were created and activity recognition identifiers were studied through observer-based data acquisition.<br/>Analysis showed that in coronary angiograms variations of total procedure times are mostly due to variable preparation times, whereas for pacemaker implantation the lead positioning times were the main source for variability. In addition, more experienced operators were shown to complete the procedure in a shorter time (-4.35%|p=0.007) in comparison to less experienced operator.<br/>Instrument and equipment use were identified as possible sources for activity recognition along with the hand kinematics, however further analysis of reliability is required.<br/>The findings in this study provide a basis for future monitoring of the workflow of these procedures using real-time data acquisition methods to improve the efficiency in cardiac catheterization laboratories.","Surgical Process Model; Procedure time; Variability; Phases; Coronary Angiogram; Pacemaker implantation; Cath lab","en","master thesis","","","","","","","","2021-07-24","","","","","",""
"uuid:c2d82ff5-83ee-4696-a48b-ca21825629bc","http://resolver.tudelft.nl/uuid:c2d82ff5-83ee-4696-a48b-ca21825629bc","Low-level radar data based road user detection","Dong, Jiaao (TU Delft Mechanical, Maritime and Materials Engineering)","Gavrila, D. (mentor); Palffy, A. (graduation committee); Delft University of Technology (degree granting institution)","2019","In order to achieve redundancy and improve the robustness of an autonomous driving system, radar is a suitable choice for road user detection task in severe working conditions (e.g. darkness, bad weather). However, the real-time multi-class radar based road user detection algorithm is less explored compared with camera and LiDAR solutions. To fill this gap, the current thesis proposes a pipeline for radar based road user detection task, which is able to detect pedestrians, cyclists and cars by a single radar sweep. The pipeline effectively utilizes the advantages of radar low-level data by using it as region descriptor and combining it with radar high-level data for region proposal. A novel convolutional neural network structure called LLTnet is designed, in combination with proper pre-processing and post-processing stages. Ensemble learning is used to further improve the inter-class detection accuracy. The LLTnet itself performs radar targets segmentation. If needed, its output can be fused into object-level detection. To better train the network, a real-life dataset containing different moving road users is created during the study by a moving test vehicle, which simulates the real-life urban driving scenarios. After the network is trained, it is firstly evaluated by target-level metrics, such as the classification accuracy and F1 score. Then object-level metrics are used for object-level evaluation, such as the precision, recall and intersection over union (IoU).<br/>Comprehensive experiments are performed which not only evaluate the performance of the proposed model but also test the importance of different stages and features, such as the importance of the ensemble learning and the validity of adding low-level data. The proposed pipeline improves the target-level F1 score from 0.59 of the baseline to 0.64 using LLTnet without ensemble learning. By adding the ensemble learning stage, the target-level F1 score is further improved from 0.64 to 0.70. The object-level recall of pedestrian class greatly improves from 0.37 to 0.68. The validity of adding low-level data to the algorithm is verified by bypassing the low-level data branch of the network. With only high-level branch, the target-level F1 score drops from 0.70 to 0.60. Furthermore, the trained model also shows good generalization ability on unseen data. <br/><br","Self-driving; Autonomous driving; Deep learning; Road user detection; VRU detection; Driver assistance; Machine learning; Automotive radar","en","master thesis","","","","","","","","2021-08-18","","","","","",""
"uuid:a5c94052-f115-4fde-b060-958152ef6d77","http://resolver.tudelft.nl/uuid:a5c94052-f115-4fde-b060-958152ef6d77","Oculus inTouch: Designing a Controller for Compelling VR Experiences Through Touch","Shor, Dan (TU Delft Industrial Design Engineering)","Hartcher-O'Brien, J. (mentor); Crone, H.E.C. (graduation committee); Delft University of Technology (degree granting institution)","2019","Arthur C. Clarke said: “Any sufficiently advanced technology is indistinguishable from magic,” and cutting edge Virtual Reality (VR) certainly is quite the illusion. VR opens to us a near infinite set of worlds and possibilities. Comprehensive, Immersive, Virtual Environments (IVEs) will change the way we shop, explore, love and live. They’ll close the gap between our digital imaginations and our physical limitations. The barrier to this vision is that right now, IVEs don’t feel real. We may have breathtaking, high resolution displays, and compelling comprehensive spatial audio, but when we reach out and touch the digital world of an IVE, we’re left holding nothing. In this thesis, I propose a solution to this challenge, redesigning one of the most common VR ecosystems -- Oculus -- to contain cutting edge vibrotactile effects and actuators. The following pages lay out a narrative for a product -- the Oculus inTouch controller -- that balances performance, comfort, immersion and realism; yet remains accessible, flexible, and compelling. More than a product, I introduce an approach -- Interaction Centric Design -- to take haptics from the intangible world of psychophysics, and the nuanced and intricate world of the engineer, placing it within the grasp of the designer. I define a new theory -- Haptic Cuing -- predicated on guiding user behavior through the careful selection of haptic signal to avoid producing haptic noise. Over these next pages, I outline my journey into and through the world of haptics. I explain my process, my theory, and my path to designing what I hope is a foundational piece of haptic interfaces to come.","Virtual Reality; Controller Design; Input Device; Oculus; Haptics; touch","en","master thesis","","","","","","","","2021-08-28","","","","","",""
"uuid:19f64c34-5eae-4f9b-85eb-828a2e190d76","http://resolver.tudelft.nl/uuid:19f64c34-5eae-4f9b-85eb-828a2e190d76","Total least squares method for the purpose of noise reduction in low-cost MRI images","van Zon, Manon (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Electrical Engineering, Mathematics and Computer Science)","van Gijzen, Martin (mentor); Keijzer, Marleen (graduation committee); Heemink, Arnold (graduation committee); Delft University of Technology (degree granting institution)","2019","MRI images are very useful for detecting diseases, as well as for the treatment of diseases. However, MRI scanners are usually too expensive for developing countries to purchase and maintain. Therefore, a less expensive scanner is being developed at Delft University of Technology and Leiden University Medical Center. Unfortunately, the images which are generated by this low-cost MRI scanner are contaminated by noise. The MRI images are determined by solving a system of equations of the form Ax= y, where x is the unknown image. As this system is perturbed, regression methods can be applied in order to find the best approximate value of x. The ordinary least squares method solves this system for perturbations in y. Whereas in the MRI case, it appears that both A and y are perturbed. The total least squares method is often used in order to solve these kind of perturbed systems of equations. The aim of this thesis is to investigate the abilities of this method for the purpose of noise reduction in MRI images. It appears that the total least squares method in combination with regularization operators is able to cancel out a certain amount of noise from the images. However, no significant advantages compared to the ordinary least squares method are found.","Total least squares; MRI images; noise reduction","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:deb34603-00fb-4ac9-b93f-ce052bb49d5e","http://resolver.tudelft.nl/uuid:deb34603-00fb-4ac9-b93f-ce052bb49d5e","Characteristics of Offshore Wind Farm Wakes and their Impact on Wind Power Production from Long-term Modelling and Measurements","Langor, Erin (TU Delft Aerospace Engineering)","Watson, Simon (mentor); Guo Larsen, Xiaoli (mentor); Delft University of Technology (degree granting institution)","2019","As the penetration of offshore wind farms continues to increase in Western Europe, the North Sea in particular is becoming more densely populated by offshore wind farms. Wind turbine wakes have been a topic of great research in the field of wind energy for some time, however the industry now seeks an understanding of the in- fluence of the wake from one wind farm on the performance of a downstream wind farm. Few studies have been conducted to this end. This project will contribute to the greater work of the DTU OffshoreWake project. This master thesis will use 2018 SCADA data provided by the project partner, Vattenfall, meteorological mast data provided by BMWi and PTJ, and the author will conduct and analyse simulations using the Weather Research and Forecasting (WRF) model for the same time period. Additionally, this project will comment on the validity of the wind farm param- eterization sub-models within WRF, and investigate the dependance of wakes on climatological variables and offer a longer term study than previously conducted, therefore giving the possibility of conclusions with greater certainty based on this body of work. It is found that both of the wind farm parameterization schemes (Fitch and EWP) used in this project can reasonable replicate the trends seen in the measured data. The EWP scheme tends to over-predict both gross power produc- tion and mean wind speed, while the Fitch scheme tends to underpredict the same. However, for both schemes, good agreement is found with measurements when the wind speed is accurately predicted. Wind farm wakes are observed in SCADA data and WRF simulations. The magnitude of velocity deficit tends to increase for sea- sons in which atmospherically stable conditions are most frequent. In the region of study, these stable conditions are accompanied by generally lower wind speeds and winds which prevail from the east.","Wind Energy; wake characterization; wakes; WRF; SCADA","en","master thesis","","","","","","DTU Wind Energy-M-0315","","","","","","Aerospace Engineering | Aerodynamics and Wind Energy","OffshoreWake",""
"uuid:f9fffbe3-637b-4161-b654-06c4064a6d35","http://resolver.tudelft.nl/uuid:f9fffbe3-637b-4161-b654-06c4064a6d35","Prosumerism in Oosterwold: Designing a Transitional Practice of Food Growing","Gokçe, Yağmur (TU Delft Industrial Design Engineering)","Giaccardi, Elisa (mentor); Stone, Taylor (graduation committee); Delft University of Technology (degree granting institution)","2019","Imagine a neighborhood where almost all of the decisions are left to its inhabitants; a neighborhood where all of the inhabitants cultivate soil to grow their food for their own consumption, in other words prosumerism*. This newly established neighborhood is Oosterwold which is located in the intersection of Dutch cities Almere and Zeewolde. Oosterwold is specifically designed to include agriculture activites into everyday life of its inhabitants which would enable sustainable ways of living in the area. This project is an attempt to explore the opportunities that prosumerism holds to enable the transition towards sustainability in Oosterwold. It explores and designs for prosumerism in Oosterwold as a means to foster the transition in the area. By framing prosumerism as a social practice and making use of ideas from transition design; the project offers a bottom-up approach to foster sharing and exchange of gardening things in the neighborhood. In order to understand and further design for the elements of prosumerism, the project makes use of both human and thing-centered design research methods. The project advocates that once the needs and desires of prosumers together with the role of gardening tools in the practice are discovered, then it would be possible to design for prosumerism to foster sustainable ways of living. The broader project question of “how can we enable the ongoing transition in Oosterwold through the food growing practices of inhabitants?” is narrowed down to the design goal of “how can we enable community building of prosumers through supporting their meanings of food growing in Oosterwold?”. The project choses sharing, exchanging and collaboration as mechanisms which enable community building in Oosterwold. Through increasing involvement in prosumerism activities and facilitating know-how sharing of individuals about gardening, community building can be reached. The resulted design is DIY Exchange Hubs that are cube-like boxes for Oosterwolders to exchange gardening things like tools, books, seeds and excess produce. The hubs can be built by Oosterwolders with the help of building manual which includes drawings of the pieces, instructions about how to put them together and extended features section that includes tips about coloring and functional differentiation of the hubs. Further, the hubs can be traced and tracked with the mobile application. Through the application, Oosterwolders may see the current status of the hubs, how to make use of the things that are in the hubs and further make a hub building request. *: A made up word which is derived from the combination of “producer” and “consumer”: “prosumer” refers to the ones who grow their own food where “prosumerism” refers to the practice of prosumers.","Transition Design; Community building; Sustainable ways of living; DIY; Thing centric approach","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:87dc488a-cca8-43b2-b4f2-141e95f34b5d","http://resolver.tudelft.nl/uuid:87dc488a-cca8-43b2-b4f2-141e95f34b5d","Mitigation of Ice-induced vibrations of Offshore Wind Turbines by Control Idling","Ali, Irfan (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Civil Engineering and Geosciences; TU Delft Offshore and Dredging Engineering)","Metrikine, Andrei (graduation committee); Hendrikse, Hayo (mentor); Pisano, Federico (graduation committee); Owen, Cody (mentor); Delft University of Technology (degree granting institution)","2019","Offshore wind farms are being developed at locations with moderate ice conditions such as the Baltic Sea, where drifting sea ice upon interacting with offshore structures could lead to the development of a phenomenon known as Ice-induced vibrations (IIV). These vibrations are especially severe when the turbine is idling. Current mitigation measures consist of an expensive solution of ice cones, which are only favourable when ice occurs seasonally. The main objective of this study is to investigate numerically a novel approach to mitigate the ice-induced vibrations of offshore wind turbines by means of control idling.<br/>Three regimes of IIV are generally distinguished, viz. intermittent crushing (ICR), frequency lock-in (FLI), and continuous brittle crushing (CBR). Among these regimes, the ICR and FLI can cause significant vibrations in the offshore structure. Preceding the ice action, the rotor aerodynamics during the parked condition shows that for the wind speeds below the cut-in wind speed of the rotor, the turbine operates in the unsteady aerodynamics termed as dynamic inflow. The comparative analysis is made between the two cases: one with the ice action only, and, the other with the combined effect of ice and wind, where the rotational rotor speeds chosen are 3.0rpm, 6.9rpm and 12.1rpm. In the ice-action case, it is found that the structural response frequency during the ICR and FLI is around the first and the second natural frequency of the structure, respectively. In the case of ice and wind, it is found that the unsteady BEM method has certain limitations, especially in the ICR regime. Also, the aerodynamic damping has no notable effect on the range of IIV regimes for the rotor speed of 6.9rpm and 12.1rpm. However, it does have a significant effect for the rotor speed of 3.0rpm. The quantitative comparison of fatigue damage between the two cases showcases that for the majority of ice-sheet velocities during ICR and FLI, the damage is found to be greater in the ice and wind case. Based on the results, it is concluded that the rotor aerodynamics does help in damping the vibrations in the ICR regime, but in the FLI regime, it has no significant impact when specific ice-drift speeds are considered. It can also be confirmed that by the careful selection of the rotational rotor speed, the range of IIV regime can be influenced. However, to draw the general conclusion, the analysis needs to be conducted for varied ranges of rotor speeds. Also, the present framework of the aerodynamic model needs to be improved to capture the vortex-ring flow state to predict the rotor aerodynamics accurately for all the ice-sheet velocities.","Offshore Wind; Ice-induced vibrations; Control Idling; Fatigue Analysis","en","master thesis","","","","","","","","","","","","Offshore and Dredging Engineering","",""
"uuid:e80e199f-ec65-4578-85cd-aa13273dd2b6","http://resolver.tudelft.nl/uuid:e80e199f-ec65-4578-85cd-aa13273dd2b6","Focal plane phase retrieval using deep convolutional neural networks: A study on the feasibility of phase retrieval in free space optical communications from a single out of focus intensity measurement using a deep convolutional neural network","Noppen, Marko (TU Delft Mechanical, Maritime and Materials Engineering)","Verhaegen, M.H.G. (mentor); Saathof, R. (graduation committee); Delft University of Technology (degree granting institution)","2019","Adaptive optics are widely used to correct the wavefront distortion imposed by atmospheric turbulence. Focal plane phase retrieval from intensity measurements has advantages due to the ease of implementation, potential broader application, less computations, low cost, high system bandwidth, simpliﬁed hardware and less calibration. To cope with the non-linear relation between focal plane intensity and wavefront phase the use of Machine Learning is investigated. A supervised learning deep Convolutional Neural Network is used to assess the feasibility for deriving a direct mapping between a single out of focus CCD intensity measurement and the Zernike modes belonging to it. A model of a typical free space optical communication system is used to asses 13 diﬀerent CNN architectures. The ﬁrst 35 Zernike modes(disregarding tip/tilt) were retrievedfromKolmogorovbasedCCDintensitymeasurementsofsize70x70withconstant amplitude, turbulence strength of 1 ≤ D/r0 ≤ 6, 7 ≤ D/r0 ≤ 12 and 13 ≤ D/r0 ≤ 18 and a SNR of 22dB. The convergence of a 128 channel six layer CNN with kernal size 3 using stride resulted in a mapping providing a residual wavefront error of 5nm, 21nm and 74nm after reconstruction of the wavefront. The results prove that a CNN can be used to map out of focus intensity data directly onto the Zernike coeﬃcients of the wavefront. The CNN is validated by an experimental setup which was used to generate real input and output data. With a turbulence strength of 5 ≤ D/r0 ≤ 15 the mean squared phase error was found to be 72nm. The use of a deep CNN for phase retrieval implementation in free space optical communications is promising and can provide fast and accurate phase retrieval with relatively simple hardware and faster computations.","Machine Learning; convolutional neural networks; phase retrieval; focal plane; Wavefront Sensor; Focus camera; direct mapping; supervised learning; optical communication; free space","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","","52.000913, 4.377319"
"uuid:c35b03b1-72e7-4481-ad20-582302b25af9","http://resolver.tudelft.nl/uuid:c35b03b1-72e7-4481-ad20-582302b25af9","Spanwise wall oscillation as a drag reduction technique: PIV-based evaluation of turbulent skin-friction drag reduction over a flat plate by spanwise wall oscillation","Ujjaini Kempaiah, Kushal (TU Delft Aerospace Engineering)","Scarano, F. (mentor); van Oudheusden, B.W. (mentor); Elsinga, G.E. (mentor); Delft University of Technology (degree granting institution)","2019","Reduction of skin-friction drag over a fully developed canonical zero-pressure gradient turbulent boundary layer (ZPGTBL) subjected to spanwise oscillation is measured using planar particle image velocimetry (PIV). The experiments are conducted at Re<sub>θ</sub> of 1000 and 1800, the chosen range of spanwise oscillations amplitude and frequency are around the optimum reported in literature studies (T<sup>+</sup><sub>osc</sub> = [100-700], A<sup>+</sup><sub>osc</sub>= [50, 150]). A high-resolution planar PIV apparatus is employed to measure the drag reduction directly by wall shear stress estimates on the oscillating wall. The measurement uncertainty of the drag estimates from PIV measurements is examined. The results show drag reduction in the order of 15% after 6 boundary layer thicknesses from the beginning of the oscillating section. Variations of the drag reduction follow the trends reported in literature. The PIV measurements enable the analysis in terms of Reynolds shear stresses, turbulence production and allow visualising vortex packets by vorticity. A pronounced drop of turbulence production in the range y<sup>+</sup> = [5, 30] is observed. The vorticity analysis indicates a distortion from the well-known hairpin-packet arrangement, suggesting that the mechanism of hairpin auto-generation may be inhibited by spanwise wall oscillations","Experimental aerodynamics; PIV; Turbulence; skin-friction; drag; reduction; spanwise wall oscillation","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:c06c3660-df3b-4b4d-b955-33779e26d5d2","http://resolver.tudelft.nl/uuid:c06c3660-df3b-4b4d-b955-33779e26d5d2","The consideration of constrained flow solutions for the purpose of implementing a tidal power plant in the Brouwersdam reconnecting Lake Grevelingen and the North Sea","de Visser, Rolan (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Offshore Engineering)","Jarquin Laguna, A. (mentor); Metrikine, A. (graduation committee); Delft University of Technology (degree granting institution)","2019","After the construction of the Grevelingendam (1965) and Brouwersdam (1971), the tidal movement in Lake Grevelingen disappeared. This caused a deterioration of ecological parameters influencing the surrounding flora and fauna and consequently a decline of the water quality set in. Amongst others, Rijkswaterstaat and the provinces of Zeeland and South-Holland aim to reconnect Lake Grevelingen with the North Sea to infuse oxygen enriched water into the lake and reintroduce an attenuated tide in the lake, thereby improving the quality of the local ecology. To reach the desired water quality, culverts will be installed in the Brouwersdam, thereby restoring the connection between the two water bodies. As part of an integrated approach, Rijkswaterstaat intends to implement turbines into the culverts to not only generate power, but also perform water management. The conclusion from the literature study is that implementation of constrained flow devices, wherein the entire mass flow is guided through the turbine, is preferred as these turbines are able to modulate discharge through the tidal barrage. Moreover, constrained flow devices have a higher theoretical power output than the other considered hydropower methods applicable in a tidal barrage. In order to broaden the insight into the behaviour of the water level in Lake Grevelingen, due to the construction of the tidal barrage, three hydraulic configurations are evaluated wherein input water level data from the North Sea is used to model the tidal variation in the lake while simultaneously estimating the energy output of the system. Considering a culvert array of 18 culverts, measuring 8 m by 8 m, the first considered case takes into account 11 of the culverts equipped with unidirectional turbines, while the remaining culverts are unequipped. The second case involves all 18 culverts with unidirectional turbines, while the third case is set up with 18 bidirectional devices. Additionally, to provide a larger view on the possibilities, a multivariable analysis of the three cases is carried out wherein power generation and water management requirements are considered. Herein varying the cross-sectional area of the culverts and their numbers, though, for the configuration consisting of equipped and unequipped culverts, also the number of empty culverts is varied. From these analyses, one can conclude that installing unequipped culverts and unidirectional turbines in the array will diminish the controllability, whereas bidirectional turbines increase the controllability of the flow which is desirable. Furthermore, full time turbine modulation, wherein the turbines are not generating the optimal amount of power over the full scope of the tidal range for the purpose of water management is preferred over intermittent turbine modulation, wherein turbine modulation only occurs when the water level surpass certain water levels, because the turbines can be altered continuously, which increases the controllability of the discharge. Nevertheless, for the culvert arrays with bidirectional turbines applies that the required values of the monthly averaged and maximum tidal ranges are insufficient. Even though, the water level in Lake Grevelingen does not exceed the overshoot/undershoot boundaries, established by Rijkswaterstaat, the entire vision of water management is only partially fulfilled due to the lack of amplitude in the tidal range. <br/> <br/>The study concludes with the selection of the following culvert array existing of 24 culverts measuring 9 m by 9 m executed with bidirectional turbines. From an economic feasibility study, wherein, amongst other involved parameters, an installed capacity of 36 MW, a market price of electricity of € 0.13 per kilowatt hour for the first 15 years and € 0.049 per kilowatt hour for the second 15 years and a loan period of 15 years, follows a payback period of 15 years and a levelised cost of energy value of € 0.058 per kilowatt hour. <br","Tidal Power Plant; Brouwersdam; Turbines; Water Management; Power generation","en","master thesis","","","","","","","","","","","","Offshore and Dredging Engineering","",""
"uuid:7a0b8590-2b97-4481-8b0d-0b832189ad88","http://resolver.tudelft.nl/uuid:7a0b8590-2b97-4481-8b0d-0b832189ad88","Wall-Modelled Large Eddy Simulation of fully rough non-uniform flow for the purpose of predicting stone stability","NIKOLAIDOU, Lina (TU Delft Civil Engineering and Geosciences)","Uijttewaal, W.S.J. (graduation committee); Hofland, B. (mentor); Bricker, J.D. (graduation committee); O'Mahoney, Tom (mentor); Jacobsen, Niels G. (graduation committee); Delft University of Technology (degree granting institution)","2019","Granular bed protections are a common measure to mitigate scour of the sand bed around hydraulic structures. In view of marching towards cost-effective solutions to tackle erosion-related problems, it is important to accurately predict the loads exerted on the bed and come up with the needed rock grading. To that end, a 3-D eddy resolving modelling technique could help in formulation of a new stability formula, based on extreme local flow conditions It is the aim of this thesis to build a hydrodynamic numerical tool, able to predict governing mechanisms in stone stability. Special attention is paid on the way of representing a rough boundary and predicting wall and free turbulence. That being said, a Wall-Modelled Large Eddy Simulation (WMLES) is suggested and is build using the open-source CFD toolbox OpenFOAM. Firstly, simple open channel flow case simulations are set-up, to evaluate the performance of rough wall functions in the LES environment. Secondly, a backwards facing step kind of flow from the experimental study of Jongeling et. al (2003) is simulated and the performance of the numerical model is evaluated based on the experimental results. Finally, the suitability of this method for the target applications of this study is discussed, including a comparison with previous numerical studies of this research area.","CFD; OpenFOAM; large eddy simulationon; wall modelled large eddy simulation; turbulence modelling; stone stability; flow over fully rough bed; LES; WMLES","en","master thesis","","","","","","","","","","","","Civil Engineering","",""
"uuid:943bb96d-7177-4ddb-99b8-447bbe446964","http://resolver.tudelft.nl/uuid:943bb96d-7177-4ddb-99b8-447bbe446964","Modelling and Demonstration of a Bifacial PV Curtain for Building Applications","Prabhudesai, Sukanya (TU Delft Electrical Engineering, Mathematics and Computer Science)","Isabella, Olindo (mentor); Ortiz Lizcano, Juan Camilo (graduation committee); Zeman, Miro (graduation committee); van den Dobbelsteen, Andy (graduation committee); Delft University of Technology (degree granting institution)","2019","Global energy demand is on the rise. According to the International Energy Agency (IEA), in 2018, the building sector alone constituted 28 % of all energy-related CO2 emissions. In an effort to reduce the carbon footprint of the building sector, the European Union has decreed that every new building from 2021 must be a nearly zero energy building where the low energy for such buildings must come from renewable sources. While this policy works well for new buildings, there needs to be also a solution developed for existing buildings or monumental buildings to be able to easily harness renewable energy, without the need for any major and costly renovation. The concept of a flexible cloth-based solar curtain as a plug and play solution for existing buildings has been explored in the current research, with particular focus on a bifacial (two-sided) design, to assess the significance of the indoor reflected daylight and artificial lights on the rear side power output of such a semi-transparent solar curtain. An optical model representing a basic semi-transparent curtain comprising 70 % cloth of roughly 62 % transparency (based on availability), and 30 % of bifacial solar photovoltaic (PV) minimodules, is prepared as a base case. To validate the optical model, it is replicated on a smaller scale and tested using an identical experimental setup in a controlled environment using a solar simulator. Four cases are prepared for this: the curtain in an empty white-walled room, the curtain in the same room but with some furniture, the curtain in a shorter room with a white rear wall and the curtain in a shorter room with a black rear wall. An analysis of simulation and experimental results shows near likeness between the two with an error margin of 3.3 % for the base case to 10.6 % for the black rear wall case. Slight non uniformity of optical property inputs used in the simulation model and an overestimation of experimentally measured power due to a relatively lower irradiance seen by the reference cell are attributed to this difference. After successful validation of the optical layout, the model is made to scale in simulations to forma PV curtain module of 538.44 Wp DC installed capacity. Using a north-east facing room as reference, an annual simulation is found to give a total DC energy yield of 188.45 kWh or 323 kWh/kWp with a bifacial gain of 8.64 %. 10 hours daily of artificial lighting inside the office is seen to increase the annual DC energy yield by 1.33 %. With an assumption that the curtain remains closed throughout sunshine hours (since it allows diffuse light to enter through its porous cloth), the power output of the curtain is seen to meet modest DC annual load profiles of 57.76 kWh in an office room for 95 % of the year with a 145 Wh lithium ion battery bank and of 48.86 kWh in a residential room for 92%of the year, but with a much higher 290 Wh battery capacity, due to a greater mismatch between generation and demand. A sensitivity analysis for room orientation shows that for a more optimal azimuth of 202.5° (180° being south), the same curtain gives 82%more annual DC yield compared to its current orientation, but at a much lower bifacial gain of 7.8 %. When analyzed for performance in different locations across the world, the curtain intuitively gives the best yield for locations in the southern hemisphere due to its orientation towards the north east. Bifacial gain is nevertheless, most significant for temperate locations where low average annual insolation makes the gain due to bifacial more significant. In cases where the room depth is reduced by half, yield is seen to improve by 2.1 %. Halving the amount of PV in the curtain, improves the bifacial gain by nearly 0.6 % but reduces the annual yield by 49 %. Conversely, doubling the PV in the curtain, results in a dip in bifacial gain by about 3.6 %, but an increase in annual DC power by 87 %. Although this is attractive, such a case must be treated with caution since the likelihood of leaving this curtain (that is now more opaque than semi-transparent) open during sunshine hours is higher. This can result in a lower power output than the base case as well as worse aesthetics. Finally, it is concluded that a bifacial curtain is a beneficial for ‘solarizing’ existing buildings with minimal renovation. The bifacial aspect is best exploited for rooms with sub-optimal azimuths. Nevertheless, to make the most of the PV curtain, it is advised that itmust be placed in shorter rooms with large windows and ideally facing the most optimal direction.","Bifacial; BIPV; Photovoltaic; curtain","en","master thesis","","","","","","","","2019-08-27","","","","","",""
"uuid:0c3beb54-6263-4739-ae37-c589147f1dff","http://resolver.tudelft.nl/uuid:0c3beb54-6263-4739-ae37-c589147f1dff","Interactive learning for multimedia archive exploration","Hammudoğlu, Joren (TU Delft Electrical Engineering, Mathematics and Computer Science)","Liem, Cynthia (mentor); Scharenborg, Odette (graduation committee); Yorke-Smith, Neil (graduation committee); Delft University of Technology (degree granting institution)","2019","Recommender systems are essential for filtering immense amounts of available digital content. As these quantities keep increasing, the impact of recommendations does so as well. In this work, we address negative impacts current state-of-the-art recommenders have. For the algorithmic filtering of items that are recommended to users, collaborative filtering techniques have been shown to give good performance in terms of accuracy. However, at the same time, they suffer from several drawbacks. Beyond the cold-start problem, which causes low recommendation quality for unpopular or newly added items and users, they also risk the creation of filter bubbles. Moreover, they tend to homogenise user preference and they recommend items with low content diversity.<br/>We argue that interactive recommenders can alleviate the problems because they, unlike the state-of-the-art, learn from all user interactions. We propose a method for combining interactive recommenders with the explorative capabilities of multi-armed bandit algorithms, which we use to formulate three explorative content-based recommenders. Using a simulation method, we evaluate them by analysing their accuracy, the diversity of recommendations and user preference, and the change in the distributions of preferences. The results show an increased content diversity, less homogenisation of preferences, and lower susceptibility to the formation of filter bubbles.","Recommender System; Interactive Learning; Multimedia retrieval","en","master thesis","","","","","","","","","","","","","",""
"uuid:19ae2a31-5c22-4da0-9627-352a7e66a6b1","http://resolver.tudelft.nl/uuid:19ae2a31-5c22-4da0-9627-352a7e66a6b1","Repetition counting in videos using deep learning","Batheja, Dhruv (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Gemert, Jan (mentor); Delft University of Technology (degree granting institution)","2019","This work tackles the problem of repetition counting in videos using modern deep learning techniques. For this task, the intention is to build an end-to-end trainable model that could estimate the number of repetitions without having to manually intervene with the feature selection process. The models that exist currently perform well on videos which are stationary but, realistic videos are rarely perfectly static. A series of intermediate experiments are performed to eventually come up with an end-to-end trainable pipeline. Techniques like the University of California Riverside's Matrix profile, bi-directional recurrent neural networks and convolutional neural network architectures that employ dilation are experimented with for the task at hand. For the experiments, a variety of videos from the Qualcomm and University of Amsterdam (QUVA) repetition dataset and the YouTube Segments (YTSegments) dataset are used which both exhibit a good number of non-static videos of real life scenarios like people exercising, chopping vegetables, etc. A proprietary Aircraft inspection dataset which contains repetition of spinning engine blades is also experimented with. The proposed model obtains a lower Mean Absolute Error than the existing deep learning architectures. Finally, the model proposed in this work is able to estimate repetitions on a variety of videos successfully in real time without manual intervention. On the task of repetition estimation, an accuracy of about 60% of correctly labelled frames (with repetitions so far) on unseen test videos is obtained.","Deep Learning; Matrix Profile; Backpropagation; LSTM; TCN; Videos; Python; Pytorch; CNN","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:9ab4f7c5-f6f4-42b4-b9bc-29fc01669523","http://resolver.tudelft.nl/uuid:9ab4f7c5-f6f4-42b4-b9bc-29fc01669523","Phosphate Recovery from Sewage Sludge by Density Concentration","Koomen, Stef (TU Delft Civil Engineering and Geosciences; TU Delft Resource Engineering; TU Delft Resources & Recycling)","Rem, Peter (mentor); Buxton, Mike (graduation committee); Bakker, Maarten (graduation committee); Delft University of Technology (degree granting institution)","2019","Phosphate is removed from wastewater to prevent eutrophication. Chemical phosphorus removal by iron dosing is commonly used for this purpose, where phosphorus is among others bound in the mineral vivianite (Fe(II)3[PO4]2 · 8 H2O). A molar Fe:P ratio of 2.5 in sludge will capture 70-90% of total phosphorus in vivianite after anaerobic digestion, a digestion method which offers ideal conditions for vivianite formation. Vivianite is paramagnetic, enabling it to be recovered by magnetic separation for recycling purposes. Phosphorus recycling from wastewater is of great importance, as in worst-case scenarios, 40-60% of all phosphate rock resources will be extracted by 2100. It is furthermore estimated that in Europe 20-30% of the fertilizer demand can be met by using phosphorus that ends up in sludge in European sewage treatment plants. To reduce processing costs of magnetic vivianite recovery, a pre-concentration step based on density concentration can be introduced, as vivianite particles are denser than organic material in sludge. This research investigated the feasibility of vivianite concentration from digested sewage sludge with a Multotec MX7 spiral concentrator. Spirals are applied in the mining industry for coal washing and pre-concentration of ores which are suspended in water. Particle separation on spirals is based on centrifugal and gravitational forces. Digested sewage sludge is more viscous than water, which affects the separation process on spiral concentrators. To investigate the influence of this high sludge viscosity on the spiral separation efficiency, laboratory experiments were performed. Diluting the sludge furthermore improved the concentration of solids towards<br/>the product flow. However, spiral efficiencies were only 9%, while efficiencies over 80% were found for synthetic sludge, meaning that particle separation was limited. The iron concentration was highest in the product outlet and increased with dilution. The phosphorus content, however, was similar for all outlets and dilutions, suggesting that only Fe minerals other than vivianite, such as siderite and pyrite, concentrated towards the product flow. Additionally, a concentrated bed of sand grains was observed near the column after a dilution of 20%. While diluting the sludge improved the concentration of sand and heavy Fe minerals, it did not induce vivianite concentration.","Phosphorus recovery; Density concentration; sewage sludge; Vivianite","en","master thesis","","","","","","","","2024-08-27","","","","","",""
"uuid:76aa9898-7edd-486c-969b-4e9425f51946","http://resolver.tudelft.nl/uuid:76aa9898-7edd-486c-969b-4e9425f51946","Towards Decentralised Energy Systems: An Analysis of the Distribution of Tasks to Safeguard Essential Energy Sector's Public Values","Yosira Ayu Jawata, Yosi (TU Delft Technology, Policy and Management)","Doorn, Neelke (mentor); Cuppen, Eefje (mentor); Warnier, Martijn (mentor); Galeano Galvan, Maria (graduation committee); Delft University of Technology (degree granting institution)","2019","","Decentralised energy system; public values; distribution of tasks","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:1cb58d76-a194-4a2f-b554-c172a8d3d78a","http://resolver.tudelft.nl/uuid:1cb58d76-a194-4a2f-b554-c172a8d3d78a","Fetal cardiovascular simulations to assess the feasibility of intrauterine ECMO","Wachter, Esther (TU Delft Mechanical, Maritime and Materials Engineering)","Dankelman, Jenny (mentor); Goos, Tom (mentor); Kok, Manon (graduation committee); Delft University of Technology (degree granting institution)","2019","The placenta is very important during the start of life, providing the fetus with oxygen and nutrients from the maternal blood. Impaired growth of the placenta and additional placental ischaemia endangers the exchange of gasses, exchange of nutrients, and optimal growth of the fetus. This thesis investigates the feasibility of intrauterine ECMO to improve oxygen levels in fetal blood during placental ischaemia. Fetal blood would be retrieved from the umbilical artery, oxygenated in the ECMO system and fed back into the umbilical artery. The objective of this thesis is to design a cardiovascular model to simulate the cardiovascular response to an ECMO support system. A lumped parameter model is created to approximate the fetal cardiovascular system. By performing a parameter search, haemodynamic parameters were gathered for the fetal model. Data from 30 week fetuses was used as initial input, because of parameter accessibility. Parameters for the gestational age of 20 to 29 weeks were obtained by extrapolating the parameters from the fetus of 30 weeks with scaling factors. A sensitivity analysis was performed to analyse the flow and pressure distribution through the fetal cardiovascular system and the cardiovascular response to different parameters. Implementation of a cannula into one of the umbilical arteries increases the resistance of that artery. Simulating the cardiovascular response to the addition of the cannula showed promising results for the feasibility of intrauterine ECMO. The fetal heart is able to maintain blood flow through the cannula despite the fact that the resistance of the artery is increased. The placental resistance increases during placental ischaemia. Because of this higher resistance, blood flow through the placenta will decrease. However, even at a lower flow rate, oxygenation of blood flow via the umbilical artery is mostly sufficient. The reason is the high percentage of fetal cardiac output flowing through the placental circulation. The designed model is able to simulate the fetal cardiovascular system and provides a simulation tool to further develop an intrauterine ECMO support system.","placental ischaemia; ECMO; lumped parameter model; fetal cardiovascular system","en","master thesis","","","","","","","","","","","","","",""
"uuid:7a03c82a-30a4-4f9a-b6df-2566a2f943d3","http://resolver.tudelft.nl/uuid:7a03c82a-30a4-4f9a-b6df-2566a2f943d3","Arenga Rainforest Sugar: Designing a tool to enhance the experience of the Arenga Rainforest Sugar for coffee bar guests","Kohler, Klara (TU Delft Industrial Design Engineering)","Schifferstein, Rick (mentor); Barati, Bahar (mentor); Delft University of Technology (degree granting institution)","2019","Forestwise wanted a suitable way to serve their Arenga Rainforest Sugar in Dutch cafés. This brown sugar comes from Indonesia and is a tasty, healthy and sustainable alternative to regular sugar. It is wild-harvested from the Arenga palm tree, which grows naturally inside the jungle. The Arenga sugar provides the local farmers with an income from their existing forests and motivates them to halt deforestation and protect biodiversity. This background story should be communicated to end-consumers. <br/><br/>The first analysis phase consists of research about the sugar’s source, the context of use, and the sugar’s characteristics. Applying the Material Driven Design method stimulates to not take the granulated, brown Arenga sugar as given, but play with texture, shape and process to find a more suitable way to serve it. <br/><br/>Synthesizing the insights into a Material Experience Vision and Design Criteria leads to a variety of ideas, categorised into 9 design directions. From those, 3 concepts are worked out. The stencil shaker concept makes use of the dark colour of the sugar and puts a surprise illustration, depicting the rainforest’s biodiversity, on the milk foam of the café guest’s drink. The rainforest globe concept is a decorative, round sugar pot from glass, depicting the eco-system of the Arenga tree and the rainforest. The selected concept of the sugar block grater lets the user transform traditional, hard sugar blocks into flakes. <br/><br/>A more specific vision is defined to develop this concept. The metaphor of a opening flower bud describes the desired user experience. The sugar should be perceived as natural and special. It is furthermore desired to let the café guests explore the background story of the sugar and get actively involved in it, feeling curiosity, pleasant surprise and virtuousness. <br/><br/>The final design proposal is a grater made out of bamboo, which is placed on the café’s tables. It is filled with cylindrical sugar blocks with chocolate-like texture. The café guest can grate sugar flakes by rotating the base of the grater. A mechanism turns and pushes the sugar blocks against a knife with two blades, shaving off a layered spiral of flakes. <br/><br/>The sugar comes out at the top of the grater in the shape of a flower. The user can observe the sugar “growing” inside an illustration of the rainforest, which is engraved in the bamboo around. This lets the user experience how the sugar naturally grows inside the biodiverse rainforest in Indonesia, contrary to being cultivated in monoculture plantations. The background story of the sugar is illustrated with engravings on the outside of the greater, showing how the sugar is wild-harvested and processed. The café guests become part of the process by grating their own sugar flakes to sweeten their drinks. This drives a sustainable system of rainforest and local farmers. The sugar is presented as special and natural, in an attractive and novel way. <br/><br/>The concept is tested with a working prototype and evaluated by users and cafés.","Integrated Product Design; Sustainability; Experience; Sugar; Material Driven Design; Food Design","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:5028e05e-661f-4791-9d1f-e50d877aa24f","http://resolver.tudelft.nl/uuid:5028e05e-661f-4791-9d1f-e50d877aa24f","Human Activity Recognition using a Deep Learning Algorithm for Patient Monitoring","Friđriksdóttir, Esther (TU Delft Mechanical, Maritime and Materials Engineering)","French, Paddy (mentor); Bonomi, Alberto (mentor); Hunyadi, Bori (graduation committee); Delft University of Technology (degree granting institution)","2019","Physical activity and mobility are important indicators of the recovery process of patients in the general ward of the hospital. Currently, monitoring mobility of hospitalized patients relies largely on direct observation from the caregivers. Accelerometers have the potential to quantify physical activity of patients objectively and without obstructing their daily routines. Human Activity Recognition (HAR) is a technique used to assess the type of activity an individual subject is carrying out based on sensor readings and has been extensively studied. However, the literature shows that HAR methodologies have been largely developed to recognize activities typical for healthy subjects. This means that activities performed at a slow and irregular pace, such as by a symptomatic patient or an elder, are scarcely considered to design HAR methods. Using HAR for patient monitoring would allow clinically meaningful metrics, such as time spent ambulating or in sedentary behaviour each day, to be obtained automatically. This may offer a convenient solution to enable caregivers automatically monitoring the recovery process of patients. <br/><br/>The aim of this work was to develop an accurate HAR model to recognize activities typical for hospitalized patients. A data collection study was conducted with 20 healthy volunteers in a simulated hospital environment. A single triaxial accelerometer placed on the trunk was used to measure body movement and recognize seven activity types: Lying in bed, upright posture, walking, walking with walking aid, wheelchair transport, stair ascent and stair descent. Features from both time and frequency domain were extracted and used to train three machine learning (ML) classifiers (Naïve Bayes, Random Forest, Support Vector Machine). Additionally, a deep neural network (DNN) consisting of a three convolutional layers and a Long Short-Term Memory layer was developed. <br/><br/>The performance of the DNN model was evaluated on holdout data and compared to the performance of the feature-based ML classifiers. The DNN model reached a higher classification accuracy than the latter approaches (F1-score= 0.902 vs. 0.821). All the models showed a large number of misclassification between the walking with or without walking aid class. By combining these two classes the DNN model reached an F1-score 0.946, compared to F1-score 0.856 of the best feature-based ML approach represented by a support vector machine classifier. <br/><br/>This work shows for the first time the value of applying deep-learning techniques to improve the accuracy of feature-based ML classifiers for addressing the problem of HAR using a single triaxial accelerometer in simulated hospital conditions.","Human Activity Recognition; Machine Learning; Deep Learning; Accelerometer; Classification; Patient Monitoring","en","master thesis","","","","","","","","2024-08-27","","","","","",""
"uuid:56a2f8d7-fb26-40f0-bb92-00271f9492df","http://resolver.tudelft.nl/uuid:56a2f8d7-fb26-40f0-bb92-00271f9492df","Optimizing the gradient ring of a low-field MRI scanner","Meijer, Angeline (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Applied Sciences)","van Gijzen, Martin (mentor); van Dongen, Koen (mentor); Delft University of Technology (degree granting institution)","2019","This report describes the study on the optimization of the magnetic field generated by a low-field magnetic resonance imaging modality. In the optimization the Genetic Algorithm and a quasi-Newton Algorithm are used.","Optimization; MRI; low-field; Magnetic field; Gradient ring","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics | Applied Physics","Low-Field MRI",""
"uuid:9e53edd5-1c52-48d7-bc97-f9a3bd7b681e","http://resolver.tudelft.nl/uuid:9e53edd5-1c52-48d7-bc97-f9a3bd7b681e","From Product to Product-Service System: The Demarcation of Producer Responsibilities in the Transition from Linear to Circular Service System","Holländer, Margot (TU Delft Architecture and the Built Environment; TU Delft Architectural Engineering +Technology)","Klein, Tillmann (mentor); van den Ham, Eric (mentor); Delft University of Technology (degree granting institution)","2019","Context - In the construction industry of today, buildings are seen as finished products rather than ongoing processes. The business model of facades as a product service system is a promising strategy to change these practices. A pilot project at Delft University of Technology sparks the interest of Alkondor Hengelo, to explore their tasks and responsibilities as pioneers in this new way of supplying facades. Suppliers would retain the ownership of a leased PSS façade and guide a project through its entire service life and beyond, managing materials in a circular way. The two main challenges were identified as 1. Going from a linear model to circularity, and 2. The ongoing involvement in a PSS instead of handing over their product. The first steps of implementing the façade leasing model have been taken, however the full strategy yet needs to be outlined, to understand how value is added for suppliers and clients and where technical barriers are found.<br/><br/>Objective - Ideally, a PSS would optimize façade performance and provide all services that are needed to do so. This adds value for the client and creates a steady source of income for the supplier. As the pathway to a full PSS is best approached in smaller steps, it should be defined: What set of tasks would the façade supplier take on in a basic stage of servitization, and what could be added on to form a more advanced service agreement? For façade suppliers, it is important to make the best use of the investment into their product, as they would not only be acting as producers, but also operate and safeguard the product and its performance throughout the entire cradle-to-cradle life cycle. Therefore, it should be designed for optimal operation and output during use, and designed for circularity, to achieve a high residual value after the first use. Different design criteria and considerations are therefore given, as a reference for future designers of circular facades as PSS.","Facade; Circular facades; Product-Service System; Façade Leasing; Reusable Facades","en","master thesis","","","","","","","","","","","","","",""
"uuid:b1059caf-8eee-48d8-8a78-c14d3b0d7db3","http://resolver.tudelft.nl/uuid:b1059caf-8eee-48d8-8a78-c14d3b0d7db3","Automated FPGA Hardware Synthesis for High-Throughput Big Data Filtering and Transformation: An SQL query transpiler targeting Vivado HLS C++ tools for high-level stream transformation and filtering on FPGAs using Apache Arrow.","de Haan, Erwin (TU Delft Electrical Engineering, Mathematics and Computer Science)","Al-Ars, Zaid (mentor); Hofstee, Peter (graduation committee); Rellermeyer, Jan (graduation committee); Peltenburg, Johan (graduation committee); Delft University of Technology (degree granting institution)","2019","Despite its advantages in performance and control, hardware design is mainly bottlenecked by high design complexity and long development time. This thesis explores the use of domain specific languages for high-level synthesis (HLS) of hardware data filters and transformations.<br/>The main goal of this thesis’ prototype is automating the transpiling of SQL to HLS C++ to generate hardware for filtering and data streams using CAPI on POWER systems. This work uses the Fletcher framework to automate the handling of data movement between memory and the field-programmable gate array (FPGA). The use of HLS technologies can greatly reduce the development time of FPGAs compared to manual FPGA development workflows. Deploying FPGAs in fast changing data processing pipelines, can be very complicated or limit the use of the FPGA hardware. This work investigates if HLScan be used for these kinds of applications to reduce total development time while still maintaining performance. Additionally, the use of the Fletcher framework further reduces required developer time. The proof-of-concept shows that it is possible to efficiently use HLS for data filtering and transformations. And that without a significant effort from the designer, usable designs and filters can be generated. For example some of the simpler kernels can reach upwards of 1 GB/s while using less than 1 % of a Xilinx Kintex UltraScale XCKU060 FPGA. By using multiple instances of these kernels the design can saturate the system bandwidth. Though this approach is not without issue, it does lend itself to extending the tool and some extra development effort to improve the current proof-of-concept.<br/><br/>The project code is released under Apache 2.0 license on GitHub at: https://github.com/EraYaN/FletcherFiltering.","FPGA; HLS; SQL; compiler; automated; python","en","master thesis","","","","","","","","","","","","","",""
"uuid:4e95d861-9e4b-4f54-96b6-ce82f92f7995","http://resolver.tudelft.nl/uuid:4e95d861-9e4b-4f54-96b6-ce82f92f7995","Orthogonality relations of q-Meixner polynomials: with the use of spectral analysis","van Doesburg, Chiel (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Analysis)","Groenevelt, Wolter (mentor); van Neerven, Jan (graduation committee); Kraaikamp, Cornelis (graduation committee); Delft University of Technology (degree granting institution)","2019","Orthogonality relations of q-Meixner polynomials, polynomials in terms of basic hypergeometric series, will be proved by using spectral measures and a difference operator.","q-Meixner polynomials; spectral analysis; Orthogonality relations","en","master thesis","","","","","","","","","","","","","",""
"uuid:6e8fbe1d-55a9-4389-b32a-842ce9c4bedd","http://resolver.tudelft.nl/uuid:6e8fbe1d-55a9-4389-b32a-842ce9c4bedd","African Market: Entry for a Trypanosomiasis Diagnostic Device","Bautista Gauna, Paola Montserrat (TU Delft Industrial Design Engineering)","Diehl, Jan-Carel (mentor); Brouwer, Willemijn (mentor); Vendel, Mirte (mentor); Delft University of Technology (degree granting institution)","2019","This report is the result of a graduation project in the domain of the Africa Market Entry for a Trypanosomiasis Diagnostic Device. The project aims to find promising ways to bring to the market a portable diagnostic device for Trypanosomiasis, developed by the company Aidx Medical BV. The context of T. African Animal Trypanosomiasis (AAT) is a vector-borne parasitic disease. It is caused by infection with protozoan parasites belonging to the genus Trypanosoma. They are transmitted to animals &amp; humans by tsetse fly bites which have acquired their infection from parasitaemic mammalian host. AAT is a major constraint to socio-economic development in Africa. AAT has significantly reduce productivity in over 150 million cattle and 260 million sheep and goats (Jahnke, Tacher, Kiel, &amp; Rojat, 1988), and it is estimated to cause annual losses of more than US$ 4.5 billion dollars through direct and indirect agricultural production losses (Yaro, Munyard, Stear, &amp; Groth, 2016). There are many barriers that complicates the access of trypanosomiasis (T) diagnostics and treatment such as lack of confirmatory test, large distances, limited trained staff and lack of laboratories facilities. The diagnosis of T is notoriously difficult, because the clinical signs are similar to other cattle diseases. Likewise, the only way to confirm a diagnosis is to demonstrate and identify parasites in body fluid. The current diagnostic practices require staff with strong proficiency and expertise, which the limits the reliability of the test. In addition, diagnostic technique for routine veterinary purposes is only suitable if it is cost-efficient. Therefore, there is a need for the new diagnostic test requiring minimum training, inexpensive and should provide rapid and reliable results. Business Modeling According to the research, the device had a strong value proposition on the market. Several business model prototypes were created and tested in a field trip to Uganda. In the field trip, it was discovered that the current technique of introducing medical devices (ex. microscopes) and drugs was through an intermediary. This intermediary may be a chain of pharmacies or a device seller that needs to be certified by the government to distribute and sell the devices or drugs. The intermediary takes also charge of the promotion and distribution of the product. The business model prototypes were redesigned with the new set of information. After an evaluation with the company, the most promising scenario was selected according to their aim, strengths and weakness. The main value of the company is to develop and manufacture an automatic diagnostic device for thick bone diseases that an unprofessional person can do a rapid and reliable diagnosis on the field. The customer segment is the government, because they are the largest employer in veterinary services delivery. The distribution channel will be through intermediaries, because they have a deep understand of the local market. As well, the company does not need a large capital investment on developing a distribution channel. The main revenue would be through asset sale of the diagnostic devices. The business model helped to outline the most important concepts of the company. Market Entry Strategy The business model helped to outline the important concepts of the company. Thereafter an International Market Entry was planned. This entailed the entry location (EL), entry timing (ET), and entry mode (EM). As it was previously explained, Aidx Medical BV will be the first mover and focused on a niche market on automated diagnostic device for veterinary health. Finally, the entry mode selected was indirect exports, meaning the company will sell the device through an intermediary. Finally, the strategy is described with the concept of 4P Marketing Mix (Mullins &amp; Walker Jr., 2013)which includes product, price, place and promotion in conjunction the international entry market and the business model to ensure that the action plans within all are complimentary and aligned.","Business Model Canvas; Market Entry Strategy; 4PS Marketing Mix; African Market; Trypanosomiasis; Neglected Tropical Disease","en","master thesis","","","","","","","","","","","","Strategic Product Design","","1.37330, 32.29030"
"uuid:3003d5d6-810a-40b4-8e5d-e41fc61fa17f","http://resolver.tudelft.nl/uuid:3003d5d6-810a-40b4-8e5d-e41fc61fa17f","Inter- and intra-driver variability in lane change behaviour","Koppel, Christiaan (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Cognitive Robotics)","Petermeijer, Bastiaan (mentor); Abbink, David (mentor); Delft University of Technology (degree granting institution)","2019","Lane change manoeuvres are known to vary widely in lane change duration. This is thought to be an effect of the surrounding vehicles and personal preference of drivers. However, little is known about the effect on steering behaviour during a lane change manoeuvre. Moreover, the relation of the effect of traffic to inter- and intra-driver variability is unknown. This study focuses on quantifying inter- and intra-driver variability in lane change duration and steering behaviour during lane changes in two different traffic scenarios. In an exploratory study, 21 participants drove 30 lane change manoeuvres in a 6 DoF moving base driving simulator. Two scenarios were used: a closing gap in the target lane and a constant gap in the target lane, with 15 repetitions per scenario. The results show high inter-driver and intra-driver variability, for both lane change duration (M=6.34 s SD-inter=0.90 s SD-intra=1.26 s) and steering behaviour (e.g. maximum steering wheel angle M=4.14 deg SD-inter=1.62 deg SD-intra=1.34 deg). The effect of the scenario was not significant for lane change duration and maximum steering wheel angles. Additionally, it was shown that lane change duration only has a medium correlation with the maximum steering wheel angle (Pearson R(585)=-.48, p\textless0.001). Furthermore, the mean and variability of the lane change duration decreased when lane changes were initiated with a shorter distance to the slow lead vehicle. Concluding, the lane change duration does not fully determine steering behaviour during a lane change, making it an unsuitable metric for determining human-like lane change trajectories. It is therefore proposed to create trajectories based on steering behaviour. It seems that drivers exhibit high variability in lane change behaviour when spatio-temporal criticality with respect to traffic is low. Higher spatio-temporal criticality limits the mean and variability of the lane change duration. Future work should determine whether this variability is the result of driver preference or indifference. Additionally, future work should implement and test human-like lane change trajectories based on steering behaviour as opposed to lane change duration.","Lane change manoeuvre; Driving simulator; Driving behaviour; Human-like driving","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Vehicle Engineering","",""
"uuid:87d1d976-a0ba-40d2-8fa4-437bd65c5b91","http://resolver.tudelft.nl/uuid:87d1d976-a0ba-40d2-8fa4-437bd65c5b91","Transverse 3D Electrical Properties Tomography","An, Xin (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Circuits and Systems)","Remis, Rob (mentor); Delft University of Technology (degree granting institution)","2019","MR-based Electrical Properties Tomography (EPT) is a medical imaging modality to reconstruct the electrical conductivity and permittivity inside the human body based on the magnetic field data obtained from an MRI system. Currently, 2D CSI-EPT implementation is able to generate reliable reconstructions under special assumption of electromagnetic fields, while 3D implementation of CSI-EPT is able to achieve accurate reconstruction. However, much effort is needed to reduce computational cost for practical application in a MRI setting. Several experiments show that the radiofrequency(RF) fields on the midplane of an birdcage RF coil is E-polarized. In this study, we assume that RF field is E-polarised in the midplane of the RF birdcage coil and no other field assumptions are imposed. The electromagnetic fields relations governed by Maxwell’s equations in the birdcage RF coil are simplified by the negligible<br/>transverse electric fields into two equations, referred to as midplane equations. In order to find the parameters that satisfy the midplane equations, an objective function is created by evaluating the difference between the measured and modeled data. A novel alternating-direction iterative method is proposed for minimizing the multivariate objective function where the electrical properties of biological tissues are retrieved in an iterative ’fix-one-optimize-for-the-other’ way. Within each iteration, a two-step procedure is conducted by updating electric field parameter and dielectric parameter in turn. Three different optimization algorithms are implemented for updating the electric field parameter. The magnetic fields data for numerical simulations are generated by placing a male head model or a longitudinal uniform head model inside<br/>a simulated magnetic resonance scanner. The proposed methods are demonstrated by reconstructions from the simulated data, which are in good agreement with true electrical properties values.<br","Electrical Property Tomography; Optimization; Alternating Direction Method","en","master thesis","","","","","","","","2024-08-27","","","","","",""
"uuid:bd090309-305e-4c04-93b7-64f1b79df8d4","http://resolver.tudelft.nl/uuid:bd090309-305e-4c04-93b7-64f1b79df8d4","Machine Learning of Atmospheric Turbulence in a Variational Multiscale Model","Janssens, Martin (TU Delft Aerospace Engineering)","Hulshoff, Steven (mentor); Dwight, Richard (graduation committee); Chen, Boyang (graduation committee); Delft University of Technology (degree granting institution)","2019","Today's leading projections of climate change predicate on Atmospheric General Circulation Models (GCMs). Since the atmosphere consists of a staggering range of scales that impact global trends, but computational constraints prevent many of these scales from being directly represented in numerical simulations, GCMs require ""parameterisations'' - models for the influence of unresolved processes on the resolved scales. State-of-the-art parameterisations are commonly based on combinations of phenomenological arguments and physics, and are of considerably lower fidelity than the resolved simulation. In particular, the parameterisation of low-altitude stratocumulus clouds that result from small-scale processes in sub-tropical marine boundary layers is widely considered the largest source of uncertainty that remains in contemporary GCMs' prediction of the temperature response to a global increase in CO2. Improvements in the capacity of machine learning algorithms and the increasing availability of high-fidelity datasets from global satellite data and local Large Eddy Simulations (LES) have identified data-driven parameterisations as a high-potential option to break the deadlock. However, early contributions in this field still rely on inconsistent multiscale model formulations and are plagued by instability. To sketch a clearer picture on the sources of the accuracy and instability of data-driven parameterisations, this work proposes a framework in which no assumptions on the model form are made, building on recent work at the TU Delft. It uses Artificial Neural Networks (ANNs) to infer exact projections of the unresolved scales processes on the resolved degrees of freedom. These ``interaction terms'' naturally arise from Variational Multiscale (VMS) model formulations. The resulting VMM-ANN framework limits error to the data-driven interaction term approximations, offering explicit insight into their functioning.<br/>The model is assessed in the context of a statistically stationary convective boundary layer turbulence problem, which is further reduced to a one-dimensional, forced inviscid Burgers' equation. Simple, feedforward ANNs with relatively local input stencils that are trained on error-free data a priori to inserting them in forward simulations (offline) are capable of predicting the interaction terms of this problem much better than traditional, algebraic VMS closures in offline settings at various levels of discretisation; they also generalise well to uncorrelated instances of the turbulence. However, this performance does not translate to simulations of forward problems. It is shown that the model suffers from instability due to i) ill-posed nonlinear solution procedures and ii) self-inflicted error accumulation. These correspond to two dimensions of forward simulations that are not accounted for by offline training on error-free data. The first instability mode can be dealt with by reformulating the VMM-ANN model architecture; the second is conjectured to demand training strategies that account for the self-induced errors. Finally, despite scaling well, the framework is still found to be comparatively computationally expensive. In all, appreciable challenges therefore remain in order to capitalise on the promise offered by ANNs to improve the parameterisation of clouds in GCMs in particular and turbulence in general.","machine learning; variational multiscale method; turbulence modelling; convective boundary layer; artificial neural networks","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:02f02df5-ac55-4ff8-8345-e262b887a8ae","http://resolver.tudelft.nl/uuid:02f02df5-ac55-4ff8-8345-e262b887a8ae","Strength influencing parameters of iroko glued laminated timber","Hüpscher, Juval (TU Delft Civil Engineering and Geosciences)","van de Kuilen, Jan-Willem (mentor); Ravenshorst, GJP (graduation committee); Hoogenboom, Pierre (graduation committee); Delft University of Technology (degree granting institution)","2019","As timber is being used for several millennia as construction material, glued laminated timber (glulam), a highly engineered timber product, exists for about hundred and fifty years. In Europe, it is nowadays common practise to make glulam from softwood species, though in the last few decades glulam made from different kinds of hardwoods emerged. Iroko glulam is part of this development, as iroko is a hardwood species from the African tropical regions. The aim of this thesis is to investigate the bending strength of iroko glulam, as well as strength influencing features. From literature it is expected that the following features are of influence: density, modulus of elasticity, tension strength of the lamellas, finger joint strength and size. Several researches conducted in the past experiments to determine these mechanical and physical properties, focusing mainly on iroko sawn timber. Only few investigated iroko glulam, and none of those focused on finger jointed iroko glulam. In this lies the originality of this work: determining bending strength values of finger jointed iroko glulam, as well as density, modulus of elasticity and investigating mechanical and physical properties of the base material: iroko sawn timber and iroko finger joints. The laboratory experiments included the following: tension tests on 38 unjointed and 38 finger jointed lamellas, and four point bending tests on 12 glulam beams. Also density, modulus of elasticity and moisture content were determined. The experimental results yield the following characteristic values: a lamella tension strength of 17 N/mm2, a finger joint tension strength of 29 N/mm2, and a glulam bending strength of 42 N/mm2 (including size effect according to NEN-EN 1995, 2011). The experimentally determined characteristic lamella tension strength is a little lower than values found in literature. This is due to a large scatter in the test results: a coefficient of variance equal to 0.37 was found. However, if the grain angle is equal or smaller than 5°, a higher lamella tension strength of 27 N/mm2 is feasible. Grain angle is as expected a significant strength influencing parameter for iroko sawn timber. And it would suggest that the strength class is as expected D40 if the lamella bending strength equals 0.6 divided by the lamella tension strength. The ratio of finger joint bending strength (30 N/mm2) and tension strength (29 N/mm2) on the characteristic level was found to be equal to 1.06. This is smaller than expected from theory: apparently the 1.4 ratio commonly assumed for softwood finger joint strength values does not hold for iroko finger joint strength values. The investigated iroko glulam beams with depth 108 mm yielded a mean bending strength of 66 N/mm2 and a characteristic bending strength of 42 N/mm2. Due to the size effect and quasi-brittle failure this figures lie lower for full scale glulam beams, however, strength class GL24h is indeed a safe assumption for iroko glulam beams. These aspects explain the higher mean glulam bending strength compared to the mean finger joint tension strength of 40 N/mm2. A strong mathematical relationship between characteristic glulam bending strength and both lamella tension strength and finger joint strength was not found; however lamella and finger joint tension strength do influence the glulam bending strength. Furthermore, density does not influence any strength or stiffness property for both iroko sawn timber, finger joints, and glulam beams. Although there is a slight positive correlation with both dynamic and local modulus of elasticity of lamellas and its tension strength.","Timber; Glulam; Iroko","en","master thesis","","","","","","","","","","","","Civil Engineering","",""
"uuid:bd9494cf-a761-438a-9be5-8e07b4606861","http://resolver.tudelft.nl/uuid:bd9494cf-a761-438a-9be5-8e07b4606861","Axiomatic Projective Geometry","Haakma, Emiel (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Analysis)","Vermeer, Hans (mentor); Hart, Klaas Pieter (graduation committee); van Elderen, Emiel (graduation committee); Delft University of Technology (degree granting institution)","2019","Starting with the three axioms of projective geometry, this paper explores concepts such as perspectives, projective maps, and harmonic additions that are unique to this geometry. In addition, important theorems such as Pappus's Theorem, Desargue's Theorem, and the Fundamental Property are mentioned and worked with extensively.","Geometry; Projective; Axiomatic; Perspective; Pappus; Desargue","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:659ae557-c376-40aa-a650-dd35798c9738","http://resolver.tudelft.nl/uuid:659ae557-c376-40aa-a650-dd35798c9738","Feasibility study of product-service system model for cradle-to-cradle products","Soni, Gaurav (TU Delft Technology, Policy and Management)","Scholten, Victor (mentor); Quist, Jaco (graduation committee); Delft University of Technology (degree granting institution)","2019","This thesis report helps to identify which business strategies can make product-service systems a feasible business model for cradle-to-cradle certified products. Cradle-to-cradle is a product certification that highlights the material re-utilization and material health of any products. Product-service systems are the business models that combine the provision of products along with related services, to ensure better and responsible handling of the products, even after selling the products. In this report, the products in focus are the cradle-to-cradle certified products. In the end, eight business strategies are generated, which can be theoretically successful for the adoption of product-service system model for cradle-to-cradle products.","Product Service System; Cradle-to-cradle; Circular economy; Sustainable business models; business strategies","en","master thesis","","","","","","","","","","","","Management of Technology","",""
"uuid:0f6d733f-f66b-4313-b3a5-554457238812","http://resolver.tudelft.nl/uuid:0f6d733f-f66b-4313-b3a5-554457238812","Online Reinforcement Learning Control of an Electromagnetic Manipulator","Valentini, Carlo (TU Delft Mechanical, Maritime and Materials Engineering)","Babuska, Robert (mentor); de Bruin, Tim (mentor); Kober, Jens (graduation committee); van den Boom, Ton (graduation committee); Delft University of Technology (degree granting institution)","2019","Machine Learning Control is a control paradigm that applies Artificial Intelligence methods to control problems. Within this domain, the field of Reinforcement Learning (RL) is particularly promising, since it provides a framework in which a control policy does not have to be programmed explicitly, but can be learned by an intelligent controller directly from real-world data, allowing to control systems that are either arduous or even impossible to model analytically. However, in spite of such considerable potential, the RL paradigm poses a number of challenges that effectively hinder its applications in the real-world and in industry. It is therefore critical that research in this field is advanced until RL-based controllers can be practically demonstrated to be real-world feasible and reliable. This thesis report presents the attempts made at applying control strategies based on Reinforcement Learning to solve a precise positioning task with a physical experimental setup. The setup at hand is a magnetic manipulator (magman) characterized by a high degree of nonlinearity. The controller uses the spatially continuous magnetic field generated by four actuators to displace a steel ball, constrained to move in one dimension, towards a reference position. Two different implementations of the Q-learning algorithm (Sutton, Barto, et al., 1998) were deployed. In spite of the good results obtained in a simplified simulated environment, both implementations failed on the experimental setup. The negative outcome of these experiments is mainly due to the fact that, since the task at hand is an accurate positioning task, the reward obtained by the learner while interacting with the environment is too sparse for it to be able to learn a stabilizing control policy. Other factors have presumably contributed to the controllers’ failure, such as the circumstance that the agent does not have access to the full system state information and a sub-optimal tuning of the algorithms’ hyper-parameters. Besides model-free RL, the Value Iteration model-based method was successfully applied both in simulations and with the experimental setup. The present findings suggest that, in order to solve the magman task with model-free RL, more sophisticated algorithms need to be deployed, such as for example an agent that can naturally deal with continuous state and action spaces, as the DDPG algorithm (Lillicrap et al., 2015), with exploration carried out in the parameter-space rather than in the control action space (Plappert et al., 2017), in addition to a more optimal exploitation of the information extracted from the environment, for example using Hindsight Experience Replay (Andrychowicz et al., 2017).","Machine Learning Control; Reinforcement Learning; Magnetic manipulator; Magman","en","master thesis","","","","","","","","","","","","","",""
"uuid:339a9cca-7a68-4888-b1bf-a308f9fd0403","http://resolver.tudelft.nl/uuid:339a9cca-7a68-4888-b1bf-a308f9fd0403","New ships, new rules: Assessment of the Required Subdivision Index for Unmanned Ships based on Equivalent Safety","de Vos, Jiri (TU Delft Mechanical, Maritime and Materials Engineering)","Hekkenberg, Robert (mentor); Kana, Austin (graduation committee); Schreier, Sebastian (graduation committee); van Gelder, Pieter (graduation committee); Delft University of Technology (degree granting institution)","2019","The research effort on autonomous ships has increased over the last years. The realisation of these ships will have as a consequence that the crew can be reduced significantly or even be removed entirely, resulting in unmanned ships. Although there is a strong belief that unmanned ships would lead to more economic efficiency, only limited research has been performed in order to demonstrate what the overall effect of the change to unmanned shipping would have on transport costs. Nonetheless, more reductions in cost or improvement of transport performance for unmanned ships would make them more attractive and economically viable. <br/>The design of a ship is subjected to regulations and requirements that limit the design freedom, but it increases safety. Removing the crew from the ship reduces the risk of shipping, under the assumption that the probability that an incident occurs does not change, since the lives of the crew are no longer at risk. If the risk is lower, the requirements to the design of unmanned ships might become less strict, while maintaining equivalent safety. In this way more design freedom can be realised for unmanned ships, as well as more economic efficiency.<br/>Within this report the required subdivision index will be evaluated, for it is expected that reducing this requirement can create more design freedom. Therefore, this research will focus on what reduction in the requirement concerning damage stability for unmanned ships can be allowed, if they are subjected to an equivalent level of risk as manned ships of the same size and type.<br/><br/>It has been found that the required subdivision index can be lowered for unmanned ships, based on equivalent safety. The contribution of the risk of losing lives to the overall level of risk is larger for smaller ships. This is reasonable, since for larger ships, the size of the crew increases with a lower rate compared to the amount of cargo, installed power or capital costs. Therefore, the allowable reduction in the required subdivision index is largest for smaller ships.<br/>However, the size of the reduction depends strongly on missing accident statistics concerning the loss of life. The missing data results in the following uncertainties, for which further research is recommended.<br/>Firstly, for different ship types differences in the accident statistics are present. There are significantly less fatalities related to bulk carriers and container ships compared to general cargo ships. It is expected that these differences are related to the individual ship size and crew size, for which both the correlation with the probability of losing life is unknown. <br/>Secondly, there is a discrepancy between the theoretical probability of survival of a ship, namely the attained subdivision index, and the probability of survival that the accident data suggests. The attained subdivision index suggests that at least 30% of all accidents should lead to a total ship loss. The accident data reveals that for general cargo ships around 10% leads to a total ship loss.<br/> <br","Autonomous ships; Required Subdivision Index; SOLAS; Risk analysis; Equivalent safety","en","master thesis","","","","","","","","","","","","Marine Technology | Ship Design, Production and Operations","",""
"uuid:1727bc3f-c0ca-4439-9590-914339678723","http://resolver.tudelft.nl/uuid:1727bc3f-c0ca-4439-9590-914339678723","NL to PDDL: One-Shot Learning of Planning Domains from Natural Language Process Manuals","Miglani, Shivam (TU Delft Electrical Engineering, Mathematics and Computer Science)","Yorke-Smith, Neil (mentor); Delft University of Technology (degree granting institution)","2019","Automated Planning (AP) is a key component of Artificial General Intelligence and has been successfully employed in applications ranging from scheduling observations of Hubble Space Telescope to generating dialogue agents. A significant bottleneck for its widespread adoption is acquiring accurate domain models which formally encode the planning problem’s environment. Traditionally, these domain models have been hand-coded by human experts and knowledge engineers. However, manually encoding domain models is an increasingly difficult task when one moves away from toy domains towards complex real-world problem scenarios.<br/>To resolve this, the AP community has developed several systems to automatically acquire domain models from valid sequences of actions called plans. This approach has two significant issues. First, the generated domain models might be incomplete, error-prone, and hard to understand and/or modify. Second, most domain learning approaches are based on data-intensive inductive learning, which needs large quantities of structured data (plans) to converge. This data is seldom available without an accurate domain model, which leads to a causality dilemma.<br/>To mitigate these issues, we take advantage of readily available and easy to craft Natural Language (NL) data. We present a pipeline called NLtoPDDL, which takes as input a classical domain’s process manual written in a natural language and outputs its Planning Domain Definition Language (PDDL) model. Specifically, NLtoPDDL does this in two steps: first, it combines pre-trained contextual embeddings with an approach developed in previous research, called EASDRL that extracted structured plans from NL data using Deep Reinforcement Learning (DRL), and a consequence, NLtoPDDL beats the EASDRL model which is the current state-of-the-art on action sequence extraction problem; second, it uses the trained DRL model from the first step to extract structured plans from a domain process manual and employs a modified Learning Object Centered Models (LOCM2) algorithm to one-shot learn a PDDL model. Finally, we showcase the effectiveness of our pipeline on four planning domains of varying complexities, by evaluating our learned domain models for soundness, completeness, validity and intuitiveness.","Automated Planning; Knowledge Engineering; Deep Reinforcement Learning; Natural Language Processing","en","master thesis","","","","","","","","","","","","","",""
"uuid:f51aed2d-6a83-4b40-9ce6-bec29f5b69b6","http://resolver.tudelft.nl/uuid:f51aed2d-6a83-4b40-9ce6-bec29f5b69b6","Uncomputability in Information Theory","Bassem Tarek Abdelraheem Elsayed Safieldeen, Bassem (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft QuTech)","Elkouss Coronas, David (mentor); Yorke-Smith, Neil (graduation committee); Caspers, Martijn (graduation committee); Delft University of Technology (degree granting institution)","2019","We present a powerful approach for learning about uncomputability and undecidability in informationtheory. Our approach is to use automata from automata theory that have undecidable properties toconstruct channels for which an information-theoretic quantity is uncomputable or undecidable. Wedemonstrate this approach by showing that, for channels with memory, capacity is uncomputable andinformation-stability is undecidable.","Information Entropy; Quantum information; complexity; finite state machine","en","master thesis","","","","","","","","","","","","","",""
"uuid:d4c48b1b-b5c4-4b51-9a00-cdc456e04200","http://resolver.tudelft.nl/uuid:d4c48b1b-b5c4-4b51-9a00-cdc456e04200","Compensator Design: Extending Van der Woude-Jeltsema's orthogonal projection approach","Bryan, Lotte (TU Delft Electrical Engineering, Mathematics and Computer Science)","van der Woude, Jacob (mentor); Delft University of Technology (degree granting institution)","2019","The aim of this Bachelor Thesis is to extend the orthogonal projection method described in 'An Orthogonal Projection Method for Computing Active, Reactive and Scattered Power and its Application to Compensator Design' by Jacob van der Woude and Dimitri Jeltsema. In the aforementioned article, a method is described to calculate the active, reactive and scattered power of a RLC network. It uses an orthogonal projection of the current on the space of (anti)derivatives of the voltage. This method can be used to improve the power factor of the network, as it also shows how to design a compensator for the reactive power. The compensator consists of a parallel connection of an electromagnetic coil and a capacitor. Two working examples are given. This research shows that Van der Woude and Jeltsema's method is not always applicable. It often results in negative values for the coil and the capacitor, although this has no physical meaning. When the given voltage consists of more than two frequencies, the method is also inapplicable. This research gives a condition that ensures an applicable execution of this method. It also shows when these conditions are met. We show how the method can be extended to a working method for any RLC network, provided the voltage consists of two frequencies. It uses a second Foster canonical form to expand the initially proposed compensator. Depending on the coefficients given by the orthogonal projection, a different type of compensator is needed. It is also described how a fitting compensator can be chosen, and how the coefficients for the coils and capacitors can be determined.","compensator; power factor; orthogonal projection","en","bachelor thesis","","","","","","","","","","","","Electrical Engineering","",""
"uuid:e9119e07-8302-4726-85eb-c3759ab2695f","http://resolver.tudelft.nl/uuid:e9119e07-8302-4726-85eb-c3759ab2695f","Emergence of leadership in communities: A study on how leadership emerges through an innovation process for solving community problems","Hamedtavasoli, Mohammadhosein (TU Delft Technology, Policy and Management)","Bots, Pieter (mentor); Ghorbani, Amineh (graduation committee); van der Zaag, P (graduation committee); Delft University of Technology (degree granting institution)","2019","Many regions around the world are facing water shortage, low water quality, unsustainable overuse or other problems that may even cause conflict among different actors. These water resources are typical examples of common-pool resources. Leaders seem to play a crucial role in the emergence of community-based management of resources and overcoming the collective action problem. The main purpose of this study is to find the mechanism behind the emergence of leaders in the process of starting collective action. <br/>I synthesized leadership studies from different domains and created Leadership for Community Development (LCD) theory. Based on LCD, leadership emerges from influencing interactions that are done to share a vision and make other community members dedicated to it. In this process, leaders gather the requirements of collective action, like support or political capital. Central to this idea is the innovation process, which has four phases of idea generation, idea elaboration, idea promotion, and idea adoption. The idea in the innovation process is the same as the vision. <br/>According to this theory, first, there might be problematizing leaders who challenge the current state and give attention to a problem through influencing interactions. Dissatisfaction with the current state can lead to idea generation. In the idea elaboration phase, the idea creator will try to elaborate and gather support for the idea among his or her close connections. If this is successful and enough support is received, dedicated actors will start promoting the idea by influencing others. In the idea promotion phase, enabling leadership emerges when actors promote their own vision and echoing leadership emerges when convinced actors advocate the vision of their influencers. Enabling leadership and echoing leadership form up effective leadership, which is the indispensable influencing effort of actors for reaching the next phase. Idea adoption or implementation, which is in the domain of management, starts when requirements such as political and intellectual capitals are enough. This theory is further supported by a case study and interview.<br/>I created an agent-based model based on the LCD theory. The model was a successful proof of concept for the LCD theory and how the identified types of leadership emerge through the process of initiating collective action. I used the model to identify the most significant factors on the role of leaders and the initiation of collective action. The social network proved to be the most important factor.<br/>Based on these findings, I emphasized on the importance of focusing on networks and building connections in the communities. Moreover, I have suggested using these findings to diagnose the lack of collective action in communities and to use this diagnosis in the process of facilitating collective action in communities. I proposed many recommendations for future steps in this study. The top priority recommendations are a call for case studies to be done to further validate the LCD theory and to perform group experiments to increase understanding of the role of the social network in collective action problems.<br","Leadership; Collective action; Emergence; Common-pool resources; Agent-Based Modeling","en","master thesis","","","","","","","","","","","","","",""
"uuid:7d4d09be-81e1-498d-adcb-21b9ecb05411","http://resolver.tudelft.nl/uuid:7d4d09be-81e1-498d-adcb-21b9ecb05411","Elastic registration of histological serial sections: A finite element approach","Coppoolse, Taco (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Gijzen, Martin (mentor); Modersitzki, Jan (mentor); Dubbeldam, Johan (graduation committee); Remis, Rob (graduation committee); Delft University of Technology (degree granting institution)","2019","For a proper three-dimensional reconstruction of histology serial sections, adjustment of the slices is necessary for combining serial sections. Deformations occur due to the sectioning and acquisition pro-cess of the microscopic analysis of histology. By reconstructing the deformations with a transformation of the sections, a mathematical correction on the images can be applied. By using image registration, a transformation function is searched for to minimize differences between the histology slices. Due to the non-linearity of the distortions, prior knowledge is required in order to have a solvable problem. Additional information in the form of elasticity regularisation is considered. Implementing the elastic regularisation with a finite element method, provides a continuous transformation function With the continuous function, in a natural way, alignment can be monitored for folding transformations. In this work, the (bi-)linear and (bi-)quadratic elements for the finite element method are implemented and compared with the finite difference method. It is observed that for the different kinds of elements, the (bi-)linear elements yield best results with the validity of the transformation. Moreover, the computa- tional costs for the bi-linear elements are the cheapest. Compared with the finite difference method, the differences in accuracy are not noteworthy but the computational time of the finite element method is longer. Furthermore, to steer the matching in an accurate direction, improvements are proposed by applying local stiffness of the elements or adding soft constraints on the volume of the elements. This results in significant improvements in the transformation. For these two approaches it is observed that local stiffness is more restrictive than volume-preserving. Solving the optimization problem, a Gauss-Newton method to search for descent directions is applied. A matrix-based and a matrix-free approach of elasticity regularisation is considered in the linear system of finding a descent direction. While the matrix-free approach decreases the memory usage, the computational costs are significantly increased.","Image Registration; Elastic Regularisation; Finite Element Method; Matrix-free","en","master thesis","","","","","","","","","","","","","",""
"uuid:ef3007d4-36e9-498c-886a-f31ff7549381","http://resolver.tudelft.nl/uuid:ef3007d4-36e9-498c-886a-f31ff7549381","Tuning of the ‘Constant in gain Lead in phase’ Element for Mass-like Systems","Hou, Xiaojun (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Precision and Microsystems Engineering)","Ahmadi Dastjerdi, Ali (mentor); Saikumar, Niranjan (graduation committee); Hossein Nia Kani, Hassan (mentor); Herder, Just (graduation committee); Delft University of Technology (degree granting institution)","2019","The development of the high-tech industry has pushed the requirements of motion applications to extremes regarding precision, speed and robustness. A clear example is given by the wafer and reticle stages that require rigorous demands like robust nanometer precision and high-speed motion profiles to ensure product quality and production efficiency. Industrial workhorse Proportional Integral Derivative (PID) has been widely used for its simple implementation and good performance. However, PID is insufficient to meet the ever-increasing demands in the high-tech industry due to its inherent constraints of linear controllers such as the waterbed effect. To overcome these fundamental limitations, researchers have turned to nonlinear controllers. Nevertheless, most of the nonlinear controllers are difficult to design and implement and thus are not widely accepted in the industry. Reset control is a<br/>nonlinear controller that is easy to implement and design since it maintains compatibility with the PID loop shaping technique using a pseudo-linear analysis tool named describing function method. However, the reset control as a nonlinear controller also introduces high order harmonics to the system that can negatively affect system performance by causing unwanted dynamics. Hence, describing function analysis as a linear approximation approach that only considers first harmonics is not accurate enough. Recently, a theory to analyze high order harmonics of nonlinear system in frequency domain termed higher order sinusoidal describing function has been developed, which enables the possibility to perform more precise analysis on reset systems. <br/>The majority of research on reset control has focused on the phase lag reduction but a novel reset element proposed in literature termed ”Constant in gain, Lead in phase” (CgLp) is used to provide broadband phase compensation and has been shown to improve system performance. However, there is no systematic designing and tuning approach in literature such that the full advantage of CgLp elements is extracted. This work focuses on the tuning of the CgLp elements in order to obtain optimal performance. High order harmonics are also considered in the tuning analysis since they are critical to system performance due to the effect of unwanted dynamics. When a group of CgLp elements are designed to provide pre-determined phase compensation at the crossover frequency, it is seen that the optimal tracking precision performance is always obtained with the case that has the highest frequency of third order harmonic peak and has almost the smallest magnitude of high order harmonics at low frequencies. Moreover,<br/>the second order CgLp controllers are observed to outperform the first order CgLp controller regarding tracking precision. On the other hand, configurations that have the lowest magnitude of third order harmonic at high frequency are found to have the best noise attenuation performance.","Reset control; Motion Control; describing function analysis; HOSIDF; CgLp","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Mechatronic System Design (MSD)","",""
"uuid:7e7b0712-9bed-4438-a37d-2b5b2ed24211","http://resolver.tudelft.nl/uuid:7e7b0712-9bed-4438-a37d-2b5b2ed24211","Periodic event-triggered control for congested networked control systems","Szymanek, Aleksandra (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Delft Center for Systems and Control)","Mazo Espinosa, Manuel (mentor); de Albuquerque Gleizer, Gabriel (mentor); Delft University of Technology (degree granting institution)","2019","With the recent development of control systems, event-triggered control (ETC) has been introduced to prevent unnecessary usage of resources, which often happens under time-based control implementations. This thesis presents a novel approach to periodic event-triggered control (PETC) that aims at reducing the number of transmissions between the controller and the sensors even further. This goal is particularly important in networked control systems (NCSs), where communication and computation resources are scarce. In this report, a relaxed triggering condition is introduced that relies on bounding the Lyapunov function of the continuous-time closed-loop system with an exponentially decaying function, rather than requiring its monotone decrease. The relaxed PETC achieves significantly less transmissions compared to existing PETC implementations. The thesis pushes the limit of event-triggered<br/>control even further, by introducing an algorithm for a scheduler of NCS that allows to skip some of the events. This can be seen as a ‘last resort’ approach, that postpones the transmission as much as possible. It is inspired by methods used in self-triggered control (STC) and scheduling event-based NCS. Reducing the communication between the plant and the controller introduces some trade-offs that are also discussed in this report. Finally, several modifications of presented ideas are given that can be applied depending on the main objectives<br/>on the performance of the control loop.","periodic event-triggered control; networked control systems; triggering mechanism","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:6946259e-7a75-4ebd-8cc3-8f348a17980d","http://resolver.tudelft.nl/uuid:6946259e-7a75-4ebd-8cc3-8f348a17980d","Is this the real-life? Or just virtual reality?: A head mounted display based virtual reality driving simulator study on the effect of roadside vegetation density on driving behaviour.","Giltay, Joris (TU Delft Mechanical, Maritime and Materials Engineering)","Abbink, David (mentor); Petermeijer, Bastiaan (mentor); Shyrokau, Barys (graduation committee); Delft University of Technology (degree granting institution)","2019","An issue in driving simulation is that behaviour displayed in simulation does not exactly replicate behaviour in real-life. For example, roadside vegetation density impacts a driver’s speed and lateral position in on-road studies, but not in driving simulator studies. In this study it is investigated if the increase in fidelity and presence that head mounted display based virtual reality bring forth, yields behavioural adaptation as shown in real-life by evaluating the effect of three different roadside vegetation density conditions in a novel head mounted display based virtual reality driving simulator. Twenty-nine participants drove a 2m wide car over a 11km long 3.5m wide winding road. Participants completed three trials driving through three different roadside vegetation density conditions per trial, the density conditions being light (one tree per 40m), medium (one tree per 20m) and dense (one tree per 5m). The effect of the density conditions was evaluated with respect to speed, lateral position, steering reversals, subjective workload and self-reported risk. Increased vegetation density increased self-reported risk, but did not affect speed or lateral positioning. This finding is congruent with findings in con- ventional simulator studies, which could indicate that despite the advantages of head mounted display based virtual reality regarding fidelity and presence the resulting driving behaviour still has a closer connection to conventional simulated driving than real-life driving. In future work the built and implemented simulator can be improved and optimized, furthermore the relative validity of the simulator should be investigated.","Driving behaviour; behavioural adaptation; Head mounted display; Virtual Reality; roadside vegetation density","en","master thesis","","","","","","","","","","","","","",""
"uuid:b64fdbc9-64cb-44bf-9b17-3c57dcfa9c0a","http://resolver.tudelft.nl/uuid:b64fdbc9-64cb-44bf-9b17-3c57dcfa9c0a","ENMOS: Energy Module for Self-Sustainable Wearable Sensors","Parag, Anirudh Kumar (TU Delft Electrical Engineering, Mathematics and Computer Science)","Serdijn, Wouter (mentor); French, Paddy (graduation committee); Fan, Qinwen (graduation committee); Urso, Alessandro (graduation committee); Rodrigues Mansano, Andre (graduation committee); Delft University of Technology (degree granting institution)","2019","This work focuses on addressing the fundamental limitation on the minimum cold start-up voltage that could be harvested from a thermoelectric element (TEG) for human-body wearable applications. For ultra-low DC voltages, the challenge translates to generating a timed-signal to amplify it up to a value that could be used to drive, say, a boost converter which can then start-up the entire energy module. Contemporary works have, thus, strived to accomplish this using a charge-pump-based or a transformer-based approach, which in turn imposes a limit on the minimum TEG voltage that can be harvested. The solution this work proposes is to decouple the Cold Start-up system from the TEG altogether and instead, use a piezoelectric element (PEH). This element being capable of producing a well-timed (AC) signal for free, based on human body vibrations, can potentially drive a boost converter. To this end, an integrated circuit (IC) is designed that can utilize the voltage from the PEH, amplifying it up to generate a well-controlled signal that could operate the boost converter. At the heart of this IC, is a self-reconfigurable charge pump that arranges its stages in different boosting ratios (without any complex logic or DSP) based on the input voltage, to allow for a maximum harvested power. The proposed self-reconfigurable architecture can potentially lead the charge pump to be load-variation-resistant. It achieves this by providing an almost constant voltage while increasing the power for higher load demands, at the same time maintaining a constant efficiency. Thus, the fully on-chip implementation in TSMC 0.18 um CMOS, can cold start-up the system from 25 mV of thermoelectric voltage to deliver an output voltage of 1 V at 56.5 % converter efficiency, consuming only 240.5 pW of dynamic power (simulation). The minimum Cold Start-up voltage and dynamic power were found to be 18 mV (ΔT = 0.1 K) and 231.6 pW respectively, to supply 1 V at 44 % converter efficiency. Moreover, in order to prove that the fundamental limitation on the Cold Start-up voltage has been addressed successfully, the IC was also simulated to check whether it can further be lowered. In this case, by providing a piezoelectric excitation voltage 73.3 mVRMS higher, the Cold Start-up voltage was found to be reduced to 15 mV to supply a constant 1 V at the load. It was also found that increasing the inductor value in this case, can also allow the energy module to support even lower Cold Start-up voltages.","Energy Harvesting; Cold Start-up; Thermoelectric energy generator (TEG); Piezoelectric energy harvester (PEH); Self-Reconfigurable charge pump; Dickson charge pump; Ultra-low power; Ultra-low voltage; Power module; Analog integrated circuit design","en","master thesis","","","","","","","","2020-08-27","","","","Electrical Engineering","",""
"uuid:3b31bc33-1f67-4fda-85db-5dace4835bcf","http://resolver.tudelft.nl/uuid:3b31bc33-1f67-4fda-85db-5dace4835bcf","Fast Self-Stable Planar Bipedal Running","van den Broek, Maarten (TU Delft Mechanical, Maritime and Materials Engineering)","Vallery, Heike (mentor); Pratt, Jerry (mentor); Griffin, Robert (mentor); Wisse, Martijn (graduation committee); Delft University of Technology (degree granting institution)","2019","Bipedal running gaits may be self-stable if they rely on the intrinsic system dynamics to attenuate deviations. This use of passive dynamics for gait stability has been observed in biological running and applied for running robotics, supported with the results of numerical simulations. It is an important aspect of the development of fast and agile legged robotic locomotion over complex terrain. One part of running stability, trunk stabilization, can be described using a virtual pendulum model. We believe such a metacentric model may be applied in robotic design to achieve passive stabilization of body pitch for fast bipedal running.<br/><br/>In this study, we test metacentric models for self-stabilization of body pitch in bipedal running and evaluate the effects of running speed, design parameter variations, and control strategies. We extract data from experiments with the Planar Elliptical Runner and compare these with a planar spring-loaded inverted pendulum model with a trunk (TSLIP).<br/><br/>We find passive self-stable gaits in the TSLIP model with the centre of mass below the hip. These gaits demonstrate robustness to disturbances and do not require inertial measurements or high-gain feedback control. At high velocities, foot placement and choice of leg stiffness become less critical for gait stability.<br/><br/>Data from experiments with the Planar Elliptical Runner support the findings from the model behaviour as it runs reliably, with passively stable body pitch, and without feedback control. A metacentric model, such as the virtual pendulum model, may explain the observed passive body-pitch stabilization. Evidence from the model ground reaction forces suggests that pitch stability for the Planar Elliptical Runner can also be explained with a metacentric model. Stability in height and velocity can be explained with the compliant leg behaviour in stance. <br/><br/>Constructing a metacentre through mechanical design is beneficial to intrinsic body-pitch stability and subsequently facilitates full gait self-stability in fast running robotics. Implicit feedback allows off-loading of high-gain feedback control onto the system mechanical design, thus contributing to developments for fast legged locomotion over rough terrain.","fast bipedal running; robotic locomotion; self-stability; robustness; running gaits; spring-mass model","en","master thesis","","","","","","","","","","","","","",""
"uuid:8d1e4867-976f-4259-8138-80af852a2eaa","http://resolver.tudelft.nl/uuid:8d1e4867-976f-4259-8138-80af852a2eaa","Electrocoagulation as a tertiary treatment of municipal wastewater: Removal of enteric pathogen indicators and antibiotic-resistant bacteria","Trikannad, Shreya (TU Delft Civil Engineering and Geosciences)","Medema, Gertjan (mentor); van Halem, Doris (graduation committee); Delft University of Technology (degree granting institution)","2019","With the growing population and economic development, there is more stress on natural water resources. Additionally, current and future water shortages, increasing environmental concerns and stringent discharge standards demand high-quality treated water. In this scenario, it is crucial to recover water and wastewater resources for reuse, reducing the dependency on new resources. While aiming for water reclamation, the influence of wastewater quality parameters on human health is given foremost attention in recent times. Enteric pathogens are a major concern when reclaiming municipal wastewater. Electrocoagulation (EC) process that introduces coagulants by electrochemical means has been successfully employed for the treatment of groundwater, industrial and municipal wastewater. EC has been widely accepted over other physicochemical processes due to its process design and lowcost material. In this research, EC has been thoroughly investigated as a tertiary treatment technology for water reclamation from municipal wastewater. This research is focused on determining the efficiency of low voltage iron EC for the removal of enteric pathogen indicators and antibiotic-resistant bacteria from secondary wastewater effluent. The effect of operational parameters: charge dosage (C/L) and charge dosage rate (C/L/min) on pollutant reduction was evaluated in different water matrices: demineralized water, synthetic wastewater effluent and real wastewater effluent. EC operated at 400 C/L, 7.2 C/L/min and natural pH allowed &gt; 3.5 log units removal for E. coli and Enterococci, &gt; 2.5 log units for ESBL E. coli and VRE and &gt; 2 and 2.7 log units for Somatic coliphages and Clostridium perfringens spores respectively in real wastewater effluent. Furthermore, a significant reduction of phosphorous, COD and the true color was observed at 400 C/L and 36 C/L/min. Pollutant reduction was influenced by sedimentation and floatation mechanisms observed at varying charge dosage rates. A marginally higher removal rate constant of pathogen indicators as a function of charge dosage at low charge dosage rate showed slow iron dosing to improve microbial adsorption and increase contact time with iron precipitates. The reduction of pathogen indicators was associated with physical removal mechanisms like adsorption, sweep coagulation and entrapment within the flocs, charge neutralization and aggregation based on literature. The effective removal of physical, chemical and microbiological parameters in real wastewater effluent was achieved at 400 C/L and 7.2 C/L/min at an operating cost of 0.17 €/m3 indicating EC to be a cost-effective treatment in comparison to alternative technologies like ozone, UV, activated carbon and reverse osmosis.","Electrocoagulation; Enteric pathogens; Antibiotic-Resistant Bacteria; Water reuse; Municipal wastewater","en","master thesis","","","","","","","","2020-08-31","","","","","",""
"uuid:d4245867-c1e4-4f64-80b5-21a4e34647a8","http://resolver.tudelft.nl/uuid:d4245867-c1e4-4f64-80b5-21a4e34647a8","Scour holes: A data-driven risk-based analysis for scour holes in the Rhine-Meuse Delta","Koevoets, Igor (TU Delft Civil Engineering and Geosciences)","Kok, Matthijs (graduation committee); van Vuren, S. (graduation committee); Pol, Joost (graduation committee); Neefjes, P. (mentor); Stenfert, Joost (mentor); Delft University of Technology (degree granting institution)","2019","In the Rhine-Meuse Delta over 100 scour holes are located. Many of these scour holes have dynamic behaviour and are growing in size and depth. A scour hole can lead to an increased probability of flooding. One of the potential hazards of the presence of scour holes is the occurrence of flow slides on the foreshore next to scour holes. Depending on the distance between the dike and the river, a flow slide can affect the water-retaining function of a dike. Flow slide is an indirect failure mechanism and can be used as a scenario in the safety assessment of direct failure mechanisms. <br/><br/>In the research, a data-driven method has been developed for the risk assessment of scour holes. The method is elaborated for flooding due to the failure mechanism overtopping. The development of a scour hole is coupled with the safety assessment regarding overtopping for the dike next to a scour hole. In the method, the development of a scour hole and the future dimensions are predicted in a probabilistic way by extrapolation of historically measured bed level data. With the predicted future scour hole dimensions, the probability of occurrence of a flow slide and the probability of several post flow slide profiles is calculated with the methods given in the Wettelijk Beoordelingsinstrumentarium (WBI). Based on the post flow slide profiles, the probability of exceeding the critical overtopping discharge is determined. Combining the probability of exceedance of the critical overtopping discharge with the consequences of a flood gives the flood risk due to the presence of a scour hole.<br/><br/>The developed data-driven method is applied to one case study, a scour hole in the river Spui. For this particular scour hole, the flood risk is assessed. A prediction is made for the future dimensions of the scour hole. The flood risk is determined with the probability of occurrence of flow slide, the probability of exceedance of the critical overtopping discharge and the expected consequences of a flood. The assessed flood risk is evaluated and risk mitigation measures are proposed. The economic feasibility of risk mitigation measures is analysed with a cost-benefit analysis.<br","Scour hole; Floodrisk; risk-based approach; Rhine-Meuse Delta; Flow slide","en","master thesis","","","","","","","","","","","","Civil Engineering | Hydraulic Engineering","",""
"uuid:ea30f1c8-70d6-493c-948b-3b6e0c398c3a","http://resolver.tudelft.nl/uuid:ea30f1c8-70d6-493c-948b-3b6e0c398c3a","Feeling Uncertain: Effects of Encoding Uncertainty in the Tactile Communication of a Spatiotemporal Feature","Driessen, Tom (TU Delft Mechanical, Maritime and Materials Engineering)","de Winter, J.C.F. (mentor); Dodou, D. (graduation committee); Bazilinskyy, P. (graduation committee); Krüger, Matti (graduation committee); Delft University of Technology (degree granting institution)","2019","An appropriate understanding of a machine's competences may be critical for safe use. Sharing measures of real-time function reliability could help users to adjust their reliance on machine capabilities. We designed a vibrotactile interface that communicates spatiotemporal information about surrounding events and further encodes a representation of spatial uncertainty. We evaluated this interface in a driving simulator experiment with varying levels of machine confidence linked to a simulated degradation of sensor signal quality and varying levels of human confidence induced through a degradation of visual feedback. A comparison between variants of the system indicated positive performance effects of providing uncertain information compared to a more conservative solution that only provided information above a specific confidence level. Subjective reports revealed a positive acceptance of uncertainty signaling in low-visibility conditions, comparable to acceptance ratings of a fully confident machine that accurately signaled the precise location of events.","reliability display; haptic assistance; uncertainty display; human-machine cooperation; automotive hmi","en","master thesis","","","","","","Digital supplement is available at www.github.com/tomdries/feelinguncertain","","","","","","Mechanical Engineering","",""
"uuid:b5aabe84-8a8b-4841-848d-136ab6ce0825","http://resolver.tudelft.nl/uuid:b5aabe84-8a8b-4841-848d-136ab6ce0825","One-Class Classification: for high-dimensional data","Elghlan, Faris (TU Delft Electrical Engineering, Mathematics and Computer Science)","Tax, D.M.J. (mentor); Reinders, M.J.T. (graduation committee); de Weerdt, M.M. (graduation committee); Delft University of Technology (degree granting institution)","2019","This M.Sc. thesis report investigates the application of one-class classification techniques to complex high-dimensional data. The aim of a one-class classifier is to separate target data from non-target data, but only a dataset containing target data is available for training. The issue with high-dimensional data is that it is difficult to perform density estimation due to the `curse of dimensionality'. Most conventional method for one-class classification rely on density estimation.<br/><br/>This thesis focusses on the use of autoencoders and generative adversarial networks (GANs) for one-class classification problems involving image data. Autoencoders can learn encoding and decoding functions for samples from the target dataset. These encoding and decoding functions are, however, expected to not perform well for non-target samples, as they have never been seen during the training phase. This makes it possible to separate target and non-target data. For GANs, the discriminator is used to distinguish between target and non-target data.<br/><br/>Autoencoders and GANs are evaluated extensively in this report. Their behavior, desired parameters and strengths and weaknesses are evaluated by performing experiments. The main findings are that GANs do not perform well for one-class classification tasks, because of mode collapse and insufficient sampling of the non-target data. Even for extremely simple datasets these issues were observed. Autoencoders are shown to perform much better and behave according to the theoretical expectations.","one-class; classification; high-dimensional; Autoencoder; GAN; Wasserstein Autoencoder; Pattern Recognition; Machine Learning; Deep Learning","en","master thesis","","","","","","","","","","","","Computer Science | Data Science and Technology","",""
"uuid:5f6fc199-1141-4f84-991c-e6ea4ec53d81","http://resolver.tudelft.nl/uuid:5f6fc199-1141-4f84-991c-e6ea4ec53d81","Integrating Biological Oxidation of Arsenite with Iron Electrocoagulation: A Novel In-line Technique for Enhanced Removal of Arsenite from Water","Roy, Mrinal (TU Delft Civil Engineering and Geosciences)","Rietveld, L.C. (mentor); van Halem, D. (mentor); Spanjers, H. (mentor); van Genuchten, Case (mentor); Delft University of Technology (degree granting institution)","2019","Human exposure to the toxic element arsenic due to consumption of arsenic contaminated water is still a global issue worldwide. Conventional treatment techniques are not very efficient at removing arsenite, which is the predominant species of arsenic in raw groundwater. Biological oxidation of arsenite by arsenic oxidizing bacteria (AsOB) has shown potential to effectively oxidize arsenite to arsenate without use of any chemicals. Arsenite is then effectively removed by adsorption or separation technologies. Iron Electrocoagulation (Fe-EC) is also emerging as an influential technique for arsenic removal that involves in-situ generation of iron coagulants using iron electrodes by electrolytic oxidation of anode. The main advantage of Fe-EC is that it does not require dosage of chemical coagulants so can be beneficial to communities with better access to electricity than chemicals.<br/>This research work is done to combine the two techniques: biological oxidation of arsenite and Fe-EC, for better removal of arsenite from water. Batch studies on Fe-EC were performed in the laboratory to investigate the effects of charge dosage, charge dosage rate, initial arsenic concentration, arsenic oxidation state and different water matrices on the rate and extent of arsenic removal. Also, growth of AsOB on suitable bio-carrier was performed by continuous dosing of 150 μg/L arsenite-spiked water over a period of 49 days. The AsOB grown on the bio-carriers performed 90 % oxidation of 150 μg/L arsenite after a period of 35 days. Finally, two continuous flow system were developed one containing arsenite oxidation step by AsOB followed by Fe-EC and rapid sand filtration whereas the other contained only Fe-EC and rapid sand filtration. The system containing biological oxidation followed by Fe- EC removed arsenite below the WHO standard (10 μg/L ) from an initial arsenite concentration of 150 μg/L at a low iron dosage compared to the system where only Fe-EC was applied.","Arsenite Removal; Iron Electrocoagulation; Biological Oxidation; Continuous Flow System","en","master thesis","","","","","","","","","","","","","Environmental Biotechnology",""
"uuid:001f523a-c964-4bb6-9f65-8c89cd29fdac","http://resolver.tudelft.nl/uuid:001f523a-c964-4bb6-9f65-8c89cd29fdac","Planetary-scale classification of natural and human-induced sandy shoreline evolution: A semi-automated method that employs Machine Learning and Satellite Derived Shorelines over the past decades","Kras, Etienne (TU Delft Civil Engineering and Geosciences)","Aarninkhof, S.G.J. (mentor); de Vries, S. (mentor); Luijendijk, A.P. (mentor); de Boer, W.P. (mentor); Antolínez, José (mentor); Delft University of Technology (degree granting institution)","2019","Today's coastal zones are densely inhabited as the majority of the world's population lives in these attractive areas. The shorelines in coastal zones are shaped by complex spatial and temporal variable interactions between natural forcings like changes in mean sea-level, tides, wave and wind conditions, and storm surges. Besides, natural hazards such as coastal erosion, tropical cyclones, hurricanes, typhoons, floods, salt intrusion and tidal surges threaten a major part of the world's population. Furthermore, climate change is likely to increase the risk of natural hazards. As a response, humans changed the world's shorelines and the forcing-driven processes that work on them, to increase protection against hazards and keep supporting their activities. These human interventions are deployed discontinued in time, disperse spatially and might result in negative consequences leading to human-induced hazards. This research focuses on one particular hazard to coastal communities, coastal erosion, which is extended to a term referred to as shoreline evolution by incorporating coastal accretion as well. Up till now, detailed local-scale studies are able to expose human and natural drivers of shoreline evolution and provide a possibility to make a step towards intentional rather than accidental coastal engineering. Digital imaging and, more recently introduced, satellite imagery proved to be a promising new technology to measure and monitor shoreline evolution at bigger temporal and spatial scales. Nevertheless, the opportunity to develop a model that exposes the drivers of shoreline evolution on a planetary scale remains unexplored. This is due to the required computational effort as well as the large variability in coastal systems around the world. With an ever-increasing data availability, data-driven models incorporating Machine Learning (ML) proved to be an efficient alternative approach to heavy computing classical process-driven models in civil engineering practice. Next to this, a coastal classification can be used as a means to inventory the aforementioned variability. Therefore, the research objective in this study is to explore the possibility of exposing and classifying the drivers of shoreline evolution on a planetary scale, by employing ML on satellite imagery. Approximately 390.000 km of shoreline is analyzed for the past 33 years. This resulted in a statistically derived classification of natural and human-induced sandy shoreline evolution. By elaborating on this classification, it is found that natural and human-induced shoreline evolution accounts for approximately 16 and 25% of the total of globally exposed and classified shoreline evolution signals respectively. All outcomes in this research can support detailed local scale investigations and therefore provide an enhanced opportunity to make a step towards intentional rather than accidental coastal engineering. Hence, it is concluded that the developed and applied methods that employ ML on satellite imagery can be used to expose and classify (in)direct human and natural influences on sandy shoreline evolution using spatial and temporal characteristics on a planetary scale. 57% of the shoreline evolution signals is present in a regime with complex and combined (compound) influences, which still requires (rather than supports) local scale investigations to determine the correct influence or driver. More research is required to elaborate on the opportunities that can enhance insight in the compound regime, to improve the obtained results and advance the applicability of this study.","Planetary-scale; Classification; natural forces; Human interventions; Sandy coasts; long-term; shoreline variation; Satellite Imagery; Machine Learning; Python","en","master thesis","","","","","","","","2021-02-27","","","","Civil Engineering | Hydraulic Engineering","",""
"uuid:43751a99-8882-4d47-97eb-488a8fafba19","http://resolver.tudelft.nl/uuid:43751a99-8882-4d47-97eb-488a8fafba19","Identifying collaborative trends in a project team environment: How can collaborative trends be identified in a project?","Eversdijk, Jeroen (TU Delft Civil Engineering and Geosciences)","Bakker, H.L.M. (mentor); Bosch-Rekveldt, M.G.C. (graduation committee); Nikulina, Anna (graduation committee); Ribberink, SJ (graduation committee); Eykelenboom, J.M. (graduation committee); Delft University of Technology (degree granting institution)","2019","This research tries to provide a first direction in measuring collaborative trends. By being able to measure collaborative trends, more research can be done towards the effects of events and the timing of collaborative practices to implement in projects. This is done by providing an answer on the main research question: “How can collaborative trends be identified in a project?”<br/>The RECAP assessment tool proved to be an elaborate tool to assess the collaboration quality on a project. However, the main issue in using the tool more frequently is the large amount of questions. By reducing the number of questions of the RECAP and making them more comprehensible for both managers and team members, the ACT tool is developed. The ACT tool measures collaborative practices, relational attitudes and team working quality over time using 20 variables. An added dimension in assessing the client and Fluor differently proved a useful dimension in assessing the alignment of both parties in terms of collaboration. By discussing the results of the tool during a workshop, joint action points are formulated to maintain and improve the collaboration quality.<br/>One of the starting points of this research is that collaboration is an often-underestimated topic where companies are searching on how to implement it right. This survey is a first step in evaluating collaborations more frequently making it possible to identify variables impacting the collaboration and their effect over time. This tool is able to provide direct feedback to managers and team members on collaboration on the project and showing areas of improvement.<br/>Statistical data analyses proved that the tool is able to measure several collaborative trends during the SELECT phase of the project. Time related trends as well as non-time related trends can be identified using the ACT tool. Evidence shows that while no significant changes over have been measured using a weekly interval, the collaboration did improve when comparing data from week 1 and week 7. During the seven weeks the client and Fluor became more aligned in their perceptions towards collaboration, showing that both parties achieved a better mutual understanding of the collaboration between both parties. Larger differences have been found in the between the management teams and team members, where the management teams were always more positive towards the collaboration than team members. Especially towards the ending of the SELECT phase differences became bigger.<br/>The tool can be used for any project with a client-contractor relationship. When there are multiple (sub-)contractors involved in a project, the survey should be adapted to include them in the mirroring questions. The mirroring questions are useful to identify gaps between client and contractor in the beginning of a collaboration and aligning both parties in mutual understanding and expectations. In more advanced collaborations, questions could be changed to “one team” instead of the difference between client and contractor. The questions have been developed specific to this project in terms of applicability. When used on other projects without colocation or direct use of counterparts the option of “Not applicable” or “Do not know” should be included to remain a high reliability of the responses.","Collaboration; Measuring Collaboration; interorganizational collaboration; Relational contracting; Partnering","en","master thesis","","","","","","","","2020-08-27","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:140cb6fd-2a2e-4853-8f37-0383278a03f1","http://resolver.tudelft.nl/uuid:140cb6fd-2a2e-4853-8f37-0383278a03f1","Evaluating Multi-Disease Interventions","Gross, Shannon (TU Delft Technology, Policy and Management)","van de Walle, B.A. (graduation committee); Kwakkel, J.H. (mentor); Nikolic, I. (graduation committee); Delft University of Technology (degree granting institution)","2019","Policymakers who work in the public health sector may rely on the help of quantitative models to support their choice of control strategy against a particular infectious disease. While policymakers have a large number of decision support models to choose from, hardly any of these tools are used to design an intervention strategy that can work well across multiple diseases. This is in part because of the need for large amounts of precise, detailed data and the presence of many unknown or confounding factors, which complicates attempts to make single-disease models, let alone multi-disease models. Is this highly data-intensive and detailed predictive approach necessary to make a good decision about how limited health resources should be allocated against multiple threats? Could the inclusion of multiple pathogens into a single decision support tool change the recommendation of an “optimal” intervention? In the following thesis, a novel multi-disease model is created. Rather than attempting to make a predictive tool to try and foresee a deeply uncertain future, this multi-disease model uses an exploratory approach to systematically evaluate the impacts of uncertain parameters. Many objective optimization techniques are used to find robust intervention strategies that work well for decision-makers who are interested in increasing the impact of their limited resources.","Public health; Robust decision making; WASH; Decision support model","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:3c4aaf9e-178a-43a6-86b0-0d619934b224","http://resolver.tudelft.nl/uuid:3c4aaf9e-178a-43a6-86b0-0d619934b224","Disappearing professions through technological development: Implications for the Dutch labour market","Schot, Paul (TU Delft Technology, Policy and Management)","Warnier, Martijn (mentor); Mouter, N. (graduation committee); Delft University of Technology (degree granting institution)","2019","Frey and Osborne (2013) have researched the effects of current digitization and robotization of society and concluded 47 percent of American jobs have a high probability of disappearing between now and the year 2030. There are signs that these technological developments may lead to a fourth industrial revolution and consequently, unemployment will rise, as job creation cannot keep up with job destruction. The previous Deputy Prime minister of the Netherlands underlined the necessity of dealing with the possible changes of technological development for the Netherlands (Buddingh, 2014). A quantitative database-driven approach is used to determine a labour market forecast for the Netherlands. The programming language ‘Python’ was used to conduct the research. The research concludes in a policy space with three technological development scenarios and a generalized methodology. The development scenarios are low, medium, and high technological development. The research concludes in respectively 0.8, 2.6 and 4.7 million loss of jobs for the scenarios. The loss of jobs should be regarded as a space for policy since it does not incorporate the creation of new occupations. It is recommended to the Ministry of Social Affairs and Employed to instate a committee that addresses the sketched scenarios and designs policy to mitigate possible negative effects.","Industrial revolution; Emerging technologies; Job loss; Technological development","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:0f5f72dd-5524-4163-a2b6-9653092af78e","http://resolver.tudelft.nl/uuid:0f5f72dd-5524-4163-a2b6-9653092af78e","An empirical study on the selection of business models using dynamic capability framework as a tool","Hussain, Yawar (TU Delft Technology, Policy and Management)","Werker, C. (mentor); Janssen, M.F.W.H.A. (mentor); Timm, Jendrik (mentor); Delft University of Technology (degree granting institution)","2019","Truly new business models are enabled periodically by a socio-technological disruption and most of the times, firms have to select and refine the already existing models to foster growth and sustain competition. However, the selection process is challenging as there is no right or wrong business model and what works for one firm might not work for the other. The researchers in the field of strategic management advocate that the selection or design of a business model is dependent on the dynamic capabilities of a firm which is unique to it. Teece D.J. (2018) argued that the three clusters of dynamic capability namely sensing, seizing and transforming make a framework which can be used to select or design a business model and maintain a competitive advantage. However, there exists a shortage of empirical studies that furnish granular details on selecting a business model using dynamic capability framework as a tool. Secondly, the inclusion of a value network is important for the selection of a business model but the framework ignores the complexity and advantages of working in a network environment, a common trend in the present business ecosystem. Hence, with this research, we aim to generate empirical insights and details on the selection of a business model using dynamic capability framework as a took by doing a case study on a firm operating in video on demand [VOD] industry.","Dynamic Capabilities; Business Model; Dynamic Capability Framework","en","master thesis","","","","","","","","2020-08-26","","","","Management of Technology (MoT)","",""
"uuid:235714fc-d2b1-4feb-bbf2-b00c8d01e743","http://resolver.tudelft.nl/uuid:235714fc-d2b1-4feb-bbf2-b00c8d01e743","Port Call Efficiency Optimization, Using Data Analysis, Process Mining and Discrete Event Simulation","Mašović, Matti (TU Delft Technology, Policy and Management)","Verbraeck, A. (graduation committee); Lefter, I. (mentor); De Leege, Arjen (graduation committee); Delft University of Technology (degree granting institution)","2019","Port call efficiency (PCE) is an important factor in the port choice of shipping lines. This research strives to contribute to the current work on PCE optimization. This is done by applying relative new techniques on port call related data. A combination of process mining (PM) and discrete event simulation (DEVS) is explored, with the Port of Rotterdam as a case study, to determine how they can contribute to identifying and assessing policies that improve port call efficiency. It is concluded that PM can be used as a tool for monitoring a port’s behaviour and spotting bottlenecks, from which port call efficiency policies are derived. Furthermore, it proved to be a useful method for conformance checking the event engine. In order to assess the identified policies, a discrete event simulation model is created, using a model structure, identified through PM. A policy is tested, where all the tugboats in the port work together as one fleet, instead of multiple fleets. From this, it is concluded that this method is successful in assessing scenarios, whose results can be translated back to real-live decision making.","Process Mining; discrete event simulation; AIS; Port of Rotterdam; Log Data; port call efficiency; optimization","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:12645c81-d42c-4789-b0f4-1c318e83b4b7","http://resolver.tudelft.nl/uuid:12645c81-d42c-4789-b0f4-1c318e83b4b7","Integrated Sulphate Removal from Ion Exchange Brine Using Chemical Precipitation and Ceramic Nanofiltration","Floriana Ayumurti Kukuh, Ayu (TU Delft Civil Engineering and Geosciences)","Rietveld, L.C. (mentor); Heijman, Sebastiaan (graduation committee); Lindeboom, R.E.F. (graduation committee); Caltran, I. (graduation committee); Delft University of Technology (degree granting institution)","2019","In drinking water production, natural organic matter (NOM) is sometimes removed using ion exchange (IEX) resin. This treatment method has a limitation based on the exchanging capacity on the resin. Therefore, the resin needs to be regenerated when it is saturated with adsorbed NOM which leads to the production of brine. In general, NaCl is used to regenerate the resin, hence, the brine will contain NOM, high sodium and chloride concentrations. Moreover, some other anions are also found in the IEX brine, such as sulphate that is usually present in surface water and ground water. Because of its salinity, the disposal of IEX brine is not possible to be done conventionally due to its impact on the environment and high cost. Therefore, separating chloride from the brine is an interesting alternative that can be reused for the regeneration of the IEX in the later process.<br/><br/>Ceramic nanofiltration (NF) emerges to be an interesting alternative for water treatment. Compared to polymeric membranes, this type of membrane offers great mechanical robustness and can be operated under extreme conditions, and tolerates high-pressure backwash, chemical cleaning, and high-temperature sterilization, which leads to longer periods of reliable performance. Moreover, ceramic NF membranes are potentially capable to separate multivalent ions from monovalent ions. Hence, this method could be applicable to treat IEX brine. Alternatively, chemical precipitation using barium and calcium is widely used to remove sulphate from water which is more straight forward than membrane filtration. The precipitates can be mechanically separated from the supernatant for further treatment or use. <br/><br/>Combination of chemical precipitation and ceramic NF membrane (later called as integrated sulphate removal) was investigated to remove sulphate from IEX brine. Along with that, investigation using synthetic brines consisting of Na2SO4 and NaCl for a binary salt solution and only Na2SO4 for a single salt solution was also conducted to build the understanding in treating the IEX brine. Barium salt was proved to efficiently remove sulphate due to its very low solubility. However, calcium salt was not as effective as barium salt. The treatment was followed by NF using a ceramic membrane with MWCO of 900 Da. In the end, the integrated approach was able to remove 86% of the sulphate and 85% of NOM from IEX brine. Furthermore, the precipitation stage was also modelled in PhreeqC by using Pitzer database.<br/><br/>Barium salt (BaCl2.2H2O) was preferred in this research for precipitating the sulphate. However, due to its toxicity, alternative precipitation was desired. Ettringite (calcium sulfoaluminate) precipitation was considered since the involving salts were not toxic. The efficacy of this method was predicted through modelling in PhreeqC to give some insight to alternatively removing sulphate from IEX brine. Eventually, a comparison using cost estimation and Life Cycle Assessment (LCA) were performed to obtain some considerations to implement the treatment alternative in a full-scale application.<br","Chemical precipitation; Ceramic nanofiltration; Sulphate removal; IEX brine; Barium salt; Ettringite","en","master thesis","","","","","","","","2021-08-27","","","","Civil Engineering","",""
"uuid:247e706e-8b0d-42a3-981c-06b4007c807a","http://resolver.tudelft.nl/uuid:247e706e-8b0d-42a3-981c-06b4007c807a","Future of Mobility: Sustainable equity through equalisation and mobilisation of socio-economic centres","Lewis, Donovan (TU Delft Industrial Design Engineering)","van Dijk, Matthijs (mentor); Dehli, Silje (mentor); Delft University of Technology (degree granting institution)","2019","The general concept and meaning of mobility have been changing and evolving since the start of mankind. Mobility has become more than getting from point A to B. Mobility is changing from solely being a means to reach a specific goal into being a goal on its own. PwC also realized this. However, at this moment PwC has no vision to do something with this mobility paradigm shift for themselves or their clients. This graduation project focused on the development this mobility vision for PwC and a design based on this vision. This is formulated in the assignment: Design a meaningful product (- service system) that enables, facilitates or improves personal mobility, in the Netherlands, by 2035.<br/><br/>Through conducting research, I created a future context. The future context is composed out of twelve cases in which people are unable to take personal responsibility for their mobility. It prevents them from creating favorable conditions in which they and others are able to create a better self. Together with PwC I decided to focus on the increasing socio-economic inequality case because, positively contributing to that case is most in line with PwC’s own vision. The selected case is about people are not able to take personal responsibly to effectively use their mobility to grow their prosperity or that of others, due to new (global) external factors.<br/><br/>I created a mobility vision for PwC that is focused at delivering a positive contribution to the above-mentioned problem. The goal of the vision is: PwC wants people to responsibly use their short-term mobility to create a better self. Essential is that the success of it depends on the increase and/or improvement in short- and long-term socio-economic prospects for themselves and others too. Moreover, these prospectives should honor the creation of a better world for flora and fauna. PwC can achieve this by: Creating with people’s mobility surplus personal interdependencies, between people’s short- and long-term socio-economic prospects.<br/><br/>Flock has been created to realize this vision. Flock is a mobility system, owned by the Dutch government, which uses road pricing to charge users based on their departure and arrival location of their journey. Users traveling from a geographical area, which is valuable for society, to another area which is less valuable will be charged less than vice versa. Flock calls these geographical ‘mobility epicentres’. This leads to more socio-economic equality which is more uniformly spread in the Netherlands on the long-term. Additionally, Flock offers people the ability to participate in a nation-wide de-centralized mobility network. People participate by investing in it with a privately-owned product that is capable of providing mobility. This is called ‘mobility virtualization’. If done successfully, the user will be granted access to means that are invested by others in the network that provide mobility. This can be in the same or different mobility epicenters. The government is in possession of a desktop application and the user, mostly Dutch citizens, are in possession of a smartphone app to interact with the mobility system.","Mobility; Future; ViP; VIP Framework; Socio-economic; inequality; 2035; System Design","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:7d497424-dd0f-476e-8486-68d93b2739a9","http://resolver.tudelft.nl/uuid:7d497424-dd0f-476e-8486-68d93b2739a9","The quality of GRACE monthly solutions and potential improvements by the use of the Global Tide and Surge Model","Brussee, Marenka (TU Delft Civil Engineering and Geosciences; TU Delft Geoscience and Remote Sensing)","Ditmar, Pavel (mentor); Slobbe, Cornelis (graduation committee); Verlaan, Martin (graduation committee); Delft University of Technology (degree granting institution)","2019","Climate change causes alterations in large scale mass transport patterns in the ocean, cryosphere and hydrology. The Gravity Recovery and Climate Experiment (GRACE) satellite mission which has been operational in the years 2002-2017 has already improved our understanding of large scale mass transport on Earth, but improvement of data quality is still needed. This will increase the quality of our current estimates of the effects of climate change on one hand and help in the validation and initiation of climate models on the other, which improves the accuracy of future predictions.<br/><br/>Noise in GRACE Level-2 data (monthly gravity field solutions) is caused by various reasons. The measurements themselves are already executed and their quality is fixed but better data processing algorithms and background models can reduce the current noise level. This is also relevant for the GRACE Follow On mission which might have a higher measurement precision. Over the ocean, these GRACE monthly solutions ideally only show mass exchange between continents and ocean and effects of self-attraction and loading. Therefore, the signal over the ocean is expected to consist predominantly of a linear trend and a seasonal variability. For certain oceanic regions this is not the case. In these areas still a signal variance representing interannual differences in the mass-derivative and large residuals with respect to a low-pass filtered signal are observed. This low-pass filtered signal contains only signals of a frequency lower than the semiannual cycle. These signal variance and residuals are unexpected and can be caused by inaccuracies in the currently applied oceanic background models in GRACE data processing. <br/><br/>For various Release 5 and Release 6 monthly solutions the noise variance, signal variance and residuals as aforementioned are estimated. The noise and signal variance are estimated by Variance Component Estimation (VCE). Additionally, numerical experiments are performed to analyze different regularization functionals and set-ups in the VCE. The oceanic regions where the largest signal variance and residuals are observed correlate. These areas are for GRACE Release 5 data the Baltic Sea, Black Sea, Arafura Sea, East Siberian Arctic Shelf, Argentine Basin and Hudson Bay. For GRACE Release 6 data a significant drop of this signal variance and residuals can be observed for the Hudson Bay and East Siberian Arctic Shelf.<br/><br/>Consequently, the oceanic background models for these releases are compared against each other and against the Global Tide and Surge Model (GTSM) which is a 2D hydrological model based on the Delft3D Flexible Mesh software developed by Deltares. For the whole ocean both 3/6-hourly time-series and monthly time-series are analyzed. For the shallow regions up to 200 m, the Black Sea and the Red Sea, GTSM shows significant differences with respect to the current applied oceanic background models. When comparing the oceanic background models of different releases it can be observed that the regions where the signal variance and residuals decreased for GRACE Release 6 with respect to Release 5 correlate to regions where the differences between these models is significant. This indicates that oceanic background models do significantly influence the quality of GRACE monthly solutions over the ocean. <br/><br/>Furthermore, it is investigated whether it can be expected that GTSM will improve the GRACE monthly solutions. For this, monthly time-series of the current applied oceanic background models are added back to the GRACE monthly solutions; consequently, by GTSM computed monthly time-series are removed. Compared to GRACE Release 5 monthly solutions, GTSM shows a reduction in the signal variance and residuals for the Hudson Bay, East Siberian Arctic Shelf, Black Sea, Baltic Sea, North Sea, Arafura Sea and certain parts of the Arctic and Southern ocean. Compared to GRACE Release 6, a reduction in the signal variance and residuals is observed for the East Siberian Arctic Shelf, Black Sea, Baltic Sea, North Sea and Arafura Sea. For these regions it is most expected that GTSM can improve GRACE monthly solutions. Since the quality of monthly solutions over the oceans is clearly influenced by the oceanic background models significant alterations in GRACE monthly solutions are expected for the shallow regions up to 200 m, Black Sea and Red Sea when applying GTSM in the GRACE data processing. Whether these will be improvements or not should be analyzed by implementing GTSM-based 3-hourly time-series in the GRACE data processing to create a new GRACE Level-2 data product.","GRACE; Global Tide and Surge Model; Ocean variability; Variance Component Estimation","en","master thesis","","","","","","","","","","","","","",""
"uuid:4e5f6904-9c56-4b08-8168-8a12f29f8654","http://resolver.tudelft.nl/uuid:4e5f6904-9c56-4b08-8168-8a12f29f8654","Feasibility of 3D-printed phantoms for quantifying Bragg peak degeneration due to tissue heterogeneity in lung proton therapy","Moret, Thijs (TU Delft Mechanical, Maritime and Materials Engineering)","Schaart, Dennis (mentor); Delft University of Technology (degree granting institution)","2019","In the field of radiation oncology, proton therapy is a relatively new technique. It shows a great advantage over conventional radiation therapy in the depth-dose relation, which results in the possibility to deliver dose far more concentrated at a specific depth. This in turn has the potential to spare the healthy tissue surrounding a tumour from receiving a very high dose. However, this depth-dose relation has the downside that it is very sensitive to small uncertainties in geometry and tissue composition, which are present in heterogeneous tissues such as lung tissue.<br/>Because of this sensitivity, it is essential that the dose delivery can be verified properly for these heterogeneous tissues, which requires highly accurate quality assurance. To improve this quality assurance, highly anthropomorphic phantoms could offer a solution. The currently commercially available phantoms however lack the high level of detail necessary, as these are produced using casting techniques. Thus a new production technique should be considered to create phantoms of greater heterogeneity and at a higher level of detail. A possible solution to this problem is to apply additive manufacturing, since this manufacturing technique can supposedly address both these issues.<br/>An important issue with the application of additive manufacturing is the lack of knowledge on the accuracy of 3D-printers. Next to the unknown accuracy, there are other challenges concerning additive manufacturing, such as the layered creation of objects and the material that is to be printed over an air cavity and the support structures this is associated with.<br/>The goal of this research is to explore the possibility to apply additive manufacturing in the creation of a phantom with a high level of detail and heterogeneity and the effect of the heterogeneous object on the quality of the Bragg peak. More specifically, simulations are performed on porous materials to quantify the degeneration of the Bragg peak. Also, a literature study on additive manufacturing will be performed, combined with the use of commercially available tabletop 3D-printers. Together, the capacity of the printer to create a high level of heterogeneity and the simulations performed on these heterogeneous structures, should give an indication on the feasibility to create a 3D-printed phantom for lung proton therapy.","","en","master thesis","","","","","","","","","","","","","",""
"uuid:da1015af-02c1-4c38-aad3-071390e5d7da","http://resolver.tudelft.nl/uuid:da1015af-02c1-4c38-aad3-071390e5d7da","Effects of upstream energy saving devices on engine operation","Sharma, Nikhil (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Marine and Transport Technology)","Visser, Klaas (mentor); de Vos, Peter (mentor); Delft University of Technology (degree granting institution)","2019","Rising carbon emissions and the International Maritime Organisation (IMO) have put immense pressure on ship owners to make ships more efficient. One way to make ships more efficient is to install an energy saving device (ESD). ESDs are designed to perform at vessel’s design speed and design draft. Thus, there is abundant information available on how they perform at the design speed or speeds close to it. However, their performance in part-load conditions remains a question mark. Although these devices are used for ships having a high block coefficient and ships that sail at their design speed or close to it for the most part of their voyage, it is still important to assess their performance in part-load conditions and how they affect the engine operation.<br/>The purpose of this thesis is to shed some light on the performance of three upstream ESDs on engine operation particularly, in part-load conditions. These three devices are Pre-duct, Pre-swirl stator and Mewis duct. Model tests and CFD self-propulsion simulations are used to assess their performance before implementing them. ESDs have been present since the first half of the 20th century. But despite that, their assumed working principle is still debatable. Performing simulations at all ship speeds is complex and time consuming. Hence, a new approach is proposed in this graduation report wherein a linear approach towards increase/decrease in specific propeller losses, influenced by the ESD, with respect to advance coefficient J is postulated. Advance coefficient is a dimensionless term defined as the ratio of the velocity of advance i.e the speed at which the water passes through the propeller disc, to the product of rotation rate and diameter of the propeller. The influence on losses is case dependent i.e depends on the type of ESD installed. The propeller is associated with three kinds of losses: axial, rotational and frictional losses. ESDs influence one or more of these losses to increase the propulsive efficiency. Therefore, the energy saving effect of these upstream ESDs increases linearly with advance coefficient. This new approach sheds some light on the performance of upstream ESDs i.e devices installed before the propeller, in part load conditions and helps in predicting their performance in low-medium speed range. This postulation is then implemented on a propeller loss diagram to make a simplistic model. This model is then implemented on the engine of a chemical tanker to assess the performance of the ESDs. The effect of these devices on engine operation is discussed and the model yields power savings for all the ESDs at design speed and speeds to close to it. However, it is found that power savings are marginal in part-load conditions even though the gain in propulsive efficiency is more or less the same at all speeds. This raises the question whether power savings in part-load condition even matter. A reduction in Energy Efficiency Design Index (EEDI) is also seen for the three ESDs. It is recommended to further study the postulation that the decrease or increase in losses associated with the propeller, influenced by these ESDs, varies linearly with advance coefficient.<br","Energy Saving Devices; Engine Operation; Mewis Duct; Pre-swirl stator; Pre-duct; EEDI","en","master thesis","","","","","","","","","","","","Marine Technology | Ship Design, Production and Operations","",""
"uuid:b4609d10-9318-465c-baa4-e945e7de1a96","http://resolver.tudelft.nl/uuid:b4609d10-9318-465c-baa4-e945e7de1a96","A governance model for managing Robotics Process Automation (RPA)","Orynbayeva, Altynay (TU Delft Technology, Policy and Management)","Janssen, Marijn (mentor); Hernandez Ganan, Carlos (graduation committee); Delft University of Technology (degree granting institution)","2019","Companies today are continually looking for new ways to digitize and automate their processes in order to maximize productivity and efficiency. Existing academic research has shown the efficiency and benefits of process automation using Robotics Process Automation (RPA). Through preliminary research, we observed that most of the companies have stagnated in a pilot or proof of concept of implementing RPA phase which implies that they are still learning how to manage RPA. The success of scaling up RPA lies in proper governance that may establish guidance, processes and mechanisms to manage and control the RPA activities in order to realize the expected benefits from technology. It is vital to assure that RPA robots are efficiently used, running as expected and following the security controls within the organization. There is a void in the academic literature which means that the current study does not provide a sufficient understanding of RPA governance, and there is no existing proper governance model for managing RPA. Therefore, the main goal of this master research is to develop a governance model for Robotics Process Automation using design science methodology from a management and operational perspective. The developed RPA governance model is based on the synthesis of the literature on RPA, IT and BPM governance and the findings from the case study analysis.","Robotics process automation; rpa; software bots; governance; Design Science Research","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:e64b56b7-ecdc-4f47-8aed-3dfbf7e269ac","http://resolver.tudelft.nl/uuid:e64b56b7-ecdc-4f47-8aed-3dfbf7e269ac","High-Throughput Big Data Analytics Through Accelerated Parquet to Arrow Conversion","van Leeuwen, Lars (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Quantum & Computer Engineering)","Al-Ars, Z. (mentor); Peltenburg, J.W. (graduation committee); Rellermeyer, Jan S. (graduation committee); Hofstee, H.P. (graduation committee); Delft University of Technology (degree granting institution)","2019","With the advent of high-bandwidth non-volatile storage devices, the classical assumption that database analytics applications are bottlenecked by CPUs having to wait for slow I/O devices is being flipped around. Instead, CPUs are no longer able to decompress and deserialize the data stored in storage-focused file formats fast enough to keep up with the speed at which compressed data is read from storage. In order to better utilize the increasing I/O bandwidth, this work proposes a hardware accelerated approach to converting storage-focused file formats to in-memory data structures. To that end, an FPGA-based Apache Parquet reading engine is developed that utilizes existing FPGA and memory interfacing hardware to write data to memory in Apache Arrow's in-memory format. A modular and expandable hardware architecture called the ParquetReader with out-of-the-box support for DELTA_BINARY_PACKED and DELTA_LENGTH_BYTE_ARRAY encodings is proposed and implemented on an Amazon EC2 F1 instance with an XCVU9P FPGA.<br/> <br/>The ParquetReader has great area efficiency, with a single ParquetReader only requiring between 1.18% and 2.79% of LUTs, between 1.27% and 2.92% of registers and between 2.13% and 4.47% of BRAM depending on the targeted input data type and encoding. This area efficiency allows for instantiating a large number of (possibly different) ParquetReaders for parallel workloads. Multiple Parquet files of varying types and encodings were generated in order to measure the performance of the ParquetReaders. A single engine has achieved up to 2.81x speedup for DELTA_LENGTH_BYTE_ARRAY encoded strings and 2.79x speedup for DELTA_BINARY_PACKED integers when compared to CPU-only Parquet reading implementations, attaining a throughput between 2.3 GB/s and 7.2 GB/s (limited by the interface bandwidth of the testing system) depending on the input data. The high throughput and low resource utilization of the ParquetReader allow for the interface bandwidth to be saturated using multiple ParquetReaders utilizing only a small amount of the FPGA's resources.","FPGA; Apache Parquet; Apache Arrow; Big Data; accelerator","en","master thesis","","","","","","","","","","","","Computer Engineering","",""
"uuid:dfa1af79-aef2-4517-a769-2f76ece984aa","http://resolver.tudelft.nl/uuid:dfa1af79-aef2-4517-a769-2f76ece984aa","Wireless Clock Synchronisation for UWB Positioning","Overman, Jeroen (TU Delft Electrical Engineering, Mathematics and Computer Science)","Langendoen, K.G. (mentor); Leus, G.J.T. (graduation committee); Van Den Heuvel, Dirk (mentor); Delft University of Technology (degree granting institution)","2019","An Indoor Positioning System (IPS) is being developed at TOPIC Embed- ded Systems to track equipment in hospitals. The system should prevent the loss of equipment en make procedures more efficient. The IPS will con- sist of anchors and tags. Anchors are the radios that form an infrastructure in the building to localise tags that are placed on equipment. Different localisation techniques and methods exist for indoor localisation, of which Ultra-wideband (UWB) is a very promising technology as it is robust to mul- tipath interference. Also the Time Difference of Arrival (TDoA) method has advantages over Two-way Ranging (TWR) in terms of energy consumption of a tag and the rate of supported location measurements. A fundamental requirement for Time Difference of Arrival (TDoA)-based localisation is that all anchors must be precisely synchronised as radio signals propagate trough air with the speed of light. Existing synchronisation solutions synchronise the anchors either trough wires or wirelessly. To keep the installation costs of the IPS to a minimum synchronisation should work without adding extra infrastructure to a building such as a clock distribution network. Therefore a wireless solution is required. The existing solutions have been evaluated on hardware equipped with precise clock sources that have tight tolerances. These clock sources are not available on the com- modity hardware (Decawave DWM1001) that is intended to be used by TOPIC. Also the existing synchronisation algorithms are not designed for large multi-hop networks. A new synchronisation algorithm based on a 3-state Kalman filter is devel- oped and evaluated with the existing solutions showing that linear interpola- tion performs the best in terms of the Mean Absolute Error (MAE),Ḣowever the linear-interpolation algorithm comes at the cost of a latency as the times- tamps become only available after the next synchronisation message. If the latency (order of seconds) cannot be tolerated, the developed 3-state Kalman filter is the best alternative. As TOPIC requires a latency of 5 min the linear-interpolation algorithm is integrated in a synchronisation scheme for multi-hop networks. This scheme has the additional ability to measure the propagation delay. The linear- interpolation algorithm is evaluated with practical experiments for single- hop and multi-hop synchronisation. The MAE of the synchronised clock is 229 ps for single hop and 258 ps for multi hop when using a synchronisation period of 1 s. This shows that that the synchronisation algorithm is very suitable for multi-hop networks. To determine the effect of the clock synchronisation on position accuracy an experiment has been conducted where anchors measure the TDoAs of a message sent by a tag. A standard multilateration algorithm [1] was usedto estimate the locations based on these measurements. The accuracy of an individual estimate was low, but by averaging subsequent measurements a mean error of 51 cm was achieved, meeting the requirement of 1 m accuracy.","Ultra Wideband; Indoor positioning system; clock synchronization; TDOA","en","master thesis","","","","","","","","","","","","Electrical Engineering | Embedded Systems","",""
"uuid:297bb0cf-f211-4700-a159-d330ef78c480","http://resolver.tudelft.nl/uuid:297bb0cf-f211-4700-a159-d330ef78c480","Enabling FPGA Memory Management for Big Data Applications Using Fletcher","Wijtemans, Lars (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Quantum & Computer Engineering)","Al-Ars, Z. (mentor); Hofstee, H.P. (graduation committee); Rellermeyer, Jan S. (graduation committee); Peltenburg, J.W. (graduation committee); Delft University of Technology (degree granting institution)","2019","vailability of FPGAs is increasing due to cloud service offerings. In the wake of a new in-memory storage format specification, Apache Arrow, FPGAs are increasingly interesting for data processing acceleration in the big data domain. The Fletcher framework can be used to easily develop FPGA accelerated applications that access data stored in Apache Arrow format, while providing throughput near the system’s limit. The current implementation of Fletcher has limited support for memory management of FPGA-local memory, with one of the biggest limitations being that memory can only be used once.<br/>This thesis explores several memory management techniques which could be suitable for use on FPGAs in a big data context. Paged memory is implemented on FPGA within the Fletcher framework in order to facilitate this memory management. The implemented system takes less than 5 % of a data centre FPGA card’s resources (Xilinx UltraScale+ VU9P). Experiments show that the paged memory provides throughput of over 99.7 % of the system’s throughput for linear memory accesses. Random memory access throughput for paged memory drops to between 30 % and 90 % of the system’s original throughput, depending on request size. The performance drop can be lightened or even prevented by employing suitable address-translation caches.","FPGA; memory management; Big Data; Fletcher","en","master thesis","","","","","","","","","","","","Electrical Engineering | Embedded Systems","",""
"uuid:b5ba4bc4-5c33-4cb7-82cd-08878bc01800","http://resolver.tudelft.nl/uuid:b5ba4bc4-5c33-4cb7-82cd-08878bc01800","Ex vivo Validation of PET Imaging by 3D-printed Phantoms","Groenendijk, Celebrity (TU Delft Mechanical, Maritime and Materials Engineering)","Schaart, D.R. (mentor); Delft University of Technology (degree granting institution)","2019","","","en","master thesis","","","","","","","","2020-08-01","","","","Biomedical Engineering | Medical Physics","",""
"uuid:f8619273-0e7e-42e3-990b-67e2f6edc78a","http://resolver.tudelft.nl/uuid:f8619273-0e7e-42e3-990b-67e2f6edc78a","Addressing Illumination-Based Domain Shifts in Deep Learning: A Physics-Based Approach","Lengyel, Attila (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Gemert, Jan (mentor); Reinders, Marcel (graduation committee); Hildebrandt, Klaus (graduation committee); Milford, Michael (mentor); Delft University of Technology (degree granting institution)","2019","This work investigates how prior knowledge from physics-based reflection models can be used to improve the performance of semantic segmentation models under an illumination-based domain shift. We implement various color invariants as a preprocessing step and find that CNNs trained on these color invariants get stuck in worse local minima compared to RGB inputs, but can achieve comparable or even superior performance when applying knowledge transfer from RGB. We also find Batch Normalization to severely affect the performance of neural networks under an illumination-based domain shift and demonstrate that Instance Normalization offers a simple remedy to this issue. Additionally, we investigate different fusion models for combining color invariants with RGB. Using a combination of these methods we achieve a 14.5% performance increase on nighttime semantic segmentation without any additional training data.","Semantic segmentation; color invariants; deep learning; computer vision; domain adaptation","en","master thesis","","","","","","","","","","","","","",""
"uuid:b07fae92-9080-4d1d-b8d9-c9f446a03083","http://resolver.tudelft.nl/uuid:b07fae92-9080-4d1d-b8d9-c9f446a03083","Designing Communication Triggers for the Flexible Office Setting","Yilmaz, Nazli (TU Delft Industrial Design Engineering; TU Delft Industrial Design)","Jaskiewicz, Tomasz (mentor); Bourgeois, Jacky (graduation committee); Delft University of Technology (degree granting institution)","2019","With the rise of remote working opportunities, the definition of office is changing and this is also affecting the way that we shape our offices. Nowadays, more and more companies are switching to the flexible workspace. This shift is redefining the relationships and the communication motives colleagues have with each other. The project explores how the hindered aspect of communication can be revived with triggers in order to help the employees form deeper relationships. This is done via an iterative design process. The end results are guidelines for designing triggers and a digital product that houses the communication triggers.","Digital Design; Communication; Office; Data; Flexible; Iterative; Triggers; Interaction","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:7a9df9fb-5dc4-4d72-a966-45edbb2bc942","http://resolver.tudelft.nl/uuid:7a9df9fb-5dc4-4d72-a966-45edbb2bc942","Black Magic in Deep Learning: Understanding the role of humans in hyperparameter optimization","Anand, Kanav (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Pattern Recognition and Bioinformatics)","van Gemert, Jan (mentor); Loog, Marco (graduation committee); Wang, Ziqi (mentor); Delft University of Technology (degree granting institution)","2019","Deep learning is proving to be a useful tool in solving problems from various domains. Despite a rich research activity leading to numerous interesting deep learning models, recent large scale studies have shown that with hyperparameter optimization it is hard to distinguish these models based on their final performance. Hyperparameter optimization has shown to improve the state of the art results on several occasions. These results cast the doubts over the performance of these improved deep learning models and lead to the question whether the final performance of a deep learning model is dependent on the person performing the hyperparameter optimization task. A user study was conducted to evaluate the impact of human's prior experience in deep learning on the final performance of a deep learning model. 31 people with different levels of experience in deep learning were invited to perform a hyperparameter optimization task. The collected data was analyzed to find the relationship between human and the final performance of the deep learning model used for the user study. From the results, we observed that the final performance of the model vary with every participant, and a strong correlation between the participant's experience and the final performance achieved. Our data suggest that an experienced participant finds better results using fewer resources.","hyperparameter optimization; deep learning; machine learning; user study","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:47dd983a-0fef-4a8a-a100-5d0603cae9d5","http://resolver.tudelft.nl/uuid:47dd983a-0fef-4a8a-a100-5d0603cae9d5","Text-based conversational interface as an alternative to a crowdsensing mobile application","Thuraka, Neha (TU Delft Electrical Engineering, Mathematics and Computer Science)","Bozzon, Alessandro (mentor); Lofi, Christoph (graduation committee); Wang, Huijuan (graduation committee); Delft University of Technology (degree granting institution)","2019","Crowdsensing is a powerful tool to easily sense diverse physical environments by collecting data from an undefined network of people. With advancements in smartphone technology, there has been an increase in the use of mobile applications to perform crowdsensing tasks. However, previous work shows that mobile applications have issues with attracting and retaining users, thus limiting the utility of crowdsensing as a data collection technique. To mitigate these issues, we propose the use of conversational agents (chatbots) as an alternative to custom mobile applications for crowdsensing applications. We hypothesize that the use of commonly used text-based applications (e.g., Telegram) enriched with the automated conversational capabilities can increase the attraction and retention of crowdsensing participants. <br/><br/>In this thesis, we designed and implemented a crowdsensing system that supports the execution of mobile and chatbot interface. We propose a design of the text-based conversational interface that provides different elements and features of a traditional mobile application. To compare these two interfaces for performing crowdsensing tasks and to understand the differences in terms of user engagement and usability, we conducted two experiments on the TU Delft campus with students as the participants. Based on the location of the experiment, we designed four task domains and three types of tasks. <br/><br/>In the first experiment, we organized a 'between-subjects' study. We recruited 80 students to analyze user engagement and usability in a quantitative fashion. The experiment shows that chatbot has better user engagement and usability than the mobile application. We conducted a qualitative survey to understand the underlying reasons behind the participation patterns. Analysis of the results of this survey shows that the unavailability of the participants and the assignment of inappropriate tasks are the main reasons behind non-participation of some students.<br/><br/>To deepen our analysis, we organized the second experiment as a 'within-subjects' study with 10 participants in a controlled environment. The experiment shows that all participants unanimously preferred chatbot over the mobile application to perform crowdsensing tasks. <br/><br/>As a result of both experiments, we conclude that the text-based conversational interface can be used as an alternative to the mobile application to execute crowdsensing tasks and the former is more engaging than a mobile application interface for crowdsensing applications.<br/><br/><br/><br","Chatbot; crowdsensing; User engagement","en","master thesis","","","","","","","","","","","","","",""
"uuid:778766d3-b500-40d7-8117-e081223b5d4e","http://resolver.tudelft.nl/uuid:778766d3-b500-40d7-8117-e081223b5d4e","Active inference for adaptive and fault tolerant control: An application to robot manipulators","Pezzato, Corrado (TU Delft Mechanical, Maritime and Materials Engineering)","Ferrari, Riccardo (mentor); Hernandez Corbato, Carlos (mentor); Wisse, Martijn (graduation committee); Kok, Manon (graduation committee); Delft University of Technology (degree granting institution)","2019","Dealing with inherently unmodeled dynamics and large parameter variations or faults, is a challenging task while controlling robot manipulators. Classical control techniques cannot usually provide satisfactory responses, and often external supervision systems have to be designed to handle the faults. Recent research has shown that active inference, a unifying neuroscientific theory of the brain, bares the potential of intrinsically coping with strong uncertainties in the system, mimicking the adaptability capabilities of humans. However, the current state-of-the-art regarding active inference in robotics is very narrow and limited. This thesis presents a novel active inference controller as a general adaptive fault tolerant solution for control of robot manipulators. The goal of this work is threefold. First, we demonstrate the applicability of active inference in robotics, deriving a control scheme which is computationally efficient and with high performance. Second, we verify the claimed adaptability properties of active inference against a model reference adaptive controller, in a simulated on-line pick and place task with a 7 degrees-of-freedom robot arm. Third, we propose a method to exploit the controller's structure to perform fault detection, isolation and recovery, without the use of external supervision systems. This work showed that not only active inference is applicable to robotics, but it also outperforms the model reference adaptive controller, and it allows to efficiently deal with sensory faults. This thesis represents a leap forward with respect to the current state-of-the-art of active inference for robotics, and it lays the foundations for further research in this direction.","Active inference; Free-energy principle; Adaptive control; Fault tolerant control; Robot arm control","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:c7c9c170-eb70-4cf2-adfb-1d08bc1b74d7","http://resolver.tudelft.nl/uuid:c7c9c170-eb70-4cf2-adfb-1d08bc1b74d7","Automated classification of satellite data of informal urban settlements","Zhou, Zequn (TU Delft Electrical Engineering, Mathematics and Computer Science)","Yorke-Smith, Neil (mentor); Rózsás, Árpád (mentor); Delft University of Technology (degree granting institution)","2019","Urban areas are rapidly expanding in developing countries. One of goals of the United Nations Human Settlement Programme (UN-Habitat) is to understand and guide urban development for some developing regions.<br/>Currently, the approaches that UN-Habitat is using cost plenty of workforce, material, and time. Therefore, UN-Habitat is interested in exploring new approaches on how to drive down costs and time, which would not only allow for faster responses but expanding their analysis. Since UN-Habit is already using satellite imagery for urban mapping, our research question is formulated as: Can we develop an automated system that provides valuable information about urban development for the UN-Habitat from satellite image data (e.g. building detection)?<br/><br/>After examining the satellite imagery provided by UN-Habitat and those available publicly (crowd AI and Inria Areial datasets), we define the main task as a building segmentation task. In this research, we study deep learning techniques for building segmentation on satellite image data.<br/>Duo to the fact that the number of images and the quality available for the region of interest (Middle East) for UN-Habitat are insufficient to solely rely on for training. Therefore, we use some public datasets (crowd AI and Inria Areial datasets) for training and evaluation, whose regions and construction practice are different. <br/>Starting with testing several classic segmentation algorithms (FCN8S, SegNet, Deep\_Lab and U-Net), from the experiment results, we find that the performance can still be improved. Then, we propose two novel data reweighing methods, named border weight and inter-building distance weight, to improve the detection performance. By increasing the weights of the pixels outside but close to the border of the buildings, the model is encouraged to learn those information and thus performs better. Inspired by the idea of reweighing the non-building pixels, we investigate whether modifying building pixels can achieve further improvement. We propose a new label representation -- multi-level boundary label that does help to improve the segmentation results. Based on the distance to the building boundary, we can divide building pixels into multiple classes, as their pixel values can be affected by some factors such as trees and shadows. From the experiment result, we can see that the performance is improved since the model captures more information about the buildings. Next, we propose a new neural network architecture that utilizes the two pixel weights, and the multi-level boundary label explained above. Our proposed model achieves state-of-the-art building segmentation performance compared with several classic segmentation methods. <br/>For example, the proposed model's mean intersection of union on the test dataset is 3\% higher than that of FCN8S. <br/>Our model also uses fewer number of parameters (~16 million in total) because we only use the first 13 layers of the VGG16 as the encoder and we do not use any convolutional layers in the decoder part. <br/><br/>The results using the publicly available datasets show that with enough good quality input the building segmentation is possible, hence should be possible in other regions as well.<br/>To see the performance of our proposed model on the UN-Habitat dataset, we train our model with public datasets (crowd AI and Inria Areial datasets) and then use transfer learning to fit the UN-Habitat dataset.<br/>The building detection performance is reduced still good results are obtained. For achieving comparable performance in the region of interest for UN-Habitat more labelled data is needed. Based on the results using the publicly available datasets, we are confident that a comparable performance is attainable. <br/><br/>Regarding the research question, our answer is definitely yes. We not only show that it is possible to obtain information about urban development from satellite image but also propose a new model with great performance in our work.","deep learning; Semantic segmentation; Satellite Imagery; buildng detection","en","master thesis","","","","","","","","","","","","Computer Science | Data Science and Technology","",""
"uuid:55bc8c26-40c2-4f3a-a352-9f18b9a6391b","http://resolver.tudelft.nl/uuid:55bc8c26-40c2-4f3a-a352-9f18b9a6391b","Dry Deep Soil Mixing Soil-Cement column panels as bottom struts for excavation support: Revising of design methodology in Scandinavia","Santos Barros, Andres Alfonso (TU Delft Civil Engineering and Geosciences; TU Delft Geo-engineering; Civil7)","Korff, Mandy (mentor); Broere, Wout (graduation committee); Lanzafame, Robert (graduation committee); Vervoorn, Robin (graduation committee); Delft University of Technology (degree granting institution)","2019","Deep Soil Mixing is an often-applied technique in the reinforcement of embankments, but little has been done to investigate and understand its behavior when used in excavation projects. The present research presents a database of the results of previous studies on the Deep Soil Mixing technique in Scandinavian soils. An expression that can estimate the improved soil strength when a specific binder content and binder ratio is mixed with the soil is proposed and its pertinence is tested with two full-scale tests. The proposed mathematical expression to predict the improved strength yields a good representation of the available data. The full-scale tests, in which a braced steel sheet pile wall interacts with panels of DSM overlapping columns are used for back-calculating the improved soil strength and stiffness properties. It is observed that the weighted average procedure for calculating properties should be used with care and that the loading conditions affect the strength and stiffness that the improved soil can develop. The drained analysis with a fixed friction angle and a cohesion intercept estimated from the undrained shear strength is the suggested design procedure to assess deep excavations involving improved materials.","Deep Soil Mixing; Dry Deep Mixing; Overlapping column struts; Deep excavation","en","master thesis","","","","","","","","","","","","","",""
"uuid:c4d93f88-b7ab-4582-ab67-6dbcaac079f7","http://resolver.tudelft.nl/uuid:c4d93f88-b7ab-4582-ab67-6dbcaac079f7","Power to methane to power: Performance analysis of a closed loop energy storage system","Goorden, Marjolijn (TU Delft Mechanical, Maritime and Materials Engineering)","Kortlever, Ruud (mentor); Ramirez Ramirez, Andrea (graduation committee); Delft University of Technology (degree granting institution)","2019","Reducing carbon emissions in the power generation sector can be done by generating energy from renewable sources such as wind and sun. However these sources alone cannot provide a reliable electricity system and therefore an energy storage system is needed. Power-to-gas is a concept in which surplus renewable electricity is used for the production a gas fuel. The gas can be stored and is used for electricity production when there is a deficit in renewable electricity. When CO2 exhaust gases form reactants for new production of gas, the system has no net CO2 emissions. The gas functions as an energy carrier for electrical energy. Methane could be an interesting gas for large scale energy storage as there is much knowledge about methane transport, storage and combustion and the gas is easier to store than hydrogen. Power-to-gas-to-power conversions come with great electricity losses. Therefore it is interesting to investigate what waste heat streams can be extracted from the process to use for external purposes. The aim of this thesis is to map the input and output energy streams of a power-to-methane-to-power system operating in 2030 to find the efficiency of the system and to see how efficiency could be maximized by using waste heat streams for external purposes. Also, a power-to-methane-to-power system requires a lot of gas storage capacity. Therefore it is useful to estimate the capacity of the gas storage facility to find if the system is technically feasible and to see what gas storage does with the efficiency of the system. Last, since the aim is to reduce carbon emissions the (small) CO2 emissions of the system are determined and analyzed. The system is scaled up to a scenario in which it provides a fully renewable electricity grid in the year 2050, to explore the feasibility in terms of carbon emissions and required gas storage capacity. The system is also compared to a power-to-hydrogen-to-power system to find the most feasible solution. The round trip energy efficiency of the system in 2030 is 88.0%, which is the sum of an electrical efficiency of 30.0% and a thermal efficiency of 57.1% The total energy efficiency can only be achieved when streams modeled as usable heat output streams can actually be used. This depends highly on the location of the system. The carbons emissions of a system with a 44MW output in 2030 are 56.3kt and the required gas storage capacity is 5.09 x 10^5 m3 of underground salt caverns. When scaling up the system to provide a fully renewable electricity grid, the total gas storage capacity is 9.34 x 10^7 m3, which is 5.5% of the total potential salt cavern volume in the Netherlands. The carbon emissions are 2.78 kt/y, which is 0.0056% of the current annual carbon emissions caused by the Dutch power generation sector. Compared to a hydrogen system the methane system performs worse in term of electrical efficiency, gas storage capacity and carbon emissions.","Energy storage; power to gas; Energy system; Renewable Energy","en","master thesis","","","","","","","","","","","","","",""
"uuid:36d382d8-3ba4-4825-b718-a080b01b0649","http://resolver.tudelft.nl/uuid:36d382d8-3ba4-4825-b718-a080b01b0649","A type system for dynamic instances","ten Napel, Albert (TU Delft Electrical Engineering, Mathematics and Computer Science)","Krebbers, Robbert (mentor); Poulsen, Casper (graduation committee); Delft University of Technology (degree granting institution)","2019","Side-effect are ubiquitous in programming. Examples include mutable state, exceptions, non-determinism, and user input. Algebraic effects and handlers are an approach to programming that gives a structured way of programming with effects. Each effect in a system with algebraic effects is defined by a set of operations. These operations can then be called anywhere in a program. Using a handler we can give an interpretation for the operations used. Unfortunately we are unable to express dynamic effects using regular algebraic effects, such as the dynamic creation of mutable references. Extending algebraic effects with effect instances enables us to express dynamic effects. These effect instances can be dynamically created and operations called on them are distinct from the same operation called on a different instance. Without a type system effect instances may result in runtime errors, because operation calls may be left unhandled. Because of their dynamic nature it is hard to give a type system for effect instances. In this thesis we present a new language, Miro, which extends algebraic effects and handlers with a restricted form of effect instances. We introduce the notion of an effect scope which encapsulates the creation and usage of dynamically created effect instances. We give a formal description of the syntax and semantics of Miro. We also give a type system which ensures that all operation calls are handled, so that there will be no runtime errors because of unhandled operation calls. Because effect instances can still escape their effect scope, in computationally irrelevant parts, we encounter difficulties in proving type safety for Miro. We discuss these difficulties and give a possible approach to prove type safety in the future.","algebraic effects","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:55668006-0331-4f62-b358-ccbf4f421e07","http://resolver.tudelft.nl/uuid:55668006-0331-4f62-b358-ccbf4f421e07","Hedging strategies to mitigate electricity price volatility exposure using storage units","Karthikeyan, Kritika (TU Delft Electrical Engineering, Mathematics and Computer Science)","Cvetkovic, Milos (mentor); Rueda, José L. (graduation committee); Stikkelman, Rob (graduation committee); Chakraborty, Shantanu (graduation committee); Delft University of Technology (degree granting institution)","2019","The ambitious energy policy goals set by the European Union have accelerated the pace at which energy efficiency and clean energy measures are being adopted. The Netherlands, lagging behind by a massive margin in transitioning to a green energy infrastructure, feel the need, now more than ever, to push the integration of renewable energy into the grid. The state of the electricity industry has remained almost the same ever since its inception, but has undergone relatively significant changes in the past two decades. The main advancements being decreasing costs of clean energy technologies like solar panels and storage solutions, increasing electricity demand, changing policy &amp; regulations to achieve decarbonization and the active attempt to phase out fossil fuel energy sources like coal. However, changing the energy mix in the electricity grid is bound to make grid management more cumbersome, owing to the intermittency posed by the renewable energy sources and their lack of flexibility, leading to extreme volatility in the electricity market prices. The inertial characteristics of the heavy rotating masses of fossil-powered plants allow traditional power plants to provide flexibility in the grid. Flexibility, in this thesis, is defined as the system’s ability to respond to uncertain generation and demand, while maintaining a constant energy balance. Inertia, in the simplest terms, refers to the resistance provided by an object to a sudden change in motion. As renewables begin replacing conventional power plants, the flexibility required will have to be provided by solutions that allow the electricity generated from the renewables to be stored and used later, which also provides an avenue to hedge the risks from volatile electricity prices. Energy Storage is identified by the Dutch government as one of the most important techniques to provide flexibility surpassing alternatives like Demand Response and Energy Efficiency. This thesis proposes a new approach to design a hedging strategy using energy storage systems. It aims to hedge the risks arising from daily price volatility in the electricity market, that the various stakeholders in the distribution grid are subjected to, caused by factors like increasing grid penetration of renewables, increasing carbon prices etc. “Hedging” in this study, is the act of risk aversion by taking a certain action in the present to avoid a future consequential risk. The ability to store electricity after purchasing from the wholesale market, when looked at from an economic point of view, directly points to being able to store electricity when its in excess (accordingly also cheapest) and to sell it when it is most expensive. This is referred to as “energy arbitrage via electricity prices” and is carried out in the research presented in this work. Along with arbitrage, the strategy also proposes the idea of also being self-sufficient during period of high electricity prices. The significance of emphasizing electricity prices in the term “energy arbitrage via electricity prices” is because energy arbitrage can also be used for technical services like peak shaving that looks into the capacity constraints of the grid, which is beyond the scope of this thesis. The scope of this thesis is to find an analytical approach to design a hedging strategy, to monetize on volatility in the day-ahead electricity market to its maximum potential, for the stakeholders like energy suppliers (that do not own generation assets) in the distribution grid.","","en","master thesis","","","","","","","","2020-08-26","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:c70b9485-60ad-4a72-aa1e-2ad014c6d89b","http://resolver.tudelft.nl/uuid:c70b9485-60ad-4a72-aa1e-2ad014c6d89b","Urban Foraging and Commoning: How can commoning support the practice of urban foraging?","de Wolde, Lotte (TU Delft Industrial Design Engineering)","Bendor, Roy (graduation committee); de Koning, Jotte (mentor); Delft University of Technology (degree granting institution)","2019","This design project investigates how commoning can support the practice of urban foraging, resulting in a framework that describes the social characteristics of commoning and the abilities and opportunities for urban foraging. The framework led to a design showcase, called Get To Gather, which is an interactive board in public space to let citizens experience the practice of urban foraging, as an entrance to the foraging community.<br/><br/>Commoning is a verb of “commons” that describes the social process to manage the commons. The goal of the commons movement is to reclaim commonwealth, and transform the focus on privatization into collective use of resources while preventing them from being commercialized. Commoning is a social process that relies on active collaboration and cooperation.<br/> <br/>The practice of urban foraging describes going from place to place searching for things to eat or use, in an urban context. Foraged food is also described as “zero-footprint food” since it is entirely outside the profit-making food production system we know today, which provides people to live self-sufficient and supports a resilient food production system in the city. Foraging goes beyond the consumption of wild edible plants because it is a social activity, in which people pass on knowledge, culture, and traditions from generation to generation. This project focuses on foraging as a leisure activity in the Netherlands. <br/><br/>Foraging is getting more popular, which resulted in the concern of external authorities about the safety of people and the environment. Also, beginner foragers experience fear of eating poisonous or dirty plants in the city. In combination with the social motivations of urban foraging, this resulted in an inspiring and robust network, a community that wants to make sure that everyone forages safely and with care for the environment. Therefore, the community expresses a need to involve beginner foragers into their network.<br/>Urban foraging is an act that transforms unused urban nature into a place with social interactions. In the city, there are fragmented municipal plots that do not fulfill a specific function. In this report, these areas are man’s lands. The final design is an entrance to the foraging community at these locations, to create awareness about the community, and involve beginner foragers to teach them how to treat the environment correctly and perform the practice safely. The design is ‘do it yourself,’ so people can make the design by themselves without waiting for external authorities. Get To Gather transforms unused urban green spaces into places for social access. <br/><br/>The design shows how commoning can support the practice of urban foraging, by making the foraging community, and nature in the city equitable accessible for people outside the community. It frames urban foraging as a practice with social benefits, by showing the community, in which foragers have strong social ties with fellow foragers.","Commoning; Urban Foraging; Community","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:99998698-7287-47e9-acd0-9d7cc1d78670","http://resolver.tudelft.nl/uuid:99998698-7287-47e9-acd0-9d7cc1d78670","Variable Fractional Order (VFO) PID Control for Precision Positioning: A Frequency Domain Approach","Nagda, Neel (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Delft Center for Systems and Control; TU Delft Precision and Microsystems Engineering)","van Wingerden, Jan-Willem (graduation committee); Giordano, Giulia (mentor); Hossein Nia Kani, Hassan (mentor); Saikumar, Niranjan (mentor); Delft University of Technology (degree granting institution)","2019","Stringent control demands from the high-tech mechatronics industry have warranted the need to explore potentially advantageous non-linear controllers. Variable Fractional Order (VFO) calculus provides one such avenue to build non-linear PID-like controllers. VFO calculus is the generalization of integer order differentiation and integration, where, in addition to the possibility of orders being real or even complex, the orders can vary as a function of a variable like time, temperature, etc. However, in this nascent field of VFO control, the focus has mainly been on controller tuning by time domain optimization of the performance for certain specific trajectories or cost functions. On the other hand, Frequency domain tools allow for analysis and tuning of controllers for performance over a wide range of exogenous inputs. For smooth adoption into industry, it is important to develop a frequency domain framework for working with VFO control. Describing function (DF) analysis is a method to obtain an approximate Frequency Response Function (FRF)-like function for non-linear systems. In this thesis, DF analysis is used for developing VFO PID controllers in the frequency domain from an industry compatibility point of view and the closed loop performance of these controllers in controlling a precision positioning stage is examined.<br","PID; Variable Fractional Order calculus; Describing Function analysis; SIDF; HOSIDFs; Precision positioning","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:21e9731a-6ec3-4230-847f-38ffa364ba8a","http://resolver.tudelft.nl/uuid:21e9731a-6ec3-4230-847f-38ffa364ba8a","Night-Time Train Travel: A Stated-Preference study into the Willingness to Use night trains for European long-distance travel","Heufke Kantelaar, Martijn (TU Delft Civil Engineering and Geosciences)","van Wee, Bert (mentor); Molin, Eric (graduation committee); Cats, Oded (graduation committee); Donners, B. J. H. F. (graduation committee); Delft University of Technology (degree granting institution)","2019","Limiting climate change forces us to switch to a more sustainable mobility. Travelling by train is more sustainable. Night trains might be a solution, they over several advantages such as a higher comfort level and can travel long-distances during the night. However, there currently is no knowledge about the Willingness to Use night trains. This study is the first into this Willingness to Use night trains, as an alternative for flying, for long-distance European travel. To do so, this paper makes use of two Stated-Preference experiments. A comfort rating experiment, in which the comfort rating is the dependent variable. In this experiment, it is explored to which extent night train characteristics influence the ’perceived comfort’ rating. In the mode choice experiment, it is in turn investigated how this comfort rating is traded-off against more traditional mode choice attributes such as trip time and trip costs. The study presents the results of linear regression and a Panel Mixed Logit model, estimated on 804 collected responses in the Netherlands. The results of both models are combined to derive Willingness-to-Pay values for an improvement in one of the comfort attributes, given an initial comfort level. Furthermore, several segments were identified using a latent class choice model. At last, the Willingness to Use the night train is explored for several scenarios. It is shown that when the night train is introduced as-is, it is predicted to have a market share of about 60%. Positioning the night train as a low-cost competitor results in a significant drop in market share.","Night train; Perceived comfort; long-distance mode choice; Panel Mixed Logit model; Hierarchical Information Integration","en","master thesis","","","","","","","","","","","","Transport, Infrastructure and Logistics","",""
"uuid:ba966be0-022c-46e1-99a3-5fe65761a7ea","http://resolver.tudelft.nl/uuid:ba966be0-022c-46e1-99a3-5fe65761a7ea","Een adaptief Monte Carlo algoritme voor het schatten van de dominante eigenwaarde en eigenvector","Brands, Marnix (TU Delft Electrical Engineering, Mathematics and Computer Science)","Meester, Ludolf (mentor); van den Dries, Bart (graduation committee); Cai, Juanjuan (graduation committee); Delft University of Technology (degree granting institution)","2019","In dit onderzoek is een Monte Carlo algoritme beschreven voor het schatten van de dominante eigenwaarde en bijbehorende eigenvector van een niet-negatieve, irreducibele matrix. Naast de werking van het Monte Carlo algoritme is ook de convergentiesnelheid onderzocht. Tevens zijn een aantal simulaties in de praktijk uitgevoerd voor zowel het Monte Carlo algoritme als de power methode en aan de hand hiervan bekeken of het Monte Carlo algoritme een goede concurrent is van de power methode.","Monte Carlo simulatie; Eigenwaarde; Eigenvector; Convergentiesnelheid; Power methode","nl","bachelor thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:8ce7e5e2-6024-4530-9313-22e05b41f077","http://resolver.tudelft.nl/uuid:8ce7e5e2-6024-4530-9313-22e05b41f077","Adoption of Electric Bicycle for the Daily Commute: Investigating Behavioral Factors in a Pilot Study","Kocaman, Mina (TU Delft Technology, Policy and Management)","Annema, Jan Anne (mentor); de Vries, Gerdien (graduation committee); van Wee, Bert (graduation committee); Delft University of Technology (degree granting institution)","2019","Cycling as a way of commuting is becoming more attractive from the eyes of the public, employers, and policymakers. By offering the ability to go faster with less physical effort, electric bicycles (e-bikes) can motivate more people to cycle to work. While the numbers of e-bicycles sold in the Netherlands is increasing (BOVAG-RAI, 2017; Plazier, Weitkamp, &amp; van den Berg, 2017b), to reduce the amount of cars in traffic there have been initiatives to help e-bikes penetrate the market faster. However, there is a lack of research on the behavioral process to guide intervention-designers on how to facilitate this process further. To build on this gap, a case study in taken on hand: the green mobility program of Delft University of Technology (TU Delft) to explore the research question: What explains the behavioral factors behind the adoption of e-bikes as the daily commute? Within the program, there is an e-bike pilot that allows people to replace their cars with an e-bike for two months. Using TU Delft's e-bike adaptors and triers as a sample, this thesis aims to answer what explains the behavioral factors behind the adoption of e-bikes as the daily commute. A theory is needed to explain the behaviour scientifically. Theory of Planned Behaviour (TPB) of Ajzen (1991) was chosen as it has been used in similar research before. This theory assumes that people's attitudes, perceived behavioral control (PBC) and subjective norms (SN) around the behaviour affects their intention, which affects the behaviour together with PBC. For this case, behaviour is defined as buying the e-bike, and an exploratory conceptual model is built. Surveys have been used to collect data that has been used for quantitative estimation of the model. Multiple regression and descriptive statistics have been used for the estimates. As the sample size was relatively small (n=75), and the survey did not cover all factors of the TPB, to support the quantitative part, interviews were conducted with pilot participants and current e-bikers. Triangulation of quantitative and qualitative methods allowed concluding the research question and supported each other's limitations. The results show that TPB can be used to explain people's intention to buy an e-bike is affected by their attitudes, perceived behavioral controls, and intentions that surrounds commuting with an e-bike. Factors such as time savings, prices, convenience, enjoyment, responsibilities, health, weather, and societal perceptions affect people's intentions to use an e-bike or not. The most important finding is that these intentions are mainly blocked by the financial barrier. Options such as leasing or financial subsidies can be explored to lower this barrier. These findings were mainly in line with previous work of other researchers, and they have several societal and scientific implications. First, as the results are in line with research from countries with different cycling maturities, it shows that Dutch cycling research can be relevant for other settings as well. Second, while it is not a full confirmatory model, it can be said that TPB can indeed explain adopting e-cycling as a habit. However, further research is needed with a larger sample and a broader range of questions. Third, findings indicate that pilots are successful in facilitating e-cycling as they can change attitudes and PBC of individuals and SN indirectly. Fourth, as the initial investment of an e-bike is relatively higher than of a regular bicycle, this price difference remains as one of the main reasons behind the gap between intention and behaviour as people are risk-averse. Options, such as leasing, which will be easier with upcoming regulations in Dutch law, can lower the threshold. Fifth, faster e-bikes, speed pedelecs could facilitate cycling more as they allow better time savings. In short, policy-makers and employers can use pilots and better policies to increase e-cyclists and lower drivers. Several gaps have been identified. Future researchers can look into these to generate better and more important results. Moreover, they can use the exploratory conceptual models that result from the research to build better surveys that use TPB to explain changes in commuting mode changes, even outside the domain of e-bikes. For practical purposes, this thesis has important outcomes for TU Delft. Firstly, many employees expect the university to take measures to give incentives for cycling financially, such as participating in the new tax scheme that makes leasing easier or adopting a bicycle plan again. Secondly, participants and employees generally saw the pilot positively, especially the way it was professionally organized. Thirdly, it is possible that promoting cycling is not enough to push people out of the cars, and additional car-demotivating actions should be put into place. Lastly, a faster e-bike option, speed pedelecs could get more people to leave their cars as time savings are higher. It also gives insights into the behavioral process of changing commuting mode, of which pilot designers and policymakers can utilize to design better interventions to motivate people to switch to e-bikes. To extend the knowledge in the area, researchers can firstly focus on longitudinal studies with larger sample sizes to further investigate the suitability of TPB to offer guidance for policy-makers. Second, they can investigate how different financial incentives affect people's intentions and behaviour. Third, speed pedelecs need more attention as they have different barriers and different motivators, at least in the Netherlands. Fourth, e-bike research and pilots in non-cycling mature contexts could be interesting as the impact can is larger. Fifth, other theories can be used in similar research as well to compare whether or not they fit better than TPB or not. In conclusion, this thesis fits adopting e-biking into a behavioral theory context and offers insights to those who work to increase the percentage, in a similar context to TU Delft or not.","Theory of planned behaviour; commute; e-bike; Transportation","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:ed39f209-1193-4704-a972-01307cb1e478","http://resolver.tudelft.nl/uuid:ed39f209-1193-4704-a972-01307cb1e478","A Wireless Sensor Network for Machine Dynamics Performance Monitoring","Torres Di Zeo, Alvaro (TU Delft Electrical Engineering, Mathematics and Computer Science)","Nihtianov, Stoyan (mentor); Fan, Qinwen (graduation committee); Mc Cune Jr, Earl (graduation committee); Delft University of Technology (degree granting institution)","2019","The availability of photolithography machines is key in the semiconductor industry, as downtime generally incurs in immense economic loss. Time to market is also very important for suppliers of photolithography systems, such as ASML. Photolithography machines include numerous measurement systems that are frequently used for qualification and troubleshooting, most of which are required during normal operation. Due to increased costs and complexity, it would not be practical to include dedicated sensors for every machine performance parameter relevant for diagnosis, therefore many parameters regarded as non-critical are not monitored. However, in some cases the information about the behaviour of these parameters can be very valuable to find the root cause of a failure or defect promptly. In these cases, a Wireless Sensor Network (WSN) would allow for a temporary installation of a measurement system to monitor such parameters.<br/><br/>This work presents the design of a WSN for monitoring the dynamics performance of the WaferHandler (WH), which is one of the major subsystems of a photolithography machine. The scope of the project includes:<br/><br/>• The selection of a radio technology on which the network is based on.<br/>• The hardware design of a wireless sensor node for measuring acceleration, based on commercial off-the-shelf (COTS) components.<br/>• The identification and firmware implementation of key principles in which the communication protocol should be based on according to the requirements of the application.<br/>• The estimation of the power consumption and lifetime of the network.<br/>• The design and execution of experiments to assess the reliability of the proposed solution.<br/><br/>Among the requirements of the system, the size of the sensor nodes, the network synchronization accuracy, and the maximum power dissipation stand out as the main challenges. As the available space inside the WH is very scarce, the sensor nodes must have a compact form factor to fit in the locations where they are meant to be installed. The reliability of the system is greatly determined by its capacity to remain synchronized with relatively high accuracy during a measurement. This can be difficult to achieve in a harsh environment such as the inside of a machine, where interference and signal fading are expected to recurrently cause the loss of packets used for network synchronization.Packet re-transmission should not be abused to alleviate the problem, as the sensor nodes are required to operate in vacuum and overheating can become a problem.","wireless sensor networks; clock synchronization; machine condition monitoring","en","master thesis","","","","","","","","","","","","","",""
"uuid:362322df-a774-4926-828a-625fa5ff94c4","http://resolver.tudelft.nl/uuid:362322df-a774-4926-828a-625fa5ff94c4","Decomposing the Dutch Productivity-Wage Gap","Hebbink, Thomas (TU Delft Technology, Policy and Management)","Schröder, Enno (mentor); Slinger, Jill (mentor); Delft University of Technology (degree granting institution)","2019","In recent years, Dutch wage growth has failed to keep up with productivity growth which has resulted in a productivity-wage gap. This suggests that workers have not benefitted proportionately from their increased productivity. This thesis investigates how productivity and wage have developed in the Netherlands during the past 50 years.","Wage; Productivity; Productivity-Wage gap","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:bc3d3d5d-bda1-4cbd-95a8-51ed6e03a1ca","http://resolver.tudelft.nl/uuid:bc3d3d5d-bda1-4cbd-95a8-51ed6e03a1ca","Urban Infrastructure Damage Detection and Mapping Using Sentinel 1","Manivannan, Padmini (TU Delft Electrical Engineering, Mathematics and Computer Science)","Lopez Dekker, Paco (mentor); van der Veen, Alle-Jan (graduation committee); Uysal, Faruk (graduation committee); Delft University of Technology (degree granting institution)","2019","Natural or man-made disasters can have a drastic impact on social, economic and environmental aspects of an affected population. Specifically, earthquakes are one of the most potent natural hazards, which cause a disproportionate amount of fatalities, primarily due to a) unexpected building collapses, b) restricted or limited access to basic amenities and c) potential hazards following earthquakes such as landslides, tsunamis etc. It is crucial to have an overview of the infrastructural damage caused following a disaster for search and rescue services to assess the extent of the damage. For the purpose of this research, Sentinel 1 imagery is used to map the building damage in an urban area after a disaster. A combination of parameters such as persistent scatterers, pixel amplitude and phase is used with a timeseries of full-resolution and spatially averaged radar images. Points that are stable in amplitude over a long timeseries, also known as Persistent Scatterers, are extracted from a stack of full-resolution images. The amplitudes of persistent scatterers, along with amplitude and coherence of pixels derived from a stack of spatially-averaged images, are statistically analysed to check the trends of the parameters pre- and post the disaster. A change detection algorithm is applied to this stack in order to localise the areas of building damage. The results are superimposed on Google Earth for easy interpretation using a graded damage scale. The analysis shows that exploiting the persistent scatterer amplitudes in the manner used in this research provides a novel way of locating building damage. This technique can be used effectively in urban areas. Using a combination of pixel amplitudes and coherence along with the persistent scatterers helps correctly find new and unique points of damage for each parameter used. The results were validated using reference Grading and crowd-sourced maps. The results illustrate that the proposed approach can be used for detecting and producing informative maps on infrastructural damage detection in urban areas.","Damage detection; Sentinel-1; Earthquake; Persistent Scatterers","en","master thesis","","","","","","","","","","","","","",""
"uuid:839b4956-95e4-4780-ace3-b307ba7e5857","http://resolver.tudelft.nl/uuid:839b4956-95e4-4780-ace3-b307ba7e5857","Generalized Additive Models on Estimation of Newbuilding Prices and Lead Times for Bulk Carriers","Yan, Chao (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Ship Design, Production and Operations)","Pruijn, Jeroen (mentor); Hekkenberg, Robert (graduation committee); Beelaerts van Blokland, Wouter (graduation committee); Delfos, Rene (graduation committee); Delft University of Technology (degree granting institution)","2019","When placing orders of new vessels, shipowners are most concerned about two things: how much they need to pay and how long they need to wait, and the estimation of newbuilding prices and lead times for new vessels is important to both shipowners and shipbuilders. This thesis introduces the generalized additive model (GAM) as the specific regression method, explains what factors are influential to newbuilding prices and lead times of bulk carriers, and illustrates how to use GAM to construct the estimation models","generalized additive model; bulk carrier; newbuilding prices; lead times","en","master thesis","","","","","","","","","","","","Marine Technology | Ship Design, Production and Operations","",""
"uuid:746cf5a9-7be1-449e-85a2-294abf49630a","http://resolver.tudelft.nl/uuid:746cf5a9-7be1-449e-85a2-294abf49630a","Mixed Finite Element Method for Elliptic Partial Differential Equations","Johnston, Julian (TU Delft Electrical Engineering, Mathematics and Computer Science)","Vermolen, Fred (mentor); Delft University of Technology (degree granting institution)","2019","This report has the main aim of comparing the Mixed Finite Element Method to the standard Finite Element Method. The other aim is to let the reader understand what these methods entail. The latter is done by first journeying through the theory behind the FEM. It is first explored in one dimension to keep the setting simple. Next, the Mixed FEM is explored. A new way of approximating the gradient from the found solution is constructed, using the basis of Finite Differences and the ideas from the Finite Volume Method. Following the theory is the implementation of the mentioned methods and the analysis of theresults. It yields that, when looking at the L2-norm, the classic FEM has a convergence order of 2, comparable to that of similar numerical methods. The Mixed FEM seemed to converge with an order of 4 in the same norm. Our constructed method only had a measly first order convergence, implying much greater accuracy of the Mixed FEM.","","en","bachelor thesis","","","","","","","","","","","","","",""
"uuid:f9e8c003-c8fc-4075-bff3-0d54e0f0fecb","http://resolver.tudelft.nl/uuid:f9e8c003-c8fc-4075-bff3-0d54e0f0fecb","Pedestrian Acceptance of Delivery Robots: Appearance, interaction and intelligence design","de Groot, Stef (TU Delft Industrial Design Engineering)","Rusak, Zoltan (mentor); Geraedts, Jo (graduation committee); Radetzki, Uwe (graduation committee); Delft University of Technology (degree granting institution)","2019","Technology developments are making it possible to start automating the last-mile of parcel logistics. This raises the question of how these autonomous technologies will interact with humans. The goal of this project is to design a concept of a delivery robot for DHL, that maximizes acceptance by pedestrians. <br/><br/>Literature research and interviews showed that the appearance of the robot should be highly functional efficient to communicate what the function of the robot is and how it will behave. Cues that improve the understandability of the behavior should be emphasized in the design. Creating aesthetic associations between other logistics products and the robot makes it more familiar. <br/><br/>The level of in which the robot is perceived as a social emotional being should in be in line with peoples’ expectations and needs. How much anthropomorphization is applied on the robot, determines if the robot is seen as a machine, cute or creepy and forms expectations on how to use it. <br/><br/>The goal is to create a product which fulfills its function without disrupting regular pedestrian behavior and without eliciting negative reactions or sabotage from pedestrians. In order to achieve this, the interaction should be very low effort and intuitive. Pedestrians are not the customer and do not want to adapt their behavior dramatically to cope with tens of delivery robots on their sidewalk stroll. Intuitive interactions can be achieved by using the same way of interacting as with known entities, like other pedestrians or vehicles. Tests show that a design in which the behavior of the robot is modeled after standardized pedestrian behavior, could result in favorable interactions. In demanding situations, the robot will use a car-like blinking light, to communicate what its intentions are. <br/><br/>In user experience tests in virtual reality, small body cues from the robot were seen as an important communication tool on top of a predictable maneuvering. In the final design, the four wheels are made highly visible by a higher body and lights under the chassis. Suspension control allows the body of the robot to lean into corners and forward just before braking, to visually accentuate and communicate the impending action.<br/><br/>The sum of all the small cues and the path of the robot are intuitively understood by pedestrians and don’t need much attention while interacting. Pedestrians will feel in control, because the robot behaves predictable and it mingles in with the natural flow of pedestrians. <br/><br/>The behavior of pedestrians and robot are simulated based on the “social-forces model”. The outcome of the simulation is a first definition of desirable robot behavior and what parameters are needed to achieve this. It is found that the robot should have a less dynamic way of moving than pedestrians. It should steer slower and move with less speed changes. It should be very early in communicating its directions by already turning into that direction a few meters before encountering a pedestrian. <br/><br/>Although the social forces model is now used within simulations, it can also be implemented as the basic logic of DHL’s future delivery robot. However, more tests are required with live test subjects, to find definitive conclusions.","Delivery; Robot; Parcel; Interaction; Aesthetics; Intelligence; Social forces; Industrial; Design; Sidewalk; Automation; Autonomous","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:290f6759-7ba5-489a-9d8c-9145161db316","http://resolver.tudelft.nl/uuid:290f6759-7ba5-489a-9d8c-9145161db316","De Extrapolatie Stelling van Yano","Michielsen, Frans (TU Delft Electrical Engineering, Mathematics and Computer Science)","Veraar, Mark (mentor); Spandaw, Jeroen (graduation committee); Geyer, Anna (graduation committee); Delft University of Technology (degree granting institution)","2019","In dit verslag behandelen we de Extrapolatie Stelling van Yano: een stelling die voor operators van de vorm T : f(x) -&gt; T(f)(x) in bepaalde omstandigheden een afschatting geeft van de absolute integraal over T(f)(x) in termen van f(x) zelf. We zullen zien dat deze afschatting, en meer afschattingen van soortgelijke vorm, onder de juiste voorwaarden continuïteit impliceert voor de operator. Om deze stelling te kunnen behandelen zullen we wat theorie over vectorruimtes opgebouwd uit functies, en enkele voorbeelden relevant voor de stelling, introduceren. Ook behandelen we wat theorie omtrent operators, en passen we de Extrapolatie Stelling van Yano toe op enkele operators.","Functional analysis; Yano's Extrapolation Theorem; Analysis; bounded operators; function norms","nl","bachelor thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:01a09ace-7326-4b20-9c0d-3de5914c31cf","http://resolver.tudelft.nl/uuid:01a09ace-7326-4b20-9c0d-3de5914c31cf","An Improved Optimization Method to Increase the Truck Planning Efficiency of Landside Air Cargo","Wu, Ting Wei (TU Delft Civil Engineering and Geosciences)","Tavasszy, Lóri (mentor); Bombelli, Alessandro (mentor); Atasoy, Bilge (mentor); Janić, Milan (graduation committee); Knoop, Victor (graduation committee); Delft University of Technology (degree granting institution)","2019","Congestion in the landside air cargo supply chain occurs for different concurring reasons. Lack of coordination between freight forwarders, as example, might create truck congestion on the ground handler side. Horizontal collaboration between forwarders can be introduced and modeled via mathematical programming to mitigate congestion. Resulting models, which are generally variations of Pickup and Delivery Problem with Time Windows (PDPTW), can be solved to optimality only for small-size instances, and the computation is generally time consuming. We therefore propose a simulated annealing (SA)-embedded adaptive large neighborhood search (ALNS) heuristic to address truck route planning in the landside air cargo supply chain. In this work, we allow the search to visit infeasible time-dependent solutions. Accordingly, the objective function minimizes the feasible solution, where total travel distance cost, total travel time cost and unassigned shipments cost, and the time-dependent violation costs. Computational results are reported for 10 instances that were also solved with a mathematical programming approach. Results shows that the meta-heuristic method performs equally or better than the mathematical model given a computational limit for the latter of 2 hours. In addition, the meta-heuristic method was able to find a feasible solution for those cases where the exact model failed to identify a feasible solution.","Landside airport operations; Vehicle Routing; Simulated annealing; Time slack","en","master thesis","","","","","","","","","","","","Transport, Infrastructure and Logistics","",""
"uuid:3259e6dd-8bf5-43f8-a6ed-d56d85f5eb29","http://resolver.tudelft.nl/uuid:3259e6dd-8bf5-43f8-a6ed-d56d85f5eb29","Finite Element Modeling of Hardwood Fracture Energy","Boerenveen, Jair (TU Delft Civil Engineering and Geosciences)","Ravenshorst, Geert (mentor); Esposito, Rita (mentor); Delft University of Technology (degree granting institution)","2019","The fracture energy for hardwood was modeled using finite element modeling (FEM) software DIANA. The results of the model was compared to the fracture energy experimental research performed by Boerenveen (2019). The fracture energy results obtained by the model are similar to the results obtained from the experimental research. An model fracture energy over tested fracture energy ratio of 1.02 was found.","Fracture; Energy; Timber","en","student report","","","","","","","","","","","","Civil Engineering","",""
"uuid:b7c648e6-30ff-496f-b004-124c7f9b2d62","http://resolver.tudelft.nl/uuid:b7c648e6-30ff-496f-b004-124c7f9b2d62","A study on Solar PV and Wind energy diffusion in India and China: Barrier analysis using Interpretive Structural Modelling (ISM) method","Dhawale, Abhishek (TU Delft Electrical Engineering, Mathematics and Computer Science)","Blok, Kornelis (mentor); Quist, Jaco (mentor); Smets, Arno (mentor); Delft University of Technology (degree granting institution)","2019","During the Paris Agreement of 2015, 195 UNFCCC members pledged to improve the global response to climate change by reducing the carbon emissions and contributing to keeping the average global temperature increase well below 2° above the pre-industrial levels. The whole world is gradually shifting towards renewable resources but this transition to non-conventional energy sources looks very slow compared to what is required to prevent the extreme effects of global warming.<br/>Countries that have shown tremendous promise, out of some of the largest solar and wind energy producers, are India and China. Both these countries have shown astonishing growth rates and boast of huge world shares in 2017 for the cumulative installed Solar PV. The total installed wind energy capacities for India and China till 2017 are also very large. Even though these growth rates look very large and are a promising start towards the complete shift to renewable energy, they are still not adequate to reduce the global carbon emissions levels fast enough to keep the average temperature change to 1.5°C. <br/>Thus, in this thesis, we aim to identify and analyze the barriers to diffusion of Solar PV and Wind energy in India and China, using interpretive structural analysis (ISM) method, so that we can propose solutions and policy recommendations to further accelerate the diffusion of these technologies. We plan to use the Interpretive Structural Modeling (ISM) method to study the inter-relations between barriers and finally present a hierarchy among them, so that the most important ones can be solved first.","Barriers; ISM; Barrier analysis; Solar PV; Wind","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:9fbb3cae-a8fd-4f5c-b068-79e65e80e476","http://resolver.tudelft.nl/uuid:9fbb3cae-a8fd-4f5c-b068-79e65e80e476","External HumanMachine Interfaces on Autonomous Vehicles: The Effects of Information Type on Pedestrian Crossing Decisions","Barendse, Marc (TU Delft Mechanical, Maritime and Materials Engineering)","de Winter, J.C.F. (mentor); Happee, R. (mentor); Eisma, Y.B. (graduation committee); Delft University of Technology (degree granting institution)","2019","Traffic is a self-organising, regulated system, but there are several ambiguous situations where no rules apply. In such situations, communication is important in order to achieve a smooth traffic flow and a safe situation. However, in the majority of traffic conflicts, adequate coordination between road users is lacking. Communication is particularly important for vulnerable users such as pedestrians, given their significant share in traffic accident statistics worldwide.<br/><br/>The increasing amount of automation in vehicles creates a potential social interaction void, which could further impede safety and a smooth traffic flow, as the chances of misinterpreting the behaviour of another road users might increase. Some researchers and companies have suggested that these problems could be addressed by adding additional means of communication to a vehicle. However, there is limited consensus as to what the most effective form and content of such communication would be.<br/><br/>The aim of this study is to investigate the effect of two different types of information on a pedestrian's crossing behaviour. This work describes the development and evaluation of a textual, external human-machine interface (eHMI), with the aim of complementing existing signals, such as vehicle movements, with explicit information addressed to human road users. Three conditions, specifically: (0) no information, (1), a pedestrian advice (Wait/Walk) and (2) a vehicle based status (Drive/Brake) are compared with respect to their effect on four variables related to the pedestrian: the minimum distance maintained to the vehicle, measured as a virtual 'Time to Collision', changes in the decision to cross (Decision Certainty), the feeling of safety as a percentage of the duration of a scenario (Decision Efficiency), and subjective acceptance.<br/><br/>28 participants participated in three repetitions of the same experiment in three different environments: a field test on a public road, an experiment in an animated virtual reality environment and an experiment using 360* video recordings. Participants stood on the pavement along an urban road in a European setting, and were asked to press a button when they felt safe to cross. During the experiment, a car drove by while showing one of the three types of information.<br/><br/>The total time that participants felt safe was significantly higher in scenarios where the car stopped, and significantly lower if the car did not stop, when information was offered. Time to Collision, decision changes and subjective acceptance also showed statistically significant differences in most scenarios, as these variables show a strong correlation among each other. However, one difference was found between the types of information for the Decision Efficiency variable. Here, effect sizes for the Wait/Walk eHMI (egocentric information) were larger than for Drive/Brake (allocentric information).<br/><br/>The results show that providing additional information could improve safety and traffic flow, although the type of information has a limited influence on the behaviour of a pedestrian. This suggests that when choosing a certain type of information, other factors should be taken into account that could perhaps be more decisive. Ultimately, this research contributes to finding the optimal characteristics of a standardised eHMI design.","External Human-Machine Interfaces; Autonomous Vehicles; Pedestrian Crossing Behaviour; Vehicle to Pedestrian Communication; Automated driving","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Vehicle Engineering | Human Factors","",""
"uuid:f7e90fb2-ecdb-4038-952b-a9bd652dc030","http://resolver.tudelft.nl/uuid:f7e90fb2-ecdb-4038-952b-a9bd652dc030","Multiple-input Multiple-output Grating Lobe Selection Scheme for Radar Applications","Cancrinus, Nick (TU Delft Electrical Engineering, Mathematics and Computer Science)","Yarovoy, Alexander (mentor); Puskely, J. (mentor); Silveira Vaucher, C. (graduation committee); Krasnov, O.A. (graduation committee); Delft University of Technology (degree granting institution)","2019","For radar applications, MIMO is often used. The problem is that the amount of available transmit- and receive channels is limited. If each channel is connected to a single antenna element, the effective aperture is small, and therefore the beamwidth is large and the angular resolution is limited. In this thesis, a novel scheme is proposed that circumvents this problem. More details are given in the full thesis. The result is an array that covers a reduced part of the visible space, with discrete beams that have improved beamwidth. The system gives the possibility to improve the angular resolution at the cost of field of view. A CST-model is made to verify this concept. In the specific example given in this thesis, the half-power beamwidth is improved from 8.4 degrees at broadside, to 5.7 degrees at broadside. At the same time the coverage is reduced from a theoretical ±90 degrees, to ±50 degrees.","grating lobe selection scheme; multiple-input multiple-output (MIMO) radar; substrate integrated waveguide (SIW)","en","master thesis","","","","","","","","2021-03-26","","","","Electrical Engineering","",""
"uuid:b2e8ecb6-6292-4393-98b7-33f513ffb02c","http://resolver.tudelft.nl/uuid:b2e8ecb6-6292-4393-98b7-33f513ffb02c","Developing a model for improving trust in artificial intelligence","Srinivasan, Aditya Vasan (TU Delft Technology, Policy and Management)","Janssen, M.F.W.H.A. (mentor); Asghari, H. (graduation committee); Vink, Micha (graduation committee); Krishnadath, Michel (graduation committee); Delft University of Technology (degree granting institution)","2019","The increasing availability of data, computing power &amp; advances in the algorithms has really driven the development of Artificial Intelligence (AI) in recent years. However, many industries &amp; societies despite realizing the value of AI are still skeptical in accepting AI, especially when several controversial incidents have come into our spotlights and the challenges that AI have been posing in recent years. This has increasingly raised the concern over the trust in AI and has become a major impediment while adopting AI. Almost every stakeholder, potential users put their concerns upfront to the developers of the technology &amp; management and all these concerns address to one main question – How can I trust AI or Whether AI can be trusted. Addressing the concerns posed by the clients &amp; ensuring that AI solutions developed are trustworthy and responsible has now become one of the top priority and challenges for several technology-based companies. From the stands of scientific literature, there hasn’t been substantial research done on the factors influencing the trust in AI despite the growing attention paid over the importance of trust in AI in recent times. At least, there hasn’t been enough study done on the concepts of trust in the field of AI from the management and socio-technical aspects. This research will focus mainly on improving the trust in AI by identifying the essential trust factors of data in terms of data quality dimensions (DQ) &amp; AI model and the prime objective is to develop a trusted AI model incorporating such trust factors that can help the management &amp; developers to assess the trust factors and improve the trust in AI. The research would mainly be employed with a qualitative study using an inductive approach in order to generate valuable theories as it is mainly supported by literature review, desktop research, interviews, and use of a case study. To be more precise, the research was divided into two phases where the first phase involves the identification of potential factors that influences the trust in data and AI model and they were primarily derived from the extensive study done on the literature review &amp; desktop research, and the second phase involves the identification of important trust factors from the perspective of actors involved in the development of AI. Based on the findings from the interview combined with the initial analysis done on the literature review, an initial version of the model was developed. Since the model was relatively new &amp; comprehensive, it required further evaluation with the experts and based on those reflections combined with the previous analysis (literature review &amp; findings from the initial interviews), a final version of the model was developed. To improve the utility of the proposed model &amp; overall research, the model was compared with some of the core themes laid by AI-based research institutions and leading tech firms to ensure that the model has considered those themes and distinguish the major value of this model. The final version of trusted AI model thus contains nine main phases involved in AI development and in each of the phases, trust factors that were crucial to be considered were tagged along with the detailed indicators for each of the phases. The trusted AI model at the end would mainly help the management and developers ( Technology creators) to establish a robust trust over the AI model or the solutions created &amp; provide a seal of trust to the investors, clients and other stakeholders involved. From this study, identification of essential trust factors of resulting AI model and essential trust factors of data in the form of DQ dimensions were considered to be one of the prime handouts to the scientific research apart from the trusted AI model proposed.","Artificial Intelligence; Trust; Trust factors; Data; AI-models; Data Quality; Actors","en","master thesis","","","","","","","","2020-08-19","","","","Management of Technology (MoT)","",""
"uuid:22d20222-37b9-4ecd-8632-3edac59052cc","http://resolver.tudelft.nl/uuid:22d20222-37b9-4ecd-8632-3edac59052cc","Maturity model for the IT-department when migrating to a SaaS-environment","Rijnveld, Justus (TU Delft Technology, Policy and Management)","Janssen, M.F.W.H.A. (mentor); Asghari, H. (mentor); Delft University of Technology (degree granting institution)","2019","In a period where digitization rapidly influences the corporate world, Cloud Computing (CC) has emerged over the past years as well. CC refers to offering hardware, software, and data by a provider over a network and can benefit organizations enormously regarding cost efficiency, operational excellence, and innovation. Software-as-a-Service (SaaS), a delivery model of CC, allows organizations to deploy and use complete applications over the internet, which are managed by an external provider. The use of SaaS can bring firms several benefits, such as scalability, transparency of costs, access to high-end applications, and avoidance of up-front costs. However, it is unclear how the migration to SaaS impacts the IT-department on an organization level, and how IT-departments should adapt to perform in a SaaS-environment. This research contributes to this knowledge gap by investigating which resources and capabilities of the IT-department should change for the IT-department to perform. Propositions were formulated based on a literature research and a questionnaire, and empirical data was collected by means of a case study research. The results show that financial assets, technological tools, organizational structure, management systems, skills, knowledge, organizational culture, contractual governance, and relational governance are important resources of the IT- department, that should change in order to perform. The insights gained from this study can support organizations’ decision-<br/>makers improving the organization of the IT-department when migrating to a SaaS-environment.","Software-as-a-Service; Cloud Computing; maturity model; resource based view of the firm; organisational change; it-department; resources; capabilities; migration","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:286d4d6f-c588-4d31-9e6b-faaa383b228a","http://resolver.tudelft.nl/uuid:286d4d6f-c588-4d31-9e6b-faaa383b228a","Pipe Supply Chain Modelling: There and back again, a PSU's tale","Pauli, Philippe (TU Delft Mechanical, Maritime and Materials Engineering)","Schulte, F. (mentor); Polinder, H. (mentor); Miedema, S.A. (graduation committee); Delft University of Technology (degree granting institution)","2019","Subsea pipelines are critical for oil and gas production and transport, more than 100.000kmof subsea pipelines have been laid. These pipelines are laid by specially designed ships which can lay these pipelines at great depth and a high speed. However, designing the supply chain to deliver joints (pipe pieces) to these pipe lay vessels can be very complex; there aremany possible supply vessel combinations andweather influences that can impact the supply chain. This makes trying to find a good solution a very difficult and time-consuming process currently with a lot of manual iterations. This is called the Allseas problem. To solve this supply chain problema mathematical model is developed, thismodel can solve the supply chain problem while taking into account the many constraints. The research question that is discussed in this thesis is: Can the optimal usage of supply vessels, required to solve the pipelay vessel supply problem, be determined using a scenario based mathematical optimisation model? This model can eliminate the need for the many manual iterations and deliver an optimal solution that the Logistics and chartering department can use.<br/>To supply joints to the pipelay vessels several different types of supply vessels can be used. These supply vessels have different characteristics such as; hold capacity, sailing speed, capital- and operational expenditure, and workability (ability to work in bad weather). The supply vessels must supply joints to the pipelay vessel which can have one or two pipe transfer cranes. The number of pipe transfer cranes that can be used significantly influences the speed at which the supply vessels can be unloaded. A final important influence on the supply chain problemis the weather; specifically the wave height and wind speed: they determine if a supply vessel can unload it joints, or if the pipelay vessel can lay pipe. The goal of the problem is to design a fleet of supply vessels that can deliver the cheapest possible set of routes that will supply all the required joints to the pipelay vessel on time.<br/>A scenario based mathematical optimisation model is developed to find the solution to the Allseas problem. Some important parameters for this model that are thoroughly researched are: the desired stock level of the pipelay vessel, i.e. how full should the holds be? The demand window, i.e. how close to the demanded number of joints should the model deliver. The final parameter of interest is the node duration, all joints must be delivered during a certain time window the parameter node duration changes the size of the time window. The influence of these parameters is also investigated when weather is simulated.<br/>The results of the developed program show that it is possible to make a mathematical model that determines the optimal pipe supply vessel usage. Some other interesting parameters settings have also been found by the model. Allseas always tries to keep the pipelay vessels stocked as full as possible, however, the mathematical model has shown that it ismore advantageous to try to keep the vessel at 80%capacity sine the supply vessels can unload faster that way ensuring shorter routes. Furthermore, the mathematical model has shown that it can deliver cheaper solutions than are currently designed. This has been proven by comparing the results of the mathematical model with a project that Allseas has completed. The mathematical model presented a solution that was ¼ 10% cheaper than the solution Allseas implemented.","Supply Chain; Scenario Based Optimisation; Routing and Scheduling","en","master thesis","","","","","","","","2024-08-26","","","","Marine Technology | Transport Engineering and Logistics","",""
"uuid:2a479391-1431-4df5-be27-f27fb7dc5d35","http://resolver.tudelft.nl/uuid:2a479391-1431-4df5-be27-f27fb7dc5d35","Enhancing Vulnerability Management for IoT Devices with Bug Bounty Programs and Responsible Disclosure","Limon De Jesus, Gianluca (TU Delft Technology, Policy and Management)","Ding, Aaron Yi (mentor); Alfano, M.R. (graduation committee); Delft University of Technology (degree granting institution)","2019","The Internet of Things (IoT) will soon impact the lives of thousands of people as numerous IoT devices are emerging in the consumer market. Consumers goods consist of products designed for the consumption of final consumers. Even though IoT applications are expected to improve people's lives, security is often lacking in current IoT devices. Vulnerabilities in these type of products pose serious risks to the security and privacy of consumers. Compared to traditional electronics, IoT devices are endowed with internet connectivity that can be exploited by hackers in remote attacks. Several attacks on IoT products that can threaten the security of a large of number actors have already been observed. To minimize the risk of attacks, developers and vendors need to identify vulnerabilities in time before any malevolent individual can exploit them. <br/>In recent years, as part of vulnerability management practices, many organizations have started to implement crowdsourced security methods such as Bug Bounty Programs (BBPs) and Responsible Disclosure Policies (RDPs). BBPs and RDPs are programs that involve the participation of ethical hackers in the security processes of organizations, reporting vulnerabilities to companies in exchange for monetary rewards or recognition. These methods present the benefit that thousands of hackers can work together with companies to identify and patch vulnerabilities. Empirical research suggests that BBPs and RDPs effectively augment existing vulnerability management practices by companies. However, the application of these programs in the field of IoT has never been studied. There are many questions open regarding the potential and future adoption of Bug Bounty Programs and Responsible Disclosure Policies. The research aim is to study and expand the literature on security practices for IoT, focusing on the application of BBPs and RDPs, and to conduct an interview-based investigation with experts in order to provide practical recommendations for companies to enhance vulnerability management practices for IoT consumer goods. For this research, the literature on IoT security and security practices is confronted with empirical data from expert interviews. The empirical data was gathered during an internship at Deloitte in the Netherlands. In total, 19 interviews with cybersecurity experts from different companies in the field were collected for this thesis. The results are employed to generate recommendations for companies to improve their vulnerability management practices with the use of BBPs and RDPs. The recommendations are directed to companies developing, manufacturing, and commercializing consumer IoT devices that want to enhance the security of their products. The main contributions of this research consist of practical and tangible security recommendations for companies to tackle IoT vulnerabilities in consumer goods, which will help enhance the overall IoT security practices. Moreover, our findings raise attention on the societal risks derived from the unsafe deployment of vulnerable IoT products into the consumer market. We create awareness on the IoT security challenge, and present a call for further actions from companies, consumers, and regulators in the IoT domain.","IoT Security; Vulnerability Management; Bug Bounty Programs; Responsible Disclosure; Crowdsourced Security Methods","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:f32458de-b842-46c2-b92d-508143e844c2","http://resolver.tudelft.nl/uuid:f32458de-b842-46c2-b92d-508143e844c2","Organizational Readiness for Machine Learning: Exploring the key readiness factors for business adoption of machine learning","Yoon, Ahhyun (TU Delft Technology, Policy and Management)","Janssen, M.F.W.H.A. (mentor); Scholten, V.E. (graduation committee); Delft University of Technology (degree granting institution)","2019","Demand for machine learning is ever-growing in today’s business. Situated at the convergence point of big data and Artificial Intelligence (AI), machine learning allows companies not only to unlock hidden insights from the data deluge but also to fundamentally revolutionize their products and services. Recognizing the opportunities, industrial players are on the lookout to partake in the machine learning journey, or some are already experimenting with machine learning. However, the disparity between expectation and action is still substantial, and subsequently, machine learning adoption remains elusive for many companies. This is partly due to the relative immaturity of the technology, but also due to a myriad of uncertainties conjoined with the adoption process. As of now, a lack of understanding of machine learning adoption in business is prevalent in both academia and practice impeding companies from creating values at scale. In brief, the way to best prepare for machine learning is still an unsolved question. In this regard, it is timely to reflect such contemporary managerial needs into academic research. With the research main question of “What are the key readiness factors for business adoption of machine learning?”, this study investigates the factors which can increase companies’ overall readiness towards machine learning. This research utilized three research strategies (i) literature review, (ii) expert interviews, and (iii) multiple case studies to answer the main research question. The main research outcomes of this research are threefold. Firstly, the research concept of organizational readiness for technology adoption is clarified and two distinctive research streams – users’ and exploiters’ readiness – are subsequently identified. Secondly, the barriers to business adoption of machine learning are consolidated. Based on this, the key readiness factors which can mitigate the barriers are identified and empirically tested. Thereby the model of machine learning readiness is developed with its constituting factors: (i) Top management support, (ii) Vision and strategy, (iii) Open culture, (iv) Multi-disciplinary team, (v) Data governance, (vi) Existence of a translator, (vii) Machine learning infrastructures, (viii) Ambidexterity, (ix) Strategic partnership, and (x) Awareness. Theses outcomes are valuable to both academia and practice. This study contributes to academia by clarifying the ambiguous theoretical concept of organizational readiness for technology adoption. For industry, this paper can be used as a white paper to understand the phenomenon of business adoption of machine learning.","Artificial intelligence; Machine learning; Machine learning readiness; Organizational readiness for technology adoption; Organizational technology adoption","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:a41b3676-2a3e-4c39-ba7d-13ac37579269","http://resolver.tudelft.nl/uuid:a41b3676-2a3e-4c39-ba7d-13ac37579269","Restarting Greece: Secular Stagnation of Total Factor Productivity Growth and the Greek Innovation System","Chrysovergis, Vyron (TU Delft Technology, Policy and Management)","van Beers, Cees (graduation committee); Storm, S.T.H. (mentor); Pesch, U. (graduation committee); Delft University of Technology (degree granting institution)","2019","In 2008, the crash of the housing market bubble lead not only to the collapse of the U.S financial system, but also to a Global Financial Crisis. The Eurozone was hurt, and the impact was not uniform. The “sick periphery”, and in particular Greece, still suffer from the consequences of this crisis. After three adjustment programmes and €293 billion in financial assistance, Greece is weakened and left in stagnation. The country is aging, and if this reality does not change in the coming years, we will not be talking about a lost decade, but about a lost generation, and even worse, a lost nation. When we observe stagnation in economic growth, we should examine carefully the slowdown of TFP growth. Consequently, we investigate whether there was a long-run slowdown of TFP growth in the Greek economy and what are the other contributing factors that can explain this decline. On this basis, we will propose policies and strategies to the Greek government and private sector for a new and effective National Innovation System.","Greek crisis; Innovation System; Secular Stagnation; TFP Growth; Labor Productivity","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:99eff6eb-ae9c-4cba-9c81-c53895689304","http://resolver.tudelft.nl/uuid:99eff6eb-ae9c-4cba-9c81-c53895689304","Robots and re-shoring: Should developing countries start to worry?","Bendermacher, Ralf (TU Delft Technology, Policy and Management)","Schröder, E. (mentor); Hansen, H.H. (mentor); Roeser, S. (graduation committee); Delft University of Technology (degree granting institution)","2019","The world is experiencing a new technological revolution that can have profound implications for the nature of work. Currently, attention is particularly focused on the implication of the increased adoption of industrial robots. Multiple studies predict that especially developing countries are at risk to be negatively affected by robotization in the near future, in ways such as unemployment and greater income inequality. To a large extent, developing countries became integrated in the world economy through their involvement in global value chains (GVCs). The establishment of GVCs, in turn, were a direct result of an upward trend in offshoring. However, because both offshoring and industrial robots primarily affect routine and labor-intensive tasks, the labor-cost advantage of developing countries is quickly eroding and puts at risk their strong export position. Furthermore, in recent year world trade is indeed observed to slow down, which has further fueled concerns. This thesis aims to quantify how much the adoption of industrial robots in developed countries contributed to the decline in world trade experienced in recent years. We do this by regressing a measure of offshoring on the density of industrial robots and other control variables. Offshoring is quantified in terms of the offshoring index, which is constructed using two datasets by the Organization for Economic Co-operation and Development (OECD). To get data on the adoption of industrial robots, we use a dataset that has been made available by the International Federation of Robotics (IFR). The final unbalanced panel dataset consist of 29 countries, 15 industries and spans the period 1993-2015. The other factors that will be controlled for in the models include: labor intensity, wages, year-dummies, country-trends and industry-trends. Furthermore, we estimate the models using fixed-effects. Our regression estimates provide evidence for a negative and statistically significant relationship between the adoption of industrial robots and offshoring intensity. We estimate that if the density of industrial robots increases by 10% in OECD countries, then offshoring decreases by 0.29%. Furthermore, we investigate if the effects are particularly strong for certain industries. We find that the effect between robotization and offshoring particularly holds true for industries that have already robotized the most in relative terms. We conclude by discussing several policies that can help developing countries to tackle the disruptive effects of automation and safeguard their future economic development.","offshoring; reshoring; industrial robots; world trade; labor markets","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:04e81949-9076-47f9-ad15-91febbb6eef1","http://resolver.tudelft.nl/uuid:04e81949-9076-47f9-ad15-91febbb6eef1","Insights in the market of recycled plastic, with practical value chain research","van Sambeek, Boudewijn (TU Delft Technology, Policy and Management)","van Beers, Cees (graduation committee); Hartmann, L. (graduation committee); van Bueren, Ellen (graduation committee); Vandehoek, Jaap (mentor); Delft University of Technology (degree granting institution)","2019","The European Union (EU) landfilled and incinerated 600 million tons of waste in 2013, which could have been recycled and returned as raw material to the economy. Resource efficiency can regain this value and bring economic, environmental and social benefits. The EU has therefore adapted the Circular Economy Package with targets to stimulate the transition to a circular economy. These targets include reusing and recycling 55% of plastic packaging waste by 2025. Member states act to achieve those targets with subsidies and funding schemes. This enables entrepreneurs to enter the market of recycled plastic with innovations to gain Schumpeterian rent. However, only approximately 50% of starting companies are still operating after 4 years. It is crucial to increase the success rate of turning new technologies into innovations in order to reach the recycling targets. Market exploration and orientation strategies can aid entrepreneurs to gain insight in the recycled plastic market. Globalized value chain research is a commonly used method, but not suitable to address the recycling industry as it is not globalized but restricted by country borders and local governance. Value chain research methodology was used, according to a handbook written by Kaplinsky &amp; Morris from 2001, which refers to and uses globalized value chain research methodology. For the recycling industry a specific selection was made from elements mentioned in the handbook. This enabled the execution of value chain research for the not globalized recycling industry. The interview questions and topics were made based on the required data for the selected elements. This thesis focussed on the biggest market segment of post-consumer plastic packaging waste in the Netherlands. In total 149 compounders, recyclers and converters were included in a database for a selection. Of which seven companies participated, which resulted in qualitative data that gives insight into the industry and enabled answering the research question.What is required from the value chain of the plastic recycling industry to increase the use of recycled post-consumer PPW? Converters must be able to get access to regranulate with stable MFI and crystallization time characteristics in higher quantities. Compounders can initiate this with joint design projects with branding companies thereby highlighting the possibilities of their regranulate. The optimization of the product and process for their regranulate lowers the switching costs for the converter and can bring rent opportunities. It furthermore showed to increase the sales of regranulate. The compounder requests higher quantities of mono streams recycled plastic from the recycler to comply with demand for regranulate to be used for high volume consumer goods. Recyclers however, upgrade their processes to maximize output for the Dutch ‘Raamovereenkomst’, which includes a mix stream next to the mono streams. This mix stream cannot be used by the compounders to make regranulate for the converters. The recyclers claim that they can technically increase the mono streams at the expense of the mix stream, although this leads to lower profits for them. A change is therefore required in the Dutch ‘Raamovereenkomst’ to optimize for mono stream output.","Plastic recycling; value chains; Market Research","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:f131127e-abc8-4a63-9152-d6c99e271a4f","http://resolver.tudelft.nl/uuid:f131127e-abc8-4a63-9152-d6c99e271a4f","Hydrogenated Indium Oxide (IO:H) by Plasma Enhanced Spatial Atomic layer deposition for thin film PV application","Pandey, Saksham (TU Delft Electrical Engineering, Mathematics and Computer Science)","Isabella, O. (mentor); Pandraud, G. (graduation committee); Vollebregt, S. (graduation committee); Creyghton, Yves (graduation committee); Delft University of Technology (degree granting institution)","2019","Hydrogenated Indium Oxide (IOH) has been recognized as a high performance transparent conductive oxide (TCO) due to its excellent mobility (&gt;100 cm2/Vs) and high transparency (&gt;90%) in the visible and near infrared region of the spectrum. Plasma enhanced spatial atomic layer deposition (PESALD), a new type of deposition process developed recently at TNO has been used to perform the deposition of IOH in this project. Sputtering is a process conventionally used in the industry for the deposition of TCO. However, PESALD offers several benefits when compared to sputtering. The process is continuous, operated at atmospheric pressure allowing large area and high throughput processing. In addition to this, PESALD uses a fully remote plasma source to avoid any substrate damage caused by the bombardment of ions. Ion-induced substrate damage could sometimes pose a problem in magnetron plasma sputter deposition processes. Different process parameters like precursor pickup flow, gas concentration in the plasma, substrate velocity and reactor temperature were altered in order to find improved conditions for IOH depositions. A novel dimethylaminopropyl-dimethylindium (DADI) precursor was used and the impact of its use was studied at different process conditions. In order to find the more optimal conditions, the IOH layers were deposited and characterized on glass substrate. Spectroscopic ellipsometry (SE), Hall effect measurements, 4 point probe measurements, reflectance and transmittance measurements and X-ray diffraction were used for analysing growth, electrical, optical and structural properties of the layers. SCOUT software is also used for a better optical analysis of the films. Additionally, the degradation of the layers under damp heat and atmospheric conditions is investigated during the course of this project. Finally, the most optimum PESALD process parameters have been used to perform deposition of the TCO on CIGS solar cells.","Transparent conductive oxide; Plasma enhanced spatial atomic layer deposition; CIGS solar cells; conductivity; transparency","en","master thesis","","","","","","","","2021-08-26","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:a508d0a5-1536-449e-aa03-9f8f933c17ec","http://resolver.tudelft.nl/uuid:a508d0a5-1536-449e-aa03-9f8f933c17ec","Temperature variation effects on electrostrictive actuators and its quasi-static compensation","Singh, Aditya (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Precision and Microsystems Engineering)","Jansen, Bas (mentor); Hossein Nia Kani, S.H. (graduation committee); Vandervelden, Ruben (graduation committee); Hunt, A. (graduation committee); Delft University of Technology (degree granting institution)","2019","Deformable mirrors are used for changing the wavefront of the reflected light by using one or more actuators behind the mirror to physically deform it. This application is widely used in telescopes to compensate for atmospheric aberrations using a feedback wavefront sensor. Recent advances in lithography process require more precise wavefront control than ever, and deformable mirrors are being considered as a suitable optical unit in the optical column of lithography systems. Using electrostrictive materials for the actuation provides benefits like less hysteresis, no creep, and fast response time. One major limiting factor in the use of such materials is the high sensitivity of strain response to temperature. Due to application constraints a position sensor is not available for the position control. This leads to a requirement of temperature dependent strain-field model in a feedforward control scheme to compensate for the temperature changes and predict the position to sufficient accuracy. In this thesis, different electrostrictive models are explored, and through high frequency impedance measurements and precise quasi-static strain-field experiments, actuator response is analyzed and model parameters are estimated. The parameters are then used in a feedforward control, with temperature sensor, to compensate for the temperature change resulting in decrease of temperature induced strain variation by 75\%-87\%. Furthermore, an optimum voltage region is identified for maximum actuation performance with compensation of temperature induced strain variation. Lastly, a novel temperature self-sensing approach is explored for which a patent application is filed.","Electrostriction; Temperature Model; PMN-PT; Feedforward controller","en","master thesis","","","","","","","","2021-08-26","","","","Mechanical Engineering","",""
"uuid:9bb0f70c-aa41-46ae-ab98-50abb081310f","http://resolver.tudelft.nl/uuid:9bb0f70c-aa41-46ae-ab98-50abb081310f","Automatic Steering Control for Path Following Vehicles: with a focus on higher order sliding mode control","Pandit, Arvind (TU Delft Mechanical, Maritime and Materials Engineering)","Shyrokau, B. (mentor); Zheng, Y. (mentor); Happee, R. (graduation committee); Wisse, M. (graduation committee); Delft University of Technology (degree granting institution)","2019","Among the trends that are going to shape the automotive industry in the coming years, autonomous vehicles stand out as having the potential to completely change the automotive industry as we know it. One of the critical tasks in this framework includes robust execution of the steering control action to maintain a pre-defined path.<br/><br/>The main shortcomings of the state of the art steering controllers are controller robustness, cross-comparison and performance validation. To address this aspect, firstly, this study focuses on implementing a sensor model that geometrically measures the lateral and the heading error of the vehicle with respect to the path. Secondly, the focus was to implement existing lateral controllers like Stanley, Path Control with Preview (PCwP), Linear Quadratic Regulator (LQR), Immersion and Invariance (II), Passivity Based Control (PBC) and evaluate path-tracking performance.<br/><br/>The Sliding Mode Control (SMC) methodology has proven effective in dealing with complex dynamical systems affected by disturbances, uncertainties and unmodeled dynamics. However, the application of SMC and its algorithms to lateral control in vehicles is not effectively analysed. Finally, this master thesis includes a novel design of three variants of Sliding Mode Control; namely Sliding Mode Control with Super Twisting Algorithm, Modified Super Twisting Algorithm and Non-singular Terminal Modified Super Twisting algorithm. These algorithms were then tested against external disturbances such as localisation error, cross-wind, and parametric variations. This thesis successfully illustrates in detail, the aspects involved in path-tracking control. Results effectively suggest a betterment of the novel steering controllers designed, over the previously existing Sliding Mode Control Super Twisting algorithm and other bench-marking controllers at higher speeds. The work ends with vital conclusions<br/>and recommendations for future researchers in this domain to further increase robustness and achieve better performance.","Path Following; Sliding Mode Control; Modified Super Twisting; Non-singular Terminal Modified Super Twisting","en","master thesis","","","","","","","","2021-08-26","","","","","",""
"uuid:4bf9b43f-4761-4fe1-808d-a490aaf63c48","http://resolver.tudelft.nl/uuid:4bf9b43f-4761-4fe1-808d-a490aaf63c48","A X-Band Patch Antenna Array With Low Cross-Polarization: For Weather Radar Applications","Vizcarro Carretero, Marc (TU Delft Electrical Engineering, Mathematics and Computer Science)","Yarovoy, Alexander (mentor); Turso, Stefano (mentor); Galvis Salzburg, Carlos (graduation committee); Bertuch, Thomas (graduation committee); Delft University of Technology (degree granting institution)","2019","Meaningful dual-polarized radar estimations suitable for radar meteorology require a cross-polarization discrimination (XPD) and isolation (XPI) in excess of 30 dB to reach a differential reflectivity accuracy lower than 0.1 dB. A planar dual-polarized patch antenna array featuring low cross-polarization is proposed to meet these requirements via a simple implementation of imaged feeding and candidates as a cost-effective electronically steerable array for short-range X-band weather radars.<br/>However, relatively high levels of cross-polarization are to be expected in a patch array and therefore counteracted with specific designs. To this end, a feed rotation technique is implemented via bi-axial imaging of the feeding probes for each logical sub-array of 2 by 2 elements. Improvements in XPD respect to a repeated feeding scheme are significant and in excess of 30 dB. Based on successful designs and simulations in CST Microwave Studio and ANSYS HFSS, an X-band array of 4 by 4 patches has been manufactured. Extensive instrumental validation has been largely supporting this specialized feeding concept meeting the theoretical expectations and electromagnetic simulation results.<br","Weather Radar; Active Electronically Steered Array; Low cross-polarization; Dual-polarization Antenna; Radar Meteorology; polarimetry radar; Patch Antenna; Mono-dimensonal Scanning; Feed Rotation; Cross-polar Discrimination; High Cross-polar Isolation; PCB Design; X-Band Radar","en","master thesis","","","","","","www.linkedin.com/in/mvizcarro","","2021-08-30","","","","Electrical Engineering","WRAD (Weather Radar)",""
"uuid:fb027b18-4551-4d18-b806-b3596e8ec758","http://resolver.tudelft.nl/uuid:fb027b18-4551-4d18-b806-b3596e8ec758","The influence of weather on travel behaviour - a multi-method analysis","Faber, Roel (TU Delft Technology, Policy and Management; TU Delft Transport and Logistics)","Molin, Eric (mentor); Kroesen, Maarten (graduation committee); Asghari, Hadi (graduation committee); Jonkeren, Olaf (mentor); de Haas, Mathijs (mentor); Delft University of Technology (degree granting institution)","2019","Societal and political attention to the effects of climate change and possible mitigation and adaptationpolicies has increased sharply in the last decades, resulting partly from increasing awareness about therole of humanity and partly from the ever more noticeable changes in our world caused by climatechange. This societal interest has highlighted a lack of knowledge about the effects that a changingclimate will have on many aspects of our lifes, one of which is the transport section. To understand theimpact climate change will have on our transport system we need to know how travel behaviours areaffected by weather circumstances, which is the main topic of our research.We focus on four aspects of the relationship between weather and travel behaviour: (1) how weatheris taken into account in the decision-making process (2) if the influence of singular weather variables(such as temperature) depend on the value of other parameters (3) if the influence of weather is differentfor urban and rural areas and (4) whether there are groups of people whose response to travelbehaviour are distinctly different from one-another. This knowledge can be used for climate changeadaptation measures, such as ensuring that our supply of travel infrastructure will be able to copewith changes in travel demand resulting from a changed climate, and mitigation measures, such asincreasing the number of people that use more sustainable travel options like the bicycle.For our analyses we use travel data provided by the KiM Netherlands Institute for Transport PolicyAnalysis, which is the result from a travel diary survey held in autumn. We use weather data asmeasured by weather stations, provided by the Royal Netherlands Meteorological Institute (KNMI).This data is used to estimate the influence of weather on travel demand and mode choice in the Netherlands,using regression and choice models respectively. Within our analyses we try to find factorsthat moderate the relationship between weather and travel behaviour, such as urban density and sociodemographics.With respect to the four aspects identified above, we report the following findings:(1) that people use a general perception of the weather during the whole day for their mode choicetravel decisions, which contrasts with the most common practice of using the weather at the trips’departure time.(2) by accounting for the fact that meteorological variables always co-occur in our models we areable to more accurately capture its effect on travel behaviour. The difference with the current practiceof estimating separate effects for each weather variable is particularly stark for days at the extreme endof the observed range of weather variables.(3) The influence of weather on travel behaviour differs more qualitatively between rural and urbanareas: the total effect size of the weather similar, but they are brought upon by different weathervariables. The difference is also very specific to travel modes. For bicyclists the effects of wind speedseem to be more sizeable in urban environments, whilst temperature, rain, and sunshine have smallereffects in urban environments.(4)We find multiple groups of travellers whose responses to weather variations are different from oneanother. These differences seem to be caused by the set of travel modes that are used during averageweather conditions. People that only use the car during average conditions are not very affected, withonly enjoyable weather conditions prompting increased bicycle use. If the car and the bicycle are usedoften people swap between the modes, although use of the bicycle during inclement conditions isrelatively much higher than for the other two groups. The last group has a more multi-modal travelpattern, which results in the largest variations caused by weather. Inclement conditions favour bothpublic transport and the car, with car use increasing quite sharply during wet weather with high windspeeds.<br/>Additionally we find that weather variations account for differences in travel behaviour across boththe spatial and temporal dimensions. A particularly surprising finding is that the smaller number ofbike trips in the western provinces of the Netherlands can be fully explained by the fact that there arehigher average wind speeds and lower temperatures in this part of the country.<br/>Our results have several implications for the research community and policy makers. We advice researchersto account for the fact that the weather is perceived as a whole and thus that the effect ofone single variable (such as temperature) will depend on the values of other variables. We also foundinteresting subgroups with different reactions with regards to weather. We advice researchers to moreclosely investigate the effects of weather for the separate subgroups. Finally we find sizeable differencesin the effect of weather between different regions, even within the relatively small country of theNetherlands. Researchers studying a relatively large study area would do well to estimate separateeffects for regions within their study area, for example based on population density and geographicallocation.<br/>For policy makers our findings imply that there is a sizeable effect of weather that could be usedto improve the forecasts of future travel demand, both in the short- and long terms. Whilst policymakers obviously can’t control the weather, we have found that changing travel patterns or attitudesto travel modes will have repercussions for the effect weather has on travel behaviour. We think thatpolicies aimed at allowing commuters to gain experience with using the bicycle for their daily commuteduring summer, coupled with temporary financial incentives when weather conditions becomeless favourable, could be one way of achieving more cyclists during inclement conditions. Policy makerscould even target younger professionals specifically, as they are much more likely to have alreadydeveloped such habits during their education.","Transport Demand Modelling; Mode Choice; weather; Travel behaviour","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:d852e2d3-d2fc-4a19-addd-9402e3d5a60d","http://resolver.tudelft.nl/uuid:d852e2d3-d2fc-4a19-addd-9402e3d5a60d","Behavioural analysis and modelling of family gathering during the 2011 Tohoku tsunami evacuation","YASAKU, Toshiya (TU Delft Civil Engineering and Geosciences)","Pel, Adam (mentor); Bricker, Jeremy (mentor); van der Gun, Jeroen (mentor); Urata, Junji (mentor); Delft University of Technology (degree granting institution)","2019","The conventional evacuation modelling assumes that that family members are to be together in the face of tsunamis and evacuate as a household or each person evacuate individually. This assumption, however, can cause an inaccurate prediction when taking family gathering behaviour into account, which was reported to have occurred during the 2011 earthquake off the Pacific coast of Tohoku in Japan. This thesis first investigates the family gathering behvaiour during the event using the survey data of evacuation by the survivors of the 2011 Tohoku tsunami. It aims to identify statistically significant travel choices and parameters defining travelers who performed the family gathering during the evacuation. Using the result of this first part, this thesis also suggests a methodology to model that family gathering behvaiour and performs a simulation for a coastal city in Japan using a general activity-based transportation model. It was found as for the behavioral analysis that stay / leave choice, departure time choice, and mode choice shows significant differences between those who performed the family gathering and those who did not whereas concerning the parameters defining those who performed the family gathering initial location, gender, and age have been found significant. The choice frequencies of alternatives developed in the behavioral analysis have been applied into the model formulation taking these findings into account. Depending on whether they performed the family gathering or people's attributes, different choice frequencies have been applied. The simulation indicates that the characteristics of the family gathering trips in comparison with the evacuation trips are explained by the faster speed achieved by the earlier departure time and by the longer travel distance caused by the destination choice being fixed locations such as home and relative’s<br/>home rather than nearby buildings. A scientific contribution has been made in terms of evacuation behaviour and evacuation modelling methodology for the family gathering during evacuation. Also, taking this particular behaviour into account for evacuation modelling leads to better prediction of evacuation trips, which in turn helps develop enhanced evacuation planning.","evacuation behvaiour; evacuation modelling; tsunami; family gatheirng; empirical analysis","en","master thesis","","","","","","","","","","","","","",""
"uuid:9245b0c4-c020-4004-95b4-ee872d8aa157","http://resolver.tudelft.nl/uuid:9245b0c4-c020-4004-95b4-ee872d8aa157","Designing a washing machine for the service economy","Bolaños Arriola, Julieta (TU Delft Industrial Design Engineering)","de Koning, J.I.J.C. (mentor); Sypesteyn, Mark (graduation committee); Ingemarsdotter, Emilia (graduation committee); Enslin, Andreas (graduation committee); Delft University of Technology (degree granting institution)","2019","Product Service Systems (PSSs) are considered to be a promising approach towards a sustainable, resource efficient economy (Tukker, A., 2015) (defined as ‘a mix of tangible products and intangible services designed and combined so that they are jointly capable of fulfilling final customer needs’ (Tukker, A. &amp; Tischner, 2006)), because they make the delivery of satisfaction possible through functions and not necessarily through products, fulfilling needs with less resources and consequently with lower impact. This is especially true when they are specifically designed to provide high quality resource efficient products. Bundles is a Dutch company that is intending to do exactly that, making high quality home appliances accessible through a Use oriented PSS (Tukker, 2003) where they lease washing machines and other home appliances, maintaining the ownership over the washing machine and becoming responsible for all maintenance and repair costs. Bundles has as a goal the reduction of waste and environmental impact caused by the use and disposal of low-end non efficient machines. They intend to increase the lifetime of their products, submitting them to several use cycles by recovering the appliance, refurbishing it and installing it in a new home. Supported by IoT technologies they currently monitor the use phase (to calculate the monthly fee based on the number of washing cycles) and are now interested in extending the possibilities of these technologies for refurbishment, reuse, and recycling processes. Additionally, with the advantage of maintaining control over the ownership of a great number of appliances, Bundles opens interesting opportunities for material and part recovery. For all of these reasons Bundles is recognized for having a business model that could benefit the circular economy. In order to fulfill all of the above, Bundles exclusively works with washing machines from German manufacturer Miele due to their high content of recyclable materials, high quality and long lasting characteristics. However, these characteristics of the product represent today, limitations to many of the envisioned processes to achieve having several use cycles. Making processes like refurbishment and part replacement expensive or not possible at all. Because of this it is unclear for Bundles how to deal with the deterioration of the machines after several use cycles and how customers will perceive this deterioration, and although Miele gives their products a life expectancy of approximately 20 years, Bundles only considers the machine to have a life expectancy of approximately 10 years within their business model. Additionally, Bundles offer is bounded to a machine that is also available for customers to purchase, limiting their competitive advantages over product-based business models. A customer with the stability and economic possibilities of purchasing a Miele washing machine will most likely perceive Bundles’ PSS as expensive in the long term. Nowadays Bundles and Miele, design and deliver their services/products independently from each other and for different types of business models. This project focuses on finding opportunities to improve the synergy between Miele's product and Bundle's service to enhance the economic, circular and environmental possibilities of the current PSS. In order to do that, this project initiated with a literature and field research with all primary stakeholders, considering them individually and relationships with one another, that delivered insights regarding the current limitations of the components and delivery of the PSSs and potential opportunities for its improvement, within all phases of its life cycle (Pre-use, Use and Post-use). The insights were then translated into values or Focus Areas to guide the ideation and further development of the PSS: Personalization is identified as a relevant value for the Pre-use phase, to increase the perceived value of the user over the PSS and refurbished products and for the Use phase, as an opportunity for the reduction of the environmental impact. Likewise, communication is identified to be a value that can be used to positively influence the user behaviour to reduce the environmental impact of the Use phase (highest among all phases of the lifecycle of a washing machine (Öko-Institut, 2005)), and improve his/ her involvement in maintenance and caring procedures. Lastly, refurbishment is selected as a focus area for the Post-use phase since the improvement of the product in this aspect could not only reduce costs for Bundles but also increase the life expectancy of the product. These values were used as a guideline throughout the ideation process, which delivered a collection of several concepts that were further evaluated together with all main stakeholders, the sinal result of these process delivered a combination of a new concept washing machine and a personalization platform. The new PSS proposes a washing service that allows users to personalize their washing machines inside and outside. The user can select a color for the front panel of the machine, thanks to the implementation of a replaceable layer and obtains a personalized ‘Washing Package’, which includes: a set of programs, number of washes per month (frequency) and set of tips. All three elements are defined by a system that considers the user’s specific washing needs with information obtained through a digital platform (The Washing Test), and pairs them with identified recommendations for: the reduction of environmental impact of washing, the best care for clothes, and recommendations related to the care and maintenance of the washing machine. The personalization of the Washing Package allows users to take the best care for their clothes without an excessive use of resources (energy and water). The internet module of the washing machine and its sensors allow the monitoring of use and state of the components of the machine. The data collected from the monitoring of use is used by the system to constantly update the Washing Package to adapt it to changes in the user’s needs or identified behaviour that increases the environmental impact. The design of the washing machine, allows it to have several use cycles without losing its aesthetic value, its quality or its resource efficiency. The construction, materials and finishings of the washing machine are proposed for the optimization of refurbishment processes as well as the improvement of access to its components for updates and repairs allowing the machine to increase its life expectancy within the PSS to the originally establishes expectancy of 20 years (defined by Miele). As a final step of this project the new concept was evaluated first, together with the main stakeholders and then submitted to an assessment to identify its improvements in disassembly and ease of access as well as refurbishment processes and the reduction of the environmental impact in comparison with the current PSS. The new concept appears to have the potential of improving the implementation of the PSS throughout all of the phases of its lifecycle and is assessed positively by the stakeholders specifically considering its potential to reduce refurbishment costs, increase the life expectancy of the product, increase the perceived value of the user over refurbished products and PSSs, and the reduction of the environmental impact of the use phase. The results of the validation and assessment allowed the identification of information gaps for further research and further development of the concept. These include for example, the development of test settings and prototypes for further proof of concept, a more refined and accurate Life Cycle Assessment to identify further specific points of improvement, further detailing and analysis of the product structure and construction to reduce its material input, and further study and analysis regarding the recovery of the product and the possibilities of the reintroduction of its materials and components in the manufacturing of new washing machines . To conclude, the new concept proposes product service combination which characteristics enhance each others functions and overall envisioned processes towards the reduction of environmental impact and increase of circularity, whilst considering the involvement of Miele and Bundles in a new collaborative relationship for the achievement of all processes and successful implementation of the PSS.","Service design; Circular economy; Product Service System; Repairability; Refurbishment","en","master thesis","","","","","","","","","","","","","",""
"uuid:278f91a5-c2df-49f9-bdd5-c18b1fa7f703","http://resolver.tudelft.nl/uuid:278f91a5-c2df-49f9-bdd5-c18b1fa7f703","Optimal Sizing and Strategy of a Hybrid Energy Storage System for Smoothing Renewable Power Fluctuations: Considering uncertainty of PV and Wind Power Output","Amanda Castolina Lahiraja, Amanda (TU Delft Electrical Engineering, Mathematics and Computer Science)","Cvetkovic, Milos (mentor); Rueda, José L. (graduation committee); Qin, Zian (graduation committee); Fu, Aihui (graduation committee); Delft University of Technology (degree granting institution)","2019","Developing renewable energy sources entails new challenges which have not been faced previously by the traditional grid. One of the issues is the variability of renewable resources due to their characteristics of weather. The intermittent nature produces uncertainty in generation output, especially in solar and wind power generation. As penetration of both sources increase, variability will be more difficult to handle. And even as this issue is being resolved, another one, that of the application of an energy storage system has arisen. The energy storage is the current and typical means of smoothing wind- or solar-power generation fluctuations. Conducted research mostly developed an energy storage for only one technology, however, different technologies can be combined and complement each other which significantly improve the storage system’s performance. In this research, a hybrid energy storage (HES) is proposed to mitigate power fluctuations of renewable plant output power.<br/><br/>This thesis aims to give understanding of the effective strategy of a hybrid energy storage for PV power output and wind power output fluctuation suppression. The strategy will stand as the foundation for a broader framework which aims to optimize the size of hybrid energy capacity to enable such application in uncertain condition. Wavelet power sharing method is proposed as the strategy to operate the hybrid energy storage using frequency-based method. The strategy can decompose the frequency component of renewable power quickly and allocate the power to the respective device. In this paper, battery and supercapacitor is adopted to meet the electric grid technical requirements for smoothing renewable power. The results show that the supercapacitor peak fluctuations of battery power are moderated by adding the supercapacitor, providing lower peaks and slower derivative of power fed to/drawn from the battery. The result from the power sharing is suitable in terms of improving the battery lifetime. Battery lasts for 1.3 years in a conventional energy storage system, while it can last up to 6 years in the hybrid energy storage.<br/><br/>After getting the optimal power allocation between storage devices, sizing the capacity of hybrid energy storage also considers uncertainty in power output. This research uses investment storage cost, penalty and life cycle cost as the objective function, while hybrid energy storage’s state of charge and the power fluctuation performance as the constraint. The chance constrained programming is used to make the fluctuation of output power under a certain confidence level, which also meet the electrical quality and economy. The optimal solution of hybrid energy storage capacity is carried out by using genetic algorithm based on stochastic simulation. The results show that, with the confidence level of smoothing requirement up to 90%, system contains two energy storage has a lower total cost than a single-sourced energy storage.","Renewable Energy; Hybrid energy storage; Stochastic Optimization; Wavelet Transform","en","master thesis","","","","","","","","2020-08-21","","","","","",""
"uuid:d63a03a1-4cd6-48da-b359-b293bfb4aa1f","http://resolver.tudelft.nl/uuid:d63a03a1-4cd6-48da-b359-b293bfb4aa1f","Synchronization Of Wireless Accelerometer Sensors For Industrial Application","Narayanan, Swarna (TU Delft Electrical Engineering, Mathematics and Computer Science)","Nihtianova, S. (mentor); Delft University of Technology (degree granting institution)","2019","Wireless sensor networks play a vital role in major technological developments. The success of such networks depend on the quality and reliability of data acquisition. Despite a lot of research involving network clock synchronization, the area of synchronous sampling has not been dealt in much detail. This thesis aims at studying and implementing synchronization at the sensor level on wireless accelerometer sensors. The designated application for this thesis involves machine condition monitoring using accelerometer sensors that requires high synchronization accuracy between the samples. Two approaches are presented to obtain synchronous sampling, namely: real-time and subsequent synchronization. The sensor nodes designed with commercially-off-the-shelf components are used for the implementation of the two methods. The embedded software was developed as a platform to realize the proposed synchronous data acquisition techniques. The real-time synchronization uses a software solution and provides an interrupt-based triggering to align the sampling instant of the sensors. An external reliable clock source is required for the accelerometer to implement this technique. The signal propagation delay were minimized by employing interrupts whenever possible. In subsequent synchronization, the samples are collected asynchronously by the sensor nodes. Each sample from the sensor is assigned a timestamp according to its local clock. As a post-process, the time shift between the samples collected by the sensor nodes are estimated and realigned using cross-correlation, interpolation and re-sampling. The subsequent synchronization technique can be used when real-time network synchronization is not possible. The testing environment was designed to emulate the real application. A mechanical shaker was used to provide controlled input signals to the sensors in order to synchronously reconstruct the signals in time-domain.","embedded systems; Accelerometer; sensor network","en","master thesis","","","","","","","","","","","","Electrical Engineering | Embedded Systems","",""
"uuid:983973b6-a94e-4011-a967-ad4da7001003","http://resolver.tudelft.nl/uuid:983973b6-a94e-4011-a967-ad4da7001003","Autonomous Exploration by Cooperative Robots","Agrawal, Charu (TU Delft Electrical Engineering, Mathematics and Computer Science)","Verhoeven, C.J.M. (mentor); Epema, D.H.J. (mentor); Roos, S. (graduation committee); Mastrangeli, Massimo (graduation committee); Delft University of Technology (degree granting institution)","2019","Imagine being lost in a desert with a bunch of friends, all of a sudden. Survival will be difficult. You will have mirages, distrust among friends and no means to leave landmarks on the sand. Unable to locate yourself, you will have no means to contact people with maps. The best you can do in such a situation is to stay together in the vicinity of each other and look for food and water. By staying together, you can see more and decrease faulty data; thereby increasing your survival probability. Robots when left to explore the moon encounter the same issues. They do not have a Geo-Positioning System to locate them nor do they have a map. They have faulty sensor readings and might find it difficult to contact a human operator on earth all the time to solve issues on the moon. Since everything looks the same, there are no landmarks to memorise. As they walk around, their battery will also get exhausted. The more we equip the robot outside earth, chances of faults do not decrease, they increase. Therefore, there is a need to make primitive robots capable of autonomous exploration. We prefer sending more than one robot, inspired by the success of the collective strength of insects in harsh environments. This thesis aims at engineering collective behaviour for a group of robots in such resource-less environments like the moon. We expect this collective behaviour to perform searching in time-critical events like earthquake-stricken areas. The thesis is designed to be implemented on legged robots called Zebros. Using communication, they will collectively perform activities such that they appear as one body of tightly coupled autonomous units. We design three distinct algorithms for such missions. Emergent behaviour is expected from the robots running these algorithms. The swarm should collectively choose the best among the possible options without disintegrating into subgroups. (https://www.youtube.com/watch?v=Yf3ToRk7YHY&amp;feature=youtu.be)","distributed systems; adaptive networks; decision making; robotics; Zebro","en","master thesis","","","","","","","","","","","","Electrical Engineering | Embedded Systems","",""
"uuid:0310a54c-dd2d-490a-b88e-76b21b1c0b3c","http://resolver.tudelft.nl/uuid:0310a54c-dd2d-490a-b88e-76b21b1c0b3c","Dune Based Alternative to Coastal Spine Land Barrier in Galveston Bay: Conceptual Design","Rodriguez Galvez, Luis (TU Delft Civil Engineering and Geosciences; TU Delft Hydraulic Engineering)","de Vries, S. (mentor); Jonkman, Sebastiaan N. (graduation committee); Bricker, J.D. (graduation committee); Delft University of Technology (degree granting institution)","2019","Galveston Bay is an area in the Upper Texas Coast (USA) historically suffering from the impact of several large magnitude hurricanes. In 2008 hurricane Ike, one of the most devastating natural disasters in Unites States recent past, raised awareness of the flood vulnerability problem of the area and triggered the beginning of different proposals, studies and designs to tackle this issue. The main action plan to be taken in the future consists on the construction of a series of interconnected dikes and storm surge barriers along the barrier islands, called Coastal Spine or Ike Dike. In this thesis, an alternative to the dike as land barrier is proposed, designed and evaluated. The concept consists of using a dune system that can serve as a flood defence structure in case of hurricane while being integrated into the coastal system in daily conditions. The dune is firstly parametrized, later its performance during design storm scenario is evaluated via numerical modelling, and lastly it is compared to the default Coastal Spine dike proposal to assess its feasibility and obtain final conclusions.","Galveston Bay; Coastal flooding; Dune design; Conceptual design","en","master thesis","","","","","","","","","","","","Civil Engineering | Hydraulic Engineering | Hydraulic Structures and Flood Risk","","29.180718, -94.973305"
"uuid:2ad5a161-017f-4318-a6bf-3bc4eeefa75b","http://resolver.tudelft.nl/uuid:2ad5a161-017f-4318-a6bf-3bc4eeefa75b","Intimate relationship development for the elderly: Transition from 'Volkstuin' (community garden) to residential environment","Hong, Eunkyu (TU Delft Architecture and the Built Environment)","Jurgenhake, B.M. (mentor); Lafeber, J.W. (mentor); Reinders, L.G.A.J. (mentor); Nase, I. (graduation committee); Delft University of Technology (degree granting institution)","2019","The family is the most intimate social environment given to us, and this basic social element plays an important role as we get older. However, changes in family structure and increasing physical distance between family members due to globalization make it difficult to care for the elderly by the family. In the global age, distance from the most intimate social group, the family, causes issues for the elderly, such as loneliness and social isolation.<br/>In the present situation, many elderly homes are not only disconnected from society but also isolated in their private rooms due to the large scale and institutional space organization. For elderly people who lose their connections with society after retirement and have less mobility, these living environments are not suitable for them to build and develop new intimate social relationships.<br/>Therefore, this study aims to provide a social environment like family by creating architectural spaces that help them form intimate social relations with their neighbors, and also assist the elderly to stay connected and part of our society. In order to achieve this, the thesis suggests a new elderly housing environment by incorporating the characteristic of ‘Volkstuin’ (community garden) that commonly exist around us into elderly housing.","elderly; care; volkstuin; community garden; cluster; family; multi-generation; neighbor; architecture","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences","","52.346, 5.613"
"uuid:2a5c9b48-5ab7-435f-a3ea-f0b1779791bd","http://resolver.tudelft.nl/uuid:2a5c9b48-5ab7-435f-a3ea-f0b1779791bd","The development of an objective test method to evaluate the (optical) quality of rigid endoscopes at the CSSD","van der Plaats, Lisa (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Biomechanical Engineering)","Dankelman, J. (mentor); Oosting, R.M. (graduation committee); Kalkman, J. (graduation committee); Bockweg, Erik (graduation committee); Delft University of Technology (degree granting institution)","2019","The quality of rigid endoscopes deteriorates during clinical use due to the sterilization process, mechanical forces and wear and tear during regular use. Regulations and standards on ensuring the quality of these instruments are currently non-existent or contain only qualitative measures, resulting in subjective examinations . Defective rigid endoscopes still reach the operating room, resulting in direct and indirect patient risks. An experimental test set-up has been developed to quantify the sharpness, contrast, distortion, light transmission, vignetting and colour correctness of the optical system<br/>of rigid endoscopes. Results are given for 85 measurements performed on 33 endoscopes, including 7 high quality endoscopes and 26 low quality endoscopes. 37 measurements have been performed on a reference rigid endoscope. The results for sharpness, contrast and distortion provide valuable insights but the current design of the test set-up proved not stable enough to draw significant conclusions. The results for light transmission, vignetting and colour correctness produce stable results and display the expected values for damaged lens systems such as loose or broken lenses. Although the current design requires significant optimization, this study has both given an account of the need for an objective method to evaluate the quality of rigid endoscopes as well as provided a promising step towards this new method and greatly encourages further research.","Rigid Endoscope; Quality Assurance; Reprocessing; Medical devices; medical instruments; Minimally invasive surgery","en","master thesis","","","","","","","","2022-01-01","","","","Biomedical Engineering","",""
"uuid:af041e54-7660-4fb1-b68c-0af3aaf27c52","http://resolver.tudelft.nl/uuid:af041e54-7660-4fb1-b68c-0af3aaf27c52","Evaluating SLAM in an urban dynamic environment","van Schouwenburg, Sietse (TU Delft Mechanical, Maritime and Materials Engineering)","Kooij, J.F.P. (mentor); Hehn, T.M. (mentor); Gavrila, D. (graduation committee); Hernández, Carlos (graduation committee); Katsifodimos, A (graduation committee); Epema, D.H.J. (graduation committee); Delft University of Technology (degree granting institution)","2019","Simultaneous Localization And Mapping (SLAM) algorithms provide accurate localization for autonomous vehicles and provide essential information for the path planning module. However, SLAM algorithms as- sume a static environment in order to estimate a location. This assumption influences the pose estimation in dynamic urban environments. The impact of this assumption on day-to-day scenarios of an intelligent vehicle is unknown. A deeper understanding on the effect of dynamic scenarios in an urban environment could lead to simple and robust solutions for SLAM algorithms in intelligent vehicles. The objective of this research is to develop a methodology that isolates the effect of an urban dynamic environment on the per- formance of a SLAM algorithm. This requires constant environment conditions including constant weather conditions, lighting conditions and identical trajectories over time. The methodology is tested with a stereo feature based V-SLAM algorithm called ORB SLAM [19], which illustrates the in-depth analysis that is possi- ble with this experiment. The main research question is: How does a dynamic urban environment influence the pose estimation accuracy of stereo ORB SLAM? Two specific dynamic scenarios are designed to represent a dynamic urban environment: driving behind another vehicle and vehicles approaching on the other side of the road. On these scenarios, an in-depth anal- ysis of ORB SLAM is performed to observe how the algorithm’s design influences the robustness to a dynamic environment. Functions within the algorithm are bypassed to analyze the effect on the performance. Specifi- cally, the place recognition function and map point filtering function are bypassed. The analysis proofs which functions assist in the overall robustness to a dynamic environment. Moreover, an analysis is performed of the algorithm in localization mode to research the effect of utilizing maps that were created under different conditions. The knowledge gained from the full analysis can be utilized to improve other V-SLAM algorithms. The experiment is performed in CARLA [6], an open source simulator. CARLA provides an elaborate sen- sor suite which support multiple camera setups and LIDAR sensors. Furthermore, the simulator provides free maps which represent realistic urban environments and allows for easy and accurate access to the ground truth position. A setup is designed with the simulator that allows complete isolation of the effect of a dy- namic environment. The setup allows full control of lighting conditions, weather conditions and allows iden- tical trajectories over time in different dynamic scenarios. Each scenario is simulated over several different trajectories in which the camera images are converted to rosbags. Each variation of the ORB SLAM algorithm is tested on the produced rosbags. The resulting pose estimations in dynamic conditions are compared to the pose estimations made during static conditions to analyze the effect of dynamic scenarios on the perfor- mance of the algorithm. The method successfully isolated the effect of a dynamic environment on the performance of stereo ORB SLAM. It allows for a detailed analysis which aids in finding the source of performance differences. In general, stereo ORB SLAM displays robust behavior to a dynamic environment. The experiment shows that the algo- rithm is sensitive to false relocalization when the stereo camera setup is driving 10 meters behind another vehicle for a long period of time. During these conditions, ORB SLAM cannot provide accurate pose esti- mations even when the place recognition module is deactivated. Furthermore, the map point filtering does increase the robustness in certain dynamic scenarios. Finally, the data suggests that utilizing maps created in different conditions does influence the pose estimation in localization mode. However, more data is needed to confirm these results. The methodology has proven its value for in depth analysis of robustness to an urban dynamic environ- ment for a SLAM algorithm. This experiment is not limited to ORB SLAM but could be utilized for other monocular and stereo V-SLAM methods, as well as LIDAR based methods. New solutions can be developed to increase robustness to a dynamic environment and tested on the same rosbags. This methodology could be an important tool for the development SLAM algorithms for intelligent vehicles.","SLAM; simulation; computer vision; simulataneous localization and mapping; localization; mapping; visual SLAM; ORB SLAM; CARLA","en","master thesis","","","","","","","","","","","","Mechanical Engineering","",""
"uuid:7a547356-190c-49b2-9477-ad269feb9ba8","http://resolver.tudelft.nl/uuid:7a547356-190c-49b2-9477-ad269feb9ba8","Experimental analysis of passive acoustic emission, in particular the Kaiser Effect, under dynamic stress conditions: Exploring the implications for in-situ failure monitoring in underground mines","Mulder, Luuk (TU Delft Civil Engineering and Geosciences)","Barnhoorn, Auke (mentor); Buxton, Mike (graduation committee); Dieudonné, Anne-Catherine (graduation committee); Delft University of Technology (degree granting institution)","2019","Irreversible damage induced by stress in brittle rock is accompanied by the formation of micro-cracks. The strain energy released during the fracturing process is released in the form of acoustic emission. This thesis applied the non-intrusive method of acoustic emission monitoring to assess the deformation process of brittle rock during cyclical loading and loading to failure in a standard uniaxial compressive strength test set-up. It is confirmed that the stress-strain curve is clearly separated into five phases and that the cumulative hits recorded throughout the failure process correspond with these five phases. Furthermore it is found that there is an obvious rise in trend in the amplitude of the acoustic events as the rock nears failure, but that individual events of high amplitude should not be considered indicative for the damage in the rock. Additionally it is found that high amplitudes characteristic for near failure stress are recorded at 25\% of the failure stress if the rock has been under high stresses, indicating a change in fracture mode. The Kaiser Effect, the phenomenon defined as the absence of detectable acoustic emission events until the load imposed on the material exceeds the previous applied level, was confirmed during uniaxial cyclical loading. Through loading samples from a highly stressed pillar in the Nepheline Syenite Stjernoya Mine in Norway, it is found that the onset of acoustic emission may be indicative of the stress in the pillar. These findings are useful to further develop acoustic emission as a monitoring method in a range of applied earth science applications.","Acoustic Emision; Deformation; Kaiser Effect; Mine; Cyclic loading; In-Situ Stress","en","master thesis","","","","","","","","","","","","","",""
"uuid:b36e962d-b264-432e-bbc9-19839e219b25","http://resolver.tudelft.nl/uuid:b36e962d-b264-432e-bbc9-19839e219b25","Repopulating a decellularized liver scaffold with liver-derived organoids in a perfusion-based bioreactor","Vermeulen, Annewiet (TU Delft Mechanical, Maritime and Materials Engineering)","Verstegen, Monique (mentor); Fratila-Apachitei, E.L. (mentor); Zadpoor, A.A. (graduation committee); Delft University of Technology (degree granting institution)","2019","Over the last decade new methods are explored in the field of tissue engineering to minimize the donor organ shortage. Engineering organs with a complex structure and large vascular network, such as the liver, remain a challenge. Luckily, the decellularization of an organ creates a scaffold that consists of the extracellular matrix (ECM) with important growth factors, bifunctional molecules such a fibronectin and multiple collagen types. This ECM provides the biophysical and biochemical cues needed for cells to adhere, proliferate and differentiate. However, there is no optimal method yet to recellularize such a decellularized liver scaffold. This project shows that it is possible to use a perfusion-based bioreactor for repopulating a porcine liver scaffold with liver-derived organoids. In the bioreactor, the Harvard Apparatus (Hugo Sachs Elektronik), decellularized porcine liver segments were infused with a HepG2 cell line and liver-derived organoids in seperate experiments. A setback in the project was the proneness to infections in the Harvard Apparatus (HA), which shortened the duration of experiments and influenced the results. The experiments were analyzed by histological and immunochemical staining and by qPCR. The HepG2 cell line validated the set up and recellularization with the HA, the cells engrafted throughout the scaffold and showed viability and signs of proliferation. The liver-derived organoids were successfully cultured and expanded in spinnerflasks, and were found engrafted and alive after 10 days in the scaffold. The qPCR data showed variability between the different organoid lines and between the different phases of the organoid culture. The results combined of this project are promising for future research, especially regarding the use of liver-derived organoids for recellularization.","Liver; Regenerative medicine; Recellularization","en","master thesis","","","","","","","","2022-08-24","","","","Biomedical Engineering | Biomaterials and Tissue Biomechanics","",""
"uuid:1c39a957-5abf-481e-afa7-35b7dd3c4877","http://resolver.tudelft.nl/uuid:1c39a957-5abf-481e-afa7-35b7dd3c4877","Towards Information Integrated Design Management: A study on the effects of inter-disciplinary information dependency on design in construction design projects","Kushwaha, Vishwajeet (TU Delft Civil Engineering and Geosciences)","Bakker, Hans (mentor); Bosch-Rekveldt, Marian (mentor); Kana, Austin (mentor); Ramanujam, Gayatri (mentor); Delft University of Technology (degree granting institution)","2019","This M.Sc. thesis is related to the use of Design Structure Matrix (DSM), a design process modeling technique, to model, analyze and improve design processes in Oil and Gas Construction Projects. DSM was used to model the design process of an engineering design section at an Oil and Gas Engineering Company using the information dependencies in the design process. The key effects of the information dependencies that were studied in this thesis include rework due to iterations, change propagation in the design process and need of design team collaboration. Further, the current design process was improved in terms of design schedule by proposing a new design process with reduced rework risk. Finally, ecommendations have been provided to improve the design process on the three aspects related to information dependencies in design process as mentioned above.","Design Structure Matrix; DSM; Design process; Design process modeling; Oil and Gas; construction projects; process model","en","master thesis","","","","","","","","","","","","","",""
"uuid:486eb057-c12b-44d5-8a13-918681ba75ba","http://resolver.tudelft.nl/uuid:486eb057-c12b-44d5-8a13-918681ba75ba","Policy Mythology: A Case Study","McMullen, Connor (TU Delft Technology, Policy and Management)","de Bruijn, Hans (graduation committee); Pruyt, Erik (mentor); Asghari, Hadi (graduation committee); Delft University of Technology (degree granting institution)","2019","What happens when we treat our policy messages more like mythology and less like rhetoric? How can we even begin to structure policy as a mythology? What is a myth anyway? This thesis endeavors to explore the mysterious world of stories, through an extensive literature review of literary analysis, and a exemplary case study about the impact of global plastics production on the future. This study leads to an experiment, where four different forms of communication: the best of rhetoric and stories, are tested against each other for effectiveness in shifting the mood, transferring information, and effecting the audience's experience. The results show that even with a small sample size the impact of stories as effective tools of policy communication are real. They result in a drastically different message than the other forms tested, hinting at the possibility of a future where stories are central to shaping policy.","plastics; storytelling; communication; public policy; case study","en","master thesis","","","","","","","","","","","","","",""
"uuid:5310a3af-f740-4b3b-846c-7651620a3fb6","http://resolver.tudelft.nl/uuid:5310a3af-f740-4b3b-846c-7651620a3fb6","Urban Characteristics of Mental Health: Data-driven policy advice for urban mental health strategies","Houwing, Lise (TU Delft Technology, Policy and Management)","Cunningham, Scott (mentor); van der Voort, Haiko (mentor); Delft University of Technology (degree granting institution)","2019","The urban population is globally increasing. Additionally, mental health problems are increasing. The determinants of mental health are found to be more present in urban environments. Due to the growing populations and the urban presence of mental health determinants, mental health problems are risking to further increase. This thesis develops a framework, in which the concepts that influence mental health are visualized. Based on this framework, the determinants of mental health are modelled for the case of Rotterdam.<br/>Subsequently, the modelling results are translated into the policy system. The findings of this thesis are that the pathways towards mental health are complex, multivariate, interconnected and sometimes contradicting. In order to address this challenge, policy-makers should take an integral evidence-based approach. This thesis conducts a first exploration of the relation between urbanization and mental health. Furthermore, it takes the first step towards developing a policy-process that incorporates this knowledge and is able to act on it. Nevertheless, more research is needed about the urban determinants of mental health, in which data is used on individual level. Moreover, qualitative studies can research integrated evidence-based policy-making in more depth.","Mental Health; Urbanization; Governance; Integral policy-making; Evidence-based policy-making","en","master thesis","","","","","","","","","","","","","",""
"uuid:e63d8898-9e74-4092-a624-6384fb0da674","http://resolver.tudelft.nl/uuid:e63d8898-9e74-4092-a624-6384fb0da674","Optimal design of a non-isolated high power density buck-boost converter","Cao, Yufan (TU Delft Electrical Engineering, Mathematics and Computer Science)","Bauer, Pavol (mentor); Qin, Zian (graduation committee); Pandraud, Gregory (graduation committee); Everts, Jordi (mentor); Delft University of Technology (degree granting institution)","2019","Semiconductor lifetime and power density are considered to be two important development directions of power converter design in the future. Especially in some high dynamic application, the operation condition is changing frequently causing the temperature swing of semiconductor, and it leads to thermal expansion and contraction which affects the lifetime or reliability of semiconductor. A high maximum temperature or a large temperature swing leads to short lifetime. Meanwhile, high power density is a general trend. If the size of a whole system is limited, a high power density converter enables more functionality of the system. Also, high power density also leads to high portability. Works have been done to use interleaved and high switching frequency converter to get a high power density. However, those converters such as interleaved buck converter do not help to improve semiconductor reliability because it can only operate in synchronous conduction mode (SCM) and triangular current mode (TCM).<br/><br/>In this work, a $20kW$ DC/DC converter for highly dynamic application is designed. The four-switch buck-boost converter is chosen because of its flexibility and its possibility to get longer semiconductor lifetime and higher power density. It is possible to offer a free-wheeling interval in which no voltage is applied on the inductor, the transferred power can be regulated by adjusting the duty cycle of this interval. In addition, an optimal modulation scheme is proposed for this topology which further helps improve the reliability of semiconductor. An optimal power stage design is given which is a two-stage interleaved structure. Plus, a close-loop control strategy is given according to the design.<br/><br/>The proposed modulation scheme is tested with a low voltage level prototype, and the performance prediction is verified.","DC/DC Converter; High Power Density; Semiconductor Lifetime","en","master thesis","","","","","","","","","","","","","",""
"uuid:9a62299f-13af-4230-b3a0-e574e6fd023f","http://resolver.tudelft.nl/uuid:9a62299f-13af-4230-b3a0-e574e6fd023f","The Criticality of the European Multimodal Transportation Network: Multifaceted Investigation of the European Hinterland Transportation Network based on Its Network Structure","Andreas Yunus, Andreas (TU Delft Technology, Policy and Management)","Cunningham, Scott (mentor); van Duin, Ron (graduation committee); Ebrahimi Fard, Amir (graduation committee); Harter, Camill (mentor); Delft University of Technology (degree granting institution)","2019","A nation’s main port is a crucial component that contributes to the economic development of a country. Therefore, the role of the port becomes more critical nowadays. However, due to the existing hub-and-spoke structure of the European multimodal transportation network, polarisation and regionalisation are visible in the network. The increasing regionalisation and polarisation that happens in the European region widen the inequality in the network. Moreover, the inequality in the network will impact the sensitivity and resistance of the whole network to targeted disruptions, such as infrastructure failures, natural disasters, or potential terrorist attack. Then, on the real aspect, the widening of inequality in the network also inhibits the well-distributed economic development in the region. In this study, various methods will be employed to have multiple points of view of the network itself, such as the multilayer network analysis, community detection, and Network-based Hub Port Assessment (NHPA). Furthermore, the study will be structured into three building blocks that shapes as a foundation to perform the final analysis and provide a multifaceted overview of the overall network, which is versatility analysis, community structure analysis, and quantification of collaboration-connectivity of the container hubs. Afterwards, three determinants as measurements of network performance are defined, to perform the criticality analysis. This study concludes that the development of connections between different communities can help to decrease the existing inequality in the network. Then, the appearance of new community structure in the network can help to decrease the inequality in the network, which lead to more well-distributed economic development in the region.","Network science; Graph theory; Multilayer network analysis; Criticality analysis; Transportation network; Multimodal transportation; Container hubs","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:ec5e8722-a630-4ef8-ba57-0d3ad68290f8","http://resolver.tudelft.nl/uuid:ec5e8722-a630-4ef8-ba57-0d3ad68290f8","Adaptive policy decision pathways for robust shipping network investment planning in Indonesia: A model application to Indonesian export trade","Indriana, Ingrid Rosalyn (TU Delft Civil Engineering and Geosciences; TU Delft Transport and Logistics)","Tavasszy, Lorant (mentor); Maknoon, Yousef (graduation committee); Wiegmans, Bart (graduation committee); Zepeda, Carlos (graduation committee); Delft University of Technology (degree granting institution)","2019","Due to its archipelagic nature, Indonesia enforces to make substantial investments in its maritime sector, especially port infrastructure, in order to promote trade, economic growth, and ease disparity among Indonesia’s island regions. The challenge, of course, is that Indonesia has many ports to invest in and a limited budget; it must prioritize among various port development projects. The government, therefore, needs to choose wisely in order to avoid wasting money by constructing shipping network plans. One of the most important aspects in shipping network planning in Indonesia is designating which ports are to become international container gateways as these ports will play an important role in connecting Indonesia with foreign markets and therefore have a strong impact on its economy. To improve the current state of policy decision-making for the Indonesian shipping network, we hereby develop adaptive policy decision pathways focused on Indonesian containerized exports. The objective of this study is to build adaptive policy decision pathways that can cope with dynamic future uncertainties and results to help the government develop a robust network investment plan that helps the Indonesian government achieve its objective of improving connectivity and value-added exports through lower logistics costs. The main general finding is that flow pattern is very sensitive to demand volumes. Moreover, Minimum Cost-Flow (MCF) model used in this study is able to identify the flow pattern so that is very useful to analyze the potential of gateways. By applying this approach, we can analyze how the flow pattern changes from period to period and therefore may lead to different policy decisions. Having this approach in shipping network planning will help policymaker to have several predictive pathways and thus can support policy decision-making.","Adaptive policy decision pathways; Shipping network planning; Minimum Cost-Flow problem; Indonesian export trade; Indonesia","en","master thesis","","","","","","","","","","","","Transport, Infrastructure and Logistics","",""
"uuid:7b4a1887-e3fd-4f52-bace-b7cd0ad4412d","http://resolver.tudelft.nl/uuid:7b4a1887-e3fd-4f52-bace-b7cd0ad4412d","Model-based Interference Mitigation for FMCW Radar System","Ding, Min (TU Delft Electrical Engineering, Mathematics and Computer Science)","Yarovyi, Olexander (mentor); Wang, Jianping (mentor); Delft University of Technology (degree granting institution)","2019","With the increase in the number of radar systems/radio applications, FMCW radars currently face various interference problems which lead to wider noise band, rise in noise floor level and masking of weak targets. This thesis aims to eliminate different types of interference for FMCW radars.<br/>In this thesis, we propose a interference mitigation technique based on the signal<br/>model. It is expected to detect the interferer at the beat frequency and mitigate the interference by reconstructing the interference-contaminated signal using the matrix pencil method in the time-frequency domain. However, there are two potential shortcomings of this approach that the interference needs to be detected and the loss of targets information is unavoidable. To solve the above problems, another model-based interference mitigation technique using matrix completion method is introduced. This method aims to decompose the measurement data to the desired signal and interference signal based on the low-rank property and the sparsity.<br/>The method efficiency for different parameters of the interference, i.e. interference duration, signal-to-noise ratio (SNR) and different target scenarios ( i.e. a single stable target and distributed targets ) are investigated in numerical simulations. The proposed interference mitigation approaches also demonstrate experimental data collected by PASAX radar. Comparisons of the proposed approaches with the zeroing technique and other beat-frequencies interpolation techniques are performed. The results indicate that the interference can be significantly suppressed, with little cost in the accuracy of the reconstructed radar echo signals.","Interference mitigation; matrix pencil; matrix completion","en","master thesis","","","","","","","","","","","","","",""
"uuid:06248c28-894a-4c69-9978-d2982a35fc9a","http://resolver.tudelft.nl/uuid:06248c28-894a-4c69-9978-d2982a35fc9a","Understanding the relationship between user emotion and latent musical features","Shastry, Aishwarya (TU Delft Electrical Engineering, Mathematics and Computer Science)","Tintarev, Nava (mentor); Houben, Geert-Jan (graduation committee); Liem, Cynthia (graduation committee); Delft University of Technology (degree granting institution)","2019","With the advent of Internet and resulting data boom, Recommender Systems have come to rescue by filtering the information available on the internet by providing us with relevant information. These systems come handy when one wants to listen to songs, watch movies or even buy products on the Internet. Primarily, these recommender systems used content based or collaborative filtering techniques to recommend items. More recent research has studied the importance of contextual features in recommender systems. Music preference has always been associated with the contextual feature emotion. However, few studies study the mood congruence effect in the domain of music recommender systems. The field of music emotion recognition also remains unexplored with recommendations being made with limited features. \\ <br/><br/>This master thesis analyses the relationship between few latent musical features and user emotion through our interface MooDify. It is a music recommendation system that incorporates emotion in a user using emotion induction techniques and investigate the effect of their emotional state on satisfaction and unexpectedness when presented with songs curated to specific musical features. To achieve this, we analysed the enjoyment and unexpectedness ratings for recommendations specific to latent musical features for a given emotional state. We have been able to achieve some interesting results through this study which has been discussed later in this work. <br","Music recommender; Emotion; Musical features","en","master thesis","","","","","","","","","","","","Computer Science | Data Science and Technology","",""
"uuid:2e89cb07-fade-4c71-9eb1-b4249364a528","http://resolver.tudelft.nl/uuid:2e89cb07-fade-4c71-9eb1-b4249364a528","HomeTree - Gamified tool to increase creative session engagement for participants with diverse backgrounds","Duan, Zhe (TU Delft Industrial Design Engineering; TU Delft Product Innovatie Management)","van der Meer, Han (mentor); Tiemersma, Simon (graduation committee); Heijne, Katrina (graduation committee); Stemerding, Frank (graduation committee); Delft University of Technology (degree granting institution)","2019","A creative session is a lot more than a session of generating ideas. It’s part of a much larger goal of delivering innovation in a company. It is necessary to get everyone on board and motivated. And when the motivation levels reached, then beautiful things can happen. In order to achieve a certain motivation level, It’s imperative that people feel the engagement during the creative session. Being engaged in the creative session is not just about paying attention. With positive emotions, people would stimulate themselves to put more effort and energy which formulates a positive loop. And game is the main media as the fun-generator. There is a huge opportunity that puts the game experience to the creative session to explore and examine business challenges, to improve collaboration, and to generate novel insights about the way the world works and what kinds of possibilities we may find there in a playful way.With the collaboration of the serious game company &amp;RANJ, the graduation project focus on developing a toolkit for the creative session based on gamification methodology to stimulate engagement of participants. And eventually, HomeTree - a gamified toolkit that includes four sequent mini-game challenges within a complete story to support participants with diverse backgrounds to get committed to the creative session process in a playful and tangible manner is designed to fufill the project objective.","Creative session; Gamification; Tangible Interaction; creative facilitation; game design","en","master thesis","","","","","","","","","","","","","",""
"uuid:befb2a68-66c9-4b74-9384-364515eeeefa","http://resolver.tudelft.nl/uuid:befb2a68-66c9-4b74-9384-364515eeeefa","Point Merge: A Feasible Arrival Procedure at Brussels National Airport?","Verhellen, Saranne (TU Delft Aerospace Engineering)","Roling, Paul (mentor); Van Biervliet, Alex (graduation committee); Delft University of Technology (degree granting institution)","2019","In order to efficiently accommodate the future, continuously growing air traffic demands at Brussels National Airport (EBBR), as well as to avoid an impending saturation of the terminal airspace, the concept of point merge has been identified as a potential solution. The characteristics of point merge that made it at first glance an interesting arrival procedure for the airport are the embedded CDO, the procedure systematisation, the possibility to maximise the runway capacity throughput and to decrease the controller workload, while maintaining - if not improving - current levels of safety, punctuality and efficiency. To verify if all these elements could be achieved in the dense and complex operational environment of EBBR, a feasibility study has been carried out. This study has been requested by skeyes, the Belgian air navigation service provider.","Point Merge System; Terminal Airspace; Arrival Procedure","en","master thesis","","","","","","","","2024-08-31","","","","Aerospace Engineering","",""
"uuid:079469e2-f334-4a72-8800-e19c4c01e29a","http://resolver.tudelft.nl/uuid:079469e2-f334-4a72-8800-e19c4c01e29a","Design against loneliness: service design toollkit for social connectivity among the elderly","Weng, Haoxin (TU Delft Industrial Design Engineering)","Sonneveld, Marieke (mentor); Goossens, Richard (graduation committee); Dong, Yumei (graduation committee); Delft University of Technology (degree granting institution)","2019","Loneliness, as a social problem, has drawn wide attention of the academic and public. Moreover, loneliness among the elderly is significant. Up to 32% of adults older than age 55 report feeling lonely at any given time. Millions of euro have spent to identify the lonely elderly. With a great interest in social design, the author is intrigued by this issue and thus, initiated the project with an attempt to make a contribution to it with design methods.<br/><br/>In the research phase, extensive literature constructed a holistic view of the loneliness and yielded a new perspective of understanding it. Loneliness is like the destination of the vicious circle between negative social interaction and negative social cognition. Moreover, it may spread through negative interaction. Thereby, the project focuses on social interaction as the entry point for intervention. Through partnering with Vierstroom, one elderly home care company who is also interested in connecting their elderly members, the project finds a context for designer’s intervention. It is activities organized by the Vierstroom and Palet welfare such as bingo game, or care lecture. Investigation of the context revealed dozens of problems and opportunities. There are five pain points highlighted in the elderly activity: the reliance of facilitator, the passive social attitude, the negative social norm, the negative complaining and the one-way communication.<br/><br/>A new relationship between elderly and organization: sports fan and coach<br/>Analysis and ideation provoke a vision that elderly and organization could be like sports fan and coach. With service design methods, the author paves the road to vision by seeing the activity as multiple-layers and sequential interaction. After that, a service strategy is synthesized with four steps for four sub-visions. Moreover, the strategy is translated into 15 design guidelines. Thereby, organizations could adopt the guidelines to enhance their service or generative service ideas in various cases. <br","Social design; Loneliness; service design","en","master thesis","","","","","","","","","","","","","",""
"uuid:8245b7ad-1a3a-431e-8a6e-e0ffdf59321c","http://resolver.tudelft.nl/uuid:8245b7ad-1a3a-431e-8a6e-e0ffdf59321c","Assessing and modeling the hydrological performance of DIT sewers: A case study at Kuiperstraat and H.A.J.M. Schaepmanstraat, Gouda, Netherlands","Dekker, Lennart (TU Delft Civil Engineering and Geosciences; TU Delft Water Resources)","van de Ven, Frans (mentor); Bogaard, Thom (graduation committee); Langeveld, Jeroen (graduation committee); Prinsen, Jan (graduation committee); Delft University of Technology (degree granting institution)","2019","Gouda deals with land subsidence and groundwater problems. A solution to these challenges is the application of Drainage-Infiltration-Transport (DIT) sewers, on which research is lacking. This thesis provides provides infiltration and drainage capacity values on DIT sewers and helps to understand the governing processes.","DIT sewers; Drainage; Infiltration","en","master thesis","","","","","","","","","","","","","",""
"uuid:2a29f2c2-20c1-4a6e-8a7e-bb05662fd844","http://resolver.tudelft.nl/uuid:2a29f2c2-20c1-4a6e-8a7e-bb05662fd844","Valuation of natural gas storage contracts with the COS method","Jonker, Hendrik (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Numerical Analysis)","Oosterlee, Kees (mentor); Borovykh, Anastasia (mentor); Dubbeldam, Johan (graduation committee); Delft University of Technology (degree granting institution)","2019","Since the liberalization of the energy markets, the storage of energy is decoupled from the production and sales. In Western-Europe the storage of natural gas becomes more and more important because production fields get depleted and governments force companies to slow down their production because of tremors in the ground. Natural gas needs to be imported from countries that are far away, like for example Russia. To provide in security of supply and to ensure there is enough natural gas when the demand is high, it is important to store natural gas nearby.<br/><br/>To determine the value of a gas storage facility in a reliable way we need an efficient market. For an efficient market is needed that the financial instruments, like futures contracts and options on natural gas, are liquidly traded on the exchange. If this condition is met, we are able to determine the value of storage according to market prices.<br/><br/>The COS method was already presented as an efficient method for pricing a broad spectrum of financial derivatives and can be used in combination with all processes for the underlying for which a characteristic function is known. For processes whose characteristic function is not available, the adjoint expansion method can be used to obtain an approximation of the characteristic function. In this work the COS method will be presented as an efficient method for determining the value of gas storage contracts which is competitive with existing valuation methods for natural gas storage contracts.","COS method; Gas storage valuation; Adjoint expansion","en","master thesis","","","","","","","","","","","","","",""
"uuid:b8aaa3b2-eb6f-408b-88cd-5df6d8f90625","http://resolver.tudelft.nl/uuid:b8aaa3b2-eb6f-408b-88cd-5df6d8f90625","Strategic usage of Real-time data for Dynamic Data Driven Simulation: A Sensitivity Analysis","Cho, Yubin (TU Delft Technology, Policy and Management)","Verbraeck, Alexander (mentor); Huang, Yilin (mentor); Delft University of Technology (degree granting institution)","2019","","","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:ca77d0f7-0ea7-4782-a42a-c878c5204956","http://resolver.tudelft.nl/uuid:ca77d0f7-0ea7-4782-a42a-c878c5204956","Multichannel LC ADC: to Record Atrial Electrograms","Das, Aurojyoti (TU Delft Electrical Engineering, Mathematics and Computer Science)","Serdijn, Wouter (mentor); Verhoeven, Chris (graduation committee); Valente, Virgilio (graduation committee); Rout, Samprajani (graduation committee); Delft University of Technology (degree granting institution)","2019","Biosignals such as electoencephalogram (EEG), electrocorticogram (ECoG), atrial electrogram (AEG) etc. are being recorded from multiple channels simultaneously to improve the spatial resolution of the signals. Conventional multichannel synchronous Analog-to-Digital Converters (ADCs) are used to convert the analog continuous time signals into discrete digital values. Several biosignals have a sparsity in time domain as they have fast-rising peaks in between periods of low activity. Use of conventional synchronous ADCs for conversion of such signals is not an efficient approach as their operation is constant, irrespective<br/>of the activity of the input signals. Asynchronous ADCs such as level-crossing (LC) ADCs exploit the sparsity of biosignals and thus their operation is activity-dependent. However, multichannel configurations of LC ADCs do not yet exist. This problem is investigated in this work and a new ADC architecture is presented that can combine synchronous sampling with level-crossing quantisation method while converting input signals from several channels simultaneously. The synchronous LC ADC presented in this work achieves 3.37 times reduction in quantisation steps and 6 times reduction in number of output bits generated during conversion of AEG signals as compared to conventional synchronous ADCs. The problem in existing LC ADCs of data overhead in adaptive resolution technique is solved through a novel method named split resolution technique which is also presented in this work.","Biosignals; atrial fibrillation; ADC; level crossing ADC; multichannel ADC","en","master thesis","","","","","","","","2020-08-23","","","","Electrical Engineering","",""
"uuid:a91471bc-0b0b-43a6-bf5b-dc1b89e168db","http://resolver.tudelft.nl/uuid:a91471bc-0b0b-43a6-bf5b-dc1b89e168db","The effects of porosity in selective laser melted titanium interbody cages and bone mineral density on subsidence: A Biomechanical Study","Bruno, Victoria (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Biomaterials & Tissue Biomechanics)","Zhou, Jie (mentor); Pellikaan, Pim (graduation committee); Delft University of Technology (degree granting institution)","2019","Degenerative disc disorders are among the most commonly diagnosed conditions and the leading cause for back and neck pain, affecting more than 266 million individuals annually. Interbody fusion is the proposed surgical treatment whenever lighter approaches such as physiotherapy and painkillers fail to improve the patient’s condition. It consists of the total or partial removal of the damaged disc, followed by the insertion of a spinal implant, referred to as interbody fusion cage or spacer, to block the vertebral segment and restore disc height. Unfortunately, in some cases this treatment can fail due to a loss in disc height as a result of subsidence, that is the sinking of the cage in the adjacent vertebrae. The investigation conducted in this thesis work focused on the effects of porosity of selective laser melted (SLM) implants and bone mineral density on subsidence, by means of a biomechanical study and a finite element model. In previous works, it was demonstrated that the most influential factor for the occurrence of subsidence is the condition of bone mineral density. Therefore, it was hypothesized that by using an implant with high porosity, the overall stiffness of the bone-implant system would decrease, as well as the stresses at the bone-implant interface, reducing the risk of subsidence and bone damage. At the same time, osseointegration would benefit due to the increased porosity, which is an important factor in the design of orthopaedic implants. The biomechanical study consisted of compression tests according to the standard ASTM-F2267 for subsidence evaluation in interbody fusion implants, according to which polyurethane foams were used to simulate the mechanical behaviour of trabecular bone. Cages designated for the cervical and lumbar regions of the spine were tested in two different porosities, in terms of apparent density of the cage, in combination with three foam densities, low-, medium- and high-density, corresponding respectively to low, average and above-average quality of bone. The results confirmed the findings in the literature and revealed significantly different outcomes when the foam density was changed, while the change in porosity did not affect the stiffness of the foam-implant system. The finite element model of a simplified cervical cage was used to explore the influence of the thickness of the solid frame in porous implants, revealing changes in stiffness of the simulations with the cages alone, while almost no stiffness variations were detected in the simulations for the implant-foam systems. Although the reduction of the stiffness of the system could not be achieved by tuning porosity, it was demonstrated that the mechanical performance of the system was not affected by an implant with higher porosity. These findings opened new research opportunities in the study of osseointegration, since it could be concluded that the use<br/>of implants with higher porosity would not affect the overall stiffness, while allowing more bone ingrowth to avoid cage migration.","Interbody fusion cage; Spinal cage; Bone mineral density; subsidence; Titanium implants; Biomechanical properties","en","master thesis","","","","","","","","","","","","Biomedical Engineering","",""
"uuid:0ef1606b-5823-4de5-af9a-e44c2fb14e45","http://resolver.tudelft.nl/uuid:0ef1606b-5823-4de5-af9a-e44c2fb14e45","Bridging the GRACE gap: Validation of satellite gravity observations via glacial isostatic adjustment","Vermeulen, Sander (TU Delft Aerospace Engineering)","Root, B.C. (mentor); De Teixeira Da Encarnação, João (graduation committee); van der Wal, Wouter (graduation committee); Ditmar, Pavel (graduation committee); Delft University of Technology (degree granting institution)","2019","The GRACE mission has provided unprecedented insights into mass redistribution processes in the Earth system. Following a strong call for continuation of the mass observations, the GRACE-Follow On (GRACE-FO) mission was launched in May 2018, leaving a coverage gap of ca. 1 year between GRACE and GRACE-FO. Geopotential solutions derived from data of the Swarm mission (2013-present) are candidate data to potentially bridge this gap, as well as bridge the minor discontinuities in the current GRACE time series. This study aims to validate the sensitivity of the Swarm measurement system to mass rates, by comparing GRACE and Swarm observations of the gravity trend induced by glacial isostatic adjustment (GIA). Studies inverting GIA observations (e.g., relative sea level change, surface deformation, [time variable] gravity) into mantle viscosity estimates suggest relatively high viscosity in the Hudson Bay area. This suggests that the North American GIA-induced gravity trend is linear on a multi-decadal time scale, which means we can extrapolate the GRACE-derived GIA observations into the Swarm time period for this area. We find that the Swarm-derived GIA observations correspond well in amplitude and spatial distribution to GRACE observations and conclude that both systems have a similar sensitivity to gravity trends at spatial scales to which Swarm is sensitive to (ca. 1500 km). We validate our findings via geopotential solutions of GRACE-FO and provide a brief analysis of the benefits of adding Swarm-derived information to the combined GRACE / GRACE-FO time series.","Satellite geodesy; Gravimetry; Gravity; GRACE; Swarm Satellite Constellation; Glacial isostatic adjustment; Earth observation","en","master thesis","","","","","","","","2019-11-01","","","","Aerospace Engineering","",""
"uuid:5bc46dcb-31dd-4cd8-85ac-2c6db22d7eb4","http://resolver.tudelft.nl/uuid:5bc46dcb-31dd-4cd8-85ac-2c6db22d7eb4","Sustainable Happiness: How we can use psychological well-being to get people to consume less","Wolf, Emiel (TU Delft Industrial Design Engineering)","Hekkert, Paul (graduation committee); Wallner, Theresa (mentor); Delft University of Technology (degree granting institution)","2019","The goal of this project is to find a way to get people to consume less, by changing what they do to improve their subjective well-being. It was found that the main issue that needed tackling is the fact that, currently, people are addicted to consumption - they depend on consumption for their happiness. The best way to remedy this would be to teach them how to make themselves happy; this can be done by getting them to derive their happiness from Eudaimonia. Eudaimonia can be defined as happiness or contentment derived from your life and the things that you do having meaning, and from good relationships with people you care about. Design intervention testing was used to explore how people would best be taught how to make themselves happy. After some initial explorations of the subject matter, three more effective designs were developed to be tested more thoroughly. Fifteen people tested the designs; they were interviewed before and after using the design to see if any changes occurred. The interviews tried to establish if the designs had any influence on what people’s life goals were, on whether the actions they took were in line with eudaimonia, and on if they would buy items that they did not need for these eudaimonic actions. This testing process yielded three main design principles. In order to help people get better at making themselves happy, a design should:<br/>● Help you reflect on which eudaimonic activities they already partake in<br/>● Get you to connect these actions to the items necessary for them<br/>● Urge you to avoid non-eudaimonic actions and items<br/>Aside from these three principles, some insights on how to best implement each of the principles were found as well. To illustrate how these principles and insights are best put to use, some design examples were developed. Firstly, a time capsule was designed which people can put items they are not sure they need into; during the month that the items are locked away in the capsule, it gets people to reflect upon whether they need the items. Afterwards, people are urged to give away any of the unneeded items. This helps people gain an understanding of what they do and do not need. Aside from this, redesigns to eBay, Bol.com and Climate Activist websites were developed to give some examples of how the findings could be used by other designers.","Design for Happiness; Subjective well-being; Sustainability; Sustainable Consumption; Eudaimonia; Minimalism","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:5961f14d-8d3e-4be6-b127-010a20f8b044","http://resolver.tudelft.nl/uuid:5961f14d-8d3e-4be6-b127-010a20f8b044","Evolving State Machines as Robot Controllers","den Toom, Matthijs (TU Delft Electrical Engineering, Mathematics and Computer Science)","Langendoen, Koen (graduation committee); Verhoeven, Chris (mentor); Nasri Nasrabadi, Mitra (graduation committee); Delft University of Technology (degree granting institution)","2019","Automated generation of robot controllers using an Evolutionary Algorithm(EA) has received increasing attention in the last years as it has the potentialfor a reduction in the development time of a robot. Often these EAs generateNeural Networks (NNs) as robot controllers. Using a NN for automaticallygenerating robot controllers has two important downsides: 1.) A human isnot able to fully understand the inner working of a multi-layer NN, and 2.)a NN has only limited abilities to decompose a complex task into sub tasks.Both of these downsides can be addressed by using a State Machine (SM)instead of a NN as robot controller. Therefore, this thesis introduces an EAcalled Evolving State Machines As Controllers (ESMAC). ESMAC generatesSMs instead of NNs. A SM is understandable for humans because ofits modularity and allows for task decomposition by using a state for eachsub task. Furthermore, two extensions of ESMAC are proposed: adaptiveESMAC and selector ESMAC. Adaptive ESMAC aims to automatically determinesthe number of states with which the best tness for a task canbe achieved. Selector ESMAC replaces the transitions that are used in aSM to switch between states with a NN-based switching mechanism. This switching mechanism allows mutations to make more gradual changes to aSM's behaviours, which improves the performance of the EA. The performance of ESMAC is evaluated on two robotic tasks: come-and-go and phototaxis-with-obstacles. All three variants of ESMAC showequally good performance as a NN-based EA on the evaluated tasks. Thecontrollers generated with standard ESMAC and adaptive ESMAC hardlymake any state transitions and mainly use one state. However, controllers that do use multiple states appear to be more robust to changing scenarios and in noisy environments. Selector ESMAC is able to generate SMs-based controllers that have complementing states and, therefore, shows potentialfor decomposing a task into sub tasks.","Evolutionary Algorithms; State machines","en","master thesis","","","","","","","","","","","","","Zebro project",""
"uuid:77650c7b-9a31-40f1-be80-a13ecd9fcb7a","http://resolver.tudelft.nl/uuid:77650c7b-9a31-40f1-be80-a13ecd9fcb7a","Designing a sustainable high-rise structure: Research into the material environmental impact of the main load-bearing structure of the building for the European Patent Office","Booms, Elise (TU Delft Civil Engineering and Geosciences)","Nijsse, Rob (mentor); Terwel, Karel (graduation committee); Jonkers, H.M. (graduation committee); Robbemont, Arnold (graduation committee); Delft University of Technology (degree granting institution)","2019","This research investigated in which ways the material environmental impact of the main load-bearing structure of a high-rise building can be reduced. To determine this material environmental impact, the shadow price for each material and product has been determined by using ten environmental impact categories. One of these categories is global warming potential.<br/><br/>In this research the material environmental impact of the main load-bearing structure for the building for the European Patent Office has been determined and optimized. The originally designed main load-bearing structure for this building consists mainly of steel columns and beams, and Slimline floors. <br/>The optimisation has been done for a design lifespan of 50 years and for 200 years. Additionally, a higher live load that creates more flexibility for the 200-year scenario is examined. The original function for the building is “office” and the other considered function is “meeting”.<br/>As alternatives for the beams and columns, steel, concrete, and timber elements have been considered. Hollow core slabs and Lignatur floors were explored as alternatives for the Slimline floors.<br/><br/>In this research it has been found that it is beneficial to prolong the design lifespan of building. The environmental impact per year is much lower for a lifespan of 200 years than for a lifespan of 50 years. In order to increase the chance of a longer lifespan, it is wise to create flexibility concerning the function of the building. A higher live load will result in slightly more material needed, but still, the environmental impact per year is much lower than for 50 years.<br/>Additionally, there can be looked at choosing the best material for each application. For a design lifespan of 50 years, the difference between the materials is such small, that no preference can be determined. For a lifespan of 200 years the differences are still small, but an entire steel structure or a combination of steel beams and concrete columns result in the smallest environmental impact. For floors, no matter the lifespan, with a big span and where no in-situ concrete can be used, hollow core slab floors proved to be the best choice.<br","Sustainability; High-rise buildings; Environmental impact; European Patent Office; Main load-bearing structure","en","master thesis","","","","","","","","","","","","Civil Engineering | Building Engineering","",""
"uuid:93509e4b-ff46-4af7-bdd2-c7de306d55d2","http://resolver.tudelft.nl/uuid:93509e4b-ff46-4af7-bdd2-c7de306d55d2","Modelling and Control of a Dynamical Labour Market System: An Economic-Engineering Approach","Huisman, Leo (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Delft Center for Systems and Control)","Mendel, Max (mentor); Delft University of Technology (degree granting institution)","2019","Labour market economics has been gaining more and more attention over the years, due to increasing job insecurity. There is a growing demand for the improvement of labour market models. Labour market models are representations of the labour market system used to provide insight to the effects of government policy. Current labour market models have been<br/>criticised due to their complexity. Moreover, the models do not provide adequate insight on the relation between the model’s assumptions and their outcome.<br/><br/>This thesis applies Economic Engineering to the labour market system. The system is modelled using Economic-Engineering analogs and the government is modelled as a controller. The Economic-Engineering methodology adds understanding to the labour market system itself and the performance of the government’s policy.<br/><br/>This thesis presents both a micro- and macro-scale interpretation of the labour market. It is shown how system characteristics determine the system’s response to market shocks. Frequency domain analysis is used to connect the dynamical behaviour on both scales to the system’s response. This gives increased insight in the labour market’s system dynamics.<br/><br/>The government is treated as a controller. A PID- and a robust H_infinity-controller are designed to provide policy advice. The control objective is to minimise the effects of international disturbances on Dutch unemployment rates. The control input of both controllers is in compliance with current economic theory. It is shown in what sense the PID controller differs from the H_infinity-controller and under which conditions which controller is advisable. This depends on knowledge on the type of uncertainty and disturbances acting on the system.","Labour market; Economic engineering; Economic modelling","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:027be3f5-1bb4-4727-8030-3d610bd508ff","http://resolver.tudelft.nl/uuid:027be3f5-1bb4-4727-8030-3d610bd508ff","Using Publisher Partisanship for Partisan News Detection: A Comparison of Performance between Annotation Levels","Yeh, Chia-Lun (TU Delft Electrical Engineering, Mathematics and Computer Science)","Tintarev, N. (mentor); Houben, G.J.P.M. (graduation committee); Wang, H. (graduation committee); Delft University of Technology (degree granting institution)","2019","News is the main source of information about events in our neighborhood and around the globe. In an era of digital news, where sources vary in quality and news spreads fast, it is critical to understand what is being consumed by the public. Partisan news is news that favors certain political parties or ideologies. It is undesirable because news organization should aim for an objective and balanced reporting. An automatic system that can classify news to be partisan or non-partisan is thus desired. Such a system (partisan news detector) requires a sufficient amount of data to learn the pattern of partisanship in news articles. However, these labels are expensive to collect since manual inspection of each article is required. <br/><br/>Inferring partisanship labels from the partisanship of publishers is another approach that has been used in previous research. By treating all articles by partisan publishers to be partisan news and those by non-partisan publishers to be non-partisan, it is easy to collect a large number of labeled articles. This way of deciding labels is noisy, making it more difficult for a detector to learn. <br/><br/>This thesis compared the performance of using publisher-level labels and article-level labels for partisan news detection. The detector was designed as a binary classifier. We compared the difference in performance across several feature sets to ensure the observed difference was due to the annotation level, not the choice of specific classifiers. The experiments were performed on two datasets of different properties to ensure the generalizability of the results. We found that classifiers trained with publisher-level labels have higher recall but lower F1-score compared to classifiers trained with article-level labels. We also observed that the classifiers overfit on publishers but reducing the overfitting with feature selection did not improve the performance. Comparing the performance difference between the two datasets, we concluded that an important factor that determines the performance achievable by the publisher-level labels is the quality of publishers that are included in the dataset. This is valuable for future dataset collection.<br/><br/>Our work provides a benchmark performance of publisher-level labels, which can be used as baselines for future research that investigate other methodologies to utilize the noisy labels. We also compared the performance between the two levels of annotation and concluded that partisan news detectors trained with article-level labels are more practical to be used in a fully-automated system since they have on average 10\% higher F1-scores than those trained with publisher-level labels. However, the high recall of the latter makes them applicable in use cases where high recall is desired.","machine learning; news media; label noise","en","master thesis","","","","","","","","","","","","Computer Science | Data Science and Technology","",""
"uuid:ec5ce42d-8cf5-4563-b4dd-adf109974f6f","http://resolver.tudelft.nl/uuid:ec5ce42d-8cf5-4563-b4dd-adf109974f6f","Elevating decision-making for maintaining inner-city quay walls: A conceptual decision-making model for implementing intervention measures","Badu-Sampene, Malcolm (TU Delft Civil Engineering and Geosciences)","Liu, Y. (mentor); Hertogh, M.J.C.M. (graduation committee); de Gijt, J.G. (graduation committee); Temmink, H.E.M. (graduation committee); Delft University of Technology (degree granting institution)","2019","It is no secret that (asset)managers are currently dealing with a difficult task to maintain and improve the quality of their assets. The main reason for this urgency is the change of use and the end of lifespan of these assets. This is especially the case regarding the inner-city quay walls. These quay walls are usually owned and managed by local governments. The city of Amsterdam in particular has a tough task ahead of them. Approximately 200 km of quay wall need to be maintained or renewed of which the technical state is unknown. A vast majority of these inner-city quay walls are retaining walls on wooden piles. The absence of this information makes it extremely difficult for the asset owner, to determine the current technical state of their quay walls. The combination of limited information and time have shown in practice that quay walls can fail at any moment. To prevent this from happening a variety of intervention measures can be deployed to ‘extend’ the lifespan of the quay walls (short-term). Thereafter a systematic approach can be applied to rebuild or renovate these quay walls (long-term). However, the implementation of intervention measures is an overall complex task due to the densely built area and the stakeholders with divergent interests. This study provides an objective conceptual decision-making model to determine which intervention method is best suited for a particular location while considering the impact on the city, stakeholders and organizations. The research revealed six important topics which need to be incorporated in to the decision- making model. The topics were determined based on literature review, a case study and interviews. These six topics are: the critical cases (1), failure mechanisms (2), intervention measures (3), characteristics of the physical surrounding and the intervention measures (4), decision- making criteria (5) and lastly mitigation measures (6). Additionally, three decision-making moments are identified.","Inner-city quay walls; Decision-making model; Failure mechanisms; Intervention measures; Safety; Accessibility; Liveability","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:f5c92b20-8a03-4da5-97c5-91fad7228274","http://resolver.tudelft.nl/uuid:f5c92b20-8a03-4da5-97c5-91fad7228274","Childhood Obesity: Data informed policies for targeted interventions in the Netherlands","Matzorou, Violetta (TU Delft Technology, Policy and Management)","Lukosch, S.G. (graduation committee); Cunningham, S. (mentor); Struijs, Jeroen (graduation committee); Delft University of Technology (degree granting institution)","2019","The dietary habits changed drastically since 1980 and the chemical composition of a lot of processed foods was altered to meet new requirements. This nutrition shift along with the industrialisation and the rise of the sedentary lifestyle, led to the spread of the obesity epidemic which still manifests in many countries, including European. Children are also affected from this epidemic, with the childhood overweight and obesity trends to grow. The OECD children average for 2017 reached a 15.5%. However, in each country different factors contribute to the manifestation of the phenomenon, composing its unique obesogenic environment. In the current thesis proposal, exploratory statistical modeling is employed, to identify the non-biological factors explaining children's weight for the Netherlands. The analysis is conducted with the use of a custom framework to capture factors which are linked with societal inequities. The outcome of this analysis is a group of factors which explain the weight in preschool children. Also, significant results for preschool children are derived by comparing different screening definitions for overweight and obesity, showing the clusters of risk-prone children. By using the insights from the analysis, data informed policies are proposed to aid the creation of a healthier urban environment for future population to thrive in. Data informed policies based on governmental data for the Netherlands can facilitate the decision making and make prevention and mitigation of the epidemic more effective, by targeting appropriately different population segments which are in need. Future research could focus on prediction models of obesity based on the significant factors identified in this study. Also, the expansion of the current models with more variables from the urban environment is needed to show more specific associations with urban features.","childhood obesity; health inequity; health policy","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:198d6ab2-cf81-47ec-81b6-064e804fdc5d","http://resolver.tudelft.nl/uuid:198d6ab2-cf81-47ec-81b6-064e804fdc5d","Direct Trade PPA: Economic &amp; Financial Benefits of a Direct Energy Contract With a Wind farm","Kruijsse, Wietse (TU Delft Technology, Policy and Management)","Correljé, A. (mentor); Hakvoort, R.A. (graduation committee); Last, Job (mentor); Delft University of Technology (degree granting institution)","2019","In the Netherlands more wind farms are constructed and energy is contracted in long-term Power Purchase Agreemenats (PPA) to guarantee a steady revenue stream for the wind farm owners. However, until now only large corporates closed PPA contracts to obtain the Renewable Energy Credits (RECs) from a wind farm and claim to be renewable. A new type of PPA is designed that has a direct link between the corporate and wind farm and transfers both power and the RECs. This direct trade PPA is analysed by applying an economic theory, the property rights theory, on the energy sector and by modelling the financial consequences. The result is a framework with the transactions, the risk allocation and the economic incentives of the actors involved. It shows more incentives to invest in renewable energy, moreover the corporate takes more volume risk on the energy production in order to obtain benefit which can be reduced by contracting a service provider. Furthermore, the financial model shows a significant financial benefit for a direct trade PPA compared to a traditional contract and shows a positive eect on the match between supply and demand. Moreover, the match and benefit can be increased by 25% by adding solar capacity in combination with wind energy. The next step is to further investigate this direct trade PPA and to promote this PPA type to corporates that want to invest in renewables and use this as a preferred contract type.","Power Purchase Agreement; Wind Farm; Direct Trade; Service provider; Property Rights Theory","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:5662ef20-f05c-440f-b0b0-20f623a6d43e","http://resolver.tudelft.nl/uuid:5662ef20-f05c-440f-b0b0-20f623a6d43e","Using Social Network Analysis for Fraud Detection: Tracing the Path from Data to Value","Clerx, Miriam (TU Delft Technology, Policy and Management)","Cunningham, S. (graduation committee); van der Voort, H.G. (mentor); Booijink, Tom (mentor); Suppers, Anouk (mentor); Delft University of Technology (degree granting institution)","2019","Facing the age of digitalisation, inspectorates are changing their way of working using a risk-oriented and data-driven approach. Social Network Analysis (SNA) seems to be promising in detecting fraud and simultaneously contributing to increasing the effectiveness and efficiency of inspection work. SNA emphasises the structural aspects of networks to detect and interpret patterns of social entities, both graphically and mathematically. Although the emergence of big data opens great opportunities in the public domain and the benefits of using SNA in fraud detection seem to be clear cut, a more institutional view challenges the assumption that simply working data-driven leads to better deployment of enforcement assets. In practice, the way in which business value is created from big data often remains unclear. There seems to be a gap between the promises of big data and its practical realisations, in particular in the public domain. Therefore, this research considered big data in the context of SNA from an institutional perspective. This means it is assumed that actors that shape the process from data as a raw material to the final deployment of inspection capacity based on the outcome of the analysis. This research underlined a decision-making perspective which states that the way in which the alternatives are framed impacts the alternative chosen by people and in turn the subsequent decision. By using a qualitative research approach consisting of a multiple-case study design combined with action research this research contributed to two main purposes. First of all, the study had a functional purpose aimed to explore the use of SNA in fraud detection, more specifically fraud in the context of food and consumer products. Following from the analysis of two large real-world data sets, it turned out that network visualisation offers a powerful solution to make information hidden in networks easy to interpret and understand. With one glance at the network one could identify who does business with whom, which entities act as bridges between two clusters, trace suspicious patterns, and gain insight into the overall structure of the networks. Applying network metrics helped to quickly identify the important players in the networks and could be used to evaluate or predict the possible consequences of removing specific actors from the networks to destabilise the networks. Secondly, the research had an institutional purpose aimed to get insight into big data value creation in the public sector. During the research, it became evident that important assumptions and decisions have been which appeared to be fundamental for the outcome of the analysis. This prevented the creation of options or led to options that were sub-optimal. Neglecting them would be at the detriment of any SNA-ambition an organisation may hold. As the research into both areas is still in a very young state, the findings from this thesis form a starting block for other studies to expand on. Future research will be addressed to widen the empirical evidence on how big data affects public decision-making.","Social Network Analysis; Fraud Detection; Public Decision-making; Big Data Analysis","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:21c1e156-c8df-4ab6-8630-25c6170d3bc6","http://resolver.tudelft.nl/uuid:21c1e156-c8df-4ab6-8630-25c6170d3bc6","Numerical and Experimental Study of Airfoils with Porous Trailing Edge","Tamaro, Simone (TU Delft Aerospace Engineering)","Ragni, D. (mentor); Avallone, F. (mentor); Shen, Wen Zhong (mentor); Delft University of Technology (degree granting institution); Technical University of Denmark (degree granting institution)","2019","The addition of porous material to the trailing edge of airfoils was studied numerically and experimentally. The purpose of this work is to inspect whether the penalization method can be successfully used to describe flows through porous media. In the numerical study, the penalization method was applied to the incompressible Navier-Stokes equations. The flow has been studied with turbulent, unsteady simulations. The SIMPLE algorithm and a mixed scale model for LES were used in EllipSys2D. The code was validated with a test case on a flat plate. In this case, porous inserts are capable of suppressing vortex shedding by mitigating the pressure discontinuity at the trailing edge. An agreement with wind tunnel data could be observed both in the wake and in the boundary layer. The code was then applied to study a NACA0018 airfoil at zero angle of attack. In this case, porous materials reduce the energy content of turbulent signals in the wake. The power spectral density of pressure fluctuations in correspondence of the porous insert is reduced in the whole spectrum. The same airfoil was considered with the addition a single roughness element to trip the boundary layer at 20% of the chord. The height of the step was chosen from the results of a sensitivity analysis. The presence of the trip triggers turbulence transition successfully. Pressure drag for the porous case was found to be dependent on the presence of the trip. In the experimental study, measurements were taken on a symmetric NACA0018 airfoil at zero angle of attack. Hot-wire anemometry and surface microphones were used to measure the flow. Porous inserts with different permeabilities have been studied. Porous materials at the trailing edge increase the shear of velocity profiles in the boundary layer and reduce the power spectral density of pressure fluctuations in correspondence of the trailing edge. According to this study, the penalization method is a promising tool to study flows through porous media.","Porous Media; Aeroacoustics; CFD","en","master thesis","","","","","","","","","","","","European Wind Energy Masters (EWEM) | Rotor Design Track","EWEM (European Wind Energy Masters)",""
"uuid:7c5a0445-cac3-470c-9e36-e9c828f15cde","http://resolver.tudelft.nl/uuid:7c5a0445-cac3-470c-9e36-e9c828f15cde","Exploring trade-offs in on-board versus cloud-based social robots","de Graaf, Marnix (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Interactive Intelligence)","Hindriks, K.V. (mentor); Hung, H.S. (graduation committee); Szlávik, Z. (graduation committee); Timmermans, Benjamin (graduation committee); Delft University of Technology (degree granting institution)","2019","Social Robotics is an emerging field in Computer Science. Most social robots currently commercially available to buy do not have fast hardware components. As a result, the built-in software has low accuracy and performance with (amongst others) speech and facial recognition and dialogs during social interaction with users. Cloud computation offers state-of-the-art techniques, performance, and accuracy with its massive available computational power, but at extra costs and increased latency. <br/><br/>In this work, we extend and improve a social robot's standard capabilities and performance by making use of cloud computation. This thesis covers an exploration for the trade-offs present when replacing or augmenting built-in robot software with IBM cloud services, based on the humanoid Pepper robot from Softbank.<br/><br/>The approach for this exploration was guided by a hospitality use case demonstrated in the offices of two companies: a Dutch Health Insurer and IBM Netherlands. Two products were developed for this single use case based on different development toolboxes. The first toolbox contains all development software from the robot's manufacturer (the NAOqi toolbox), while the second toolbox makes use of cloud services (the Watson Toolbox). Using the product built with the NAOqi toolbox, we evaluate interactions with real users and obtain baseline data and experiences. After evaluating the second product built with the Watson toolbox, we can compare differences in human-robot interaction quality, robot component quality, development methods, and software engineering complexity and Total Costs of Ownership for both products. <br/><br/>The main findings include an overview of relevant test metrics and test methods for a social robot's component, including acquired data for some components of the Pepper robot. We show possible architectures for a (semi) cloud-based system, and their trade-offs. Evaluations show that the cloud-based system indeed performs better and has higher human-interaction quality compared to the product built with the NAOqi toolbox, yet downsides such as latency and operating costs are present. This is also reflected in the analysis of single components, where specifically Speech-to-Text from the cloud shows a significant increase in performance and capabilities. We show that a mix of toolboxes results in the best working and cheapest social robot when considering Total Cost of Ownership. IBM Cloud pricing structures and operating costs are analyzed for this. Finally, we contribute to the currently available knowledge on this subject with a decision matrix combining all previously mentioned information in a compact form accessible to people not knowledgeable in the hospitality robot or cloud domains. With the matrix, early-development advice decisions for creating a social robot can be formulated using the data gathered in this thesis.<br/><br/>With a broad approach, this research focuses on finding and discussing trade-offs, rather than an in-depth analysis of all components. Providing methods to determine the data as mentioned above, findings, and trade-offs are more important than the actual numbers found in this thesis, as advances in this domain are quick and expected to change often. The end product built using the Watson toolbox is an improvement on multiple levels, yet is still not always able to autonomously and correctly finish all intended interactions. However, its capabilities, performance, and robustness are closer to the level of being used commercially. The techniques we use to extend Pepper's capabilities could be applied to any social robot.","Social Robotics; Cloud Computing; human robot interaction","en","master thesis","","","","","","","","","","","","","",""
"uuid:444450c5-ae6f-4e2b-b1e2-66fe496bf888","http://resolver.tudelft.nl/uuid:444450c5-ae6f-4e2b-b1e2-66fe496bf888","Optimizing The Installation of steel, Open-Ended Piles Through Impact Hammering For Offshore Applications: A Parametric, Experimental Study In The Geocentrifuge","Quinten, Tristan (TU Delft Civil Engineering and Geosciences)","Askarinejad, A. (mentor); Gavin, Kenneth (graduation committee); Pisano, F. (graduation committee); Hof, van 't, Cornelis (graduation committee); Alvarez Grima, Mario (graduation committee); Delft University of Technology (degree granting institution)","2019","As a result of population growth and economical prosperity, energy consumption has been on the rise for decades. Present-day projections predict the continuation of this trend with the rapid industrialization of former second world countries. Together with the rise of energy demand, incentives fo the scientific community to quantify the environmental impact of the ever increasing need for energy have gained momentum. It now is clear that continued use of carbon-based energy sources will have a catastrophic, irreversible impact on the global climate. The urgency of this message, which is supported by nearly the entire scientific community, was finally heard in 2012 when the Paris Agreement was drafted. Nearly collectively, the world’s countries are committing themselves to start the transition to durable sources of energy. One of the most promising sources of energy to facilitate the aforementioned transition, is the wind. Europe specifically is home to large patches of sea, which are ideally suited for the construction of offshore wind farms. Due to high construction costs, these endeavors out at sea were, until recently, heavily dependent of governmental support. However, due to advances in technology, wind frams have become profitable enough to be realized without governmental grands. Of the current offshore wind farms, the majority of the budget is allocated to the foundation design, construction and ultimately installation. Monopiles are convincingly the most common foundation type found. Although alternatives under development, it is unlikely for the popularity of this simplistic foundation will diminish in the near future. Especially, as the hollow, large diameter, hollow, steel profiles are finding their way into other foundations types, in example tripods. The installation of the monopiles offshore is mostly done through costly operations involving large hydraulic hammers. Prior to installation, drivability analyses are commissioned which determine the required hammer capacity. The rather simplistic software (in terms of soil representation) used to conduct these calculations, offers limited room for the optimization of the installation process. On the other hand, several full scale experiments have demonstrated that clever manipulation of driving parameters, specifically: (I) hammer weight; (II) driving frequency; (III) falling height/impact velocity; can significantly benefit installation times. This leaves a huge potential for cost savings (several millions EUR) per farm and forms a prime opportunity to stimulate the transition of offshore wind energy towards the mainstream. However, no consensus has been reached on the dynamic processes which positively contribute to the drivability of monopiles, let alone how these processes can be consciously induced in the subsoil. This research sets out to, by means of a parametric experimental study in the centrifuge, evaluate the effects of changes in driving parameters on driving time. Three hypothesis has have been drafted in an attempt to explain the higher efficiency piling operations employing HiLO (high frequency, low falling height) techniques instead of conventional driving, namely: (I) aggravated friction fatigue along the shaft due to an increased number of load cycles as a result of frequency increase; (II) Less dynamic soil resistance following from lower impact velocities, yielding the more efficient usage of available piling energy; (III) accumulation of excess pore water pressures, which reduce the effective stress regime surrounding the pile and thereby benefit piling rates. Through 24 centrifuge experiments, the aforementioned hypotheses are evaluated. During the experiments the effect of changes in driving parameters in monitored. Moreover, water pressure sensors mounted both on the pile shaft and inside the surrounding soil body record the soil response during driving. Results indicate that the dynamic installation of open-ended tubular piles in sandy soil, characterized by a high Rd (¼80%), is associated with the development of excess pore water pressures at larger radial distances from the pile due propagation of seismic waves. However, unlike similar experiments of samples with a lower Rd , the generated excess pore fluid pressures are limited in their magnitude as the soil exhibits no contraction to aid further generation. Moreover, closer to the pile, a transition towards a dilative soil regime is observed, where the increase of driving frequency is arguably related to the accumulation of tensile pore fluid pressures along the shaft, which negatively affects pile drivability. Results indicate the aforementioned adverse effect is partially compensated through the use of a heavy hammer due to subtle difference in soil-structure interaction related to the different geometry of the hammer. Consequently, it seems that HiLo driving is not a technique which guarantees better drivability under all circumstances. Hence, in the quest for optimum drivability, the prevailing soil conditions should play a decisive role in the selection of the best suited pile-hammer combination and driving technique.","Pile Driveability; Pile driving; Impact hammer; Excess pore water pressure; geo-engineering; Centrifuge modelling; Physical modelling; Monopile optimization; Monopile Installation; Offshore Wind","en","master thesis","","","","","","","","2021-08-23","","","","","",""
"uuid:e688d392-7110-4465-ab1b-4f63305768bf","http://resolver.tudelft.nl/uuid:e688d392-7110-4465-ab1b-4f63305768bf","The effect of post process treatments on biomechanical properties of Ti6Al4V metamaterials and spinal cage implants manufactured by selective laser melting","Blok, Adriaan (TU Delft Mechanical, Maritime and Materials Engineering)","Popovich, V. (mentor); Ahmadi, S.M. (mentor); Rans, C.D. (mentor); Gonzalez Garcia, Y. (graduation committee); Zhou, J. (graduation committee); Delft University of Technology (degree granting institution)","2019","Selective laser melting (SLM) is an additive manufacturing technique, which is currently on the rise of being used for manufacturing bone implants. Spinal cage, dental and hip implants can for example be manufactured using SLM. Ti6Al4V lattice structures, categorised as metamaterials, can be printed by SLM with mechanical properties close to bone tissue. Due to the lattice structure the stiffness of the Ti6Al4V is decreased, by which stress shielding can be reduced. The lattice structures enhance bone ingrowth which in turn improves the implant’s integration into bone tissue. In light of this potential, this research is focused on biomechanical properties of additively manufactured Ti6Al4V metamaterials.<br/><br/>The current research is aimed at improving the fatigue resistance and wettability of diamond lattice structured Ti6Al4V by applying different microstructural designs and surface engineering through hot isostatic pressing (HIP), sand blasting (SB) and chemical etching (CE). Furthermore a comparison is made between the two SLM processes in terms of continuous and pulsed laser scanning. In order to verify the developed herein post treatment procedures, the tests were also upscaled to actual spinal cage implants. Furthermore, surface modifications affect its wettability which can be linked to cell adhesion and ultimately healing time of the implant. Hence Sessile drop tests were performed to assess the wettability and compare the effect of the various surface modifications.<br/><br/>For both SLM methods it was found that HIP reduces porosity of Ti6Al4V metamaterials, which reduces crack initiation sites and it also serves as a heat treatment increasing the b-phase fraction and thus increasing ductility<br/>and fatigue resistance. SB and CE were found to reduce surface indiscrepancies, which decrease the effect of stress concentration and fatigue initiation sites. Finally SB induces compressive residual surface stresses which means the surface is work hardened, increasing the overall mechanical properties.<br/><br/>For continuous SLM samples an increase in yield strength from 89 MPa up to 115 MPa was found by applying HIP treatment. It should be noted, however, that static mechanical properties were not affected by SB and CE treatments. Fatigue resistance, both low cycle (LCF) and high cycle fatigue (HCF), was significantly improved by a combination of HIP, SB and CE. The observed trend was similar for both pulsed and continuous SLM samples. It is worth noting that SLM samples manufactured with pulsing laser were found in general to be inferior to the<br/>continuous laser SLM, both in terms of static and dynamic properties. The difference is likely attributed to the nature of the laser scanning process, where for pulsing laser method each bead interconnection serves as stress concentration, while for continues laser it is rather the strut interconnections that act as weakest points. Furthermore, for the continuous SLM a preferred grain growth direction was observed which indicates anisotropy. This was not observed for pulsed SLM samples.<br/><br/>For the wettability results it was observed that SB decreases and CE increases the contact angle. A decrease in contact angle means the surface has become more hydrophilic, hence the in this study developed SB modification could be considered as more favourable for osseointergration.<br/><br/>The upscaled spinal cage implants post treatment procedure showed a decrease in yield strength and an increase in fatigue resistance for the HIP+SB+CE as compared to as-processed implants. The rather limited post treatment<br/>improvement on implants was linked to the post process treatment method, which should be modified to account for the complex geometry of these structures.","Ti6Al4V; Metamaterials; Lattice; Fatigue; Mechanical behaviour; Microstructure; Selective Laser Melting; Spinal cage; Wettability; Normalisation","en","master thesis","","","","","","","","2021-08-23","","","","","",""
"uuid:fda2008b-d061-4f5a-99de-119966edf1ce","http://resolver.tudelft.nl/uuid:fda2008b-d061-4f5a-99de-119966edf1ce","Development of an analytical model for a special design asynchronous motor","Li, Wan (TU Delft Electrical Engineering, Mathematics and Computer Science)","Bauer, Pavol (mentor); Dong, Jianning (mentor); Bax, Peter (mentor); Smets, Arno (graduation committee); Delft University of Technology (degree granting institution)","2019","Electrical motors have been widely used in various fields for hundreds of years. The asynchronous motor is always an interesting topic due to its advantage of the simple structure, robustness, low maintenance cost and long lifetime. In this research, a special structure rotor is used instead of the classical squirrel cage rotor. To understand the asynchronous motor behaviour and improve the motor performance, an analytical model is developed in MathCAD and a simulation model with finite element method is built in ANSYS. The research problem is solved successfully by eliminating certain space harmonics with proper winding distribution design. The effectiveness of the proposed method is verified via both modelling and simulation. In the end, a well-performing prototype is made and the test results are aligned with the results from the developed analytical model.","Asynchronous motor; Space harmonics; Finite element method; Winding distribution; Analytical modeling","en","master thesis","","","","","","","","","","","","","",""
"uuid:4bb635dc-6e4e-434d-a583-22414e2069f2","http://resolver.tudelft.nl/uuid:4bb635dc-6e4e-434d-a583-22414e2069f2","Identifying Anomalous Transitions in SIP Traffic: Using PDFA State Merging","Reinbergen, Hugo (TU Delft Electrical Engineering, Mathematics and Computer Science)","Verwer, Sicco (mentor); Delft University of Technology (degree granting institution)","2019","The analysis of lawfully intercepted traffic is a key part of many investigations of criminal activity. This makes it vitally important that the intercepted data is correct and that issues with the configuration of the network or interception solution do not contain errors. A late discovery of a problem in either the network setup or the traffic delivered to law enforcement can lead to loss of crucial information.<br/><br/>This thesis presents a method that aids in the timely discovery of such issues by using machine learning to create a state machine that models the traffic of a SIP network. This state machine is learned with state merging using the blue-fringe algorithm with multiple statistical tests. The state machine is learned in an unsupervised manner from completely anonymous data. Any new network traces can be classified by the state machine using the probability of the transitions found in the model. Any sequence in the trace that has a transition below a certain threshold will be seen as anomalous.<br/><br/>The result of this method is a model that can identify anomalies from a large dataset with 99% recall and 81% precision. It is also shown that the model can identify the errors in the data from an incorrect configuration encountered in the past. This is done in a white-box fashion that shows exactly which transitions in the SIP traffic are incorrect. Being able to do this gives the opportunity to prevent a loss of critical data for an investigation by alerting operators of errors in the network as soon a possible. This allows them to resolve the issues faster and gather as much evidence as possible.","SIP; State Merging; Machine Learning","en","master thesis","","","","","","","","2029-08-23","","","","","",""
"uuid:a3e8e436-1c8d-45c9-9d15-50e5623950cc","http://resolver.tudelft.nl/uuid:a3e8e436-1c8d-45c9-9d15-50e5623950cc","Resilient Logistics &amp; Distribution System: A Conceptual framework for ABC","Ritu Raj, Ritu (TU Delft Technology, Policy and Management)","Maknoon, Yousef (mentor); Tavasszy, Lóri (graduation committee); Verburg, Robert (graduation committee); Radford, Alex B. (graduation committee); Delft University of Technology (degree granting institution)","2019","Today, Oil and gas industry is fulfilling the world’s energy need, but while doing so, it is also facing challenges due to volatile crude oil price and global warming concerns. This puts emphasis on cost optimization to increase the profit margin and avoid any cost leakages. The logistics and distribution domain always remained important for managers interested to reduce cost and add value to its product and services. Many a times, due to imbalance between the production capacity and inventory storage capacity, the logistics supervisors are compelled to rent 3rd party offsite warehouse which puts extra financial burden on the company. Hence, there is a need to align the production, inventory and distribution operations to maximize the profitability of the manufacturing facility. In this work, a conceptual framework has been prepared to bring resilience in the transport planning of ABC Refinery and PP Polymer Plant. The main research question in this research is as follows: “How to design a conceptual model for logistics and distribution system to make it more resilient against real time disturbances?”. To answer this, System design methodology has been adopted. In this approach, functional analysis has been performed to developed alternative solutions to bring resilience in the transport planning which would align the production capacity and inventory, thereby offsetting the impact of any external disturbance. In this work, unstructured interviews, desk research followed by survey among truck drivers has been conducted to identify the factors affecting the ABC transportation. Later, Bayesian network has been used to analyze the present operations and to predict the performance in worst case of road congestion. To answer the main research question, literature review has been performed to design a Decision support system for dynamic slot allocation of Truck loading in ABC. The result of this work shows that the Multi Agents based Decision support system can improvise the Logistics and Distribution system of ABC by bringing more resilience in the Transport planning against any unforeseen events. Descriptive evaluation has been performed to assess the performance of this solution strategy over attributes identified in the system analysis. In the end, this work provides recommendation of using Operations research in the slot definition and slot allocation process for new shipment order.","logistics; Transportation; Decision Support System; Business Process Model; Bayesian Network","en","master thesis","","","","","","","","","","","","","",""
"uuid:491df961-e62a-4785-bf15-e572470f66e4","http://resolver.tudelft.nl/uuid:491df961-e62a-4785-bf15-e572470f66e4","Technical feasibility study for slurry transport of the Atlantis II deep-sea mining field","Jorna, Stijn (TU Delft Mechanical, Maritime and Materials Engineering)","Miedema, S.A. (mentor); Hendrikse, H. (graduation committee); Schouten, T.D. (graduation committee); Posthuma, Andrys (mentor); Serlé, Vincent (mentor); Delft University of Technology (degree granting institution)","2019","Deep-sea mining is becoming more popular. The Atlantis II Deep is a deep sea mining field of metalliferous muds in the Red Sea. This field could be exploited by transporting the sediments through a pipeline laid from shore onto the sea bed to the field. From determined concentrations with their shear stress-shear rate relation, parameters for the power law and Bingham plastic model were determined, relayed to test data, so that in the end the Bingham Plastic model was used to calculate pwoer consumption for a variety of cases.","slurry transport; Non-newtonian; bingham plastic; power law; flow assurance; limit deposit velocity; concepts; Deep-sea mining; power consumption","en","master thesis","","","","","","","","2021-08-23","","","","Offshore and Dredging Engineering","AtlantisII",""
"uuid:2d03dfef-dea6-465f-be8c-8833eba99675","http://resolver.tudelft.nl/uuid:2d03dfef-dea6-465f-be8c-8833eba99675","Laminate Blending Demonstrator: A buckling experimental campaign of a physical laminate blending demonstrator","Mohamed Gomaa Abdulfattah Tolba, Mohamed (TU Delft Aerospace Engineering)","van Campen, J.M.J.F. (mentor); Delft University of Technology (degree granting institution)","2019","The use of fiber-reinforced composites in the aerospace industry has increased over the past couple of decades thanks to their high specific properties. Fiber-reinforced composites also enable engineers to tailor the stacking sequence to satisfy the required stiffness or strength requirements. However, locally optimizing the stacking sequence of composite laminates introduces incompatibilities between the locally optimized sections which jeopardize the structural integrity of the panel. This highlights the importance of “laminate blending” which is a term given to problems that involve the local optimization of laminates while taking into account continuity guidelines to ensure manufacturability. In this work, a constant thickness blended demonstrator of 32 layers and 5x5 sections was designed, manufactured and tested for its stiffness and critical buckling load. The results were compared to a constant stiffness conventional laminate of the same geometry and weight. The critical buckling load of the blending demonstrator was 80.9% higher than that of its conventional counterpart and the stiffness was 93.75% higher.","Variable stiffness; Composites; Buckling; laminate blending","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:9c9dd269-f574-4bbf-b15e-e20da95fd125","http://resolver.tudelft.nl/uuid:9c9dd269-f574-4bbf-b15e-e20da95fd125","Wind energy acceptance: Linking perceived impacts and characteristics in Dutch wind energy projects","Mertens, bertus (TU Delft Technology, Policy and Management)","Pesch, Udo (mentor); Quist, Jaco (graduation committee); Delft University of Technology (degree granting institution)","2019","The number of wind energy projects in Europe has increased rapidly in the last decade and this growth is expected to continue. In the Netherlands there is a similar increase in the amount of wind energy projects. Wind energy projects, as large-scale infrastructural works and building projects, have numerous effects on the surrounding communities. The most prominent challenge in onshore wind energy realisation in the Netherlands was identified as a lack of acceptance by the local community and the potential for this lack of acceptance to result in resistance. This research focusses on acceptance of wind energy on a local level. However, acceptance can be a complex issue. There are multiple actors, technical characteristics, economic factors and institutional boundaries involved. To analyse this complexity, this research explores which impacts are perceived by local residents of a wind park; impacts as noise nuisance and shadow flicker. Literature suggests links between perceived impacts and the local context of a wind energy project. Local factors, like the height of the turbines, could influence local residents experience on for example noise nuisance. This research extends on these possible relations and aims to research how characteristics of a wind project and perceived impacts of local residents could relate. A case study of 18 Dutch wind energy projects was executed. For each project one or two interviews with a stakeholder were conducted on the perceived impacts of local residents. The data was combined with desk research on the characteristics of the wind parks. For each case study was further analysed how project characteristics and perceived impacts of residents could relate. Multiple possible relations were identified between characteristics and perceived impacts. Examples of these are turbine characteristics as distance to residents, height of turbines, the presence of other wind parks nearby and obstruction lighting. Additionally, regional characteristics as accumulation of existing regional impacts, regional property prices, regional stress and the if the wind park is located in a silent area were indicated as influential in some case studies. Institutional factors have been attributed to influence the process. These included the administrative division, decision making power and legal guidelines. Furthermore, measures to reduce or compensate impacts were also named as influential. These include the extent of financial participation and a standstill provision. Two general characteristics influencing wind energy acceptance in general were identified. These were if the wind park was located on an industrial site and if the wind park was a repowering project. In some cases, the characteristics could relate to other characteristics or perceived impacts relate to other perceived impacts. For example, interviewees stated the concerns for housing value decrease were directly related to concerns for shadow flicker, noise nuisance and visual impact. Even on a case level, multiple relations were mentioned and could have both negative as positive effects. On a broader level, a cross-case examination was done to discover the importance of the perceived impacts and what possible relations were frequent in Dutch wind energy project. While the exploratory research has its limitations, it discovered that acceptance is complex and depended on multiple factors. Relations as for example height turbines resulting in more visual impact that were mentioned in literature did not occur in every project. Some relations can be negative or positive depending on the project context. Furthermore, perceived impacts could be related to other perceived impacts and multiple characteristic might influence one perceived impact. This creates a complex web of interrelations where some relations appeared in the case studies but others are still unknown. This research show that further research is needed generate profitable knowledge on this complex topic. With the results of the thesis, a number of limited recommendations are done for local residents, policy makers and project executors. One of these recommendations is to implement a local approach to a case project and take the unique characteristics of the project into account. This includes integrating existing regional impacts to estimate which impacts could cause the most concerns. Additionally, consulting with local residents is an important step to fathom local wishes and preferences. Local residents might be willing to trade in time for extra benefits or need a technical implementation as a standstill provision. More insight in the perceived impacts of local residents can help in providing participation measures or structure the process.","wind energy; participation; local residents; acceptance","en","master thesis","","","","","","","","","","","","Industrial Ecology","",""
"uuid:b02ca317-8855-48b7-9e3f-7215ed63641f","http://resolver.tudelft.nl/uuid:b02ca317-8855-48b7-9e3f-7215ed63641f","Potential of polymer sewage heat exchangers with enhanced thermal properties","Avadhani, Maneesh (TU Delft Mechanical, Maritime and Materials Engineering)","Infante Ferreira, Carlos (mentor); Delft University of Technology (degree granting institution)","2019","Buildings contribute to 30% of global CO<sub>2</sub> emissions and consume 40% of the global energy supply (Yang et al., 2014). Heating and cooling requirements of the buildings form the major part of the energy consumption in buildings (Culha et al., 2015). Thus to solve this problem, one of the solutions currently being<br/>looked at is to recover heat from the sewage. Cities have large sewage flows and in the winter the sewage is warmer than ambient and in the summer it is colder than the ambient, thus making it a good heat source and sink respectively. This work involves the integration of waste water heat exchanger with heat pump<br/>to form a Waste Water Source Heat Pump (WWSHP). This system was further integrated with Aquifer Thermal Energy Storage (ATES) system. The WWSHP system was modeled in Matlab and the aquifer was modeled in COMSOL. COMSOL Live-link Matlab feature was used to integrate the two models. <br/>Polymers were chosen as heat exchanger material due to their low cost, low weight (lower CO<sub>2</sub> emissions during transportation), flexibility, non corrosive nature and low energy requirement in manufacturing (Hussain et al., 2017). Two systems were proposed to support the heating and cooling demands of the concert venue and convention centre of the Rotterdam, the ’Doelen’. The objective of this work was to illustrate the potential of polymer sewage heat exchangers. The first system was called the WWSHP system. In this system, heat was recovered from the sewage in the winter through polymer heat exchangers and was upgraded in a heat pump for use in the heating network of the ’Doelen’. The heat pump was a reversible one, thus, in the summer, heat was extracted from the cooling network of the ’Doelen’ and rejected to the sewage through the same polymer heat exchangers. To obtain more heat in the winter, a second system was proposed. This system was called WWSHP + ATES system. In this system, heat was extracted from the sewage and an aquifer. This extracted heat was upgraded in a heat pump for supply to the ’Doelen’. In the summer, the heat extracted from the ’Doelen’ along with the heat recovered from the sewage were used to refill the warm well of the aquifer to maintain thermal balance. The scope of the work also included optimizing the dimensions, material and cost of the waste water heat exchanger. In both the systems, the summer and the winter models were different, hence they were simulated separately. The heat recovery model was built based on a sewage channel near the ’Doelen’. The sewage channel data and the sewage flow and temperature data were provided by the Gemeente of Rotterdam. The waste wa-ter heat exchanger was chosen to be a multi row tube polymer heat exchanger. Various polymer options were available, among which the option with the highest thermal conductivity, High Density Poly-ethylene (HDPE) was chosen. Among six combinations of standard HDPE tube lengths and diameters, tube length of 30 m and tube inner diameter of 29 mm were found to be the most optimum in terms of economics and heat recovery. Based on the optimized tube dimensions, heat delivered by the system to the ’Doelen’ per unit cost was compared for different materials and the results confirmed that HDPE with a cost of 0.54 €/kg was the best choice. Thus, using the optimized combination of tube dimensions and HDPE as tube material, 374 MWh of heat was recovered from the sewage in the winter and 486 MWh of heat was supplied to the heating network of the ’Doelen’ through the heat pump. In the summer, 23 MWh was removed from the ’Doelen’ by the heat pump and 26 MWh was rejected to the sewage using the same HDPE heat exchangers. Among the different polymer and filler combinations, PE (Polyethylene) with 30% graphite filler was foundto be the best choice. Using PE with 30% graphite resulted in 32% higher heat recovery from the sewage in the winter and 15% higher heat rejection to the sewage in the summer when compared to HDPE with no fillers. Thermal enhancement of polymer tubes, although increased the amount of heat exchanged with the sewage in the winter and the summer, it reduced the system economic performance (kWh/€) in the winter. <br/><br/>The WWSHP + ATES system supplied 1244 MWh of heat to the ’Doelen’ in the winter and removed 388 MWh of heat from the ’Doelen’ in summer. Furthermore, thermal enhancement of polymers of the waste water heat exchangers reduced the performance (kWh/€) of the WWSHP+ATES system in both the summer and the winter. WWSHP + ATES system proved to be capable of handling higher heating and cooling demand than the WWSHP system. The costs of heat exchangers and electricity were also much higher for this option, thus making it less economical. For instance, the WWSHP model supplied 66 kWh to the ’Doelen’ per € spent, as opposed to the WWSHP + ATES system which supplied only 34 kWh/€. Thus, only high heating and cooling requirements would justify the use of WWSHP + ATES system.","Polymers; Waste heat recovery; ATES; Sewage; Heat exchanger; Waste water source heat pump; Heat pump","en","master thesis","","","","","","","","","","","","Mechanical Engineering","",""
"uuid:d771f451-c9db-430f-8dcb-6ab31c58ffa7","http://resolver.tudelft.nl/uuid:d771f451-c9db-430f-8dcb-6ab31c58ffa7","Cycle experiments on the cryptographic permutation Xoodoo","Calamur Viravalli, Gouri (TU Delft Electrical Engineering, Mathematics and Computer Science)","Picek, Stjepan (mentor); Daemen, Joan (graduation committee); Delft University of Technology (degree granting institution)","2019","Cryptography is the science of concealing messages, and it provides data security and privacy. A cipher is designed to be as secure as possible, to not be easily broken with the current availability of computational power in a reasonable amount of time. Various attacks have been discovered over time, and recently, the invariant subspace attack was presented on the PRINTcipher. This is a statistical saturation attack which makes use of the weak keys of the cipher.<br/><br/>This report delves into the cryptographic permutation known as Xoodoo, and explores the possibilities of its vulnerability towards the invariant subspace attack. For this, we investigate the cycle structure of the permutation by performing cycling experiments on its round function. We implement the naive Xoodoo round function after stripping off its round constants, and take advantage of the symmetry properties of the Xoodoo state to understand how the symmetry classes behave. The identification and description of symmetry classes of Xoodoo states based on the concept of lattices help us observe some of the symmetry classes that are small enough and can fully determine their entire cycle structure. With an exception for one anomaly case, there were no observed deviations from the behaviour of Xoodoo in comparison to the behaviour of a random permutation, and the cycles were found to have no particular structure. We thus conclude that it is highly unlikely that Xoodoo is vulnerable to invariant subspace attacks. Many factors about the algebraic background of the cipher were taken into consideration for the implementation. The parity of the cycle count, the behaviour of the cipher with different symmetry classes with a given state size, the interaction between bits in the intermediate states of the cycles, and the factors that influenced the number of cycles were all analysed. The concept of symmetry is rigorously described. We establish that the number of cycles increases as the length of the input permutation decreases. The outcomes of the experiments are compared with the theory behind the implementation and anomalies are explained.","cryptography; Xoodoo; cycle experiments; permutation","en","master thesis","","","","","","","","","","","","","",""
"uuid:b2ccf849-e6f7-452a-a2d5-9ff63f85efe7","http://resolver.tudelft.nl/uuid:b2ccf849-e6f7-452a-a2d5-9ff63f85efe7","Towards Understanding of Deep Learning in Profiled Side-Channel Analysis: Similarity of predictors measured and explained","van der Valk, Daan (TU Delft Electrical Engineering, Mathematics and Computer Science)","Picek, Stjepan (mentor); Hartel, Pieter (graduation committee); Urbano, Julián (graduation committee); Batina, Lejla (graduation committee); Delft University of Technology (degree granting institution)","2019","Side-channel attacks (SCA) aim to extract a secret cryptographic key from a device, based on unintended leakage. Profiled attacks are the most powerful SCAs, as they assume the attacker has a perfect copy of the target device under his control. In recent years, machine learning (ML) and deep learning (DL) techniques have became popular as profiling tools in SCA. Still, there are many settings for which their performance is far from expected. In such occasions, it is very important to understand the difficulty of the problem and the behavior of the learning algorithm. To that end, one needs to investigate not only the performance of machine learning but also to provide insights into its explainability.<br/><br/>In this work, we look at various ways to explain the behaviour of ML and DL techniques. We study the bias-variance decomposition, where the predictive error in various scenarios is split in bias, variance and noise. While the results shed some light on the underlying difficulty of the problem, existing decompositions are not tuned for SCA. We propose the Guessing Entropy (GE) bias-variance decomposition, incorporating the domain-specific GE metric in a tool to analyse attack characteristics. Additionally, we show the relation between the mean squared error and guessing entropy. Our experiments show this decomposition is a useful tool in trade-offs such as model complexity.<br/><br/>To dive deeper into the inner representations of neural networks (NNs), we use Singular Vector Canonical Correlation Analysis (SVCCA) to compare models used in SCA. We find that different datasets, or even leakage models, are represented very differently by neural networks. We apply SVCCA to a recent portability study, which shows one should be careful to overtrain their networks with too much data.<br/><br/>Finally, do we even need complicated neural networks to conduct an efficient attack? We demonstrate that a small network can perform much better by mimicking the outputs of a large network, compared to learning from the original dataset.<br","Deep learning; Side-Channel Attacks; Classification; Explainable Machine Learning; Machine Learning; Neural Network; Convolutional Neural Network","en","master thesis","","","","","","","","","","","","","",""
"uuid:971a5690-23ec-47a1-9172-183a90b76176","http://resolver.tudelft.nl/uuid:971a5690-23ec-47a1-9172-183a90b76176","IPS as a tool for designing to improve the care for people with dementia: designing a new system for nursing home","Gong, Haotian (TU Delft Industrial Design Engineering)","Kortuem, Gerd (mentor); Wang, Gubing (graduation committee); Delft University of Technology (degree granting institution)","2019","This project aims to improving the care service for people with dementia who exhibits BPSD (Behavioral and Psychological Symptoms of Dementia) by providing the relevant stakeholders data insights, and meanwhile improving these people’s working efficiency.","Indoor positioning system; people with dementia; nursing home; care service; service design","en","master thesis","","","","","","","","","","","","","",""
"uuid:6c2100e9-2528-4e75-9655-2e1d9249953c","http://resolver.tudelft.nl/uuid:6c2100e9-2528-4e75-9655-2e1d9249953c","A Multi-Criteria Analysis on Digitizing Services in the Port of Rotterdam","Janssen, Donald (TU Delft Technology, Policy and Management)","Annema, Jan Anne (mentor); de Bruijne, Mark (graduation committee); van Wee, Bert (graduation committee); van Wulfften Palthe, Linde (graduation committee); Delft University of Technology (degree granting institution)","2019","The purpose of this master thesis was to explore in which way the service of Vopak Agencies could be digitized and be accepted by the client the most.","TAM; Technology Acceptance Model; BWM; Best Worst Method; User acceptance; MCA; Multi Criteria Analysis; Port sector; Maritime Industry","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:8a2af54b-2e80-47b2-b917-b41d53470c58","http://resolver.tudelft.nl/uuid:8a2af54b-2e80-47b2-b917-b41d53470c58","Noninvasive Hemodynamic Monitoring: Left Ventricular Pressure-Volume Loop Reconstruction","Reddington, Aoibhinn (TU Delft Mechanical, Maritime and Materials Engineering)","Dekker, Ronald (mentor); Dankelman, Jenny (graduation committee); Pertijs, Michiel (graduation committee); Delft University of Technology (degree granting institution)","2019","Heart disease - already a leading cause of death in industrialized societies - is becoming more and more prevalent as society ages. With this increase, improvements in diagnosis and monitoring of heart disease are necessary. Current state-of-theart cardiac assessment techniques are invasive and too strenuous for heart disease patients. Therefore, there is a need for a noninvasive, fast, and mobile cardiac evaluation method. We propose the use of personalized lumped parameter models to simulate the circulatory system, so that left ventricular pressure can be estimated from left ventricular volume as acquired with 3D ultrasound imaging. Subsequently, the estimated pressure and the imaged left ventricular volume can be used to reconstruct pressure-volume loops, which are significantly indicative of cardiac health. As ultrasound is fast, not strenuous, and can be applied from the bedside, this method is suitable for critical care patients.","","en","master thesis","","","","","","","","","","","","","",""
"uuid:3dec3876-36dc-40b4-99d3-c239072209fa","http://resolver.tudelft.nl/uuid:3dec3876-36dc-40b4-99d3-c239072209fa","Stability of randomly placed log bed protections","van den Berg, Mario (TU Delft Civil Engineering and Geosciences)","Uijttewaal, Wim (mentor); Hofland, Bas (graduation committee); Bricker, Jeremy (graduation committee); Buschman, Frans (mentor); Sieben, Arjan (graduation committee); Delft University of Technology (degree granting institution)","2019","Design criteria for the stability of rock filters on river beds (i.e. rock bed protection) are extensively researched and successfully applied in practice. The most common stability criteria are the Izbash and Shields criteria. These methods define a critical flow (Izbash) or parameter (Shields). Rijkswaterstaat (RWS) wants to explore a more sustainable bed protection by using logs. A pilot project is started where logs will be used as bed protection. It is yet unclear if the design and construction approaches for rock bed protections can be used for log bed protections. The most dominant aspect is that logs are cylindrical objects, while rocks are spherical. This means that the design criteria for rock filters might not be directly applicable to log filters. This research aims to verify if the Izbash and Shields criteria for rock can be used for logs to create functional and safe designs. To achieve this, two experiments are performed at the TU Delft faculty of Civil Engineering &amp; Geosciences. The first experiment, done in a water filled tank, explores the settling behaviour of logs for multiple drop methods. Insight is gained in the settling velocities, horizontal spread and magnus effect (force exerted on a rotating object, e.g. the curve of a football spinning through the air) of logs settling in a water column. Results from these experiments are used in the second experiment. This experiment is done in a 14.3m long flow flume where a log filter is constructed. The log filter is constructed using the drop method that was preferred from the first experiment. The roughness, stability and porous flow of a log filter are investigated. The results are compared with what is known for rock filters. Tree branches were used as model logs. This was done to be able to correctly scale the results to prototype scale. Primary reason for this was the effect of bark on the roughness of a cylinder. This is difficult to replicate on model scale. Using branches of trees that will be used Saturating the model logs however was more time consuming than initially expected. Attempts were made to accelerate the process but they were futile. One method, using a diaphragm vacuum pump, could not be applied due to lack of resources. For any future research on the topic of tree branches as model logs it is highly recommended to use a vacuum pump to ensure that the maximum density is reached. From the first experiment it was concluded that large quantities of logs can still be used to create functional log filters. This is a positive result as this will reduce construction time on prototype scale. The method used was a funnel. This method was applied in the flume to create the log filters. By measuring the velocity profile for multiple discharges the roughness of a log filter was measured. This also resulted in an equation of the shear velocity as a function of the discharge. By increasing the discharge step by step, several mobility stages of a log filter were found. This resulted in a dataset that could be directly compared with the Izbash and Shields equations for rock. Higher critical Shields parameters were observed than for rock of the same diameter. The behaviour of a log filter differed from a rock filter in the transition from one stage to another (stable to mobile to transport to failure) did not occur slowly, but almost instantaneous. This behaviour is unwanted because it is difficult to monitor in what stage a log filter is if no changes can be observed between stages. Thus, although applying the equations for rock filters to log filters are conservative, the behaviour of log filters are more sudden and prone to escalation close to their critical thresholds. Final conclusion is that more research is required to better understand the significance of variables for the settling behaviour and stability. These are water depth, log diameter independent of density and vice versa, log orientation and log length to diameter ratio. This can be done by doing more experiments in a similar fashion where only one variable is changed at a time. For the application of the design criteria for rock to a log filter with regards to the pilot project, it is recommended to be conservative. Based on these experiments it is safe to assume that when the most unfavourable scenario is used (e.g. low log density, small log diameter, high flow velocities near the bed) a sufficient design is made, especially if the top layer(s) of the filter are placed parallel to the flow direction. Backfilling of the log filter did not increase the stability significantly in this research and is only be beneficial for scour protection.","Log; bed; protection; stability","en","master thesis","","","","","","","","2019-08-29","","","","","",""
"uuid:a070d733-d9bb-405a-ae1d-3d4a0936159d","http://resolver.tudelft.nl/uuid:a070d733-d9bb-405a-ae1d-3d4a0936159d","Sulfur stream identification and selective removal of heavy metals from ironmaking blast furnace dust: Improved leaching of metal sulfides using oxidants and microwave treatment","Kempke, Alex (TU Delft Civil Engineering and Geosciences)","Yang, Yongxiang (mentor); Buxton, Mike (graduation committee); Voncken, Jack (graduation committee); Xiao, Yanping (graduation committee); Delft University of Technology (degree granting institution)","2019","The main waste products of ironmaking at Tata Steel IJmuiden are CO2¬(g) and a solid waste stream consisting of mainly carbon and iron-bearing compounds. This solid waste is generally called Zn rich filter cake which contains too much Zn to be reintroduced into the iron making process. Besides Zn, Pb and Cd are also present. These filter cakes originate from the flue dusts that are expelled from the top of the blast furnace. Currently the solid waste is separated based on size distribution which allows the recycling of most of the materials and concentrates the heavy metals into the Zn rich filter cake. Previous research has shown that these cakes are resistant to regular leaching methods for selectively dissolving the contained heavy metals. This is due to their sulfide form. The methods that do work (such as acid leaching) also dissolve additional material such as iron, which is the main component of the waste stream. Therefore Tata Steel Europe is investigating whether alternative options are available to selectively extract these heavy metals and reintroduce the remaining material as secondary ore back to ironmaking.<br/><br/>In this research the option of adding oxidants with and without additional microwave treatment is investigated. Based on what is applicable in reality, literature and thermodynamic evaluations several oxidants were selected to oxidize the metal-sulfides to metal-oxides which can be readily leached in ammonia based media. Furthermore the material was characterized and an investigation was done on where the sulfur originates and whether this stream can be reduced or avoided. The quality of the results was verified by comparing the heavy metals dissolved into the leaching solution by ICP analysis and by determining the heavy metal content in the solid material before and after leaching with XRF. It was found that 98% of the sulfur originates from the blast furnace and only 2% from the addition of sodium sulfide at the water cleaning department. <br/><br/>Leaching experiments were done with a 40 °C leaching solution, a 5:1 liquid to solid ratio. Leaching solutions were all ammonia based due to its selectivity to heavy metals. Leaching the sample material without microwaving or addition of oxidants the highest Zn, Pb and Cd recovery was 54%, 0.5% and 24% respectively. Potassium permanganate as the oxidant resulted in the highest extraction of Zn at 67% in a 2M ammoniumsulfate, 9M ammonia leaching solution. Ferric chloride in a 2M ammoniumsulfate, 9M ammonia leach solution reached extractions of Zn and Cd at 64% and 45% respectively for the IJmuiden filter cake. For Pb the best extraction was 5% in a 2M ammoniumcarbonate, 9M ammonia leach solution with the same oxidants. Microwaving the sample during leaching resulted in a higher extraction for both Pb and Cd, whilst matching the non-microwave oxidant leaching extraction for Zn. The highest extractions were 61%, 42%, 83% for Zn, Pb and Cd respectively. Aging has also been proven to have an detrimental effect on the extraction of heavy metals, however the aging effect is negated when using microwave treatment or oxidants. Extractions for lab reactor leaching of fresh samples without added oxidants or microwaving with an ammonia sulfate solution, resulted in extractions of 62%, 0%, 40% for Zn, Pb and Cd respectively. <br/><br/>It has been verified that most of the sulfur comes from the blast furnace. Further it has been reaffirmed that the metal sulfides this sulfur forms are difficult to leach out. One study states that metal sulfides can and will form in the blast furnace. The current study supports that, even though no direct study of the blast furnace itself was done. Oxidants and microwave assisted leaching seem to work well for Pb and Cd, but are less effective on extracting a higher percentage of Zn. It is recommended to use this method in combination with another process, a different ironmaking process such as HIsarna would be preferable due to the reduction of ZnS to ZnO which is readily leached with an ammonia leaching solution.<br","Heavy metals; blast furnace dust; sulfur; metal sulfide leaching; leaching; stream identification","en","master thesis","","","","","","","","","","","","","",""
"uuid:3fa73fcf-044b-4f4c-b425-1e3d76acd31a","http://resolver.tudelft.nl/uuid:3fa73fcf-044b-4f4c-b425-1e3d76acd31a","Calibration of a Single element ultrasound transducer using an aberration mask","Visser, Bram (TU Delft Electrical Engineering, Mathematics and Computer Science)","Leus, Geert (mentor); Kruizinga, Pieter (graduation committee); van der Meulen, Pim (graduation committee); Delft University of Technology (degree granting institution)","2019","Previous work [1] has demonstrated the possibility of high resolution imaging through the use of a single element and a aberration mask. This thesis will expand on the previous work by examining the proposed method for errors in the creation of the model. The analysis is preformed by examining the various aspects of the measurements setup and underlying theoretical model, after which measurements are performed to determine their contribution and correctness with regard to the model. Results demonstrated a systematic error of a non-linear frequency scaling and semi-linear phase shift. The origin of the error lies in the unwanted addition of transfer functions of some of the components. A Tikhonov regularized least squares method is proposed to estimate this transfer function and supply compensation based on all the measurements. The results of application of this method on the uncalibrated model are demonstrated through 1D imaging experiments. The result of which show a signicant improvement over the previous uncalibrated results. After which the possibility of calibration due to a singular measurement is explored and a adaptation of the Tikhonov regularized least squares method is proposed for close approximation of the previously found transfer function. Further to obtain an indication of possible remaining hurdles and successes with this method, extensive simulations are preformed to examine the individual impact of various sources of noise and interference.","Calibration; Ultrasound; Single element imaging","en","master thesis","","","","","","","","","","","","","",""
"uuid:bdfb4f06-adcd-4a7c-bf63-035f92f72efb","http://resolver.tudelft.nl/uuid:bdfb4f06-adcd-4a7c-bf63-035f92f72efb","From log files to train traffic reports : Using Natural Language Generation to explain anomalies from Train Control System log files","Urumovska, Bojana (TU Delft Electrical Engineering, Mathematics and Computer Science)","Tintarev, Nava (mentor); Houben, Geert-Jan (graduation committee); Spaan, Matthijs (graduation committee); Delft University of Technology (degree granting institution)","2019","The Natural Language Generation field has advanced in generating human readable reports for domain experts in various fields. Nevertheless, Natural Language Generation and anomaly detection techniques have not been used in the rail domain yet. Currently, data analysis and incident reporting for log files from the train control system are performed manually which is very time consuming task that is prone to missing crucial information. The rail domain is safety critical domain where detailed analysis of the train control system may prevent incidents from happening as well as help improve the performance of the train control system. This research designs, implements and evaluates a Natural Language Generation model that successfully translates anomalies detected in log files into human readable reports.<br/>This thesis presents the steps taken for developing a Natural Language Generation system in the rail domain. Additionally, we examine two representations of the train control system used for the Content Determination task of the Natural Language Generation system. Through a case study with domain experts, we evaluate the performance and preference between the reports generated based on the two representations of the train control system and the data retrieved from the log files. The goal is to find a representation that presents the used with a full/solid understanding of the anomalies detected in the log files.<br/>Based on the case study performed to evaluate the system, we present the finding that when developing a Natural Language Generation system for the rail domain, reports generated using a more detailed representation of the train control system (more precisely, using both state names and state attributes that specify the step by step process of setting a route for a train) were preferred over the reports generated using a less detailed representation (only state names). The preference was based on readability, accuracy and understandability measures of the reports presented during the case study.","Natural Language Generation; Anomaly Detection; Log Files; Rail Domain","en","master thesis","","","","","","","","","","","","","",""
"uuid:c749ec01-782c-4581-9e61-202156325563","http://resolver.tudelft.nl/uuid:c749ec01-782c-4581-9e61-202156325563","Circular Economy within Integrated Contracts: A Delphi study into the contractor’s perspective on how circularity is and should be embedded in official tender documents of infrastructural projects","Partoredjo, Elvira (TU Delft Civil Engineering and Geosciences)","Schraven, Daan (mentor); Kooijman, Joyce (mentor); Chao-Duivis, Monica (graduation committee); de Jong, Nynke (mentor); Delft University of Technology (degree granting institution)","2019","Circular Economy (CE) is proposed as an solution to the problems the world is facing concerning global warming and resource scarcity. The construction industry however struggles with the new concept of CE. Practitioners lack knowledge, experience and examples. Therefore, embedding circularity in the contract may work as a stimulation. The purpose of this research is to determine a list of requirements on how the client can embed circularity in official documents of infrastructural commissions in an integrated contract in such a way that the contractor can understand, relate and implement the concept in the commission. The results of the research should answer the main research question: What requirements, according to the contractor, do clients of infrastructural projects have to uphold in embedding circularity in the official documents of their commission to stimulate the contractor in implementing circularity in the project? The intention of this research is to form consensus amongst contractors concerning which re¬quirements are necessary for the client to uphold and include in the contract in order to stimulate the contractor in implementing circularity in the project to its fullest potential. To reach consensus, the Delphi-method is applied, which consists of three rounds in this research. The first round is the scoping round in which semi-structured interviews were held with contrac¬tors and clients. From the first round, six themes in which participants encounter struggles with CE were identi¬fied. The second round was a questionnaire in which contractors are asked to judge statements, which were drafted based on six themes from round one. General statements were used as a validation for the six themes identified, example statements were used to determine how currently embedded circularity is perceived by contractors and which improvements have to be made. Moreover, contractors were asked to pro¬vide arguments that support their judgement. Statements on which no consensus have been reached were questioned again in round three. Along with the statements, the arguments given by contractors in round two were provided as well. These arguments enabled respondents to revise their judgement, which is necessary to reach consensus on more statements. The Delphi-method ended with round 3. From the 29 statements, 23 have reached consensus after the third round of the Delphi method; 6 statements did not reach consensus. From the arguments given, combined with the results of the questionnaire, it became clear that in general, clients need to adhere more to the tender-requirements stated by the European law. Concerning the answer to the main research question it becomes evident that clients need to be clear about the by them used definition of the concept of CE. Moreover, direction and scope is appreciated. Award criterion are better for stimulation and a more objective measuring method is necessary. Collaboration is necessary for finding the best solution possible.","circular economy; integrated contracts; Delphi Study","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:bb6621df-325c-499c-b77f-27c56d69dc6a","http://resolver.tudelft.nl/uuid:bb6621df-325c-499c-b77f-27c56d69dc6a","Mechanically Storing Renewable Energy at a Residential Scale","Lorist, Stefan (TU Delft Industrial Design Engineering)","Flipsen, Bas (mentor); Thomassen, Erik (mentor); Delft University of Technology (degree granting institution)","2019","Today, more and more households are generating their own solar power. This helps us to come closer to a circular economy, since less fossil fuels are required to meet our energy needs. However, excessively generated energy is often wasted, since transporting or storing it for later use is challenging. Lithium ion batteries provide a solution, however their short lifespan and environmental problems that are caused during production make them far from green.<br/>A mechanical storage system was proposed, minimizing the environmental problems of Li-ion while providing the household with a storage solution for excessively generated solar energy. After exploring multiple energy storage methods and analyzing their potential suitability to residential energy supply &amp; demand, Flywheel Energy Storage was chosen as the applied storage technology due to its high energy density and mainly mechanical components.<br/>ScriptEssential calculations were extended into a full simulation script, used to analyze different scenarios of use. It is capable of the following:• Confirming chosen rotor dimensions• Determining required rotational speed• Characterization of rotor losses &amp; spin-down times • Characterization of torque losses• Reading supply/demand data from external source • Visualizing 24h supply/demand/storage profilePrototypeThe script was partially validated using a functional model and performing tests concerning spin-down times with two different rotors and vacuum levels.LEFtAs a final deliverable, a full mechanical storage system was designed. LEFt, which stands for Leftover Energy Flywheel technology, is a mechanical battery that stores an excess of residential solar power in the form of kinetic energy by spinning a flywheel in a vacuum. It comes in three main form factors; Flat, Slender and Extra Slender. These types all suit different scenarios and therefore different households. LEFt was designed using a subsystem approach to cope with all co-dependent aspects of the system.The most essential part, the flywheel rotor, was dimensioned according to the script.RotorDifferent versions of LEFt include differently dimensioned rotors. A large height over radius ratio makes LEFt suitable for short term storage. It can be applied to store electricity that is generated during the afternoon for evening use.Changing the application and storage limit result in different configurations and dimensions. A rotor with a small height over radius ratio can be suitable for longer term storage. A setup with a certain supply &amp; demand makes this type potentially capable of 24h storage and might allow off-the-grid living in the future.SuspensionThe flywheel rotor is suspended nearly frictionless in the vacuum, by levitating it using a magnetic bearing system.The main vertical thrust is supplied by a Halbach Array of passive magnets, whereas radial displacement is corrected by two Active Magnetic Bearings that are handled by an advanced control system.Motor/GeneratorDriving the rotor and regenerating electricity is done by one machine; an electric motor that is positioned outside the vacuum. Using a single phase motor allows easy installation without the need for a transformer.Magnetic couplerTo drive the rotor from outside the vacuum, a magnetic coupler was designed, making use of two discs with a pattern of passive magnets. A control system allows smart coupling and decoupling, resulting in a freely spinning rotor in idle situations.Vacuum housingEnclosing the flywheel rotor is done by a depressurized housing.This has proven to reduce resistances, increasing storage times and therefore the applicability to longer term storage.Market implementationSelling LEFt is done best by a lease plan, in collaboration with solar panel suppliers. The full retail price of over €10,000 will be too high for a one-time investment.Sustainability assessmentThe environmental impact of the design is done by comparing it to a competing lithium ion battery. The results of an Eco Audit show that the impact of LEFt is lower, but still significant because of the large amounts of steel that are needed. ConclusionA conceptual design for a flywheel energy storage system was proposed and partially validated. It was concluded to be a better alternative for lithium ion batteries in residential energy storage, since it minimizes social and environmental problems. Further development and extensive analysis is required to fully validate and make the design ready for production.","Sustainability; Energy Storage; energy storage system; flywheel; residential; solar power; off-grid; mechanical storage; household energy","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:1719296b-45a8-4a45-9b4a-1116bd3e4305","http://resolver.tudelft.nl/uuid:1719296b-45a8-4a45-9b4a-1116bd3e4305","A WeChat-based e-commerce solution to sell Dutch brands in China","Fang, Yihui (TU Delft Industrial Design Engineering)","Bakker-Wu, Sijia (graduation committee); Kranzbühler, Anne (mentor); Delft University of Technology (degree granting institution)","2019","Oversea shopping is becoming increasingly popular among Chinese consumers. Nextport- China is a China-focused digital marketing agency in Amsterdam. The company is help- ing some Dutch brands to market in China. It wants to explore the possibility of selling Dutch products to Chinese consumers online.","","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:654f6d75-1f64-4c62-b487-cbb5ae3d65dc","http://resolver.tudelft.nl/uuid:654f6d75-1f64-4c62-b487-cbb5ae3d65dc","Modeling and Control of a Solid State Transformer and verification with Controller Hardware in the Loop","Yadav, Sachin (TU Delft Electrical Engineering, Mathematics and Computer Science)","Qin, Zian (mentor); Bauer, Pavol (mentor); Smets, Arno (graduation committee); Sun, Yin (graduation committee); Delft University of Technology (degree granting institution)","2019","Climate change is driving the evolving energy mix in the world. The amount of renewables are rising to avoid the detrimental effects of fossil fuels to the environment. Solar and wind power are the major players in the rising renewable energy mix. Most of these power generation sources are interfaced through power electronic converters. In the future, it is foreseen that the amount of renewables in the distribution shall increase. The power system is designed to handle the unidirectional flow of power. However, with the increased renewables, the power flow becomes bidirectional. This leads to stability issues in the power system. Solid State Transformers (SST) are envisaged to mitigate these issues by providing advanced functionalities like reactive power support, DC power generators and storage integration among others.<br/><br/>FLEXstation project is a Dutch government subsidized project which deals with building an SST. The SST shall be installed the distribution grid. In this thesis, the model and control algorithm for the transformer are discussed. Also, a controller hardware in the loop setup is made using two renowned makes of real time simulators namely OPAL-RT and dSpace. The setup between the two controllers is also discussed in detail.<br/><br/>The topology of the SST is made using a multilevel Cascaded H-Bridge (CHB) converter as the grid interface and Dual Active Bridge (DAB) converters as high frequency links between the MV and LV side converters. The balancing of the capacitor voltage of the multilevel converter is discussed. It is shown that due to the difference in the properties of DAB high frequency transformer, the capacitor voltages do not get perfectly balanced through the conventional method used in the literature. The issue is solved using DABs for balancing the capacitor voltages. The capability of the DABs are further utilized to decouple the active power flowing through the capacitors. The method can be used to significantly reduce the capacitor sizes thus reducing the cost and size of the converter.","Solid State Transformer; Modeling; Control; Real Time Digital Simulator; OPAL-RT; dSPACE; Control Hardware in Loop","en","master thesis","","","","","","","","","","","","","",""
"uuid:5e7977f3-9cbe-4c14-85e9-395d8eeddad3","http://resolver.tudelft.nl/uuid:5e7977f3-9cbe-4c14-85e9-395d8eeddad3","Exploring interactive media for indoor large-capacity tourist attraction: Sound of the Netherlands","Li, Xiaomin (TU Delft Industrial Design Engineering)","Vermeeren, Arnold (mentor); van Egmond, Rene (graduation committee); Wang, Da (graduation committee); Delft University of Technology (degree granting institution)","2019","This graduation project focuses on leveraging interactive media and designs for a future large capacity indoor attraction, namely “sound of the Netherlands”. Since the project starts from scratch, project assumption is needed in the beginning to facilitate the follow-on study and design. Desk research was used to define the scope and formulate project assumptions, which are the stepping-stone for the following phases.<br/>Moreover, the research about the interactive media and representative sounds of the Netherlands were conducted to spot the relevant media and content that can be used in the design.<br/>In the second step, user research was conducted to define and better understand the target group. The result revealed their primary motivation, expectation, and concerns toward large capacity cultural tourist Attraction. Building upon this, the design goal was formulated:<br/>Design an interactive Creative Cultural Attraction (400-450 p/h) with a novel experience and intuitive interaction around the topic “Sound of the Netherlands, which allows people to feel free to enjoy with others and know about the lifestyle of the Netherlands.<br/>To address the design goal, the designer viewed current large-capacity tourist attraction. Moreover, the literature research on how to adopt intuitive interaction design for a variety of users was conducted to find possible design solutions.<br/>The fourth stage was the design phase. The design started with building a holistic story and context for the Attraction. JORA VISION suggests to kick off the attraction design from developing the storyline. Two brainstorming sessions were conducted to develop the storyline. There is no precise number about the size and scale of the Attraction given in the design brief. So the designer developed a space model based on the design requirements and visitors' needs. After the space model was built, the detailed interaction design is developed along with the design guideline.<br/>Finally, an evaluation test was conducted to validate whether the design concepts fulfill the design goal and reach interaction quality. The designer used the Walkthrough 3D video and VR model in the cardboard for participants to understand the context and experience the space. The interaction storyboard (animation with sound) and interactive prototypes were used to test interaction. The designer combined 7-point Likert Scale and interviews to gain the feedback and insights of participants. The results of the test were used as a foundation for future recommendations for the company.<br/>Overall, it's an explorative project. The designer did extensive explorations in both problem space and solution space. During the process, the problem and solution also co-envolved.","Interactive Media; Attraction Design; Interaction; Experience","en","master thesis","","","","","","","","","","","","","",""
"uuid:25c46cbf-2e13-4791-be21-c5e23101986e","http://resolver.tudelft.nl/uuid:25c46cbf-2e13-4791-be21-c5e23101986e","The influence of mechanical contrast on industrial and natural hydraulic fracturing","van Oosterhout, Paul (TU Delft Civil Engineering and Geosciences; TU Delft Petroleum Engineering)","Barnhoorn, Auke (mentor); Buxton, Mike (graduation committee); Dieudonné, Anne-Catherine (graduation committee); Schmitz, Robrecht (graduation committee); Delft University of Technology (degree granting institution)","2019","The heterogeneity of layered systems leads to variation in rock or soil mechanical properties, influencing the resistance to failure. A formation breaks by fracture propagation when the effective stress surpasses the formation strength. The propagation of a fracture through a mechanical interface depends on whether the formation strength of the second formation is overcome. This critical effective stress level could be trespassed by high natural or industrial induced pore pressures. Understanding fracture propagation in multi-layered systems with variable pore pressure regimes has important implications and applications to many industries such as quarrying and hydraulic stimulation. The slope stability of Westerwald Clay Quarries is influenced by inter-bedding of thin sand layers. Surface and slope fractures within the clay formation originated from a high observed hydrostatic head within the sand layers and a reduced confining stress from mining activities. The slopes of the quarry are key in determining the volume of economically mineable clay, these slopes are in turn controlled by the size/extent of fractures and whether they extend through multiple formations. This study examines the effect of fracture continuation from sand layers into the stiff Westerwald Clay Formation. The soil parameters (cohesion and friction angle) of the different lithologies within a Westerwald Clay Quarry are determined for slope stability analysis by shearbox testing. Soil classification has been done in terms of plasticity, grain size and mineralogy by Atterberg Limits, Sieving and XRD &amp; XRF respectively. The results show that fracture initiation within the Westerwald quarries is a combination of mining activities lowering the confining stress and a constant natural hydraulic head. The hydraulic head within the small sand formation lowers slope stability by causing fracture initiation and water infiltration into the clay formation. Slope stabilisation occurs by artificial water pumping or natural water dissipation lowering the hydraulic head. Slope stability is decreased by embankments of low permeability backfill and increased by high permeability backfill. Inter-bedded systems are common target locations for an unconventional reservoir systems and can be found both within source rocks as well as in conventional geological traps. Improvement in recovery from these tight systems often depends on the extent and continuity of fractures through heterogeneous interfaces. This study examines the propagation and continuity of the fractures in an artificial heterogeneous layered system. The fractures will be initiated by hydraulic fracturing in a dried layered system via water injection in a triaxial cell. Fracture propagation is analysed through Micro-CT scans. The mechanical properties such as acoustic wave velocities, unconfined &amp; confined compressive strength and tensile strength are all determined for the analysed layered systems. The results show that hydraulic fractures initiated within the weakest layer are arrested at the interface between a mechanically weak and strong formation, whereas fractures initiated within mechanically stronger layers prograde through the interface. Hydraulic fractures are initiated when local pressure difference at the interface exceeds the formation’s critical tensile stress, the formations critical tensile strength is dependent on the confining pressure.","Hydraulic fractures; stress; Water injection; Mining; Petroleum Engineering; inter bedding; mechanical contrast","en","master thesis","","","","","","","","2024-08-22","","","","","",""
"uuid:a79269df-2c78-4f68-83f0-e5d661dc1110","http://resolver.tudelft.nl/uuid:a79269df-2c78-4f68-83f0-e5d661dc1110","A study of Jacobian-free Newton Krylov methods and Schur complement parameters for solving coupled systems","Brulleman, Floris (TU Delft Applied Sciences; TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Reactor Instituut Delft)","Lathouwers, Danny (mentor); Vuik, Kees (graduation committee); Perko, Zoltan (graduation committee); Heemink, Arnold (graduation committee); Tiberga, Marco (graduation committee); Delft University of Technology (degree granting institution)","2019","Numerical models are paramount in describing the complex physical world around us. They are often based on non-linear functions, which have to be solved in order to run a simulation. The first goal of this thesis is to compare the Jacobian-free Newton-Krylov method against the regular Newton-Raphson method for solving non-linear equations. When doing this, preconditioning was only used for the Newton-Raphson method. As a second goal, the optimal parameters for solving a coupled system with the Schur complement method are determined. For computational purposes, these analyses are performed using PETSc. The comparison between JFNK and Newton-Raphson were performed by solving a heat equation. The physical system which was analyzed is a one-dimensional radiating rod, with a heterogeneous thermal conductivity and Dirichlet boundary conditions. Firstly this rod was modelled as one single system. For this case, it was found that Newton-Raphson outperformed the JFNK method by a factor of 5-1700, depending on the type of preconditioning used. Secondly, the rod was modelled as a coupled system by solving two parts of the rod separately. In this case, it was found that the JFNK method outperformed the preconditioned Newton-Raphson method by a factor of 9.1± 0.3. It was concluded that the JFNK is only favorable over regular Newton-Raphson for coupled systems. To achieve the second goal, an incompressible Navier-Stokes coupled system was solved using the Schur complement method. The coupled system originated from incompressible flow in a back-step pipe, using a finite element method. For the Schur complement parameters, it was shown that using an approximation of the Schur complement offered a significant increase in efficiency. The momentum and pressure subsystems were analyzed separately. The momentum subsystem performed best with a relative tolerance of τ<sub>r </sub>=10<sup>-4.5</sup>, while the pressure subsystem performed best with a tolerance of 10<sup>-2</sup>. With these parameters, the Schur complement method had the same computational time as the pressure-correction method, which was used as a benchmark. For future research, there are three main recommendations. Firstly, to use preconditioning for the JFNK method. This was not done in this thesis because of technical constraints, but it is theoretically possible. Secondly, if the JFNK method is preconditioned, it could be used for the incompressible Navier-Stokes simulation. Finally, there are combinations of parameters which were not tested for the Schur complement method. Trying out more combinations might result in finding an even more optimized method.","Newton-Raphson; JFNK; Schur; incompressible Navier-Stokes","en","bachelor thesis","","","","","","","","","","","","","Double bachelor TW&TN",""
"uuid:cb61a81b-4f5f-4637-ad53-be98d4383a14","http://resolver.tudelft.nl/uuid:cb61a81b-4f5f-4637-ad53-be98d4383a14","Design for Leave-taking: Research and design for leave-taking experience in an aviation context","Yang, Ginny (TU Delft Industrial Design Engineering)","van der Meer, J.D. (mentor); Oonk, M.M.E.M. (mentor); Kiemel, Thamar (graduation committee); Delft University of Technology (degree granting institution)","2019","This research project focuses on understanding and improving the leave-taking experience in KLM Royal Dutch Airlines. The main focus was to explore how KLM HR can provide a better leave-taking experience for employees and managers. The study started with literature review, followed by context-mapping methodology as the main methogs. The findings and the results are summarised as a design toolkit. This toolkit depicts the overview of context analysis and provides hints and tips when designing for different target groups in KLM. This design toolkit serves two purposes: 1. An organised and interactive information carrier for the stakeholders to have the full picture of the findings and 2. A design facilitator that guides the developers and designers when generating new ideas to solve these problems. With the use of the toolkit, three concepts were proposed in corresponding to the three problems. Through the impact/effort matrix, one of the concepts ‘Manager dashboard’ was selected and further developed into three products. The products are mainly designed for the managers who have big team of staff work in shifts, as they have the most pain in supervising leave-taking, sickness and absenteeism. With the roadmap provided, it is expected that two of the products can be launched in 2020 Q1, and the other can be launched in 2021 Q4. The budget of the product can not be calculated due to the limited information, but a rough estimation leads to a safe of € 26.557.500 if the absenteeism rate in KLM can drop by merely 1%.","Service Design; Absenteeism; Organisation; Co-creation","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:d76ae286-972d-4f33-99a3-7a4fcf7bb501","http://resolver.tudelft.nl/uuid:d76ae286-972d-4f33-99a3-7a4fcf7bb501","Friction Forces of Micropatterned Elastomers with Carbon Fibre Fabric Reinforcement on Soft Substrates","Cheung, Eunice (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Biomechanical Engineering)","Dodou, D. (mentor); van Assenbergh, S.P. (mentor); Popovich, V. (graduation committee); Delft University of Technology (degree granting institution)","2019","Gecko-inspired adhesives mimic the external structure of geckos with micropatterned surfaces and the internal structure by fabric reinforcement in soft elastomer adhesive pads. Previous research measured the friction forces of synthetic adhesives, with either an external or internal structure, mainly on hard substrates. Much less is known about the effects on static friction forces on soft substrates of adhesives with a combined external and internal structure and with a contact area beyond a centimetre square. We fabricated 40 by 40 mm adhesive pads (Epad = 2.1 +/- 0.1 MPa) from polydimethylsiloxane (PDMS) elastomer and tested them on two soft PDMS substrates (Esub = 2.6 +/- 0.2 MPa and 1.0 +/- 0.1 MPa). A colloidal lithographic approach was used to fabricate the external structures of the adhesive pads with microscale dimples with and without a terminal layer (TL). The internal structures were fabricated by reinforcement of the adhesive pads with carbon fibre fabric (CFF), which varied in the types of CFF weave and its orientation with respect to the substrate. We found that samples without an external structure generated lower friction on the softer substrates, whereas samples with micropatterned surface generated similar friction between the substrates, presumably due to mechanical interlocking between the external structure and soft substrates. Samples with microscale dimples without TL generated the lowest friction forces among all samples, likely due to limited initial contact with the substrates. Samples with microscale dimples with TL generated similar friction forces as samples without an external structure. Those samples with TL were not able to generate higher friction, due to their fabrication method which restricted the movement of the fibre bundles, hindering the stress redistribution along the sample during the measurements. Samples with an internal structure showed significant higher friction compared to samples without reinforcement, due to a better stress distribution along the samples, but generated similar friction forces among the types of CFF weave.","Gecko; Micropattern; Carbon fibre; Friction; Soft substrate; Adhesive","en","master thesis","","","","","","","","2020-02-06","","","","Biomedical Engineering","",""
"uuid:672e1f92-306e-4b71-a18d-6b59d3c5ba8d","http://resolver.tudelft.nl/uuid:672e1f92-306e-4b71-a18d-6b59d3c5ba8d","A strategy to monitor and mitigate risks associated with the plan-adaptation process at HollandPTC","Visser, Miranda (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Biomechanical Engineering)","Klein, J. (mentor); Clarijs, Jesse (graduation committee); Delft University of Technology (degree granting institution)","2019","The steep rise of advanced technology in healthcare and the required spe- cialisation of staff causes healthcare systems to have become increasingly complex. This increased complexity poses great challenges on the risk management of systems. Many different methods have been developed the past decennia to identify potential risks in these system to enhance safety. A commonly used prospective risk analysis method is HFMEA, which is based on the linear view on system safety. Another relatively new method is FRAM which meets the dynamic systemic view on safety and focusses more on potential risks in a system due to ""everyday performance"". An example of a complex healthcare system is proton therapy; a novel type of radiotherapy to treat tumours in the proximity of the central nervous system. The first operational clinic in the Netherlands providing this therapy is HollandPTC. During the therapy the tumours are irradiated with a high precision in multiple sessions. When anatomical variation is observed between these sessions, the treatment plan of a patient has to be adjusted. This critical process is called plan-adaptation and has to be both time-efficient and safe. To ensure the safety of the plan-adaptation process at HollandPTC, currently controls are designed based on potential risks identified with HFMEA.<br/>The aim of this thesis is to identify an effective strategy to identify which controls are able to monitor and mitigate risks associated with the process of plan adaptation at HollandPTC.<br/>Independently of the HFMEA, a FRAM was conducted on the plan-adaptation process at HollandPTC. The resulting set of potential risks were compared with the po- tential risks identified with HFMEA. Furthermore, the effectiveness of the controls proposed by HFMEA were assessed on the set of potential risks identified with FRAM. Based on these results a strategy is proposed to monitor and mitigate the potential risks. <br/>The analysis of the FRAM models revealed among others potential risks related to: informal communication lines between caregivers, discrepancies between caregivers ideas about task division and identified multiple causes for time delays. These risks were not identified with HFMEA. The controls proposed by HFMEA do not mitigate the potential risks identified with FRAM. By combining the strengths of both HFMEA and FRAM, an effective strategy is proposed to monitor risk and to identify effective controls. This strategy can be used as a prospective risk-analysis method and on ongoing processes.","Proton therapy; FRAM; Safety","en","master thesis","","","","","","","","2021-08-22","","","","","",""
"uuid:51d69925-fb7b-4e82-9ba6-f8295f96705c","http://resolver.tudelft.nl/uuid:51d69925-fb7b-4e82-9ba6-f8295f96705c","Enriching Financial Datasets with Generative Adversarial Networks","De Meer Pardo, Fernando (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Numerical Analysis)","Oosterlee, Kees (mentor); Delft University of Technology (degree granting institution)","2019","The scarcity of historical financial data has been a huge hindrance for the development algorithmic trading models ever since the first models were devised. Most financial models assume as hypothesis a series of characteristics regarding the nature of financial time series and seek extracting information about the state of the market through calibration. Through backtesting, a large number of these models are seen not to perform and are thus discarded. The remaining well-performing models however, are highly vulnerable to overfitting. Financial time series are complex by nature and their behaviour changes over time, so this concern is well founded. In addition to the problem of overfitting, available data is far too scarce for most machine learning applications and impossibly scarce for advanced approaches such as reinforcement learning, which has heavily impaired the application of these novel techniques in financial settings. This is where data generation comes into play. Generative Adversarial Networks, GANs, are a type of neural network architecture that focuses on sample generation. Through adversarial training, the GAN can learn the underlying structure of the input data and become able to generate samples very similar to those of the data distribution. This is specially useful in the case of high-dimensional objects, in which the dimensions are heavily inter-dependent, such as images, music and in our case financial time series. In this work we want to explore the generating capabilities of GANs applied to financial time series and investigate whether or not we can generate realistic financial scenarios.","Generative Adversarial Networks; Data Augmentation; Financial Time Series","en","master thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:e3305316-2423-4a0c-8b2f-c391561b0de0","http://resolver.tudelft.nl/uuid:e3305316-2423-4a0c-8b2f-c391561b0de0","Redesign the Minddistrict platform to increase therapists engagement","Yin, Yu (TU Delft Industrial Design Engineering)","Goossens, Richard (mentor); Chmarra, Magda (graduation committee); Stroomer, Bas (graduation committee); Delft University of Technology (degree granting institution)","2019","Minddistrict (http://www.minddistrict.com) is a Dutch ehealth company that has been founded in 2008. What Minddistrict provides is a secure, flexible and user- friendly ehealth platform with an extensive catalogue of online modules, diaries and questionnaires to help clients with mental issues on their way to positive change. Minddistrict hopes to use ehealth technology to create more benefits for both clients and therapists, so that mental healthcare could be more efficient and flexible. To achieve this goal, it depends on the users to play an active role in daily use. Therapists engagement is also very crucial to successful implementation.<br/>However, the real situation is that there is not an organization who uses the product in its full potential. Professionals have very little time to learn, or to even think about ehealth. So, the challenge in this project is to find the barriers that stop therapists from using the platform, and to increase the usage of the product.<br/>Through the literature review and user research, multiple factors that may lead to low engagement from five main domains were found out. By collaborating with employees in MD, three design directions were selected based on their viability and feasibility. Also, the design vision was formulated as follows: We want to improve the therapist’s engagement of using the Minddistrict platform, by providing a better onboarding experience and creating an online community where they can actively interact with each other.<br/>The design vision and the nine design requirements gave a clear guide to three design directions: improving the onboarding experience for therapists (Chapter 4), creating an online community (Chapter 5), and exploring future technologies (Chapter 6). For the first two directions, user tests were conducted to collect feedback, and several iterations were done to refine the concepts. For the last direction, two promising technologies were discussed about how to apply them to engage more therapists in ehealth.<br/>The project finishes with recommendations for future improvement and limitations of this project.","eHealth; engagement; Gamification; Online community; onboarding","en","master thesis","","","","","","","","","","","","","",""
"uuid:ef99e4bc-4cea-4ebe-96f3-9fdc2604760a","http://resolver.tudelft.nl/uuid:ef99e4bc-4cea-4ebe-96f3-9fdc2604760a","Optimal scheduling for agile Earth observation satellites","Maene, Jochim (TU Delft Aerospace Engineering)","Noomen, Ron (mentor); de Bruijn, Ferdi (mentor); Palm, Christopher (mentor); Schrama, Ernst (graduation committee); Snellen, Mirjam (graduation committee); Delft University of Technology (degree granting institution)","2019","The past decade has seen a continuous increase of Earth observation missions, since they are regarded as an important tool to address global problems such as climate change or disaster mitigation. A commercial trend exists now towards higher resolution imagery, which drives the use of agile satellites. Nevertheless, a disadvantage of agile satellites is the increased complexity to compute the optimal imaging schedule. In fact, the problem can be interpreted as a time-dependent selective travelling salesman problem for which the travel between the cities is also a constrained optimal control problem. Considering the simplifying assumptions in literature, this MSc thesis presents a novel method which approximates the optimal control problem between the targets using an artificial neural network. This approach provides a significant improvement over any previous research resulting in an increase in scheduling performance of around 10%. Considering the high cost of agile Earth observation satellites, this advancement can offer important profit increases for satellite operators. Additionally, a new exact scheduling algorithm was developed based on dynamic programming logic. The algorithm is shown to be able to plan up to one hundred targets for a given restricted number of visible targets at each epoch, while previous research was only able to solve problem sizes of up to twelve targets. Furthermore, the new exact scheduling algorithm is also shown to have unmatched performance for cases of up to twelve targets, such that this should not be considered a difficult problem anymore.","Optimal Control Theory; Pseudo-Spectral Method; Dynamic Programming; Combinatorial Optimization; Artifical neural networks; Scheduling; Attitude control; Traveling Salesman Problem; Agile spacecraft","en","master thesis","","","","","","","","2024-08-23","","","","Aerospace Engineering","",""
"uuid:44ee86af-3160-452b-bfb2-bb1556f45a19","http://resolver.tudelft.nl/uuid:44ee86af-3160-452b-bfb2-bb1556f45a19","Enhancing Mobility around Schiphol Airport for International Passengers","Liu, Mingyu (TU Delft Industrial Design Engineering)","Hiemstra-van Mastrigt, Suzanne (mentor); Ruiter, Iemkje (graduation committee); Delft University of Technology (degree granting institution)","2019","This study presents the process and results of the graduation project: Enhancing Mobility Experience around Schiphol Airport for International passengers.This project is part of this project Optimaliseren Mobiliteit rondom Schiphol (in English Optimise Mobility around Schiphol). Within its broad scope, this graduation focuses on Chinese passengers, who arrive at Schiphol Airport for the first time. It is aiming to create a care-free and seamless transport journey from/to Schiphol from their perspective. The project took place in five phases, Research&amp;Analysis phase, Ideation phase, Conceptualisation phase, Embodiment phase and Verification phase. The Research&amp;Analysis phase consisted of desk research, field research and analysis. The Research&amp;Analysis phase revealed the existing ecosystem: a well-developed transport system in the Netherlands, and the potential of the Chinese outbound tourism market. This phase also showed the real experience of first-time passengers: difficulty on getting information, making a choice and feeling the sense of safety. Last but not least, it defined the design goals for the design phases: enable passengers to plan their trips based on the needs easily, and make them feel confident, supportive all the time.The Ideation phase and Conceptualisation phase developed the final concept according to the design brief established at the end of Research&amp;Analysis phase. During this phase, several iteration cycles were conducted to develop and refine the concept. The final design is a digital platform, in the form of a WeChat Mini Program, a light application embedded in WeChat (one of the most frequently used digital product in China). It supports the users from planning their transport before leaving to conducting their transport plan after arrival by fulfilling people’s needs on choosing route, tickets, getting information and finding the right spot for boarding.In the last two phases Embodiment phase and Verification phase, a high-fidelity interactive prototype was built and tested. The user test shows the final design almost meet the design goals. Passengers feel supported during the process of choosing routes and tickets, and feel easier on completing the tasks of finding the spot and getting on the vehicle in an unfamiliar environment. However, the role of the Mini Program in a visitor's journey of visiting the Netherlands is not clearly defined. For the final design, it is recommended to accomplish the service beyond the phone screen. For Schiphol Airport and other transport operators, it is recommended to use WeChat Mini Program as the carrier of service. The final design could be a starting point of the future development of the digital platform as a Mini Program. Those conclusions from Research&amp;Analysis stage might also be a reference for them.","passenger experience; user experience design; airport; mobility; Schiphol","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:bfc5745a-ddc9-4317-a957-c8a04c7b90f0","http://resolver.tudelft.nl/uuid:bfc5745a-ddc9-4317-a957-c8a04c7b90f0","High Density Integrated Capacitors for Smart Catheters and Implants","Naaborg, Jeroen (TU Delft Mechanical, Maritime and Materials Engineering)","Dekker, Ronald (mentor); Delft University of Technology (degree granting institution)","2019","The Flex-to-Rigid (F2R) technology platform is an interconnect platform to integrate heterogeneous electronic systems and devices onto a partially flexible chip for minimally invasive medical instruments. This technology platform allows for the integration of micro electro-mechanical systems (MEMS) and integrated circuits (IC) on a chip in a planar plane, which can later be folded into any arbitrary shape. Downscaling of the technology and the increasing number of integrated components in the F2R platform have a high impact on the power distribution and consequently on the signal integrity. It is widely accepted that one of the most powerful strategies to encounter signal integrity problems is to use decoupling capacitors. However, there is an inherent trade-off between the capacitance and size of a capacitor. This thesis is focused on the development on high density capacitors for the integration in the F2R technology platform. One of the objectives was to increase the capacitance density. Because there is limited space available on the F2R chip, additional area to increase the capacitance is found in the depth of the silicon. By etching multiple trenches into the silicon, a capacitance density increase by a factor of 10 is obtained. To even further increase the capacitance, the use of a silicon dioxide – silicon nitride – silicon dioxide multilayer (ONO) dielectric is reviewed. Moreover, a first step has been made in the fabrication of high breakdown voltage and low breakdown voltage parts in this dielectric layer. A second objective was to deliver the capacitors as a ‘’building block’’ that can be implemented in the F2R process flow. Therefore, the process needs to be compatible with the standard IC and MEMS technologies that are available in the Philips Innovation Service cleanroom. The steps of the fabrication process are verified and where needed optimized, and a dedicated mask set is designed for the fabrication of the capacitors. With this mask set, the so called trench capacitors have been made. These test devices are characterized in terms of breakdown voltage and capacitance. It is found that the capacitance density can be increased by an order of magnitude with the introduction of trenches to the test devices. In addition, the advantage of a multilayer dielectric compared to a single layer dielectric is shown.","Microfabrication; High Density Capacitors; Flex-to-Rigid","en","master thesis","","","","","","","","","","","","Biomedical Engineering | Tissue Biomechanics and Implants","",""
"uuid:fc89a24e-9ef8-49cf-b5fb-3f3fa1e3051b","http://resolver.tudelft.nl/uuid:fc89a24e-9ef8-49cf-b5fb-3f3fa1e3051b","An ex-ante LCA study on wind-based hydrogen production in the Netherlands","Delpierre, Mathieu (TU Delft Technology, Policy and Management)","Cucurachi, Stefano (mentor); Quist, J.N. (mentor); Delft University of Technology (degree granting institution); Universiteit Leiden (degree granting institution)","2019","Environmental emissions from transports need to be reduced in order to construct a sustainable society. Nowadays, gasoline and diesel account for 21% of the total carbon emissions in the world. In the Netherlands, important projects are present to develop a hydrogen economy by 2050. Hydrogen can be used as a sustainable fuel alternative for transports as its consumption produces only water. However, the current technologies for hydrogen production possess environmental emissions such as CO2, based on steam reforming and coal gasification. If hydrogen is to be used massively as an energy carrier, a shift in its production paradigm is necessary.<br/>The thesis compares the environmental performances of the two strongest potentials for green hydrogen (without harmful emissions) production: the alkaline and PEM electrolysers. Both of these technologies are based on the same principle: water is split with electricity into oxygen and hydrogen. To produce green hydrogen, the electricity comes from the wind energy, the largest renewable energy source potential in the NL. Both electrolysers are used at a pilot-scale currently. The main question studied in the thesis is to see how the environmental profiles of these two alternatives may evolve when a shift is operated pilot-scale to large-scale implementation. The Life Cycle Assessment tool is used to achieve the assessment and to put the focus on environmental emissions. LCAs at a pilot-scale were constructed based on a literature review. Analyses of the environmental performances from alkaline and PEM electrolysers enabled to settle a list of potentially relevant parameters to consider during upscaling process.<br/>Several technology analyses were conducted (workshop, interviews, collaboration with a company) and combined with the General Morphological Approach (GMA) to create scenarios for 2050. By combining the scenarios constructed with the GMA approach and the pilot-scale LCA models, prospective LCA models were created for potential future electrolyser’s plants. A special focus was made on electrolysers’ parameters to understand clearer their potential influences. <br/>Analyses of the prospective (named “ex-ante”) LCA models and comparisons were made between alkaline and PEM electrolysers. The alkaline electrolyser performs slightly better than PEM, even though the two alternatives possess virtually the same environmental performances. The differences in environmental performances between alkaline and PEM electrolysers are most of the time non-significant. The largest contributor in environmental emissions remains the electricity production (from Dutch wind turbines). That said, other perspective, such as geopolitical ones, may favour more one technology than the other (e.g. the PEM electrolyser consumes noble metals). <br/>Overall, a combination of LCA and GMA methodologies has been applied in the thesis to assess the environmental performances for two electrolysers in 2050, for green hydrogen production. Using renewable energy source decreases significantly the environmental impacts but the electricity production will likely remain the biggest contributor. The electrolysers are unlikely to influence significantly the environmental profile of green hydrogen production. A focus should be made on the electricity’s production. <br","hydrogen; electrolysis; PEM; alkaline; ex-ante LCA; GMA; cars","en","master thesis","","","","","","The Master's programme Industrial Ecology is jointly organised by Leiden University and Delft University of Technology.","","","","","","Industrial Ecology","",""
"uuid:df36a2dd-caa3-455b-84a7-77f99511d4b6","http://resolver.tudelft.nl/uuid:df36a2dd-caa3-455b-84a7-77f99511d4b6","Novel microelectrode arrays for in-vitro analysis of neural activity","Vyza, Yashwanth (TU Delft Electrical Engineering, Mathematics and Computer Science)","Valente, V. (mentor); Renz, Aline (mentor); Weaver, Sean (mentor); Voros, Janos (mentor); Serdijn, W.A. (graduation committee); Dekker, Ronald (graduation committee); Delft University of Technology (degree granting institution)","2019","Microelectrode arrays (MEAs) are extensively used for measuring neural activity in-vitro given their ability to monitor several neurons simultaneously unlike techniques such as patch clamp. However, MEAs still have limitations in acquiring high spatial resolution data due to limited number of channels that can be parallelly scanned, the need for bulky anti-aliasing filters, and limitations in signal-to-noise ratio (SNR) arising from thermal noise. Commercially available MEAs rely on resistive or self-capacitive sensing scheme, but this research proposes a new approach to increase the number of sensing locations while reducing the channels and to increase SNR. Fundamental design aspects of a MEA such as the shape and size of electrodes are revisited. By employing traditional lithographic fabrication techniques, these arrays with various geometries are fabricated and characterized. Neural cultures are seeded on these novel MEAs to record neural activity in the electrical domain and concurrently Ca+2 Imaging is performed to correlate and verify the activity of a neuron.","Microelectrode arrays; Neural interface; In-vitro analysis","en","master thesis","","","","","","","","2023-07-01","","","","","",""
"uuid:6eed2225-cd6b-43cb-8f91-4b608b5d6807","http://resolver.tudelft.nl/uuid:6eed2225-cd6b-43cb-8f91-4b608b5d6807","Implementing 3D printers to produce airworthy aircraft cabin parts","Kamber, Fehmihan (TU Delft Industrial Design Engineering; TU Delft Design Engineering)","Doubrovski, Zjenja (mentor); Willemen, Maurits (graduation committee); Delft University of Technology (degree granting institution)","2019","The research phase starts with an extensive literature study. To this end, a research question was drawn up, which reads as follows: What possibilities does Additive Manufacturing (AM) offer in airworthy aircraft part production and in what way can suitable parts be selected and redesigned? The most interesting findings from this literature study are as follows. The 3 most frequently mentioned benefits that AM offers the aviation industry is the ability to produce complex geometry, lightweight part production and reduce material waste. Moreover, each conserved kg saves US$3000 on an annual basis in fuel. Designated certification standards or criteria applicable for AM parts do not exist yet. Besides, material plays an overwhelming role in the selection of an AM machine. The current use in the studied literature were mainly certified metal AM parts, all were critical components from the engine or wing. Last, the production of plastic tooling is low-hanging fruit, which means that all the benefits that AM offers can also be used here and no certification is required. The result from the literature study was very educational and broad. However, not all found can be used immediately for KLM’s purpose. As a result, in the continuation of the project are some topics which were not applicable, re-examined and elaborated for KLM’s use. This involved firstly investigating the European regulatory bodies, EASA. Indeed, there are no standards or regulations for the use of AM in aviation yet. However, we know that 3D printed and certified exists. EASA explains the importance of repeatability of the production process and traceability of the material quality is the most important in general for production in the aviation. When we talk about producing and certifying parts, the certificates DOA and POA of EASA are of importance. With a DOA, an organization is allowed to design new parts within a specific category. While a POA allows an organization to produce new parts within a specific category. KLM holds of a DOA in aircraft cabin parts, but doesn’t hold a POA yet. Next are the applicable benefits AM offer applicable for KLM researched. This resulted in the top 5 of faster lead time, integrating assemblies, reducing weight, customization and reducing purchase costs. In the same way is the current use of AM by direct competitors of KLM investigated. Interesting to see that all these parts were plastic while most examples in the literature were about metal parts. With this outcome and the area in which KLM is allowed to design with its DOA is the cabin. An investigation has been done into which plastic printers may actually be used in the aviation industry to produce certified parts, due to the fact the cabin mainly consists of plastic parts. The result was only SLS and FDM. Because these 2 processes only have material that meets the general cabin material requirements applicable in the aviation. Thereafter, a list of suitable components for AM was drawn up at 3 different times with different techniques executed during these moments. In addition is a very elaborated trade-off table constructed to select part with the largest potential for each of the prior found top 5 benefits AM offers KLM. The list of criteria of the trade-off table is based on previous AM benefit consequence relations found. All criteria are rated by 8 KLM experts to provide objective weights. This resulted into the selection of 5 products for each benefit. The design phase When entering the design phase with the 5 selected products, it was realized that some of the selected were categories instead of specific products. A new route has been created for this to easily find partner numbers for each category and compile real parts. AM benefit = Selected component Faster lead time = Zodiac seat armrest Integrating assemblies* = Toilet paper holder* Reduce weight = Recaro bi-fold seat tables Customization = Boeing window shades Reduce purchase costs = Zodiac business class cabin bumpers Next is a standard template created which serves during the redesign process of each part and ensures structure but also that every concept is equally worked out. The template consists determining 4 comparison aspects, mind mapping, inspiration collage, idea sketching, CAD modeling, strength analysis and test on printability. The 4 comparison aspects create an overview on purchase price, lead time, weight and amount of parts between the original and redesigned parts. This overview easily displays whether an improvement or deterioration has been achieved with the redesign. The purchase price and weight are determined with a constructed formula. These formulas have been drawn up based on the ratio method. The lead time with an assumption, while the amount of parts can easily be counted in the CAD model. After this step is every redesign tested for strength with FEM analysis. This is done based on specific maximum use scenarios created for each component. The forces in these scenarios are determined by DINED, anthropometric database created by TU Delft. The strength analysis is highly important to validate and accept the determined comparison aspects for the redesigned parts. It can be shared that all components have passed the strength analysis. Similarly is testing on printability of a part very important. Even though all parts will be redesigned for AM, there may still be reasons why a component is not suitable for printing. It is best to remove these parts as quickly as possible. A method has been devised for this. Printability is related to 2 conditions, the function requi¬rements of the component and printer specifi¬cations. A list of function requirements are set up and linked to printer specifications of both FDM and SLS. When selecting the function requirements for the part, the limitations of the AM process will immediately be discovered which will serve to decide whether the part fits for AM or not. All 5 parts have been developed into concepts where according to determinations very large improvements have been made compared to the original part. The main target during development of the 5 concepts was the AM benefit this part was selected for. While other advantages of AM are side concerns. One thing is certain, there can be lots gained even with the side issues. Using the elaborate trade-off table constructed previously for selecting the most pro¬missing part to further develop. This resulted in the selection of the Zodiac seat armrest. The final phase During the final phase is the seat armrest redesigned concept further optimized. A specific list of requirements has been constructed and fined tuned by KLM experts specialized in airworthiness and seats. Consequently is the AM process and material selected, with which the strength analysis of the optimized component has been carried out. The process is SLS and material is PA2241FR. The maximum usage scenario has been changed to an extreme scenario where the size of the prior force exerted on the component in the concept phase is doubled for the final phase. The optimized component even passed this analysis. After this the printability test was performed for SLS and are the 4 comparison aspects determined. Next is the component is checked on its precision of dimensions and real fit on the assembly by producing tangible prototypes. Iterating the design in the real world and real use of context resulted into finalizing the CAD model. With the final redesigned armrest being pro¬duced in the eventual real specifications, could this SLS printed part be used to validate the previously determined comparison aspects with the eventual real aspects. This results in 97% reduction in lead time, 37% reduction in purchase costs and 58% in weight reduction when compared with the original part. This shows that the main benefit, lead time, the armrest is selected for is achieved. Besides, in case all current armrest will be replaced on the 777 and 787 fleet by the final seat armrest redesign, will result in a po¬tential fuel cost reduction of $4.665.000 on an annual base. After all the previous steps in design, test and maturation in the process, we have now fully completed the development of the new part and printability has been proven. The last final step is making a statement on meeting previously set requirements and whether this part has a chance of obtaining a certification. This certification should declare the part being airworthy and therefore authorized to fly. To be able to make a substantiated statement, 7 experts actively on this topic were consulted. All have been shown the list of requirements and has the issue whether or not having a chance of success at KLM and obtaining certification for this redesign has been asked. We can conclude from the conversations and discussions held. That the results together prove the armrest meet previously set requirements and provide enough confidence to conclude that the new armrest will get certified and thus succeeded. The most important thing is that the operator (KLM) accepts the new part and expiry of the ETSO certificate. And the component must be proven for flammability and the moment of breaking will have sharp edges. We know that this has happened before, which generates sufficient confidence. All in all, the results from the discussions held with 7 experts together with the real comparison aspects of the SLS printed part shows that the project has led to an amazing and successful result.","3D Printing; Additive Manufacturing; Aviation; Aerospace; Plastic; KLM","en","master thesis","","","","","","","","","","","","","",""
"uuid:b7601c86-5deb-497a-a7fb-4f579081483e","http://resolver.tudelft.nl/uuid:b7601c86-5deb-497a-a7fb-4f579081483e","When the journey becomes the destination: Proposing a mindset-based vision to rethink and create multi-modal mobility solutions","Fort Munoz, Julia (TU Delft Industrial Design Engineering; TU Delft Product Innovatie Management)","Hekkert, Paul (graduation committee); Snelders, Dirk (mentor); Obendorf, Hartmut (graduation committee); Delft University of Technology (degree granting institution)","2019","The mobility industry is facing a disruptive transformation. A large number of social, economic and technological trends are shaping the way we will move in the future. In this fast-changing environment, mytaxi becomes FREE NOW due to the joint venture in 2019 between its mother company Daimler together with BMW. While joining forces to become a stronger mobility player, FREE NOW’s product portfolio is undergoing a major change. Moving from offering only taxi rides to becoming a multi-modal mobility provider. This holistic approach to mobility brings lots of new challenges for the company.<br/><br/>This project is born from the knowledge gap identified within the company, regarding the city dweller’s behaviours and attitudes. With an open and explorative approach, this project focuses on providing the company with a human-centred upgrade to mobility.<br/><br/>Based on a user and trend research, this project identifies how the essence of mobility – of covering a physical distance – will evolve towards a multi-purpose-driven activity: shifting from a compromising experience towards a fulfilling experience.<br/><br/>The project, ’When the journey becomes the destination’, identifies four mindsets that describe the interactions city dwellers will have while travelling in the future context. For FREE NOW, the identified potential is to enable people to act according to their state of mind and facilitating them to recognise the mindset they are at that moment. This will allow providing a fulfilling service experience by matching them with the right mobility service.<br/><br/>This mindset-based approach proposed aims to help FREE NOW rethink and create multi-modal mobility solutions. While leaving apart the purely functional connotations of mobility, the designed mindsets focus on the meaningful nuances of mobility. From the service experience resulting from the human interactions with the space, four design directions are created to stimulate the designers from FREE NOW to question the status quo, as well as the future context.","Design; Mobility; Mindset; FREE NOW; Vision in Product Design","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:0ba88c37-2593-4db5-a4cb-c4c03b3c3bfc","http://resolver.tudelft.nl/uuid:0ba88c37-2593-4db5-a4cb-c4c03b3c3bfc","Measuring Darknet Markets","Stinenbosch, Bas (TU Delft Electrical Engineering, Mathematics and Computer Science)","Hartel, Pieter (mentor); van Eeten, Michel (graduation committee); van Wegberg, Rolf (graduation committee); van Hardeveld, Gert Jan (graduation committee); Delft University of Technology (degree granting institution)","2019","Background: A lot of scientists have tried to shed light on dark web markets. They did this by scraping these marketplaces over a period of time and describe what they were seeing. However, the methods used to measure these markets were never validated before. Research goal: This research will identify and validate the methods that are used in the literature to measure darknet marketplaces. Methods: To validate these methods, a novel dataset is used, namely the confiscated backend of a market. This dataset is cleaned and used to analyze the accuracy of these proxies on. Results: It is found that the number of transactions, revenue, and market share can be estimated with a high amount of explained variance. The predictions are precise enough to find prominent vendors on the market. The designed method of calculating the illegally obtained profits of a darknet vendor is easy to understand and could be used by law enforcement agencies. Finally, it is found that some vendors register to a market early as a strategy to ensure their business continuity.","Cryptomarket; Darknet; Market; Measuring; Proxies; Validating","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:9b433a09-1487-468c-b66d-068b616f724e","http://resolver.tudelft.nl/uuid:9b433a09-1487-468c-b66d-068b616f724e","Analytical modelling of the three-dimensional stress field induced by fluid production and injection in reservoirs with displaced faults","Singhal, Pranshu (TU Delft Civil Engineering and Geosciences; TU Delft Petroleum Engineering)","Jansen, Jan Dirk (mentor); Vossepoel, Femke (graduation committee); Wapenaar, Kees (graduation committee); Delft University of Technology (degree granting institution)","2019","Injection and production of fluids into/from the subsurface has been known to trigger earthquakes, referred to as induced seismicity. This seismicity may occur when anthropogenically caused changes in the in-situ stress conditions result in reactivation of pre-existing faults in the subsurface causing slip accompanied by sudden release of energy. Several studies have numerically modelled the induced stresses due to production/injection in reservoirs of various geometries. In this report we present a simplified three-dimensional reservoir with a displaced fault and derive analytical expressions for induced stresses in and outside the reservoir due to production and injection of fluids. We use the calculated stresses for the three-dimensional model and analyse onset of slip across the fault. The research builds upon the analytical two-dimensional plane-strain analysis for induced stresses and slip initiation in \citet{Jansen2019} to which our work contributed. We reaffirm the findings from the plane-strain analysis in \citet{Jansen2019} and conclude that the effects of incorporating third dimension on induced stresses and slip behaviour are limited. We find infinite peaks in resultant shear stresses at the reservoir boundaries and observe a distinctly different pattern in induced stresses and slip behaviour between production and injection scenarios. In case of production, the slip patches are predicted to grow inwards into the reservoir initially until they merge, while for injection the slip patches grow separately into the overburden and underburden. The findings in this report are in agreement with the previous analytical and numerical studies on induced seismicity. In this research we also introduce geometrical complexity in the reservoir in the form of laterally varying height of the reservoir and we observe that the effects of variation in reservoir thickness are also minimal, however the induced stress patterns and slip initiation is significantly impacted by fault throw, initial stress conditions and fault frictional characteristics.","Induced Seismicity; gas depletion; Induced Stress; displaced fault; three dimensional reservoir","en","master thesis","","","","","","","","","","","","","",""
"uuid:f9d6aad5-c0d8-40df-a04b-dda11acf3617","http://resolver.tudelft.nl/uuid:f9d6aad5-c0d8-40df-a04b-dda11acf3617","Agent-based modelling in energy scenario development: An analysis of contemporary energy scenarios for the Netherlands","Bosch, Max (TU Delft Technology, Policy and Management)","Chappin, Emile (mentor); Blok, Kornelis (graduation committee); van Daalen, Els (graduation committee); Delft University of Technology (degree granting institution)","2019","In order to determine how the energy sector of the Netherlands can or should look in the future, energy scenarios are used to explore possible alternative futures. Many scenarios for the Netherlands exist, but a classification of contemporary Dutch electricity scenarios is missing. Additionally, agent-based modelling (ABM) has often been proposed for energy scenario development as it is able to model the uncertain behaviour of energy companies, which is not possible in more traditional energy scenario models. However, a recent publication of the impacts of the Dutch climate agreement seems to suggest that agent-based modelling is not yet used to develop energy scenarios in the Netherlands. This research first classified Dutch energy scenarios for 2030 which are focused on the electricity sector. Additionally, it analysed two Dutch energy scenario with EMLab, an agent-based model. The agent-based model was able to replicate the scenario results when the inputs of that scenario were used. Additionally, it showed how uncertain behaviour would cause overinvestments and what measures can be used to impact this behaviour. The results show that ABM can and should be used to support scenario development for the Netherlands.","Agent-based modelling; scenario analysis; Netherlands 2030","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:cccc445f-085a-448d-8d13-22c792696a2b","http://resolver.tudelft.nl/uuid:cccc445f-085a-448d-8d13-22c792696a2b","Feasibility study of oil immersed power electronic based high voltage test source for onsite testing purpose","Lourduraj, Getssy Prathiba (TU Delft Electrical Engineering, Mathematics and Computer Science)","Vaessen, Peter (mentor); Ghaffarian Niasar, Mohamad (graduation committee); Stefanov, Alex (graduation committee); Baum, Benjamin (graduation committee); Delft University of Technology (degree granting institution)","2019","There is an increasing demand for compact onsite dielectric test systems of medium and high voltage equipment. Though there are commercially available mobile high voltage (HV) test sources, they have some important drawbacks such as limitation in voltage capability, complexity in building up the test setup and lack of versatility to test different equipment. Alternatively, the present challenges in these conventional test sources could be resolved by constructing a power electronics based test source. Amongst various converter topologies, Modular Multilevel Converter (MMC) is considered as a suitable topology for this application because of its high efficiency, modular structure, and reduced filter requirement. In order to achieve a compact solution, an oil immersed design of MMC, instead of the typical air insulated converter design is proposed in this master thesis. Oil can act both as a coolant and an effective insulating medium, thereby reducing the dimensions of the test system. <br/>This master thesis demonstrates the feasibility of oil immersed MMC based HV test source, covering both system level and component level aspects. The extent of compactness of the test source in oil was estimated at a system level. It was found that for the given trailer dimensions, the voltage capability of test source is around 4 times higher in oil when compared to air, This shows the effectiveness of oil as an insulating medium. The feasibility of oil immersed converter design depends on the degree of compatibility of its components under oil. Hence, experimental investigation was conducted on Insulated Gate Bipolar Transistor modules (IGBT) under oil as they are considered to be a pivotal component in MMC. Preliminary results show the penetration of oil into the IGBT chip surface. Despite oil migration, the operation of IGBT was not hindered during the test. Based on the results obtained from experimental work, a road map of future tests is suggested that need to be performed to realize an oil immersed HV mobile test source.<br","submodule; MMC; Converter layout; IGBT; Insulation; mineral oil; silicone gel","en","master thesis","","","","","","","","2020-08-21","","","","","",""
"uuid:3bd052ee-b8a0-4687-85d0-ca6df0b07d0d","http://resolver.tudelft.nl/uuid:3bd052ee-b8a0-4687-85d0-ca6df0b07d0d","Task Observability in change driven incremental build systems with dynamic dependencies","Sol, Roelof (TU Delft Electrical Engineering, Mathematics and Computer Science)","Konat, Gabriël (mentor); Visser, Eelco (graduation committee); Delft University of Technology (degree granting institution)","2019","Context:<br/>Updating an old result by selective re-execution of the inconsistent<br/>parts of some computation is usually faster than recomputing everything.<br/>Incremental build systems and interactive development pipelines<br/>use this technique to speed up feedback.<br/>They consist of different tasks. <br/>These tasks form a graph by depending on the environment and the result of other tasks. <br/>To re-execute a build requires an incremental build algorithm to find and re-execute inconsistent tasks.<br/>This can be done by traversing the dependency graph top down. <br/>When the mutations to the input environment are known in advance a<br/>build algorithm can avoid graph traversal. Thereby scaling with the size of a change instead of the size of the graph.<br/>Another important distinction between incremental build systems is their ability to handle dynamic dependencies.<br/>That is, dependencies that are discovered during a build.<br/>PIE is a bottom-up build algorithm that supports dynamic task dependencies.<br/>It schedules and executes inconsistent tasks without traversing the entire dependency graph. <br/>The current PIE algorithm is capable of adding dynamic task dependencies.<br/>However, it does not process removing dynamic task dependencies.<br/>This preserves consistency, but limits scalability over time.<br/>Each detached task is still scheduled and executed by the bottom up algorithm.<br/><br/>Inquiry:<br/>PIE is inefficient when it executes tasks that are no longer a transitive dependency. <br/>In this paper we introduce task observability to solve this.<br/>This problem is unique to bottom up scheduling build systems.<br/>However, we are able to re-use techniques from incremental build systems and garbage collections to implement our solution. <br/><br/>Approach:<br/>We split the problem into three parts, determining task observability, scheduling, and re-observing.<br/><br/>Knowledge<br/>With the new algorithm we are able to improve the efficiency of PIE and its scalability over time.<br/><br/>Grounding:<br/>We verify and benchmark our changes with two artificial and one real world use case in the Spoofax Workbench.<br/><br/>Importance:<br/>The PIE runtime is able to continue operating efficiently even when tasks are detached. <br/>In some situations the Spoofax PIE pipeline reduces the feedback time with 1800 ms when results are not observed by the user. <br/>Additionally, new design patterns are made possible.<br/>For Spoofax, toggling observability creates the opportunity to implement various quality of life features such as file and project renaming.<br/><br/>As a secondary contribution we implement a garbage collector for detached tasks and create a visualization tool for displaying the dependency graphs stored in PIE.<br/><br","Build Systems; Interactive development pipeliens; Incremental computation","en","master thesis","","","","","","","","","","","","Computer Science","PIE | Spoofax",""
"uuid:ffdcf947-06df-4941-a587-bdf008f87783","http://resolver.tudelft.nl/uuid:ffdcf947-06df-4941-a587-bdf008f87783","Interwoven: Designing Biodigital Objects with Plant Roots: Exploring Material Structure and Experience","Zhou, Jiwei (TU Delft Industrial Design Engineering)","Karana, Elvin (mentor); Wu, Jun (mentor); Delft University of Technology (degree granting institution)","2019","Interwoven is a textile grown from plant roots, showing the intelligence of plants. It is originally from the attempt of training plant roots to form a manmade pattern since 2015 by visual artist Diana Scherer based in Amsterdam. Due to fragility, it still remains an artistic work. However, Interwoven has a great potential for sustainable product design if further development is made through altering the material structure. <br/><br/>Collaborating with Materials Experience Lab of Industrial Design Engineering in TU Delft, Diana Scherer wants to bring an artistic material closer to people’s daily life. The author, by following the Material Driven Design method (Karana et al., 2015)*, develop the material by altering material structure through hacking the growing process, incorporating generative design techniques and the results from the user studies, with a particular emphasis on people’s experience on interpretive level. Digital Fabrication techniques are used to design the structural pattern for achieving functionally graded material properties (e.g. spatially graded stiffness), and shape optimisation.<br/><br/>Based on Diana Scherer’s experience and early experiments, a few techniques are synthesized and developed in the tinkering with Interwoven. Some potential structures for digital biofabrication are: [1] root growth can be manipulated to mirror digitally generated patterns, which would provide intended technical and experiential characteristics in Interwoven; [2] roots grown in agar gel change properties to stiffer and stronger by hand feeling (further mechanical tests are needed); [3] roots can sew through descrete obstacles in their growing direction and these obstacles can be designed with digital fabrication techniques.<br/><br/>Combining the insights and experiential studies, a material concept has been created: showing roots glue-ability to porous materials and growing traces to blend nature and man-made world. The material experience vision is to exhibit the glue-ability of Interwoven through a daily object co-created by roots and digital manufactured structures and bring forward the collision and collaboration between natural growth and man-made world. The final product concept is to imitate one of the most mass-produced daily products - IKEA ALSEDA, questioning the current way of manufacturing and material use. The co-creation structure increased durability of Interwoven.","Material Driven Design; Biomaterials; Digital Biofabrication; Growing Material","en","master thesis","","","","","","","","","","","","Design for Interaction","Interwoven",""
"uuid:4aad89f6-ac52-4e46-be5f-e5137f6b31c3","http://resolver.tudelft.nl/uuid:4aad89f6-ac52-4e46-be5f-e5137f6b31c3","Something fishy going on! Evaluating the Poisson hypothesis for rainfall estimation using intervalometers: first results from an experiment in Tanzania","De Villiers, Didier (TU Delft Civil Engineering and Geosciences)","van de Giesen, Nick (mentor); ten Veldhuis, Marie-claire (graduation committee); Schleiss, Marc (graduation committee); Delft University of Technology (degree granting institution)","2019","Sub-Saharan Africa is one of the most vulnerable regions in the world to climate change. This is largely driven by the dependence on rain fed agriculture for food production. At the same time African climate observational networks have been in decline since the 1990s. A new kind of rainfall sensor (the intervalometer), which counts the arrival of drops at a piezo electric element, is tested during the Tanzanian monsoon season alongside tipping buckets and an impact disdrometer. Rainfall rates are derived from rainfall arrival rates using Marshall and Palmer’s (1948) exponential parameterisation. This parameterisation is defined independently of a notion of scale and therefore implicitly assumes that rainfall is a homogeneous Poisson process. Testing of the Poisson assumption shows that 22.5% of the total drops observed can reasonably be considered Poisson and that the main reason for Poisson deviations are non compliance with the stationarity criterion (36.7%) and the presence of correlations between drop counts (14.3%), particularly at higher arrival rates (ρa &gt; 500 [m−2.s−1]). The total rainfall amount [mm] calculated from intervalometer measurements overestimates the tipping bucket value by a factor of approximately three. The overestimate is most likely due to poor calibration of the minimum detectable drop size (Dmin). A correction is applied to constrain the overestimates of mean drop size by the intervalometer parameterisation to the observed disdrometer measurements. The correction results in an improvement in the estimate of the total rainfall amount to within 10% of tipping bucket measurements. The total rainfall amount [mm] calculated from disdrometer rainfall arrival rates is within 5% of co-located tipping bucket measurements. The form of the mean drop size relation with arrival rate appears stable in time and space. The intervalometer shows good potential for use as a rainfall measurement instrument or to derive estimates of mean drop sizes.","Homogeneous Poisson; Rainfall estimation; intervalometer; Drop size distribution","en","master thesis","","","","","","","","","","","","","TWIGA",""
"uuid:e6f3e5cc-ed4e-4161-957a-cea387decf91","http://resolver.tudelft.nl/uuid:e6f3e5cc-ed4e-4161-957a-cea387decf91","The Mechanisms of Non-Photochemical Laser-Induced Nucleation: Theory and Experiment","van Waas, Tom (TU Delft Applied Sciences)","Eral, H.B. (mentor); Delft University of Technology (degree granting institution)","2019","Non-photochemical laser-induced nucleation (NPLIN) is a crystallisation method in which a highly structured phase is formed out of solution by exposure to a laser beam. NPLIN offers unprecedented spatiotemporal control and characterisation of nucleation. NPLIN is energy efficient compared to conventional crystallisation methods and can be implemented in continuous microfluidic reactors, enabling sustainable operation. However, its working principles are not yet fully understood. This study contains an evaluation of four proposed mechanisms and a description of an experimental setup involving an ultrahigh speed camera. Two mechanisms describe interaction of molecular polarisation with the electric field, either isotropically known as dielectric polarisation (DP), or anisotropically via the optical Kerr effect (OKE). The other two mechanisms involve cavitation bubble formation by nanoparticle heating through light absorption. This work contains a refined description of this so-called cavity-induced nucleation where its consequences are distinguished into two mechanisms, either based on concentration enhancement (CICEN) or due to pressure enhancement (CIPEN). Novel theoretical calculations in conjunction with experimental data suggest that NPLIN phenomena are based on DP or CICEN, potentially operating in concert. It is conjectured that the influence of DP and<br/>CICEN can be quantified further by development of a topological description of DP, simulations of CICEN and relating nucleation probabilities to the metastable zone width of various solutes. The calculations suggest that OKE and CIPEN have little significance because involved energies are several orders of magnitude<br/>below kBT . The proposed setup allows for observing the NPLIN phenomena and establishing dependence on cavitation bubbles, providing empirical validation. Solutions to experimental problems are provided, including reduction of sample fluid evaporation, aligning the nucleation site with the region of interest of the camera and removing image noise.<br/><br","NPLIN laser cavitation bubble concentration enhanced nucleation","en","bachelor thesis","","","","","","","","","","","","","LightX",""
"uuid:3ea6562b-8c69-46a4-b9db-badefc2c4495","http://resolver.tudelft.nl/uuid:3ea6562b-8c69-46a4-b9db-badefc2c4495","Assessing port competition via a cost-based logistic chain model: A transparent and generic approach","Lute, Kevin (TU Delft Mechanical, Maritime and Materials Engineering)","Frouws, J.W. (mentor); van Hassel, E.B.H.J. (graduation committee); Hekkenberg, R.G. (graduation committee); Beelaerts van Blokland, W.W.A. (graduation committee); Delft University of Technology (degree granting institution)","2019","This study was conducted to address the lack of insight port authorities have in port competitiveness. Within this thesis a data-driven model is presented that allows to assess port competition within a bounded scope. This model is developed from the ground up and programmed in the Python programming language as a stand-alone solution. The model doesn’t rely on extensive black-box models as often found in related literature. Due to its generic nature, the logistic chain choice model can also serve as a base model for different scenario analyses. Scenarios could include the change of ship-size, (oil) price or cost scenario’s and future throughput forecasts. The model can provide insights regarding effective port investments and policy making.","Container shipping; Logistic chain; Port Competition; Port selection; Hinterland","en","master thesis","","","","","","","","2019-10-01","","","","Marine Technology | Ship Design, Production and Operations | Shipping Management","",""
"uuid:63445bf6-3674-43b8-8f84-62efadc8d74a","http://resolver.tudelft.nl/uuid:63445bf6-3674-43b8-8f84-62efadc8d74a","Validating the effect of the persuasive game design principle simulation on attitude change for multi-actor decision-making","Rambharos, Shanita (TU Delft Technology, Policy and Management)","Kortmann, L.J. (mentor); Verbraeck, A. (mentor); de Vries, G. (mentor); Erdbrink, A.E. (mentor); Delft University of Technology (degree granting institution)","2019","Persuasive games have great properties for facilitating lasting attitude change for complex societal issues, making them a valuable tool for achieving attitude change towards cooperation and information sharing that is often necessary for effective multi-actor decision-making. It is assumed that persuasive game design principles are key drivers for conceiving successful persuasive games, however, their effect on attitude change and attitude reinforcement has not been validated. To get one step closer towards validated persuasive game design principles, this research aimed at validating the most frequently used persuasive game design principles for persuasive game for multi-actor decision- making: simulation. Game experiments in the form of laboratory experiment were conducted to control for possible confounding variables. Three versions of an existing game were conceived in which the persuasive game design principle simulation was varied. A mixed methods approach was used in which both quantitative and qualitative measures were conducted to assess the effect of the persuasive game design principle simulation on attitude change. Based on current findings it cannot be confirmed nor denied that the persuasive game design principle has affected attitude change regarding cooperation and information sharing. Still, the main scientific contribution of this research is the creation of a sufficient method for evaluating the effect of persuasive game design principles on attitude change in isolation which did not consist yet. Further research on the methodology is advised to validate its effect and for fine-tuning. Additionally, it is advised to conduct this research with a greater sample size in this future.","Persuasive games; Method design; Persuasive Game Design; Persuasive game design principles; Simulation; multi-actor decision making","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:c24aada6-04d2-4306-88fb-aead1c99d1dc","http://resolver.tudelft.nl/uuid:c24aada6-04d2-4306-88fb-aead1c99d1dc","Microalgal cultivation on recovered nutrients: Cultivation of the extremophilic microalgae Galdieria sulphuraria on reverse osmosis concentrate from water and resource recovery pilot plant of New Energy and REsources from Urban Sanitation (NEREUS)","Narayen, Dhavissen (TU Delft Civil Engineering and Geosciences)","Lindeboom, R.E.F. (mentor); Weissbrodt, D.G. (mentor); de Kreuk, M.K. (graduation committee); van den Brink, Paula (mentor); Schepers, Otto (graduation committee); Delft University of Technology (degree granting institution)","2019","Galdieria sulphuraria (G. sulphuraria ) is a eukaryotic, extremophilic, spherical and unicellular species of red algae. G. sulphuraria can grow at very low pH-values (pH 0.05 – 5.0) and high temperatures (35 – 56 °C). The growth conditions of G. sulphuraria make it suitable for axenic cultivation because the low pH and high temperature minimalize the risk of microbial contamination. Next to its ability to remove nutrients in wastewater treatment, G. sulphuraria is a prospective producer of a valuable product, Phycocyanin (PC), a thermostable blue pigment-protein complex, which is used as, among others food additive and food colorant. <br/><br/>These characteristics of G. sulphuraria lead its selection by Evides Industriewater for the uptake of the ammonium present in the reverse osmosis (RO) concentrate of New Energy and REsources from Urban Sanitation (NEREUS). NEREUS focuses on the re-use of nutrients present in wastewater, among others ammonium. One of the goals of NEREUS is to re-use the ammonium present in the RO concentrate with the use of algae. In order to recover ammonium from the RO concentrate of NEREUS, it is necessary to test whether G. sulphuraria is capable of growing on such medium. The possibility of cultivating of G. sulphuraria on the RO concentrate from water and resource recovery pilot plant of NEREUS was investigated in this thesis. <br/><br/>The objectives of this thesis were to find the optimal growing conditions and assess the biomass growth and nutrients consumption. Screening experiments with synthetic Allen medium, which is usually used for the cultivation of the G. sulphuraria, were conducted to obtain the best growing conditions of G. sulphuraria. In order to understand the best growing conditions for the cultivation of G. sulphuraria, the effects of several factors were investigated, which are: 1) different metabolism, 2) different nitrogen sources and concentrations (ammonium: 100 – 1000 mgNH4+-N/L and nitrate: 247 mgNO3--N/L), 3) different carbon sources (glucose, bicarbonate and CO2) and different glucose concentrations (C:N = 5:1 and 10:1), 4) different phosphate concentrations (N:P = 37:1 and 7.2:1), 5) culture densities. Ammonium with mixotrophic metabolism turned out to be the best nitrogen source. Biomass concentration on ammonium was four times higher than on nitrate. Increasing the ammonium concentration from 200 mgNH4+-N/L to 1000 mgNH4+-N/L resulted in around 25% more biomass and no firm conclusions could be drawn from the experiment performed with different phosphate concentrations. No significant increase in the growth of G. sulphuraria was observed between Carbon:Nitrogen (C:N) ratio = 5:1 and 10:1. Furthermore, culture densities higher than 0.7 g/L of biomass resulted to a slower growth of G. sulphuraria. <br/><br/>Experiment with synthetic RO concentrate shows that there was light limitation involved during the cultivation. Highest and fastest growth (µmax = 0.78 day-1) was observed in the mix of 40% real RO concentrate and 60% synthetic RO concentrate medium culture. Growth inhibition was observed in cultures containing RO concentrate of NEREUS. Still, G. sulphuraria did grow on RO concentrate of NEREUS. This work is contributing to the scientific and engineering community in the field of microalgae.<br","Microalgae G. sulphuraria; Nutrient re-use; reverse osmosis concentrate","en","master thesis","","","","","","","","2021-08-21","","","","Civil Engineering","",""
"uuid:ec72cba4-a4b2-476d-ad0f-173c84969fa8","http://resolver.tudelft.nl/uuid:ec72cba4-a4b2-476d-ad0f-173c84969fa8","A GaN-based Power Factor Correction Converter: for Electric Vehicle Charging","Lyu, Dingsihao (TU Delft Electrical Engineering, Mathematics and Computer Science)","Qin, Z. (mentor); Raaijmakers, Stefan (mentor); Chandra Mouli, G.R. (graduation committee); Bauer, P. (graduation committee); Smets, A.H.M. (graduation committee); Delft University of Technology (degree granting institution)","2019","Because of its superior conduction and switching performance, and falling price, Gallium Nitride (GaN) power semiconductor device is expected to bring improvements to the power electronics system, including higher efficiency and higher power density. How will the new semiconductor device benefit the rapidly growing Electric Vehicle (EV) charging application, where high efficiency, high power density are two of the most important design requirements? In order to verify the match between the new semiconductors and the EV charger application, hardware demonstration needs to be carried out. In this thesis project, the design of a GaN-based, high switching frequency, single phase, 2KW PFC converter for EV charging will be introduced. The operation principle and control of the converter will be explained, and the hardware demonstration results will be shown. The testing results prove the high-efficiency, high-frequency abilities of the new technology.","Gallium nitride device; Power Factor Correction; EV charging infrastructure","en","master thesis","","","","","","","","2021-08-21","","","","","",""
"uuid:5643a235-242a-44a1-bae1-8764b22a775d","http://resolver.tudelft.nl/uuid:5643a235-242a-44a1-bae1-8764b22a775d","Measurement strategy for state estimation of medium voltage grids with distributed generation","Sirige, Sindhura (TU Delft Electrical Engineering, Mathematics and Computer Science)","Rueda, José L. (mentor); Stefanov, Alexandru (graduation committee); Qin, Z. (graduation committee); Delft University of Technology (degree granting institution)","2019","The world is going through an energy transition towards decentralized electricity generation like photovoltaic systems and new loads like electric vehicles, which contribute to the variability of the operation state of distribution systems. To ensure future operation under safe and efficient conditions, it becomes increasingly important to have precise knowledge of the state of the grid. For this, Distribution System State Estimation (DSSE) has extensively been discussed in the literature. However, distribution networks at present are not only characterized by sparse measurement locations, which makes application of DSSE difficult due to un-observability, but also the anticipated highly stochastic load profiles will affect the accuracy of the system state estimate. Therefore, it is now necessary to assess how the DSSE accuracy is affected by different factors that result from continuous changes in the consumption pattern and measurement scheme. For this purpose, an improved measurement scheme is proposed in this thesis, that not only considers the meter placement, but also the required measurement intervals, to establish a minimum required accuracy level of the state estimator under stochastic conditions. The work presented in this thesis starts with a sensitivity analysis of the Weighted Least Square (WLS) DSSE algorithm applied on a synthetic model of an existing 10kV distribution network in the Netherlands, with respect to the stochasticity of the load profiles applied. Based on this analysis, an algorithm is developed to determine the measurement configuration that satisfies a predefined maximum DSSE error. The effects of the following parameters on the state estimation accuracy are assessed: i) Percentage of pseudo measurements ii) Stochasticity of the applied load profiles iii) Interval of measurements The analysis can be used to recognize the conditions at which the DSSE results become unacceptable. From here, a novel algorithm for determining a proper measurement scheme is presented, considering the existing meter placement and the required interval of measurements to compensate for the uncertainty in the load profiles. The focus is on determining intervals of measurement to establish a minimum predefined DSSE accuracy level, more than placing additional meters. The method first establishes the meter locations to achieve observability. Then, the algorithm uses the SE error resulting from Monte Carlo simulations to improve the accuracy. The measurement intervals are determined based on the analysis of sensitivity to the interval of measurements. This results in a measurement configuration that maintains the SE error within the acceptable range at every instant of time. It is tested on the 10kV distribution network model, in the future scenario with high stochasticity in load profiles resulting from the projections of the energy transition for the year 2040. The results will show the effectiveness of the proposed algorithm for the determination of measurement scheme. This is important for the network operators who would use the results of the SE algorithm to make decisions on the grid operation.","State estimation; Medium voltage networks; Measurement configuration","en","master thesis","","","","","","","","2021-08-31","","","","Electrical Engineering","",""
"uuid:09572370-c7a0-4d11-9436-83762b4fcafc","http://resolver.tudelft.nl/uuid:09572370-c7a0-4d11-9436-83762b4fcafc","How can I touch you?: Setting the Yardstick: A Quantitative Metric for Effectively Measuring Tactile Internet","Verburg, Joseph (TU Delft Electrical Engineering, Mathematics and Computer Science)","Venkatesha Prasad, R.R. (mentor); Kroep, H.J.C. (graduation committee); Delft University of Technology (degree granting institution)","2019","Tactile Internet (TI) is, the next frontier of connectivity development wherenot only information but interaction can be exchanged digitally. Much effort in the field of TI has been spent towards developing the necessary technologies needed to transmit interactions over the internet in a naturally perceivedway. However not much has been done on improving the evaluation of these TI technologies, that is, Mean Opinion Score score or Peak Signal to Noise Ratio measures for audio-video applications. Existing measures and measuring methods only give coarse-grained indications of performance and lackthe depth for good comparison. By using Dynamic Time Warping as starting point we propose our new measures Effective Time &amp; Value -Offset that fundamentally changes the way to evaluate performance. We verify our measures by showing it performs significantly better compared to existing work by using data from a new testbed designed to allow testing in stringent network conditions and to be usable for many futureworks.Our contributions will push forward TI development allowing both incremental and novel developments to be tested more easily and with improved verification.","Tactile; Measures; Testbed; dynamic time warping; Tactile Internet","en","master thesis","","","","","","","","2021-09-01","","","","","",""
"uuid:652473a6-547e-4a86-8f64-c5f5bf79e986","http://resolver.tudelft.nl/uuid:652473a6-547e-4a86-8f64-c5f5bf79e986","A Proportionally Controlled Microvalve using a Piezoelectric Unimorph Microactuator","Gunda, Arun (TU Delft Mechanical, Maritime and Materials Engineering)","Ghatkesar, Murali (mentor); Tichem, Marcel (graduation committee); Goosen, Hans (graduation committee); Lötters, J.C. (graduation committee); Delft University of Technology (degree granting institution)","2019","Microvalves are important flow-control devices in many standalone and integrated microfluidic applications. PDMS-based (Polydimethylsiloxane) pneumatic microvalves are the most commonly used type for research purposes, but they require large peripheral connections and cannot be used for controlling gases due to the high gas permeability of PDMS. There are many alternatives found in the literature that use Si-based microvalves, but variants that can throttle even moderate pressures (1 bar) tend to be bulky (cm-range), have a complex fabrication process, or consume high power. This thesis details the development of a low-power, normally-open piezoelectric microvalve to control flows with a maximum driving pressure of 1 bar, but also retain a small effective form-factor of 5mm x 5mm x 1.8mm. A novel combination of rapid-prototyping methods like stereolithography and laser-cutting was used to realize this device. The maximum displacement of the fabricated microactuator was measured to be 8.5 μm at 150V. The fabricated microvalve has a flow-range of 0 - 90 μL/min - water at 1 bar inlet pressure. When fully closed, a leakage of 0.8% open-flow was observed with a power-consumption of 37.5 μW. A flow resolution of 0.2 μL/min was measured at 0.5 bar pressure.","microvalve; piezoelectric; unimorph; 3D-printing","en","master thesis","","","","","","","","2020-12-31","","","","Mechanical Engineering","",""
"uuid:7eea5e14-d1bc-4f7e-83e7-775d1ed13f21","http://resolver.tudelft.nl/uuid:7eea5e14-d1bc-4f7e-83e7-775d1ed13f21","Elaboration on Kwapien's theorem: Representing bounded mean zero functions f as coboundary f = g ◦ T − g","Borst, Matthijs (TU Delft Electrical Engineering, Mathematics and Computer Science)","Veraar, M.C. (mentor); van den Dries, B. (graduation committee); Kraaikamp, C. (graduation committee); Delft University of Technology (degree granting institution)","2019","class=""MsoNormal"">In [8] Kwapien proved that every mean zero function f ∈ L∞[0, 1] we can<br/> write as f = g ◦ T − g for some g ∈ L∞[0, 1] and some measure preserving<br/> transformation T of [0, 1]. However, as was discovered in [4] there is a gap<br/> in the proof for the case that f is not continuous. The aim of this bachelor<br/> thesis is filling in that gap in the proof. We first extend Kwapien’s proof for continuous functions to certain other measure spaces. Thereafter, we use the method of proof suggested by Kwapien, to proof the theorem for mean zero function f ∈ L∞[0, 1] for which λ(f<sup>−1</sup>({x})) = 0 for all x ∈ R. Using this result we then proof that every mean zero function f ∈ L∞[0, 1] can be written as a sum f =(g<sub>1</sub> ◦ T<sub>1</sub> − g<sub>1</sub>) + (g<sub>2</sub> ◦ T<sub>2</sub> − g<sub>2</sub>) where g<sub>1</sub>, g<sub>2</sub> ∈ L∞[0, 1] and where T<sub>1</sub>, T<sub>2</sub> are<br/> measure preserving transformations of [0, 1]. We finish this thesis with an<br/> application of Kwapien’s theorem in the study to singular traces","Kwapien; Coboundary equation; measure preserving transformation","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:aa5c948d-43c4-480d-9818-43949c67a3b5","http://resolver.tudelft.nl/uuid:aa5c948d-43c4-480d-9818-43949c67a3b5","Efﬁcient Neural Architecture Search for Language Modeling","Li, Mingxi (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Interactive Intelligence)","Oliehoek, F.A. (mentor); Pan, W. (graduation committee); van Gemert, J.C. (graduation committee); Zhou, H. (graduation committee); Delft University of Technology (degree granting institution)","2019","Neural networks have achieved great success in many difﬁcult learning tasks like image classiﬁcation, speech recognition and natural language processing. However, neural architectures are hard to design, which requires lots of knowledge and time of human experts. Therefore, there has been a growing interest in automating the process of designing neural architectures. Though these searched architectures have achieved competitive performance on various tasks, the efﬁciency of NAS still needs to be improved. Moreover, current neural architecture search approach disregards the dependency between a node and its predecessors and successors. <br/>This thesis builds upon BayesNAS which employs the classic Bayesian learning method to search for CNN architectures, and extends it to the problem of neural architecture search for recurrent architectures. Hierarchical sparse priors are used to model the architecture parameters to alleviate the dependency issue. Since the update of posterior variance is based on Laplace approximation, an efﬁcient method to compute the Hessian of recurrent layer is proposed. We can ﬁnd candidated architectures after training the over-parameterized network for only one epoch. Our experiments on Penn Treebank and WikiText-2 show that competitive architectures can be found in 0.3 GPU days using a single GPU for language modeling task. We ﬁnd that our algorithm is more efﬁcient than state-of-the-art.<br","NAS; Deep learning; Artificial intelligence","en","master thesis","","","","","","","","","","","","Electrical Engineering | Embedded Systems","",""
"uuid:60e57237-f840-4b17-8be0-26e789f52f0a","http://resolver.tudelft.nl/uuid:60e57237-f840-4b17-8be0-26e789f52f0a","Control Strategy in Parallel AC-DC Re-configurable Links System","Wu, Yang (TU Delft Electrical Engineering, Mathematics and Computer Science)","Soeiro, Thiago B. (mentor); Bauer, P. (mentor); Rueda, José L. (graduation committee); Shekhar, A. (graduation committee); Delft University of Technology (degree granting institution)","2019","Recent studies have shown that energy distribution systems based on hybrid (or parallel)point-to-point AC and DC links are interesting solutions for capacity enhancement andon-line improvement of energy efficiency under specific operating conditions, particularlyfor high power, medium to high voltage levels and long-enough distances, e.g.&gt;5km.Additionally, due to the power controlability provided by the power electronic circuitswithin the DC links the parallel distribution system can be re-configured through GISdisconnectors operating with improved switching performance. In this work this featureis explored and strategies for the system re-configurations are proposed. These aim toprovide a nearly zero current switching for the GIS in order to prevent its deteriorationand to extend the number of maneuvers for the typical GIS lifetime.<br/>In fact, the proposed re-configuration strategies rely on the DC bus voltage and powercontrols of a Back-to-Back (B2B) power electronic system constructed with Voltage SourceConverters (VSC). Herein, three-wire three-phase two-level VSCs with thrid-order AC har-monic filters (or LCL filter) are adopted in the B2B system. Moreover, Grid-side CurrentControls (GCC) for the inner/fast control loops of the front- and back-end circuits are im-plemented in order to enhance the system performance against grid disturbances. Herein,a notch filter-based GCC scheme with a harmonic rejection control is proposed. This isable to deliver attenuation to the LCL filter resonances while suppressing the harmonicsin the grid-side currents originated when the AC voltages are distorted. Interestingly,the parallel AC and DC links provides a low impedance path for the zero-sequence com-ponents which can be created by the power electronics, thus the implementation of aZero-sequence Circulating Current (ZSCC) controller becomes necessary for the properoperation of the system. Hence, ZSCC controllers for the VSCs are used, while bothfront- and back-end circuits are modulated with constant switching frequency using theconventional sinusoidal PWM strategy.<br/>All in all, results are obtained in both, computational simulations carried out in MAT-LAB/SIMULINK and laboratory experiments performed in a5kVA VSC or a B2B circuit,are used to verify the study and to prove the superior performance of the investigatedand proposed technical concepts. Herein, more specifically for the re-configuration studyof the parallel AC and DC links, the standalone mode control of the receiving-end VSCin the full DC link configuration is investigated and the smooth transition between grid-connected and standalone modes are realized in both simulation and experimental tests.","Control of the Voltage Source Converter; parallel AC-DC system; re-configurable system","en","master thesis","","","","","","","","2022-08-21","","","","","",""
"uuid:d62aed59-364c-4e91-90ff-3d61ed5635e1","http://resolver.tudelft.nl/uuid:d62aed59-364c-4e91-90ff-3d61ed5635e1","Understanding the role of IoT end users in Miria-Like bot remediation","Verstegen, Susanne (TU Delft Technology, Policy and Management)","van Eeten, Michel (graduation committee); Hernandez Ganan, Carlos (graduation committee); Cunningham, Scott (graduation committee); Turcios Rodriguez, Elsa (mentor); Noroozian, Arman (mentor); van Beusekom, Dennis (mentor); Delft University of Technology (degree granting institution)","2019","Malicious software such as botnets are a threat to society and increasingly so through Internet of Things (IoT) devices. The large volume, pervasiveness and high vulnerability of IoT devices make them low hanging fruit for malicious actors. Currently, the biggest threat for insecure IoT devices is Mirai, a botnet which is deployed for DDoS attacks. Home users often fail to detect and resolve Mirai on their IoT devices. For this reason, Internet Service Providers (ISP) increasingly take efforts to increase remediation. Sending their infected customers a notifications containing cleanup instructions is currently the most feasible measure on a large scale. However, previous studies point out that it is not clear how people process these notifications, if they comply with it and how this effects the remediation rate and speed. The central research question of this study is ‘What is the role of IoT device end users in Mirailike bot remediation?’. We have conducted an eight-week experiment at the KPN Abuse Desk that notifies customers about abuse incidents. 177 Mirai-infected consumers have been randomly assigned to a walled garden notification (i.e., a quarantined environment), an e-mail notification, or control group. All subjects within the experiment have been tracked for two weeks to estimate the infection time and are contacted afterward for interview purposes. Male consumers and consumers younger than 54 years possess relatively more often a Miraiinfected device compared to other consumers. Both e-mail and walled garden notifications are effective in reaching consumers, informing them and encouraging them to take action. The majority of consumers do not follow the recommendations provided by the notification. In contrast, the number of actions that are performed while not mentioned in the notifications is remarkably high. Since many consumers asked for additional help, we conclude that consumers appear don’t have a full understanding of how to tackle the problem. In the control group, several consumers remediated Mirai unintentionally. However, these cases do not explain all observed remediation. Using two survival analysis modeling techniques, we find that consumers placed in a walled garden have a 29% to 85% shorter infection time than other consumers. We conclude that there is a discrepancy between stated behavior and the actual behavior of consumers. Although we cannot observe all cleanup efforts of consumers, we observed that awareness of the Mirai-infection and the intention to comply with the recommended actions influence that unobserved behavior. Gender also influences the unobserved behavior. Women clean up their device quicker than men while their statements during the interviews contradict this. One explanation is that women may unintentionally clean up their device. We conclude that age, consumer market, device type and customer satisfaction have no significant influence on remediation. We believe that it is unlikely that all unexplained remediation can be attributed to the unobserved behavior. We thus cannot explain all observed remediation from the user perspective. Therefore, we argue that future work must also focus on the attacker perspective. Since we only observed Mirai-infections, we cannot exclude the possibility that competing malware confiscated infected devices within our experiment. In addition, novel Mirai variants may have evolved scanning behavior which obstructed proper detection of infected bots.","Mirai; IoT; User behavior; Cyber security; Survival analysis","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","","52.242531, 5.164305"
"uuid:dcf5ef90-7533-48e4-9c86-1aa03c9e4b4a","http://resolver.tudelft.nl/uuid:dcf5ef90-7533-48e4-9c86-1aa03c9e4b4a","Efteling: Innovative, while authentic and customer centric","Wu, Hoi San (TU Delft Industrial Design Engineering; Efteling)","van den Hende, Ellis (graduation committee); Cankurtaran, Pinar (graduation committee); Prins, Willemijn (mentor); Delft University of Technology (degree granting institution)","2019","There is a shift to the experience economy. Customers are increasingly craving unique experiences and authentic brands; brands that are real, sincere. Additionally, technological developments are booming and can help enhance these customer experience. Efteling employees have lots of ideas to innovate technically. This master thesis explores how the Efteling can balance these changing factors with the question: How can the Efteling balance technological innovation, without losing sight of the brand authenticity of the Efteling and meet the expectation of the customers? Different physical, digital and phygital (physical + digital) technological innovations were researched via in-depth interviews with Efteling employees and guests. Comparing the results gave insights in points for improvement in the current authenticity process. Physical innovations are doing well with the current guidelines and there are some chances to improve in digital and phygital innovations. Creative workshop sessions revealed criteria for how to improve these points. All insights from the above mentioned research, combined with literature and Efteling insights revealed recommendations on how the current authenticity guidelines of the Efteling can be improved, and applicable for all three categories technological innovation, and not only physical innovations. Recommendations for what the current authenticity guidelines of the Efteling should contain: 1. Build everything for eternity, from real materials Keep the changing context and consumer needs in mind 2. Make it look like it has been around forever Immerse the guests in the magical world of the Efteling 3. Highlight a fragment of a story Use implicit storytelling to trigger the imagination of the guests 4. Look for it in the little things too Beautiful finishing and details are important 5. Strive for perfection Have a consistent Efteling style throughout all innovations 6. Use organic forms: think in curved lines Stimulate wondering and exploring, in a Pieck style 7. Use well-known fairy tales and stories Create an experience that triggers nostalgia 8. Let technology facilitate the story Technology should be purposeful and easy for the guests 9. Guard the heritage Be inspired by the founders Pieck and Reijnders","authenticity; customer experience; technological innovation","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:0c90ee45-aa2e-4e9d-8091-d74046d11ef1","http://resolver.tudelft.nl/uuid:0c90ee45-aa2e-4e9d-8091-d74046d11ef1","Innovation in Internet of Things: Designing an innovation process for Hilti to identify and protect business-relevant ideas in the area of Internet of Things","Hochuli, Silvio (TU Delft Industrial Design Engineering; TU Delft Product Innovatie Management)","Kortuem, Gerd (mentor); Coelen, Jeroen (graduation committee); Vetter, Marc (graduation committee); Delft University of Technology (degree granting institution)","2019","The construction industry is undergoing a significant change driven by the emergence of new technologies. Digitalization is transforming the sector with the Internet of Things (IoT) being one of its core enablers. As a leading multinational organization that provides cutting-edge tools, technologies, software and services for the global construction sector, Hilti is responding to this change by shifting from a product-oriented focus to become a more solution-oriented company. One essential factor of this transition is the adoption of the IoT technology to provide new solutions to address the customers’ needs in the digital future. Thus, Hilti needs to identify and seize opportunities in the field of IoT. The purpose of this graduation thesis is to enable Hilti to identify new ideas in the area of IoT and protect them with intellectual property rights to enable long-term differentiation. A good overview of the IoT patent landscape will provide clarity to spot new business opportunities systematically. The project aims at developing an innovation process that captures ideas from within the company. A qualitative user research was conducted uncovering several pain points in the current process. The loss of ideas and the lack of quality of ideas were found to be the biggest challenges that are hindering innovation from happening. The findings were contrasted with literature, which pointed out the importance of the development of an abstract idea to become more concrete, in order to derive value from or protect it. <br/> In an iterative process, a solution was developed that addresses the identified pain points. The outcome is a combination of a sequential and iterative innovation process structured into four phases, including ideation, collection, assessment and protection of ideas. The basic concept of the process is the validation of assumptions, for which a tool was developed that facilitates this and acts as the main touchpoint throughout the process. The process is visualized in a process blueprint providing detailed information about the different components and interactions. An implementation plan was developed, giving suggestions for the next steps to be taken to operationalize the process. <br/> The project provides a feasible solution for Hilti to identify and protect new ideas in the area of IoT. For the implementation, it is recommended to give much attention to the guidance and training throughout the process to ensure its correct use.","Hilti; Internet of Things (IoT); Innovation process; Process design","en","master thesis","","","","","","","","","","","","Strategic Product Design","","47.179142, 9.52338"
"uuid:ed243ae1-af75-41f4-9ba8-970132468391","http://resolver.tudelft.nl/uuid:ed243ae1-af75-41f4-9ba8-970132468391","Foxpat: Training simulator for Cementless Oxford Partial Knee Replacement","Gurram, Nitin (TU Delft Industrial Design Engineering)","Goossens, Richard (mentor); Wu, Jun (mentor); Delft University of Technology (degree granting institution)","2019","The learning curve of novice surgeons takes about 25 surgeries to be proficient at the knee replacement procedure. So it is not just enough if we design efficient and more ergonomic surgical tools, it is also important to provide a learning platform for them to get better before they operate on a real patient. Although many training simulators are available to train different surgical procedures, most of them are digital trainers that simulate the surgical process in a virtual world. There are physical training simulators available in the market for surgeries like laparoscopy and arthroscopy, but not for arthroplasty. FOXPAT is a reusable training simulator for knee arthroplasty surgery. Unlike the existing digital simulators, FOXPAT is a physical simulation of a patient knee with integrated sensors. The training tool lets novice surgeons use actual instruments that are used in the operating theatre. Besides providing a realistic experience of the surgical procedure, the sensors track the usage of tools provide feedback to the surgeons on their outcome. <br/>Arthroplasty being an invasive surgical procedure, any training model will be destroyed in every training session. This makes it difficult for any manufacturer to provide a reusable design that the novice surgeons can train multiples of times. Foxpat can promise such a long term reusability. Novice surgeons can practice the whole surgical procedure of knee replacement before they try on an actual patient. This includes letting surgeons performing actual cutting, drilling and milling procedures. By just replacing a set of low-cost polyurethane bones after every practice session, Foxpat will be ready for a next practice session. As the product is used for training the novice surgeons, these sessions take place either in a conference hall or in a hospital. A training support team or a local technician in the hospital helps to set up the device. <br/>During this project, two iterations of working prototypes were developed and tested before reaching the final design. This design is now ready to be manufactured in small quantities of 50 pieces per year and requires another iteration for large-scale production.<br","Medical device design; Medesign; orthopedic surgery; Knee implant; Training; learning curve; Manufacturing","en","master thesis","","","","","","","","2020-08-20","","","","Integrated Product Design | Medisign","Hipp",""
"uuid:812be430-79fb-4900-a0e2-b0bc9c3d804b","http://resolver.tudelft.nl/uuid:812be430-79fb-4900-a0e2-b0bc9c3d804b","Redefining Integrated Assessment Models: An Exploratory Approach Towards Robust Climate-Economic Policies","Lingeswaran, Shajeeshan (TU Delft Technology, Policy and Management)","Storm, Servaas (mentor); Kwakkel, Jan (mentor); van Beers, Cees (mentor); Delft University of Technology (degree granting institution)","2019","Integrated Assessment Models (IAMs) are aiming to shed light on the cost-benefit of climate mitigations. However, current IAMs are depicted with a wide range of weaknesses. Next, to questionable assumptions of model functions, such as the damage function, IAMs are inadequate at addressing deeply uncertain parameters, such as the equilibrium climate sensitivity (ECS). Various research has been conducted in addressing uncertainties by utilizing stochastic dynamic programming or approximate dynamic processing. However, two crucial aspects were not considered in these studies. First, most researchers utilized optimization to determine the optimal policy as their decision analytic method for the risk analysis. Yet optimal strategies are highly sensitive to uncertainties and thus, they lose their prescriptive value in a deeply uncertain environment like in the field of climate economics. Furthermore, most economists described the deep uncertainties of IAMs model by a normal distribution, at best by a lognormal distribution. However, Weitzman (2009) has shown in his Dismal Theorem, that deep “uncertainty in the form of fat tails is, at least in theory, capable of swamping the outcome of any CBA”. This research addresses both aspects by utilizing the Exploratory Modelling and Analysis (EMA) framework on the Dynamic Integrated Model of Climate and the Economy (DICE) of the Nobel prize winner Nordhaus. By translating the DICE model into a stochastic simulation model and conducting an EMA approach, this research demonstrates the importance of defining robust strategies against the disproportional risk in the fat-tails.","Intgrated Assessment Models; Decision-Making; Deep Uncertainty; Fat-tailed Distributions; Robust Optimisation","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:3d48f0f2-259f-42e8-bf18-689270f53a10","http://resolver.tudelft.nl/uuid:3d48f0f2-259f-42e8-bf18-689270f53a10","Spoofing detection in a loosely coupled GNSS and IMU system via Synthetic Arrays","Biserkov, Kostadin (TU Delft Electrical Engineering, Mathematics and Computer Science)","van der Veen, Alle-Jan (mentor); Uysal, Faruk (mentor); Bos, Andre (mentor); Delft University of Technology (degree granting institution)","2019","With the ever-expanding need for accuracy in the world of navigation, Global Navigation Satellite Systems(GNSS) such as GPS and Galileo have become the primary option around the world. As such, the potential damage that can be caused by malicious tampering with the receivers continues to grow. One such threat, known as Spoofing, comprises of transmission of altered GNSS signals to a target receiver(s). This process leads to false positional and/or time data on the receiver's end. Spoofing has been a topic of discussion for roughly two decades. With many theoretical approaches to its detection, this work focuses on the Angle of Arrival technique via the construction of a synthetic array from a single moving element, aided by positional information provided by Inertial Measurement Unit (IMU). This method relies on the periodic nature of the L1 signal, and focuses primarily on the case of GPS as an example. Using simulation and sample data, the possibility and limitations of constructing virtual antenna arrays is explored. It is shown that despite being viable for low number of sources during the simulation, the complexity of signal propagation within the real world implementation of GNSS system renders this technique inoperable in its first iteration.","GNSS; Spoofing; IMU; Synthetic arrays","en","master thesis","","","","","","","","","","","","","",""
"uuid:067709d8-fbb0-4dad-9f85-e08df08db570","http://resolver.tudelft.nl/uuid:067709d8-fbb0-4dad-9f85-e08df08db570","Robust Policies: An Exploratory Study on the Energy Transition of the Dutch Built Environment Sector","Hupkens, Mark (TU Delft Technology, Policy and Management)","Blok, Kornelis (graduation committee); Pruyt, Erik (mentor); Slob, Adriaan (graduation committee); Delft University of Technology (degree granting institution)","2019","This study has been performed in cooperation with TNO and set out to analyze the robustness of Dutch energy transition policies under deep uncertainty for the scope of the built environment sector. Open data is gathered which is used in a System Dynamics model to allow exploration under deep uncertainty. The Adaptive Robust Design methodology has been adopted to understand how energy transition policies can be designed to be more robust under deep uncertainty for the period of 2019-2050. Subsidy-based policy variants have been created, inspired by promising policy instruments from current policy documents. Static, dynamic and mission-oriented policy variants have been simulated to show effects on annual CO2-eq emissions, renovated houses and awarded subsidies. Adaptive policies have shown to be promising to curb undesired influence of uncertainties. However, this study showed that subsidy percentage, alone, does not ensure that policy targets for 2050 are reached. Policies should also ensure ample increase in renovation capacity to keep up with rising demand. The limitation of merely subsidy-based policies resulted in less significant differences between the policy variants. To benefit of the adaptive nature of the climate plan, policies should include ample adjustment mechanisms within policies to realize their goals by adapting to changing circumstances.","Exploratory Modelling and Analysis; deep uncertainty; energy transition; built environment","en","master thesis","","","","","","","","","","","","","",""
"uuid:575e83e5-8b0f-4a9c-b776-2a2c7eda5361","http://resolver.tudelft.nl/uuid:575e83e5-8b0f-4a9c-b776-2a2c7eda5361","Solving the intercontinental integrated LTL loading and routing problem","Aammari, Loubna (TU Delft Electrical Engineering, Mathematics and Computer Science)","Yorke-Smith, Neil (mentor); Delft University of Technology (degree granting institution)","2019","In this research we look into the integrated LTL routing and loading problem. A review from previous research shows that this integrated problem is novel. All previous literature that researched into an integrated routing and loading problem focused on the loading and vehicle routing problem (3L-CVRP). Different heuristics have been tested on similar problems where a loading and routing problem were integrated. However, a classical decomposition was not tried in any found literature on this subject. In this research we tried different<br/>decomposition techniques to solve the integrated problem. The results show promising results.","routing; container loading; decomposition","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:7a556b44-9a4d-4573-b403-62f3a552845f","http://resolver.tudelft.nl/uuid:7a556b44-9a4d-4573-b403-62f3a552845f","Geography based bi-facial cell design for low LCoE","Ramesh, Santhosh (TU Delft Electrical Engineering, Mathematics and Computer Science)","Weeber, Arthur (mentor); Janssen, Gaby (graduation committee); Delft University of Technology (degree granting institution)","2019","The Levelized Cost of Electricity (LCoE) produced by PV systems is determined by yield (kWh) and cost of the system. Reducing the LCoE of the solar power can be achieved either by increasing the yield or by reducing the cost. The yield of bi-facial PV systems is promoted by high efficiency and a high bi-faciality factor.<br/><br/>Yield due to the front efficiency depends on the parameters ($V_{oc}$ ,$I_{sc}$ and $FF$) that contribute to that efficiency. It was found that the different parameter helped maximize the yield in each climatic condition. For low irradiation and low operating temperature zones, yield improved when the product $I_{sc} \times V_{oc} $ was increased at the cost of the $FF$. While at equatorial tropical climates with fairly high temperatures, yiele improved when $V_{oc}$ was increased at cost of $I_{sc}$ and $FF$. For high irradiance and high temperature desert climates, yield improved when the product $ V_{oc} \times FF $ increased at the cost of $I_{sc}$. Designing cells to suit the operating conditions of the region improved yield per $W_{p}$ thereby reducing the LCoE.<br/><br/>A large part of the cell processing cost is in the metal (silver) used on the cell. The amount of silver is usually optimized for the cell efficiency (i.e. power in W) delivered under standard test conditions, i.e. a solar irradiance of 1000 W/m2. When the metal patterns were optimized for the yield at a climatic zone, results showed that up to 50\% of silver per cell could be saved (From a reference cell considered). Up to 5\% LCoE improvement was theorized. <br/><br/>The irradiance on the bi-facial modules varies with different system orientations (Equator facing, East west tilted, East West Vertical ). The metal patterns were also optimized for the different system orientation at a climatic condition. The results showed metal patterns can be made more thin when designed for vertical systems.<br/><br/>Advanced c-Si cell concepts try to reach the theoretical efficiency by employing different passivation technologies, grid patterns, etc. Each cell technology will have advantage over the other. This makes it interesting to study if we can attribute a cell concept to a climatic condition where it will outperform other cell concepts.","Bifacial; yield maximization; simulation; metal pattern optimization; PV Systems","en","master thesis","","","","","","","","2019-12-31","","","","","",""
"uuid:6ce5a7a8-ccba-422d-99ff-e5159773ba5f","http://resolver.tudelft.nl/uuid:6ce5a7a8-ccba-422d-99ff-e5159773ba5f","Flexibility in Future Power Systems with High Renewable Energy Penetration","Hernandez Serna, Ricardo (TU Delft Electrical Engineering, Mathematics and Computer Science)","Bauer, Pavol (mentor); van der Blij, Nils (mentor); Ramirez Elizondo, Laura (graduation committee); Delft University of Technology (degree granting institution)","2019","Future energy systems will present high penetrations of variable renewable energy (VRES). Due to the uncertainty that is related to the intermittency of wind and solar energy, and loads such as electric vehicles, the need for flexibility will be higher. This research identifies the possible sources of flexibility in a power system. Firstly, using statistical errors and probability theory, the required reserves of flexibility that a system needs to ensure a proper operation are quantified. Secondly, with the increase of VRES, the amount of synchronous generators is expected to decrease. This will mean that the inertial response used to keep a stable frequency will be reduced. On this paper, a method to quantify inertia and the concept of minimum required reaction time of flexibility are explained. Finally, an optimization problem is proposed to allocate the different types of flexibility taking into consideration their technical capabilities. This problem minimizes the cost of reserving different flexibility sources in a distribution grid.","Flexibility; Power Systems; Optimization; Renewable Energy","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:9df62bd5-1615-45ee-ba95-85d673199b2c","http://resolver.tudelft.nl/uuid:9df62bd5-1615-45ee-ba95-85d673199b2c","Actuator for oral care in edentulous elderly patients","Lluch Sicard, Salvador (TU Delft Industrial Design Engineering)","Willemen, A.M. (mentor); Goossens, R.H.M. (graduation committee); Domhof, Daan (graduation committee); Delft University of Technology (degree granting institution)","2019","There are currently no technological options in the market for the oral care of edentulous population. Dental Robotics, a company already involved in the production of dental care devices for elderlies, is interested in new technological solutions to attend this sector. The design is challenging as it has to meet several requirements: 1) be built upon an existing platform (the Air 1 handle), 2) to demonstrate potential for efficiently clean different mouth morphologies, 3) to use an actuator that requires minimal maneuver and is easily accepted by patients and be practical for nurses, and all these while showing manufacturing feasibility and production scalability. The methodology followed a combination of design thinking and lean startup, meaning a human centered, technology-based iterative and integrative process of prototyping and test. Through this progressive development, diverse strategies were applied, including literature research, field work observations and empathizing with the problem, comparison of market-available alternatives, exploration of materials and prototyping processes, evaluation of effectiveness and acceptance of different design versions, image analyses to evaluate cleaning capacity, manufacturing process, etc. The result is a validated prototype that meets the technical requirements and represents the optimal solution within the explored options; however, future progress could result from optimizing the motion of the Actuator, improve design features to make the assembly easier, explore different arrangements of tufts textures to increase comfort, increase the sample of mouth morphologies to better represent the edentulous elderly population in The Netherlands, to test the effect of the gum cleaner with Laser Doppler Flowmetry to find out if it could stimulate blood flow (Irrigation) on the gingiva, and for how long, and evaluate the long-term impact of this device in the reduction of Residual Ridge Resorption clinical tests. If proven, this could be an added value offered by the company. The proposal for oral care in edentulous elder patients developed in this work proved promising as market product after further performance and manufacturing process refinements.","healthcare design; Edentulism; Med-Tech; Oral care","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:da06f359-3720-4c4a-b10d-d510a49450e7","http://resolver.tudelft.nl/uuid:da06f359-3720-4c4a-b10d-d510a49450e7","Investigation into the DC-DC Converter for the PV Integrated Bidirectional EV Charging System","Zhou, Mengxi (TU Delft Electrical Engineering, Mathematics and Computer Science)","Bauer, P. (mentor); Qin, Z. (mentor); Rueda, José L. (graduation committee); Delft University of Technology (degree granting institution)","2019","With the rapid development of the economy and the continuous innovation of technology, the automobile industry is developing at a high speed. While providing convenient transportation and improving the efficiency of production and living, it has also caused a series of problems such as the energy shortage and environmental pollution. Electric vehicles (EVs) are getting more and more attention and support because of their unique advantages such as the energy saving and zero emission. Once the electric vehicle can charge from the clean and sustainable energy source such as the solar and wind energy, it can be an environment-friendly mode of transportation. Therefore, the photovoltaic (PV)<br/>integrated EV charging system appears in recent years. In the meanwhile, ABB is also interested in finding a way to combine their PV products and the EV chargers to make a more compact and efficient PV integrated EV charging system.<br/>A possible solution of making a more compact PV integrated EV charging system is to use the multiport converter which can integrate the separated DC-DC converters. However, the traditional multiport converter needs a large number of active switches and the control of the whole converter is complex. Moreover, the zero voltage switching (ZVS) operation cannot be achieved easily in the traditional multiport converter. Therefore, a dual boost integrated dual active bridge (DAB) converter used for the PV integrated bidirectional EV charging system is investigated in this master thesis project.<br/>This master thesis is the first step to investigate the dual boost integrated DAB converter working with a large output voltage range, which can be compatible with the new CHAdeMO standard (CHAdeMO 2.0) regarding the charging voltage range and make the whole PV integrated EV charging system more compact and efficient. The investigation is divided into three parts which are: the working principle and control analysis, the power loss modeling and analysis and the experimental verification tests.<br/>First of all, the specifications of the converter are clarified, the circuit structure, the working principle of the two interleaved boost converters in the primary side and the working principle of the whole converter are analyzed. Secondly, the parameters of the converter are calculated according to the specifications and all the equations in terms of the voltage, the current and the output power are<br/>deduced. The power modes and the control structure of the converter are also introduced. Afterwards, the soft switching characteristics of the switches and the circulating power in the dual boost integrated DAB converter are investigated by considering the DC bus voltage, PV voltage, and the EV battery voltage, and then the ZVS region is enlarged by applying the DC blocking capacitor voltage control. Besides, the transistor candidates are chosen and the power loss model and the thermal model of the candidates are built. The loss breakdown, the loss ratio and the thermal performance of the switches are analyzed and evaluated.<br/>An analysis tool which can analyze the voltage and current at different points, the output power, the soft switching region and the circulating power of the dual boost integrated DAB converter is developed in Mathcad. This analysis tool is not only suitable for this project but also can be used to do other customized designs, which helps to decrease the time and cost for the development. The simulation model including the control loop and the thermal model of this converter is built in PLECS to check the feasibility of the design. Finally, a test bench is built and the experimental tests are implemented to verify the analysis and the simulation results.","Multiport DC-DC converter; EV charging system; SSPS plus PWM modulation","en","master thesis","","","","","","","","2021-08-31","","","","Electrical Engineering","",""
"uuid:8161421d-c86e-4a9a-b768-1b4fd3a1797b","http://resolver.tudelft.nl/uuid:8161421d-c86e-4a9a-b768-1b4fd3a1797b","The Influence of Geometrical and Structural Properties of Wind Turbine Blades on Blade Bearings","Baust, Sebastian (TU Delft Aerospace Engineering)","Teuwen, Julie J.E. (mentor); Delft University of Technology (degree granting institution)","2019","In this thesis the influence of the geometrical and structural rotor blade properties on the pitch bearing loads and deformations is investigated by developing a scalable finite element rotor blade model in Ansys Classic and analyzing the impact of different blade designs. The research aim of this thesis is to determine blade properties which are critical for the bearing design, so these critical parameter can be considered by blade designer in future blade<br/>designs to improve the performance of the pitch bearings. For this purpose the research question is, which rotor blade parameter have a significant impact on the bearing and which blade designs are favourable for the loads and deformations of the bearing.<br/><br/>To answer the research question, this thesis investigates several blade properties, including the number and position of the shear webs, the width and arrangement of the spar caps, and the overall bending stiffness of the blade. The author hypothesizes, that the shear web and spar cap configurations of different blades have a significant influence on the rolling element forces and deformations of the bearing. This assumption applies especially to flapwise loads. For edgewise loads no significant influences are expected.<br/><br/>For the investigation many blades with different properties are needed. For this purpose, this thesis presents one method of developing a scalable rotor blade model, which is used to efficiently design many blades with different shear web and spar cap configurations, and different bending stiffnesses. The different blades are then assembled to the bearing for the parameter study. To perform the study as close as possible to reality, support structures like a wind turbine rotor hub and a stiffener plate on the bearing are also considered.<br/><br/>The results reveal, that neither the shear web configuration, nor the spar cap configuration have a considerable influence on the bearing loads and deformations. The results contradict the hypotheses of the author and suggest, that it does not make sense to include the bearing characteristics in the blade design process. However, to verify this conclusion, future work is necessary, as some phenomena present in current blade model can not be explained conclusively.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:b73a29d6-cd62-425d-b33e-402574f676be","http://resolver.tudelft.nl/uuid:b73a29d6-cd62-425d-b33e-402574f676be","Development of a 3D Image Analysis Method to Measure Blast-Induced Fragmentation at the Leveäniemi Mine","Taylor, Renske (TU Delft Civil Engineering and Geosciences)","Buxton, M.W.N. (mentor); Soleymani Shishvan, M. (graduation committee); Smal, I.V. (graduation committee); Sormunen, Matti (graduation committee); Wimmer, Matthias (graduation committee); Delft University of Technology (degree granting institution)","2019","The first size reduction stage in open pit hard rock mining is blasting and is fundamental for mineral resource extraction as it enables transportation of the rock. Consistent frag-mentation results are preferable as it can ease the loading, hauling and crushing stages. Fragmentation analysis assists in identifying areas where similar blast results appear when comparable drill and blast designs are used. Subsequently, drill and blast domains can be defined for the Leveäniemi mine to ease the drill and blast design process.<br/><br/>Measuring fragmentation has been continuously researched over the past years. Image analysis methods were developed as it minimised disruption to production and provided a reasonable indirect estimation of particle sizes. So far, research was focussed on 2D image analysis. However, by adding a 3rd dimension, some limitations can be overcome that were experienced when using only two dimensions. Therefore, the potential of 3D image analysis of blasted rock, loaded in haul trucks, is of interest. By evaluating truck loads, the muck pile is better represented in comparison to measuring a whole muck pile. This is one of the few studies done until now on 3D image analysis in open pit mining, analysing material in loaded trucks.<br/><br/>A 3D image analysis field test was executed to measure blast-induced fragmentation in a production environment at the Leveäniemi mine. The aim was to gain a clear understand-ing of the factors contributing to an optimal blast result and to establish blast domains. The test setup consisted of an image acquisition system, photographing truck loads from above using two cameras that were triggered by a laser. RFID truck markers were com-bined with Minestar data to identify the origin of the truck. Truck loads were analysed using software developed by LKAB and 3GSM, constructing 3D models and automatically delineating particles to analyse fragmentation. No pre- or post-processing of the images or delineation results have been done. Drill and blast, and muck pile shape parameters were acquired as well.<br/><br/>The results show x50 particle sizes ranging from 5 to 56cm and x80 ranging from 20 to 150cm. Care should be taken when interpreting these results due to the limited amount of data analysed and bias in the measurements and software. Fines are underestimated and correct particle delineation occurred on average in 42% of each load. The limited amount of data resulted from the practical problems arising during data acquisition. Con-tinuous data acquisition of images was not achieved.<br/><br/>Correlation of fragmentation to drill and blast, or muck pile shape parameters was not achieved due to the challenges faced. 3D image analysis of truck loads proved to have potential but requires many modifications and developments to the system and software to achieve continuous data acquisition. A focus on image quality and the practicalities of the system is recommended. Continuous data acquisition is required when using frag-mentation analysis for establishing blast domains.<br/><br/>Comparable and repetitive measurements are the main prerequisites for choosing a method to analyse fragmentation for the purpose of defining blast domains. Hence, other methods like using drones to analyse whole muck piles after blasting should be consid-ered, though it would statistically be less representative. For the Leveäniemi mine, it is recommended to achieve geotechnical domains including joint spacing and orientation before a follow-up study is started on blast domains. Additionally, the development of this method should be finalised, or an alternative is recommended.","3D image analysis; Fragmentation; Drilling and blasting; Open pit mining; Blast domains","en","master thesis","","","","","","","","","","","","Applied Earth Sciences | European Mining Course","","67°39, 21°03"
"uuid:b79f3041-ca7f-4e07-b926-8392d828890e","http://resolver.tudelft.nl/uuid:b79f3041-ca7f-4e07-b926-8392d828890e","Waste heat recovery from quenching towers","Moussa, Salah (TU Delft Mechanical, Maritime and Materials Engineering)","Infante Ferreira, C.A. (mentor); Vlugt, T.J.H. (graduation committee); Tummers, M.J. (graduation committee); van der Velde, Tom (graduation committee); Delft University of Technology (degree granting institution)","2019","Steel plants are one of the largest sources of waste heat. Waste heat recovery throughout the steelmaking process is not a new phenomenon. One of the sources of waste heat is found in the coke plant. Cokes are an essential part of steel production. During the coking process hot cokes are cooled down. Most coke plants in the world traditionally use water, so called wet quenching. In this process, all the heat put into the cokes is dispersed to the environment as steam. This waste heat source has huge potential. The goal of this study is to find a method to utilise this waste heat and to evaluate this method’s technical and economic feasibilities.<br/>The chief issue that must be tackled in a design is the fact that the steam generated during a quench is close to atmospheric pressure. Another issue to be solved is that of the solid particles suspended in the steam. Several potential designs were produced to use the steam from a quench to recover the waste heat. Based on several criteria, the design using the Synext engine was found to be the superior one and was developed further.<br/>This design is divided into three sections, capture, cleaning and storage. A water wall and capture valve are used to capture the steam. An impaction and a cyclone separator are used to rid the steam of the solid particles to the extent that their detrimental effect to the Synext engine is minimised. The sepa-rators’ dimensions are derived based on the steam input and Synext engine requirements. The steam is then stored in a storage vessel.<br/>A Simulink model of the design is composed to simulate the process and evaluate its efficiency and technical feasibility. The model’s findings show that the outputs for certain cases require unreasonable dimensions for the design. The economic analysis showed the designs costs make it an unlucrative investment.","Steel; Waste heat recovery; Coke; Quenching tower","en","master thesis","","","","","","","","2022-08-20","","","","","",""
"uuid:53f1eab4-e01b-4fd6-aca3-536b5260bdbc","http://resolver.tudelft.nl/uuid:53f1eab4-e01b-4fd6-aca3-536b5260bdbc","Data-driven engine state monitoring: Applying multivariate statistics and machine learning to fault detection and isolation.","Drakoulas, Michail (TU Delft Mechanical, Maritime and Materials Engineering)","Delft University of Technology (degree granting institution)","2019","The technological advances of the last decades eventually have led to systems with growing complexity. As a consequence, the task of supervising their condition has become increasingly challenging. Especially for the case of turbocharged diesel engines, this task is even more difficult due to the interaction of the turbocharger with the engine. An effective monitoring system that promptly detects abnormal behavior and provides information regarding the state of the engine is essential to prevent failures and/or system shutdowns. With this paper, the author is proposing a data-driven approach to achieve this objective and then evaluates its performance with the help of a simulation model of a four-stroke diesel engine.<br/> The proposed strategy focuses on evaluating the state of the engine based on a limited number of signals collected during its operation. It applies multivariate methods to analyze the multidimensional collected measurements. At the core of this approach, there is a method known as Independent Component Analysis (ICA), which allows expressing the data in a lower-dimensional space that explains most of the observed variation. This sub-space defined by the dimensionality reduction model makes possible to extract unique features from new deviating observations, thus facilitating the detection and isolation of a problem. Fault detection is achieved with multivariate statistical techniques based on ICA, while fault isolation with the help of a classifier that evaluates the extracted features and attempts to recognize a previously encountered fault pattern.<br/> The application of the proposed monitoring strategy on the simulation model of the case study engine indicated a very robust performance regarding the detection and isolation of the modeled faults. This can largely be attributed to the effectiveness of ICA at exposing abnormal behavior of the system. To the best of the author's knowledge, ICA has not been used in similar applications, thus this work opens the way to further research such data analysis techniques for the purpose of supervising the operation of real engines.","","en","master thesis","","","","","","","","2024-08-27","","","","","",""
"uuid:0ca8238f-30c6-4f0f-8f1f-a7b2056d3122","http://resolver.tudelft.nl/uuid:0ca8238f-30c6-4f0f-8f1f-a7b2056d3122","Applicability Study of Artificial Intelligence to Forecast New Infrastructure Project Introduction Based on The Decision-Making Duration by The Government: Case Study: Public Road Infrastructure in the Netherlands","Yosep Pandji Hario Wicaksono, Pandji (TU Delft Civil Engineering and Geosciences; TU Delft Technology, Policy and Management)","van Wee, Bert (mentor); Annema, Jan Anne (mentor); Rellermeyer, Jan (graduation committee); Nuijten, Jeroen (mentor); Delft University of Technology (degree granting institution)","2019","This research aims to provide an insight about the applicability of Artificial Intelligence (AI) in making a forecast about decision-making duration of a new infrastructure project by the government during infrastructure planning procedure prior to the market introduction. The decision-making duration in this research is the duration which the government requires to decide on the preferred alternative for a certain infrastructure problem. By identifying the likely timeframe of a new infrastructure project introduction from the government, the construction firms can prepare itself better by allocating its resources accordingly to the profile and requirement of the upcoming projects. This research decided to explore further about the applicability of AI to forecast the duration within this context based on the potentials of AI that shown by previous researches. <br/><br/>With regard to the scope of the research, the Netherlands construction industry is chosen with the perspective of a construction firm, which is BAM Infra BV. With regard to the legal framework of the industry, Dutch Infrastructure Planning Act (Tracewet) is the main reference of the research, which acts as the foundation of the proposed forecasting model. Lastly, the research focuses on the road infrastructure project from the Netherlands government, which falls under Tracewet. <br/><br/>This research applies a combination of three methods to fulfill the aforementioned objective, which are literature study, experts interview, and model simulation. This research is divided into four main steps to answer the main research question: [1] AI Theory and System Design for Forecasting, [2] Data and Variable Exploratory Study, [3] AI Forecasting Model Implementation, and [4] Result Discussion. <br/><br/>The result shows that the AI technology, specifically ANN, is not applicable to be used as a forecasting model to predict a new infrastructure project introduction based on the duration of decision-making on the preferred design alternative by the Dutch Government. Two approaches have been explored in this research, namely the ANN regression model and ANN classification model. It is found that neither models produce a reliable prediction, which indicated by high RMSE and low model accuracy on the dataset. This reliability is evaluated by interviewing BAM’s commercial manager about the acceptable range of error for the prediction made.<br/><br/>The optimization effort has been done to address these results by iterating several different variables combinations into the models. These optimization results revealed that some factors influenced the performance of the models. A further discussion has been done on these factors; namely number of data entries, input variables influence, and representation of the world by the model. It is found out that the combination of these factors has an impact to a certain degree on the model performance. Besides that, a comparison with other conventional methods (i.e., Multiple Linear Regression and Logistic Regression) has been done. The result shows that the ANN models do not perform better than the conventional methods being compared in term of model prediction accuracy, which transcends into its ability to handle imprecise data and non-linear approach. This comparison result indicates the importance of dataset quality over the decision of a forecasting model to be used.","","en","master thesis","","","","","","","","","","","","","",""
"uuid:4cce916e-4841-4a2d-8473-1d1b7e07ba28","http://resolver.tudelft.nl/uuid:4cce916e-4841-4a2d-8473-1d1b7e07ba28","Personalising patient education for lung cancer patients","Mui, Claudia (TU Delft Industrial Design Engineering)","Snelders, Dirk (mentor); Dekkers, Tessa (mentor); von Meyenfeldt, Erik (mentor); Delft University of Technology (degree granting institution)","2019","Personalising patient education is an important aspect that is needed for patients to become active in decision making and their treatment. Standardised methods are not enough and personalisation can make an improvement in healthcare by focussing more on the patient. This report focusses on patient education at the Albert Schweitzer Hospital from the perspective of healthcare professionals (HCPs). They are the experts in their field and in how patient education is given. Interviews were held with HCPs and observations of the consultation took place to analyze the current patient journey and process of patient education. The results of this research are visualisations of the current process of patient education, insights and opportunities to improve patient education, and a proposal on how to personalise patient education. Patient education can be personalised by personalising the methods, information and dialogue. This should start right at the beginning of the patient journey so that HCPs can focus on putting the patient’s goal as the priority throughout care. Personalised information will keep patients engaged and HCPs can provide personalised care based on their characteristics. This will create a dialogue between patients and HCPs to make shared decisions. Patients that have participated in decision making will be motivated to work on their set goal and understand what to expect, which will improve their satisfaction.","personalisation; patient education; lung cancer; patient-centred care; shared decision making","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:30846529-9080-4945-8502-dc962ec00bf3","http://resolver.tudelft.nl/uuid:30846529-9080-4945-8502-dc962ec00bf3","A Human-Machine Approach to Preserve Privacy in Image Analysis Crowdsourcing Tasks","Shriram, Sharad (TU Delft Electrical Engineering, Mathematics and Computer Science)","Bozzon, Alessandro (mentor); Mauri, Andrea (mentor); Houben, Geert-Jan (graduation committee); Finavaro Aniche, Mauricio (graduation committee); Delft University of Technology (degree granting institution)","2019","Modern web information systems use machine learning models to provide personalized user services and experiences. However, machine learning models require annotated data for training, and creating annotated data is done through crowdsourcing tasks. The content used in annotation crowdsourcing tasks like medical records and images might contain some private information which can directly or indirectly identify an individual. The name, age, ethnicity, gender, contact details are examples of private information that directly identifies an individual. Indirect private information relates to the cultural, economic, and social factors of an individual. For instance, the visual cues of religious objects or symbols relate to the religious beliefs of an individual. In this thesis, we study how to minimize the amount of private information extracted from images using a hybrid algorithm which combines machine learning models and crowdsourcing. We also demonstrate that the proposed hybrid algorithm reduces the amount of private information exposed from the image and the cost of using the crowd for detecting private information in the image.","Privacy-preserving; Crowdsourcing; Machine Learning; Hybrid Human-AI Algorithm; Hybrid Intelligence; Privacy","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:1b89e09c-c1fd-4aa9-a0d2-ee95de19710e","http://resolver.tudelft.nl/uuid:1b89e09c-c1fd-4aa9-a0d2-ee95de19710e","Identification of Quasi Normal Modes: In Wave-Field Problems","Prakash, Pranav (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Circuits and Systems)","Remis, Rob (mentor); Delft University of Technology (degree granting institution)","2019","Quasi-Normal Modes (QNMs) are a key concept in reduced-order models. In this thesis, we use Finite-Difference approach to create a discretized model of an open electromagnetic system in order to identify its QNMs and the Perfectly Matched Layer (PML) modes. We develop a structure of the QNMs and the PML modes and identify different regions of the eigenvalue distribution in our system. We validate the idea of dominant QNMs by using the identified QNMs to get the solution that was obtained using the Finite-Difference method.","QNM; PML; Scattering Poles; Quasi-Normal Modes; Electromagnetic; Wave Field; Resonance; Open system","en","master thesis","","","","","","","","2020-08-31","","","","Electrical Engineering | Circuits and Systems","",""
"uuid:d4f2beb4-1889-49b1-a0ba-aa24b0cb7b84","http://resolver.tudelft.nl/uuid:d4f2beb4-1889-49b1-a0ba-aa24b0cb7b84","Optimizing Construction Knowledge Integration in Offshore Wind Projects","Soni, Harsh (TU Delft Civil Engineering and Geosciences; TU Delft Integral Design and Management)","Hertogh, Marcel (graduation committee); Jalali Sohi, Afshin (mentor); Hoving, Jeroen (graduation committee); Cats, Nico (graduation committee); Meijs, Jeroen (graduation committee); Delft University of Technology (degree granting institution)","2019","'Construction Knowledge' is the requisite knowledge for effective and efficient construction and its use in project processes across project lifecycle for better constructability is 'Construction Knowledge Integration (CKI)'. Past researches show that there is limited integration of construction knowledge in preparation stages of the project since these are carried out by different project teams. Hence, limited integration of construction knowledge in the realm of 'Offshore Wind' projects is the main problem being addressed in this research and optimizing it is the primary objective. The scope of this research is limited to optimizing CKI in the engineering &amp; management processes of foundations in OW projects as these remain a major 'Balance of Plant' component executed by the primary contractor. This research gathered its data through desk research (literature study) and case studies of three ongoing OW projects. The former was aimed at finding the key concepts related to CKI which support its optimization. Literature study confirmed the importance of CKI in early stages, integrating construction knowledge from a mix of relevant sources and practices. The case study was aimed at finding the existing regime of CKI in OW projects and the key issues which hinder CKI. Case data was mainly gathered through 12 semi structured interviews of project staff. It revealed that the current regime was highly informal, with high reliance on use of lessons learned data and limited integration of knowledge from fabrication, installation and past/ongoing projects. The key issues hindering CKI were found to be lack of standard protocol for knowledge integration activities and lack of integrated knowledge database which hindered knowledge retrieval, sharing and creation. The recommendations were devised for all issues that had a causal or correlational linkage with the two key issues, where the main outline was to formalize knowledge integration efforts and recommend an essential setting for an integrated knowledge database. These recommendations also address the missing link to essential knowledge sources in the current regime. Complementing the detailed recommendations to each specific issue, this research recommends the offshore wind sector to formalize CKI efforts using a mix of tools and practices, focus on integrating relevant sources of knowledge, specially fabrication knowledge and realize and share the importance of construction knowledge integration in projects.","Knowledge Integration; Offshore Wind; Project Management; Construction Knowledge Integration; value","en","master thesis","","","","","","","","2020-08-31","","","","","",""
"uuid:33bc746a-472d-4919-af26-e12896bf9abb","http://resolver.tudelft.nl/uuid:33bc746a-472d-4919-af26-e12896bf9abb","Stability of the floating ice shelf of the Petermann glacier and its response to a changing environment","Rosier, Job (TU Delft Civil Engineering and Geosciences)","Lhermitte, Stef (mentor); Mottram, Ruth (graduation committee); Delft University of Technology (degree granting institution)","2019","Nearly all major glaciers in Greenland have reduced in size over the last two decades. An increase in the amount of ice transported from the Greenland ice sheet to the oceans is predicted following an increase in Arctic air and ocean temperatures. One of the last glaciers with a floating ice shelf and draining a substantial area of the Greenland ice sheet is the Petermann glacier in North West Greenland. With two major calving events in 2010 and 2012 the extent of its floating ice shelf was reduced to only half of that prior to 2010 and since 2016 new fractures indicate a new calving event is predicted to reduce the length of the glacier by ~14 km.<br/><br/> Multiple studies have indicated that after the major calving event of 2012 the glacier accelerated and a new increase in the velocity, possibly linked to the next calving event, has already been observed. With every part of the glacier’s ice shelf that is lost the resistive force that holds the glacier back is reduced and the amount of ice drained to the ocean increases. Losing its entire ice shelf could lead to a significant increase in the contribution of the Petermann glacier to global sea level rise as the Petermann fjord extends inlands below sea level for nearly a hundred kilometers. This study uses ice thickness and surface elevation data combined with velocity data from different sources to analyze the current and future stability of the Petermann glacier. Ice thickness and the velocity data is used as input in a fracture model in order to investigate the different contributions of stress, thinning and an increase in the availability of surface water to the depth crevasses can reach. The areas on the glacier that show locations where crevasses penetrate deep into the ice indicate that the glacier is vulnerable to fracturing in those spots. Connected weak spots might indicate further potential for future calving events. The results derived from the thickness data and the subsequent melt rates show that near the grounding line the glacier is experiencing significantly larger melt rates than near the calving front. The high melt rates are concentrated in space and caused three large basal channels to form, which run downstream parallel to the flow direction. The location of the western channel corresponds to the location of fractures that initiated during the same time the channel deepened, indicating a relationship between an increase in melt rate and fracturing. This relation is also observed in the results from the fracture model, where there is enough water and the ice shelf thinness fractures are capable of penetrating deep in the glacier ice. The results also show that when the average melt rate between 2011 and 2017 continues to prevail the floating ice shelf of the Petermann might be gone within the next decade","glacier; Climate change; Remote Sensing","en","master thesis","","","","","","","","2020-08-19","","","","","",""
"uuid:bd22471f-058a-4071-95bb-5126e263124b","http://resolver.tudelft.nl/uuid:bd22471f-058a-4071-95bb-5126e263124b","Acceleration of Seed Extension for BWA-MEM DNA Alignment Using GPUs","Lévy, Jonathan (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Computer Engineering)","Al-Ars, Zaid (mentor); Ahmed, Nauman (mentor); Zandrahimi, Mahroo (graduation committee); Ishihara, Ryoichi (graduation committee); Delft University of Technology (degree granting institution)","2019","DNA aligning is a compute-intensive and time-consuming task required for all further DNA processing. It consists in finding for each DNA string from a sample its location in a reference genome. Usual techniques for short reads (hundreds of bases) involve seed-extension, where a small matching seed is found with quick search through FM-index and then extended on both ends with a custom Smith-Waterman algorithm, giving optimal solution. However this seed-extension takes a tremendous amount of time. This is why we present in this thesis a solution to offload extension on a GPU to be done in a parallel fashion. This is possible thanks to the fact that the DNA reads do not present any kind of relation between each other. We used the Burrows-Wheeler Aligner - Maximal Exact Match (BWA-MEM), a reference program in the field, to which we integrated a GPU-accelerated library for extension, GASAL2. However, BWA-MEM has a left-right dependency on extension starting scores, with the left alignment starting with the seed score, then the right part starting with the previously calculated left score. We designed a solution by starting both extensions with the seed score, we called this method the ""seed-only"" paradigm. On our test machine featuring 12 hyperthreaded cores and an NVIDIA Tesla K40c, when running with 12 threads, we could observe a raw kernel speed-up of 4.8x ; but if we allow non-blocking calls to let the CPU run the seeding tasks while the GPU computes the extension, we can reach a 16x effective speed-up for the extension. This extension part takes around 27% of the total time but our acceleration introduces a small overhead due to memory preparations and copying, which makes the whole application 1.28x faster, getting close to the theoretical maximum of 1.37x. Additionally, the paradigm shift we operated creates minimal differences in the final main scores on good quality alignments, with a 1.82% difference for our 5.2 million sequences data set. This makes our acceleration with GASAL2 an solid and efficient solution for a single machine.","GPU; DNA; biology; parallel processing","en","master thesis","","","","","","","","","","","","","",""
"uuid:d132baae-141f-4e03-a8ca-39dfd326e925","http://resolver.tudelft.nl/uuid:d132baae-141f-4e03-a8ca-39dfd326e925","Human Activity Recognition using Channel State Information","Al-Rahbi, Mohammed (TU Delft Electrical Engineering, Mathematics and Computer Science)","Venkatesha Prasad, R.R. (mentor); Verhoeven, Chris (graduation committee); Rao, Vijay (graduation committee); Delft University of Technology (degree granting institution)","2019","Human Activity Recognition (HAR) is a key enabler of various applications, including smart homes, health care, Internet of Things (IoT), and virtual reality games. A large number of HAR systems are based on wearable sensors and computer vision. However, a challenge that has emerged in the last few years entails recognizing human activities using WiFi Channel State Information (CSI). Exiting state-of-the-art solutions have considered only amplitudes of the CSI to recognize human activities, we explore both amplitudes and phase differences to recognize activities. We utilize Continuous Wavelet Transform (CWT) to generate scalogram images from the CSI measurements. Then, we use these images as input to the pertained Convolution Neural Network (CNN), namely AlexNet to extract features that are resilient to environment changes and classify the activities. The experimental results show that the proposed method achieves an accuracy of 98.18% +/- 1.26% using amplitude and phase difference. We also studied the impact of different environments and people, and the results show its robustness.","Human Recognition; Channel State Information; WiFi; Deep learning; Wavelet Analysis","en","master thesis","","","","","","","","","","","","","",""
"uuid:752f180e-1db7-4dcc-ada5-dffabf505125","http://resolver.tudelft.nl/uuid:752f180e-1db7-4dcc-ada5-dffabf505125","Identification of the Hierarchy in Public Transport Networks based on Passenger Flow Patterns","Wang, Ziyulong (TU Delft Civil Engineering and Geosciences)","Cats, Oded (mentor); Verma, Trivik (graduation committee); Luo, Ding (graduation committee); Delft University of Technology (degree granting institution)","2019","In this study, a data-driven, generic and transfer-based methodology for separation and ranking the PTNs has been put forward. With the hierarchy of a network, this is beneficiary for the management and operation of operators for focusing on the higher level network layer and in turn provide better service for passengers. The study introduces three steps to rank the hierarchy of a PTN: (1) using the passenger journey and ride data to derive transfer flow matrix; (2) applying C-space network representation with community detection method to separate and visualize the PTN layer; (3) performing ranking method, regarding inner- and intra- transfer flow. To this end, the hierarchy of a PTN could be presented with temporal attributes. Different day of week and various time period of a day could potentially yield different hierarchy. The proposed unsupervised learning algorithm is based on passenger transfer flow data, independent from geographic location and the mode of transportation. The study shows that the level is changing based on the selected time slot and can be a mixture of different modes, which is dissimilar from the hierarchy purely based on qualitative method.","Hierarchy; Public Transport; Data-Driven","en","student report","","","","","","","","","","","","","",""
"uuid:6cc7881f-731b-4952-87c2-c7410a08ed52","http://resolver.tudelft.nl/uuid:6cc7881f-731b-4952-87c2-c7410a08ed52","Generation and Evaluation of Truss Structures for the Strut-and-Tie Model: Based on Topology Optimization Results for Deep Concrete Beams","Argudo Sanchez, Geovanny (TU Delft Civil Engineering and Geosciences)","Hendriks, Max (mentor); Lukovic, Mladena (graduation committee); Xia, Yi (graduation committee); Houben, Lambert (graduation committee); Delft University of Technology (degree granting institution)","2019","The Strut-and-Tie model (STM) is an efficient technique for the design of concrete structures, but the creation of suitable truss structures gets complicated when these structures become more complex. The topology optimization (TO) is a convenient technique that has been used in recent years for the creation of trusses of complex structures for the STM. This thesis presents a process for the creation of suitable truss structures for the STM using the results obtained with the TO, as well as, an evaluation of them to see which is the most optimal truss structure according to the total amount of tension force present on the full truss, this total amount of tension force is the selected evaluation criterion. Three deep concrete beams were analyzed using two topology optimization (SIMP and BESO approaches) for the generation of stress paths, these approaches are based on the minimization of the strain energy. The procedure starts with the computation of the principal stresses over the results of the topology optimization, then bar elements are placed over the stress paths of these diagrams creating a first (harsh) layout of the trusses. These trusses were not always found stable, but all the trusses were stabilized because, in this way, it is easy to calculate the axial force of in the truss elements, thus satisfy a basic requirement of the STM. To stabilize the truss structures two methods were explored. (i) The addition of new members outside of the stress paths (stabilizers), the essential characteristic of these new elements is that the axial force in them should be zero to not change the stress distribution found during the optimization process. A sensitivity analysis of the stabilizers was performed to track how the axial force changes in these members depending on the position of the nodes connected to them, this process was necessary because when an element outside the stress paths has axial force the stress diagrams have been changed. (ii) The creation of substructures within the stress paths, this process stabilizes the global structure without the addition of members outside the stress paths. Finally, a structural analysis was performed to obtain the axial forces in each member of the truss structure, and through an analysis of these results, the total amount of tension forces in the truss was computed. The truss with the minimum value of total tension force is assumed as the most optimal structure for each case. It is clear through the analysis that the variation of the input parameters does not cause large variations in the results of the topology optimization, but it has an impact in the stabilization process and the performance of the structures according to the evaluation criterion. Furthermore, it has been proved that suitable trusses for the STM can be created using any of the two selected optimization approaches obtaining good results, and a similar performance according to the evaluation criterion.","Strut-and-Tie model; Topology Optimization; Truss structures; Tension force","en","master thesis","","","","","","","","","","","","Civil Engineering","",""
"uuid:8299fcce-98ab-4e0c-ae7b-c6895ec70ea1","http://resolver.tudelft.nl/uuid:8299fcce-98ab-4e0c-ae7b-c6895ec70ea1","Investigation of interface modelling techniques using finite element analysis with ATENA","Vithalkar, Arjun (TU Delft Civil Engineering and Geosciences)","Lukovic, Mladena (mentor); Braam, Rene (graduation committee); Houben, Lambert (graduation committee); Delft University of Technology (degree granting institution)","2019","Study of interface behavior has been the primary area of focus for researchers in the field of concrete science and technology. This interface between two concrete elements becomes important for prefabricated systems, combination of precast and in-situ concrete elements, combinations of concrete cast at different times, repairs of existing concrete structures, strengthening of a structural element such as beam or slab and so on. In this research an attempt is made to check if the interface behavior is reliably predicted using finite element analysis in ATENA with the help of standard elements available in the software. Validation of the numerical results is performed by simulating an experimental bond test and structural test and conclusions are drawn based on the response of these numerical models. <br/><br/>Strength of the interface is mainly governed by the roughness of the adjacent surfaces. In the literature study, a chronological overview of the development of shear models is presented that make use of these roughness parameters in calculating shear capacity of the interface. A finite element analysis is performed using standard elements available in ATENA. ATENA interface material model (ATENA IMM), present in the software uses 2D line interface elements having zero thickness to model an interface. Roughness parameters assigned to this model are based on the guidelines proposed in different design codes. Many parameters need to be defined in this interface that are difficult to measure accurately from experiments. For this, a 5 mm thick artificial interface layer is created by using 2D linear quadrilateral material elements. This technique is named as artificial interface model (ArtIM) that uses physical material properties to define the interface. Since, cohesion and friction coefficient parameters cannot be specifically defined in ArtIM unlike in ATENA IMM, an explicit roughness is incorporated by designing the interface layer in a wave pattern with certain wavelength and amplitude depending on the different surface roughness classes as defined in the Model Code 2010. <br/><br/>A check is performed for the assigned input parameters for the two interface modelling techniques, by simulating bond tests (direct tension test and shear load test) on a small scale composite concrete specimen. Furthermore, validation of the two interface modelling techniques is carried out by comparing the numerical results to experimental findings for a bond test performed by T. Paulay, R. Park and M. H. Phillips [1] and for a structural test case of the Eindhoven airport car park garage failure [2], [3]. ATENA IMM rightly predicts the initial response of the interface but does not comply with the experimental results once the interface fails. With the use of ArtIM, an overestimation of the shear strength is exhibited and the conventional ratio of 2 between the shear and tensile strength [4], [5] cannot be obtained. Moreover, once the material in the interface layer fails, a brittle behavior is exhibited pertaining to the concrete properties assigned to the interface material layer. <br/><br/>Different reinforcement modelling techniques are studied using ATENA IMM with a very low bond strength (no bond condition). The default 1-D reinforcement (RF) bar element when modelled perpendicular to the interface does not reliably predict the response of loading. Hence, other RF modelling techniques are discussed among which, 1-D RF bar elements modelled in cross pattern reliably predict the initial stiffness of the RF bars. The inclination of the RF bars was tested for different angles to comply with the experimental results. However, further research is required to calculate appropriate inclination of the RF bars. In this case the optimum angle between the cross RF bars and interface is around 80°. <br/><br/>In the structural test, interface behavior is investigated for a specimen with (fully reinforced) and without (partially reinforced) shear reinforcement in the flexural span. ATENA IMM safely predicts the bond strength in case of both, partially reinforced and fully reinforced models. However, by using ArtIM, an overestimation of the interface strength is observed. The important aspect in the structural model is the shear strength of the interface and since, while using an artificial material element for the interface the shear strength obtained is almost 40% higher than the experimental results, the ultimate load carrying capacity of the whole model increases manifold. <br/><br/>After investigating the two interface modelling techniques, on bond level and structural level, it can be concluded that, the ATENA interface material model (IMM) as well as the artificial interface model (ArtIM) do not predict the interface behavior reliably. However, by using ATENA IMM a conservative response is obtained as opposed to the ArtIM which overestimates the shear capacity of the interface.","Interface; Finite element analysis; ATENA; Interface modelling technique; Shear strength","en","master thesis","","","","","","","","","","","","Civil Engineering | Structural Engineering","",""
"uuid:47f57d0c-cd1e-4abf-8f85-85a14665eef6","http://resolver.tudelft.nl/uuid:47f57d0c-cd1e-4abf-8f85-85a14665eef6","DISTRIK MELINGKAR: Circular housing in Indonesia","Hegeman, Steffan (TU Delft Architecture and the Built Environment)","van de Pas, Roel (mentor); Smit, Mo (graduation committee); van der Meel, Hubert (graduation committee); Delft University of Technology (degree granting institution)","2019","Indonesia is currently facing a housing deficit of 15 million units. In order to try and resolve this problem, 800.000 units of formal housing are being build every year and the most popular typology in this fast growing housing market is the Indonesian housing cluster. The goal within this project is to do a redesign of the housing cluster typology and create a sustainable neighbourhood using building principles derived from the learnings of circular economy.","Housing Cluster; Indonesia; Bandung; Circular economy; Sustainabilty; housing; Bamboo; Architecture; modular construction","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Explorelab","",""
"uuid:26572c35-ef68-4df9-8c57-7e424cb49354","http://resolver.tudelft.nl/uuid:26572c35-ef68-4df9-8c57-7e424cb49354","Fruit and vegetable packaging solution: A reusable and convenient packaging solution, for fresh fruits and vegetables","Blaak, Nathan (TU Delft Industrial Design Engineering)","Balkenende, A.R. (mentor); Sypesteyn, M. (graduation committee); Delft University of Technology (degree granting institution)","2019","This thesis started with the question of ‘’What is the necessity of all packaging in food products?’’. The problem of packaging waste is undeniable, an example of the cause of packing to the environment is the ‘’plastic soup’’. Plastic packaging degrades over time, which produces microplastics. Microplastics accumulate in the environment and nowadays traces of it can be found everywhere. To counter the accumulation of microplastics, less leakage of plastic waste should be achieved. This could be done by selling less single-use packaging and sorting waste better. A contribution to a solution for the packaging waste problem is performed in this project, by making a reusable packaging solution for the fresh fruits and vegetable sector. The designed packaging should be convenient for the consumer, which is why was set that the packaging solution should maintain or improve the consumer packaging experiences with reusable packaging.<br/><br/>The current fruit and vegetable packaging were benchmarked on functions and features, but analyzing all fruits and vegetables and their packaging was too big of scope for this project. This is why a decision process was performed on the shelf life of fruits and vegetables. The mushroom had the shortest shelf life and was therefore analysed. The mushroom is a vulnerable vegetable and is sensitive to humidity levels, pressures and carbon dioxide levels. The found mushroom packaging had features like strengthening structures for the protection of the mushrooms, and airholes for humidity levels and carbon dioxide concentrations. In interviews about the conventional blue mushroom packaging, it was discovered that consumers have a preference for transparent packaging. Also, it was discovered that with reusable packaging information that is normally printed or stuck on the packaging needs to be communicated in another way. From consumer research was retrieved that consumers lack knowledge about packaging features and production processes of fruits and vegetables. Also, consumers find the opening, closing and resealing of packaging the most important conveniences. The thresholds values of the consumer with using reusable packaging, retrieved from consumer research were the skill in filling of the packaging and no room for storage of reusable packaging. <br/><br/>To support the consumer in reusable fresh fruit and vegetable grocery shopping, ‘’the grocery tree’’ was designed. The grocery tree is a combined grocery bag and packaging that can hold eight packaging, which can differ in size and can be taken from the grocery tree at every time. The packaging is designed to support the consumer in the filling process of fruits and vegetables, by making packaging with instructions in the shape of use-cues and two predesigned ways of holding it. The consumer is supported in the supermarket with an app on the smartphone, which is interactive with the designed scales at the supermarkets. At home, the packaging can be used to store the fruits and vegetables, and the remaining of the grocery tree can easily be disassembled for convenience in storing. <br/><br/>The grocery tree is designed to eliminate single-use fruit and vegetable packaging. The grocery tree is reusable but needs the dedication of the consumer to use the product. The grocery tree has gone through optimization steps, but can be further optimized in shape, convenience and amount of material. This to save cost and to support the consumer more in fruit and vegetable shopping with a reusable packaging solution. <br","Packaging; Reuse; Consumer Experience; Sustainability; Fruit and vegetables; Food","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:20f5e7bf-5af1-4b13-bedc-6ab73dcc6429","http://resolver.tudelft.nl/uuid:20f5e7bf-5af1-4b13-bedc-6ab73dcc6429","The People-side of Implementing Business Model Innovation: A study on the role of employee motivation, development &amp; readiness to change in implementing business model innovation","Raguraman, Sushmitha (TU Delft Technology, Policy and Management)","Bouwman, W.A.G.A. (mentor); Verburg, R.M. (mentor); Latifi Rostami, S.M.A. (graduation committee); Delft University of Technology (degree granting institution)","2019","The concept of business model innovation (BMI) has taken off significantly over the last decade in the academic as well as the business environment. It is seen as an important source of competitive advantage and is increasingly being used to achieve superior firm performance. Nevertheless, the field is yet to embrace the organizational dimension, especially in the BMI implementation phase. There is more focus given towards the technical aspect than the people aspect of BM implementation. Therefore, this research draws attention towards the people-side of implementing BMI, more specifically the role of employee motivation, development and readiness to change during BM implementation and how it influences the link between BMI and firm performance. First, a set of propositions, based on literature review, are used to develop a conceptual model that depicts the role of employee’s motivation, development and readiness to change in the BMI process. Thereafter, this model is used to analyze two cases of BMI in SMEs using a semi-structured interview method, to attest and refine the propositions. Besides obtaining a better understanding of the role of employees during BM implementation, this research provides empirical evidence that explains how certain employee characteristics influence the link between BMI and firm performance. Finally, the insights obtained has practical relevance as it stimulates better organizational practices when it comes to the people-side of implementing BMI.","Business Model Innovation; Business Model Implementation; Organizational change management; Employee perspective; SMEs","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:5bd80024-6bb9-41a8-8e0e-b18ee1063e27","http://resolver.tudelft.nl/uuid:5bd80024-6bb9-41a8-8e0e-b18ee1063e27","An Entrepreneurial Approach to Water Purification System in West Bank, Palestine","Fajar Sidiq, Fajar (TU Delft Technology, Policy and Management)","Doorn, N. (mentor); Kroesen, J.O. (graduation committee); Hasan, Abdelfattah R. (graduation committee); Delft University of Technology (degree granting institution)","2019","The improvement of access to clean water is considered one of the world’s major agenda issues nowadays. The agenda to improve water access is not only considering the quantity of water but also the quality of water that should be provided for the society. The problem of the water crisis is happening in many countries around the world and needs a feasible solution. One of the regions that suffer most of the clean water crisis is the Middle-East and North-Africa. Furthermore, most of the water crisis problems are happening in the countries that are having a conflict, for example, Palestine, Iraq, and Syria. In this thesis, the case of clean water crisis will be focused on the West Bank, Palestine. The clean water crisis covers several problems that are not only focusing on technical problems but also on the governance and business opportunity problems in situations where conflicts taking place. Furthermore, this thesis only focuses on the business opportunities of water desalination and purification system in the West Bank. The goal is to develop business models for implementing the CED system in West Bank. The research also explores the cultural values and institutions of the society in the West Bank, with regard to their effects on the feasibility determination of the business model for CED in the West Bank.","","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:cd2f78cc-7bf8-4583-9124-6b56d36a2170","http://resolver.tudelft.nl/uuid:cd2f78cc-7bf8-4583-9124-6b56d36a2170","Objective Image Quality Assessment and Comparison of Ultrasound Probes: Research to Application of Trans-Balloon, Miniaturized TEE in Atrial Ablation Procedures","Grandia, Leander (TU Delft Mechanical, Maritime and Materials Engineering)","Dankelman, J. (mentor); Hendriks, B.H.W. (graduation committee); Swamy, A. (graduation committee); Vos, H.J. (graduation committee); Nijhof, Niels (graduation committee); Delft University of Technology (degree granting institution)","2019","Atrial Fibrillation (AF) is a common type of arrhythmia, characterized by rapid and irregular contraction of the atria. Irregular contraction of the atria is caused by erroneous electrical activation, originating from the tissue around the Pulmonary Veins (PV) in the Left Atrium (LA). Catheter-based treatment of AF includes ablation of the tissue around the PV. <br/><br/>Imaging of ablation catheters and LA-anatomy is of great importance for accurate and successful treatment of AF. In current state of the art LA-ablation procedures, static, pre-procedural acquired 3D models of the LA are used for catheter navigation and monitoring. However, due to the limited accuracy of these static 3D models there is a continuous demand for real-time 3D imaging techniques during catheter based treatment of AF.<br/><br/>A possible solution for real time imaging is to use trans-balloon, miniaturized transesophageal echocardiography (TEE) as imaging modality for AF ablation procedures. Trans-balloon, miniaturized TEE can provide real-time 3D ultrasound imaging of the LA. <br/><br/>Since trans-balloon, miniaturized TEE is not used in clinical practice yet, it is unknown whether image quality of the miniaturized TEE probe will be sufficient for imaging during AF ablation procedures. Therefore, the image quality of trans-balloon, miniaturized TEE has to be compared to image quality current state of the art TEE probes.<br/><br/>In this thesis, image quality of the miniaturized ultrasound probe was compared to current state of the art TEE probes, and the influence of the balloon on image quality was investigated. Image quality was assessed using standardized ultrasound image quality assessment phantoms and software. Image quality was measured using the following image quality parameters: contrast to noise ratio (CNR), spatial resolution and penetration depth of the ultrasound signal.<br/><br/>The results have shown that CNR of the miniaturized probe is equal to that of state of the art probes, but that spatial resolution of the miniaturized probe strongly depends on the rotation angle of the ultrasound imaging plane. Rotating the imaging plane of the miniaturized TEE probe negatively impacts spatial resolution, which was not observed for the state of the art TEE probes. The penetration depth of the ultrasound signal was significantly less compared to state of the art TEE probes.<br/><br/>The rotation-dependent spatial resolution of the miniaturized probe is undesired, since rotating the imaging plane is common practice in TEE. A review study involving clinical experts is recommended to judge whether image quality of the miniaturized probe with rotated imaging plane is sufficient.<br/>Since the anatomical structures of interest during AF are close to the transducer, the limited penetration depth of the miniaturized probe will not be a major limitation. Despite aforementioned limitations, the results suggest that trans-balloon miniaturized TEE can be used for real-time ultrasound imaging during AF ablation procedures.<br/><br/>The research in this thesis provides a theoretical framework to measure and compare image quality of ultrasound probes, which is an important first step in the development of a novel, real-time 3D imaging technique for imaging of AF ablation procedures.<br/><br","Ultrasound; Image Quality Assessment; transesophageal echocardiography; trans-balloon; atrial fibrillation","en","master thesis","","","","","","","","","","","","Biomedical Engineering","",""
"uuid:8afd27a0-f943-40c6-b3f3-10f7e570c0d5","http://resolver.tudelft.nl/uuid:8afd27a0-f943-40c6-b3f3-10f7e570c0d5","Kite Farm Simulation: Assessing the impact of flight paths for multiple-unit airborne wind energy systems","Johnson, Holly (TU Delft Electrical Engineering, Mathematics and Computer Science)","Faggiani, P. (mentor); Schmehl, R. (graduation committee); Delft University of Technology (degree granting institution)","2019","As airborne wind energy is a relatively new field, much of the current research is rapidly progressing towards the development of larger commercial systems with larger airborne components. Farms of airborne wind energy systems can provide higher power generation than a single kite system and offer a potential solution to issues that single kite systems exhibit with continuous power production. An in depth analysis of small scale kite farm systems will be conducted based on Kitepower’s single kite flight path model. This model has been further developed for improved performance, and has been verified with experimental data from the Kitepower system. From this single kite model, a kite farm simulation was developed to evaluate the effects of varied flight paths for several kite farm layout configurations, providing results for power density, power stability, and spatial requirements of the systems.","Airborne Wind Energy; Kite farm; Airborne wind farm","en","master thesis","","","","","","","","2021-08-19","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:1c2af380-8dd4-4321-9f78-e5cb66def6d2","http://resolver.tudelft.nl/uuid:1c2af380-8dd4-4321-9f78-e5cb66def6d2","Seismic analysis of fluid mud: Detection of shear parameters in fluid mud and the relation between seismic velocities and yield stresses","Buisman, Menno (TU Delft Civil Engineering and Geosciences)","Kirichek, Alex (mentor); Draganov, D.S. (mentor); Maurer, H (mentor); Delft University of Technology (degree granting institution)","2019","In this research, a new measuring method to detect shear parameters in fluid mud is proposed, namely using shear waves, or S-waves opposed to the conventional pressure waves, or P-waves. Currently, detecting fluid mud is done by the use of P-waves. This paper shows that conventional P-waves velocity measurements are unsuitable for linking velocities to the yield stress, which is likely caused due to gas in the mud. Opposed to this, S-wave velocities do show an logarithmic increase, which most likely can be linked to the yield stress development of fluid mud. Both S-wave velocities and yield-point measurements show an exponential increase over time and, because of this, it could be that there is a linear relation between them. The difference why S-waves are more suitable for shear-strength measuring is due to their nature of propagation. S-waves do not propagate through gas and are therefore hardly effected by gas production, opposed to P-waves. For this research, both P-and S-wave velocities are estimated from a transmission seismic experiment. Also, a frequency analysis has been conducted showing large similarities over time and for dissimilarities between different mud samples. The yield-point measurements are derived from a rheometer with the same mud sample used for the seismic experiments. Besides a velocity analysis from the transmission measurements, also a reflection measurement has been conducted. The aim for this is to detect converted P-to S-waves and to detect the Scholte wave. Furthermore, a dispersion analysis has been conducted, which is likely important since the relative change in S-wave velocities is small and the velocities are frequency-dependent.","fluid mud; rheology; Yield Stress; Seismic; shear wave","en","master thesis","","","","","","","","","","","","Applied Geophysics","MUDNET",""
"uuid:b0b39832-c921-412c-b6f8-9ac4c52b57f6","http://resolver.tudelft.nl/uuid:b0b39832-c921-412c-b6f8-9ac4c52b57f6","Log Differencing using State Machines for Anomaly Detection","Tsoni, Sofia (TU Delft Electrical Engineering, Mathematics and Computer Science)","Verwer, Sicco (mentor); van Deursen, Arie (graduation committee); Finavaro Aniche, Mauricio (graduation committee); Wieman, Rick (mentor); Delft University of Technology (degree granting institution)","2019","Huge amounts of log data are generated every day by software. These data contain valuable information about the behavior and the health of the system, which is rarely exploited, because of their volume and unstructured nature. Manually going through log files is a time-consuming and labor-intensive procedure for developers. Nonetheless logging information can expose the problematic execution of the software, even though the final outcome seem to be normal. Nowadays the automatic analysis of the log files is crucial for detecting problems, but mainly for understanding how the software behaves, which would be beneficial for the prevention of failures and improvement of the software itself. Towards that direction, this project aims the identifications of unexpected executions of the software and the determination of the root cause behind them. In more details, the expected behavior of the software can be approximated using model inference techniques and the newly incoming observed data can be analyzed to verify if they are conformed by the expected behavior. The conformance checking method that will be used is called replay. The incoming traces will be replayed in the graph, at the point they are not validated, the alignment algorithm will take over. The sequence alignment is performed in three different ways. Two of the methods are looking for the best alignment at a specific radius around the problematic node. Additionally a global alignment technique is implemented, which is based on the famous algorithm by Needleman and Wunsch for DNA sequences. Our goal required the modification of the aforementioned algorithm to not only align two sequences, but a sequence with a tree structured model. Finally the implemented tool provides the visualization of the differences in a way that makes it intuitive for the developers to understand what went wrong. Some additional information are also provided to make the investigation of the ""anomaly"" easier.","log analysis; log differencing; anomaly detection; state machines; software engineering; sequence alignment; model checkers; log comparison","en","master thesis","","","","","","","","","","","","","",""
"uuid:e5489f8a-cbe5-4935-8e4e-2bb24e40b9ff","http://resolver.tudelft.nl/uuid:e5489f8a-cbe5-4935-8e4e-2bb24e40b9ff","Innovation beyond the stage-gate: Factors influencing commercialisation phase within financial services and solutions to mitigate barriers","Grace, Caecilia (TU Delft Technology, Policy and Management)","Verbraeck, Alexander (graduation committee); Verburg, Robert (mentor); Das, Patrick (graduation committee); Delft University of Technology (degree granting institution)","2019","Financial services industry which used to be relatively traditional is in the midst of change caused by the emergence of FinTech, forcing traditional firms to improve its innovation effectiveness. There exist various studies on corporate entrepreneurship, especially on the fuzzy front-end. However, studies on the back-end phase of innovations for financial services is still severely limited. This study attempted to increase our understanding of factors influencing the innovation outcome, as well as to explore possible solutions to increase effectiveness. A total of twelve factors were identified from literature. <br/><br/>Through an explorative case study and practitioners interviews, the influence of these twelve factors in real-life working situation are determined. The case study was undertaken at a major European bank. Meanwhile, expert interviews were conducted with practitioners from various traditional financial services firms and the academic field. Based on the empirical result, five drivers and three barriers are identified. Several factors are quite applicable for innovation in general, although others are more specific for the financial services industry. Five improvement points are proposed based on the interviews and further literature review. This research contributes to improving empirical knowledge of factors during the commercialisation of service innovation and providing a basis for further research.","Innovation; Corporate Entrepreneurship; Financial services; bank; innovation implementation; innovation drivers; innovation barriers","en","master thesis","","","","","","","","2019-08-30","","","","","",""
"uuid:4aef2dc0-ddeb-4198-af19-83303fcabbd1","http://resolver.tudelft.nl/uuid:4aef2dc0-ddeb-4198-af19-83303fcabbd1","Managing Service Innovations in Business-to-Business and Business-to-Consumer Contexts","EzhilKumar, Mythili (TU Delft Technology, Policy and Management)","Verburg, Robert (mentor); Verbraeck, Alexander (graduation committee); Das, Patrick (graduation committee); Delft University of Technology (degree granting institution)","2019","With the rapidly growing service economy, firms must address the fundamental needs of the customers to sustain their competitive advantage. The role of the customer is being increasingly stressed by both academia and practice. However, an important implication from this is to make a distinction between the business customer and the general consumer. The underlying premise of this thesis- that a business-to-business innovation is different from a business-to-consumer innovation stems from the age-old B2B/B2C divide which has received a lot of attention from the marketing literature. This thesis is a three-phased research- with the first phase identifying the differences between service innovations in the business-to-business and business-to-consumer contexts. This phase was carried out through a literature review followed by expert interviews to further enhance the understanding of business-to-business and business-to-consumer service innovations in practice. The results indicated a substantial number of differences along different dimensions such as : market characteristics, innovation processes, the challenges these innovations face and the critical success factors amongst other operational differences. With definitive differences established between the two contexts, the foundation for the next phase was laid. Multiple authors have called for contingency innovation management for better performance based on the context of innovation. While prior work has been done from the contexts of radical-incremental, process-product, explorative-exploitative innovations, there has been meagre attention to the dichotomy of business-to-business and business-to-consumer. Based on the findings from Phase 1, it was posited that a general approach to innovation management in business-to-business and business-to-consumer innovations will not fit. To study and observe this phenomenon in detail, a case-study at ING Labs (the innovation accelerator of ING Bank) was carried out. Six case studies with cases from business-to-business and business-to-consumer contexts were chosen, and the results were analysed following a cross-case analysis. The controls that were being studied were based on the stage-gate control framework consisting of output controls (project timelines and project budget control) and process controls (deliverables and gate evaluations). In the context of ING, the results indicated that controls followed a quasi-fit or a partial-fit with different contexts.In the initial Validation Phase, irrespective of their contexts, the initiatives did not face much challenges. As they progressed, in the Implementation Phase, the business-to-business initiatives particularly face context-specific tensions. However, considering the number of contingencies that further emerged from the research, it can be said that a \textit{ideal fit} between the controls and initiatives would be impractical if not impossible to achieve. In the third phase, recommendations were derived from expert interviews and literature for the tensions that were identified at the intersection of control and innovation.<br","Service Innovation; Business-to-Business; Business-to-Consumer; Innovation management; Management Controls","en","master thesis","","","","","","","","2019-08-30","","","","","",""
"uuid:6943c5a0-74cc-49d2-8cf9-6f7e6e66c57e","http://resolver.tudelft.nl/uuid:6943c5a0-74cc-49d2-8cf9-6f7e6e66c57e","Effect of Flexural Cracks on Web-Shear Cracking of Prestressed Concrete Continuous Members","Tuitjer, Mathijs (TU Delft Civil Engineering and Geosciences)","Hendriks, Max (mentor); Roosen, Marco (graduation committee); Yang, Yuguang (graduation committee); Delft University of Technology (degree granting institution)","2019","Shear tension failure in thin-webbed prestressed concrete elements is yet to be predicted in an accurate manner. The analytical method uses assumptions to simplify the theory. This makes it less accurate. The calculated resistance to web-shear cracking is based on the principle tensile stress reaching the tensile strength of concrete. Failing in shear tension is more risky than failing in bending, since it often happens abruptly without any warnings. Previous research shows however that shear tension failure often occurs before the principle tensile stress reaches the assumed tensile strength of concrete. This means that the resistance is being overestimated. Comparisons between experimental results and theoretical models have shown that the coefficient of variation for the shear force at web-shear cracking for experiments including flexural cracks is significantly larger than for experiments without flexural cracks. It is assumed that flexural cracks are present when principle tensile stress in the outer fiber is higher than tensile strength in the flange. This indicates that the presence of flexural cracks influence the stress distribution in the areas where web-shear cracking occurs. To find the influence of flexural cracks on web-shear cracking a well documented experiment about continuous prestress concrete members failing in shear tension is used for a case study. Namely the thesis ‘’The Influence of Axial Load and Prestress on The Shear Strength of Web-Shear Critical Reinforced Concrete Elements’’ written by Liping Xie in 2009. Three of the specimen are chosen to be researched, between these three the only changing variable is the amount of prestress. All three fail under shear tension, however one has no observed flexural cracks, one has the flexural cracks and the web-shear cracks occur simultaneously and the last one shows flexural cracks before web-shear cracking. Three analyses are performed per specimen: analytical analysis, linear finite element analysis (LFEA) and a non-linear finite element analysis (NLFEA). These analyses are compared to each other and to the experimental results. An outstanding result is that for every load in every specimen it holds that: σ<sub>1_ANA</sub> &gt; σ<sub>1_LFEA</sub> ≥ σ<sub>1_NLFEA</sub>. The maximum principle tensile stresses calculated with an analytical method are consistently higher than principle tensile stresses that follow from a LFEA and NLFEA. This means that performing a simple analytical analyses gives a lower shear resistance than the LFEA and the NLFEA. All three analyses indicated flexural cracks for the beam in which no flexural cracks were observed. However the NLFEA showed that these were cracks of a maximum crack width of mm at the moment of web-shear cracking. These widths are not visible by eye. All specimen showed web-shear cracks under a shear load lower than predicted, meaning all analyses overestimate the shear tension resistance. A sensitivity analysis is performed to find the influence of shear reinforcement and of the tensile strength of the concrete. Conclusions are that the shear reinforcement has little to no influence up until the moment of web-shear cracking. All analysis overestimate the resistance to web-shear cracking. In this thesis a sensitivity analysis is performed to the influence of the tensile strength of concrete. It is concluded that if the tensile strength of the concrete is reduced by 40% the NLFEA still results in shear forces larger than the shear force at web-shear cracking during the experiments. Another conclusions of this research is that the presence of micro flexural cracks reduce the principle tensile stresses in the adjacent web areas. The specimen in which no flexural cracks were observed during testing shows flexural cracks conform all analyses it is impossible to compare specimen uncracked in bending with specimen cracked in bending. Up until reaching the tensile strength of the concrete the LFEA and the NLFEA are logically equal. When the load is further increased differences between the LFEA and the NLFEA occur. It is assumed that this difference is the result of the presence of the flexural micro cracks. The specimen with the smallest flexural micro cracks showed also the smallest difference between σ<sub>1_LFEA</sub> and σ<sub>1_NLFEA</sub> From this it can be concluded that larger cracks result in a larger reduction of σ<sub>1</sub>. It is expected that if the micro flexural cracks evolve to significant flexural cracks that the principle stresses are reduced even more, resulting in a underestimation of the actual shear tension resistance.","Non-Linear Finite Element Analysis; shear tension cracking","en","master thesis","","","","","","","","","","","","Civil Engineering | Structural Engineering | Concrete Structures","",""
"uuid:3e61b92e-37a1-4693-889e-95a636dbb6b0","http://resolver.tudelft.nl/uuid:3e61b92e-37a1-4693-889e-95a636dbb6b0","Proxy-model for Flow and Transport in Geothermal Reservoirs","Ahmad Mohammad Tahir, Ahmad (TU Delft Civil Engineering and Geosciences; TU Delft Geoscience and Engineering)","Voskov, D.V. (mentor); Bruhn, D.F. (graduation committee); Brehme, M. (graduation committee); Wang, Y. (graduation committee); Delft University of Technology (degree granting institution)","2019","The hot water produced from a geothermal doublet possesses energy, which once utilized, the water cools down and is re-introduced back into the same reservoir at a sufficient distance using an injector well. As cold water flows through the reservoir, it acquires thermal energy from surrounding in-situ rocks. This process recurs until a substantial drop in rock temperature occurs and the water is unable to be recharged adequately; as a result, cold water starts to ""break-through"" into the production well and the doublet soon needs to be abandoned.<br/>This breakthrough time can be predicted using reservoir simulation. Significant work has been done in the past to determine the effect of different parameters on the breakthrough time and accuracy of models have been improved by incorporating real world physics. Despite being capable to predict breakthrough time, accurate high-fidelity 3D models require significant time in uncertainty quantification and data assimilation analysis due to CPU demanding simulations.<br/>In this project, a physics-based proxy model is developed to predict flow and heat transport in low-enthalpy reservoirs. Streamlines that describe flow in a system and mostly controlled by steady-state pressure distribution are traced using Pollock's method (Pollock, 1988) and the reservoir is divided into streamtubes. Rock-heat depletion is modelled by semi-analytic model along streamlines. The objective is to predict geothermal doublet breakthrough time using only a limited number of streamtubes, thus minimizing simulation time and CPU resources.<br/>Comparison with accurate high-fidelity model reveals that results for proxy model are optimistic; the error for pressure and temperature distributions, as well as the breakthrough curves is within the acceptable tolerance. The time required to simulate the proxy-model is less than the high-fidelity model. And as the number of streamtubes (to simulate the proxy model with) decrease, the time required for simulation further decreases but conversely the error between the breakthrough curves increases.<br","Reservoir Simulation; Geothermal; Doublet; Low Enthalpy; Breakthrough Time; Heat and Mass Transfer; Streamlines; Streamtubes; Operator Based Linearization","en","master thesis","","","","","","","","","","","","Petroleum Engineering and Geo-sciences","",""
"uuid:c0bd3fed-307b-4ab6-bf33-79e6f52cd991","http://resolver.tudelft.nl/uuid:c0bd3fed-307b-4ab6-bf33-79e6f52cd991","Customer Acceptance of a Revenue Management Platform with Multi-Party Computation: Application of Multi-Party Computation to Revenue Management in the Semiconductor Industry","Faujdar, Vidyottama (TU Delft Technology, Policy and Management)","de Reuver, G.A. (mentor); Fiebig, T. (graduation committee); Warnier, Martijn (graduation committee); Delft University of Technology (degree granting institution)","2019","Research ProblemIn today’s competitive and fast-paced nature of conducting business in the semiconductor industry, the discipline of revenue management (RM) is often mentioned. Through a dynamic pricing capability, RM enables firms to maximize profits by capitalizing on missed revenues. Moreover, RM enables customers to receive products on short notice, by allowing them to place orders with a(n) (earlier) delivery wish date, wish price and volume. Since the semiconductor industry is characterized by volatile market demand, long production times and high capital investment (Ehm &amp; Ponsignon, 2012), the semiconductor industry is a model representation of the manufacturing industry. Despite the benefits of RM, the manufacturing industry has not yet witnessed a widely-adopted revenue management system.In order to apply revenue management in the manufacturing industry, it is primarily important to understand that the data involved from the parties participating in the revenue management process is confidential. For manufacturers, the confidential data includes the daily unallocated available-to-promise data, which is available to commit to customers for orders on short notice. On the other hand, for customers, the maximum price that they are willing to pay for such products with a shorter delivery time is confidential. Hence, due to the confidentiality involved, as well as the need for enabling a more equal collaboration model between buyers and sellers, a secure technology that involves inputs from multiple parties is required in order to facilitate the implementation of revenue management in the manufacturing industry.Multi-party computation is a promising cryptography technology which has been theoretically studied by researchers but has not yet been practically applied. This technology is a value-added tool in the use case of revenue management because it deals with multiple parties’ confidential data and performs a computation with them securely. The outcome of the algorithm presents a revised price (based on the desired price adder range provided by the manufacturer, as well as the price wishes of the customer), a volume and a delivery date. This will allow manufacturers to secure their unallocated available-to-promise data, and customers to share the confidential maximum price they are willing to pay to receive products earlier. Multi-party computation has been proposed to be applied to revenue management by the EU H2020 SafeDEED project. We further build on this concept (SafeDEED, 2018).As a consequence of multi-party computation being an up-and-coming technology, as well as revenue management being new to the business-to-business field, it is challenging to imagine what a possible implementation of their integration is...<br","Revenue Management; Multi-Party Computation; Human-Computer Interaction; Security","en","master thesis","","","","","","","","2020-08-16","","","","Management of Technology (MoT)","",""
"uuid:1871631d-1049-4b44-9eaa-460bc054656c","http://resolver.tudelft.nl/uuid:1871631d-1049-4b44-9eaa-460bc054656c","Probabilistic system identification and reliability updating for hydraulic structures - Application to sheet pile walls","Chai, Xuzheng (TU Delft Civil Engineering and Geosciences)","Hendriks, M.A.N. (mentor); Rózsás, Árpád (mentor); Slobbe, Arthur (mentor); Teixeira, Ana (graduation committee); Schweckendiek, T. (graduation committee); Yang, Y. (graduation committee); Delft University of Technology (degree granting institution)","2019","Given its geographical location and history, water defense is of utmost importance for the Netherlands. Structural Health Monitoring (SHM) offers a promising approach for system identification of hydraulic structures in this water defense system. The aim of SHM is to set sensors on structures and use the monitored responses to identify structural parameters of interest. However, many pertaining questions are unanswered concerning realistic hydraulic structures and monitoring systems: What type of sensors (e.g. strain gauge, SAAF, etc.) can and should be used in the monitoring system? How many sensors are needed, where and when to install these sensors? What is the influence of construction stages of structures on system identification? Considering the evaluation of a structure, what is the influence of system identification as well as construction stages on reliability (failure probability) of structures? Considering practical implementation: which computational algorithm is suitable and feasible? How to construct a proper surrogate model of the mechanical model to reduce computational time? <br/>To answer these questions, a single anchored sheet pile wall is studied using a probabilistic approach. The sheet pile wall is modeled using the finite element (FE) method, synthetic data are used and Bayesian approach is adopted to cope with measurement uncertainty and model uncertainty. The information conveyed by sensors is quantified by the Kullback–Leibler (KL) divergence between prior and posterior distributions. Moreover, the correlation in model uncertainty of various structural responses is quantified by comparing a full-scale experiment from the literature and a corresponding calibrated 3D finite element model. <br/>The results show that: <br/>• A combination of different sensor types (in our case they are SAAF and strain gauge) should be used in the monitoring system (e.g. the combination of four different types of sensors outperforms the strain sensors on the sheet pile wall by conveying 40% more information with respect to the former); <br/>• Even limited number of sensors can convey sufficient information. In our case, 3 sensors placed at proper locations can convey 90% information carried by 6, 8 and 9 sensors considering different responses. They should be installed as early as possible; <br/>• The failure probability computed using posterior from system identification largely decreases compared with that computed using prior (the ratio of prior and posterior failure probabilities can go up to 15<sup>10</sup> in our case); <br/>• Delay of the start of monitoring during the construction stages decreases the information conveyed by sensors in system identification (the conveyed information can decrease by 50% in our case) and increases the computed failure probability in reliability analysis: the ratio of prior and posterior failure probabilities can be as large as 30<sup>10</sup> ); <br/>• MultiNest performs well in Bayesian inference in high dimensional problems; <br/>• Gaussian process regression (GPR) with anisotropic radial basis function (RBF) kernel and white kernel as well as an adaptive infilling criterion is capable of constructing an accurate surrogate model even when it goes to high dimensionality. The error of surrogate model prediction can be explicitly explained. <br/>To my knowledge the work presented in this thesis is the first application of combined system identification and reliability assessment for hydraulic structures, and the first detailed analysis of the effect of sensor installation time on system identification and structural reliability of hydraulic structures. <br/>The findings imply that probabilistic system identification is a promising approach to substantially reduce our uncertainty in modelling hydraulic structures and in turns to increase their calculated safety. The approach has the potential to extend the working life of aging hydraulics structures and save costly strengthening and replacement. The analysis framework can also be applied to other structures in civil engineering.","Structural Health Monitoring (SHM); Bayesian Inference; Reliability analysis; Surrogate modelling; Hydraulic structures","en","master thesis","","","","","","","","","","","","Civil Engineering | Structural Engineering | Structural Mechanics","",""
"uuid:f13dda2a-f1ca-4ecc-b45b-0650ed1fc869","http://resolver.tudelft.nl/uuid:f13dda2a-f1ca-4ecc-b45b-0650ed1fc869","Dielectric Loss Measurements at Sub-K Temperatures and Terahertz Frequencies","Kouwenhoven, Kevin (TU Delft Electrical Engineering, Mathematics and Computer Science)","Baselmans, Jochem (mentor); Endo, Akira (graduation committee); Vollebregt, Sten (graduation committee); Delft University of Technology (degree granting institution)","2019","On-chip spectrometers, such as DESHIMA and SuperSpec, require transmission lines with very low loss of tanδ &lt; 10<sup>-4</sup> to achieve sufficient system efficiency. Transmission lines with higher loss would introduce too much signal attenuation in the line from antenna to filter and in the filters themselves. Data regarding the losses of transmission lines at THz frequencies and sub-K temperatures is severely lacking. In this report an on-chip Fabry-Pérot resonator concept is demonstrated that can be used to measure the losses of a transmission line with high sensitivity at high frequencies. To create the in-line Fabry-Pérot resonator, a transmission line of certain length is coupled to a THz source via a twin-slot lens antenna on one side and to an Al-NbTiN hybrid MKID on the other side. The goal of this work is to measure the losses of microstrip lines at frequencies &gt; 300 GHz, at a temperature of about 250 mK, with dielectric dominated loss in the range of 10<sup>-3</sup> &gt; tanδ &gt; 10<sup>-5</sup>. There are several experimental challenges for measuring tanδ. The first challenge is the limited frequency resolution of the source, due to which resolving low tanδ can become impossible. Secondly it was experimentally found that there is stray light coupled to the detector which causes a spurious response with a level of −30dB with respect to the peak (unity) transmission of the Fabry-Pérot resonator. Taking these experimental challenges into account results in a Fabry-Pérot resonator design where the length, the mode number, and the coupler quality factor <i>Q<sub>c</sub></i> of the resonator are optimized. Furthermore multiple resonators on a single chip are used, each coupled to a separate antenna and detector, with different <i>Q<sub>c</sub></i> values. This design method is applicable for different dielectric materials and different transmission line configurations. Using this method a chip was designed and fabricated for a microstrip line based Fabry-Pérot resonator fabricated from sputter deposited superconducting NbTiN metal and a PECVD deposited a-Si layer. Using this chip a tanδ ≈ 10<sup>-4</sup> @ 350 GHz was measured, which represents the lowest loss values of a microstrip line at frequencies &gt; 10 GHz ever measured.","Dielectric loss; Sub-K; Terahertz; Transmission line; Microstrip; Fabry–Pérot resonator; Resonator; Loss measurements; On-chip spectrometers; Lab-on-a-chip; a-Si; NbTiN; Dielectric","en","master thesis","","","","","","","","2020-08-15","","","","","",""
"uuid:06910b19-31e1-4d10-ad6b-6e05789971a5","http://resolver.tudelft.nl/uuid:06910b19-31e1-4d10-ad6b-6e05789971a5","Injectivity reduction in geothermal wells: Investigating the causes","van der Hulst, Tim (TU Delft Civil Engineering and Geosciences)","Bruhn, David (mentor); van Breukelen, Boris (graduation committee); Vardon, Phil (graduation committee); Eilers, Joren (graduation committee); Reerink, Ayla (graduation committee); Delft University of Technology (degree granting institution)","2019","This study investigated the three possible main causes of injectivity reduction in geothermal wells (suspended solids, scaling, biological activity). That has been done by obtaining water samples at three operating geothermal doublet locations in the Netherlands. This paper contains new geothermal data and the interpretation of them. At the moment, injectivity reduction is the biggest and least understood issue in geothermal projects in the Netherlands. Investigating this problem is valuable for current and future geothermal injectors and essential for the upscaling of geothermal energy in the Netherlands.The three locations differ from each other in several aspects (reservoir, surface facilities, chemicals in use, injectivity reduction), which yields a good comparison. Water samples were taken at different moments in time, on different points in the geothermal systems and for different purposes: TSS, chemical composition and ATP concentrations. The data is obtained in the laboratory and used for scale analysis (using the <i>Stream Analyzer</i> software from OLI Studio®) and microbial kill tests to determine the influences on growth. Scientific quality and data reliability are guaranteed by multiple pre-experiments (e.g. to verify sterility of sample bottles) and extra measurements (e.g. duplo samples, oxygen concentrations). It has been found that TSS is reduced through the systems by filters (from 35-55 mg/L in production water to &lt;8-16 mg/L in injection water). Also, scales can potentially form (calcite before- and barite after the heat exchanger). Furthermore, biological activity in the water is initially low, but can grow over time to high levels (&gt;500.000 microbial equivalents). Microbial growth is site-specific and correlatable to injectivity reduction. When there is microbial growth, corrosion inhibitor (CI) enhances this growth. Scale formation is possible, but has a limited likelyhood to cause significant injectivity problems. Furthermore, there is no reason for TSS to be problematic, but it can also not be excluded as possible source for injectivity reduction. Mitigation of these issues can be done by using more injection filters in a geothermal system (for further TSS reduction). Scaling inhibitor can be used preventive and a CI without nutrients (in the solvent) should be used, or a biocide should be injected simultaneously with the CI. This report is interesting for geothermal operators, researchers and anybody else interested in geothermal operations in general or more specifically in injectivity reduction.","Geothermal Energy; geothermal doublet; geothermal system; Injectivity decline; injection; biocides; corrosion inhibitor","en","master thesis","","","","","","","","2019-08-15","","","","Petroleum Engineering and Geo-sciences","",""
"uuid:e0e318de-79e0-481c-82d3-4153e6cd9998","http://resolver.tudelft.nl/uuid:e0e318de-79e0-481c-82d3-4153e6cd9998","Effect of wind speed gradients on AEP in a wind farm cluster","Duffy, Patrick (TU Delft Aerospace Engineering)","Watson, Simon (mentor); van der Laan, Paul (mentor); Peña, Alfredo (mentor); Delft University of Technology (degree granting institution); Technical University of Denmark (degree granting institution)","2019","The engineering flow models used to estimate annual energy production (AEP) in offshore wind farm layout optimization typically assume inflow homogeneity over the model domain. This assumption lies in contrast with observations of horizontal wind speed gradients in coastal regions where many offshore wind farms are being constructed. Accounting for wind speed gradients in wind farm models may lead to reduced uncertainty in AEP estimates and reduced bias in<br/>optimized wind farm layouts. This thesis examines whether accounting for horizontal wind speed gradients with WRF simulated wind resource inputs to engineering wake models impacts AEP prediction for a wind farm cluster in the Irish Sea by comparing results with calculation methods which assume homogeneous inflow. Analysis of a wake free two turbine case under a gradient shows that the assumption of homogeneity leads to errors with the true power which a gradient based method is able to predict. Despite this, results suggest that the overall impact of modelling wind speed gradients on AEP predictions in the Irish Sea cluster is small. Homogeneous and gradient methods using the same wind resource data predicted differences in AEP of between 0.1% and 0.75%, with most cases below 0.75%. Filtering by wind direction reveals AEP differences larger than the assumed wake model uncertainty for two sectors with inflow from land. The AEP contribution from sectors with mean wind speed gradients is limited by low frequencies and mean wind speeds. Additionally, positive and negative power differences predicted by homogeneous and gradient methods were found to balance over the year.","wind speed gradient; wind farm cluster; Annual energy production; Wake model; coastal zone","en","master thesis","","","","","","","","","","","","European Wind Energy Masters (EWEM)","Rotor Design Track",""
"uuid:f1aab45f-2145-4ade-b600-31019f0d0489","http://resolver.tudelft.nl/uuid:f1aab45f-2145-4ade-b600-31019f0d0489","Analytical and Numerical Study of Arch Action in T-beam Bridges","Mustafa, Shozab (TU Delft Civil Engineering and Geosciences)","Hendriks, Max (mentor); Ensink, Sebastiaan (graduation committee); van der Veen, Cor (graduation committee); Houben, Lambert (graduation committee); Delft University of Technology (degree granting institution)","2019","The main objective of this research is to understand the development of arch action in a single T-beam acting as part of the bridge system, ignoring the distribution of the load in transverse direction. As the beam is loaded, several mechanisms work simultaneously in the bridge system, resulting in enhanced ultimate load bearing capacity of the bridges, like compressive membrane action (CMA) in deck slabs and arch action in concrete beams. For this research, an approximate analytical model for quantification of arch action in underwater concrete slabs loaded with uniformly distributed loads (suggested in CUR-077) is verified using non-linear finite element analysis for varying span-to-depth ratios, stiffness of lateral restraint and initial prestressing in the system. The adopted analytical model seems to be able to conservatively predict the arching capacity (within 12%), horizontal stretch (within 10%) and membrane forces (within 10%) in concrete members when compared to the numerical models, provided that the slenderness is less than 15 and the stiffness of end-restraint is at least equal to the stiffness of restrained member. The verified analytical model is then extended to beams loaded with concentrated loads and within the central half of the span, the adapted model is able to conservatively predict the arching capacity with an accuracy of at least 15%. The analytical model is then further extended to beams with T-shaped cross-sections for uniform and concentrated loads. These models are able to predict the arching capacity in T-beams with an accuracy of 7.5% when the numerical failure is due to crushing of concrete. In T-beams with thin webs, the strut failure is observed and the adapted models are not able to predict the arching capacities. As a case-study the Vechtbrug beam is modeled using 2D, 2.5D and 3D approaches in DIANA and the models are validated using the experimental work done by Ensink as part of his PhD studies. All the models show comparable load-deformation behavior and peak loads (within 7%) but only the 3D model is able to simulate the crack pattern observed during experiments. The validated numerical model of the Vechtbrug beam is then adapted as though it is connected to the bridge through cross-beams by applying full restraint at the edge faces of the cross-beams in longitudinal direction. The arching behavior of the adapted Vechtbrug beam model is compared with a disjointed bridge model developed by Ensink in which the distribution of the load is prevented in transverse direction by disconnecting the slab of the loaded sub-span with neighboring beams. Applying full restraints at the edge faces of cross-beams is found to overestimate the influence of arch action in the loaded sub-span when compared to the disjointed bridge model. The adapted analytical model for arching in T-beams with point loads is applied on the loaded sub-span but is found unable to conservatively predict the arching capacity owing to the thin web of the Vechtbrug beam causing strut failure, which is not taken into account by the analytical model.","Arch action; Ultimate load; T-beams","en","master thesis","","","","","","","","","","","","Civil Engineering","",""
"uuid:f6af846b-b59a-4663-8eac-f9a83fb43c90","http://resolver.tudelft.nl/uuid:f6af846b-b59a-4663-8eac-f9a83fb43c90","Semi-passive trailing-edge flaps: for ultimate and fatigue load reductions on wind turbines","La Porte, Jesse (TU Delft Aerospace Engineering)","Barlas, Thanasis (mentor); Ferreira, Carlos (graduation committee); Delft University of Technology (degree granting institution); Technical University of Denmark (degree granting institution)","2019","This thesis investigates the potential of a semi-passive trailing-edge flap on a large conceptual wind turbine. The mechanism passively reacts to blade and tower accelerations by changing the airfoil camber, opposing the dynamic loads on the turbine. An active element is present, which influences the mean of the flap oscillation. First, a low-fidelity, parameter study was done in MATLAB. Next, the flap model was implemented in the aeroelastic code HAWC2, to capture dynamic and structural effects due to blade accelerations. Results show that the semi-passive design reduces ultimate and fatigue loads, during normal power production. Effects on AEP are minimized by the active element and are an improvement to the passive model. The present study motivates simulation of more design load cases, e.g. parked or grid failure. Also, the benefits of the mechanism should be investigated in combination with a new, enlarged, rotor at similar key loads.","wind energy; Wind Turbine; loads; aerodynamics; control; aeroelastic; DTU 10MW RWT; Energy; flaps; fatigue","en","master thesis","","","","","","","","","","","","European Wind Energy Masters (EWEM) | Rotor Design Track","",""
"uuid:6afc130a-df43-4c60-b7a1-5cc7c7cd6713","http://resolver.tudelft.nl/uuid:6afc130a-df43-4c60-b7a1-5cc7c7cd6713","A new coupled modelling framework for turbine inflow generation: mesoscale-synthetic turbulence","Vemuri, Adithya (TU Delft Electrical Engineering, Mathematics and Computer Science)","Watson, Simon (mentor); Basu, Sukanta (mentor); Bierbooms, Wim (graduation committee); Delft University of Technology (degree granting institution)","2019","At the mercy of strong winds, high wind shear, unstable boundary layer and anomalous atmospheric conditions, stands a wind turbine designed to produce sustainable power under harsh conditions. The field of wind energy is a promising prospect for a sustainable future. Diverse research towards the improvement of a wind turbine’s capability and cost is currently the focus of the wind energy industry. With higher wind turbines being designed every day, various challenges and limitations of the current state-of-the-art surface; anomalous atmospheric conditions, structural integrity and cost.<br/>The goal of this thesis is to extend the approach to design a site-specific wind turbine considering an anomalous atmospheric condition. By coupling a mesoscale model with a stochastic turbulence function, a wind field capable of depicting a particular atmospheric condition is created. Using an aeroelastic solver the resulting loads on a wind turbine can be simulated. The methodology uses Weather, Research and Forecasting (WRF) model to re-create an event of low-level jet identified at the met mast of FINO-1, off coast Germany. The wind profile is coupled with a stochastic turbulence function designed at FINO-1 to be used as wind field for the aeroelastic solver, FAST.<br/>A literature survey identified a multitude of approaches used for simulating a low-level jet and analyse the loads on a wind turbine, the majority of which indicate high computational costs and contrived re-creations of the event. Thus, the challenge was to identify a near-realistic event creation with low computational costs. Therefore, coupling a low-resolution mesoscale model to create the event with a site-specific stochastic turbulence function is used to analyse loads on a wind turbine. <br/>Meteorological data analysis at FINO-1 led to the identification of three case studies of low-level jets under varied stability conditions of the atmosphere. The case studies are compared with the International Electrotechnical Commission (IEC) standard’s, IEC – 61400 – Ed3; IEC Kaimal and IEC Great Planes Low Level Jet (GPLLJ) spectrum. For cases with high stability, on an average proposed model predicts 21% higher stress on blade root and 27% higher at the tower top and base in comparison to IEC GPLLJ and 15% and 30% lower in comparison to IEC Kaimal, respectively. Similarly, under unstable conditions, proposed model predicts similar loads on the blade root, 7% lower loads at the tower top and base in comparison to IEC GPLLJ and 30% higher loads for blade root and tower top and base in comparison to IEC Kaimal. Comparing these results with literature on high stability loading higher loads are expected under these conditions.<br/>Concluding, this project developed a model framework to analyse anomalous atmospheric phenomena on a wind turbine specific to a site with low computational costs. While the capabilities of the model have been successfully showcased, only a partial validation on a benchmark case has been carried out. Therefore, going forward a full physical validation of the model for its accuracy for its target applications is recommended.<br","Wind field modelling; WRF-Wind turbine design; mesoscale-synthetic turbulence; WRF Synthetic turbulence; WRF; FINO1 spectral model","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","","54.01, 6.59"
"uuid:ea0d17ed-797f-4c30-92fe-616f24fffc8d","http://resolver.tudelft.nl/uuid:ea0d17ed-797f-4c30-92fe-616f24fffc8d","Modelling of Multi-Tubular Fixed-Bed Reactor for Fischer-Tropsch Synthesis to Produce Synthetic Crude Using Syngas Obtained from the Work’s Arising Gases of an Integrated Steel Mill","Sajeev Kumar, Asvin (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Process and Energy)","de Jong, Wiebren (mentor); Sauerhöfer Rodrigo, Frank (mentor); Santos, Stanley (mentor); Urakawa, Atsushi (graduation committee); Swinkels, Pieter (graduation committee); Delft University of Technology (degree granting institution)","2019","Steelmaking process is a highly carbon-intensive process. This is mainly due to the use of coke as a reducing agent in the blast furnaces to produce carbon-rich pig iron, which in turn, is used for the production of low-carbon steel in the basic oxygen furnaces. The exhaust gases from the blast and basic oxygen furnaces, which mainly contain CO and CO<sub>2</sub>, are utilised for electricity generation, and thus, these pollutants are released to the atmosphere. One of the possible ways to treat these work’s arising gases (WAGs) is to convert them into syngas, which can then be further converted into syncrude via Fischer-Tropsch synthesis (FTS). The FTS syncrude can then be further refined and processed to produce liquid fuels such as gasoline, kerosene, diesel, etc. These synthetic fuels are sulphur-lean and are essentially capable of replacing the existing fossil-derived liquid fuels, thus contributing to curbing the carbon emissions.<br/><br/>The main objective of this thesis was to develop a detailed model of a multi-tubular fixed-bed reactor (MTFBR) to produce synthetic crude from syngas via Fischer-Tropsch synthesis (FTS). The model was then used to simulate a reactor that utilises the syngas obtained from the processing of work’s arising gases of an integrated steel mill to produce synthetic crude. The FTS product distribution was modelled using the kinetic model based on CO-insertion mechanism, developed by Todic et al. A basic MTFBR model was initially developed using the equations and assumptions from the fixed-bed reactor model of Todic, and the basic MTFBR model was able to produce similar results as that of the Todic’s model, with slight deviations in the temperature and pressures profiles. The basic MTFBR model was then further improved to render it comparable with the commercial FT reactors. The main improvements in the model include the dynamic extraction of thermodynamic and transport properties of the system components using Aspen Properties; calculation of dynamic vapour-liquid equilibrium, liquid holdup and catalyst effectiveness factor; and the use of improved heat transfer and pressure drop equations.<br/><br/>A sensitivity analysis was performed to determine the effect of design and process parameters on the performance of the MTFBR model. The most crucial design parameter was observed to be the tube diameter as it had a considerable effect on the heat management and the pressure drop in the reactor bed. The most important process parameters for the reactor were observed to be the inlet temperature and the feed flow rate. A simplified FTS gas loop process was also modelled in Aspen Plus in order to introduce a recycle stream into the MTFBR. The effect of tail gas recycle for the recovery of unreacted H<sub>2</sub> and CO was also studied, and it was observed that higher recycle ratios resulted in lower conversions per pass; however, overall CO conversions were observed to increase until a maximum, and then decrease thereafter. The optimum conditions for the simplified gas loop process were estimated to be with an inlet temperature of 484.5K and a total recycle of tail gas to the recovery section, for a inlet pressure of 30 bar. Optimised process conditions resulted in a CO conversion per pass of 46%, an overall CO conversion of 89%, a C<sub>5+</sub> selectivity of 86.6%, a CH<sub>4</sub> selectivity of 6.2%, and a C<sub>5+</sub> productivity of 252,540 tonnes/y. The optimised model results, in terms of C<sub>5+</sub> selectivity and overall CO conversion, were also pretty much inline with the available data from the Shell SMDS plant in Bintulu.","Fischer-Tropsch Synthesis; Multi-Tubular Fixed-Bed; Reactor Modelling; Synthetic Crude; Blast Furnace Gas; Basic Oxygen Furnace Gas; Cobalt Catalyst","en","master thesis","","","","","","","","2024-08-15","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:9976ea22-07be-4674-b984-1a8f6563f0ee","http://resolver.tudelft.nl/uuid:9976ea22-07be-4674-b984-1a8f6563f0ee","Shared mobility for the first and last mile: Exploring the willingness to share","Arendsen, Koen (TU Delft Civil Engineering and Geosciences)","van Lint, J.W.C. (mentor); van Oort, N. (mentor); Veeneman, Wijnand (mentor); Alonso González, M.J. (mentor); de Bruyn, M. (mentor); van Hagen, M. (mentor); Delft University of Technology (degree granting institution)","2019","class=""MsoNormal"">Over the past decade, the development of ICT and online platforms has provided the infrastructure for new ways of sharing on a scale never seen before which are causing a shift from ownership to access-based- consumption. This trend offers promising prospects for the case of mobility but the true magnitude of impact that the increasing popularity of shared mobility services will have on the total transportation system remains uncertain. For NS, as largest railway operator in the Netherlands, it is therefore relevant to investigate how these new services can contribute to better first and last mile transportation within the multimodal train trip, as most of these types of shared mobility operate on an urban scale. Accordingly, this study aims to explore and measure the factors that affect people’s willingness to use shared mobility services as access or egress transport in multimodal train trips. A series of stated choice experiments was developed in which respondents were asked to choose their preferred mode from a set of alternatives for a given access- or egress trip. Next to conventional modes, included shared modes were bike, (standing) e-scooter, and car. By applying discrete choice modelling, separate mixed logit models were estimated for the home-based side trip (origin to railway station) and the activity based side trip (railway station to final destination) in order to assess the impact of choice factors related to characteristics of the available modes, trip, and traveler. Results show that the willingness to use shared modes is in the first place strongly affected by familiarity with these modes. As the overall observed familiarity and in particular experience with shared modes was low, intrinsic (negative) mode preferences were found to be the dominating choice factors. This was especially the cases for shared e-scooter and to a lesser extent also for the shared car. Traveler characteristics were found affect the magnitude of the fixed mode preference in a sense that young and higher educated travelers significantly appeared to be more open to try shared modes. Contrary to the e-scooter and car, the shared bike exemplifies a more familiar option which was found to results in a different hierarchy of mode related factors: the general fixed mode preference becomes less dominant and usage costs gains more importance.","shared mobility; bike-sharing; e-scooter; shared car; door-to-door trip; stated preference; discrete choice modelling; public transport","en","master thesis","","","","","","","","","","","","Transport, Infrastructure and Logistics","",""
"uuid:558cc345-16c3-4859-a378-b4bb4388fb3c","http://resolver.tudelft.nl/uuid:558cc345-16c3-4859-a378-b4bb4388fb3c","Robust on-line planning for automated inspection with a MAV in the presence of disturbances","de Jonge, Reinier (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Cognitive Robotics)","Alonso Mora, J. (mentor); Hellendoorn, J. (graduation committee); Zhu, H. (graduation committee); Delft University of Technology (degree granting institution)","2019","Safe and reliable autonomous inspection tasks using \ac{MAVs} in cluttered environments are challenging due uncertainties encountered during inspections. In general, algorithms consist of pre-planning paths and executing them. These precomputed inspection paths do not consider potential occlusion by obstacles. In turn, this could render the path infeasible and result in an incomplete inspection of the object to inspect. In order to solve this, a robust method is required, defined as the mitigation of viewing disturbances. This thesis presents an on-line inspection method for occluded environments with static obstacles. The proposed method splits an off-line computed global inspection path into segments and treats each segment as a separate inspection problem. By using an information-based cost function, an \ac{MPC} allows for robust on-line inspection of each of these segments by rejecting obstacle occlusion and collision, if necessary. Additionally, the cost function is designed to be submodular, a mathematical property describing diminishing returns and allowing greedy optimisation while obtaining performance guarantees. Properties of the method are demonstrated in two different environments: with and without obstacles. Due to many sigmoid functions within the cost function, it is a complex optimisation problem. For this reason, scalability is tested and measured in amount of triangles to determine feasible-sized inspection segments. It is shown that for $16$ triangles with one obstacle (both of arbitrary sizes), the calculation time for each \acs{MPC} iteration starts to exceed $15Hz$, becoming more unstable with each added triangle. This effect can be mitigated by discarding information cost of the intermediate cost function. Finally, it is shown that, where the global inspection path is partly occluded, the proposed method handles occlusion by obstacles during inspection at the cost of increased duration of the inspection, while maintaining quality of the solution. However, the predicted performance guarantee by submodularity does not always hold in practice. Future work can explore the integration of sensor measurements to the method or use learning-based approaches to reduce the required on-line computational resources.","Autonomous inspection; MAV; Robust; Online; MPC","en","master thesis","","","","","","","","2022-08-01","","","","Mechanical Engineering | Systems and Control","",""
"uuid:9e96abdb-d2c9-4367-b84e-dd580d3f0367","http://resolver.tudelft.nl/uuid:9e96abdb-d2c9-4367-b84e-dd580d3f0367","Investigations of the Destruction Mechanism of High Pressure Water Jetting","den Haan, Sergei (TU Delft Civil Engineering and Geosciences; TU Delft Petroleum Engineering)","Bruhn, D.F. (mentor); Wolf, K.H.A.A. (graduation committee); Dieudonné, A.A.M. (graduation committee); Delft University of Technology (degree granting institution)","2019","As the demand for green energy is growing, geothermal energy will play an important part in the future energy mix. Geothermal energy is widely used for both direct-use and electricity generation. A viable geothermal reservoir must have a sufficiently high temperature, a fluid pathway through the rock (permeability) and a fluid that can collect and transport the heat to the surface. Deeper reservoirs often have high temperatures and a low permeability, whereas shallow reservoirs often have a high permeability but low temperatures. When the permeability is too low, the reservoir can be stimulated. This is conventionally done by fracking the reservoir rock; that is, creating fractures to enhance the flow. This is a very expensive and potentially hazardous operation. Another technique is Radial Jet Drilling (RJD), which uses a high pressure focused fluid jet in order to drill small diameter horizontal holes (laterals) from the vertical borehole. Laterals can be drilled in multiple directions of the borehole and can be as long as 100 metres, potentially increasing the production 3-8 times (Blöcher et al. 2016). However, the destruction mechanism of rocks during jetting is not yet fully understood. Experiments and simulations were conducted in order to investigate the destruction mechanism of a rock during jet impingement. First, experiments and simulations were carried out which had the aim to find a relation between stagnation pressure (exerted pressure on the rock by a water jet) and jetted cavity depth. The experiments provided information about the maximum jettable depth (with a static nozzle), while the simulations provided a continuous pressure depth relationship. Combining the simulation and experimental results leads to the conclusion that pressure fluctuations are key for the destruction process, which is consistent with the theorem of hydraulic fracturing. Furthermore, a Finite Difference Method (FDM) solver was developed in order to investigate the pore pressure inside a porous rock during jet impingement. The solver was used to investigate (1) the difference in pressure between the first layer of pores (adjacent to impinged area) and the fluid pressure of the jet and (2) the influence of an increased pore pressure in the whole sample (i.e., back pressure). It became clear that the pressure fluctuations in time between the pores and jet are significant and sufficient enough to induce hydraulic fracturing. Increasing the back pressure resulted in higher pressure fluctuations, but only when the back pressure is higher than the average jetting pressure. There are still some doubts in the literature in whether or not cavitation erosion is the governing destruction mechanism. Cavitation is the formation of vapour bubbles in a fluid due to fluid pressure drop below the vapour pressure. Once the bubbles travel to a higher pressure regime, they implode, creating either a shock wave or a mini jet, resulting in erosion of material. Hahn et al. (2019) and (Kumagaiet et al. (2011) evaluated the location of cavitation erosion on a flat surface and concluded that cavitation erosion is not the governing erosion mechanism as there was no damage at the impinged area. But those studies did not prove that cavitation erosion does not occur inside a hole. Experiments and simulations were therefore performed to investigate cavitation erosion inside a cavity. It is found that cavitation erosion does occur inside a cavity, even at cavity depths of &gt;25mm. However, experiments on one of the rocks showed that the maximum jetting depth was 25mm. From these results, it was concluded that although cavitation erosion occurs inside a cavity, it cannot be the governing destruction mechanism. Based on the results in this study, it is concluded that hydraulic fracturing is the governing erosion mechanism, because of the proved dependency of destruction on pressure fluctuations and the disprove of surface erosion due to shear forces (in literature, Buset et al. (2001)) and cavitation erosion being the governing mechanism. Another, in literature, proposed mechanism is pore-elastic tensile failure, which is partly interconnected with the theorem of hydraulic fracturing and not further investigated in this study. Based on this conclusion, a 'jetting correlation' was developed which is able to predict whether a rock is jettable or not. Combined with the pressure-depth relationship, it can also predict the maximum jetting depth. The correlation matched with the experimental results, which is another indication that hydraulic fracturing is the governing destruction mechanism.","Radial Jet Drilling","en","master thesis","","","","","","","","2022-08-15","","","","","SURE",""
"uuid:ed58420b-af86-48ea-be65-fcab9991902e","http://resolver.tudelft.nl/uuid:ed58420b-af86-48ea-be65-fcab9991902e","Passive design guidelines for Philippine housing based on the bahay kubo: Thermal comfort analyses and conceptual implementation of vernacular design strategies","Spittka, Rubin (TU Delft Civil Engineering and Geosciences)","Ham, Pieter (mentor); Nijsse, Rob (graduation committee); van den Ham, Eric (graduation committee); Spiegeler, Jasper (graduation committee); Delft University of Technology (degree granting institution)","2019","Philippine low-income housing is uncomfortable since it is not built to deal with the hot and humid climate in a passive way. Since local vernacular architecture is known to have a good climatic responsive performance, the aim of this research is to learn how Philippine vernacular design strategies can improve thermal comfort for low-lying, sub-urban and rural, low-income housing. The strategies studied are openings, eaves, stilts, orientation, roof insulation and roof angle. <br/> Two-day in-situ thermal measurements are used to study the comfort performance of the housing typology. To study the influence of the strategies or combinations of them on comfort, numerical predictions are used consisting of energy and CFD, wind-driven simulations. The numerical models are validated before the strategies are varied on a general case or a case study. The average exceeding temperature (AET) in Kelvin is used to assess comfort. It is calculated by accumulating for every hour of the year the exceeding temperature in Kelvin and divide this by the amount of hours that could be uncomfortable. A conceptual implementation study is performed to take disaster resilient and practical considerations into account. The impact of varying the strategies on the case study resulted in a reduction in AET of about 5 K for openings, 0.7 K for orientation, 0.6 K for eaves, 0.5 K for stilts and 0.1 K for roof insulation. On this basis, it can concluded that applying the guidelines as stated below, comfort increases significantly. More impact can be obtained if the strategies are implemented and combined as described by the passive design guidelines below. • To increase wind driven ventilation in wind direction, openings should be made on the wind- and leeward facade until ground floor, have an opening height (O<sub>h</sub>) based on the facade height (F<sub>h</sub>) by the rule of thumb: O<sub>h</sub>[m]=0.85·F<sub>h</sub>[m], include a leeward roof opening and include openings on the remaining facades. • Dependent on the wind direction, the openings should be opened accordingly. If no wind is present, all roof openings should be opened. During typhoons, they should be closed. • As much open area on facades in the main monsoon wind direction is advised. The openings on the other facades should be placed in the middle of the width to increase the performance with wind coming from the other directions. • Hinged eaves with a 15° angle and length calculated by the rule of thumb:  E<sub>l,15°</sub>[m]=0.6·F<sub>h</sub>[m] should be used. During typhoons they should be folded in to decrease the related pressures. <br/>• Increasing stilts height increases comfort by an exponential decay. To determine the height, a comfort increase of about 0.17 K for 1 meter, 0.30 K for 2 meter and 0.40 K for 3 meter in AET reduction are obtained. Braced, wooden stilts are advised to protect against floods and increase earthquake resilient behaviour. • A roof insulation with an Rc-value of 1 m<sup>2</sup>K/W is advised to gain about 0.2 K AET. Further research is needed on buoyancy driven ventilation to improve the provided design guidelines.","Passive Design; wind-driven flows; Natural ventilation; Phillippines; CFD simulations; Stilts; Openings; Orientation; Eaves; bahay kubo; Vernacular design strategies; climate responsive design strategies; Design guidelines; Average exceeding temperature; Thermal measurements; Low-income housing; Rubin Spittka; Implementation passive strategies; Energy calculation; Finch Floating Homes Project; Heat absorption; Thermal comfort performance; thermal performance; sustainable; sustainable design; bahay kubo strategies","en","master thesis","","","","","","","","","","","","Civil Engineering | Building Engineering","","12.8797,121.7740"
"uuid:14acd31d-7175-4da5-b78c-e0d53bd008fc","http://resolver.tudelft.nl/uuid:14acd31d-7175-4da5-b78c-e0d53bd008fc","Detection and Classification of Power System Disturbances Using Discrete Wavelet Transform and Pattern Recognition","Rasheed, Aminat (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Electrical Sustainable Energy)","Popov, Marjan (mentor); Palensky, Peter (graduation committee); Chavez Muro, Jose (graduation committee); Ghaffarian Niasar, Mohamad (graduation committee); Delft University of Technology (degree granting institution)","2019","In order to enhance the reliability of power systems, a continuous monitoring of the network to detect and clear disturbances is crucial. Fast detection and isolation of disturbances can prevent equipment damage, downtime and other adverse effects associated with their occurrence. The focus of this project is on the detection and classification of two non-linear, complex and severe disturbances: ferroresonance and arcing faults. These disturbances are detected and classified by continuous signal processing of the three-phase voltage and current signals. The models of these disturbances are simulated in EMTP and the three-phase voltage and current are extracted. The extracted data are pre-processed using the discrete wavelet transform (DWT) to extract fault signatures and features used in classifying the disturbances. A decision tree classifier is trained with the extracted features and it is able to detect and classify a disturbance as either ferroresonance or arcing faults using an adaptive time based on the disturbance class. The computational burden in the detection and classification process is reduced by using the superimposed component of the voltage and current to detect transient inceptions prior to classification. Adaptive dead time is adopted to classify the sustained period of the ferroresonance signals and to detect the extinction time of the secondary arc. The results show that the proposed methodology can detect the different ferroresonance modes and arcing faults with 99.8 % accuracy within 100 ms and classify the sustained modes afterwards.","Ferroresonance; arcing faults; detection and classification","en","master thesis","","","","","","","","2020-01-31","","","","Electrical Engineering","",""
"uuid:76dd292d-dec0-4a85-9342-58589cf77285","http://resolver.tudelft.nl/uuid:76dd292d-dec0-4a85-9342-58589cf77285","How to create a sustainable customer growth strategy for a small brand: to leverage branding and design for sustainable customer growth","Yang, Yujing (TU Delft Industrial Design Engineering; TU Delft Industrial Design)","Tassoul, Marc (mentor); de Jonge, Femke (mentor); Bakker-Wu, Sijia (graduation committee); Fust, Ruben (mentor); Delft University of Technology (degree granting institution)","2019","In order to realize sustainable customer growth, a company could adopt different strategies: opening up a new market, developing new products, etc. Based on the SWOT analysis, No Label is small and lacking capital, while its main target group (middle-class men, aged 25-45) is growing rapidly. Thus, No Label’s biggest opportunity lies in focusing on the current market and attract more potential customers within the market. After several interviews with its potential customers, the designer found the main challenge for converting its potential customers to real customers is that those people don’t hold a strong belief that No Label is a “relevant brand” and “My kind of product”. The believes that the brand is relevant could result in higher brand loyalty and positive responses to brand-driven activities such as their willingness to pay a premium price, keep purchasing the same brand, adopt new products and so on. This project focuses on leveraging branding and design to elicit the belief of ""relevant brand"" and ""My kind of product"", thus converting potential customers of No Lable.","Branding; Design; Customer growth; Research; Marketing communication","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:31afa88f-1829-4f64-be5a-c099f4bfce8d","http://resolver.tudelft.nl/uuid:31afa88f-1829-4f64-be5a-c099f4bfce8d","VR Mediated Teleoperation: Total workspace utilization using null-space projection control","Hoeba, Nirul (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Cognitive Robotics)","Abbink, David (mentor); van der Stap, Nanda (graduation committee); Kober, Jens (graduation committee); Delft University of Technology (degree granting institution)","2019","Joint limits and singularities limit the total and intuitive utilization of the robotic workspace in VR mediated teleoperation. This paper presents the development and validation of a novel null-space projection control method, used to adjust joint configurations of teleoperated robot arms containing joint limits and singularities. The novel null-space projection controller enables the operator to manually adjust invalid joint configurations. By doing so, we allow the operator to intuitively utilize the entire workspace of a teleoperated robot arm. A within-subject design experiment assessing operator task performance, acceptance and controller preference of 26 novel operators was executed. The participants were analyzed using the novel and the state-of-the-art end-effector controller for a trajectory following task. The novel controller significantly out-performed the end-effector controller in trajectory accuracy. Operators utilizing the novel controller use significantly less effort when operating the robot arm. The novel controller was also rated significantly more useful and satisfying than the end-effector controller, resulting in 81\% of the participants preferring the novel controller over the end-effector controller. Further development and future studies will explore the full capabilities of the novel controller, improve performance, user acceptance and explore additional applications.","Teleoperation; Virtual Reality; Robot arm control; null-space control; end-effector control","en","master thesis","","","","","","","","","","","","Mechanical Engineering","",""
"uuid:554cdc2b-76ac-4fd8-b08d-b3d6c5c012b5","http://resolver.tudelft.nl/uuid:554cdc2b-76ac-4fd8-b08d-b3d6c5c012b5","An analysis of the influence of the flood duration on slope stability: What is the influence of the flood duration on slope stability and in what degree affects the flood duration the design?","van Leeuwen, Pauline (TU Delft Civil Engineering and Geosciences)","Pol, Joost (mentor); Kok, Matthijs (graduation committee); van den Eijnden, Bram (graduation committee); Kanning, Wim (graduation committee); Delft University of Technology (degree granting institution)","2019","In most current dike assessments only the stationary water levels are investigated in the assessment of the stability of the inner slope, while there are differences for all kind of dikes between the stationary and transient pore water pressures and therefore in the stability. This results in a conservative probability of failure, while determination of a probability of failure should not be conservative but should be as realistic as possible. When time dependency is included in a calculation, an average flood duration is used, while the flood duration is highly variable. The following research question is defined to address the problem: “What is the influence of the flood duration on slope stability and in what degree affects the flood duration the design?” The degree of influence of time dependency on the pore water pressures and slope stability depends on dike characteristics, flood wave characteristics and the delay in failure. The basis for answering the research question is the software SEEP/W to model the time dependent pore water pressures and the software SLOPE/W to calculate the safety factor for the stability of the inner slope. In the research theoretical dike are used and there is focused on the flood waves in the Rhine and Meuse. A correlation analysis is performed to get insight in the contribution of different flood wave shape variables to the safety factor. And a probabilistic analysis is performed using transient and stationary water levels to know the differences in probability of failure between taking the shape of a flood wave into account or not. In both probabilistic analyses is varied in the permeability and the strength of the material; the shape of the flood waves is varied in the transient analysis. In this way the contribution of the flood to the probability of failure can be quantified. Dike characteristics The differences in pore water pressure are especially large for dikes that consist of an impermeable material such as clay. When only the subsoil consists of clay, larger differences are expected than when only the dike body consist of clay. However, large differences in pore water pressures do not necessary lead to large differences in the safety factor. The largest differences in safety factor are obtained when uplifting of the hinterland takes place during the stationary state and/ or during the passage of a flood wave. A transient calculation is therefore most useful for dikes with an aquifer and a thin (thinner than 5 m) weak (low POP values) hinterland. Flood wave characteristics The differences in safety factor during a permanent water level and the passage of a flood wave are large when no stationary conditions are reached during the passage of a flood wave. This is the case for high and short flood waves. Both in the Rhine and Meuse, the amount of short waves (&lt; 7days) is high, which increases the influence of a time dependent calculation. Also, the importance of a time dependent calculation increases when the response to the increased pore water pressures is delayed caused by the permeability of the material. The influence of the height of a flood wave on the stability increases when the soil is permeable. Delay in failure Time dependency causes failure of the embankment to not occur simultaneously with the maximum wave height. The flood wave is decisive for the dike failure, but the permeability and the strength of the dike determines the moment of failure. Influence on design Taking time dependency into account leads to higher safety factors and lower probabilities of failure with exception for dikes that consist completely out of sand. For these types of dikes, the probability of failure and safety factors are the same order of magnitude. This could affect the design, because the dikes are safer when time dependency is considered. The strength of the material is the largest contributor to the distribution of safety factors and therefore to the probability of failure (60-95%). Whereas the contribution of the permeability to the probability of failure is small (2-12%), the variation in the height and duration of a flood wave contribute for 2-20% to the probability of failure. In a permeable dike this contribution is mainly determined by the height of a flood wave, while in an impermeable dike the duration of a flood wave is of importance. Considering the influence of time in stability probabilities of failure, this research proved that probabilities of failure taking the duration into account differ significantly from stationary calculations. It is therefore useful to take time dependency into account when determining the correct safety factor for impermeable dikes, but it is not useful in determining the correct safety factor for permeable dikes, because a stationary calculation is sufficient. In clay dikes it is useful to take the variation in height and duration into account, while for a sand dike it is sufficient to only consider the variation in height of a flood wave. When the variation of the duration of a flood wave is not considered, it is recommended to use a representative duration of a flood wave; that results in the same total probability of failure as when the variation of the duration is included. At Lobith the duration of the representative flood wave varies from 13 - 16 days. At Borgharen the representative duration varies between the 10 – 11 days for different dike types.","","en","master thesis","","","","","","","","","","","","Civil Engineering | Hydraulic Engineering","",""
"uuid:7d998552-d78b-4b8e-b048-fa622ced2f6a","http://resolver.tudelft.nl/uuid:7d998552-d78b-4b8e-b048-fa622ced2f6a","Voxel-based additive manufacturing of biomimetic multiscale anisotropic materials","Gunashekar, Deepthishre (TU Delft Mechanical, Maritime and Materials Engineering)","Mirzaali Mazandarani, M. (mentor); Zadpoor, A.A. (mentor); Delft University of Technology (degree granting institution)","2019","Polymer composites are found to have high performance efficiency because of its highly flexible polymer matrix and stiff fibres or functional fillers. The matrix and the reinforcements are two main components for a strong and tough composite. The performance of these composites highly depend on the material property of the matrix and the reinforcement, volume fraction of the fibre and the matrix ,and the geometry and the orientation of the matrix and the reinforcements. Here material selected for the composites are polymers and the volume fraction is kept constant. Playing with the geometry and the orientation of the matrix and reinforcements will help in improving the mechanical behaviour of the composite. With nature providing intrinsic designs after undergoing various environmental stresses and strains, like in bone, nacre, wood etc, to achieve high strength and toughness, these designs can be taken as bio-inspiration for the structural modifications in the matrix and reinforcements. Analysis of these nature’s designs brings us to common design motifs like hierarchy, structural anisotropy and functional gradients. In this research, polymer composites have been designed for improved performance by adapting various design motifs in the matrix and reinforcements. These geometrical variations being done in the micro-scale, the composites are manufactured using Object350 Connex3 polyjet 3D printing technique for higher design accuracy. This is a voxel based 3D printing technique which uses a strategic placement of different materials with high accuracy using polyjet technology.","polymers; bioinspired composites; hierarchy; anisotropy; voxel based additive manufacturing","en","master thesis","","","","","","","","2020-12-31","","","","Biomedical Engineering","",""
"uuid:10c33647-8d88-4091-b3c0-3ed4222f270c","http://resolver.tudelft.nl/uuid:10c33647-8d88-4091-b3c0-3ed4222f270c","Zr- and Zr- based bulk metallic glasses: a multifunctional coating by plasma electrolytic oxidation containing Ag nanoparticles for trauma and orthopaedic implants","Meeuwis, Max (TU Delft Mechanical, Maritime and Materials Engineering)","Apachitei, I. (mentor); Zadpoor, A.A. (graduation committee); Sietsma, J. (graduation committee); Delft University of Technology (degree granting institution)","2019","To keep patients mobile and to treat injuries to improve the quality of life, functional biomaterials for implants and prosthesis are designed. Apart from growing demand in orthopaedic replacement and trauma surgeries, the number of revisions surgeries is increasing as well. Revisions surgeries are performed after the life-time of the implant has exceeded, but also due to implant failure. The latter is mainly caused by mechanical failure. Metallic glasses form a promising class of metallic materials possessing an amorphous structure. When such an alloy can be formed in rods over 1 mm in diameter, it is called a bulk metallic glass (BMG). Compared to the currently used crystalline alloys, BMGs possess several beneficial mechanical properties over the currently applied crystalline biomaterials. Next to mechanical failure, implant loosening by lack of osseointegration and an implant associated infection (IAI) are a reason for necessary revision. In the US, 2% joint prostheses and 5% of fracturefixation devices become infected. After bone implantation, there is a competition in the colonisation of the implant by human bone cells and bacteria, in which the surface morphology and biochemistry have influence. Predominantly S. aureus cause IAI. In most cases, antibiotics are effective, but there is a rising incidence in stems, like methicillin-resistant S. aureus (MRSA), resistant to commonly used antibiotics. A local general antiseptic effect from the implant material is desired. There is a rising interest for the use of silver nanoparticles (AgNPs), which a potent bactericidal effect, while the cytotoxicity is low to mammalian cells. Also desired is improved osteointegration sought after by a large specific surface area that is osteoconductive. Plasma electrolytic oxidation (PEO) can create a firmly adhered coating with high porosity on some materials. AgNPs in a PEO coating on BMGs is a strategy to reduce revision surgeries by better mechanical properties, improved osteointegration, and protection against IAI. The synthesis of a multi-functional PEO coating on Ti- and Zr- based BMGs is described by a total approach. Ni and Be-free BMGs were produced in cooperation with the ETH Zürich of nominal compositions; Zr60.5Cu10.2Al8.9Fe10.2Ag9.7Ti0.5 (Zr605), Zr62.5Cu22.5Al10Fe5 (Zr625), and Ti47Zr7.5Cu38-Fe2.5Ag2Sn2Si1 (Ti47). A PEO coating was successfully made on BMGs with a DC power supply in combined galvanostatic and potentiostatic mode of 4 A and 350 V, respectively. Incorporation of Ag-NPs in the coating was achieved, confirmed with EDS. The surface morphology was characterised with XRD, SEM and EDS. The viability of MC3T3-E1 pre-osteoblasts was confirmed on the untreated, PEO treated BMGs, and PEO treated with AgNPs. Moreover, the antibacterial effect of the PEO coated BMGs with AgNPs against MRSA was demonstrated in vitro by a zone of inhibition in an agar leaching assay. Ag-containing BMGs has a small zone of inhibition as well after PEO treatment. Probably, there is a (synergistic) bactericidal effect with Cu and Ag, deduced from the ion release kinetics in PBS measured by ICP-OES. From initial tests, the strategy of a multi-functional coating to reduce revision surgeries and improve the quality of life for patients holds promise. The described PEO process with DC could be a starting point from where PEO coating on BMG coatings can be optimised. The mechanical performance, especially the fatigue endurance with and without coating, should be assessed. The in vitro and biological performance of should be extensively evaluated before proceeding to in vivo experiments.","Bulk metallic glasses; Plasma electrolytic oxidation; Zr-based BMG; Ti-Based BMG; Ti-6Al-4V; in vitro; MRSA","en","master thesis","","","","","","","","2023-08-14","","","","Biomedical Engineering","","52.000813, 4.371183"
"uuid:a39f65de-2dda-4042-b2a9-b6357ba6ce0e","http://resolver.tudelft.nl/uuid:a39f65de-2dda-4042-b2a9-b6357ba6ce0e","Facilitating the process of carbon abatement policymaking by exposing the complexities of GHG reduction","Swart, Freek (TU Delft Technology, Policy and Management)","Chappin, E.J.L. (mentor); de Vries, G. (graduation committee); Bouwmans, I. (graduation committee); Delft University of Technology (degree granting institution)","2019","Binding climate agreements and the necessity to lower greenhouse gas emission levels requires increasing implementation of carbon abatement options and supporting policies on a global level. Due to the wide range of possible strategies, policymakers experience problems in choosing the right carbon<br/>abatement strategy. This challenge has led to the creation of the Y-factor, which provides a high-level overview of the complexities to deal with when implementing abatement options. However, the YFactor has not yet reached the stage of development to be ready for an introduction into the policy arena. It has not yet established a reputation, and is still relatively underdeveloped in comparison with alternatives and has no proven functionality in real-world situations. By applying the theoretical framework of the policy cycle, conducting focus group sessions and interviews with policymakers, this research has tested the applicability of the Y-factor for policymaking. This led to the conclusion that the Y-factor method could very well assist policymakers in the phase of policy formulation by highlighting the most important implementation barriers and facilitating discussions on how to tackle these. To increase its reliability and subsequently improve its usability for policymakers, it is advised to create carbon abatement reference curves on a national level.","Sustainable transition; Policy cycle; Marginal abatement cost curves; Y-factor; Climate strategy","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:c3463d7e-e618-41c8-b7fb-da0fc4078ee6","http://resolver.tudelft.nl/uuid:c3463d7e-e618-41c8-b7fb-da0fc4078ee6","Data-driven Business Model for a breakthrough technological product","Ganapathi Shanbhag, Avin (TU Delft Technology, Policy and Management; Royal HaskoningDHV)","de Reuver, G.A. (mentor); van de Kaa, G. (graduation committee); Tiago de Almeida, João (graduation committee); Delft University of Technology (degree granting institution)","2019","b>Problem:</b> Lack of Water Sanitation is a global problem due to the experiment-based research required in its field, hindering scientific progress. Commercializing breakthrough technologies in Water Sanitation into the market is uncertain and there comes a requirement to design to appropriate business models. The emergence of Big Data has led firms to potentially gain a competitive advantage and firms need to understand how Big Data creates changes in business models. Managers in the Wastewater industries aim to diffuse breakthrough technologies by leveraging big data. <b><br/></b><b>Goal/Objective: </b>The objective of this thesis is to understand and study how Big data creates changes in Business Models for firms. This study helps firms diffuse breakthrough technological products and contribute to the niche literature on Data-driven Business Models (DDBM).<br/><b>Design/Methodology/Approach: </b>This thesis consists of a Single Case Study Design within a firm with a breakthrough technological product. The study consists of 17 semi-structured interviews across various units of analysis and a Focus Group exercise with 6 participants of a business unit with a breakthrough technological product. The interviews and archival records are transcribed, coded and analysed through a qualitative data software and a logical chain of evidence is maintained for validity and reliability.<br/><b>Findings:</b> The Case Study research has dealt deeper into the dimensions of the business model for a firm where there are significant changes in the Value Creation &amp; Value Proposition phase of a Business Model. The study showcases how a Datatized Organization can be achieved by leveraging Big Data, what the organization management and governance changes are required, what the various data-driven activities are in order to leverage big data, and what the data-driven competencies that are needed to perform the various data-driven activities. Furthermore, a Data-driven Value Proposition has been derived for a business unit.<br/><b>Research Limitation/Implications:</b> Due to the lack of a team of investigators to collect the necessary data from multiple cases and coding the qualitative data was not possible due to the characteristic of the specific master thesis project. However, various validation and generalization techniques have been used to build the internal, external and construct validity. The thesis provides future researchers to aid the theoretical development of logically consistent explanations of the relationships (linkages) between well-defined components (constructs) of DDBMs.<br/><b>Originality/Value: </b>This study highlights how Big Data creates changes in the business models of firms with a breakthrough technological product, thereby adding to the body of knowledge of Data-driven business models. The uniqueness of this study is the breakthrough technological product that was chosen to keep the Value Proposition phase of the business model as constant as possible and study the changes in the other phases.","Business models; Big Data; Data-driven business models; Organizational change management; Organization Governance; Data-driven activities; Data-driven competencies; Data-enabled activities; Data-enriched products & services","en","master thesis","","","","","","","","2021-08-14","","","","Management of Technology (MoT)","",""
"uuid:d9bd17ba-e551-41da-a5c3-62dbed6d85fa","http://resolver.tudelft.nl/uuid:d9bd17ba-e551-41da-a5c3-62dbed6d85fa","Perylene as Cathode for Magnesium Batteries: A feasibility study","Shetty, Bhavya (TU Delft Electrical Engineering, Mathematics and Computer Science)","Kelder, E.M. (mentor); Jager, W.F. (graduation committee); Sudhölter, Ernst J. R. (graduation committee); Delft University of Technology (degree granting institution)","2019","Magnesium ion batteries (MIB) have attracted much attention from battery researchers around the globe. Magnesium is divalent in nature and offer a higher theoretical capacity than that of lithium. However, the magnesium research is still in the niche stage and the search continues for better electrolyte systems and for high voltage cathode materials. Currently, extensive research is being done in employing organic materials for battery cathode materials. Organic materials are made from naturally occurring compounds and are easy to dispose since they have no metals. Perylene diimide is an organic material gaining importance as cathode material in metal ion batteries.<br/><br/>The goal of the project is to determine the voltage window of perylene in lithium and magnesium battery systems. Cyclic Voltammetry (CV) is employed to measure the electrochemical activity of the cell. The output of the CV is a scan of the current versus the voltage. During the operation of the cell, duck shaped peaks are observed which correspond to the reduction/oxidation activity of the cathode and the anode respectively. The current corresponding to the peaks is used to determine the cathodic and anodic current of the cell. Once the voltage and the current are known, the area under the peaks is calculated to determine the<br/>charge/discharge capacity of the cell.<br/><br/>Since no prior research was done on magnesium, the most common cathode material (inorganic), chevrel phase molybdenum sulphide is synthesized and tested. Research with the perylene as cathode material is started with lithium because lithium is being studied extensively in the research group. Tests with both the monomer and the polymer has been conducted against lithium and magnesium battery systems. The lithium cell employing perylene is optimized as much as possible and is shown to be electrochemically active. The lithium cell shows a redox voltage of 2.5V vs Li/Li+. In the magnesium system, perylene is active as small peaks are observed at 1.5V and 1.7V vs Mg/Mg2+. However, the cell fails to operate after the first charge. This is most likely due to the electrolyte forming a passive film on the surface of the anode. It is recommended to disassemble the magnesium cell after the first discharge cycle to observe the magnesiation on the cathode and the passive film formation on the anode.<br","Perylene; Cyclic voltammetry; lithium ion battery; Magnesium-ion battery","en","master thesis","","","","","","","","2021-08-15","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:b5679758-343d-4437-b202-86b3c5cef6aa","http://resolver.tudelft.nl/uuid:b5679758-343d-4437-b202-86b3c5cef6aa","Design of an Ethical Toolkit for the Development of AI Applications","Sosa Hidalgo, Mario (TU Delft Industrial Design Engineering)","Price, Rebecca (mentor); Sturkenboom, Nick (graduation committee); Veldman, Sebastian (graduation committee); Delft University of Technology (degree granting institution)","2019","Artificial Intelligence (AI) is one of the most groundbreaking developments of the last half-century. More and more organizations are either implementing AI or considering its application to optimize their lines of business. At the same time, this exponential growth has also raised questions regarding its ethical implications and societal consequences. As many commercial intelligent applications are becoming ubiquitous, and some are getting implemented in higher levels of decision making, it is extremely important to consider the societal and ethical results of this “digital transformation” process. Organizations should understand where their AI comes from as well as whom they are helping or affecting when implementing it. <br/><br/>This situation opens a new window of opportunity for the development of ethical tools that assist companies in the responsible implementation of AI, as well as the current and future business opportunities that this represents. The current thesis explores the ethics of the development of AI applications and its implementation in MOBGEN | Accenture Interactive projects. By including an ethical perspective towards the application of this technology, the organization will improve its value proposition and prevent future unintended and harmful outcomes for the organization and their clients.<br/><br/>Accordingly, the current thesis focuses on understanding the ethical views and future concerns of all the stakeholders involved in the development of AI applications. This is done by following a double diamond design process, which simultaneously includes the execution of a couple of Action Research cycles to generate awareness on the topic inside the organization.<br/><br/>A detailed literature review, several in-depth interviews, and an intense empirical research effort are conducted to understand the current AI ethics context. This reveals a considerable large amount of insights, which are translated to ethical principles and, afterward, transformed into design principles. At the same time, these principles led to the creation of a theoretical framework intended to assist in the ethical evaluation of AI-related projects.<br/><br/>Based on this theoretical framework, a toolkit is designed to help the development teams of MOBGEN | Accenture Interactive with the ethical assessment of AI applications. The toolkit is designed in the form of a “full-day” workshop, which is composed by seven different modules distributed into two major strategic phases. These modules are designed to assist in the generation of ideas and support ethical dialogue creatively and collaboratively.<br/><br/>Finally, a total of six evaluation sessions with MOBGEN | Accenture Interactive and other external stakeholders validated the design toolkit, serving as the perfect preface to recommendations for further development. These recommendations include the development of ethical frameworks using design methods, measuring the ethical impact AI systems, and to enhance research on AI ethics from a design perspective.<br","Toolkit; Ethics; Artificial Intelligence; Strategic Design","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:47212ffd-ba35-4a6e-a654-2c1b16526ce6","http://resolver.tudelft.nl/uuid:47212ffd-ba35-4a6e-a654-2c1b16526ce6","Towards Risk-based Prioritisation of Primary Navigation Locks: As an improvement to the existing method used for scheduling renovation work","Kemper, Arno (TU Delft Civil Engineering and Geosciences)","Jonkman, Sebastiaan N. (mentor); Voorendt, M.Z. (graduation committee); van den Boomen, M. (graduation committee); van den Berg, Stefan (graduation committee); Harmsen, Manon (graduation committee); Delft University of Technology (degree granting institution)","2019","The operation and maintenance of most of the Dutch primary navigation locks are the responsibility of Rijkswaterstaat. The portfolio of Rijkswaterstaat consists of 52 primary navigation locks that are part of the primary flood defence. All these navigation locks are assigned a safety norm together with the adjacent water-retaining bodies. For both main functions, norms and acts are defined that prescribe a certain level of performance. Rijkswaterstaat is responsible that all its primary navigation locks do meet the safety or nautical requirements.Most of the primary navigation locks are built in the first two decades of the 20th century. In principle, Rijkswaterstaat considers a functional lifetime of their navigation locks, equal to 100 years. A number of these navigation locks are technically modified to extend the functional lifetime. In the coming decades, many of these navigation locks have to be renovated in order to meet new norms or requirements. It might that not all the renovation work can be executed in the same period of time. Therefore, the works have to be scheduled and given a priority when they will be renovated. In the existing method, the ”Vervanging&Renovatie” (V&R) prioritisation, one indicator is considered that entails the remaining lifetime as a function of the design lifetime.A risk analysis is conducted regarding the flood safety and nautical requirements of navigation locks. Given the requirements for the flood safety and nautical function, three drivers are defined that affect these functions: climate change, intensity growth, and ageing of material. For these drivers, a number of aspects are distinguished that affect either the flood safety or nautical function. The combination of aspects is framed in a method that can be used to assess the urgency of renovation, relative to the norms en requirements that are linked to the aspects. For each aspect, it is assessed at what moment in time the norm is exceeded. This result is compared to the existing V&R prioritisation of renovation works. Given both methods, it can be concluded whether or not the proposed moment of renovation is according to the required moment of renovation, to safeguard the nautical and flood safety functions.Validation of the proposed method of prioritisation is established via two case studies. The main conclusion of the case studies is that the existing method of prioritising the renovation work of primary navigation locks is not optimal. A number of aspects, as these are assessed in the case study, indicate that the required moment of renovation is before the moment according to the V&R prioritisation. This conclusion is based on the expected performance in the (near) future relative to the required performance that follows from legislation. Some aspects show deviations of up to 40 years relative to the V&R prioritisation Apart from the assessment of the aspects based on the norms, a criticality assessment is conducted. For all aspects as defined in the prioritisation method, the effect of a ”postponed” moment of renovation is balanced with a proposed mitigation measure. This is done with the use of a modified FMECA. It is assumed that the mitigation measure reduces the likelihood of occurrence of the aspect to zero. The costs that are the result of a mitigation measure are compared with the costs of ”doing nothing”. This implies that the consequences of a postponed renovation are expressed in financial terms, in order to balance this with the mitigation measure. In this way, the results of the case studies are financially weighted, independent of whether or not they serve the nautical function or the flood safety function.","Prioritisation; Navigation locks; Renovation; Criticality; FMECA","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:877f5299-ac54-4b8b-9b49-1d237d55e661","http://resolver.tudelft.nl/uuid:877f5299-ac54-4b8b-9b49-1d237d55e661","Crowdsourced Knowledge Base Construction using Text-Based Conversational Agents","Enreina Annisa Rizkiasri, Enreina (TU Delft Electrical Engineering, Mathematics and Computer Science)","Bozzon, Alessandro (mentor); Qiu, Sihang (mentor); Houben, Geert-Jan (graduation committee); Pouwelse, Johan (graduation committee); Delft University of Technology (degree granting institution)","2019","Knowledge Base Construction (KBC) is a challenging and complex task involving several substeps and many experts of a knowledge domain. Crowdsourcing approach has been used to support KBC with promising scalability and output quality, but to enable even more people to participate in KBC, there is a need to broaden the pool of workers beyond the ones who are already familiar with existing crowdsourcing platforms. Meanwhile, the number of people who use messaging platforms has been increasing. There is also a renowned popularity of text-based conversational agents -- chatbots -- existing on these messaging platforms. By leveraging the fact that there is a large number of users who are familiar with conversational interfaces, we see an opportunity to broaden the participants of crowdsourced KBC by using chatbots to execute KBC tasks. In this thesis, we investigate the use of chatbots to enable crowdsourced construction of knowledge bases. We design a conversational crowdsourcing platform to support the execution of KBC tasks. An experiment involving 43 students using our system and interviews with 7 participants were conducted to evaluate the system within the context of constructing a knowledge base for the TU Delft campus. From the results, we show that the platform is suitable to be used for crowdsourced KBC with justifiable execution time, accuracy, and completeness. We also laid out the potential future work to improve and extend the functionalities of the chatbot system.","Knowledge Base Construction; Conversational Agents; Chatbot; Crowdsourcing","en","master thesis","","","","","","","","","","","","Computer Science | Data Science and Technology","",""
"uuid:58190053-89a4-4329-b23e-ea6a605a0bbd","http://resolver.tudelft.nl/uuid:58190053-89a4-4329-b23e-ea6a605a0bbd","Optimization of Kiln Feed Yield through an Analysis of Drilling and Blasting Parameters in a Quarry","Waheed, Atif (TU Delft Civil Engineering and Geosciences)","Buxton, Mike (mentor); Hennig, Dr. Alexander (mentor); Guerrero, Dr. Rodrigo Serna (mentor); Weimer, Lucas (mentor); Delft University of Technology (degree granting institution)","2019","Blasting and drilling serves as an essential element for a mining operation to excel. Optimization of this operational aspect, requires consideration of various parameters that can be controllable or uncontrollable. To overcome the tediousness of analyzing each element selectively, some major parameters are outlined, and each blast is rendered relative to the other, by organizing the data from each blast design and integrating it in an empirical model called Kuz-Ram Model, which further can be used for predicting the impact of these parameters on fragmentation. Image analysis aids in validating the model credibility for using it as step forward for proposing alterations to the current practices in drilling and blasting area. Each image is processed with the help of Unmanned Aerial Vehicle, for safety and coverage of complete muck-pile. The study involves in depth focus on the impact of rock mass characteristic over fragmentation as well. Discontinuities, fractures, joint orientation and fillings are considered in designating each rock zone to specific class with the help of a geo-mechanical classification system called, Rock Mass Rating. To test the theory, an exercise is performed by separating two zones of variable rock mass properties and then the procedure is followed with empirical calculation, image analysis and supported by preferential loading to acquire a broad image of each zone fragmentation profile. Suggesting the variation in particle size distribution due to rock mass influence. The collected data and analyses shall serve as supporting tools for changes to blast design for obtaining desired fragmentation, which is synonymous to increasing the feed of kilns.","Mining; Blasting; Empirical models; Image analysis","en","master thesis","","","","","","","","","","","","","",""
"uuid:46a474be-b3ef-4225-b01c-7a8d0a436722","http://resolver.tudelft.nl/uuid:46a474be-b3ef-4225-b01c-7a8d0a436722","Establishing Business Ecosystems for Smart Living services: A case study on how to improve the robustness of the underlying networked Business Model","Koorevaar, Lennart (TU Delft Technology, Policy and Management)","Bouwman, Harry (mentor); Roosenboom-Kwee, Zenlin (graduation committee); Delft University of Technology (degree granting institution)","2019","Smart Living falls under the broader rubric of Internet of Things (IoT) and is described as a residence with connected technologies that are able to anticipate and respond to occupants’ emotional, rational, social, economic, and physical needs. Because Smart Living services have a networked nature, collaboration between actors in the business environment is essential. However, Smart Living services have hardly ever been realized on a large scale, and the various features are often not integrated. From a strategical viewpoint, this is caused by a lack of alignment between service providers. Consequently, the robustness of the underlying networked Business Model is often limited. This research presents a process framework which serves as a guideline for establishing a Business Ecosystem for Smart Living services. Central to this framework is an approach to analyze interactor relationships in a dynamic model. This model reveals alignment, misalignments and conflicts in actors’ interdependencies and interactions. To resolve the identified misalignments and conflicts, activities can be devised to adapt the underlying networked Business Model with the objective of improving its robustness.","Business Ecosystems; Business Models; Business Model Robustness; Business Model Tooling; STOF Ontology; VIP Framework; Smart Living; Smart Homes; Internet of Things (IoT)","en","master thesis","","","","","","","","","","","","","",""
"uuid:b5539dcb-358b-410a-a3cb-21043a9228ce","http://resolver.tudelft.nl/uuid:b5539dcb-358b-410a-a3cb-21043a9228ce","Towards 5D BIM: A Process Map for Effective Design and Cost Estimation Integration","Kharoubi, Yara (TU Delft Civil Engineering and Geosciences)","Bakker, Hans (graduation committee); Lousberg, Louis (graduation committee); Annema, Jan Anne (graduation committee); hoeve, jasper (mentor); Delft University of Technology (degree granting institution)","2019","The construction industry faces problems in interoperability. Information is not easily interpreted nor accessed by participants. The insufficient level of interoperability occurs due to fragmentation between disciplines in the construction industry. To enhance interoperability, Building Information Modeling (BIM) formed a collaborative model that connects team members. However, the different disciplines continue to share information that cannot be directly used by others. This situation is present between designers and cost engineers. Despite working in a 5D BIM model that considers cost information, fragmentation between these disciplines persisted. Costs do not guide the design and they are computed after the model matures. Furthermore, the detachment of design and cost estimation processes led to the segregation of information in BIM. Addressing the problem of fragmentation between processes, the research aims at investigating the main question: How can design and cost estimation be effectively integrated using 5D BIM?<br/>To answer the research question, several steps were performed. From the case study research, the following issues on fragmentation and BIM application are identified: [1] unsteady involvement of the cost engineer in the design, [2] limited influence of the cost engineer on the design, [3] model complexity, [4] incompatibility of model information and cost estimation, [5] absence of standardized and uniform information representation, and [6] resistance of clients and practitioners to the application of BIM/5D BIM.<br/>By countering these issues, the “Integrated Design – Cost Estimation 5D BIM Process” is designed to answer the research question. The integration between design and cost estimation via 5D BIM focuses on cost driving components which are components influencing costs. Accordingly, these components are considered as key for communication, discussions between designers and cost engineers, and model development. Focusing on cost driving components, the process balances the information in the model. The information in the model is checked for compatibility with the estimate’s accuracy. Furthermore, the process proposes the consideration of the cost engineer’s perspective in the design. Then, 5D BIM is incorporated in the designed process by standardizing information and following the semi-automated approach for cost computation. <br/>To assess the effectiveness of the integration addressed in the research question, a pilot case is performed to test the process in a running project. From the observations, it is concluded that the process provided a standard representation of objects, enhanced the communication between the designer and cost engineer, and involved the cost engineer earlier in the design. Furthermore, the pilot case led to the conclusion on barriers to BIM implementation. These include: the cultural change from individual effort to collaboration, lack of support from the management and client, inadequate planning for BIM application, and the inexperience in applying 5D BIM. These factors limited the successful implementation to reach effective integration. Despite the limited integration achieved in the pilot case, project participants and interviewed BIM experts ensured that the process leads to effective integration. However, it is crucial to respond to the noted barriers to have effective integration between designers and cost engineers via 5D BIM.","BIM; Design; Integration; Cost Estimation; 5D BIM; process","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:1c3a9e32-3963-4d25-8f5f-cc3842cf5a2b","http://resolver.tudelft.nl/uuid:1c3a9e32-3963-4d25-8f5f-cc3842cf5a2b","Investigation of Wind Turbine Fatigue Loads under Wind Farm Control: Analysis of Field Measurements","Tagliatti, Federico (TU Delft Aerospace Engineering)","Andersen, Søren (mentor); Giebel, Gregor (mentor); Gocmen, Tuhfe (mentor); Bierbooms, Wim (mentor); Duc, Thomas (graduation committee); Alloin, Lucas (graduation committee); Delft University of Technology (degree granting institution); Technical University of Denmark (degree granting institution)","2019","Wind energy is one of the most promising sources of renewable energy and has experienced a very rapid growth in the last 15 years. In order to maintain and sustain this growth wind energy needs to be competitive with the other sources of energy, especially with fossil fuels. A major factor keeping the competitiveness of wind energy is the sustained investment made on research and innovation. Active wake wind farm control is part of the research effort that aims to reduce the cost of producing wind energy; these new control strategies have the goal of reducing wind turbine wakes interactions in order to increase the power production and to minimize loads and fatigue. <br/>Literature shows good potential for these control strategies; however most of the studies have been made in a virtual environment through the use of computer simulations and as a consequence there is a lack of real field measurement data analysis that could confirm the potential of these strategies. The French National Research Agency SMARTEOLE project implemented two wind farm control strategies in an operating wind farm called La Sole du Moulin Vieux and owned by Engie Green in order to assess the effects that the applied innovative wind farm control strategies have on the blade loads, particularly in terms of blade fatigue. The two wind farm control strategies applied are the curtailment strategy and the yaw-control strategy.<br/>It needs to be noted that due to the high sensitivity of loads and fatigue to inflow conditions and due to the limited amount of data available the results observed should be considered as general trends very specific for this particular wind turbine set up and location. <br/>In the curtailment strategy the upstream turbine SMV6 loads decreased up to 33% (at 9 m/s) in the flapwise direction and up to 67% (at 8 m/s) in the edgewise direction. Fatigue loads decreased up to 22% (at 9 m/s) in the flapwise direction and up to 2% (at 9 m/s) in the edgewise direction. In the downstream turbine no clear trend has been detected due to the high uncertainty in the results. Most likely low amount of data and increased turbulence in the downstream turbine led to this uncertainty in the trends. <br/>In the yaw-control strategy loads showed a decrease up to 8% (at 9 m/s) in the flapwise direction loads and up to 72% (at 9 m/s) in the edgewise direction loads for the upstream turbine SMV6. Fatigue also decreased up to 19% (at 11 m/s) in the flapwise direction loads and up to 1.3% (at 10 m/s) in the edgewise direction for the upstream turbine. The downstream turbine SMV5 showed no significant reductions in the flapwise loads and fatigue when the whole wake was analyzed but, when the full-wake only was analyzed, a significant increase in loads and power produced, without any significant increase in fatigue loads have been observed. This underlines the potential of the yaw-controlled strategy to increase power production without significantly increasing fatigue.","Wind farm control; Load Measurements; Fatigue Analysis","en","master thesis","","","","","","","","","","","","European Wind Energy Masters (EWEM) | Rotor Design Track","",""
"uuid:adf34b26-fd31-4111-b8c7-a30a021d9b11","http://resolver.tudelft.nl/uuid:adf34b26-fd31-4111-b8c7-a30a021d9b11","Designing a Smart User Feedback System for a Cordless Vacuum Cleaner","Chen, YingJu (TU Delft Industrial Design Engineering)","van Egmond, Rene (mentor); Keller, Ianus (mentor); Delft University of Technology (degree granting institution)","2019","Nowadays people become busier than ever before. Even though people still have 24 hours in each day, it feels as if no one has “free time” to do anything. Thus, busy people prefer using their limited time to clean the most important area indeed. It is how the idea “dust map” came. Users can create the map by themselves and the appliance will collect data to predict or explain the level of cleanliness at home. In this way, users are able to know which area should be cleaned the most and which area can be skipped out of their limited time. The project is to redesign the UI of Philips SpeedPro Max, based on this futuristic idea.","user interface design; vacuum cleaner; Efficiency","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:9cabca9d-d56b-463c-9ee1-80670dc386d7","http://resolver.tudelft.nl/uuid:9cabca9d-d56b-463c-9ee1-80670dc386d7","Inspecting crossing geometry: Tool development for manual inspections of crossing geometry","Wegdam, Jeroen (TU Delft Civil Engineering and Geosciences)","Markine, V.L. (mentor); Liu, X. (graduation committee); Delft University of Technology (degree granting institution)","2019","Turnouts allow trains to change from one track to another. Therefore, they are an essential part of infrastructure to create and operate a railway network. This project focuses on the (common) crossing; the part of the turnout where the inner rails cross through one another. Because of the shape of the wheels, it is necessary to create a discontinuity in the rail at this location. As a consequence, wheels experience a disturbed support which causes wear, deformation and fatigue on the crossing. In the Netherlands, this problem has a high priority. This is because the Dutch railway network is unique in two ways; it is very dense and it has a high utilisation. Per km2 of land area, the Netherlands has the second highest amount of track length (right after Switzerland). Per km of track, the Netherlands has the second highest amount of passenger kilometres (right after Japan). The consequence is a set of 7000 that are relatively heavy loaded.<br/>In order to extend the lifetime of these crossings, they have to be monitored and maintained. In present practise, some deformations have to be cut off and cracks have to be ground away. This ensures safe wheel passages and prevents fatigue related failures. Such practises are described well, within the current norms.<br/>A less clear topic however, is the maintenance of geometry. Geometry is defined as the cross-sectional shape of the rail. As soon as the geometry of a crossing changes due to deformation and wear, the vehicle behaviour is influenced. Unfavourable geometry can lead to a big amplification of dynamic forces from passing wheelsets. For this reason, maintainers seek for favourable ways to assess and control the shape of worn/deformed crossings.","","en","student report","","","","","","","","","","","","Civil Engineering","Additional thesis project",""
"uuid:24eca76e-729f-4cba-9dae-3346c2f60b23","http://resolver.tudelft.nl/uuid:24eca76e-729f-4cba-9dae-3346c2f60b23","Constrained Multi-Aircraft Maintenance Scheduling Using Component Prognostics","Engelke, Anna (TU Delft Aerospace Engineering)","Verhagen, Wim (mentor); Mitici, Mihaela (mentor); Delft University of Technology (degree granting institution)","2019","In recent years, airlines have increasingly developed the ability to monitor the condition of aircraft components by means of sensors. In turn, aircraft maintenance aims to use this sensor data to predict component failures. However, the challenge remains to make use of these prognostics to generate appropriate maintenance schedules. In this paper, we develop a Monte-Carlo tree search to schedule maintenance tasks based on component prognostics and available maintenance slots. This approach is used to create a maintenance policy for multiple aircraft which specifies which aircraft are allocated for maintenance and on which days. The results show that the scheduling of the maintenance tasks is robust and able to accommodate the maintenance scheduling of smaller airline fleet sizes. Overall, our results support the integration of aircraft component prognostics in aircraft maintenance scheduling.","Multi-Aircraft; Prognostics; Maintenance Scheduling; Monte-Carlo Tree Search","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:e4f0fb85-a08e-48b5-a88b-cb54b7663a42","http://resolver.tudelft.nl/uuid:e4f0fb85-a08e-48b5-a88b-cb54b7663a42","Edge Computing on the Rise: Towards a Business Model Tool for Analyzing the Potential of Edge Computing for IoT Applications","Huisman, Michiel (TU Delft Technology, Policy and Management)","Ding, Aaron (mentor); de Reuver, Mark (graduation committee); Chappin, Emile (graduation committee); Delft University of Technology (degree granting institution)","2019","Edge computing can deliver substantial value to the general idea of the Internet of Things (IoT). However, there is a myriad of potential IoT applications for edge computing. Stakeholders are left with uncertainty about how the business potential of edge computing for these IoT applications can be identified. This research contributes in solving this, by designing a business model tool that can be used to identify the business model potential of edge computing for distinct IoT application areas, based on business model viability and feasibility. Through the Design Science Research Methodology (DSRM), the tool has been designed, demonstrated, and evaluated. Based on the STOF ontology, and supplemented by the theoretical domains of business ecosystems and platform theory, nine generic variables have been identified to explain business model viability and feasibility. These generic variables have in turn been contextualized towards the edge computing domain, in terms of 45 contextual input variables. This is the first research that unfolds these business model variables for edge computing.","Edge Computing; Decentralized Computing; Internet of Things (IoT); Business models; Business Model Tooling; Business Model Potential","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:3cbcc9f9-58d3-4548-9e29-92116e6d25a8","http://resolver.tudelft.nl/uuid:3cbcc9f9-58d3-4548-9e29-92116e6d25a8","Real-time anomaly detection in logs using rule mining and complex event processing at scale","Stavroulakis, Alexandros (TU Delft Electrical Engineering, Mathematics and Computer Science)","Katsifodimos, Asterios (mentor); Bozzon, Alessandro (graduation committee); Aniche, Maurício (graduation committee); Vincelli, Riccardo (graduation committee); Delft University of Technology (degree granting institution)","2019","Log data, produced from every computer system and program, are widely used as source of valuable information to monitor and understand their behavior and their health. However, as large-scale systems generate a massive amount of log data every minute, it is impossible to detect the cause of system failure by examining manually this huge size of data. Thus, there is a need for an automated tool for finding system's failure with little or none human effort. Nowadays lots of methods exist that try to detect anomalies on system's logs by analyzing and applying various algorithms such as machine learning algorithms. However, experts argue that a system error can not be found by looking into a single event, but in multiple log event data are necessary to understand the root cause of a problem. In this thesis work, we aim to detect patterns in sequential distributed system's logs that can capture effectively the abnormal behavior. Specifically as a first step, we will apply rule mining techniques to extract rules that represent an anomalous behavior, which potentially in the future may lead to a failure of a system. Except for that step, we implemented a real-time anomaly detection framework to detect problems before they actually occur. <br/>Processing log data as streams is the only way to achieve a real-time detection concept. In that direction we will process streaming log data using a complex event processing technique. Specifically, we would like to combine rule mining algorithms with complex event processing engine to raise alerts on abnormal log data based on automatically generated patterns. The evaluation of the work is conducted on Hadoop's logs, a widely used system in the industry. The outcome of this thesis project gives really promising results, reaching a Recall of 98\% in detecting anomalies. Finally, a scalable anomaly detection framework was build by integrating different systems into the cloud. The motivation behind this is the direct application of our framework to a real-life use case.","Anomaly Detection; Rule Mining; Complex Event Processing; Distributed File System; Streaming architecture; Log Analysis","en","master thesis","","","","","","","","","","","","Computer Science | Web Information Systems","",""
"uuid:bdb1e704-edf7-4be5-acba-704ac7fc536d","http://resolver.tudelft.nl/uuid:bdb1e704-edf7-4be5-acba-704ac7fc536d","Experience on the preparation of HPMC viscous fluid for physical modeling in the geocentrifuge","Quinten, Tristan (TU Delft Civil Engineering and Geosciences)","Askarinejad, Amin (mentor); Gavin, Kenneth (graduation committee); Delft University of Technology (degree granting institution)","2019","Investigating soil response before, during and following large scale, dynamic events like slope failure or impact hammering of monopiles, is challenging. Full scale research into these processes is often conducted in the field, as laboratories don’t offer the required space to conduct these experiments. Apart fromthe monumental costs related to full scale experiments, it is often impossible or impractical to define or portray all boundary conditions, which increases uncertainty. As an alternative to full scale field tests, centrifuge tests on a scaled model are often carried out. When conducting research in the centrifuge, the decrease in geometry is compensated by through the acceleration of the model to N times gravity g. In this way, full scale stress conditions are imposed on the sample. Consequently, the model offers an accurate representation of full scale soil behavior. However, artificial ’gravity’ enhancement impacts a broad range of physical quantities. Scaling laws dictate how physical quantities are affected by conditions in the centrifuge and require careful observation. Yet, the use of scaling laws introduces a discrepancy between the timescale related to dynamic events and diffusive processes. The latter is of particular importance to build-up and dissipation of deviatoric pore fluid pressures. Decreasing the permeability of the soil is generally the best option to eliminate the aforementioned discrepancy. Consequently, instead of water, viscous fluid is used for the centrifuge tests, where the viscosity is increased N times with respect to water. Over the years, various fluids have been developed and utilized in centrifuge experiments. A widely used fluid, consists of aqueous solutions (Hydroxypropyl) Methylcellulose or (HP)MC in short. HPMC molecules form polymeric chains which increase viscosity while largely maintaining the density of the solvent, water. These favorable properties make it a highly sought-after substitute for water in centrifuge experiments. Experience with the fabrication and use of (HP)MC solutions is limited at the centrifuge facility of Delft University of Technology. As part of an initiative to develop in-house knowledge relating to the aforementioned points for physical modeling purposes, this research presents a robust fabrication methodology and maps the viscous properties of HPMC solutions, fabricated usingMethocel® F4M, at various concentrations. Results indicate that advocated preparation methodology enables the fabrication of viscous fluids in the range of 10 to 100 mPa ¢ s of consistent quality. However, overall, the viscosities of the fluids created along the lines of the presented methodology are consistently more viscous than anticipated. Several hypotheses aimed explaining the discrepancy are drafted. However, the nature of the underlying cause remains a topic of debate. Furthermore, it is observed that the HPMC fluids express a substantial degree of shear thinning at high shear rates. The relative decrease in viscosity increases with concentration, causing the viscosities of fluids of different concentration to gradually converge at high shear rates. The latter stresses the importance of quantifying expected shear rates beforehand to prevent behavioral inconsistencies between model and prototype. However, under some circumstances, it is doubtful whether the use of viscous fluids created from Methocel® F4M is suitable to study prototype behavior. In an attempt to facilitate drafting of appropriate recipes for the fabrication of viscous fluid, a general expression is presented to calculate the required concentration, provided the desired viscosity and anticipated shear rate. This generic expression provides adequately describes the experimental data, but requires further tuning in order to fully fulfill its intended purpose. Nonetheless, it provides a valuable indication of the required concentration to obtain a fluid with sought-after properties; thereby shortening the time spent on drafting the ideal fluid recipe.","HPMC; Methylcellulose; Hydroxypropyl Methylcellulose; Viscous fluid; Methocel; Shear thinning; Physical modelling; Centrifuge modelling","en","student report","","","","","","","","","","","","Geo-Engineering","",""
"uuid:7ee4cd6a-c6bf-4da2-acef-baf88b642fa0","http://resolver.tudelft.nl/uuid:7ee4cd6a-c6bf-4da2-acef-baf88b642fa0","Edible sensor and barcode: for food packaging","Cramwinckel, Bas (TU Delft Applied Sciences)","Delft University of Technology (degree granting institution)","2019","To reduce food spillage and the counterfeiting of products an indicator is needed, which can indicate if a product is still suited for consumption. In this study a new indicator, made from a caseinate glycerol film, has been tested. The film breaks after exposure to humid air after a certain time. The indicator can indicate if a food product is still safe to eat or not and could indicate if a product packaging has been opened when transported. Three different compositions of the caseinate glycerol film were tested for their capacity to absorb water and for their strength. The highest water absorption in percentage of water per polymer was at the higher humidity level. The different compositions showed an increase in absorption depending on its thickness and glycerol content. The film which best absorbed the water was the thinnest film. This is explained by its relatively large surface area versus volume in comparison to the other two tested films. The difference in water absorption was ten times higher at 85% humidity as compared to the water absorption at 60%. From the strength test it appeared that the film with the lowest glycerol content was the film which broke the easiest after being exposed to humidity. The other samples did not break due to the limits of the equipment used. The sample who did break with lowest glycerol content for its volume shows the most potential to be used as an indicator because of the relatively low strain required to break the film.","","en","bachelor thesis","","","","","","","","","","","","","Molecular Science and Technology",""
"uuid:bfdc3a61-62a4-43b4-95f3-abee2a06e945","http://resolver.tudelft.nl/uuid:bfdc3a61-62a4-43b4-95f3-abee2a06e945","Belief dynamics driven by social influence: A social practice-based model of belief adaption driven by intragroup interaction with application to transport mode choices","Roes, Nena (TU Delft Technology, Policy and Management)","Warnier, Martijn (mentor); Chorus, C.G. (graduation committee); Mercuur, R.A. (graduation committee); Delft University of Technology (degree granting institution)","2019","Agent-based modelling (ABM) is a widespread and commonly used technique for the understanding of social system behaviour. Despite ABM being a commonly used method for the analysis of complex social systems, simulated agents still can best be described as autistic before a specific set of social rules is ascribed to them. This discrepancy leads to model outcomes that can differ from reality. For improving agent-based models on this aspect, a social practice theory-based approach can be used as a theoretical framework. The main question to be researched is: How does enabling agents to reason about others' beliefs on social practices affect dynamics of belief and behaviour formation as opposed to action adaption models, with respect to transport mode choices? Two agent-based models have been created within this study to provide an answer to this research question. Through including a case study within the transport domain, model results can be hold against macro-behaviour within the state of the art of models on transport mode choices. The case study depicts a group of students making a decision for a transport mode to move from their university faculty to a compulsory seminar. The students influence each other, leading to belief adaption. Within the transport domain, usually this social influence is translated to compared and adapted actions instead. This study differs itself by letting beliefs be the reference point for social comparison. Therefore, belief dynamics and agent behaviour for the models with belief adaption are compared to the state of the art action adaption models. Lastly, the effect of limitations towards having insight to other agents' personal characteristics is analysed. The analysis provides the following conclusions. Within the field of transport mode choices, enabling agents to reason about others' beliefs on social practices results in the same opinion dynamics and behaviour as is presented by action adaption models. However, an agent-based model that allows agents to reason about others' beliefs on social practices with limited insight in others' private characteristics through a theory of mind capacity, does provide a different reaction to an increase in the social capital of agents. More specifically, enhancing social network connectivity through increasing the group size or similarity threshold does not lead to more consensus within the theory of mind model, which is the case in the other models presented within this study. This stresses the importance of considering the extent to which are capable of forming a just conjection on others' private characteristics when designing an agent-based model with social interaction.","Social practice theory; Social influence; Social agents; Agent-based modelling; Transport mode choices; Theory of mind; Similarity bias; EPA","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","","51.9181493, 4.4739436"
"uuid:f02b62dc-164f-429b-b5d6-0c780ca78094","http://resolver.tudelft.nl/uuid:f02b62dc-164f-429b-b5d6-0c780ca78094","Integrity check of grounding grids at high voltage substations","Misra, Mohit (TU Delft Electrical Engineering, Mathematics and Computer Science)","Vaessen, Peter (mentor); Ghaffarian Niasar, Mohamad (graduation committee); Stuurman, Claudi (graduation committee); Bhuyan, Ranjan (graduation committee); Velitsikakis, Konstatinos (graduation committee); Delft University of Technology (degree granting institution)","2019","The safety in the high voltage substations rely on the integrity of its grounding grid. A single discontinuity at any part of the grounding grid may cause a swell in touch or step potential that may expose the personnel to a hazard of critical electric shock. It may also lead to malfunction of the protection devices leading to erroneous tripping of circuit breakers. This report presents a cost-effective, reliable and precise way to investigate the integrity of grounding grid. An experimental setup was performed in the laboratory to inspect and corroborate the results; thereafter repeating and validating the experiment in a substation.","Discontinuity; Grounding Grid; Mapping; CDEGS; Interference; Corrosion; Current Generator; Magnetic FIeld; Frequency Response; Mutual Coupling; Soil Model","en","master thesis","","","","","","","","2020-12-31","","","","Electrical Engineering","","51.4169° N, 4.1808° E"
"uuid:8ee38c25-1f73-4b61-9e19-f2211fc03530","http://resolver.tudelft.nl/uuid:8ee38c25-1f73-4b61-9e19-f2211fc03530","Long-Term Adaptive Flood Risk Management: Investing in coastal protection and stormwater management under deep uncertainty","van den Broek, Hidde (TU Delft Civil Engineering and Geosciences)","Kok, Matthijs (mentor); Timmermans, Jos (mentor); van Berchum, Erik (mentor); Delft University of Technology (degree granting institution)","2019","Flood risk management is the process of analysing, assessing and (if required) reducing flood risks, in terms of economic costs and affected population or loss of life. The analysis is performed through a probabilistic approach in which the factors are represented by a probability distribution function to address uncertainties. However, relevant factors in the analysis, such as mean sea level and the population living in the area, often are deeply uncertain on the longer term, resulting for example from climate change and changing socio-economic conditions. Generally, FRM explores these conditions through scenario analysis. However, the way FRM creates and analyses the scenarios is subjective and leaves open a lot of uncertainty. Often, only a limited set of subjective qualitative scenarios is made, which risks not taking scenarios into account that turn out to be important later. Quantitative scenarios become increasingly uncertain as the time horizon over which these are used lengthens, due to uncertainty in the trend.This research investigates a new addition to flood risk management to support it in dealing with long-term deep uncertainty. It uses robust decision making approaches as an addition to the usual FRM approach, by analysing results for a much larger set of scenarios to increase robustness, both static and flexible, to different scenarios. It combines aspects of dynamic adaptive policy pathways (Haasnoot, Kwakkel, Walker, &amp; ter Maat, 2013) and aspects from robust decision making (Lempert, Popper, &amp; Bankes, 2003), with the FRM approach to create an eight-step iterative approach called Flood Risk Adaptation Pathways, which was later tested in a case study. The approach starts by analysing the current situation and possible futures, after which it determines the difference between those situations and the preferred state. Based on this, possible flood risk reduction measures are designed, and then tested on their performance in a flood risk screening model, to create so called effectiveness regions, which show under which conditions which solutions are effective in reducing the gap between states. Based on the effectiveness regions, pathways of actions over the different possible futures are created. A monitoring plan is then created, which defines the signposts and their trigger values. Finally, the situation is monitored and actions are implemented when required.The Flood Risk Adaptation Pathways approach aims to provide policymakers with the ability to anticipate different futures, by creating actions, which meet the objectives, for a wide range of tested futures. It should allow policymakers to plan the implementation of measures ahead of time. The long-term situation is investigated, including the measures required at that point, and linked to the current situation, including the currently required measures. This should ensure that measures remain implementable by actively assuring the conditions for implementation are not violated, thus reducing negative effects of path-dependency. The link between the long-term measures and the current measures should also allow for an improved cohesion of the sequence of measures, with short-term measures providing a starting point for long-term measures. Finally, it narrows down the measures to the ones highlighted by the approach for later on in the process, when an action needs to be implemented.The approach has been tested in a case study, on Beira, Mozambique, which is prone to severe rainfall and coastal flooding. Furthermore, compound flooding problems arise when high sea water levels coincide with rainfall events. The Flood Risk Reduction Evaluation and Screening model (van Berchum, van Ledden, Jonkman, Timmermans, &amp; van den Broek, 2019) was used to model the current flood risk, as well as the effect of flood risk reduction measures on the flood risk, affected population and construction costs. For this research, the model was adapted to test specific actions over a set of changing conditions, to test their performance for the longer term. The approach was then used in the case study, following the steps (described above). The data was gathered from local sources and reference projects. After the completion of the case study, the approach was reflected upon: The main limitation arising from the case study, is the considerable computation time and time-consuming analysis of the results. Overall, Flood Risk Adaptation Pathways strengthen the FRM approach in dealing with long-term deep uncertainty, and thereby enhance the performance of flood risk reduction strategies under different than expected conditions.","Flood risk management; Robust decision making; Deep uncertainty","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:bf2af2e5-9ce9-4faf-b344-1bedead28625","http://resolver.tudelft.nl/uuid:bf2af2e5-9ce9-4faf-b344-1bedead28625","Electric field and Ionic current density modelling for HVDC and Hybrid transmission lines using Finite Element Methods","GURUMOORTHI, Hari Prasath (TU Delft Electrical Engineering, Mathematics and Computer Science)","Vaessen, P.T.M. (mentor); Ghaffarian Niasar, M. (mentor); Delft University of Technology (degree granting institution)","2019","Increase in demand for electric power and renewable sources of energy drives the need for more transmission &amp; distribution capacity. When using DC, as RMS and peak voltage are the same, transferring more power can be economical but at the same time erecting new transmission lines is often associated with demanding approval procedures, conflicts of interest and mainly with more cost. Thus a more cost-effective option to cater the demand is to share HVAC and HVDC lines on the same tower (called as hybrid lines). Charges due to corona creates problems like radio interference, audible noise and power losses. Also electric field (below transmission lines) at ground level causes head hair sensation resulting in public annoyance. Thus electric field and ion current density with the effect of space charges at ground level needs thorough investigation.This thesis focuses on calculation of electric field (affected by space charges) and ion current density on ground for HVDC and hybrid transmission lines using COMSOL multiphysics software. In HVDC, several configurations like monopolar, bipolar and double bipolar were examined. Effect of wind and ground conductors on space charges were also studied for monopolar models. A verified HVDC model is presented in this thesis which can be used to study the effect of space charges from DC conductors on electric field and current density. This work has been further extended to build a model for hybrid (HVAC+HVDC) configuration.","HVDC; FEM analysis; Hybrid transmission line; COMSOL multiphysics","en","master thesis","","","","","","","","2021-12-31","","","","Electrical Engineering","",""
"uuid:7b1912f0-bde6-4953-b8ae-ad4a37419817","http://resolver.tudelft.nl/uuid:7b1912f0-bde6-4953-b8ae-ad4a37419817","A Combined Breakwaters System: A Wave Attenuation Study on the Combination of Submerged and Floating Breakwaters using REEF3D","Damdam, Khaled (TU Delft Civil Engineering and Geosciences)","Bihs, Hans (mentor); Kamath, Arun (graduation committee); Delft University of Technology (degree granting institution); Norwegian University of Science and Technology (NTNU) (degree granting institution)","2019","Coastal zones have been a dynamic area and most favoured locations utilized for living, leisure, recreational activities, tourism, commerce and many other human activities. Submerged and ﬂoating breakwaters have been used as eﬀective systems to protect these zones from wave attack. However, they are only eﬀectively functional if the incident wave height is relatively low. Under such condition, these systems can reduce the wave transmission with significant wave dissipation and hence achieving a desirable tranquillity in designated areas. Therefore, the focus of this research is mainly to investigate the possibility of using a combination of a submerged porous breakwater (SBW) with a ﬂoating breakwater (FBW) as an innovative coastal protection system that can provide adequate calm conditions in the coastal zones with minimum visual impact. This study utilizes the open-source CFD model, REEF3D to simulate such wave-structure interaction. This CFD model is based on the RANS equations coupled with the level set method and the k − ω turbulence model. In the present study, the ﬁrst section deals with the simulation of irregular wave breaking over an irregular bed proﬁle with the use of wave reconstruction method to generate irregular waves. An excellent agreement between the computed results and the experimental data is obtained showing that REEF3D model is capable of capturing the dominant features of the evolution of the wave breaking process, both in the shoaling region and the surf zone. The second section deals with the simulation of regular wave interaction with the SBW. The simulation is conducted using the VRANS method to resolve the porous ﬂow. The wave interaction with the SBW is validated by comparison with experimental data. An impressive agreement between the numerical results and the experimental data is achieved with very small RMSE values. Finally, the validated model is then used to simulate the combination of the SBW and the FBW. Three diﬀerent cases are investigated with three diﬀerent spacing between these structures. For each case, ﬁve diﬀerent conﬁgurations related to the geometry of the FBW are simulated. It is found out that an eﬀective reduction of more than 90%, on average, of the incident wave height, can be achieved for this combined breakwaters system. This means that a transmission coeﬃcient (Kt) of less than 10% is calculated across this combination. Besides, it is found out that 1.75 FBW length to wavelength (L/λ) ratio produces a very low transmission coeﬃcient (Kt). Further, an eﬀective distance of 1-2 wavelength between the SBW and the FBW subsystems can also result in lower transmission coeﬃcients (Kt).","CoMEM; REEF3D; Wave-structure interaction; Wave Attenuation; Submerged Breakwater; Floating Breakwater","en","master thesis","","","","","","","","2019-09-30","","","","Coastal and Marine Engineering and Management (CoMEM)","",""
"uuid:f03d59ca-6b20-416e-afe5-77c0d47d8461","http://resolver.tudelft.nl/uuid:f03d59ca-6b20-416e-afe5-77c0d47d8461","Submerged Floating Tunnel: Water-Structure Interaction","Popov, Daniil (TU Delft Civil Engineering and Geosciences)","Bihs, Hans (mentor); Kamath, Arun (graduation committee); Wang, Weizhi (graduation committee); Delft University of Technology (degree granting institution); Norwegian University of Science and Technology (NTNU) (degree granting institution)","2019","This study focuses on water-structure interaction of submerged floating tube in homogeneous and stratified flows, as well as gravity current development. The latter was done in order to set up and validate numerical model that treats water stratification properly and in a computationally efficient manner.<br/>First part of the study is dedicated to gravity current development. Grid convergence study was performed for simulation of two-dimensional gravity current, which showed that optimal cell sizes for the problem in question are 5 mm and 2.5 mm. In addition, Large-Eddy Simulation (LES) model of turbulence was tested, and its performance in simulation was compared to performance of simulation without any turbulence modelling. It was established that the latter represents gravity current development in two dimensions more accurately. After that, gravity current development in three dimensions was performed with LES modelling of turbulence and without any turbulence model. Both simulations were in good agreement with results of physical experiments, therefore LES model is a preferable choice as it is less computationally demanding.<br/>In second part of the project, rigidly fixed horizontal cylinder in flow was considered in order to investigate in-line forces, acting upon the cylinder. At first, model with homogeneous flow was set up and validated. It was established that two-dimensional model with cell size of 2.5 mm and CFL criterion of 0.3 is a good choice in terms of balance between accuracy and computational efficiency. After that, system of two cylinders with varying distance between them was tested. It was established that in-line forces for both cylinders are affected, with influence on the second cylinder being more stark.<br/>Third part of the study is dedicated to horizontal cylinder in stratified flow. Parameters of produced internal waves were in agreement with results of physical experiments.","SFT; Fravity Current; LES","en","master thesis","","","","","","","","","","","","Coastal and Marine Engineering and Management (CoMEM)","",""
"uuid:a5594fcc-fc09-4b50-8bb3-c3572f0f26fb","http://resolver.tudelft.nl/uuid:a5594fcc-fc09-4b50-8bb3-c3572f0f26fb","Uncertainty-Driven Policies for Resource Allocation in Epidemics Response","den Brok, Emma (TU Delft Technology, Policy and Management)","Comes, Tina (mentor); Kwakkel, Jan (graduation committee); van de Walle, Bartel (graduation committee); Delft University of Technology (degree granting institution)","2019","Humanitarians and global health actors come to the aid of many people every year, with the aim of preventing disease, increasing wellbeing, and providing (medical) aid to those suffering from disease. One of the contexts in which they operate is that of an epidemic. An epidemic is dynamic by nature and provides a complex and evolving environment in which medical aid needs to be provided. A key aspect in a response to an epidemic is logistics – specifically the allocation of resources such as personnel and medical supplies. These resources are often limited, calling for a targeted and strategic response. There is a variety of studies tackling the problem of resource allocation in the context of an epidemic, which include sequential decisions as the epidemic evolves, as well as the choice between several locations to which resources can be sent. However, these studies often assume decision-makers have complete information on the situation at hand and can make “perfect” choices. In reality, due to the large number of actors involved in a response, poor (telecommunication) infrastructure, and the fact that an epidemic is a moving target due to its dynamic nature, decision-makers often have to deal with incomplete and uncertain information on the number of patients and the way the epidemic is evolving.","deep uncertainty; humanitarian logistics; Epidemic; direct policy search","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:cccaaafa-f6d6-4337-8ee2-8361c76aec63","http://resolver.tudelft.nl/uuid:cccaaafa-f6d6-4337-8ee2-8361c76aec63","The Development of a Simulation Model for Airline Cockpit Crew Rostering","van Amerongen, Michiel (TU Delft Aerospace Engineering)","Lopes Dos Santos, Bruno (mentor); Delft University of Technology (degree granting institution)","2019","This paper presents the development of a simulation model for airline cockpit crew rostering. The developed simulation model supports airlines in performing comparative analyses of different crew rostering scenarios. The model was developed in collaboration with a major European airline, leveraging actual historical pairing, crew and roster data to accurately model the airline crew rostering process. The simulation model is based on a novel solution method that is based on the Hungarian assignment algorithm and that exploits the resemblance of the weekly crew rostering problem to a minimum-cost bipartite matching problem. An assessment of the performance of the simulation model has shown that the simulation model is able to construct rosters of near-optimal solution quality in limited computational time. To test the applicability of the developed model as a scenario analysis tool, two experiments have been performed. The insights the performed experiments have provided confirm the practical value of the developed simulation model.","Airline Crew Rostering Problem; Personalized Crew Rostering","en","master thesis","","","","","","","","2024-08-09","","","","Aerospace Engineering","",""
"uuid:31489989-f939-4232-aec2-e3f7977730b8","http://resolver.tudelft.nl/uuid:31489989-f939-4232-aec2-e3f7977730b8","The influence of land subsidence on pluvial flooding in Rotterdam: Supplementing conducted stress test pluvial flooding with land subsidence assessment","Vleugels, Jef (TU Delft Civil Engineering and Geosciences)","ten Veldhuis, Marie-Claire (mentor); van de Ven, Frans (graduation committee); Hanssen, Ramon (graduation committee); Delft University of Technology (degree granting institution)","2019","In the Netherlands, the Delta Programme aspires to adjust spatial planning climate-proof and water-resilient, in order to be prepared for extreme weather in 2050. To achieve this ambition, municipalities, provinces, regional water authorities and central governments conduct stress tests to map out the vulnerabilities in their areas of authority by no later than 2019. The stress tests comprise four themes: pluvial flooding, drought, heat and floods. In addition, the Delta Programme 2019 acknowledges the mitigation of and adaptation to land subsidence as an important tasking. The municipality of Rotterdam faces the challenge of adding land subsidence as stress test theme and assessing its influence on pluvial flooding. Contrary to the stress test pluvial flooding, no consended methodology exist on how to map out vulnerabilities concerning land subsidence. In addition, only few studies have numerically investigated the spatial-temporal effect of land subsidence on pluvial flooding in urban areas. However, the advent of techniques to measure ground level (LiDAR) and land subsidence (InSAR) and advances in high resolution flood modelling (3Di) enable the numerical modelling of urban pluvial flooding influenced by land subsidence. This research explores the investigation of the influence of land subsidence on pluvial flooding in Rotterdam by supplementing the conducted stress test pluvial flooding with a land subsidence assessment. The conducted stress test pluvial flooding in Rotterdam is based on a 3Di-simulation of standardised rain events, based on a DEM 2016. <br/><br/>To asses the current influence of land subsidence on pluvial flooding, a Digital Elevation Model (DEM) that approximates the sub-neighbourhood Tuinenhoven at design level is created and used as 3Di-input. When comparing 3Di-results based on this design DEM to the stress test pluvial flooding, it becomes clear that the total volume of water during extreme rainfall stored on the streets is not affected by land subsidence. The bathymetry of the DEM does affect the water's distribution however. The Tuinenhoven case-study demonstrates that currently land subsidence increases the severity of the impact of pluvial flooding but that the main cause of pluvial flooding during extreme rainfall is the limited capacity of the drainage system. <br/><br/>Land subsidence in Rotterdam complex. The conducted land subsidence analysis based on an InSAR data-set supports this complexity. It illustrates that the subsidence behaviour of Rotterdam is influenced by foundation type, land use classification, the presence of dredge in the anthropogenic layer and top soil type. This respectively indicates the occurrence of pole rot and shallow foundations, anthropogenic compression and compaction of shallow soft layers caused by loading, landfill subsidence as a result of land fillings that contain dredging spoil and consolidation of the Holocene clay layer as a result of drainage. However, the land subsidence analysis failed to identify location-specific dominant land subsidence processes. This failure was primarily caused by the limitation to only one linear subsidence rate between 2009 and 2014 per point. To demonstrate how land subsidence can be translated to pluvial flooding based on a land subsidence analysis, land use classification was selected as the most dominant influencing factor and used in a linear land subsidence prognosis until 2030. The linear assumptions largely obstructs results to be interpreted location-specific.<br/><br/>The IJsselmonde case-study shows that land subsidence is expected to decrease the passability of roads and decrease the risk per building in the future. These decreases are caused by the fact that roads relatively subside fast and buildings relatively slow. The biggest influence on the risk per building classification is the assumed threshold value per building. Simulated road maintenance results in an increase of the passability of roads and an increase of buildings at risk of water nuisance. The loss of the water-storing function of the road after reconstruction increases the water levels in gardens and puts buildings at an increasing risk. <br/><br/>In conclusion, the most challenging part of investigating the influence of land subsidence on pluvial flooding is the crucial identification of the different occurring land subsidence processes. It is demonstrated that the possibilities with InSAR-data are promising, when used with sufficient competency, although the available InSAR data should be divided in shorter intervals to detect the subsidence rate trends. Land subsidence rate trends are crucial in the identification of land subsidence processes and assessing influences like groundwater variations and increased loading due to maintenance or construction works. When the land subsidence analysis is improved, so will the land subsidence and threshold height per building prognosis. When the relative prognosed decrease of the threshold value per building is improved, it can be quickly assessed whether buildings classified at risk in the stress test pluvial flooding are at future increasing risk during extreme rainfall, without conducting a full 3Di-simulation.","Land subsidence; Pluvial flooding; InSAR; 3Di; Stress Tests; Rotterdam","en","master thesis","","","","","","","","","","","","","",""
"uuid:cdeb6ed8-c039-4e76-b68d-39865e536b2a","http://resolver.tudelft.nl/uuid:cdeb6ed8-c039-4e76-b68d-39865e536b2a","Creating habit-forming digital products: Enhancing retention for online grocer Picnic","Evers, Willem (TU Delft Industrial Design Engineering; TU Delft Product Innovatie Management)","Nas, Deborah (mentor); Coelen, Jeroen (graduation committee); Delft University of Technology (degree granting institution)","2019","class=""MsoNormal"">The aim of this thesis is to increase retention for Picnic by creating a habit-forming store. Currently, conversion rates are suboptimal. In areas where Picnic is active roughly half of all households downloads the app and registers. However, the conversion of this group to active customers is sub-optimal, meaning that not all users are retained. Sub-optimal retention rates hurt companies, as they miss opportunities for business growth, increasing their profitability and cost savings. This effects also holds true for Picnic where it takes three orders to break-even on that specific customer. Project context This thesis focusses on the Dutch market, as this is where Picnic as its strongest presence. In addition to that, the Dutch online grocery market is the most advanced in Europe. This thesis focusses mainly on the competition with physical supermarkets because the growth of the online groceries segment stems from consumers switching from physical supermarkets to online grocers. Increasing the retention rates has a positive impact on the users of Picnic and society as a whole: It increases the amount of free time for users, reduces food waste and emissions in inner cities. Theoretical foundation Retention Retention is driven by the perceived utility on one hand and switching costs on the other. Both these dimensions are influenced by the habits of users. Perceived utility increases as the users gain more experience with the product, leading to a faster and more pleasant experience. Switching costs are influenced by the investments a user makes in a product, and by uncertainty about whether other companies can provide similar value. Groceries Groceries are eminently a habitual consumption: They are high-frequency purchases Groceries have a limited variability over time Grocery shopping is a behaviour that is learned over a long period of time Therefore, the challenge of this thesis is to help more users successfully form a habit around using Picnic, thereby converting into active customers.<br/> <br/> <b>Habits</b><br/> Habits are formed when both frequency and perceived utility are high enough. A habit has four elements: The trigger, action, reward and investment. Currently, most customers fail in the action element of the habit loop. This is due to either a lack of ability or a lack of motivation.<br/> This theory on habits and its connection is visualized in the figure below.<br/> <br/> <br/> <b>User research</b><b><br/> </b>The theoretical framework was combined with extensive user research to define what type of users currently are able to form a Picnic habit. <br/> The qualitative user research consisted of a combination of interviews, workshops, user testing sessions, surveys and concierge tests. The quantitative user research consisted of analyses of in-app user behaviour data, purchase data, demographic analysis and market size estimations.<br/> <br/> <b>Early market</b><b><br/> </b>Users that successfully form a Picnic habit, and thereby form Picnic’s early market have both high motivation and high ability to use the service.<br/> The high motivation results from the users being time-constrained, having physical limitations, and experience going to the supermarket negatively. This group’s high ability is a result of their high ability to plan, their relatively predictable life, and the guidance in food they receive from recipes and diets. The majority of this group are families, which are also the most profitable customers for Picnic.<br/> <br/> <b>Product strategies</b><b><br/> </b>By combining the insights from user research with the theoretical framework, three product strategies were proposed that help more users form a strong Picnic habit.<br/> First more different types of users are enabled to place orders by their increasing their motivation and ability. Once these users are enabled to order at Picnic, their frequency of interaction is increased. Finally, when these users are interacting with this app frequently, users remain engaged by an app that improves with each usage-cycle. This happens through both user- and Picnic- driven personalization. <br/> <br/> <b>Implementation of product strategies</b><b><br/> </b>These strategies must be embedded in the store team and Picnic organization in order to be effective. In order to do so, three organizational challenges must be overcome: <br/> <i>Challenges in aligning teams across the organization, </i><i><br/> Challenges in creating buy-in for customer-focused projects<br/> Challenges in autonomous decision making, due to large dependencies between teams.<br/> </i><br/> <b>Product design framework</b><b><br/> </b>To deal with these organization challenges, the strategies are translated into a product design framework. This framework provides the team with clear and inspirational guidance while being concise and measurable for the rest of the organization. This leads to companywide buy-in.<br/>  <br/> <b>Validation</b><b><br/> </b>The framework was validated in two steps: In sessions with customers and internally. The results of these validation steps indicate that the framework is likely to be successful, but it can only truly be proven by implementing it and putting it to the test.<br/> <b><br/> Implementation</b><br/> To achieve successful implementation, the framework must be clearly communicated and embedded in the daily work of the team. The latter should happen in both creative activities and evaluative activities.<br/> <br/> <b>Conclusion</b><b><br/> </b>The framework helps the store team to set a course for a longer period of time. It helps the team focus on solving the right problems for its users, by providing a way to visualize these problems and the effect the solutions should have. The vision and strategies provide the team with direction and help stakeholders across the organization align. The framework is not a definitive ‘how-to guide’ on building a habit-forming store, and its implementation and the subsequent execution are crucial for its success. ","Digital; Strategy; Habit; Retention; Conversion; Organizational design; Innovation","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:2f2ee8aa-3ed3-4e5d-802d-b64e85853d7a","http://resolver.tudelft.nl/uuid:2f2ee8aa-3ed3-4e5d-802d-b64e85853d7a","Gravity model for air passenger demand estimation: the addition of big data","Boelrijk, Wesley (TU Delft Technology, Policy and Management)","Annema, Jan Anne (mentor); Enserink, Bert (graduation committee); Delft University of Technology (degree granting institution)","2019","Over the last decades, flying has become increasingly accessible and the global aviation industry is growing rapidly. This causes airports and airspaces to reach their capacity limits. Reliable estimation and forecasting of air passenger demand is very important for airlines in order to allocate resources effectively in a constrained and competitive aviation environment. A model is developed to estimate air passenger demand suitable for routes where currently no direct service exists in order to aid decision-making on new destinations. For this model the traditional gravity model is extended with big data from worldwide flight search engines (meta search data). The model is applied to a case study with real world data from KLM Royal Dutch Airlines. We find that the gravity model enriched with meta search data is able to accurately predict demand and rank destinations that are currently not connected to KLM’s network by a direct flight. The data-driven approach allows us to give recommendations about promising destinations that could be added to an airline’s network. Ultimately, a more efficient network as a result of advanced demand estimation is expected to lead to higher load factors and lower emissions per passenger.","Air Passenger Demand Estimation; Aviation; Networks; Gravity Model; Ordinary Least Squares; Big Data","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:aa7bab4a-774c-4094-9e95-e754e0c103b2","http://resolver.tudelft.nl/uuid:aa7bab4a-774c-4094-9e95-e754e0c103b2","Data Collaboratives: Trusted Data Intermediary Business Models","Flipsen, Maartje (TU Delft Technology, Policy and Management)","de Reuver, Mark (mentor); Cunningham, Scott (graduation committee); Susha, Iryna (graduation committee); Delft University of Technology (degree granting institution)","2019","To address complex societal issues, cross-sector partnerships are needed that specifically aim to create value to address such challenges. Data collaboratives are initiatives that encourage and promote such partnerships, by the collection, sharing, or processing of data. Data collaboratives are faced with barriers that complicate collaboration between data contributors and data users. As a result, the potential of public value creation is not being reached. To overcome these barriers, decision-makers in data collaboratives need a better understanding of the Trusted Data Intermediary as a coordination mechanism. Trusted Data Intermediaries are entities entrusted with enabling data transactions between data contributors and data users across sectors, thereby generating value for collaborators, and enabling the creation of public value. Currently, academic knowledge on how these intermediary entities is absent. By a qualitative, exploratory multiple-case study, descriptive business models of six cases are developed and analyzed. From the analysis, it was found that Trusted Data Intermediaries implement different business models, depending on their characteristics in specialization to specific segments of data contributors and users. Further, the implementation may depend on the profit motive and chosen centrality of data storage. Based on these dependencies, two Trusted Data Intermediaries' business model archetypes are developed: the Generic archetype and the Specialized archetype. In addition, variations to these archetypes are discussed. As the two archetypes offer an initial theory on Trusted Data Intermediaries, next steps may include the testing of the archetypes on more cases, as well as extending the theory for Trusted Data Intermediaries with other characteristics.","Data collaboratives; Trusted Data Intermediaries; Business models","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:10b7529c-d62d-4d61-a24d-4302bff98ea3","http://resolver.tudelft.nl/uuid:10b7529c-d62d-4d61-a24d-4302bff98ea3","Inversion algorithm development for passive electromagnetic detection of line sources: Prototyping a submarine power cable tracking system","Stolz, Tobias (TU Delft Civil Engineering and Geosciences)","Slob, E.C. (mentor); Delft University of Technology (degree granting institution); ETH Zürich (degree granting institution); RWTH Aachen University (degree granting institution)","2019","The position of installed submarine power cables is often not accurately known for several reasons. The precise knowledge of the cable position is important for the maintenance process and necessitates the need for cable tracking systems. Current systems are in many cases imprecise and have a short sensing distance, limited to a few meters. A device with better accuracy and sensing range is in demand for enhancing the cable maintenance process. Three new inversion algorithms are introduced which invert the passive electromagnetic _eld created from an injected signal in the target cable. The cable is treated like a line source. This can be seen as an inverse source location _nding problem, while the source time signature is known. The algorithms are tested on synthetic data, modeling a power cable in homogeneous sea water with noise. Several parameters like sensor array, dip angle of the cable and relative position to the system are analyzed. The inuence of soil and the sea surface are studied on synthetic data created from a numerical three-layer forward model. Additionally, a prototype is developed, and di_erent processing schemes are presented and compared. The system is tested with di_erent inversion algorithms on a _eld cable on land. A solution is found which can determine the cable position accurately in sea water with noise terms for a distance up to 6 m. However, this system is highly sensor array dependent. A second inversion method gives a smaller sensing range of 5m but can be used with more versatility. In a di_erent modeled scenario without noise terms, the cable is buried in marine sediments and air is on top of a layer of sea water. The sensors are in the sea water layer. The soil has a great impact on the accuracy of the inversion. In some cable-system-orientations, the absolute error caused by the layered earth exceeds 1 m. The prototype is successfully tested on a _eld cable for di_erent scenarios. An inverted cable position in a global reference frame can be obtained by including a motion sensor.","","en","master thesis","","","","","","","","","","","","Applied Geophysics | IDEA League","",""
"uuid:d5f3b772-48d5-410e-b862-23bf8d9e1ef4","http://resolver.tudelft.nl/uuid:d5f3b772-48d5-410e-b862-23bf8d9e1ef4","A multi-pole perfectly matched layer (PML) absorber for finite-difference time-domain (FDTD) seismic modeling in 2D","Eppenga, Eric (TU Delft Civil Engineering and Geosciences)","Slob, Evert (mentor); Giannopoulos, Antonis (mentor); Draganov, Deyan (graduation committee); Schmelzbach, Cedric (graduation committee); Delft University of Technology (degree granting institution); ETH Zürich (degree granting institution); RWTH Aachen University (degree granting institution)","2019","The multi-pole PML (MPML) is tested on models that simulate seismic waves traveling through the subsurface. Using a recursive integration technique a stretching function consisting of the sum of multiple stretching functions is implemented in the velocity-stress finite difference time domain wave equations. The MPML is implemented in both the rotated staggered grid (RSG) and the Virieux grid. The performance of the MPML is tested on a square model, rectangular model and a rectangular model with a free-surface and compared to other types of PML’s implemented in these models. The main result is that the MPML can be implemented in the velocity stress wave equations giving stable results similar to other PML types.","Finite Difference Method (FDM); Multi-pole perfectly matched layer; Wave Equation; Perfectly matched layer","en","master thesis","","","","","","IDEA League Joint Master's in Applied Geophysics","","","","","","Applied Geophysics | IDEA League","",""
"uuid:12693ba0-61a5-4430-99fa-3f72bed91a08","http://resolver.tudelft.nl/uuid:12693ba0-61a5-4430-99fa-3f72bed91a08","Exploring Gravitational Waves Recordings with Machine Learning Techniques","Diab Montero, Hamed (TU Delft Civil Engineering and Geosciences)","Schmelzbach, Cedric (mentor); Ferraioli, Luigi (mentor); Meier, Men-Andrin (mentor); Broggini, Filippo (mentor); Giardini, Domenico (mentor); Delft University of Technology (degree granting institution); ETH Zürich (degree granting institution); RWTH Aachen University (degree granting institution)","2019","The study of Gravitational Waves (GWs) opened a new window of possibilities to improve our understanding of the Universe. GWs provide suitable astronomical messengers for studying events that were not possible before through electromagnetic radiation, or in other cases complementing their observations. Ground-based interferometers like LIGO have been recording multiple GW events since the first detections in 2015. Despite the success of Earth-based observatories, the space limitations and noise sources on Earth point toward the need of building a spaceborne interferometer. The Laser Interferometer Space Antenna (LISA) is a planned project that will provide us with such a detector and will allow gaining access to lower frequency bands and more types of GW sources. To make the most out of LISA’s strengths, it is important to identify and develop alternative data analysis tools which are more appropriate for low latency searches of GWs than the current ones in use. Machine Learning techniques are a promising candidate since they can provide high accuracies, higher speeds, and a lower computational cost. Therefore, they can be used for the development of Low Latency Detectors (LLD) of GWs, which will be used to analyze the LISA recordings. I propose to build a prototype LLD by using a Sliding Window Algorithm, which makes use of Convolutional Neural Networks (CNNs) as its classification mechanism. To implement the LLD, I first create datasets composed of synthetic GW recordings of two different GW source types: Galactic Binaries (GBs) and Merging Blackhole Binaries (MBHBs). Then, I transform these recordings originally represented only in the time domain, into the frequency domain, and the time-frequency domain and train two different ML architectures (CNNs and Fully-Connected Neural Networks) using both the original and the transformed data. A performance evaluation is done to select the best combination of ML architecture and domain representation for solving the detection task. The chosen combination is then used as the classifier mechanism of the LLD acting in windows of five days duration. The LLD is tested on one-year-long recordings with different levels of noise. The analysis suggests that the time-frequency domain representations offer the most promising results for detecting both types of sources (GBs and MBHBs) reaching high accuracies in recordings with low to moderate signal-to-noise ratio (SNR).","Gravitational Waves; Machine Learning; Neural Networks; Deep Learning; Spectrogram; Laser Interferometer Space Antenna (LISA); Classification; Low Latency Detection","en","master thesis","","","","","","","","","","","","Applied Geophysics | IDEA League","",""
"uuid:f1ee6108-c165-49da-b63e-daeeb0550570","http://resolver.tudelft.nl/uuid:f1ee6108-c165-49da-b63e-daeeb0550570","Ultra High Kinetic Inductance Detectors","Verheul, Stefan (TU Delft Applied Sciences)","Baselmans, Jochem (mentor); Endo, Akira (graduation committee); Steele, Gary (graduation committee); Delft University of Technology (degree granting institution)","2019","Microwave Kinetic Inductance Detectors (MKIDs) are extremely sensitive radiation detectors based on superconducting resonators that can be combined in large arrays on a single readout line within a limited frequency bandwidth. This makes MKIDs ideal detectors for the ultimate far-infrared observatory: a future space-based actively cooled telescope with its performance solely limited by the low universe background radiation. However, to reach these detector requirements, state-of-the-art MKIDs still need a order of magnitude improvement in device sensitivity. In this work, the MKID sensitivity is improved by reducing the aluminium volume that absorbs pair-breaking radiation into quasiparticle excitations, while making sure all radiation is still absorbed. Furthermore, a key requirement is sufficient reduction of excess noise as to keep the device intrinsically limited by thermally driven random fluctuations in the number of quasiparticles in absence of radiation, or Generation-Recombination (G-R) noise. To this end, a model is developed that describes the noise contributions as function of device geometry, readout power, material properties and radiation power. Subsequently, a realistic MKID design is presented and tested that reduces excess noise and maximises the sensitivity, expressed as Noise Equivalent Power (NEP). At high temperatures, good overall agreement is found between the measured noise spectra and the model. At low temperature T = 120 mK, the measurement results give an optical NEP similar to current state-of-the-art MKIDs. The NEP is not as low as expected due to short quasiparticle lifetimes, an unexpected decrease in the G-R noise level and a very high excess noise attributed to Two-Level Systems (TLS) noise that starts to dominate the already low G-R noise spectrum at low temperatures. Possibly, the quick quasiparticle lifetime saturation and noise level drop are caused by a strong readout power effect, as the readout power is known to create excess quasiparticles and to cause a strongly non-thermal electron energy distribution in the aluminium strip of the MKID. However, the exact microscopic details of these effects are unknown and not studied in this project. Based on the current chip design, a straightforward way to improve device performance and study the readout power effect in more detail is a reduction of the high TLS noise levels, which is possibly fabrication related. This would allow an unobstructed view of the G-R noise spectrum at low temperatures, thereby allowing both a study of the readout power effect on the quasiparticle system, and ultimately achieving the improvement in NEP needed reach the detector requirements for the ultimate space-based far-infrared observatory.","MKIDs; Microwave Kinetic Inductance Detectors; Superconducting resonators; superconducting radiation detectors; far-infrared; microwave resonator","en","master thesis","","","","","","","","","","","","","",""
"uuid:0883fc24-c0c3-410e-ba96-6e2898b2fb59","http://resolver.tudelft.nl/uuid:0883fc24-c0c3-410e-ba96-6e2898b2fb59","Sexuality and Intimacy Healthcare for Adolescents and Young Adults with Cancer","Wang, Ruocha (TU Delft Industrial Design Engineering)","Desmet, Pieter (mentor); Groeneveld, Bob (graduation committee); Albers, Leonore (graduation committee); Delft University of Technology (degree granting institution)","2019","Adolescents and young adults (AYAs) with cancer, aged from 15 to 39 years, are making the transition from childhood to adulthood. When the burden of cancer is added, it becomes part of this extraordinary and challenging time in their growth and development. Cancer affects the psychosexuality of AYAs as well as intimate relationships, which in turn influences their well-being. However, the discussion on sexuality and intimacy is hard to initiate, and AYAs are not satisfied with the information provided by the healthcare providers. The project looked into the big picture of sexuality and intimacy care for AYAs in the Netherlands and the unmet needs of AYAs. Based on the research findings, the design concept is developed. It is an online application together with a website. To tackle the problem of insufficient discussion, the application gives information about the disturbances and prepares AYAs to initiate the discussion with their healthcare providers. For AYAs’ dissatisfaction with the information supplied, the project looked into AYAs’ unmet needs and constructed an information architecture that covers their needs. Literature study and interviews were conducted in the research phase. The design phase implemented iterative design and human-centred design approaches, where AYAs were kept at the heart in the process.","Sexuality and Intimacy; Adolescents and Young Adults with Cancer; Human-Centered Design","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:16e4b8aa-83de-41ac-a82f-1fce5b447cdc","http://resolver.tudelft.nl/uuid:16e4b8aa-83de-41ac-a82f-1fce5b447cdc","Positive Strategic Design: The development of a design tool that facilitates positive organizational and business development","van der Heijden, Omar (TU Delft Industrial Design Engineering; TU Delft Industrial Design)","Desmet, Pieter (mentor); Bakker-Wu, Sijia (mentor); Delft University of Technology (degree granting institution)","2019","This report is the result of a self-initiated design graduation project that regarded positive design in a strategic design context. The goal of the project was to design and develop a tool or method that integrates positive design knowledge into strategic design processes. To get to the bottom of this, desk research and user research into the domains of strategic and positive design were conducted. Research presented opportunities to apply happiness interventions on multiple strategic levels of a product-service system. These opportunities were developed into an overview, the positive strategic design (PSD) framework. Research also presented several strategically viable implications to communicate the happiness interventions. The chosen strategy was one that was directed at design students. The students are the bridge between theory and practice and can potentially improve engagement with positive design in both areas. The strategy was to create a solution that included principles from both strategic design and positive design and incorporated the PSD framework. The final design included a tool in the form of website and a printable card set and were developed to give users the same value independent of the format that they use. Moreover, people can download the card set through the website, making it easier to use and discuss the happiness interventions in a group. The website can be accessed via https://positivestrategicdesign.com","positive design; strategic design; positive strategic design; positive organizational development; positive business development; happiness; happiness strategies; happiness interventions","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:fc9c2caf-d4b4-47c6-a7e7-7157bc286058","http://resolver.tudelft.nl/uuid:fc9c2caf-d4b4-47c6-a7e7-7157bc286058","Intent-Based Networking with Programmable Data Planes","Mohammad Riftadi, Adi (TU Delft Electrical Engineering, Mathematics and Computer Science)","Kuipers, Fernando (mentor); Nasri Nasrabadi, Mitra (graduation committee); Hauff, Claudia (graduation committee); Delft University of Technology (degree granting institution)","2019","Switches that can be (re)programmed through the network programming language P4 are able to completely change – even while in the field – the way they process packets. While powerful, P4 code is inherently static, as it is written and installed to accommodate a particular network requirement. Writing new P4 code each time new requirements arise may be complex and limits our agility to deal with changes in network traffic and services. To solve that problem, we present two frameworks within this work: P4I/O and GP4P4. P4I/O is a new approach to data-plane programmability based on the philosophy of Intent-Based Networking. P4I/O provides an intent-driven interface that can be used to install and/or remove P4 programs on the switches when needed and which is easy to use. In particular, to realize P4I/O, we (1) describe an extensible Intent Definition Language (IDL), (2) create a repository of P4 code templates, which are parsed and merged based on the intents, (3) provide a technique to realize the resulting P4 program in a programmable switch, while accommodating intent modifications at any time, and finally (4) implement a proof-of-concept to demonstrate that intent modifications can be done on-the-fly. Our second framework, GP4P4, is a genetic programming approach able to autonomously generate programs for P4-programmable switches directly from network intents. We demonstrate that GP4P4 is able to generate various network functions in up to a few minutes; an important first step towards realizing the vision of ‘Self-Driving’ networks.","programmable switches; intent based networking; genetic programming; data plane programmability","en","master thesis","","","","","","","","2020-07-27","","","","Computer Science","",""
"uuid:ee14c373-7c8b-4079-bec9-0406582b5309","http://resolver.tudelft.nl/uuid:ee14c373-7c8b-4079-bec9-0406582b5309","Network Decentralized Collision Avoidance with Applications in a Scalable Unmanned Aerial System Testbed","Ledzian, Patrick (TU Delft Mechanical, Maritime and Materials Engineering)","Giordano, Giulia (mentor); Verhaegen, Michelle (graduation committee); Shyrokau, Barys (graduation committee); Batselier, Kim (graduation committee); Delft University of Technology (degree granting institution)","2019","Decentralized control and estimation are both active research areas in the field of systems and control. A new approach to these topics utilizes graph theory to characterize inter-agent communication as a graph that, in this thesis, can have time-varying topology. This approach has been named ""network-decentralized"" and the use of network-decentralized control and estimation can enable multi-agent systems to achieve tasks in low information environments. In this thesis a novel network-decentralized control algorithm is proposed to enable collision avoidance and formation producing behavior in a multi-agent system. Additionally, a network-decentralized estimation algorithm is also proposed that is combined with the network-decentralized control approach yielding a first of its kind network-decentralized network-estimated control algorithm. A multitude of simulation environments are developed to test the algorithm in a 2-D holonomic multi-agent environment and a parameter tuning method is presented. Strong performance is shown in 2-D with collision avoidance guarantees, at the cost of difficult to tune parameters. The use of holonomic agents in 2-D is consistent with most research in decentralized control and estimation. Since this type of agent is common, this thesis extends its work to the 3-D non-holonomic agent case in an attempt to help characterize how accurate, scalable, and useful existing decentralized research is for real world applications. To develop the network-decentralized algorithm to this point, it is first expanded to the holonomic 3-D case where it is further tested in newly developed simulation environments, where again, collision avoidance guarantees are provided. A novel free-space metric is introduced which allows for tests to be compared across dimensions (eg: 2-D and 3-D) and also yields addition insight as to when parameter-performance breakdown will occur. For the extension of the algorithm to a non-holonomic vehicle in 3-D a suitable quadcopter platform is designed. In addition, the Delft Center for Systems and Control (DCSC) Distributed Robotics Lab is re-designed and completely virtualized to allow for students to easily access lab resources, such as motion capture (MoCap) information, quadcopter test-code environments, and documentation all in one location. A first-principles based system identification process is presented and used to identify the designed quadcopter platform so that a suitable controller can be found for in-lab use. Two quadcopter simulation environments are developed to allow for the design of hover-envelope controllers based on identified parameters. Since the DCSC department was unable to acquire multiple physical vehicles for swarm testing the system identification process and quadcopter simulation environments are validated against the test results from a single physical quadcopter in the newly designed lab environment. A more comprehensive multi-agent implementation of the collision avoidance portion of the algorithm is tested in a real-time vehicle simulation environment. It is found that while the single physical agent can closely track the behavior of holonomic agents and quadcopter simulation results, the real-time multi-agent case exhibits a degradation in performance that further declines in obstacle dense environments. This explains a loss of performance that can lead to collisions in the real-time setting where in the holonomic case the exact same test yields successful results.","Network-decentralized; Decentralized Control; Decentralized Estimation; Formation Control; Collision Avoidance; Quadcopter","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:26cd823b-217f-42f1-b5bc-7f988f14ae24","http://resolver.tudelft.nl/uuid:26cd823b-217f-42f1-b5bc-7f988f14ae24","The Effect of Mechanical Strain on Non-enzymatic Cross-linking of Collagen type II Fibrils in Articular Cartilage","Lagrand, Jaap (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Biomaterials & Tissue Biomechanics; TU Delft Biomechanical Engineering)","Pouran, B. (mentor); Weinans, H.H. (graduation committee); Zadpoor, A.A. (graduation committee); Harlaar, J. (graduation committee); Delft University of Technology (degree granting institution)","2019","Investigations into mechanotransduction in connective tissue extracellular matrix (ECM) have demonstrated that collagen networks show cell-independent mechanosensitive behavior. It has been suggested that mechanical strain could lead to conformational changes in the molecular structure of collagen, thereby influencing the susceptibility to other molecules. In the process of normal aging, the collagen fibrils in cartilage undergo a non-enzymatic process known as glycation. It involves the accumulation of advanced glycation end products (AGEs) after exposure to sugars, resulting in the formation of cross-links between the collagen fibrils. This process is correlated with increased stiffness and brittleness of the cartilage, making it more prone to mechanical damage. The goal of this thesis was to assess whether mechanical compression has any effects on the formation of non-enzymatic cross-links during the aging of articular cartilage. Two different models have been developed to mimic aging knees that undergo static and dynamic compression. Healthy cartilage explants were exposed to L-threose sugar to induce artificial aging. During incubation, these explants were submitted to either static or dynamic unconfined compression. Treatment with static compression consisted of a 5, 10 or 15\% strain throughout the whole incubation period, using a custom-made bioreactor. Treatment with dynamic compression consisted of multiple loading cycles at a frequency of either 0.01 Hertz (Hz) or 1 Hz, using a Dynamic Mechanical Analyzer (DMA). We conducted cartilage surface color analyses, micro‐indentation tests, dynamic mechanical analyses and biochemical measurements of pentosidine cross‐links to assess the effects of advanced glycation cross‐linking under these different conditions. Dynamic compression at a frequency of 1 Hz was found to affect the formation of non-enzymatic cross-links. Biomechanical and biochemical data showed a similar trend, namely, the average values for equilibrium modulus, dynamic moduli, phase shifts and pentosidine per collagen level were noticeably higher (or lower in case of phase shift) for the 1 Hz treated samples compared to samples of other treatment groups. The results of these studies suggest that compression at the physiological frequency of walking does affect the formation of cross-links in the articular cartilage during aging. These findings contribute to a better understanding of the mechanochemistry of collagen fibrils, which is necessary to develop future strategies against cartilage aging and deterioration.","Cartilage; Collagen; Cross-links; Biomechanical properties; HPLC; Aging; DMA; Indentation; Strain-dependency","en","master thesis","","","","","","","","","","","","Biomedical Engineering","",""
"uuid:fde5d464-52d5-449c-8160-52ba9c41b21b","http://resolver.tudelft.nl/uuid:fde5d464-52d5-449c-8160-52ba9c41b21b","Autopilot Design for Software-in-the-Loop Validation of Fixed-wing UAV Guidance Laws","Thomas, Arun (TU Delft Electrical Engineering, Mathematics and Computer Science)","Baldi, S. (mentor); Verhaegen, M.H.G. (graduation committee); van Genderen, A.J. (graduation committee); Wang, X. (graduation committee); Delft University of Technology (degree granting institution)","2019","UnmannedAerial Vehicles(UAVs) have multi-domain applications and fixed-wing UAVs are a widely used class. There is ongoing research on topics in view to optimize the control and guidance of UAVs. This work explores the design, implementation and Software-in-the-Loop validation of an autopilot using adaptive guidance laws with emphasis on formation control of multiple fixed-wing UAVs. The work is done on Raspberry Pis in C++ which can be interfaced to standard autopilots as companion computers. The work splits a mission given by the user into primitive missions and uses an adaptive vector field approach for following it. For formation control, the work implements a discretized version of the Model Reference Adaptive Control synchronisation laws for multi-agent systems. Simulations are done in a distributed setting with a server program designed for the purpose. The server program handles the user inputs and configurations of the UAVs.","Unmanned Aerial Vehicle; Formation Control; Adaptive Vector Field; synchronization; Autopilot Design","en","master thesis","","","","","","","","","","","","Electrical Engineering | Embedded Systems","",""
"uuid:0b5617bd-87de-43ba-a4c8-7c5d35f2723f","http://resolver.tudelft.nl/uuid:0b5617bd-87de-43ba-a4c8-7c5d35f2723f","Interlocking worlds: A 2035 envisioned concept for Volkswagen Escapism Mobility","Snoodijk, Alain (TU Delft Industrial Design Engineering)","Kets, Wouter (graduation committee); van Grondelle, Elmer (mentor); Delft University of Technology (degree granting institution)","2019","This thesis is the documentation of a design proposal for a 2035 envisioned concept for Volkswagen Escapism mobility that responds to a rapidly changing mobility demand. The rapidly growing population is changing the urban landscape and how we move around in our cities. Technological developments are giving us more control over smart systems and create new interactions with our surroundings. In regulated urban systems, the desire for freedom that is deeply rooted in our human character is becoming increasingly more difficult to satisfy. Problem In 2015, the automotive industry witnessed the hard consequences of the Dieselgate. Nowadays, Volkswagen still suffers from the scandal, as it influences the brand image negatively. Although the brand is building a fully electric identity, Americans still relate to the Dieselgate when they talk about Volkswagen. The people’s opinion of Volkswagen used to be shaped by the iconic models of the past but is now overruled by negativity. In order to enlarge the American market share, Volkswagen should design an eye-catching mobility concept in order to re-establish the brand image. Vision The American Volkswagen driver is someone who irrationally chose to drive a Volkswagen in search for emotional connections with the product. These people will feel uncomfortable in the future which will be shaped through the strive for efficiency. They feel more related to the other side of the future, one that focuses on escaping the daily life and experience memorable moments. In order to re-attract the American Volkswagen driver, the portfolio should offer a product that bridges both worlds, a product that is pushing them to take the risk while feeling trusted going out of their comfort zone. Design The design proposal, named Volkswagen Valor, was developed in corporation with Volkswagen’s design studio in Wolfsburg. It is a 3-person vehicle that offers two configurations. Each configuration is tailored perfectly to the desired interaction, both in the future world of efficiency as in the world of escaping. Valor provides the smooth transition between both worlds and offers several features that give the passengers a memorable experience. Valor is a fresh looking concept with a silhouette that will become iconic in the future. The design language is showing the risk-taking character while breathing the confidence of trustworthiness, embodied by a future interpretation of Volkswagen’s American design language. Evaluation Valor was evaluated by professional car designers working in the Wolfsburg studio. The proposal was reviewed as provoking and interesting. The goal of creating something fresh and unique in order to become iconic in the future, responded perfectly to the evaluation of the proposal. It was evaluated that the vehicle responds logically to the problem and fits well in the envisioned future.","Automotive design; Exterior Design; Vision in Design; Mobility; Volkswagen; car design","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:3152697f-eacc-42dc-a686-33948fd5ea3a","http://resolver.tudelft.nl/uuid:3152697f-eacc-42dc-a686-33948fd5ea3a","Word Embedding Models for Query Expansion in Answer Passage Retrieval","Roy, Nirmal (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Web Information Systems)","Hauff, Claudia (mentor); Tintarev, Nava (graduation committee); Scharenborg, Odette (graduation committee); Moraes Gomes, Felipe (graduation committee); Delft University of Technology (degree granting institution)","2019","With the increasing popularity of mobile and voice-assisted, extracting short and precise answer passages to open-domain questions is becoming an increasingly important information retrieval (IR) task. The recently released large-scale corpus for answer passage retrieval—WikiPassageQA—was shown to be challenging for both traditional retrieval models and neural architectures. One of the classic approaches to improving retrieval effectiveness across tasks is automatic query expansion (QE). QE is the process of reformulating a user’s query by adding more terms with the goal of retrieving more relevant information. Word embeddings are commonly employed to obtain QE terms by taking advantage of the low dimensional semantic space formed by these embeddings.<br/>Recently, Diaz et al. showed that QE using word embeddings trained on a local query-specific corpus performed better than embeddings that were trained on an entire global corpus for document ranking tasks. We aim to examine the effectiveness of QE, specifically using locally-trained word embeddings, in this new context of answer passage retrieval. Additionally, a query-specific corpus can be small in size with limited vocabulary which forms a challenge for training word embedding models. Since the extent to which limited vocabulary influences the semantic information captured by word embeddings is relatively unexplored, we compare two word embedding models—CBOW and IWE—in this thesis. Having the same underlying training philosophy, the IWE model differs from CBOW in two aspects—it incorporates sub- word information of words and uses a convolutional neural network to learn context representation.<br/>Our results corroborate the findings of Diaz et al.—query-specific data is also beneficial in the task of retrieving passages to open-domain questions. Word embeddings trained on a global corpus fail to capture the nuances of query-specific language present in the answer passages. We also found out that IWE word embeddings capture more semantic information than CBOW word embeddings when trained on local data with a limited vocabulary. Our experiments show that both the IWE model components contribute to the improved quality of word embeddings and consequently better QE terms. Our work can be extended by using the same methodology in other domains or by using different word embedding models to obtain QE terms. The insights from our thesis can help researchers to make an informed decision while choosing word embedding models and training data for their IR and natural language understanding tasks.","Word embedding; Query Expansion; Question Answering; Information Retrieval","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:c3bce984-730b-495b-9ebf-077f80b895ea","http://resolver.tudelft.nl/uuid:c3bce984-730b-495b-9ebf-077f80b895ea","Indisputable GDPR compliant signatures in ContractChain","van den Hoek, Martijn (TU Delft Electrical Engineering, Mathematics and Computer Science); Houwing, Krijn (TU Delft Electrical Engineering, Mathematics and Computer Science); Vollebregt, Frank (TU Delft Electrical Engineering, Mathematics and Computer Science)","Erkin, Zekeriya (mentor); Visser, Otto (graduation committee); Wang, Huijuan (graduation committee); Delft University of Technology (degree granting institution)","2019","Nowadays, entering into a contract with an overseas company still relies on postal services to send a printed contract, which is signed on paper. Lizard Global is developing an online platform for constructing, reviewing and signing digital contracts for one of their clients. In the original system, when a signee signed a contract, his personal information was used as a signature and stored in blockchain. However, this way of signing a contract does not enjoy the same degree of legal validity as a written signature. Moreover, the implications on privacy legislation, specifically the European Data Protection Regulation (GDPR) had not yet been taken into account by Lizard Global. This project describes how agile development was used to construct a high quality software solution to the problem, thereby implementing firstly an advanced e-signature to make signing a contract legally binding and secondly functionality to store this signature in blockchain such that it is compliant with the GDPR legislation. This is done by only storing hashed values in the blockchain and adding a user panel. In this panel, signees are able to control their personal data. High quality is obtained by testing thoroughly (100 per cent branch coverage), using the static analysis tool ESLint and requesting, receiving and implementing feedback from the software improvement group.<br","blockchain; GDPR; electronic signature","en","bachelor thesis","","","","","","","","","","","","Computer Science","TI3806",""
"uuid:abb11035-b49e-465d-8d68-2f07df582703","http://resolver.tudelft.nl/uuid:abb11035-b49e-465d-8d68-2f07df582703","Quantifying the impact of in-vehicle crowding on customer satisfaction in Public Transport: A Den Haag case study","Seerden, Maarten (TU Delft Civil Engineering and Geosciences; TU Delft Transport and Planning)","Hoogendoorn, Serge (graduation committee); van Oort, Niels (mentor); Kroesen, Maarten (mentor); Nijënstein, Sandra (graduation committee); Delft University of Technology (degree granting institution)","2019","In an environment in which Public Transport plays an ever growing role in urban areas and passenger experience. In-depth knowledge on customer satisfaction is key in improving passenger experience. Crowding has shown to be an important aspect of route and mode choice, but its impact on customer satisfaction has not yet been quantitatively explored. This paper investigates this impact. Using a Structural Equation Model based on customer satisfaction survey data and corresponding occupancy and punctuality numbers a significant effect of occupancy levels on perceived crowding was found. In-vehicle crowding, both subjective and objective, seems to impact overall customer satisfaction indirect, with comfort being the main mediating variable. Model results were converted into a calculation tool which can be used to assess the impact of changes in passenger numbers, passenger distribution and frequencies on customer satisfaction. Further research can verify the linearity of the relation between in-vehicle crowding and customer satisfaction and deepen knowledge of external factors such as weather and disruptions have on experienced crowding.","Urban Public Transport; structural equation modelling; in-vehicle crowding; Customer satisfaction","en","master thesis","","","","","","","","","","","","Transport, Infrastructure and Logistics","",""
"uuid:71b3920f-61c3-4a91-bc07-d948e9d36a85","http://resolver.tudelft.nl/uuid:71b3920f-61c3-4a91-bc07-d948e9d36a85","Collective migration and phenotypic plasticity in cancer metastasis: Conflicting views or complementary mechanisms?","Verhagen, Mathijs (TU Delft Applied Sciences)","Fodde, Riccardo (mentor); Teeuwssen, Miriam (mentor); van Royen, Martin (graduation committee); Jenster, Guido (graduation committee); Delft University of Technology (degree granting institution)","2019","Cancer metastasis, the spread of cancer to distant organs, is the major cause of cancerrelated mortality. Hence, understanding the mechanisms underlying cancer metastasis is crucial to improve clinical interventions. Despite intensive efforts, the driving mechanisms remain ill-understood due to the difficulties posed by studying the different steps of the metastatic cascade in patients. Two established models have been proposed to underlie the driving mechanisms of metastasis are phenotypic plasticity and collective migration. Phenotypic plasticity, i.e. the capacity of the migrating cancer cell to adapt to the different cellular contexts that it encounters en route to form a metastasis, revolves around reversable transitions from epithelial to mesenchymal (EMT and MET) identities. The collective migration model denotes migrating cancer cells can overcome barriers by coordinated cooperation. Recently, these views have been integrated in a model where partial (EMT) is believed to mediate collective migration. Here, we will investigate critical assumptions of this integrated model by focusing on different steps along the invasion-metastasis cascade. Using an unsupervised approach based on complete transcriptomes, we unravel single cell EMT-related transcriptional differences in colorectal cancer cell lines and map different phenotypes on the EMT spectrum to identify E/M sub-states that might underlie collective invasion. Next, we have developed and evaluated 3D collagen models to facilitate collective migration studies both in vitro and ex vivo. Preliminary data obtained using this approach highlights how EMT induction can alter the dominating tumor migration type. Taken together, our results support a case for phenotypic plasticity and collective migration as complementary and functionally correlated mechanisms, and could serve as point of engagement for further studies aimed at clarifying the role of partial EMT in collective migration.","single-cell RNA sequencing; epithelial-mesenchymal transition; E/M sub-state; collagen; collective migration; circulating tumor cell","en","master thesis","","","","","","","","","","","","Applied Sciences | Nanobiology","",""
"uuid:8e38bc8b-6bff-4794-a27a-93ce6a95ee53","http://resolver.tudelft.nl/uuid:8e38bc8b-6bff-4794-a27a-93ce6a95ee53","Retrieval-Based Open-Domain Question Answering: Exploring The Impact on The Retrieval Component across Datasets","Jiang, Kun (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Web Information Systems)","Hauff, C. (mentor); Scharenborg, O.E. (graduation committee); Kuipers, F.A. (graduation committee); Delft University of Technology (degree granting institution)","2019","Open-domain question answering (QA) is an important step in Artificial Intelligence and its ultimate goal is to build a QA system that can answer any question posed by humans. The majority of the open-domain QA system is the retrieval-based open-domain QA system, which enables the retrieval component to retrieve relevant documents from a large-scale knowledge source to a question and the answer extraction component to extract the answer to this question based on retrieved documents. As the techniques of Deep Learning progressing significantly, many researchers tried to apply the neural reading comprehension (RC) model to serve the answer extraction component of the open-domain QA system. However, the performance of the neural RC model in open-domain QA is considerably worse than the performance of it in RC-style QA. Therefore, many works have focused on the neural RC model for addressing the performance gap, whereas the retrieval component of the open-domain QA system lacks equivalent attention. Some researchers have built the neural network based information retrieval (IR) models, but currently, it is still difficult for these neural IR models to directly retrieve documents from a large-scale knowledge source in open-domain QA. Hence, many works attempted to use neural IR models for re-ranking documents retrieved by the traditional but efficient IR models (e.g., TF-IDF, BM25) in open-domain QA. However, these works did not analyze the impact of different questions of QA datasets on traditional IR models. Thus, this research gap is the focus in this thesis. We conduct error analyses of questions of different QA datasets to figure out the error types of questions that have a negative impact on the traditional IR models. From the error analysis, we learn that different QA datasets have different impacts on the traditional IR models and are differently hard to be dealt with by the traditional IR models. Therefore, we propose hypotheses that might mitigate the negative impact of the error types of questions that are relatively harder to be handled by the traditional IR models. Furthermore, we perform experiments based on the methodologies that implement our hypotheses for figuring out the validity of these hypotheses. In conclusion, we believe that our work is a step forward to obtaining more insights into the retrieval component of the open-domain QA system and will contribute to the development of the retrieval component for a better open-domain QA system. Moreover, our work can give our users guidance on how to issue a more suitable question that can be processed by the open-domain QA system for giving a more accurate and better answer.","open-domain QA systen;; retrieval component; traditional IR models; questions of datasets","en","master thesis","","","","","","","","","","","","Electrical Engineering | Embedded Systems","",""
"uuid:b4025883-47f5-4280-ac10-ccaafc664520","http://resolver.tudelft.nl/uuid:b4025883-47f5-4280-ac10-ccaafc664520","Optimization of a Data-Driven Customer Relationship Management System for Better Decsion-Making","Khajehvajari, Milad (TU Delft Technology, Policy and Management)","Cunningham, Scott (mentor); Huang, Yilin (graduation committee); Fific, Damir (graduation committee); Delft University of Technology (degree granting institution)","2019","As financial markets have evolved and become more digital, the ways of marketing, communication and customer service have also adapted to the times. Customers expect a higher standard from all industries, financial services included. On top of being a nuisance to unsatisfied customers, poor customer service costs industries globally ＄338.5 billion in potential revenue losses per year. The industry with the highest losses is financial services, with about ＄44 billion lost per year (Genesys, 2009). Systems utilizing customer data for the purpose of improving business relationships with customers through better customer communication and service are called Customer Relationship Management (CRM) models (Chen &amp; Popovic, 2003). Part of CRM operations is lead management. Lead management in particular is the set of methodologies, systems and practices with the aim of helping to better service existing clients (retention) or discovering and bringing in potentially new clients (acquisition). This project is performed with the goal of improving the lead management system in the private banking department of ING. More specifically, the goal is to improve the identification of the best leads weekly from the pool of all available leads to be sent out to customer contact teams. The methodology consists of the integration of machine learning algorithms into the lead management infrastructure for the purpose of scoring leads in order to improve the selection process, leading to improved customer communication as well as revenue potential. Additionally, more information was put into the decision making by considering the performance and preference of the customer contact teams. Due to the usage of data modelling, a review of relevant compliance measures with regards to GDPR was performed, with an additional measure of decision explainability being proposed for this project as well as all projects using machine learning algorithms.Three different algorithms were tested, with the best one selected based on performance being a random forest model. The model was tested against the existing lead selection method for 6 weeks, and showed considerable and consistent improvement in performance from the third week onwards (up to 16%). The random forest was more flexible over the weeks and based on analysis of decision interpretability made on particular model decisions, benefitted largely from the inclusion of team performance. In fact, the team which was handling the lead proved to be the most important factor in the decision making of the model. Preference did not seem to have any particular impact on the performance of the leads and thus was omitted from the final model. Overall, based on the results of the testing, the use of machine learning algorithms was shown to significantly improve the performance of the lead management system, based on better lead selection and the consideration of team performance. For future research, it is suggested to implement machine learning techniques in the lead generation step (rather than after), in order to reduce the information restriction the algorithm faced in the case of this project.","lead management; Customer Relationship Management; customer analytics; predictive analytics; GDPR compliance","en","master thesis","","","","","","","","2020-07-31","","","","Engineering and Policy Analysis","",""
"uuid:207014bd-d853-4a60-984b-2022de136f41","http://resolver.tudelft.nl/uuid:207014bd-d853-4a60-984b-2022de136f41","Light into the Urban Black Box – A Comprehensive Urban Metabolism Approach for Strategic Policy Making: A Case Study of Household Waste Management in Amsterdam","Vetter, Elias (TU Delft Technology, Policy and Management)","Cunningham, S. (mentor); Huang, Yilin (graduation committee); Delft University of Technology (degree granting institution)","2019","The limitation of natural resources forces humanity to rethink its current habits of material use. Plastic product packaging, fossil fuels for transportation and energy generation are just a few examples of highly resource intensive processes in modern society. Urgency of this matter increases due to the fast-growing world population and big economies as India, China and Brazil. Understanding the current material flows and the system they flow through might generate knew knowledge of material use dynamics. This knowledge can help policy makers to stimulate material use efficiency. To generate the necessary knowledge this research takes an Urban Metabolism (UM) approach. In contrast to established material flow focused and analytical aggregated UM approaches, this research proposes a more comprehensive approach. Defining the UM not only as material flows and processes, but giving more weight to the Social, Economic, and Institutional system aspects as well as the role of actors. On top of the different system perspective the metabolism analysis is conducted on different time and spatial levels. The addition of disaggregated analytical levels enables the use of statistical analysis to discover material use patterns over time and identification of actor group related material-use behaviour. The statistical methods used are Time Series, Correlation and Geospatial Analysis in addition to the common Material Flow Analysis and a Life Cycle Assessment. The proposed UM approach is applied to the case of household waste management in Amsterdam. This research showes the potential of a deeper and holistic metabolism analysis enabled by increasing amount of available data. Opening up and troughing light into the up to this point Urban Black-Box.","Urban Metabolism; Data Analytics; Comprehensive design framework; Sustainable Development Goals; Policy design","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:ab1a2d9e-ef0f-4bf3-9649-05ada7fe8994","http://resolver.tudelft.nl/uuid:ab1a2d9e-ef0f-4bf3-9649-05ada7fe8994","Induction heating simulation of out of autoclave production techniques: Design of method to simulate an induction heating system of out of autoclave mould to scale to full scale production","van Duin, Frank (TU Delft Aerospace Engineering)","Groves, R.M. (mentor); Delft University of Technology (degree granting institution)","2019","This master thesis is part of research at Fokker Aerostructures to an out of autoclave production method for thermoplastic composites. The objective of the thesis is to simulate the induction heating process of this production method to make it possible to simulate the production method before the mould is produced. The final product is a guideline to the design of an induction heating setup for the specific production method.","","en","master thesis","","","","","","","","2021-08-06","","","","Aerospace Engineering","",""
"uuid:a56077b1-4633-4a30-bfe6-46d1c315028c","http://resolver.tudelft.nl/uuid:a56077b1-4633-4a30-bfe6-46d1c315028c","Towards measuring the microscopic origin of 1/f-flux noise using nanowire transmons subject to a magnetic field","Vaal, Elmore (TU Delft Applied Sciences; TU Delft QuTech)","di Carlo, Leo (mentor); Akhmerov, Anton (graduation committee); Endo, Akira (graduation committee); Dobrovitski, Viatcheslav (graduation committee); Delft University of Technology (degree granting institution)","2019","Superconducting-normalconducting-superconducting (SNS) transmons with 2-facet Al-shell nanowires are qubits compatible with magnetic fields above 10 mT. There are important correlations of the room temperature nanowire resistance with the chance of the qubit being measurable: at a resistance of 2−3 kΩ, the qubit is almost guaranteed to work. The chance of success halves every 2−3 kΩ increase. This information can be used to increase the yield. The flux noise power spectral density (PSD) of a model spin-1/2 fluctuator has been investigated as a function of the magnetic field using the Zeeman interaction. Not only the fluctuations parallel to the magnetic field contribute, but also the fluctuations perpendicular to the magnetic field. Cross-terms cancel out. The flux noise PSD of the SQUID is a linear combination of these spin PSDs when the spins are spatially uncorrelated. The magnetic field suppresses the parallel spin-axis noise PSD contribution as cosh^(-2)(μB/kBT). The magnetic field changes the perpendicular spin-axis PSD contribution due to the Larmor precession frequency peak 2fZ~μB, but does not influence the PSD contribution at frequencies higher that the Larmor precession frequency. When rotational asymmetry in the SQUID geometry is present, the PSD contributions of the perpendicular and parallel components can be separated. In our setup, a perpendicular coil is used to align the magnetic field with the transmon plane. The alignment procedure of maximizing the resonator frequency vs. the perpendicular coil field has been verified. To measure the flux noise, the perpendicular coil is first used to change the flux bias by large amounts. Then a dedicated flux bias is used to make a fine-grained sweep over the flux without flux-jumps, to calibrate the magnetic field at the SQUID. We have found a signal of the flux noise at zero field and at field. A flux noise amplitude of A~1000 μΦ_0 has been found at zero magnetic field.","quantum computing; quantum information; superconducting transmon; nanowire","en","master thesis","","","","","","","","","","","","Applied Physics","",""
"uuid:f9ae1982-d9e8-4e83-b91e-b09a76eaa970","http://resolver.tudelft.nl/uuid:f9ae1982-d9e8-4e83-b91e-b09a76eaa970","Development and optimization of ultrathin solid electrolyte systems for TF Li-ion batteries","Popławski, Mateusz (TU Delft Mechanical, Maritime and Materials Engineering)","Haverkate, Lucas (mentor); Gonzalez Garcia, Y. (mentor); Wagemaker, M. (graduation committee); Delft University of Technology (degree granting institution)","2019","Solid state Li ion batteries have garnered attention due to their high safety and increased energy density. A key challenge towards commercialization is reduction of the high interface resistance affecting the charge transfer and in turn performance. In this thesis the aim is to analyze lithium phosphorous oxynitride (LiPON) properties. By variation of layer thicknesses and electrode conguration, LiPON bulk and interfacial properties were determined using electrochemical impedance spectroscopy. The results show a high degree of consideration with respect to surface morphology and deposition conditions is required for the reduction of interface resistance in solid state batteries.","LiPON; Battery; Thin Film; solid state battery; Solid state electrolyte","en","master thesis","","","","","","","","2024-08-05","","","","Mechanical Engineering","",""
"uuid:326178cc-051e-4b02-91b1-ce4d90ff3dc6","http://resolver.tudelft.nl/uuid:326178cc-051e-4b02-91b1-ce4d90ff3dc6","Towards a brighter blue: Creating an impact index to increase adoption for sustainable jeans","Ebbers, Lauren (TU Delft Industrial Design Engineering)","Hultink, H.J. (graduation committee); de Jonge, F.M. (graduation committee); Veenhoff, James (mentor); Delft University of Technology (degree granting institution)","2019","The fashion industry is the second most polluting industry in the world, mostly due to the many ways fashion is polluting the environment (Fischer, 2015). First of all by the CO2 emission produced in manufacturing and logistics, second the massive amounts of water used in dyeing processes and production of natural resources, third the pollution of groundwater and rivers by pesticides and dyes and last but not least the enormous amount of waste created by fast fashion items that are only worn once. One of the most impactful garments in this industry is something most of us wear every day: a pair of jeans. The production of a single pair uses on average 8000 litres of water (Water Footprint Network, 2016). Besides water, toxic and corrosive chemicals are used to dye and ‘wash’ the jeans to its desired style. Every year, more than 2 billion pairs of jeans are produced worldwide, adding to its yet existing footprint (Greenpeace, 2016). Some brands in the industry are already putting a lot of effort into the production of sustainable denim. However, reducing the impact of the denim industry is not just up to denim brands and manufacturers anymore: consumers have to play their part as well. To raise awareness and higher the demand for sustainable jeans amongst consumers, this graduation project for House of Denim focusses on solving the following challenge: how might we help consumers buy better jeans? To raise the demand for sustainable jeans, the impact of a jeans has to become more transparent and understandable for consumers. In an attempt to achieve this, a jungle of certifications has popped up in the fashion and jeans industry, resulting in more confusion than transparency; many consumers are not familiar with any of these existing certifications. Besides awareness, understanding what a certification stands for demands quite some knowledge of materials or manufacturing from consumers. To make it easier for consumers to make a positive choice, Brighter Blue, a product rating tool, was developed in cooperation with denim experts and consumers. To accomplish this, the project used an inside- out approach to research the impact of a pair of jeans, to see what factors contribute most to this impact and to explore how this impact could be minimised. Afterwards, a case study was used as a parallel perspective, to see and learn how indices in other industries help change behaviour. Qualitative interviews with eight denim experts and a literature study on green consumer behaviour defined the most important challenges and design guidelines for Brighter Blue. These guidelines were further developed into a first minimum lovable prototype of the rating: the impact index. From this moment and outside-in approached was used to develop this concept using lean methodology. Through three design interventions with important industry stakeholders and (expert) consumers, the rating was developed into the final concept Brighter Blue. Brighter Blue is a positive and easy indicator of the best jeans out there: accessible on various levels to serve as many consumers as possible. By means of a hangtag and Google extension, the ratings are communicated to consumers, so they can look good and feel confident that they have made the right choice. An overarching platform conveys the message that sustainable choices do not have to be that hard or complicated: everyone can vote with their money. Brighter Blue helps consumers regain their power to decide and gives a little push to young conscious consumers that want to make better choices but not always know how. This thesis presents the development and final concept of Brighter Blue, including the rating methodology, working mechanism, benchmarks, prototypes of the various consumer tools, and a detailed plan for further implementation and market launch.","Denim; Green consumer behaviour; Product rating","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:39d037d6-10a0-4031-ba65-09bda58cb617","http://resolver.tudelft.nl/uuid:39d037d6-10a0-4031-ba65-09bda58cb617","Physical Model Study of Living Breakwaters: Stability and Ecological Analysis of Green-Grey Hybrid Structure Concept for Climate Change Adaptation","Raza, Nauman (TU Delft Civil Engineering and Geosciences)","Lubbad, Raed (mentor); Hofland, B. (graduation committee); A. Arntsen, Øivind (graduation committee); Sasikumar, Athul (graduation committee); Delft University of Technology (degree granting institution); Norwegian University of Science and Technology (NTNU) (degree granting institution)","2019","A vast majority (84%) of all countries in the world have coastlines and 80-100% of their population resides within 100 km of the shoreline. Studies show a major growth in population in low-elevation coastal zones and a scenario of rising sea level may force millions of people to relocate. To deal with the increased frequency of extreme events and sea level rise, coastal vegetation (mangroves, salt marches and coral reefs) has been observed to act as an effective natural barrier. Coral reefs are believed to reduce upto 90% of wave energy but increasingly warming oceans and acidification are destroying this barrier by coral bleaching. Apart from a social, ecological and environmental damage, this will also result in an increase in environmental loading on coastal structures. This study focuses on the development of a climate change adaption measure for existing structures on the principles of Sustainability. In order to do so, a representative existing breakwater at Kiberg Norway is chosen. A brief ecology study of the area is conducted and based on economic value and vulnerability, Red King Crabs and Capelin are chosen as target species. A green-grey hybrid structure consisting of an existing breakwater with additional Artificial Reefs (AR) as toe elements is hypothesized to be the suitable solution. However, hydraulic performance of AR is still not understood properly and to utilize them to enhance the stability of existing breakwater may create tension between hydrodynamic and ecological performance. In order to investigate the hydraulic behaviour of hybrid structure, physical model study is conducted. A traditional method of using transmission coefficient to quantify energy dissipation over submerged/non-submerged AR breakwater is not suitable for this hybrid structure. Therefore, stability of existing breakwater is measured in terms of damage level (Ahrens and Cox, 1990) and indirectly by turbulent kinetic energy (Mukaro and Govender, 2013) for 9 plunging and 6 surging wave conditions. Four configurations of experimental setup are finalized with four types of AR units (AR1, AR2, AR3 and AR4) and in total 175 tests are carried out. Behaviour of breaking and non-breaking waves is observed to be different especially over config-3 and config-4. Landward vortex and breaker tongue are not fully developed in config-3 due to depth limited scenario. Additional non-linearities in the flow, due to interaction of incoming and secondary waves, are observed for config-4, which resulted into higher reflection coefficient than other configurations. Behaviour of a hybrid structure can be predicted by Van der Meer stability formulas for plunging and surging waves at lower wave heights. However, higher waves exhibit greater damage reduction and formulas show larger deviations. Results indicate that one row of AR placed as toe, does not reduce much damage (10%). A comparison of all the configurations indicate that config-3 and config-4 show an average damage reduction of 38% and 51% respectively. Critical stability number of config-4 (i.e. 1.45) is lower than of config-1 (i.e. 1.7), indicating that disturbing forces are becoming weaker due to the presence of AR. Residence time of wave on reef is believed to be of much importance and with a 15m reef length a damage reduction upto 45% is observed. Reef porosity is observed to have dependency on placement location and reef length. Ecological performance is predicted to increase by 25% in 10 years of construction. However, differently chosen indicator species might have shown better results. It is concluded from the study that green-grey hybrid structures can be a suitable short-term climate change adaption measure.","CoMEM; Living Breakwaters; Climate Change Adaption; Artificial Reefs","en","master thesis","","","","","","","","2020-08-01","","","","Coastal and Marine Engineering and Management (CoMEM)","",""
"uuid:f76ad1e0-23c9-46be-a815-afe91755c4c5","http://resolver.tudelft.nl/uuid:f76ad1e0-23c9-46be-a815-afe91755c4c5","Comparing Performance of Locally Repairable Codes","van der Pas, Thomas (TU Delft Electrical Engineering, Mathematics and Computer Science)","Weber, Jos (mentor); Delft University of Technology (degree granting institution)","2019","With the internet growing exponentially, the amount of information stored digitally becomes enormous. Storage systems are expected to withstand failures to prevent the loss of data. To provide the reliability, data is stored multiple times in different storage units. If in this case, one of the storage unit goes offline, a backup of the data will be available in another. Needing to deal with duplication causes massive amount of excessive storage overhead. To prevent this overhead, erasure coding can be used. This form of coding can reduce the storage space needed, while still being able to provide a certain level of fault tolerance. Erasure coding makes use of so-called parities; symbols that do not directly contain data, but can be used to retrieve actual information nonetheless. When informational symbols get lost, due to a failure, the parity symbols are combined to reconstruct the lost symbol. Since multiple parities might be used in this process, repair traffic is generated. This traffic slows down the rest of the data flow, retaining quick access to the data. The amount of traffic needed to recover an erasure, is called the locality of a code. Codes with small amounts of storage overhead tend to have a greater locality, causing a lot of repair traffic in case of an erasure. In this thesis, multiple codes are being compared based on their locality and storage overhead. Besides these characteristics, a large code distance is favorable in erasure coding schemes. The distance within the code words of a scheme, determines how many erasures the scheme can handle without losing data. The Maximum Distance Separable (MDS) codes, such as the widely used Reed-Solomon codes, are optimal in the trade-off between code distance and storage overhead. In other words, these codes only need a little amount of overhead in order to withstand a large number of erasures. The pitfall of these codes, however, is their large locality which makes them almost unusable for some applications. Nevertheless, they form a great base for another type of coding scheme; the Locally Repairable Codes (LRC). These codes are extended with extra parity symbols on top of the MDS code which ensures a code locality lower than that of the MDS codes. Since less traffic is needed to repair erasures, they form an interesting group considering the compromise between code locality and storage overhead. The foundation of this thesis is formed by the content of the research paper “XORing Elephants: Novel Erasure Codes for Big Data” [4]. In this paper, researchers explain the creation of the (10,6,5) Locally Repairable Code and compare its characteristics to those of the (10,4) Reed-Solomon code. On top of the researchers’ findings, different parameter configurations will be applied to discover more of the LRC family in this thesis. Different configurations create codes that perform differently in recovering erasures. After comparing their characteristics, applications will be sought for each of the newly created LRCs. As one code might be optimal on the aspect of storage overhead, another might be optimal on the aspect of locality and yet another on the aspect of code distance. In Table 3 of the conclusion it shown which codes excels on what aspects.","","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:85362150-c627-44c8-af8b-0ed0e09591da","http://resolver.tudelft.nl/uuid:85362150-c627-44c8-af8b-0ed0e09591da","Filtration of natural organic matter and micro pollutants","Horsman, Niels (TU Delft Electrical Engineering, Mathematics and Computer Science)","Vuik, Cornelis (mentor); Delft University of Technology (degree granting institution)","2019","This study discusses the filtration of micro-pollutants and natural organic matter<br/>from water by a granular activated carbon filter. To determine the efficiency of a<br/>filter, simulations are run to predict it’s efficiency. This study will describe a demo application and it’s underlying model that are used to determine the efficiency of a filter over time. The model is able to predict the adsorption of pollutants by the filter. But the model requires a high computational power. A solution to this problem is to look for a better time-integration method. This study will look into the filtration process and usage of time integration-methods on the model. The following research question will be posed: What numerical method is most valid for the simulation of the filtration process by a GAC filter?","Numerical Analysis; natural organia matter; filter; Micropollutants","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:92ada70f-59a9-4fac-9d6d-4f89461b9df7","http://resolver.tudelft.nl/uuid:92ada70f-59a9-4fac-9d6d-4f89461b9df7","Embedded System Design for Bioelectronic Interface to Sensory Cortex","Misdorp, Alexander (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Computer Engineering)","Al-Ars, Z. (mentor); Carloni, Luca (graduation committee); van Genderen, A.J. (graduation committee); Delft University of Technology (degree granting institution)","2019","Visual perception is a pillar of human life. Visual impairment, therefore, has a severe impact on the quality of life. The Bioelectronic Interface to Sensory Cortex (BISC) project is aimed at building a system capable of both recording and stimulating neurons in order to remedy visual impairment. The proposed BISC system consists of three components: a brain implantable chip, a relay station, and a base station. The so-called BISC chip implanted atop the brain can electrically interact with neuron populations for the purpose of recording and stimulation. The relay station transfers data to and from the BISC chip wirelessly, and is composed of an embedded system and a printed circuit board (PCB) that the user can wear on the outer side of the head. The base station connects to the relay station via Wi-Fi in order to communicate with the BISC chip, and is represented by a desktop computer. In this work we focus on the design of the embedded system in the relay station. We compare networking protocols and perform bandwidth measurements on the Wi-Fi link to explore the design space. A minimum bandwidth of 83.2 Mbit/s is required to support the BISC chip data rate. Our C++ software infrastructure for networking reaches an attainable bandwidth of about 90 Mbit/s using 5 GHz Wi-Fi. A C++ Application Program Interface (API) is developed in order to communicate with the BISC chip from the base station, through the relay station. The API enables a base station user to send instructions to the BISC chip in order to set it up for recording or stimulation. Responses and recordings from the BISC chip are transferred to the base station for analysis. A digital module for the relay station is designed in order to relay data to and from the BISC chip. The digital module is written in SystemC and synthesized for FPGA fabric using a high- level synthesis tool. The module successfully interfaces to the PCB and is capable of relaying 83.2 Mbit/s of data from the BISC chip to memory. Additionally, embedded software to control the digital module is developed. The embedded software is capable of delivering BISC chip instructions to the module, and can read responses and recordings from memory in order to make them available to the API. By testing in vitro, the BISC system is demonstrated to be functional with acknowledgements sent out by the BISC chip in response to commands sent from the base station. Recordings can be stored on the relay station or transferred wirelessly to the base station in real-time.","embedded systems; FPGA; high-level synthesis; zynq; SoC; bioelectronic; sensory cortex; brain-computer interface; blind; visual cortex; BISC","en","master thesis","","","","","","","","2021-07-30","","","","Electrical Engineering | Embedded Systems","Bioelectronic Interface to Sensory Cortex",""
"uuid:8423f271-d65f-4cd2-a94f-e3cd526b1076","http://resolver.tudelft.nl/uuid:8423f271-d65f-4cd2-a94f-e3cd526b1076","Improving Na-beta”-alumina interface and grain boundary as solid-state electrolyte for large scale Room Temperature applications: Effect of particle size and liquid addition on capacity, conductivity and cyclability","Leclercq, Loïc (TU Delft Electrical Engineering, Mathematics and Computer Science)","Wagemaker, Marnix (mentor); van der Maas, Eveline (graduation committee); de Klerk, Niek (mentor); Delft University of Technology (degree granting institution)","2019","The aim of my project at the Storage of Electrochemical Energy section of the TU Delft is to improve the performance and uncover the electrolytic hurdles of the widely used Na-beta”-alumina solid electrolyte within Sodium semi solid-state batteries at Room Temperature. Na-beta”-alumina could be an interesting candidate to replace volatile and flammable organic electrolytes, seeing as it is not flammable and made of abundant elements. It would be a safer, with potential for mass-production due to the abundancy and low costs of the required materials. However, to make working electrolyte pellets, high sintering temperatures are needed for a high density. The material would be a lot more interesting if it could be used without such high sintering temperatures and reasonable conductivity at room temperature. The aim of this thesis is to investigate whether the point-contact problem is solid-state electrolytes can be circumvented by varying the solid electrolyte particle size in combination with liquid addition and various potential concepts. Regarding our conclusions, we can affirm that the mechanically pressed BASE electrolyte pellet concept performs worse than the slurry electrolyte concept. This is related to the improved slurry contact, as well as the increased point contacts for the pellet in combination with a suspected lower ionic liquid coverage. We can also conclude that the electrolyte resistance is lowered with organic electrolyte or ionic liquid addition. The evidence space-charge of has yet to be demonstrated for our components, as smaller particles resulted in lower conductivity and capacitance, regardless of the various series and concepts experimented with. Finally, the Na+ diffusion was better for bigger particles for all three liquid additions.","Sodium; battery; Energy storage; solid-state","en","master thesis","","","","","","","","","","","","Electrical Engineering","",""
"uuid:67365d8d-2b2d-4271-bffd-7f8345054e3b","http://resolver.tudelft.nl/uuid:67365d8d-2b2d-4271-bffd-7f8345054e3b","Simulating wave penetration in an inlet using the numerical models SWAN and SWASH: Dimensioning of an inlet and the comparison of two numerical models","Komen, Rutger (TU Delft Civil Engineering and Geosciences)","Hofland, Bas (mentor); Antonini, Alessandro (graduation committee); van Vledder, Gerbrant (graduation committee); Pantano, Franco (graduation committee); Delft University of Technology (degree granting institution)","2019","Near IJburg a new Island named Strandeiland is being build to create living area. On the eastern part of this island an inlet is situated. In this research the wave penetration in this inlet is simulated using the numerical models SWAN and SWASH. With the results of the simulations the verticall walls which surround the inlet are dimensioned. Furthermore a comparison between the used models is made.","SWASH; SWAN; Strandeiland; wave modelling","en","master thesis","","","","","","","","","","","","Civil Engineering","",""
"uuid:4f42bb8f-033d-4074-9314-62a5aa9d5702","http://resolver.tudelft.nl/uuid:4f42bb8f-033d-4074-9314-62a5aa9d5702","Roll Damping Prediction Method: To determine linear and non-linear roll damping coefficients based on multiple 2D CFD simulations","Smaal, Stijn (TU Delft Mechanical, Maritime and Materials Engineering)","Akkerman, Ido (mentor); Westerweel, Jerry (graduation committee); Visser, Klaas (graduation committee); Delft University of Technology (degree granting institution)","2019","Accurately predicting the ship motions, is essential knowledge when operating in water. To predict the ship motions, multiple ship characteristics have to be known. For the roll motion, one of these characteristics is the roll damping coefficient. Nowadays the industry standard to determine the roll damping coefficient of a ship is by performing model tests or using empirical formulas created in the late ’70s. In recent years computational power has increased significantly. This increasemakes it possible to start using computational fluid dynamics (CFD) for practical purposes instead of solely scientific research. The roll damping coefficient is a very interesting parameter to examine with viscous flow solvers as the roll motion is heavily influenced by the viscosity of the water. Multiple studies have been performed with 3D and 2D CFD simulations. By simplifying the simulation to 2D, calculation time is reduced drastically. This simplification is performed by only simulating one cross-section of the midship. Only simulating one cross-section causes a loss of accuracy in how well the roll damping coefficients can be determined as the damping effects of the bow and stern are not taken into account, or are roughly estimated. During this research, a method to accurately determine the roll damping coefficients of a ship, while maintaining low computation time, is investigated. This method is based on performing multiple 2D CFD simulations of different cross-sections and combining the results to capture the behaviour of the entire ship. With this approach, the high accuracy of 3D simulations and the low computation time of 2D simulations are combined. The accuracy of this 2D section method is determined by comparing the results with experimental data. The experimental data is obtained through free roll decay tests of a ship from Van Oord on model scale. A 3D CFD model, which simulates a free roll decay test, is created using OpenFOAM. The results of this simulation are compared to the experimental data to determine how well a 3D simulation can predict the roll damping coefficients. Next, a 2D CFD model is created using OpenFOAM which is validated using experimental data of a structure which has a uniform cross-section along the entire length. Lastly, the validated 2D CFD model is used for the 2D section method. Multiple cross-sections of the same ship from which the experimental data is obtained and with which the 3D CFD simulation is performed, are simulated. The results of the 2D section method are compared to the experimental results in order to determine how well this method can determine the roll damping coefficient of a ship. The simulation of the 3D free roll decay test underestimated the linear damping. The non-linear damping was within the margins of the experimental data. The 2D forced oscillation simulations showed an excellent agreement in linear and non-linear damping with both the experimental data as with a comparable CFD simulation. The 2D section method slightly overestimates both the linear and non-linear damping of an entire ship but overall this method shows promising results. However, more research should be done to optimise the method further.","Roll damping; 3D; Computational Fluid Dynamics (CFD); 2D; 2D section method; Free roll decay; Forced oscillation","en","master thesis","","","","","","","","","","","","Marine Technology | Hydromechanics","",""
"uuid:cf138038-adc9-41b6-a08f-3f2e9359a3fc","http://resolver.tudelft.nl/uuid:cf138038-adc9-41b6-a08f-3f2e9359a3fc","Feasibility Study of a Fast Electric Passenger Ferry","Francis, Moreno (TU Delft Mechanical, Maritime and Materials Engineering)","Hopman, Hans (graduation committee); Kana, Austin (mentor); Akkerman, Ido (graduation committee); Frijters, Thomas (mentor); Delft University of Technology (degree granting institution)","2019","The negative effects of global warming can already be noticed. The burning of fossil fuel not only contributes to global warming, but also to the reduction of air quality, especially in urban areas. In order to limit the climate change, as well as to improve the air quality, more and more vehicles are replaced by emission free versions. This thesis is a case study in which the feasibility of replacing a fast passenger ferry (300 passengers, 30 knots) by an emission free vessel was investigated. Two options remained after analysing different methods of emission free propulsion: battery powered and hydrogen fuel cell powered, both in combination with an electric motor. So in this report, the emission free ferry is an electric vessel. Without additional design changes, a battery powered version is not possible. So a reduction in energy consumption is required. A hydrogen powered ferry is feasible, but more expensive, thus a reduction in energy consumption is desirable as well. It must be mentioned that costs is not the most important aspect, because the reduction in emissions might be worth it. Furthermore, a lot of indirect costs are related to pollution. The effect on energy consumption was analysed for three design related changes: elongating the hull, using carbon composite instead of aluminium, and applying expected future battery and fuel cell systems. Currently, a battery powered ferry is only feasible with an elongated hull, but future technology significantly increases feasibility, also for the original hull length. A reduction of structural weight also increases feasibility, which effectively means a reduction in costs. The hydrogen powered ferry was already feasible, but the above mentioned changes in design improve feasibility, i.e. reduce the costs. Two operational changes were analysed as well: operating at a lower design speed and operating on a shorter crossing. The first has a limited effect on energy consumption, but the latter significantly increases feasibility of the battery powered ferry. Both changes do not have much effect on the feasibility of the hydrogen powered concept. The final concept that was analysed is the hydrofoil supported catamaran, because hydrofoils can significantly reduce resistance. Compared to existing hydrofoil vessels, there are two major differences: the electric concept has relatively more weight, and its design speed is significantly lower. Therefore, the hydrofoil must be relatively large to generate the required lift, and a larger hydrofoil suffers from larger 3D and interference effects. This drastically lowers the efficiency, and as a result, the hydrofoil concept is not a feasible solution. It can be concluded that an emission free fast ferry is feasible. A battery powered ferry is best suited for short crossings and the hydrogen fuel cell powered ferry can operate at longer crossings. The direct costs are likely to be higher, but this might be worth it, as it leads to a reduction of emissions, and thus to a reduction of indirect costs related to pollution. So the remaining question is: do we want to invest now, or pay for the damage afterwards?","Emission Free; Electric; Catamaran; Ferry; Battery; Hydrogen; Fuel Cell; Hydrofoil; Resistance","en","master thesis","","","","","","","","","","","","Marine Technology | Ship Design","",""
"uuid:6f7a61ac-fc5e-4926-9278-c88ebcea9cd6","http://resolver.tudelft.nl/uuid:6f7a61ac-fc5e-4926-9278-c88ebcea9cd6","Conceptual design of an autonomous amphibious container transportation vehicle","Kleefstra, Timo (TU Delft Mechanical, Maritime and Materials Engineering)","Negenborn, R.R. (mentor); van den Bos, W. (mentor); Delft University of Technology (degree granting institution)","2019","The share of container transhipment within the Port of Rotterdam increases over the years. A new concept for a transportation vehicle will extend the use of autonomous vehicles for the transhipment between different terminals. In order to avoid the high traffic density highway A15, this new vehicle will make use of amphibious capabilities in order to exchange between road and inland waterway networks. Eight technically viable designs are established which are evaluated on their operational application by means of multi-criteria analyses. A more detailed design will present an example of how such a vehicle can be realised.","","en","master thesis","","","","","","","","","","","","Marine Technology | Transport Engineering and Logistics","",""
