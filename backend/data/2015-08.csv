"uuid","repository link","title","author","contributor","publication year","abstract","subject topic","language","publication type","publisher","isbn","issn","patent","patent status","bibliographic note","access restriction","embargo date","faculty","department","research group","programme","project","coordinates"
"uuid:6b444e08-abde-45b2-a270-5c48831eab4c","http://resolver.tudelft.nl/uuid:6b444e08-abde-45b2-a270-5c48831eab4c","Numerical Determination of the Three-Tangle of Mixed States","Saad, S.","Thijssen, J.. (mentor); LaHaye, D.J.P. (mentor)","2015","","","en","bachelor thesis","","","","","","","","","Applied Sciences","Theoretical Physics","","","",""
"uuid:0570c58a-4366-4fee-8ceb-73808529fd2d","http://resolver.tudelft.nl/uuid:0570c58a-4366-4fee-8ceb-73808529fd2d","Isogeometric Analysis for Compressible Flows with Application in Turbomachinery","Jaeschke, A.M.","Möller, M. (mentor); Vuik, K. (mentor); Schuttelaars, H. (mentor)","2015","Computer-aided design (CAD) and finite element analysis (FEA) tools are extensively used in industrial design processes. The idea of isogeometric analysis (IGA) is to bring those worlds closer together. Combining them significantly increases the efficiency of the design and development processes. The general idea of the IGA approach is to use non-uniform rational B-splines (NURBS) that are used to represent the geometry in the CAD tool also as a basis for numerical analysis of the partial differential equations (PDE) via FEA. The simplest setting is to use the space spanned by NURBS as a search/test space in the standard Galerkin method. Nowadays, increasing the efficiency of turbo-engines and therefore decreasing the emissions of mainly CO_2 and NO_x is a field of very active research. Therefore, design optimization of turbomachines, largely based on numerical simulations, is extensively performed in industry. An additional motivation for solving the underlying flow problems by IGA is its ability to exactly represent the complex shapes of domains, which is an important feature for flow solvers that need to accurately resolve boundary layers. The topic of this thesis project: application of isogeometric analysis to compressible flow problems is very broad and it is beyond the scope of this thesis to answer all questions arising during the pilot implementation of an IGA solver for compressible flows. Therefore, it was decided to set the implementation of a B-spline-based IGA solver for the compressible Euler equations as the main goal. To achieve this goal several intermediate milestones were set. The first was the implementation of a simple B-spline basis generator and evaluator. The next step was to solve the Poisson problem with IGA. The next step consisted in implementing the solver for the convection-diffusion equation in stationary and time-dependent variants. Those steps led to the final milestone - the implementation of the compressible inviscid flow solver based on the IGA approach. It is well known that the standard Galerkin finite element method as well as its isogeometric counterpart suffer from infamous oscillatory behaviour for convection-dominated problems and problems including discontinuities or steep gradients in the domain. Therefore, the algebraic flux correction (AFC) stabilization was implemented to avoid oscillations and non-physical values in the solution. The main novelty of this thesis is to combine AFC with IGA for the compressible Euler equations. All solvers implemented during the thesis work were successfully validated using common benchmark problems. This work sets a base for further research and development that will hopefully lead to a productive implementation of IGA-based optimisation in industrial turbomachinery design.","IGA; isogeometric analysis; AFC; algebraic flux correction; B-splines; compressible Euler equations","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","COSSE","",""
"uuid:c22c2006-c553-402a-b220-65a4dc6204de","http://resolver.tudelft.nl/uuid:c22c2006-c553-402a-b220-65a4dc6204de","A value based market introduction strategy for a medical device start-up: Case study of Adjuvo Motion","Butter, G.G.J.","Smulders, F.E.H.M. (mentor); Rusák, Z. (mentor)","2015","Adjuvo Motion is focused on solving the problem of too little treatment of stroke patients in outpatient care. Adjuvo Motion offers a combination of a patented robotic brace and an e-health service developed for home rehabilitation. This product service combination will ensure that stroke patients are treated at home with the same care as they would receive in specialised rehabilitation clinic. Unlike competing treatment systems Adjuvo Motion brings the therapy to the patient instead of the patient to the therapy.","strategy; lean startup; medical devices","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product Innovation Management","","Strategic Product Design","",""
"uuid:33257d89-3016-4b85-8fa3-517fb3abd314","http://resolver.tudelft.nl/uuid:33257d89-3016-4b85-8fa3-517fb3abd314","Supervised Learning for Measuring Hip Joint Distance in Digital X-ray Images","Krishnakumari, P.K.","Vilanova, A. (mentor); Flipse, I. (mentor)","2015","Osteoarthritis is a degenerative joint disease which is hard to diagnose objectively and may vary based on the surgeon. This disease is usually diagnosed by measuring several characteristic features of Hip X-rays mainly the joint distance between the femoral head and acetabular cup. Hip joint distance reduction is a clear symptom of Osteoarthritis as it suggest cartilage disappearance. Hip joint distance metric involves segmentation of the femur and pelvis in X-rays, which is a challenging task because of contrast variations as well as external factors like anatomical and pose-variation. A multiscale approach based on Machine Learning is presented in this work for the segmentation of multiple bone structures. This technique uses landmark detection via data-driven joint estimation of image displacements and introduces a unique refinement step for improving the accuracy of detection. The detection is based on supervised learning using manually annotated landmarks. Therefore, the landmark placement along the edge of the bone has been covered in detail. The detected landmarks are then used to determine the joint distance in several locations along the hip joint. Aside from the segmentation technique, this work also introduces novel joint distance metrics which can be used to detect joint space narrowing. A detailed quantitative evaluation proved this work to be superior to the current state-of-the-art segmentation that handles multiple bone structures and is the first in evaluating the joint space width metric. We have also considered and discussed in brief the impact of such a system for diagnostic purposes.","joint space; landmark detection; Active Shape Models; 2D gradient profiling; X-ray image; automatic segmentation; supervised learning; osteoarthritis; machine learning","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Computer Graphics and Visualization","","Masters ICT Innovation","",""
"uuid:59bc3836-1d31-4401-ad2d-aef82f936c3d","http://resolver.tudelft.nl/uuid:59bc3836-1d31-4401-ad2d-aef82f936c3d","Economical and Ethical Implications of Off-shoring Decisions from Germany to Romania","Pavel, T.M.","Storm, S. (mentor); Van de Poel, I. (mentor); Van Beers, C. (mentor)","2015","With globalization, off-shoring has become a common practice for companies because of its cost saving advantages and ability to access needed human capital. However, off-shoring is often associated with the job loss and wage change in the domestic country. With the opening of the East European market, Germany has become one of the most important foreign investor in Romania. This paper derives a measurement for the German off-shoring in Romania using the World Input-Output Database and asks the question whether the changes in the off-shoring pattern can be associated with changes in the employment and wage levels in Romania and Germany. The results show that there is indeed a positive correlation between off-shoring and employment in both countries, whereas the correlation between off-shoring and the wage level is negative for Germany’s case and positive for Romania. The results of the econometrical analysis are then applied on the utilitarian and Rawlesian framework to assess whether the German off-shoring to Romania is an ethical process. Based on the ethical discussions, the German and Romanian governments as well as the German companies are given recommendations on how to act in the most ethical way in the context of the German off-shoring to Romania and its economic implications.","off-shore; employment; wage; utilitarianism; rawls","en","master thesis","","","","","","","","","Technology, Policy and Management","Economics of Technology and Innovation","","","",""
"uuid:070e13e3-c6f2-4903-bb27-17a28e6cfeb5","http://resolver.tudelft.nl/uuid:070e13e3-c6f2-4903-bb27-17a28e6cfeb5","Analysis of the impact of sedimentological heterogeneity and fractures on fluid flow properties in a deltaic reservoir setting using numerical models","Lipus, M.P.","Storms, J.E.A. (mentor); Hardebol, N.J. (mentor); Van der Vegt, H. (mentor); Barnhoorn, A. (mentor)","2015","Process-based numerical simulations in river delta modelling have demonstrated the importance of hydraulic and sedimentary forcing mechanisms on delta morphodynamics. Insights of these simulations on deltaic systems have a high potential to improve reservoir predictions in the industry. However, detailed morphological studies are typically conducted in a qualitative manner which provides unsatisfactory results for reservoir characterisations. This work presents a systematic workflow to perform semi-quantitative classification of process-based deltaic models created in Delft3D-FLOW with the use of dynamic reservoir flow models. The flow response of synthetic reservoir models is investigated using two Delft3D models which were modelled with varying sediment input conditions. Subdomains of the models were extracted and stacked onto each other to model sequence stratigraphic stacking pattern such as progradation, aggradation and retrogradation. Moreover, the effect of different orientations of production-injection well doublet and mechanical unit-confined fractures is investigated. As a proof of concept, a case study is conducted using 48 flow simulations. The results are investigated in terms of flow rates of the oil and water phase at the production well over time which is subsequently compared to average permeability maps of each individual parasequences. The findings are compared to sweep efficiencies per layer at the end of the flow simulation. Compared to finer sediment input compositions, the results suggest that coarser grained sediment input requires a lower pressure differential between injection and production well due to higher permeabilites but also a higher chance of quick water-breakthrough through a single parasequence. Furthermore, it was demonstrated that progradational stacking pattern result in a succession of parasequences with a higher area of incision compared to retrogradational stacking pattern which lead to improved vertical connectivity. The results show that the effect on the flow performance of the synthetic reservoir model is influenced stronger by the local occurrence of channels at the well location than the general stacking pattern. The results also indicate that fractures lead to higher differences in sweep efficiencies of individual parasequences, in particular when the fractures are orientated perpendicular to the main stream direction of the geological deposits. The work does not aim to present conclusive reservoir classification but should motivate other researchers to use the developed workflow for further quantitative reservoir analysis of Delft3D models.","fluvio-deltaic stratigraphy; sediment supply; fracture; reservoir modelling","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Applied Geology","",""
"uuid:41044ff2-3aaf-49e9-bcf5-639bbd36d800","http://resolver.tudelft.nl/uuid:41044ff2-3aaf-49e9-bcf5-639bbd36d800","The motivation of attackers in attack tree analysis","Van Holsteijn, F.A.","Pieters, W. (mentor); Franssen, M.P.M. (mentor); Van den Berg, J. (mentor); Van Gelder, P.H.A.J.M. (mentor)","2015","The number of cyberattacks has been growing over time and is expected to keep growing. In order to prevent such attacks, countermeasures have to be put in place by IT security experts. These IT security experts are however often tied to budgets and do not have a good overview of the threats that are present. It is thus necessary to provide them tools that can help them to decide on how to allocate their resources. One of these tools is the attack tree methodology, which is used to analyse complex attacks that consist of multiple steps. Properties of the overall security of the system are derived by properties of the smaller steps. These properties of the attack are represented in the form of parameters that are allocated to the nodes in the attack tree. Some of these parameters used are however dependent on the type of attacker. In order to be able to reuse the attack tree for analysing it for various types of attackers, the parameters in the attack tree have to be made independent of the attacker. In order to do so, attacker properties are considered separately, which are summarized in attacker profiles. So far, methods have been formed to include the attacker’s resources and the attacker’s skill in the attack tree methodology. The result of the current research is a framework that includes the motivation of the attacker in the attack tree methodology. The framework can be used by IT security experts to analyse the attack tree for variously motivated attackers, without having to update the parameter values. A design science approach is used to design the framework, which starts with the identification of the knowledge gap. The knowledge gap lies in how to include the motivation of the attacker in the attack tree methodology. This motivation is assumed to have an influence on the pay-off an attacker receives from performing an attack. The value that including the motivation in the analysis can bring can be summarized as the following: ? The gains parameter is made independent of the type of attacker ? Various pay-offs are possible for variously motivated attackers ? The gains parameter is made more realistic The framework is ensured to reach this potential added value, by adhering to a list of requirements. This list of requirements is build up from constraints to which the framework must conform and dilemmas for which a design choice has to be made. The resulting framework is mainly based on the method presented by Lenin et al. (2014). Changes to the current method are mainly made to the gains parameter. The gains is no longer a global parameter that is only received by the attacker when reaching the root node. Instead it is possible to include intermediate pay-offs, which means that gains can also be allocated to intermediate nodes. In this way, different gains are possible for different attack paths in the attack tree. The gains can thus be represented in a more fine grained way. Also an opt-out possibility is included to allow attackers to perform attacks to only reach an intermediate node and not the root node of the attack tree. In the current method the pay-off for an attacker was considered to be equal to the gains, which was the same for every type of attacker. This gains was also a single value. In the designed framework the gains has been slit up in five types of gains to deal with the five forms of motivation that an attacker may have, which are financial benefits, causing damage, knowledge gaining, pleasure seeking and gaining notoriety within a community. With the use of weight values, the importance of the various types of gains for an attacker can be represented. By multiplying the gains with the weight values, a pay-off can be calculated for a certain type of attacker. This way various pay-offs are possible for variously motivated attackers. A case study has been described to show the working of the framework on a real world case, which also served as a validation of the framework. In addition an expert opinion has been asked to validate the framework. The main improvement that can be made to the framework by future research is focussed on allocating values to the different types of gains and allocating the weight values for the different types of gains. Also attention could be paid to several dependencies between attack and attacker properties that have not yet been taken into account.","attack tree; motivation; attacker profile; pay-off","en","master thesis","","","","","","","","","Technology, Policy and Management","Information and Communication Technology","","Systems Engineering, Policy Analysis and Management","",""
"uuid:453fcf4e-822f-433e-9eaa-7f5e1e9b0026","http://resolver.tudelft.nl/uuid:453fcf4e-822f-433e-9eaa-7f5e1e9b0026","An Empirical Study of Cultural Dimensions and Their Applications","Reichenbach, E.A.","","2015","This report presents an empirical study on cross-cultural analysis, focusing on the applicability of cultural dimensions theory in a professional work environment. This study is one of the first to test cultural dimensions on practitioners. The goal is to find out how practitioners make use of existing theory and how this can be improved. Through a series of twenty one-on-one interviews with practitioners at engineering services provider Atkins Aerospace, the following results have been obtained: Current awareness of cultural differences and knowledge of cultural dimensions theory is low; practitioners of various experience levels showed good understanding of the theory when introduced to it; useful dimensions were in particular Geert Hofstede’s Individualism, Power Distance, and Indulgence; and practitioners showed keen interest in further learning, but were inconclusive on preferred teaching methods. Recommendations are that organizations should increase their efforts to train people on cultural dimensions, while theorists should improve the accessibility of their models. Pragmatism is required from all parties, and dimensions that are defined and labeled in a simpler way are more likely to be used by practitioners.","Cultural Dimensions","en","master thesis","","","","","","","","","Technology, Policy and Management","MAS","","Management of Technology","",""
"uuid:f18e30b0-6252-4280-be65-d1ea1c29b614","http://resolver.tudelft.nl/uuid:f18e30b0-6252-4280-be65-d1ea1c29b614","A training tool for the flow-volume test for young children with Cystic Fibrosis","Den Breeijen, M.H.","Goto, L. (mentor); Visch, V.T. (mentor)","2015","Cystic Fibrosis is a rare genetic disorder that causes the mucus inside the lungs and other organs to become increasingly viscous, leading to a degeneration of their performance. A regularly held flow-volume test is an important aspect in the treatment of CF, since it can help detecting lung problems in an early stage and enables monitoring the progress of the disease over a longer period of time. Young children (aged 3-6) often have difficulties performing the test. Blaasweerspel is a training tool that can be used to train for the flow-volume test at the patient's home. It consists of a digital game that can be played on a tablet by breathing thourgh a breath controller. The persuasive game design model (Visch, Vegt, Anderiesen, & Van der Kooij, 2013) functions as a desgin method to create a fun experience for the children, while still reaching the transfer goals: learning the breathing technique and getting familiar with the nose clip and mouthpiece.","persuasive game design; cystic fibrosis; young children; flow-volume test","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design for Interaction","","","",""
"uuid:0654d34f-90fc-4d7a-944d-c2230f543cbb","http://resolver.tudelft.nl/uuid:0654d34f-90fc-4d7a-944d-c2230f543cbb","Location-aware Energy Disaggregation in Smart Homes","Reyes Lua, A.R.","Srirangam Narashiman, A.U.N. (mentor)","2015","Providing detailed appliance level energy consumption may lead consumers to understand their usage behavior and encourage them to optimize the energy usage. Non-intrusive load monitoring (NILM) or energy disaggregation aims to estimate appliance level energy consumption from aggregate consumption data of households. Hitherto, proposed NILM algorithms are either centralized or require high performance systems to derive appliance level data, owing to the computational complexity associated. This approach raises several issues related to scalability and privacy of consumer's data. In this thesis, we present the \textit{NILM-Loc Framework} that utilizes occupancy of users to derive accurate appliance level usage information. NILM-Loc framework limits the appliances considered for disaggregation based on the current location of the occupants. Thus, it can provide real-time feedback on appliance level energy consumption and run on an embedded system locally at the household. We propose several accuracy metrics to study the performance of NILM-Loc. To test its robustness, we empirically evaluated it across multiple publicly available datasets. NILM-Loc has significantly higher energy disaggregation accuracy while exponentially reducing the computational complexity. NILM-Loc presents accuracy improvements up to 30\% better than other traditional methods. It reaches an accuracy of 89\% for the evaluated datasets. We also detail a case study for the use of the fine-grained appliance-level energy information obtained. We present a load scheduler that minimizes cost and discomfort based on hourly day-ahead pricing. The proposed Demand Response (DR) system ensures user discomfort is minimzed by abstracting patterns from past user behavior and incorporating them to the designed cost-optimal schedule.","energy disaggregation","en","master thesis","","","","","","","","2015-08-31","Electrical Engineering, Mathematics and Computer Science","Embedded Software Group","","Embedded Systems","",""
"uuid:d13450ab-fc3c-47a8-8023-55557319d30c","http://resolver.tudelft.nl/uuid:d13450ab-fc3c-47a8-8023-55557319d30c","Modelling the absorption of binary mixtures in plate heat exchangers","Nuijten, M.P.","Infante Ferreira, C.A. (mentor); Vlugt, T.J.H. (mentor); Kapteijn, F. (mentor); Kirkenier, J.A. (mentor)","2015","Ocean thermal energy conversion (OTEC) is currently developed as a clean and sustainable energy technology for offshore application in tropical areas. The technology shows promising possibilities in combination with the Kalina cycle, a thermodynamic cycle for the generation of energy from low temperature difference heat sources using a working fluid mixture. Due to the differences in boiling point between the components in a mixture and the resulting temperature glide, this allows more heat to be exchanged and thus a higher thermal effectiveness of the overall cycle. Ammonia-water is identified to be a suitable candidate for application in the cycle, but still relatively little is understood about the performance of different components in the cycle when this mixture is used. The condenser in the cycle exchanges heat between the working fluid and cold deep ocean water. In case a mixture is used, the process in this heat exchanger is described as absorption. In this study, an attempt is made to model the relevant hydrodynamics and heat and mass transfer processes in the heat exchanger, given typical operating conditions and a specified heat exchanger geometry. A plate heat exchanger is used for the absorber, due to specific advantages of this type of heat exchanger. A review of the used thermodynamic cycle, working fluids and their properties, and the heat exchanger type is included in this study. Also, literature on the hydrodynamics, pressure drop, heat transfer and mass transfer is discussed. A review of modelling approaches is provided before an extensive description of the implemented model is given. The model is stable, the predicted parameters converge to constant values during the iterative procedure, and the predictions show reasonable agreement with other work. The heat transfer may be overestimated as a result of the assumed hydrodynamics in the model. Besides, jumps in parameter profiles result from full condensation and the corresponding change in flow pattern. The modelling approach shows promise to be extended to make predictions for different operating conditions, working fluids and heat exchanger geometries. In the future, the model could be developed into a tool for optimization of the absorber performance. A preliminary experiment was performed for validation of the model. Comparison of the numerical results with the experiment and previously developed numerical models points out that the prediction of the model for the heat exchanger performance is promising. More experiments of sufficient accuracy and reliability are required for a better validation of the model, and to allow predictions of the heat exchanger performance for a wider range of conditions.","modelling; binary mixtures; absorption; plate heat exchangers; OTEC; Ocean Thermal Energy Conversion; two-phase flow; flow patterns; low-grade heat","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Process and Energy","","Chemical Engineering","",""
"uuid:98728747-571c-4df8-ac88-f5b5cf19626c","http://resolver.tudelft.nl/uuid:98728747-571c-4df8-ac88-f5b5cf19626c","BitTorrent file sharing using Tor-like hidden services","Ruigrok, R.J.","Pouwelse, J. (mentor)","2015","The Internet is a large public network of networks and computers. When no countermeasures are taken, all information and activities taking place on the public Internet are subject to traffic analysis, threatening personal freedom and privacy. The first measure to take is securing all transferred information by applying encryption on it, which makes it at least very hard to tap the contents of the transferred information. But encryption does not add any value when it comes to anonymity. Although the contents of the message are not known (because it is encrypted), it is still possible to track down where a message comes from, and where it is going to by analyzing the network infrastructure. Governments or Internet providers may apply censorship or block any kind of network traffic coming or going from somewhere. This is where hidden services come in. The idea of hidden services was described by the authors of Tor (The onion router). The hidden services protocol hides the location of both the sender and receiver by transferring and encrypting messages over multiple hops, without revealing the true identity or contents of the messages in transit. This thesis proposes a design for implementing Tor-like hidden services in a decentralized peer-to-peer system, enabling the possibility of downloading and seeding anonymously. A proof-of-concept will be implemented into Tribler, a BitTorrent client developed at Delft University of Technology. Tribler already supports anonymous downloading using encryption over circuits with multiple hops, but to make hidden services work, an end-to-end encrypted circuit between both the seeder and downloader needs to be established. This is not as easy as it seems, because the seeder and downloader do not know each other. The implementation details of hidden services are part of this work, as well as experiments on the performance of the system. Furthermore, a number of issues related to transforming the original idea of hidden services into a fully distributed context are solved.","hidden services; tor; anonymity; anonymous; onion routing; peer to peer","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","PDS","","CS","",""
"uuid:9635a771-2618-4fc8-b721-f288ee9f34d8","http://resolver.tudelft.nl/uuid:9635a771-2618-4fc8-b721-f288ee9f34d8","An E-learning Platform for Career Development of International Talents in the Netherlands","Wang, X.","Creusen, M.E.H. (mentor); Aselmaa, A. (mentor); Xie, T. (mentor)","2015","HoiTalent is a young start-up to help international talents with their career development in the Netherlands. The company has its job portal hoitalent.com with thousands of openings for internationals and HoiCoaching to offer tailored and face-to-face career coaching service. Currently, the company is going to launch a new project as an e-learning platform named “HoiCareer” to help the young international job seekers improve their career development knowledge and skills. There are three main goals to be achieved by launching the project. First, the company wants to improve its product profile; second, the company aims to make the coaching session more efficient and reach a scalable market by building an online platform; third, the brand awareness of HoiTalent is desired to be increased by introducing the new platform to mass users. Concerning the international young talents’ difficulties in career development in the Netherlands, culture barrier and lack of professional experience and culture barrier are the biggest issues. To ideally solve their problems, the website will use video tutorials to present related knowledge and skills which are both professional and practical, especially fit the Dutch job market. Moreover, online CV polishing and mock interview will be offered as value-added services to tackle the users’ difficulty in hunting job. The platform will be built as a website, including professional courses and services to take, simple interface to use and storytelling tutorials to give users friendly and effective learning experience. Together with other HoiTalent products and services, it will contribute to a HoiTalent as a professional brand in career development field with full service from career coaching to job application.","e-learning; online education; career development","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Strategic Product Design","","Strategic Product Design","",""
"uuid:ad116c32-ea7c-40eb-955a-ba96d62ac5c8","http://resolver.tudelft.nl/uuid:ad116c32-ea7c-40eb-955a-ba96d62ac5c8","Applying a life cycle perspective to research on metal recovery from electronic waste using bioleaching","Villares, M.","Guinée, J.B. (mentor); Offerman, S.E. (mentor)","2015","The Master’s programme Industrial Ecology is jointly organised by Leiden University and Delft University of Technology. Waste electronics and electrical equipment (WEEE) constitute a growing waste stream which is becoming more problematic in its management. Unsafe disposal contributes to environmental pollution and threatens human health as well as wasting secondary resources. A biologically mediated natural process, termed bioleaching, applied to the recovery metals from electronic waste, may become a promising emerging technology contributing to secondary resource recovery. Improved resource efficiency is highly relevant in the context of a transition to a more environmentally benign circular economy. Initial experimental bioleaching results using bacteria show efficient yields. Claims of benign environmental performance in the research literature are only based on process centric suppositions. Compared to metal recovery using smelting at high temperatures, the bioleaching micro organisms can work at close to ambient temperatures and directly generate few contaminants. This thesis reports on the environmental assessment of the novel bioleaching process. LCA methodology was applied at the early research stage to the process to embed it in a life cycle context, linking it to upstream and downstream flows. Then LCA was combined with an elaborate conjectural scenario to gauge its application in a potential future context and compare it to an established metal recovery process. The implications for LCA methodology were then discussed. Using primary data from the lab research, a product system was defined at laboratory scale to which LCA was applied. Data for elemental copper recovery was not available so this was estimated. After gathering ample contextual information on the direction of research, regulations, technological precedents and existing similar technologies a short term future scaling up scenario was defined. A second LCA was performed on this estimated scaled up product system. Environmental profiles were obtained for the lab product system, the scaled up system and optimised versions of the scaled up system. The latter were compared to the environmental performance of an existing technology, which aligned with the scaled up scenario in terms of scope and comparability. In the first two LCAs potential hotspots were identified in the energy and material inputs for the bioleaching process and solvents for copper recovery. However, the comparison with the existing technology returned a far inferior environmental profile, even after further optimisation. These results could not be considered robust given the precociousness of application, yet valuable information was generated. The uncertainties also prompted further enquiry about the system boundary and comparability of product systems. Despite the amount of uncertainty and conjecture involved, the whole exercise can nonetheless be considered a valid, informative mock-up of a plausible future. The tandem application of ex ante LCA and exploratory scenario brings a degree of systematic rigour and discipline to an ambiguous situation. It provides a medium for stimulating attitudes of critical examination and discovery in the very early in development can allow it to have a significant influence in broadening the research context. It is recommended that, for the bioleaching research, the LCA be built upon and refined in subsequent development stages with appropriate data gathering. In general, the approach should be applied again, possibly even earlier and for other technologies, to test it and establish its validity as an environmental screening tool in these anticipatory circumstances. As estimations are key for its application, this component should be targeted by dedicated simulation software and databases also adapted for this purpose. The promotion of the systems approach perspective of the methodology can also be disseminated by using it as an exercise as part of the training of designers, researchers and engineers. If it can be sufficiently validated after application to other research and concepts then it may be expanded to incorporate economic & social aspects.","LCA; bioleaching; WEEE; scenario; metal recovery; e-waste","en","master thesis","","","","","","","","","Delft University of Technology","Industrial Ecology","","Industrial Ecology","",""
"uuid:410aea7a-0397-40dd-b5ed-9f2a9a5f5974","http://resolver.tudelft.nl/uuid:410aea7a-0397-40dd-b5ed-9f2a9a5f5974","Automated Expansion of Statistical Shape Model Training Set for Femur","Li, H.","Vilanova, A. (mentor)","2015","Active Shape Model (ASM) uses Statistical Shape Model (SSM) to fit the manually labeled landmark point in Magnetic Resonance Image (MRI) scan and segment the femur from the MRI scan. The SSM is trained from a training set containing 275 complete femur meshes. In general, with more femur meshes in the training set, there would be more shape variance information in SSM, and the segmentation result would be more accurate. Currently, it is hard to get complete femur meshes. However, 2000 partial femur meshes are available. A method to incorporate these partial femur meshes to the SSM training set is proposed. This method includes building point to point correspondence between partial femur and complete femur, filling missing values to perform Principal Component Analysis(PCA) and designing the mechanism to utilize the content in partial femurs. Before incorporation, a rejection criteria is set to reject the unsatisfactory partial femur meshes that cannot contribute to the SSM. A evaluation method is designed and performed to validate the incorporation method. The evaluation results show the accuracy of outliers of SSM fit can be improved by incorporating partial femurs to the SSM training set.","Statistical Shape Model; Training Set Expansion","en","master thesis","","","","","","","","2017-07-31","Electrical Engineering, Mathematics and Computer Science","Intelligent Systems","","Digital Media Technology","","51.993789, 4.386978"
"uuid:166773b8-a748-43dc-9cd3-64f9753c0044","http://resolver.tudelft.nl/uuid:166773b8-a748-43dc-9cd3-64f9753c0044","High-Speed Object Detection: Design, Study and Implementation of a Detection Framework using Channel Features and Boosting","Runia, T.F.H.","Loog, M. (mentor)","2015","In this thesis we design, implement and study a high-speed object detection framework. Our baseline detector uses integral channel features as object representation and AdaBoost as supervised learning algorithm. We suggest the implementation of two approximation techniques for speeding up the baseline detector and show their effectiveness by performing experiments on both detection quality and speed. The first improvement to our baseline classifier focuses on speeding up the classification of subwindows by formulating the problem as sequential decision process. The second improvement provides better multiscale handling to detect objects of all sizes without rescaling the input image. This speed-up builds upon the scale invariance property of image statistics in natural images that offers a powerful relationship for approximating feature responses of adjacent scales. While these techniques are not new itself, to our best knowledge we are the first to combine these into a framework for high-speed object detection. Our detection framework is built from the ground up using a fast GPU implementation. Based on these approximation techniques and the GPU implementation for extracting channel features we report detection speeds of 55 fps on a laptop. In a series of experiments we study the contribution of each component to the overall detection time and the possible change in detection quality due to the approximations. We train and test the detector on our car dataset that was constructed for this work. More specifically we focus on rear-view car detection. However the methods discussed are not limited to this object class.","computer vision; machine learning; object detection; image processing; parallel computing","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Intelligent Systems","","Pattern Recognition and Bioinformatics","","51.4554115, 5.3962274"
"uuid:7d7438af-9b75-4fa9-adc8-63e51a099839","http://resolver.tudelft.nl/uuid:7d7438af-9b75-4fa9-adc8-63e51a099839","Designing a collaboration platform for effective technical communication","Han, Y.","Badke-Schaub, P.G. (mentor); Wijntje, M. (mentor); Kabir, S. (mentor)","2015","At Shell Innovation, Research and Development Organization (Shell IR&D), technical communication plays a central role of people’s day-to-day business. To do technical communication, most of time, people need to prepare the technical communication materials. However, Shell’s technical communication materials range from film and video to TV, print and digital (e.g. film, magazines, posters, brochures, slides, exhibitions etc.). To narrow down the research scope, Slides, as the most frequently used technical communication material at Shell IR&D, are chosen as the main technical communication material for this project. Additionally, with a focus on bringing the behavior to the collaboration level, the research question is formulated as: how to design a collaborative system that contributes to effective slides used for technical communication. Based on the literature review, the design framework of three-dimension support (communication support, coordination support and cooperation support) for the future collaborative system was built up as a guideline for the later design phase. In order to understand the current situation of making and using slides in terms of technical communication, an user research was carried out. The result showed that the current situation of making and using slides for technical communication in Shell was less effective and efficient, because in Shell, significant amount of hours has gone into creating slides, mostly redundant slides. Information overload is the main reason behind it, as well as the lack of awareness of the audience. To help people overcome the two barriers, a deep analysis was conducted. The results clearly showed that two existing online database results to information overload since there are too many folders and files stored in there without a nice structure. Additionally people need colleagues contribution in terms of reusing relevant slides made by colleagues and get colleagues’ feedback to help them improve the content of the slides. Therefore, with a focus on avoiding redundant reproduction of slides, as well as helping people to get feedback from colleague about their slides. The design goal was proposed: Designing a sharing platform for slides which empowers users to quickly find and make effective slides by boosting user contribution. The design metaphor is ‘book club’. After the ideation and conceptualization phase, the final concept of the sharing platform was developed, as well as a new slide making process and a modified Shell slide template. The final concept was evaluated with target users with an interactive prototype. The results showed that the concept achieved the design goal and in general, the feedback from users was positive. But meanwhile, it revealed some usability problems. Thus, to solve the usability problems, the recommendation about the main improvements were described.","technical communication; collaboration platform","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product Innovation Management","","Master of Science Design for Interaction","",""
"uuid:fa30a061-ac80-475b-aaf1-0b30b395e925","http://resolver.tudelft.nl/uuid:fa30a061-ac80-475b-aaf1-0b30b395e925","Stakeholder Network Governance: Analysing network governance in a NGO-initiated network from a transaction cost, relational governance and network governance perspective","Van Veldhuizen, M.M.","Künneke, R.W. (mentor); Scholten, D.J. (mentor); Chappin, E.J.L. (mentor)","2015","","","en","master thesis","","","","","","","","","Technology, Policy and Management","Economics of Technology and Innovation","","Systems Engineering Policy Analysis and Management","",""
"uuid:1bfec308-2c16-4cd3-baf6-35062a885ad7","http://resolver.tudelft.nl/uuid:1bfec308-2c16-4cd3-baf6-35062a885ad7","Enhancing Real-Time Twitter Filtering and Classification using a Semi-Automatic Dynamic Machine Learning setup approach","De Jong, N.","Houben, G.J.P.M. (mentor); Hauff, C. (mentor); Stronkman, R.J.P. (mentor)","2015","Twitter contains massive amounts of user generated content that also contains a lot of valuable information for various interested parties. Twitcident has been developed to process and filter this information in real-time for interested parties by monitoring a set of predefined topics, exploiting humans as sensors. An analysis of the relevant information by an operator can result in an estimation of severity, and an operator can act accordingly. However, among all relevant and useful content that is extracted, also a lot of irrelevant noise is present. Our goal is to improve the filter in such a way that the majority of information presented by Twitcident is relevant. To this end we designed an artifact consisting of several components, developed within a dynamic framework. Its major components include a machine learning classifier operating on dynamic features, a semi-automatic setup approach and a training approach. Our prototype operates on Dutch content, but it can be adapted to operate on any language. With a partially implemented prototype of our designed artifact we achieve F2-scores of 0.7 up to 0.9 for our Dutch test-sets using 10-fold cross validation, which is on average a 30% improvement over the existing Twitcident filtering architecture. The artifact is robustly designed, allowing for many forms of future improvements and extensions. We also make some side-contributions, like an approximate matching algorithm for variable length strings.","real-time filtering; social filtering; machine learning; classification; twitter; twitcident","en","master thesis","","","","","","","","2017-08-31","Electrical Engineering, Mathematics and Computer Science","Software Technology","","Web Information Systems","",""
"uuid:bd7d532c-17f9-4d7b-8ba5-aa71667b5bbc","http://resolver.tudelft.nl/uuid:bd7d532c-17f9-4d7b-8ba5-aa71667b5bbc","Horizontal distribution of concentrated loads in deep composite slabs: An analytical model validated by FEM calculations and laboratory testing","Dracht, M.S.","Bijlaard, F.S.K. (mentor)","2015","Composite steel-concrete floor slabs are a type of flooring that consists of a steel profiled deck, cast in-place concrete and steel reinforcement meshes in the concrete and steel reinforcement bars in the profiled ribs of the steel deck. Composite floors can roughly be separated into two types, those that use: shallow steel decks and deep steel decks. The deep profiled deck ComFlor210 is installed by hand and is then used as a work floor and as permanent form work for the casting of the concrete. The use of deep composite steel-concrete floor slabs is advantageous if aspects such as low self-weight, construction speed and floor height are important. The ComFlor210 composite floor is constructed by default with one reinforcement mesh, but if a large concentrated force is expected in the design than a second reinforcement mesh is added. However the effect that this added mesh has on the distribution of that concentrated force is not exactly known. The design of deep composite slabs also falls outside of the scope of Eurocode 4, design of composite structure, which leads to conservative assumptions and inefficient usage of materials. These factors lead to a need for more insight into the behaviour of composite slabs loaded by a concentrated load and in what manner this is effected by the addition of a second reinforcement mesh. An analytical was created in order to predict the horizontal distribution. In the analytical model it was chosen to only model a two dimensional strip over the width of the composite slab. Any three dimensional aspects occurring in the slabwere then incorporated into the two dimensional model. This was achieved by assuming the ribs of the composite slab as zero dimensional points which were supported by translation springs. The translation springs were modelling the ribs deflection and stiffness behaviour. The top part of the composite slab was modelled as a continuous beam spanning the entire width of the model. In order to incorporate the rotation resistance of the ribs, rotation springs were used to connect the ribs to the translation springs. For the analytical model accuracy, ease of use and a basis in mechanical behaviour were the aims. A finite elementmodel was also created in order to validate the analytical model and to analyse the behaviour of the composite slabs. Only a quarter of the slab was modelled by making use of the symmetry and only the areas of the steel deck effective in bending were included in the model. Finally laboratory experiments were also performed on life-sized test specimens. Three test specimens: one with two reinforcement meshes, one with one mesh and one without a mesh were tested. A concentrated load was applied in a non-destructive test at a quarter of the span length and a destructive test was performed at half the span length. The results of these tests were compared with the analytical and finite element model. The result of the comparison was that the accuracy goal of the analytical model could not be reached. This was because the translation springs in the model included both the distribution at the point of loading and the redistribution between that point and the supports. Therefore the distribution cannot be accurately estimated without further research and experimentation. The analytical model should therefore be revised in order to more easily assess its parameters. The stiffness of the supports is another aspect that was not taken into account into the model that could be included. The finite element model also did not have sufficient accuracy in order to use as a validation method, possibly due to the use of only the effective steel profile. Adding the whole steel deck might improve the accuracy. The experiment results yielded the conclusion that the second reinforcement mesh increases the distribution of the load in the horizontal direction significantly while loaded at mid span. The slab without mesh also could be loaded until high loads of 100 kN, but its load was far more concentrated than in the other slabs. Although initially at 10 kN all slabs had very similar distributions and until a load 60 kN the maximum difference in the middle rib was only 10% of the total applied load. It was also concluded that the steel deck was active in the transverse direction after the chemical steelconcrete bonding was lost, but the size of contribution depended on the number of reinforcement meshes. Suggestions for future research that were not included in this thesis include the horizontal and vertical shear capacity of the composite deck, the crack propagation in the slabs and the behaviour of the steel-concrete chemical bond.","Composite","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Steel Section","",""
"uuid:5c89d318-8bd7-4e98-b9c0-8d52f1c6ca7e","http://resolver.tudelft.nl/uuid:5c89d318-8bd7-4e98-b9c0-8d52f1c6ca7e","Control of Subsurface Flow: The Effect of Al-OM Interactions on Hydraulic Conductivity","Vis, R.","Heimovaara, T.J. (mentor); Paassen, L.A. (mentor); Jansen, B. (mentor); Chassagne, C. (mentor)","2015","Control of subsurface flow is important for sustainable water management. It is, for example, a useful tool for the handling of contaminated sites or the reduction of unwanted seepage. In this thesis the complexation interactions between DOM and Al are successfully used to reduce the hydraulic conductivity of a sand layer. The complexation of Al and DOM and the resulting floc sizes were first analysed with filtrations and a Malvern Mastersizer. According to the scientific norm approximately 95\% of the organic matter precipitated at Al/C 0.03 (i.e. did not pass through a 0.45 $\mu$m membrane). It was found that the mean floc size drastically grows between Al/C 0.02 and 0.03. At high Al/C ratios ($>$ 0.05) these flocs were also formed in a sand layer at constant saturated flow. In the two dimensional laboratory set-up a narrow (1 cm), dark brow layer grew at the contact front of the Al and DOM solutions. It is thought that hydrodynamic dispersion mixes the solutes and therefore changes the Al/C ratio and that the changed Al/C ratio leads to the immobilisation of Al and DOM. EC measurements showed that the small precipitate layer limits further dispersion of Al, and might therefore limit its own growth. Furthermore it was firmly proven that immobilized Al and DOM cause a significant reduction in hydraulic conductivity. Firstly the hydraulic conductivity was reduced to 38\% of its original value after which is was reduced to 23\% in a second experimental phase.","subsurface flow; alumnium; organic matter; flocculation; clogging; sealing","en","master thesis","","","","","","","","2015-09-25","Civil Engineering and Geosciences","Geoscience & Engineering","","Recource Engineering","",""
"uuid:9f2105cd-2193-4aca-b51f-7dcb01e9d603","http://resolver.tudelft.nl/uuid:9f2105cd-2193-4aca-b51f-7dcb01e9d603","Developing a dynamic framework for the selection of niche strategies to introduce new high-tech products","Bruinsma, V.M.","Ortt, J.R. (mentor); Kamp, L.M. (mentor)","2015","In many industries innovation is essential for companies to remain competitive in the market place. However, due to the embedded nature of technology, the commercialization of radically new high-take products is a complicated task to manage. Due to the presence of barriers to direct large-scale diffusion within the incumbent market situation, companies often choose to apply niche strategies to make commercialization of the new-high tech product possible despite these barriers. Existing approaches that aim at guiding the selection process of niche strategies, on the basis of the barriers in the market, are inept to deal with the actual complexity and dynamic nature of the market. In order to develop an approach for the selection of niche strategies that is a better fit with the complex market situation, and can cope with the inherent dynamics, a dynamic conceptual framework for the selection of niche strategies is developed in this thesis. To test and refine the resulting conceptual framework, it was applied to case studies of the materials Nylon and Teflon. Results indicated that the Functions of Innovation Systems approach could be used to assess the dynamics taking place with regard to factors relevant for the commercialization of new high-tech products. Furthermore, it was demonstrated that barriers within the market develop in time, that niche strategies can influence the development of these barriers, and that virtuous cycles can occur that stimulate the development of the factors required for large-scale diffusion of the product. The framework might be improved, and more cycles and relationships might be uncovered by performing additional case studies, by operationalizing the framework, and by modelling the framework using system dynamics or agent-based modelling.","functions; niche strategies; high-tech products; dynamics; nylon; teflon","en","master thesis","","","","","","","","","Technology, Policy and Management","Values, Technology and Innovation","","Economics of Technology and Innovation","",""
"uuid:d9741f92-9c07-4c91-a73d-e96e4c3f2cbc","http://resolver.tudelft.nl/uuid:d9741f92-9c07-4c91-a73d-e96e4c3f2cbc","Hypoxemia diagnosis for rural India: Design a low-cost uniform solution (single-probe) to spot-check the SpO2 that fits children from 0 to 5 years old that is adequate for low-resource setting","Ramirez Herrera, S.L.","Diehl, J.C. (mentor); Molenbroek, J.F.M. (mentor)","2015","Pneumonia is one of the leading causes of children’s deaths before they can celebrate their fifth birthday. The majority of pneumonia cases and deaths caused by it are concentrated on the poorest regions of the world; having India the burden of leading both lists. For this reason, UNICEF and the WHO, have made of this issue a priority on their agendas by spreading vaccinations, designing guidelines and training personnel to help detect and fight pneumonia. There are several test to detect pneumonia, unfortunately these are not easily accessible in rural areas. The IMCI (Integrated management of childhood illness) guidelines, were developed to assess pneumonia based on physical symptoms; cough with fast breathing are enough to give antibiotics to the child. Breaths counting have been pointed out to be a good sign to detect pneumonia. Nevertheless, it is a difficult task and several studies shown that most of the times are miscounted. Not only due to the lack of skills of community health workers that could be illiterate and/or innumerate; but also due to distractions or simply because the breaths are hard to see. Therefore Philips Research, have been working for several years developing an automatic respiration counter that will soon hit the market. Most of the cases of pneumonia are allocated in rural areas of hard access and lack of adequate hospitals. The first contact of a sick child with the health system is a community health worker, in India is called ASHA (Accredited Social Health Activist); this worker is trained to determine which children need immediate attention and/or which children need to go to a higher health facility. Since 2014, the IMCI guidelines suggest the use a pulse oximeter if available and ask for referral to a higher facility if below 90. A pulse oximeter allows to measure the percentage of oxygen in the blood called SpO2. When the SpO2 is abnormally low it is called Hypoxemia, in the presences of hypoxemia the chances of survival diminish exponentially. Making this information accessible to the first contact point of the healthcare system would provide the ASHA with a tool to make an accurate and fast decision that could help lives.Philips Research is eager to add a SpO2 measurement for the second generation of their current device. Therefore, this graduation project focused on the development of a pulse oximeter probe for children until the age of five that can be use by the ASHA workers and fits in a rural context. In order to create the program of requirement to fulfill the users’ and context needs; the project started with an analysis phase to understand the disease, the technology, the users and their context, as well as the advantages and disadvantages of similar products. Several body locations and possible probes for the measurement were explored, four body locations were selected after an evaluation, concentrating on 2 body location and five different direction that were detailed. Two probes, one for the head and one for the finger (Figure 1), were designed, iterated and prototyped. An experts’ evaluation and a user test were performed to compare the probes and test the reaction of the children. Along with the forehead and finger, the belly line and heel were also tested to compare which body location was less intrusive for the child and would fit in the context. Even though the probes were tested on healthy children and not in the context, the results were translated into recommendations to modify the forehead and finger probe to test them on the field. As for the belly line and heel probe, the signal needs to be analyzed in order to determine the possibility of calculate the SpO2 from this locations. Nevertheless, the heel is not recommended as a viable location for the contexts and users.","hypoxemia; pneumonia; low resource setting; child mortality; India","en","master thesis","","","","","","","Campus only","2017-08-31","Industrial Design Engineering","Industrial Design","","Master of Science Design for Interaction","",""
"uuid:5368cbce-bde9-4637-a804-c19a8aa84e18","http://resolver.tudelft.nl/uuid:5368cbce-bde9-4637-a804-c19a8aa84e18","GonioTrainer","Bosma, B.; Scoop, M.C.","Makinwa, K.A.A. (mentor)","2015","Increasing physical performance in this day and age is aided by technology. The GonioTrainer is a device which will measure a joint angle and give the user visual feedback on a smartphone, real time haptic feedback using a feedback module, and elaborate visual feedback on a computer or tablet after a session of usage. This device will consist out of two modules, the goniometer, which is the module that will perform all measurements, and the feedback module, which will provide the haptic feedback. The GonioTrainer will measure the joint angle with a frequency of 100 Hz. An algorithm will make the decision whether haptic feedback should be given or not. This algorithm will not be implemented by the project group and will thus not be reported in this thesis. However, the algorithm for determining when the haptic feedback should be given will be implemented, using a peak detection algorithm from data received by an inertial measurement unit. The time window between deciding when haptic feedback should be given and actually receiving said feedback will be no more than 50ms. In this thesis the power supply choices and corresponding circuitry, for both the goniometer and feed-back module will be implemented, documented and analysed. A prototype for the feedback module will be designed and implemented. Power consumption for a time period of 3 hours was done which concluded a rechargeable battery with a capacity of 240 mAh will be needed for the goniometer, and a battery with a capacity of 127.22 mAh the feedback module. Due to the dimensions of both modules, a battery with a Lithium-Ion Polymer chemistry was chosen. These batteries will need recharging. A suitable charger was sought and found. In order to indicate whether a battery is nearly empty, a battery fuel gauge was implemented so the remaining active relative capacity could easily be displayed. The feedback module was implemented using a 9mm eccentric rotating mass DC motor. As a method to control the motor, a motordriver was chosen. Both the gauge and the motordriver have an I2C interface.","","en","bachelor thesis","","","","","","","","2020-07-08","Electrical Engineering, Mathematics and Computer Science","Electronic Instrumentation","","Electrical Engineering","",""
"uuid:337f3b28-a91e-403d-87b3-65ee37859e85","http://resolver.tudelft.nl/uuid:337f3b28-a91e-403d-87b3-65ee37859e85","Using the Green Public Procurement policy as guide for green innovation in the flooring industry","Rao, B.","Straub, A. (mentor); Kamp, L.M. (mentor); Verburg, R.M. (mentor); Qian, Q. (mentor)","2015","Sustainable development, after all these years development, has already been accepted as one of the themes of 21st century, especially after the reveal of some serious environmental problems, such as global warming, resource exhaustion, etc. Construction industry, although being considered as one of the traditional industries of which the development speed is slowing down, is currently still playing an important role in the society and economy system. Meanwhile, it is also an industry that relies heavily on resources and energy consumption, especially the construction manufacturing industry. As a result, the pursuit of sustainability within the construction industry seems to be inevitable. In order to stimulate and push for the green transitioning in the construction industry in Europe, the European Commission issued the Green Public Procurement policy to motivate manufacturers of building products to develop green products and technologies. As a gesture of support, many member states quickly issued their own GPP policies which are more tailored for their specific situations. However, many challenges stand in the way toward fully implementation, and one of which is the shortage of qualified suppliers. Many existing literatures elaborate on the possibility of solving this challenge from the perspective of public authorities. This research, however, looks at this challenge from a different angle, the perspective of manufacturers of building products. This research studies into the flooring industry and intends to develop some suggestions for manufacturers who plan to develop green products based on the successful experiences of some frontrunners. To realize this objective, research questions are developed in this study: 1) What are the GPP requirements for flooring products in public construction projects and how are they evaluated? 2) What are the enablers and barriers during the development of green products? How do these factors get influenced by GPP policy? 3) Given the enablers and barriers, how can manufacturers of building products adjust their product development strategies to meet GPP criteria? What green attributes should be emphasized on during green product development? A literature review was conducted to find answers for the first research question. The EU GPP criteria are made for general terms of building products with no specification for each category. Two sets of criteria are contained in the EU GPP criteria, the core criteria and the comprehensive criteria which are built on the former. The main requirements of the core criteria are that products compete for public tenders should either be eco-labeled or provide detailed LCA reports to prove their environmental performance during life cycles, and if the products are wooden based, then the wooden materials are supposed to be responsibly sourced. The comprehensive criteria, based on the core criteria, add two more requirements regarding the recyclability of the products and the amount of recycled materials that should be contained in the products. In public tenders, the core criteria work as selection criteria for the qualification of suppliers, while the comprehensive criteria act as award criteria. Apart from the general EU GPP criteria, eco-label criteria can also be used as evaluation references. The eco-label criteria, comparing to the EU GPP criteria, are more detailed and specified. Three subgroups for the flooring products are made by the eco-label criteria, namely hard flooring, textile flooring, and wooden flooring. These criteria consider every stage and aspect in the life cycle of products, and only products fulfill all of them get to wear the labels. Case studies were conducted to research into question 2 and 3. Three frontrunner companies in the flooring industry who have successful experiences in marketing green products were interviewed, in order to identify the enabler and barriers of green product development process as well as some recognizable green product attributes. Main findings on enablers and barriers are listed Table A. As for the influence of the GPP policy, interviewees claimed it to be limited, mostly because they developed green products before or along with the development of the GPP policy. Enablers: 1) Motivations: concern for the sustainable development of the company; concern for the competitiveness of products; concern for the image of the company; market requirement. 2) Success factors: partnership; in-house knowledge base; government subsidies. Barriers: 1) worries about future uncertainty: high price perception of customers; low functional performance perception of customers; future uncertainty (policy change, market requirement change, etc.). 2) Practical difficulties: difficult to sell at competitive prices; development cost; need for extra knowledge and expertise; loss of government subsidies; stringent public scrutiny. Some of the most mentioned green product attributes by the interviewees are: - Toxin-free raw materials - Containment of recycled contents in products - Recyclability of products - Reduction of production wastes - Use of renewable energies - Closed-loop water recycling systems. Based on these findings, some recommendations are given for manufacturers of flooring products who plan to develop their own green products in the near future: For enablers: - Bring the plan of developing green products up to schedule to meet future market demand. - Build stable and cooperative relationships with main raw material suppliers and lead clients. - Start to cultivate in-house knowledge base for green product development. - Look out for government subsidy plans, and build project based on that. For barriers: - Consider long tern return on investment when setting prices for green products. - Try various ways to gather the initial investment, such as loan, partner investment, government subsidies, etc. - When choosing what green certificates to apply, consider the zone of influence of the certificates and the market area and supplying sector of the focal company. For green attributes: - Use toxin-free materials in the products. If greener alternative is not available yet, then keeping the toxic materials below safe limits is necessary. - Contain certain amount of recycled materials in the products. - The design of the products should enable recycling. - LCA assessment report shall be provided. - Use green packaging. - Use renewable energy in production. If not possible, then energy saving plans shall be applied. - Consider using water in closed loops. If not possible, then waste water should be processed before discharging to keep certain materials below required limits. - Consider reutilizing production wastes and by products.","green innovation; Green Public Procurement","en","master thesis","","","","","","","","","Technology, Policy and Management","Management","","Management of Technology","",""
"uuid:d03e7abb-bbd0-4bed-aa1c-5e48e3d84f7c","http://resolver.tudelft.nl/uuid:d03e7abb-bbd0-4bed-aa1c-5e48e3d84f7c","Quantification of deformation and sliding of orbital fat during rotation of the eye","Coorens, R.J.M.","Vilanova, A. (mentor); Simonsz, H.J. (mentor)","2015","The anatomy of the eye is well known, however the mechanical properties and behaviour of the eye are not well known. Knowing these properties could potentially be an improvement for preoperative planning in orbital surgery. To get a better understanding of the mechanical properties of the eye while it is in movement a Finite Element Model (FEM) has been developed at the TU Delft by Schutte et al. [1]. For the FEM it is important to quantify what part of movement is sliding and what part is deformation because both are modelled in a different manner. We present a complete pipeline to quantify sliding from MRI image volumes. The registration methods previously applied to the orbit are unable to deal with sliding. Therefore, two methods developed for registration problems where sliding occurs are tested for applicability to the orbit using phantoms. The method developed by Berendsen et al. [2], or sliding splines method, performs best on the phantoms, and is applied to the orbit. The results of the sliding splines method are compared to results from regular B-splines registration which has been the registration method used in the orbit up until this project. Amelon et al. [3] have developed a method to characterize sliding from displacement fields, which has never been applied to the orbit. We applied this method to the displacement field generated by the regular B-splines registration and the sliding splines method. Comparison of both registration methods, using the characterization method, shows that methods previously applied to the orbit are unable to preserve sliding in their displacement field. The sliding splines method is able to preserve sliding, but also introduces sliding in regions where it does not occur. We conclude that further study into registration methods that allow for sliding is necessary. Especially, into the sliding splines method since it is able to preserve sliding and shows promising results.","","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Computer graphics and visualization","","","",""
"uuid:9549c9d1-07fb-484e-b4c8-3dfce1d34673","http://resolver.tudelft.nl/uuid:9549c9d1-07fb-484e-b4c8-3dfce1d34673","Holarchy: Architecture as tool for urbanization","Gallissian, J.","Havik, K. (mentor); Van Gameren, D. (mentor); Avermaete, T. (mentor); Mota, N. (mentor)","2015","This project proposes to adress the infrastructure of mobility as generator and tool for urbanization in the context of Addis Abeba. However, many African cities are subject to a massive economical and demographical growth challenging the existing urban condition. The infrastructure of mobility is a key element in the modernization process and thus needs to be reconsidered. By proposing an alternative way of thinking, this project questions the integration and place of such a fundamental figure within these cities, but also in our western context.","","en","master thesis","","","","","","","","","Architecture and The Built Environment","Architecture & Dwelling / Methods & Analysis","","Global Housing Graduation studio","","9.0249700, 38.7468900"
"uuid:e6d6b754-31ac-4553-899f-72a373eb6ff0","http://resolver.tudelft.nl/uuid:e6d6b754-31ac-4553-899f-72a373eb6ff0","Cost-benefit analysis of biodiesel related policies: The assessment of applicability. A case study in new biodiesel policies in Indonesia","Halim, I.F.","Stikkelman, R.M. (mentor); Annema, J.A. (mentor); Van Beers, C.P. (mentor)","2015","Until recently, biodiesel development in Indonesia is far from the target. The previous government policy cannot substantially increase its domestic consumption. Moreover, as the crude price oil decrease, the viability of biodiesel development is still questionable. This is due to the fact that biodiesel still remains uncompetitive since the production cost of biodiesel is higher than fossil diesel. A cost benefit analysis (CBA), as an important and systematic approach in estimating the best possible policy options has already been conducted in biodiesel sectors. It was applied specifically to analyze the financial feasibility of the industries in different countries. Despite its remarkable use, the applicability assessment of CBA in investigating the impact of different policies has been hardly examined. Thus, this research aims to investigate the applicability of CBA within biodiesel related policy changes in Indonesia. It should be noted that the Indonesian government has particularly implemented the new biodiesel related policy. The applicability of CBA to analyze the impact of any biodiesel current and future policy has given some new insights. Beside several effects that cannot be monetized, a stakeholder’s analysis plays an important role in analyzing the added value of CBA in this particular case study. The application of CBA can be used to briefly determine what the main purpose of each policy will be.","Indonesia biodiesel policy; cost-benefit analysis; applicability; future energy policy","en","master thesis","","","","","","","","","Technology, Policy and Management","Engineering System and Services","","Management of Technology","",""
"uuid:759b5c57-1001-4dee-8f23-c815c36bcace","http://resolver.tudelft.nl/uuid:759b5c57-1001-4dee-8f23-c815c36bcace","Development and Application of a Method to Design a Demand-Responisve Service Operated by Fully Automated Vehicles","Winter, M.K.E.","Van Arem, B. (mentor); Cats, O. (mentor); Homem de Almeida Correia, G. (mentor); Corman, F. (mentor); Wiggenraad, P.B.L. (mentor)","2015","","","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Transport & Planning","","","",""
"uuid:b66c7121-9484-449d-b231-24e68576504c","http://resolver.tudelft.nl/uuid:b66c7121-9484-449d-b231-24e68576504c","Topology Control in Energy-harvesting Wireless Sensor Networks","Wang, X.","Prasad, R.V. (mentor)","2015","Ambient energy-harvesting technology is a promising approach to keep wireless sensor networks (WSNs) operating perennially. Depending on the harvesting source, nodes can either be active (alive) or inactive (dead) at any instant in such Energy-Harvesting WSNs (EH-WSNs). Thus, even in a static deployment of EH-WSNs, the network topology is no longer static. A popular method to increase energy-efficiency in WSNs is by employing topology control algorithms. Most of the topology control algorithms in the literature focus only on the transmission power while constructing a static topology without taking into account the residual energy of the nodes. Consequently, they cannot handle the situation when nodes have different energy levels, and when the number of active nodes varies with time in EH-WSN. Since the number of nodes alive in EH-WSNs is varying there is no possibility of having a centralized solution. To address this issue, we present two localized energy based topology control algorithms, viz., EBTC-1 and EBTC-2. EBTC-1 is for convergecast applications of WSNs and EBTC-2 is for a generic scenario where all nodes are required to be strictly connected. In some cases, to ensure fault tolerance the network may be required to be k-connected. While typical topology control algorithms select a particular number of neighbors, the distinguishing feature of both these algorithms is that they select neighbors based on energy levels, and render the global topology strongly-connected. Simulation results confirm that EBTC-1 and EBTC-2 reduce the transmission power and they let nodes have neighbors with high remaining energy. Results show that our proposed algorithms increase at least 33% in the remaining energy per neighbor. In addition, in terms of energy consumption and fault-tolerance, our proposed algorithms typically achieve 1-connected topology using 74% less energy compared to K-Neigh.","Energy-harvesting; Topology control; Wireless sensor network","en","master thesis","","","","","","","","2015-09-04","Electrical Engineering, Mathematics and Computer Science","Software and Computer Technology","","Embedded Systems","",""
"uuid:879609fb-012d-4c42-a3b9-539e5473266d","http://resolver.tudelft.nl/uuid:879609fb-012d-4c42-a3b9-539e5473266d","Modelling sand-mud-bed interaction in the Scheldt estuary","Groenenboom, J.","Stive, M.J.F. (mentor); Van der Werf, J.J. (mentor); Van Prooijen, B.C. (mentor); Van Rooijen, A.A. (mentor)","2015","The tide-dominated Scheldt estuary is located in the southwest of the Netherlands. From the Dutch-Belgian border seawards, it consists of a system of channels and shoals and an ebb-tidal delta facing the North Sea. The behaviour of non-cohesive (sand) and cohesive (mud) sediment particles in the area are (until now) generally studied using separate numerical models. Better understanding of the physical processes in the area of interest can be obtained using process-based hydro-morphodynamic models. Based on a literature review, it is concluded that the mutual influence of sand-mud mixtures is of significant importance on the morphological development and should be accounted for when modelling multiple sediment fractions. Recently implemented modules in Delft3D can be used to improve the modelling of the cohesive fines and the interaction between the sand and mud fractions. An existing Delft3D sand-model of the Scheldt estuary is extended with a mud fraction based on a mud model of the same area. The model simulates the morphological development of one year using a representative spring-neap tidal cycle and a morphological acceleration factor of 25. The bed is modelled using a fluff layer, transport layer and base layer. Furthermore, a critical mud content is used to distinguish between a non-cohesive and cohesive regime. In each regime, different formulations are used to calculate the erosion fluxes of sand and mud. A calibration on the mud parameters is performed to improve the behaviour of the mud particles in the model. The performance of the model is assessed using a list of desiderata. The development in the model is subjected to a simulation loop in which the output is used as the input for the subsequent run in order to reduce the spin-up effects. The required period for the bed composition to develop into a state where it is in line with the boundary forcing is considered to be too long. Therefore, it is important that the model results are sufficiently stable so that the morphological development in the warmed-up model is better predictable. The computed mud concentrations in the water column and their spatial distribution are in good agreement with the results of the mud model and with observations. However, the model calculates an export of mud at the mouth of the estuary whereas observations show an import of mud. Spin-up effects are responsible for this flaw of the model as the mud transports are still influenced by the initial bed composition. The computed mud export gradually decreases over time and is expected to change to import when a significantly longer simulation period is used. Several model scenarios were set up to assess the importance of the hydrodynamic forcing mechanisms and sand-mud-bed interaction processes. By comparing the results of the model scenarios, the sensitivity of different components (tides, wind and waves) on the sediment transport and morphological development is investigated. In addition to the tidal forcing, the locally generated wind-waves have a significant impact on the morphological development of the Scheldt estuary. Based on the results of this study, it is concluded that the effect of the mud fraction on the large-scale net sediment transport is of minor importance. Studies on the large-scale sand-transport patterns between macro cells in the Scheldt estuary can therefore be done using a model that only contains a sand fraction. However, the morphological development of the fringes of the intertidal areas is significantly affected by the presence of mud since it prevents erosion of these areas. It is therefore recommended to take this interaction into account in morphodynamic simulations of the Scheldt estuary.","sand-mud; Scheldt estuary; morphology; Delft3D","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Hydraulic Engineering","","","",""
"uuid:0a20bfca-32df-47a0-990c-c4fe55a23ce6","http://resolver.tudelft.nl/uuid:0a20bfca-32df-47a0-990c-c4fe55a23ce6","Design for patient experience in cancer centers","Verlaan, P.J.","Melles, M. (mentor); Goto, L. (mentor)","2015","The incidence of cancer is increasing each year: more people are getting in contact with cancer (they get cancer themselves or close relatives get cancer). In order to keep up with this growing group of patients, the Antoni van Leeuwenhoek hospital (NKI/AVL) is currently undergoing a renovation. Patient satisfaction is put as a primary consideration in this renovation process. The hospital wants to move from a clinical-focussed-design to a patient-centred-design, where the emotions, well-being, peace of mind and satisfaction of the patient are central. Depending on the type and stage of cancer, patients have to undergo quite an amount of diagnostics tests and treatments and they probably experience several more or less severe symptoms. This all influences the physical and mental state of the patient and the way he experiences his treatment process. Literature research showed that patient satisfaction is strongly related to how people experience a certain interaction. In order to be able to improve the patient satisfaction, a patient experience journey of the cancer treatment process is made. This patient experience journey shows insights in current and past experiences of patients during different phases of their treatment process. Insights are structured into four topics: Clarity - Uncertainty Confidence - Distrust Human-oriented - Process-oriented In control - Powerlessness A fifth topic: Convenience - Discomfort, is more related to the physical surroundings of the hospital. Therefore these insights are shown in a (separate)floor plan. Following the patient experience journey, four design directions were found as interesting fields for improvement: Communication within teams Communication towards the patient Integration of after care Information services for patients The latter two directions are further explored during this project. The current situation in the hospital regarding after care and information services is analysed and the ongoing projects with their visions for the (near) future are mapped. This overview shows a ‘gap’ in the process of after care and rehabilitation that is not (yet) addressed by the hospital itself. This ‘gap’ is translated to the following design goals: Make the patient aware of his request for help or need for support Trigger the patient to act upon this request Help patients to learn and benefit from others who experience(d) a comparable situation Give patients the opportunity to seek for information themselves Conceptualisation and iterations resulted in the final design: the Vijver. The Vijver is an interactive floor projection of a pond in combination with an application. The application can be used on permanent touch screens next to the projection, as well as on the patient’s own smart phone and tablet. Stepping stones in the pond show each a dilemma that is experienced as difficult by cancer patients, for example: ‘How do I tell the kids about my diagnosis?’ With the application, the patient can read about experiences of others (how did they deal with the situation?) and he can get more information about the used help or support. The Vijver provides patients with a tool to get in control over their own after care process, without being dependent on the knowledge and skills of their specialist. An evaluation study with an interactive prototype, showed that patients, their relatives and also medical professionals, were very positive about the design. Further development is needed to get the design ready for implementation.","patient experience; cancer; design","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Design for Interaction","",""
"uuid:4670bb38-ffbb-44c1-86ac-0d6498d9433f","http://resolver.tudelft.nl/uuid:4670bb38-ffbb-44c1-86ac-0d6498d9433f","Analysis and Regulation of the Coupled Dynamics of a Two- Turbine Floating Tidal Energy Converter","Gunnink, T.","Van Wingerden, J.W. (mentor)","2015","Tidal energy converters are an emerging technology with the potential to expand the portfolio of renewable energy sources. Bluewater is developing the BlueTEC, a floating tidal energy converter with two variable pitch turbines. From research on floating wind turbines, it is known that control is fundamentally limited due to right hand plane zeros that are a result of coupled dynamics between turbine and platform. There are many similarities with floating tidal turbines. Therefore analysis is needed to determine whether similar limitations occur for the BlueTEC platform and whether they are of influence for control. Furthermore it has to be determined whether centralized or decentralized control is needed to guarantee stability. The platform model was simplified into two second order models, with parameters identified from a high-fidelity model. The first model considers only the surge and tilt degrees of freedom to assess whether right hand plane zeros occur. The second model considers the surge and yaw degrees of freedom, to analyze the effect of a two turbine platform. These simplified models were validated in the time domain against high-fidelity simulations. Analysis of the simplified models shows that the closed-loop bandwidth is fundamentally lim- ited, similar to floating wind turbines. Two methods are explored to overcome this problem. Firstly, changing the operating point around rated conditions, which does not remove the lim- itation but does improve performance. Secondly, adding an extra control degree of freedom can overcome this limitation by using the generator torque at high frequencies. Finally, input channel couplings are analyzed to assess the need for centralized control. Couplings occur at a frequency higher than the bandwidth limitation, which means that decentralized control is sufficient to guarantee stability of the two-turbine platform. The performance of the controllers was compared using time domain simulations. Since the multivariable controllers are optimized for generator speed tracking, the power and blade pitch fluctuations show an increase as opposed to a classical PI controller with limited bandwidth. The changed operating point, on the other hand, shows to be a crude method to cope with the bandwidth limitation by making sure that the rated generator speeds is minimally exceeded. This does go at the price of a decrease in generated power. Comparing the centralized multivariable controller to the decentralized controller does not show a major difference in performance for the tested conditions.","Floating Tidal Energy Converter; negative damping","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","DCSC","","","",""
"uuid:65968738-e9de-4a22-b572-177d742da7e3","http://resolver.tudelft.nl/uuid:65968738-e9de-4a22-b572-177d742da7e3","Ortho-Planar Springs: Design of a zero stiffness mechanism for energy harvesting applications","Geerders, R.","Tolou, N. (mentor)","2015","Vibrational energy harvesters convert ambient kinetic energy into electrical energy that can be used to power electronic devices. Harvesting in the low frequency range over a wide bandwidth proves to be a challenging task. In this paper it is argued that stiffness cancellation can be used to effectively operate in this range. A conceptual design of a compact zero stiffness mechanism that can be used as suspension in an energy harvester is proposed, modeled and tested. The design is based on two ortho-planar springs with a spiral topology(diameter = 48,7 mm). Through application of a force prestress, a force reduction of 74,7% is achieved over an eight mm stroke perpendicular to the plane.","Energy harvesting; Ortho-Planar Spring","en","master thesis","","","","","","","","2019-08-28","Mechanical, Maritime and Materials Engineering","Precision and Microsystems Engineering","","Mechatronic System Design","",""
"uuid:f35dde73-71ff-4b28-8ffb-603f3508d7c2","http://resolver.tudelft.nl/uuid:f35dde73-71ff-4b28-8ffb-603f3508d7c2","Transmission Expansion Planning Under Uncertainty: Model support in evaluating lon-term investment plans in interconnections","Mavroeidis, N.","Weijnen, M.P.C. (mentor); Lukszo, Z. (mentor); De Vries, L.J. (mentor); Correlje, A.F. (mentor); Van der Lee, G. (mentor)","2015","The electricity transmission system, lynchpin of the power system chain, has been recognized to play a significant role in fulfilling policy targets such as high integration levels of renewable energy sources, reduction of CO2 emissions, lower electricity costs and increased security of supply. In the European context, cross-border transmission projects are set in center of such discussions and significant investments have been considered for the near future. The European Network of Transmission System Operators for electricity (ENTSO-e) has been established to explore the development of the European transmission system as a whole. The dynamic character of electricity power systems puts great challenges on the long-term transmission planning. Increased levels of uncertainties due to RES integration, variable load profiles (developments in electrical vehicles and demand response) and regulatory changes are only some of the uncertainties. On top of that, the need for a co-ordinated planning process in Europe raises new questions regarding the modeling types used and processes followed. Main focus of this thesis was to examine which modeling approaches are the most appropriate for planning cross-border investments at a pan-European level by taking into account the large uncertainties inherent to transmission planning. An evaluation framework for assessing the different modeling types in transmission expansion was developed and the different options were thoroughly evaluated. In addition, the several uncertainties in transmission planning and ways to address them were examined using an analytical process. These two analyses revealed that there is still room for improvement in the pan-European transmission planning process both in terms of modeling types and uncertainty analysis. Subsequently, several recommendations for transmission planner and policy makers were presented. The topic this thesis examined gets more and more attention among academic and business cycles. The analysis presented can offers a great starting point for the development of new models and practices for transmission planning under uncertainty.","transmission planning; uncertainty; Monte Carlo; Capacity expansion model; Production cost model","en","master thesis","","","","","","","","2015-08-31","Technology, Policy and Management","Energy & Industry","","MSc EPA","",""
"uuid:4ea57416-a26f-4fc4-ab06-dd54cd02d069","http://resolver.tudelft.nl/uuid:4ea57416-a26f-4fc4-ab06-dd54cd02d069","LegBank: Strategic view on orthopedic care at BoP in Colombia","Herrera Manzano, S.C.","Tassoul, M. (mentor); De Jonge, F. (mentor)","2015","A feasible, desirable, viable and impactful business strategy with potential to bring an innovative and context-fitted value proposition (Majicast) closer to the lives of low-income people with mobility disabling conditions at BoP in Colombia though a service outreach delivery infrastructure. With this approach, a non-profit organization based in The Netherlands is given the opportunity to dabble in two complementary business alternatives throughout the implementation, selection and replication of the most reasonable business model for the long run in Colombia.","business strategy; Base-of-the-Pyramid; BoP; Colombia; healthcare","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product Innovation Management","","Management & Organization","",""
"uuid:015312bf-905c-439a-a511-8b6f721888a5","http://resolver.tudelft.nl/uuid:015312bf-905c-439a-a511-8b6f721888a5","Orchestrating Mixed-Criticality Melody: Reconciling Energy with Safety for Mixed-Criticality Embedded Real-Time Systems","Narayana, S.","Venkatesha Prasad, R. (mentor); Thiele, L. (mentor)","2015","Embedded systems are getting into various domains of our daily life as well as in many of the highly sophisticated large systems, such as air planes, military tanks, rockets, satellites. These large systems consist of many modules which are executing umpteen number of tasks semi-independently. However, not all tasks have the same levels of priority and/or criticality. One way is to design individual systems with dedicated processors to avoid the dependency as proposed by the industry. However, mixed-criticality notion helps to enhance system performance, and reduce system cost, size, and weight. The idea is to integrate functionalities of different safety criticality levels into a common computing platform. Further, the energy consumption of these systems should also be taken into account. While there are many algorithms under the broad umbrella of scheduling - preemptive, non-preemptive, etc., -- solutions that jointly minimizes both static and dynamic energy consumption in mixed-criticality systems on multi-cores under partitioned scheduling are, hitherto, not addressed in depth. To reconcile the conflicting requirements of safety and energy: (i) we formulate a general energy minimization problem; (ii) we provide an analytical optimal solution on unicore systems and a corresponding low-complexity heuristic and (iii) we provide energy-aware mapping techniques based on our unicore solutions on multi-cores. Effectiveness in energy reduction is demonstrated for our solutions through extensive simulations with synthetic task sets.","mixed-criticality; criticality; energy minimization; multi-core","en","master thesis","","","","","","","","2016-08-28","Electrical Engineering, Mathematics and Computer Science","Embedded Software","","MSc. Embedded Systems","",""
"uuid:4c6b4a94-4f15-4e67-8c30-eb8156aab406","http://resolver.tudelft.nl/uuid:4c6b4a94-4f15-4e67-8c30-eb8156aab406","Transportation of Cable Suspended Load using Unmanned Aerial Vehicles: A Real-time Model Predictive Control approach","Jain, R.P.K.","Keviczky, T. (mentor)","2015","Unmanned Aerial Vehicles (UAV) have received an increasing amount of attention recently with many applications being actively investigated across the globe, and several related open research questions being actively pursued. Possible applications include search and rescue, disaster relief, environmental monitoring and surveillance, transportation, and construction. Transportation of cable suspended payloads using Unmanned Aerial Vehicles is one such application which is the topic of this research. Autonomous transportation of objects using UAV can contribute to the safe and reliable supply of food and medicine in remote or disaster-affected areas and even in commercial delivery of goods. The state-of-the-art approaches towards the slung load transportation either develop non-linear feedback control laws to stabilize the system to a predefined trajectory or employ open loop off-line trajectory planning schemes to generate optimal control inputs to the system. Most of these techniques often rely on availability of an accurate model of the system backed up with simulation results. Very few results exist which target experimental validation of the proposed method. Based on the findings of the previously conducted literature survey, it appears that the application of closed loop on-line trajectory generation and control schemes to transport a slung payload in swing free manner remains unanswered. The work in this thesis sets off to answer the research questions in this direction and address the issues that come along with experimental validation. Model Predictive Control (MPC) is a promising framework, which provides the means to tackle both the trajectory generation problem and the feedback control problem in an unified manner. As a result, it forms the most important component of this thesis. Specific research problem that is addressed in this thesis is to transport a cable suspended load using quadrotor from one point to another, while minimizing the swing through the use of Linear Time Invariant MPC techniques. A non-linear dynamic model for the quadrotor-slung load system is obtained and the structure within the system dynamics is exploited to decide the control strategy. Two different MPC formulations viz. MPC with integral action and MPC with delta-u formulation are simulated and compared to Linear Quadratic control with integral action which acts as a benchmark controller. Backed with simulation results, it is shown through experimental validation that it is possible to control the swing of cable suspended load using linear control techniques. MPC being an computationally expensive task, state-of-the-art fast optimization solvers such as FORCES PRO is used to achieve on-line implementation of MPC for the quadrotor-slung load system. To this end, a new software framework for implementation of MPC is developed which establishes a wireless link with the quadrotor resulting in a real-time networked control loop.","quadrotor; model predictive control; paparazzi; MAV; robotics","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Delft Center for Systems and Control","","Systems and Control","",""
"uuid:fdb6272f-5d16-4f49-b356-76307cd78e20","http://resolver.tudelft.nl/uuid:fdb6272f-5d16-4f49-b356-76307cd78e20","Effects of Li4Ti5O12 coating on the performance of LiNi0.5Mn1.5O4 cathode in Li-ion batteries","Pan, Q.","Kelder, E. (mentor); Fredon, R. (mentor)","2015","Lithium ion batteries have attracted a lot of attentions due to the high power density and specific density that can potentially meet the requirements of new applications in the future. In recent years, one of the most promising cathode layer applied in lithium-ion batteries is called spinel LiNi0.5Mn1.5O4 (LNMO), which has advantages of high electrochemical performance and low cost. However, the main disadvantage is the capacity fading during cycle test. Surface coating is recognized as an effective approach to reduce those negative influences. Theoretically, lithium titanate (Li4Ti5O12, LTO), which has a similar lattice parameter with LNMO, could be a good choice. In this project, spinel LiNi0.5Mn1.5O4 layer was made on various substrate materials. Then, Li4Ti5O12 is applied as an epitaxial coating on LiNi0.5Mn1.5O4 layer. Both layers are made through electrostatic spray pyrolysis process. The samples with stainless steel substrate were made into coin cells, while the samples with aluminium substrate were made into Swagelok cells. XRD was used to identify the crystal structure. AFM and SEM were applied to observe the morphology of layers. In addition, the electrochemical properties information were obtained by charge-discharge cyclic test.","LiNi0.5Mn1.5O4; Li4Ti5O12 coating; electrostatic spray pyrolysis; spinel; electrochemical properties","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Materials Science & Engineering","","Material Science and Engineering","",""
"uuid:3ca9a74b-5a4c-4b1c-bcfe-7202a9bde9b6","http://resolver.tudelft.nl/uuid:3ca9a74b-5a4c-4b1c-bcfe-7202a9bde9b6","Horizontal Semicircular Canal Orientation and the 3-D Vestibulo-Ocular Reflex","Lauwerends, L.J.","Happee, R. (mentor)","2015","Goal. The three-dimensional vestibulo-ocular reflex (3-D VOR) is responsible for the maintenance of stable vision through generating compensatory eye movements in response to head movements. The main functional components of the 3-D VOR are the semicircular canals. The anatomy of the three canals is complicated, requiring the definition of several natural coordinate systems in order to assess the canals' functionality. Most notably, the horizontal canals form a significant angle (25°) with respect to the earth-horizontal (E-H) while the head is upright. The goal of this study was to determine the influence of head pitch orientation on the quality of the VOR, and thus to identify the 3-D VOR dependence on the canal anatomy and orientation. Methods. Eight healthy upright seated subjects underwent whole-body sinusoidal and transient stimulation delivered by a six degree of freedom (6-DOF) motion platform. Small-amplitude sinusoidal oscillation was delivered around the yaw axis and axes in the horizontal plane between roll and pitch at increments of 22.5°. Transients were delivered in yaw, roll and pitch and in the vertical canal planes. This sequence of stimuli was repeated for the subject with his/her head under three different initial positions: upright, pitched nose down 16°and 25°, aligning the horizontal canal prime direction and maximum response direction with the E-H, respectively. 3-D scleral search coils were used for the recording of eye movements. Results. For sinusoidal stimulation around axes in the horizontal plane, a decline in gain and an increase in misalignment were found for increasing downward head pitch, in the light as well as in darkness. All component gains had lower values in darkness than in light. For vertical axis rotation, this decrease in gain and increase in misalignment was also present, except for the torsion component which increased with both upward and downward (from upright) pitch. Transient stimulation yielded overall lower gains than sinusoidal stimulation. No significant differences between the different head pitch orientations were found for vertical axis stimulation. For transients around axes in the horizontal plane however, the horizontal component gain increased with increasing nose-down pitch, while overall the vertical component decreased. Conclusions. The incongruence between the mathematically modelled coordinate systems of the semicircular canals and the obtained results in terms of gain and misalignment, suggests the contribution of other mechanisms to the 3-D VOR. The gravity-induced otolith-mediated VOR is likely to have an additional effect with the head pitched. The inhibitory effect of the otolith-mediated gravity vector on the torsional eye position is a possible explanation for the reduction in gain for sinusoidal rotation around axes in the horizontal plane. The opposite is seen during transient stimulation, which could be attributed to the otolith organs' low-pass behaviour.","eye movements; vestibular system; vestibulo-ocular reflex; three-dimensional; motion platform; semicircular canals; otolith organs; rotation","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Biomechanical Engineering","","Specialization: Biomechatronics","",""
"uuid:38391497-885e-456e-b5a6-f3d9207533ca","http://resolver.tudelft.nl/uuid:38391497-885e-456e-b5a6-f3d9207533ca","Performance Assessment for Advanced Process Control","Thöne, C.M.","Baldi, S. (mentor)","2015","Model predictive control (MPC) is a control technique that is frequently used in the process industry. Two advantages of model predictive controllers is their ability to predict the impact of disturbances, and to easily account for constraints. However, a disadvantage of model predictive controllers is that they rely on mathematical models of the controlled processes. Changes in process conditions may cause the model to no longer accurately represent the real process, which in turn may result in a drop in performance. Detecting performance drops and taking subsequent action is thus highly desirable. This thesis aims at assessing current methods that detect and revert these performance drops due to model-plant mismatch. To this end, a benchmark distillation column model representing a typical industrial process was designed. For two different control configurations, models were identified using prediction-error identification, and model-predictive controllers were subsequently designed for reference tracking and rejection of disturbances. Performance of these model-predictive controllers has been compared, and results show that the so called double-ratio configuration is better at disturbance rejection, and shows more robust performance. Further, a performance index that tracks the average variance of the controlled output, computed over a time-range, was developed. A methodology is shown which can be used to compute the optimal time range, when the historic variance, a desired false alarm rate, and threshold is known. In the event a performance drop due to model-plant mismatch is detected, the plant should be re-identified in order to restore nominal performance. This can however be a costly proce- dure. The second part of this thesis therefore focuses on least-costly identification methods. Recently, a new experiment design method was developed that is aimed at minimizing the length of an identification experiment, while constraints on the minimal accuracy of the to-be- identified model and the maximum values of the in- and output signals are honoured Analysis of this new minimal-time algorithm shows that the identification experiment time can be reduced by up to 56 % when compared with conventional least-costly identification methods. Further, Monte-Carlo simulations have been performed for different initializations and it has been shown that the minimal-time algorithm manages to find its global minimum for various initial conditions, although the probability to obtain it from an arbitrary simulation is different from system to system. The last part of the thesis discusses the relevance and applicability of performance monitoring and re-identification in practice. While literature assumes tracking the variance of the controlled output is a good indicator, in reality wrong limits on the control inputs, a sub-optimal economic function in the model-predictive controller, and up-time of the model-predictive controllers are more important factors that determine the economic benefits gained from a model predictive control system.","model predictive control; performance monitoring; process control; Least costly identification","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","DCSC","","Systems & Control","",""
"uuid:1ff77220-3f3c-4aeb-b93e-758ddddc00dc","http://resolver.tudelft.nl/uuid:1ff77220-3f3c-4aeb-b93e-758ddddc00dc","Business Model Innovation in circular product design: A case study in kitchen appliances","Schuit, C.S.C.","Bakker, C.A. (mentor); Roscam Abbing, E. (mentor); Smit, E. (mentor)","2015","Without the guarantee for product return or company ownership, circular alternatives can have a higher perceived financial risk than linear alternatives. Therefore, it is essential to start at the business model to create preconditions for a circular system and develop propositions consumers are willing to pay for. This requires a shift in thinking, in which products are merely seen as tools to accomplish a desired outcome. This thesis explores how business model generation can steer circular system and product design. Based on a literature study, the thesis proposes a revised business model canvas which can be used as a tool in circular economy projects. The case study focusses on kitchen appliances for working mothers. Based on three different business models, food processor redesigns are developed to explore how business models steer system and product design.","circular economy; circular design; business model innovation; business model","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Master of Science Integrated Product Design","",""
"uuid:ca7302f2-22ca-4073-a360-acd1f1bd0751","http://resolver.tudelft.nl/uuid:ca7302f2-22ca-4073-a360-acd1f1bd0751","The challenges in scheduling multiple collaborative design projects in the front-end phases","Ma, X.","Vrancken, J.L.M. (mentor); Verbraeck, A. (mentor); Leijten, M. (mentor)","2015","In large engineering organizations, multiple projects run in parallel, and their progress is controlled through scheduling. Schedulers often go through the cycles of scheduling: making schedules, executing them, monitoring the status, receiving changes in decisions, and updating schedules again. The schedules easily mismatch with how the projects actually go, and generating a new version takes much efforts. Disagreement between stakeholders sometimes arises. Some faulty decisions are made in a hasty start of projects. This thesis investigates how to boost the efficiency of scheduling. To boost the efficiency of scheduling a group of projects, the factors that constrain the scheduling efficiency need to be investigated. First, various stakeholders are interviewed about the efficiency issues. Second, the main ideas obtained in interviews are tested through a survey. The survey ranked the impact of various factors and measured the time usage on different activities. Third, project tasks that have been finished are analyzed in terms of the cause of delay. The causal relations between issues are built through analyzing the data obtained. The causal relations explain how the causes lead to the problems in project scheduling. The first category of causes lie in the uncertainty in the inputs leads to the uncertainty in the schedules. The uncertain inputs are listed in the following paragraphs. First, the work to be done is uncertain. At the early stages of a project, whether the project will remain selected is uncertain. Not all ideas for projects are able to be supported due to limited budget. Therefore, different project proposals need to be compared in terms of costs and other figures. In the selection procedure, some projects get approved while some are stalled. At the beginning of each project, it is not sure how much the project will cost. The project cost is influenced by the project’s scope, design, and outsourcing strategy, which is not static. The ambiguity in a project’s cost affect whether the project is better than other projects. The client may change the decision in project selection, in scoping and in design. Such changes affect the workload, and the workload affects how long the project work takes. Second, the order in which the projects are processed is seldom stable and clear. Within a large company, the engineering department often receives multiple projects from multiple internal clients. Limited engineering resources lead to clients competing for resource usage. Lack of coordination between clients often leads to changing priority ranking. Even for the same client, there are competitions between new projects and existing projects. Third, the resource supply could also vary. When the demand of resources exceeds the amount of engineers in the organization, the wished deadlines for projects specified by clients become infeasible if internal resources are only used. The engineering party needs to negotiate with clients whether to postpone some projects, or outsource some projects. Clients are usually reluctant to agree to outsourcing because the outsourced work ought to be paid from the fixed budget, according to the financial policy of the company. Such disagreement leads to uncertainty in resource supply. Besides, sometimes emergent tasks appear which occupy the hands of the task performers who were reserved by projects. Fourth, coordination between different tasks is challenging. Engineering projects usually involve cooperation between multiple disciplines, professions, or business functions, since the artifact built through a project consists of various parts delivered through different tasks. Each task is undertaken by different task performers. Different parts of a project’s deliverable have to be compatible, implying the discussion in the interface. Chronologically, the tasks in a project need to be carried out sequentially, and thus one slip in some task may hinder the progress of succeeding tasks. Delays often arise which make the baseline schedule unfeasible. Even when tasks’ deadline is extended, delays remain. Therefore, the actual status of projects varies with changes in such inputs. Dividing such a varying schedule into fine-grained time intervals would generate more uncertain items. The increased amount of uncertain items soon overwhelm the attention of managers. The second group of causes responsible for low efficiency in scheduling is that, schedulers tend to expect the progress on every time interval matches the actual status. Such a pursuit of perfect match leads to unexpected side effects. Each task owner protects his/her commitment date by placing buffers. Later such buffers prove to be used on other tasks. Task performers switch attention between multiple tasks, and postpone the start or progress of tasks with later deadlines. At the last moment for a task, things easily go wrong, leading to delays. Third, the decisions that influence project schedules are not easily made and tend to change: the relevant input information is scattered; misinterpretation of technical design diagram sometimes arise; different stakeholders prefer different design options; etc. Based on the understanding about the causes that constrain scheduling efficiency, measures for coping with such challenges are devised. The solutions include: first, the decisions whose execution depend on low chance preconditions, should be removed from schedules to make the schedule more robust. To prevent optimism bias in setting deadlines, multiple estimation methods should be adopted. Second, some insignificant discrepancies between the baseline schedule and the actual progress, could be tolerated. Tasks had better be coordinated through a relay-race style, letting early completions in some tasks offset delays in other tasks. Third, multi-tasking should be reduced to make schedulers figure out the dedicated progress speed when task performers focus. It is better to promote project progress rather than making task performers busy. Fourth, the updates in information needed in scheduling should be pushed into a shared database as soon as updates arise. The inconsistencies between information should be eliminated. Fifth, rules for resolving disputes should be developed to avoid deadlock or indecision in making some joint decisions. The proposed solution is tested conceptually with the problems aforementioned. The relevant empirical studies which have adopted similar solutions in tackling similar problems are mentioned, serving as evidence for the effectiveness of the solution in this thesis. The implementation plan is discussed, which attempts to provide a step-by-step roadmap towards the changes.","scheduling; project portfolio; planning; collaborative design/engineering; front-end phases; Stage-Gate model","en","master thesis","","","","","","","","2015-08-15","Technology, Policy and Management","Management","","Management of Technology","",""
"uuid:22336fab-35e6-4bce-8097-42f10f785dd9","http://resolver.tudelft.nl/uuid:22336fab-35e6-4bce-8097-42f10f785dd9","Between mobility and monuments: A search for possible synergy between mobility and industrial heritage","Delemarre, S.R.B.","Van Arem, B. (mentor); Baggen, J.H. (mentor); Van Nes, R. (mentor); Stoop, J.A.A.M. (mentor)","2015","In the Netherlands there are many cities with an old, historical city centre, in which daily traffic leads to inconvenience for the residents and congestion. In these cities there may also be vacant industrial buildings, which one can assign as industrial heritage and accordingly wants to preserve. This thesis work search for possible synergy between the mobility problems in urban areas and industrial heritage.","Urban Consolidation Centre; heritage; Gorinchem; urban mobility problems","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Transport & Planning","","Transport, Infrastructure & Logistics","",""
"uuid:6104eb3c-0189-4ac2-ba3b-0a7956c9dc31","http://resolver.tudelft.nl/uuid:6104eb3c-0189-4ac2-ba3b-0a7956c9dc31","Analytical and Simulation Study of Sweep Efficiency in Gas-Injection EOR","Yu, G.","Rossen, W.R. (mentor)","2015","WAG (Water-Alternating-Gas injection) is a non-thermal EOR process, which was proposed to improve the volumetric sweep efficiency and consequently the oil recovery during a gas injection project. Though miscible gas injection gives fantastic displacement efficiency due to its miscibility with oil, it usually shows very poor volumetric sweep efficiency due to the high mobility of gas phase. Alternate injection of gas and water significantly reduces the gas relative mobility, and therefore leads to less gas fingering and/ or tonguing of gas. Aside from fingering and channeling, gravity segregation is another major effect that leads to the deterioration of sweep efficiency in gas-injection EOR processes. After the injected gas and water travels a certain distance in the reservoir, they completely segregate from each other under gravitational forces. Gas goes to the top of reservoir forming an override zone, and water goes to the bottom forming an under-ride zone. In Chapter one, fractional-flow theory is applied to provide insight into the advantages of HWAG. The fractional-flow method describes the flooding process in 1-D homogeneous reservoirs, which can be applied to a wide range of EOR processes. The method is accurate, when its assumptions are satisfied, in reflecting the saturation, front position and relative mobility of the agents injected, from which an optimal injection strategies can be determined. The main focus of Chapter two is the simulation study of gravity segregation in non-horizontal reservoirs. First, extensive simulations are done to examine the accuracy of Namani’s model for the segregation distance in dipping reservoirs. Second, it is equally important to understand all the dynamic processes during the process of gravity segregation.","Fractional-flow method; Miscible Hot WAG; Numerical Simulation; Segregation Distance; Non-horizontal Reservoir","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Petroleum Engineering","",""
"uuid:d67ed37b-95ee-48fd-a9d9-8ea5e0988bf6","http://resolver.tudelft.nl/uuid:d67ed37b-95ee-48fd-a9d9-8ea5e0988bf6","Optimisation of Method for Snow Avalanche Detection in SAR images: Supporting the development of snow avalanche mapping and monitoring of Svalbard","Wesselink, D.S.","Klees, R. (mentor); Lindenbergh, R.C. (mentor); Malnes, E. (mentor)","2015","Avalanches form a threat to people travelling in mountainous regions as well as for infrastructure and buildings. They cause around 250 fatalities annually worldwide. To limit the number of future fatalities, forecasting services are interested in knowledge on avalanche activity to verify their warning system. They rely on information about the frequency, location and extent of debris fields, as provided by avalanche experts. As avalanche terrain is mostly remote and inaccessible, it can be dangerous or even impossible to obtain necessary field information. This information is especially crucial to gain during strong winds and blowing snow when an increased avalanche danger is present. By applying Synthetic Aperture Radar (SAR), large areas can be monitored at once with both high spatial resolution and high acquisition frequency. It also has the advantage of being daylight- and weather independent. The area of interest, Nordenskiold Land on Svalbard, experiences over four months of polar darkness per year. Consequently, the most applicable technique for avalanche monitoring is SAR. Avalanche debris has an increased surface roughness compared to the surrounding unperturbed snow causing a higher backscatter signal. Therefore, the debris fields appear bright in SAR images. The main goal of this research project is to optimise avalanche detection in SAR images by exploring the option of automatic detection of debris fields. Hence, we present a method to automatically detect avalanche debris fields in SAR images. It is designed and tested on both RADARSAT-2 Ultra Fine (UF) mode and Sentinel-1A Extra Wide swath (EW) mode images. Sentinel-1A has the advantage of obtaining images twice per day over Svalbard and is made available for free. Due to the high costs to acquire RADARSAT-2 data over Svalbard, these images have a low acquisition frequency. The UF mode images are geocoded to a pixel spacing of 3m compared to 40m for the EW mode images. Both modes detect the location of debris fields, but the extent is only clearly distinguishable in the UF mode images due to the fine resolution. In case of automatic detection, the backscatter coefficient of the debris fields is compared to the backscatter coefficient from a reference image. This reference image should be obtained during dry snow conditions or during a snow-free summer. The difference in backscatter coefficient between the two images is determined by subtracting the reference image from the avalanche image. By applying a threshold on the difference image debris fields are successfully located. However, to eliminate areas above the threshold value but not considered as avalanche, a filter is applied. Two filters are tested; a median filter and a Remove Small Objects (RSO) filter. For the RADARSAT-2 UF mode images the best result is obtained by using a median filter and a threshold value of 1.9dB, while for the Sentinel-1A EW mode images a RSO filter in combination with a threshold value of 3.4dB resulted in the optimum detection. None of the designed automatic detection methods resulted in a 100% probability of detection and zero false alarms, but they do confirm that automatic detection of avalanches in these SAR images is possible. They also show that the automatic detection method is depended on the characteristics of the input data. By combining a regular detection of the whole of Svalbard by the coarse Sentinel-1A EW mode images and a more specified forecasting using the fine RADARSAT-2 UF mode images avalanche maps can be created indicating both location and extent of debris fields. These maps can be of great value for avalanche warning services, although further research is necessary before automatically generated avalanche maps can be included in daily operations.","SAR; avalanche detection; Synthetic Aperture Radar; Sentinel-1A; RADARSAT-2; snow avalanche","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience and Remote Sensing","","","",""
"uuid:6d77615d-925e-4a7e-88d7-818552522bda","http://resolver.tudelft.nl/uuid:6d77615d-925e-4a7e-88d7-818552522bda","Design of a highly efficient charger for Nickel-Iron batteries","Ananda, A.K.","Popovic-Gerber, J. (mentor)","2015","Obtaining good performance from stand-alone PV systems requires successful integration of batteries that are reliable, effective, long lasting, environmental-friendly and affordable as it is crucial to deal with variable solar illumination throughout the year. Nickel Iron battery technology (Ni-Fe) is a perfect fit for the solar-powered households as it is satisfies all the requirements. Charge controllers need to be efficiently designed for Ni-Fe batteries for protection from overcharge/discharge. This thesis concentrates on selecting the best topology from B2R converters from the patent 550 of ESA to be applied for designing the charge controller for Ni-Fe batteries. An analysis is carried out to determine the advantage of B2R converters in the patent over conventional buck-boost topologies like SEPIC or Cuk and evaluate their utility for charge control applications. The focal point of topological selection will be the evaluation of topologies on the basis of efficiency and complexity for realistic adaptation into a charge controller. After defining the load power parameters, the operation of the topologies in two different modes of conduction (BCM & CCM) is investigated and an analytical model is developed for losses. Significant factors that play a role in determining the efficiency for varying source parameters (input voltage) are scrutinized. The relative merits of using BCM/CCM for design are inspected by carrying out simulations for loss calculations using the analytical model with data-sheet parameters from realistic components for their suitability for the application. Component selection is done by keeping in mind the prevalent technologies in the market that are cost effective and the procedure followed in the design of magnetics for the topologies in different modes of conduction and its impact on efficiency is discussed and an assessment is carried out on the performance of the components with variations in input voltage for the same power level. The proposed analytical models for switching losses in MOSFETs and overall losses topologies are validated by carrying out experiments on the prototypes of two best topologies in both conduction modes. The results critique the accuracy of the analytical model in determining the actual efficiency of the topologies, the margin of deviation by means of comparison with the experimental results and concludes with suggestions for selecting the most efficient topology and recommends a mode of conduction for best results.","Boundary Conduction Mode; Continuous Conduction Mode; Battery Charger; Topology","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Electrical Power Engineering","","DC Systems, Energy Conversion and Storage","",""
"uuid:002ee5ed-f355-425c-b871-97c1a055349b","http://resolver.tudelft.nl/uuid:002ee5ed-f355-425c-b871-97c1a055349b","A Scaling-upMethod for Assessing the Impacts of ITS on Traffic Efficiency","Huang, X.","Hoogendoorn, S.P. (mentor); Pel, A.J. (mentor); van Noort, M. (mentor); Annema, J.A. (mentor)","2015","Human beings today have to face a series of problems brought by transport development — severe urban congestion, increasing number of injuries and fatalities as well as global warming caused by excessive emissions. Intelligent Transport Systems (ITS), as effective tools to solve these problems, thus have drawn much attention. In the future, it is expected that more and more ITS would be developed and applied in real practice. Before adopting ITS measures, it is necessary for policy makers to know the impacts of the ITS measure on on a large scale (e.g. national/European level). In many cases, the impacts of ITS are evaluated on a much smaller scale, for example from a microscopic traf- fic simulation or a field experiment. These effects need to be scaled up to the larger scale. There are two known scaling-up methods. The modelling method can accurately represent the large scale scenario, but requires considerable effort and a large amount of data which may not be available. Furthermore, it requires a macroscopic model of the ITS, which may be a challenge to derive. The statistical method describes the local scenarios via situational variables (like road types, vehicle types and traffic situations), classifies the local scenar- ios into categories and calculates the impacts on large scale as the weighted average of the local impacts. This method is easier and faster than the modelling method. However, the statistical method is only applicable for cases which only consider categorical situational variables, because the classification of the local scenarios into categories is not feasible when numerical situational variables are used. As a result, the statistical method is only suitable for ITS whose impacts are on the microscopic mechanisms (e.g speed and headway) and thus mainly affected by categorical situational variables (e.g road type and vehicle type). A scaling-up method to assess the impacts of ITS on traffic efficiency which is generally suitable for all ITS is still missing. To start filling this gap, this study develops a new scaling-up method for ITS that have direct network-wide influences to assess their large-scale impacts on traffic efficiency. The framework of the new scaling-up method is shown in Figure 2.2 and the graphical and mathematical interpretations are presented in Figure 2.3 and Figure 2.4. In brief, the new scaling-up method firstly chooses the suitable indicator of the impacts and situational vari- ables, then collects needed data and builds deterministic relationships between the indi- cator and the numerical situational variables, at last uses scaling sideways to calculate all local impacts and aggregates the local impacts to large scale. From the theoretical perspec- tive, the designed method is considered to be able to evaluate the impacts of ITS measures with direct network-wide influence on traffic efficiency in a large-scale scenario. To provide an evidence of the quality of the new scaling-up method, this study applies it to a specific ITS measure, that is the on-trip dynamic navigation system. Although the final large-scale impacts of the on-trip dynamic navigation system is not calculated due to the limitation of data source, it is proved that the new method is able to accurately assessthe large-scale impacts of the on-trip dynamic navigation system with enough available data. Other findings from the case study are also valuable. For example, the choice of the indicator and the situational variables, and the built deterministic relationship can be directly adopted in other projects that study the impacts of the on-trip dynamic navigation system, which indicates the practical contribution of this study. From a methodological perspective, the new scaling-up method is a great improvement of the current scaling-up approaches. The new scaling-up method expands the applica- tion area of scaling-up methods to ITS that have network-wide influences. Compared to the current methods, the new scaling-up method also improves the accuracy of scaling up and leads to more reliable assessments. Apart from the merits, there are also some dis- advantages of the new scaling-up method, such as the possibility of more time cost and data needed, as well as the possible difficulty to explain the deterministic relationships in a sensible way. The new scaling-up method is regarded to be with significant political value. The out- puts can provide useful information to support policy making. On one hand, according to the political economy model designed by Beuthe, the impacts of ITS play an important role in making policy decisions. The impacts of ITS can directly reflect the perceived effectiveness and the perceived distribution of benefits and costs. On the other hand, based on the outputs of the new scaling-up method, there are also other policy advices that could be made. For instance, the built deterministic relationship(s) can suggest the to-be-set value of the related parameters when adopting a certain ITS measure. For future researches, the attention could be focusing on applying the new method to more ITS measures and investigating the applicability of the new method on assessing the impacts on safety and environment. Specifically regarding the study of the on-trip dynamic navigation system, if the needed data is available, it would be beneficial to conduct a com- plete assessment of the large-scale impacts in a specific scenario in the future. In addition, the influences of other situational variables besides the considered situational variables could also be taken into account. Furthermore, a more specific classification of network structure is expected in future researches.","scaling-up method; impacts of ITS; ITS evaluation","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Transport & Planning","","Transport, Infrastructure and Logistics","",""
"uuid:bfe39799-8487-4be3-9642-2ee08de29c06","http://resolver.tudelft.nl/uuid:bfe39799-8487-4be3-9642-2ee08de29c06","Magnetic and Induced Electric Field Management for Underground cable Installation: Calculations, analysis and Design Optimization","Muralidhar, S.H.","Rodrigo Mor, A. (mentor); Meijer, S. (mentor)","2015","The international growing concern for the human exposure to magnetic fields generated by electric power lines has unavoidably led to imposing legal limits. The world health organization sets limits for exposure to magnetic and induced electric fields. Basically, the world health organization references to the guidelines provided by the International Commission on Non-Ionizing Radiation Protection (ICNIRP). For 50 Hz exposure, this guideline is 1000 ?T for occupational workers and 200 ?T for the general public. In several countries however, stricter limits are set, down to 0.3 ?T. However, it is stressed that the calculation methods and starting points also differ significantly and these values can therefore not be compared one-to-one. In this study the magnetic and induced electric fields of different cable installation methods like directly burial, underground tunnels were calculated and evaluated against the ICNIRP guidelines. Different operating conditions such as normal operation at 1450 A, emergency operation at 1760 A, 80 kA short circuit currents and operation during maintenance were assessed. Based on the study, it could be concluded that all situations were below the ICNIRP values for 50 Hz exposure, except for the short circuit conditions. However, these are only during a very short duration of maximal 1 second and their allowance needs to be discussed with the relevant authorities. Moreover, voltage might be induced in other metallic structures (due to magnetic induction) which might lead to unsafe situations, like where public or animals come in contact to energized metal object and experience shocks. The ultimate outcome of this thesis study is to answer the part of questions arising for health concern due to exposure of magnetic fields, as this study limits to underground installation (direct burial and tunnels).","Magnetic Fields; ICNIRP; Safety","en","master thesis","","","","","","","","2019-07-27","Electrical Engineering, Mathematics and Computer Science","Electrical Power Engineering","","Master","",""
"uuid:a080360d-9eeb-4b0d-9613-0c736f8769e5","http://resolver.tudelft.nl/uuid:a080360d-9eeb-4b0d-9613-0c736f8769e5","Numerical Pricing of Bermudan Options with Shannon Wavelet Expansions","Maree, S.C.","Oosterlee, C.W. (mentor); Ortiz-Gracia, L. (mentor)","2015","This thesis is about pricing Bermudan options with the SWIFT method (Shannon Wavelets Inverse Fourier Technique). We reformulate the SWIFT pricing formula for European options to improve robustness, which allows us to heuristically select - and test the goodness - of all of the parameters a priori. Furthermore, we propose a simplified version of the SWIFT method, based on the Whittaker-Shannon sampling theory, which is an easy to implement method that posses algebraic convergence in the pricing of European and Bermudan options. The main contribution of this thesis is a new pricing method for Bermudan options by the SWIFT method, for exponential Levy processes using the Fast Fourier Transform. We compare the results of the SWIFT method to those of the COS method.","option pricing; Bermudan options; exponential levy processes; wavelet series approximations; Shannon wavelets; Shannon-Whittaker sampling theory; Fourier transform inversion","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Delft Institute of Applied Mathematics","","","",""
"uuid:0d7092b6-682c-47e0-9d3f-7dd0792df470","http://resolver.tudelft.nl/uuid:0d7092b6-682c-47e0-9d3f-7dd0792df470","Modeling the single seed oxygen consumption of germinating seeds","Wiegman, L.","Budko, N. (mentor)","2015","The rate of oxygen consumption by germinating seeds is considered to be one of the promising parameters for monitoring the seed status and a candidate for predicting germination and seed vigor. Nowadays, the single seed oxygen consumption patterns can be measured on a big scale and at a detailed time resolution using a Q2 machine. However, interpretation of the data in terms of functioning of internal oxygen transport and overall seed properties is still hard, due to the lack of knowledge on and the complexity of these properties and processes. Modeling may be of great help in understanding the relation between germination and the oxygen consumption pattern of a seed. In this thesis a model for the single seed oxygen consumption inside a closed test tube is proposed, relating the measured oxygen concentration to the size of the active mitochondrial population. The analytical solution of this model is used for calibration of the experimental data and all calibrated results are analyzed. From this analysis an attempt is made to distinguish between germinating and non germinating seeds in order to determine which seed properties cause slow/fast germination. Based on this model a method introducing the seed and test tube volume is proposed in order to predict the observations when the sizes of these volumes change.","seeds","en","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Numerical Analysis","","","",""
"uuid:99a9fdaf-8bb3-445b-ac25-8b4711ac9366","http://resolver.tudelft.nl/uuid:99a9fdaf-8bb3-445b-ac25-8b4711ac9366","Synchronization in power-grid networks","Ringlever, T.D.K.","Dubbeldam, J.L.A. (mentor)","2015","This thesis discusses two different models regarding the synchronization in power-grid networks. These models are then compared to each other with respect to a nine-bus test system.","","en","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Mathematical Physics","","","",""
"uuid:e971c1e4-4e10-4530-9c50-239ea41fbd85","http://resolver.tudelft.nl/uuid:e971c1e4-4e10-4530-9c50-239ea41fbd85","Development of a reserve reconciliation tool for the Hengelo Brine Field","Schootstra, J.","Buxton, M.W.N. (mentor)","2015","Reserve reconciliation is widely applied in the petroleum and mining industry. By updating the reserves throughout the operation, the remaining reserves can be better quantified and the extraction scheduling optimized. The goal of this study is to develop a reserve reconciliation tool for the Hengelo Brine Field, operated by AkzoNobel Industrial Chemicals B.V. in the Netherlands, in order to improve the long-term development and production planning for the field. The study follows the principles of the LeanSixSigma methodology for problem solving in five phases: define, measure, analyze, improve and control (DMAIC cycle). The study consist of 4 parts. The first part provides background information on the production process, the Hengelo Leaching Technique and the geological situation. The second part measures and analyzes the mass balances in the field, magnitude of fluid losses, Solling Fm., sonar measurements and insoluble material. The report continues with the reserve reconciliation in which an accounting tool is implemented on an area with 23 caverns. In the fourth part the discussion, conclusion and recommendations are discussed. The aim of this study was to determine if it is feasible to develop a predictive methodology able to accurately quantify the properly and if this methodology can be utilized in the long-term planning of the production and development of the Hengelo Brine Field. The extraction process is affected by geological and mining related uncertainties. The most important uncertainties are:  Fluid losses from caverns  Cavern shape & geometry  Insoluble material & bulking factor The reserves can be calculated more precisely using the new data. A reconciliation tool was developed and validated on 23 caverns. The production controlled handling of the caverns results in a loss of reserves. This loss is caused by the outflow of fluids from a cavern. The average recovery factor for the first leaching phase is estimated to be 75%, versus the 80% which is used in the current reserve estimates. However, due to the conservative initial estimate of the reserves based on the insoluble content, the caverns still show a small surplus. The implementation of this tool for the entire field and incrementally improving it will assist future long term planning of the Hengelo Brine Field.","solution mining; mining; AkzoNobel; salt; mass balance; reserve reconciliation; sonar measurement; Solling Fm.","en","master thesis","","","","","","","","2017-07-31","Civil Engineering and Geosciences","Geoscience & Engineering","","Petroleum- and Resource Engineering","",""
"uuid:6d406753-deaf-47ac-bb4b-db3fbdfb6206","http://resolver.tudelft.nl/uuid:6d406753-deaf-47ac-bb4b-db3fbdfb6206","Numerical stability for velocity-based 2-phase formulation for geotechnical dynamic analysis","Mieremet, M.M.J.","Vuik, C. (mentor); Beuth, L.I. (mentor)","2015","In the field of geotechnical engineering, the study of numerous processes such as pile installation requires to model large deformation of soil. Soil is an assembly of solid particles whose pore volume is filled with water or air. Its deformation mainly depends on the highly non-linear stress-strain behaviour of the soil skeleton. In case of the loading of saturated soil, its deformation is commonly also governed by the gradual generation and dissipation of excess pore pressures. A 2-phase formulation is often necessary to take into account these processes involving the solid and water phase. The finite element method is nowadays a popular tool for the study of 2-phase problems. However, mesh distortion might occur when considering large deformation problems. The material point method overcomes this problem by discretizing a solid with material points that flow through a fixed finite element mesh. In the MPM code developed by Deltares and partners, the Euler-Cromer scheme is used for time integration. Owing to its semi-implicit nature, the method requires a stability criterion; i.e., the time step size must be bounded by some critical value. The available Courant-Friedrichs-Lewy condition for undrained wave propagation appears to be insufficient. The criterion is initially improved by a permeability-dependent term that is obtained from a simplified formulation during a preliminary study, but it still does not render a reliable criterion. During the final study, the coupled equations of the velocity-based 2-phase formulation are analyzed. By means of the matrix method, the first sufficient stability criterion is obtained. It is presented in this master thesis defense.","Numerical Stability; Geotechnical Engineering; Finite Element Method; Material Point Method","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","Numerical Analysis","",""
"uuid:f2099f40-b96d-4948-8aa4-5840a127065e","http://resolver.tudelft.nl/uuid:f2099f40-b96d-4948-8aa4-5840a127065e","SamenDoen: A Menzis-initiated platform that helps young seniors of the age 55-65 years old to stay or become more socially active","Elferink, H.","Ozcan Vieira, E. (mentor); Visch, V.T. (mentor)","2015","SamenDoen is a platform designed for young seniors to expand their social network through joining in local activities with others. The platform facilitates organising activities in six different categories. When registered to SamenDoen a user can sign up and join activities in their area. The activities will be organised by both Menzis and by users. The Ontdek page shows all activities offered in the area. If a user has a great idea, but wishes not to organise it themselves, they can enter the suggestion in the ideabox. Users can vote for ideas they like, until a user decides to organise it. If there is no user that picks up the activity idea, but many people are interested, Menzis can choose to organise that activity. By joining activities, the users will make contact with new people, which results in widening of the network and therefor softening the sudden decrease of the social network when retiring. With an expanded social network when retiring, the young seniors will be better equipped to deal with the new life phase they will enter, which includes having a lot of free time on their hands.","social design; young seniors; platform; loneliness prevention; social health","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","","",""
"uuid:be16ccce-04cb-45ba-8e0b-c033c66c148f","http://resolver.tudelft.nl/uuid:be16ccce-04cb-45ba-8e0b-c033c66c148f","Design and evaluation of a Trust-tool to arrive at unrestricted replenishment planning in a VMI-environment","Degen, M.J.M.","Tavasszy, L. (mentor); Kroesen, M. (mentor); Steenhuisen, B. (mentor)","2015","","benchmarking; rational trust building; VMI; Vendor Managed Inventory; integrated supply chain; collaborative trust","en","master thesis","","","","","","","","2016-08-24","Technology, Policy and Management","Transport and Logistics","","SEPAM","",""
"uuid:d5efa569-c6db-44c4-b5df-85b0963252f6","http://resolver.tudelft.nl/uuid:d5efa569-c6db-44c4-b5df-85b0963252f6","Towards a Swiss national Earthquake Risk model: Sensitivity and gap analysis","Schwarz, C.","Wiemer, S. (mentor); Danciu, L. (mentor)","2015","Switzerland is exposed to earthquakes and has a high vulnerability and high losses endangered. The available seismic risk models are not sufficient and therefore the development has to go towards a new Swiss national seismic risk model. The model developed is an end-to-end calculation from the initial hazard to the final loss. It contains a deterministic and a probabilistic part and is calculated with the fully open software OpenQuake by the GEM foundation. For the deterministic calculation a critical issue is identified in the spatial distribution of the exposure model. Furthermore the sensitivity of the model is tested by changing the various parameter like hazard input model, calculation parameters, vulnerability model or exposure model. It is discovered that the different parameters and models show effects from zero to several 1000s of percent change. The uncertainty level in the vulnerability model is identified as critical value of uncertainty. The input models show uncertainties in the same range. No parameter dominates the uncertainty estimation. The new obtained preliminary national seismic risk model is an improvement to the initially available model and it describes the uncertainty as well.","Earthquake; seismic risk model; Switzerland; OpenQuake; Sensitivity","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Applied Geophysics and Petrophysics","",""
"uuid:9bbcf030-af4b-42c8-a7e5-2157bde13706","http://resolver.tudelft.nl/uuid:9bbcf030-af4b-42c8-a7e5-2157bde13706","Development of a Parametric 3D Turbomachinery Blade Modeler","De Koning, R.C.W.","Pini, M. (mentor); Vitale, S. (mentor)","2015","Nowadays Organic Rankine Cycle (ORC) power systems are of paramount importance to exploit waste heat and renewable energy sources. Standard design rules and empirical models are mostly available for steam/gas turbines and can not be directly applied for ORC. Because of this, a redefinition of the design strategy is needed, starting from the turbine concept, passing through dedicated preliminary design optimization and eventually arriving at a complete new redefinition of the optimal blade profiles through advanced optimization methodologies. To fill the gap between (zero-dimensional) mean-line analysis and 3D fluid-dynamic analysis a Turbomachinery Blade Modeler (TBM) is required. The modeler not only gives direct control of the blade geometry but also provides valuable feedback of the design. This allows the user to construct a good initial design before refining it with more computationally expensive methods. The TBM is developed using the python API within the framework of the open source software FreeCAD. Furthermore, it is also tightly coupled to two mesh generators, an in-house one UMG (Unstructured Mesh Generator) and to the open source Salome. This link guarantees the quasi-automatic generation of high quality CFD meshes for any kind of blade design. The approach to construct a variety of turbomachinery blades is based partially on state-of- art parametrization techniques and uses fundamental design variables such as metal blade angles, chord length and the stagger angle. The geometry is purely build up with NURBS curves and surfaces which has the benefit that sharp edges are avoided and high smoothness of the profile shape is guaranteed. NURBS include control point position, weight and curve degree which allow a flexible control of the shape without introducing many variables, which is beneficial in optimization routines. The TBM allows for the design of any kind of blade: these include axial, centrifugal, centripetal, radial rotors/ impellers and mixed blades. Moreover, to aid the designer the flow passage area distribution can be visualized run time. The TBM has been already successfully tested for the design of a high loaded centrifugal rotor. Additionally, a complex twisted and flared axial compressor, the NASA Rotor 67 was reconstructed using the TBM. The small differences between the reference geometry and the reconstructed one were evaluated with 2D CFD simulations. Finally, a design of a radial-inflow turbine was reproduced and meshed for future analysis. The parametric 3D turbomachinery blade modeler has proven to be a very powerful tool for designing turbine and compressor stator/rotors. Moreover, after the consolidation of the algorithms and a direct coupling with the CFD solver SU2, the tool will be ready to be used as a turbomachinery optimization environment.","blade modeler; turbomachinery; axial; centrifugal; centripetal; radial; turbine; compressor; ORC; NASA Rotor 67; rotor; stator","en","master thesis","","","","","","","","","Aerospace Engineering","Flight Performance and Propulsion","","Flight Performance and Propulsion","",""
"uuid:aa6afabe-be70-45d5-810d-0ac1861bb8f9","http://resolver.tudelft.nl/uuid:aa6afabe-be70-45d5-810d-0ac1861bb8f9","A Multi-Actor Approach to Conflict and Conflict Management in Cross-Functional Collaborative New Product Development: Case Studies within a Technology Firm","Abdulhasain, F.","De Bruijn, H. (mentor); Van der Voort, H. (mentor); Lukosch, S. (mentor)","2015","The purpose of New Product Development (NPD) is addressing disequilibria in the market place through identification, development and deployment of suitable solutions as products, services or solutions. Teamwork, cross-functional collaboration, and conflict management in NPD are often described as leading factors in addressing such change and achieving market success of products. Especially cross-functional collaboration, defined as the involvement of multiple functions in a team, has been applied as an approach to higher efficiency in time and cost and customer value output by firms to counter competition. The NPD process is deemed to be a good location to implement organisational changes. Despite decades of research on collaboration in general and in NPD, the occurrence location of conflicts and conflict management in the collaborative process between the key NPD functions Marketing, Development, Procurement, and Operations have not been clearly defined in the context of product development in the electronics industry. This topic and scope is addressed by this research. Triggered by organisational changes within a large electronics firm, this exploratory research was set up to gain a better understanding of the collaboration dynamics, the role of conflict and its management in NPD. This research was planned and executed following a multi-method and multi-actor approach to determine the types and location of conflict in new product development. An initial literature study covering the topics of NPD, collaboration, conflict and conflict management was followed by empirical research through semi-structured interviews among members of NPD teams, project leaders, and higher management functions. Furthermore, workshop observations and reflective staff interviews were used to gather data on the NPD collaboration and decision making process, its dynamics and conflict within two separate NPD teams in two divisions of the research hosting firm. The research context was defined by the application of the Design for eXcellence (DfX) methodology in the context of both case studies. The empirical findings confirm the paradox of conflict. Depending on the type of conflict and the approach to manage it, conflict can be beneficial to NPD performance and relations. In this research, conflict of substantive nature is found to have a positive effect on NPD performance and relations between team members. Whilst moderate levels of substantive conflict have been found to allow for higher NPD performance. Low levels of conflict limit the questioning and challenging of ideas, solutions, and decisions, which is likely to lead to outcomes below the potential of the available knowledge and resources. High levels of substantive conflict also results in lower performance in time and relations due to the continuous questioning and challenging of ideas, solutions and decisions. Both extreme conditions tend not to stimulate sound progress and substance. Process conflict relates to unclear roles and responsibilities, as well as unclear procedures. In cases of substantive conflict, process conflict is likely to increase the level of conflict to an extent that lowers the positive performance effects of substantive conflict. Reaching this potential with the sensitivity towards conflict requires effective conflict management. This study has identified that substantive conflict through confrontation is perceived as positive in a collaborative atmosphere. This even applies under high workloads, while process conflict is perceived negatively and has been found to impact project performance in time and relations negatively. The main finding of this research is that escalation to higher management is chosen as a conflict management and resolution approach. The approach is chosen mainly under the conditions of process conflict and lower levels of informal interactions among project team members from different functions and between the project team and the management team.","","en","master thesis","","","","","","","","","Technology, Policy and Management","Section of Policy, Organisation, Law and Gaming","","Systems Engineering, Policy Analysis and Management","",""
"uuid:dcbf247b-1a33-4101-bb55-4231157a0fd4","http://resolver.tudelft.nl/uuid:dcbf247b-1a33-4101-bb55-4231157a0fd4","Understanding Uncertainty in the European Biodiesel Market: An Exploratory Modelling and Analysis Approach","Vita, P.","Stikkelman, R.M. (mentor); Kwakkel, J. (mentor); Van Beers, C.P. (mentor)","2015","Investigation of the factors and uncertainties affecting the European biodiesel market performed through Exploratory Modelling and Analysis. This includes the employment of the EMA Workbench software in order to run numerous computational experiments with a bespoke system dynamics model.","biodiesel; Europe; Exploratory Modelling and Analysis; transport; Future Technology Analysis; System Dynamics; bioenergy","en","master thesis","","","","","","","","","Technology, Policy and Management","Engineering Systems and Services","","Management of Technology","",""
"uuid:4bc461e6-3e90-4928-9a12-4dcebfbddb1c","http://resolver.tudelft.nl/uuid:4bc461e6-3e90-4928-9a12-4dcebfbddb1c","Suction bucket buckling: Buckling behaviour of suction buckets during installation in layered soils","Welschen, Y.","Kaminski, M.L. (mentor)","2015","","","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Offshore engineering","","","",""
"uuid:dcac6baf-1a15-4cf1-80b8-1d8ba5e50b95","http://resolver.tudelft.nl/uuid:dcac6baf-1a15-4cf1-80b8-1d8ba5e50b95","Assessing Integration of Bus Networks with Non-Motorised Access and Egress Modalities: Case Study: Bus Network Integration with Access and Egress Modalities in Amstelland-Meerlanden","Brand, J.C.","Hoogendoorn, S.P. (mentor); Annema, J.A. (mentor); Van Oort, N. (mentor); Schalkwijk, B.S.C. (mentor)","2015","","Transport Network Integration; Bus Services; BRT; Walking; Cycling; Access and Egress","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Transport and Planning","","Transport, Infrastructure and Logistics","",""
"uuid:5147ce96-4d99-4642-8d78-9b013ba0baa2","http://resolver.tudelft.nl/uuid:5147ce96-4d99-4642-8d78-9b013ba0baa2","Olla-Deluxe, development of a patient-specific commode","Dinh, P.L.","Ruiter, I.A. (mentor); Thomassen, E.W. (mentor)","2015","The new concept introduces a patient-specific commode, achieved by connecting the commode to the hospital bed. This will diminish the chances of cross-contamination between patients. The one-person-use will save the nurses up to 30 minutes of cleaning time per use. The features integrated into the concept will be supporting the nurses during their work to assist the patient, but will also allow the patient to have a correct toilet posture.","commode; medical device","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Master of Science Integrated Product Design","",""
"uuid:b4c6c86f-18a4-4ada-9962-f85841ea3017","http://resolver.tudelft.nl/uuid:b4c6c86f-18a4-4ada-9962-f85841ea3017","Dealiasing of radar Doppler velocities to improve wind estimations","Brukx, P.B.J.","Unal, C.M.H. (mentor); Russchenberg, H.W.J. (mentor)","2015","With its three beams in different directions, the Transportable Atmospheric RAdar system (TARA) can provide a wind field estimation. These estimations are inaccurate when the Doppler velocities in one or more of the three beams are aliased. Amongst different approaches to solve aliasing are a continuity check up to four dimensions, staggering PRT (Pulse Repetition Time) technique and a method using polarimetric information. The staggering PRT technique is not applicable, because it requires altering the radar system itself. For the main beam of TARA the method using polarimetric information is used, but for the offset beams nopolarimetric information is available. The research presented in this thesis focuses on the dealiasing of the offset beams using a continuity check in one dimension. The assumed correctly dealiased main beam is used as a reference to compare the offset beams with. The first step towards correct Doppler velocities is unfolding every individual Doppler spectrum. Then, a reference spectrum is searched for in the main beam. The first spectrum in the offset beam that is placed in the right Doppler velocity interval, is the one that is at the same height as the reference spectrum. From there on a continuity check is performed. First away from the radar and then towards the radar. Comparison is done by using the mean Doppler velocities of every Doppler spectrum. The algorithm proposed in this thesis shows significant improvement in performance, compared with the old algorithm. In case of very wide Doppler spectra, a large difference between the reference and the current spectrum and clutter, the algorithm can fail.","radar; Doppler; aliasing","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Telecommunications","","Geoscience & Remote Sensing","",""
"uuid:d73234ae-d7e0-4348-ac69-92078820438c","http://resolver.tudelft.nl/uuid:d73234ae-d7e0-4348-ac69-92078820438c","Seismic blending and deblending of crossline sources","Reinicke Urruticoechea, C.","Drijkoningen, G.G. (mentor); Van Groenestijn, G.J.A. (mentor)","2015","Blending is a recent seismic acquisition design, which allows seismic shots to interfere. Current processing techniques are not capable to deal with blended data. Consequently, the blended data must be deblended (separated) as if they were acquired in a conventional way. I propose a new acquisition design based on blended crossline sources. In contrast to existing blended- acquisition designs that only blend in 2D (inline direction and time), this design blends sources in 3D (inline direction, crossline direction and time). Blended crossline sources allow to increase the data quality and/or to reduce the acquisition costs. While most blended- acquisition designs blend two sources, the proposed acquisition design blends up to seven sources. In order to realize this increase in number of blended sources without degrading the data quality, both the blended-acquisition design and the deblending method must be improved. To enhance the blending, I introduce a new incoherency measure of the blended-acquisition design, and propose three incoherent blending patterns. A 2D synthetic data example il- lustrates that the deblending quality indeed is optimized by maximizing the incoherency of the blended acquisition. To enhance the deblending, I derive a 3D deblending method. In contrast to 2D deblending methods, this method exploits both the crossline and inline direc- tion to deblend sources. The 3D deblending method significantly increases the deblending quality as illustrated by a 3D synthetic data example. The feasibility of blended crossline sources is proven on a 3D complex synthetic data example. Two acquisition configurations are examined: The Wide Crossline Source Array that aims to reduce the acquisition costs, and the Dense Crossline Source Array that increases the data quality. Both of them provide excellent deblending results with quality factors of 14.2 dB and 20.8 dB respectively.","blending; deblending; simultaneous sources; incoherent; incoherency","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Applied Geophysics and Petrophysics","",""
"uuid:a01495d7-c791-4113-968e-4c2925b74aa1","http://resolver.tudelft.nl/uuid:a01495d7-c791-4113-968e-4c2925b74aa1","Adaptive deghosting of seismic data: A power-minimization approach","Schuberth, M.G.","Kamil Amin, Y.I. (mentor); Caprioli, P. (mentor); Vassallo, M. (mentor); Van Manen, D.J. (mentor)","2015","In marine seismic acquisitions, a major deteriorating effect on resolution is caused by ghost re- flections. Sensors towed at depth within a water column record not only the desired up-going wavefield reflected from geological formations, but also its reflections from the sea surface known as down-going wavefield, or seismic ghost. This generates notches in the spectrum of the measured wavefield, reducing significantly the usable bandwidth and hence the resolution of the seismic data. Recently, the removal of the ghost (‘deghosting’) has attracted increasing attention with the aim of obtaining more broadband data. In particular, improved deghosting promises to bring value to both legacy and newly acquired data in terms of high signal to noise ratio across a wide range of frequencies. Deterministic deghosting techniques assume a perfectly known ghost model. Unfortunately, environmental effects causing cable positioning errors and poor crossline sampling in marine seismic acquisition can cause deviations from a deterministic ghost model. As a result, this demands strong and often unrealistic assump- tions, such as exclusive inline propagation, a perfectly flat sea surface, or exactly positioned receivers. Additional measurements try to overcome these limitations, however, this is gener- ally expensive, thus motivating an adaptive deghosting approach for single sensor acquisitions. This thesis proposes a novel, simple and fast algorithm to effectively remove the ghost, based on a sequential approach that first estimates the ghost delay parameter through power min- imization of a hypothetical up-going wavefield, and deghosts the data in a final step. The algorithm was applied to real data and compared to current approaches, showing encouraging results. Through its simplicity and speed, the proposed method is largely domain independent and offers many opportunities to be extended.","adaptive deghosting; marine seismic","en","master thesis","","","","","","","","2015-08-09","Civil Engineering and Geosciences","Geoscience & Engineering","","Applied Geophysics and Petrophysics","",""
"uuid:ec1ffb71-5f1b-4730-89ae-45b81efbf5ec","http://resolver.tudelft.nl/uuid:ec1ffb71-5f1b-4730-89ae-45b81efbf5ec","Effect of Chemical Composition and Microstructure of Zn and Al-based Coatings on Electrochemical Response in Corrosive Environments","Mutgi, A.V.","Mol, J.M.C. (mentor)","2015","Hot formed steels are witnessing an increasing use in safety critical and structural parts for automobiles due to their high strength, light weight and absence of springback, due to which understanding the corrosion behaviour of coated products for hot forming is crucial to increase their stronghold in Body-In-White (BIW) applications for automobiles. Currently, aluminium alloy coatings are the preferred choice due to their high temperature stability and low density. However, with OEM’s increasing interest in endowing sacrificial protection to hot formed components, zinc coatings are also making a foray into the product portfolio of steel solution providers. In this study, the corrosion performance of Galvanized Iron (GI), MagiZinc® and Usibor® AlSi coatings for hot press forming was investigated with the help of electrochemical techniques. Galvanostatic testing was used to analyze the response of the coatings to austenitization. The corrosion performance and resistance to pitting was assessed using Cyclic Voltammetry and the corrosion mechanism was characterized through Scanning Electron Microscopy (SEM) and Glow Discharge Optical Emission Spectroscopy (GDOES). The results indicated up to a five-fold improvement in coating thickness for the Zn coatings after hot forming. MagiZinc® containing Mg and Al 1.6 wt. % each was found to have better corrosion resistant properties, as the alloying additions rendered it a better passivation ability compared to conventional GI. Usibor® AlSi developed an aluminium alloy coating layer after hot forming, that possessed only limited sacrificial ability and displayed a vulnerability to pitting. Thus, in terms of the quality of cathodic protection offered to the substrate, the Zn coatings were found to have an upper hand compared to the AlSi coating.","corrosion; hot forming; press hardened steels; coatings","en","master thesis","","","","","","","","2020-08-28","Mechanical, Maritime and Materials Engineering","Materials Science and Engineering","","","",""
"uuid:adaa5dd4-10ca-42b3-b352-00bdc184657d","http://resolver.tudelft.nl/uuid:adaa5dd4-10ca-42b3-b352-00bdc184657d","Safe Interaction Between Lateral and Longitudinal Adaptive Cruise Control in Autonomous Vehicles","Idriz, A.F.","Baldi, S. (mentor)","2015","According to the statistics, driver error is the main reason for the road accidents: this has motivated an intensive research on intelligent vehicles equipped with automated driving technology, active safety and driver-assistance systems so as to enhance the safety of drivers, facilitate vehicle controllability and stability, and improve driving comfort. One of the driver assistant systems currently under development by most automotive manufacturers is the Adaptive Cruise Control (ACC) system. The ACC system, which is an extension of the classic Cruise Control (CC) system, controls both speed and distance to preceding vehicles: the aim of ACC is not only provide the drivers with comfort and safety during driving, but also increase the capacity of roads and reduce fuel consumption. One of the major drawbacks of ACC system solutions commercially available in the automotive industry is the limited performance in cornering situations, where the road presents current/future curvatures. In particular, the interaction between longitudinal and lateral controller systems has not been deeply studied. Moreover, in order to obtain both lateral stability and safe clearance to avoid rear end collisions in critical driving situations, coordinated control of the actuators is necessary without avoiding conflicts caused by the coupling of vehicle dynamics. Summarizing, an implementation of an integrated vehicle dynamics control is far from definiteness. A part of this thesis concerns the parametric vehicle model which is based on a set of vehicle parameters (mass, maximum torque etc.) with realistic nonlinearities in longitudinal and lateral dynamics of vehicle. The longitudinal and lateral control systems are designed to fulfill the objectives and requirements. Since driver acceptance of the proposed control systems is crucial, practical constraints are determined via experimental studies on human driving. Furthermore, in order to allow the driver to personalize the control system in a desired manner, parameterization of control system is provided. An appropriate control structure is adopted to create synergies and safe interaction between longitudinal and lateral controllers, taking into account the previous mentioned aspects, compromising between comfort and safety for various driving situations, in order to obtain both lateral stability and safe clearance of advanced autonomous driving vehicle. This MSc thesis mainly focuses on the design of an Integrated Vehicle Dynamics Control (IVDC) strategy for Adaptive Cruise Control with auto steering application intended to decrease driver’s workload. In severe driving situations, the proposed control strategy is designed based on indexes for driving situations to optimally coordinate the brake and steering actuators to avoid rear-end collision danger and unstable lateral motion of the vehicle. Afterwards, the implementation of the designed controllers has been carried out. Simulations are conducted in Matlab/Simulink by using a set of traffic scenarios which are likely to occur in reality. From simulation results, the performances of designed controllers are evaluated with respect to determined performance specifications. Simulation results have shown that the proposed integrated controller satisfies the performance in terms of autonomous driving, path tracking and collision avoidance for a complete envelope of working conditions.","adaptive cruise control; integrated vehicle dynamics control; vehicle dynamics; longitudinal control; lateral control","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Delft Center for Systems and Control","","Systems and Control","",""
"uuid:25c1f3ab-915a-4eaa-ac68-63f24d77dd9d","http://resolver.tudelft.nl/uuid:25c1f3ab-915a-4eaa-ac68-63f24d77dd9d","Coda: A Change Impact Analysis Tool for Scala","Mackenbach, C.M.; Ang, A.W.Z.","Panichella, A. (mentor)","2015","KeyLocker, a start-up developing cryptographic products that put the control of encryption keys into the hands of the end-users, has requested a review of their own software development process. During their first year of existence, the company experienced problems in following software development methodologies, sharing knowledge effectively between employees, and with testing the software being developed. Being a start-up where its employees are always busy, the company requested outside assistance in analyzing their own processes. Consequently, two students, who previously worked part-time at the company, were tasked with researching the development practices at KeyLocker, identifying problem areas. Subsequently, the students were charged with developing a software application that could assist in the development process, remedying some of the highlighted problems. Two problem areas of knowledge sharing and test maintenance were selected and research was conducted in the field of Change Impact Analysis - the identification of potential consequences of a change to components in software. A tool was designed that could perform an analysis of the source code projects at the company. As Scala was the chief programming language used at the company, the application needed to be able to parse Scala source code and interpret changes to this source code. Then, the application needed to be able to analyze the code for potential consequences of those changes. Needless to say, developing such an application required an in depth knowledge of the Scala programming language. The three main goals of designing such an application were utility, usability, and maintainability. In short, the software needed to solve the problems experienced at KeyLocker effectively, in a user-friendly manner, and be easy to maintain in the future. Over the course of sixteen weeks, the application has been developed with exactly these three goals in mind. During the completion phase of the project the application has been tested by the development team at KeyLocker, receiving a positive response. Nevertheless, there is room for improvement and some recommendations are provided for future work.","Change Impact Analysis; Coda","en","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Software Technology","","","",""
"uuid:735c9c97-d04e-4caf-90d4-081b13a8e464","http://resolver.tudelft.nl/uuid:735c9c97-d04e-4caf-90d4-081b13a8e464","ATP - EMTP Modeling of Distance Relays to Simulate Single Line to Ground Fault Performance in Transmission network","Hakim, A.R.","Popov, M. (mentor)","2015","The thesis deals with the modeling and simulation of distance relays in ATP - EMTP. Transmission line which is 125.6 miles long operates at 60 Hz and 115 kV line voltages are simulated in ATP - EMTP. The first part of the thesis discusses the implementation and simulation of the ATP - EMTP model for microprocessor based mho distance relay using angle comparator method in the network. The model includes the modeling of input filter, sample and Fourier fundamental frequency detector, which process the input for mho distance relay model. A number of simulations of single line to ground faults (SLGF) with different fault locations were carried out to verify the correct operation of the relay based on the developed protection scheme. The results of the simulation show the operation of the relay based on its protection scheme and its response time related to the fault locations. The study is also extended to the double line to ground fault for the same purpose. The second part of the thesis discusses the model for an electromechanical mho distance relay, which includes the modeling of current transformer (CT) and capacitive voltage transformer (CVT). A validated ninth-order mathematical model of the electromechanical Mho distance relay is constructed in ATP - EMTP to observe the dynamic behavior of the relay during a critical fault. For that purpose, SLGF were tested in critical locations which is very close to the relay. The results show how CT saturation and CVT transient influence the relay operation. The applied procedure can be used for testing of distance protection performance against single phase fault currents.","ATP - EMTP; microprocessor based mho distance relay; electromechanical mho distance relay; current transformer (CT); capacitive voltage transformer (CVT)","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Electrical Power Engineering","","MSc","",""
"uuid:0f457080-1ef1-4796-9b8a-4b6017f71ab9","http://resolver.tudelft.nl/uuid:0f457080-1ef1-4796-9b8a-4b6017f71ab9","Development Patterns and Factors Influencing the Growth of Industrial Symbiosis: Case Study of Tata Steel IJmuiden and the Surrounding Industrial Region to Achieve Reduction in Water Consumption Using Industrial Symbiosis Approach","Deshpande, S.S.","Weijnen, M.P.C. (mentor); Stikkelman, R.M. (mentor); Pesch, U. (mentor); Jägers, G.A. (mentor)","2015","In today’s competitive and environmentally conscious industrial society, companies thrive to perform their production activities in the most environmentally friendly way. Companies are moving from individual resource efficiency approaches to broader community approaches. They are now looking for opportunities to broaden the scope and go beyond their fence to share and cooperate. In essence, they are looking for ecological aspects in an industrial site. Waste of one industry could become resource to another industry. Webs of exchanges of by-products, wastes and residues are seen to reduce the overall environmental impact of the industries. These webs are called as Industrial symbiotic links. A classic example is Kalundborg industrial site were several industries share wastes and resources with each other to add benefit to the environment in an economic way. Several attempts have been put to replicate Kalundborg example of industrial exchange but less success has been achieved. Many sites who claim to have a symbiotic development approach are either in planning stage or have failed. According to academic scholars, there is a gap in what industrial symbiosis is in theory and what is being implemented. Therefore, it is important to understand the development patterns of Industrial Symbiosis and find out what factors influence the development of Industrial Symbiosis. This thesis investigates the factors influencing the development of Industrial Symbiosis (IS) in a well-established industrial site which shares a long history of colocation with other firms. The Aim of this thesis is to understand development pattern of IS and find (factors in terms of) drivers and barriers which foster or impede the growth of IS links among the firms. To serve this purpose a literature review and interview based analysis approach has been used. This thesis was conducted on the region of IJmuiden/Velsen Noord/Beverwijk/ Hemskerk (For simplification it is called as IJmuiden region).","Industrial Symbiosis; Eco Industrial Parks; Industrial Ecology; Self Organizing Nature; Planning Approach; Facilitated Evolution Approach","en","master thesis","","","","","","","","2015-08-31","Technology, Policy and Management","Energy and Industry","","Management of Technology","",""
"uuid:4ec4194e-5310-4ebd-8ac8-dba3b644eaa2","http://resolver.tudelft.nl/uuid:4ec4194e-5310-4ebd-8ac8-dba3b644eaa2","Integrating a Temperature Sensor into a CMOS Image Sensor","Markenhof, J.","Theuwissen, A.J.P. (mentor)","2015","Dark current noise in image sensors is highly sensitive to temperature, and a difference in temperature in image sensors can be seen in the image as a non-uniform noise source. Many CMOS image sensors are integrated in mobile devices and lack a physical shutter to generate dark frame subtraction to compensate for dark current noise. In this thesis, the design and implementation of a bandgap based temperature sensor into an image array is proposed. A single parasitic pnp BJT, together with a source follower and control switches, is integrated inside an image array and is biased from outside the array. By means of CDS in the column amplifier of the imager, the difference in base-emitter voltage of a single BJT, that is being biased by a known current ratio, can be measured to calculate temperature. A total of 542 temperature sensors are fully integrated in a 192x64 test array of 4T APS based pixels and share the same readout as the image pixels. At the moment of writing, the chip was still waiting for tape-out and no measurement results can be presented in this thesis.","Dark current; CMOS Image Sensor; Temperature Sensor; T-sensor","en","master thesis","","","","","","","","2016-08-28","Electrical Engineering, Mathematics and Computer Science","Electronic Instrumentation","","","",""
"uuid:73d49aca-555d-4018-8035-40dc2965c5ab","http://resolver.tudelft.nl/uuid:73d49aca-555d-4018-8035-40dc2965c5ab","Internet of Things in the kitchen: Design of a connected product","Guadalupi, L.","Hajian, M. (mentor); Pourtalebi, S. (mentor)","2015","""Lella"" is a system that allows users to follow and create recipes in a new way exploiting the internet of things technology. The system is composed by a cutting board, a dock station and an app.","Internet of Things; Delft Design Guide; Value Proposition Design; Cutting Board; App; Networking","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Integrated Product Design","",""
"uuid:d1094eb2-49c0-4e07-8900-bb97719c51a6","http://resolver.tudelft.nl/uuid:d1094eb2-49c0-4e07-8900-bb97719c51a6","Planning for investment in the dairy future of Sub-Saharan Africa: Navigating uncertainty in the contextual business environment","Sonneveld, A.M.H.","Tavasszy, L.A. (mentor); Enserink, B. (mentor); Hulstijn, J. (mentor)","2015","The global dairy market is turning sour. Prices have continued to fall due exceptionally strong supply growth – in particular following EU milk quota removal at the time of writing – and reduced buying. This stress has caused dairy players to seek new markets. Sub-Saharan Africa has become the new target. However, those with intentions to invest in this region are facing uncertainty due to (1) lack of knowledge and (2) variability inherent to the sector. The focal decision of Rabobank clients to which this thesis aims to provide decision support is: ‘Whether or not to invest in dairy business development in Sub-Saharan Africa and if so, where and how?’. A combined approach has been used. Trade flow mapping helps to put the promise of Sub-Saharan Africa in perspective and provides insight into regional differences in access to market, thereby breaking the tendency to evaluate the continent as if it constitutes “one big country”. The second approach, strategy analysis of multi-actor systems, reveals why business development is perceived as a challenge. Investigation of complex dynamics within the ‘black box’ of African dairy allows for pinpointing sources that add to the uncertainty. Lastly, the scenario planning helps in navigating future uncertainty. This third approach has been adjusted to match the cross-organizational research set up. Reviewing the options for business development against the portrayed possible paths into the future yields the conclusion that African dairy business is not for the risk averse. Robust strategies do not exist. Solely adaptive strategies provide a way out for the level of uncertainty close to the ignorance extreme. The strategic balance between trade and foreign direct investment (FDI) should be adapted as forks in the road appear. As a starting point, guidance is provided regarding the relative attractiveness of trade versus FDI for ten selected countries. Following this case study, next steps for academia would be (1) to analyse the potential of the cross-organizational set up in case of redeployment from a banking perspective, (2) to review the use of scenario methods in the changing landscape of food and agriculture and (3) to explore possibilities for proper integration of corporate social responsibilities (CSR) in order to prevent scenarios from reinforcing the tendency of taking a blinkered, economic view on the focal decision. The scientific article accompanying the thesis critically reflects on a structural weakness of the scenario approach, rooted in a rule-of-thumb, that increases the chance of CSR remaining unaddressed in business planning.","scenario planning; multi-actor systems; dairy business development; global commodity trade","en","master thesis","","","","","","","","2016-09-01","Technology, Policy and Management","Engineering Systems and Services - Transport and Logistics","","Systems Engineering, Policy Analysis and Management","",""
"uuid:d9ee66a8-6c45-472a-b586-31b01d56836f","http://resolver.tudelft.nl/uuid:d9ee66a8-6c45-472a-b586-31b01d56836f","The Iconic Value of Infrastructure Projects: A case study to the iconic value of the Erasmus Bridge","Heijnsdijk, R.","Mouter, N. (mentor)","2015","This study aims to provide insight in the iconic value of infrastructure projects by measuring the iconic value of the Erasmus Bridge in Rotterdam. This study was motivated by the lack of insight in iconic value in the appraisal of infrastructure projects aspiring to become iconic artifacts in Cost-Benefit Analysis. We designed a contingent valuation experiment, with two contingent scenarios and two respondent samples. One sample representing the inhabitants of the city of Rotterdam and one sample representing the inhabitants of the Netherlands excluding the inhabitants of Rotterdam. For both respondent samples significant (from zero) WTP estimates were found. Furthermore, people who virtually never use the Erasmus Bridge for transportation goals, or even see the Erasmus Bridge still have a WTP for the iconic value of the Erasmus Bridge. Allowing for uncertainties we estimated a lower bound and an upper bound for the total WTP for the iconic value of the Erasmus Bridge for inhabitants of the Netherlands. Regardless if we choose the lower bound (69.7 million euros) or the upper bound (95.7 million euros) the iconic value of the Erasmus Bridge is higher than the extra costs made in reality to build the Erasmus Bridge instead of a more conservative design (18 million euros). Hence, it can be concluded that the iconic value of infrastructure projects can be substantial, at least in the case of the Erasmus Bridge. Therefore iconic value should not be ignored in the CBA.","","en","master thesis","","","","","","","","","Technology, Policy and Management","Transport & Logistics","","","",""
"uuid:4ce2bed4-c879-44fb-8e13-61aa22e0b3f6","http://resolver.tudelft.nl/uuid:4ce2bed4-c879-44fb-8e13-61aa22e0b3f6","Treatment of cooling tower blowdown water: The effect of biodispersant on the ultrafiltration membrane","Olariu, R.","Rietveld, L.C. (mentor); Heijman, S.G.J. (mentor); Pande, S. (mentor)","2015","Taking into account the growing population, water scarcity is a relevant problem which needs to be addressed. Wastewater needs to be assured by quality, ecosystems protected and the wastewater reuse in industry should be a more common approach that would also assure the reduction of fresh water intake. Dow Chemicals decided to reduce the fresh water consumption by reusing the wastewater streams. Evides built a pilot plant in Terneuzen that will treat 3 water sources: rainwater, wastewater treatment plant effluent and cooling tower blowdown (CTBD) water. The biggest stream and the most difficult to treat is the CTBD water due to its high salinity and composition resulting after the evaporation process. Since the performance of the pilot was not very efficient and the ultrafiltration (UF) membrane suffered from rapid fouling during operation with CTBD, a solution to reduce the fouling was researched. First, the coagulation/flocculation step was evaluated. It is known that iron chloride used as coagulant will decrease the pH of solution, which will result in smaller and more difficult to settle flocs. For the improvement of the coagulation step a base was added together with the coagulant in order to keep the pH in the sweep coagulation zone. Since the focus of the research was on improving the UF operation, more attention was put into what could be the cause of it. It is known that in the cooling tower many chemicals are added to prevent corrosion, scaling or microbial growth. Of all chemicals, the biodispersant was the unknown solution which prevents microorganisms attaching to surfaces. The assumption made was that the biodispersant will form a layer on the membrane’s surfaces which causes the pressure increase after continuous operation. The nature of the biodispersant was investigated through surface tension and electrical-conductivity measurements and it was concluded that the biodispersant is a non-ionic surfactant. The critical micelle concentration was established to be 0.03 mg/l. CMC is the concentration above which the biodispersant is not only present as molecules, but it start forming micelles. The higher the concentration, the higher the number of micelles will be. When the concentration is equal with the CMC the solution is saturated with surfactant molecules which form a layer on the surfaces. Furthermore, the operation of the UF was observed in experiments with different biodispersant concentrations. Solutions of demiwater and Schie canal water with and without biodispersant were filtrated in order to observe the fouling behavior. It was indeed seen that the biodispersant is causing the fouling of the UF membrane and the backwashes did not help restore the initial membrane resistance. Experiments with powdered activated carbon (PAC) and clay were also performed to see if the adsorption of biodispersant was possible, but the results were not promising. For clay the adsorption area was too small and not much was adsorbed. For PAC, besides the biodispersant there are present other organics that will compete for adsorption. Because the surfactant concentration in the blowdown water was much higher than the CMC concentration (assumed 4 mg/l) experiment with solutions with surfactant concentration closer to the CMC were performed. It was observed that at a concentration of 0.1 mg/l biodispersant the fouling was much lower than the fouling increase recorded with solutions at 4 mg/l biodispersant and the backwashes were more efficient. At a biodispersant concentration of 0.1 mg/l the system is supposed to still be saturated. Therefore, it is assumed that the microbial growth should not be increased and the system’s behavior will not be affected by the decrease of biodispersant dosage. This statement should be further researched, but it a decrease in biodispersant dosage would not only result in a stable efficient operation of the pilot, but also lower operational cost, since less surfactant would be added in the cooling tower.","water; water treatment; cooling tower; blowdown; biodispersant; ultrafiltration; coagulation","en","master thesis","","","","","","","","2015-08-27","Civil Engineering and Geosciences","Water Management","","Sanitary Engineering","",""
"uuid:75232e4a-a818-4131-bd4a-1d450d08259f","http://resolver.tudelft.nl/uuid:75232e4a-a818-4131-bd4a-1d450d08259f","Prioritizing and selecting KPIs: An AHP-based model to evaluate the alignments among strategy business model and performance metrics","Jiang, Y.","Bouwman, W.A.G.A. (mentor); Groenleer, M. (mentor); Tan, Y. (mentor); Verhagen, M. (mentor)","2015","","KPI prioritization; performance metrics; strategy making process; decision making; performance management","en","master thesis","","","","","","","","2017-08-27","Technology, Policy and Management","Information and Communication Technology (ICT)","","System Engineering, Policy Analysis and Management","",""
"uuid:a575e9f7-de8c-4de8-a88b-9173b291ac4c","http://resolver.tudelft.nl/uuid:a575e9f7-de8c-4de8-a88b-9173b291ac4c","Computational Modeling of Turbulent Ethanol Spray Flames in a Hot Diluted Coflow using OpenFOAM","Abul Kalam Azad, T.A.","Roekaerts, D.J.E.M. (mentor)","2015","Spray combustion finds a wide range of application in gas turbines, internal combustion engines, industrial furnaces, etc. In turbulent spray combustion, liquid fuel is injected into the combustion chamber in the form of droplets. In order to improve the combustion efficiency and to reduce the thermal NOx emissions released during combustion, spray combustion could be operated in flameless mode. In a flameless combustion, the oxidizer is mixed with recirculated hot combustion gases to preheat and to dilute it. The dilution of oxidizer results in lower peak combustion temperature which reduces the NOx emissions and oxidizer preheating improves the thermal efficiency of combustion. In order to fully understand the combustion mechanics for its effective implementation in various applications, numerical simulations of flameless turbulent spray combustion are potentially useful because simulations are cost effective and serve as basis for further experimental studies based on the validation of numerical models. Turbulent spray combustion is a complex phenomenon involving two phases namely the gaseous phase and liquid phase. These two phases interact with each other through mass, momentum and energy transfer between them. This is complicated further by the interaction between the turbulence in the flow field and chemistry of the reacting species. Hence simplified models are necessary to simulate and understand the phenomenon of turbulent spray combustion. In this thesis, numerical validation study of turbulent ethanol spray flame using open-source software package OpenFOAM is carried out for the experiments done in Delft Spray-in-Hot-Coflow (DSHC) burner operated in flameless mode. The modeling approach used is Reynolds Averaged Navier Stokes simulations (RANS) with Eulerian-Lagrangian framework for the continuous phase and discrete phase respectively. Models like evaporation and turbulence models used in the sprayFoam solver are optimized for the spray combustion and validated with experimental data for one flame. The evaporation models studied are Gradient diffusion model and Spalding model. It is found that Gradient diffusion model gives better prediction of droplet properties at higher axial locations than Spalding model. The standard and realizable k-? model turbulence models comparative analysis showed that standard k-? model has much better gas phase temperature prediction than realizable k-? model due to the dependence of combustion model (Partially Stirred Reactor model) on the turbulence mixing frequency, ?/k. These optimized models are extended to simulation of HI and HIII flames. The peak gas phase temperature was under-predicted by the PaSR model. The results showed the importance of analyzing the different initial spray conditions.","","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Process and Energy","","Sustainable Process and Energy Technology","",""
"uuid:86c32d9c-2779-44a3-a6e6-743e78426217","http://resolver.tudelft.nl/uuid:86c32d9c-2779-44a3-a6e6-743e78426217","Investigation on Steam-based System for Creepforming Dyneema Hemisphere Preform","Simbolon, M.R.","Marissen, R. (mentor); Bergsma, O.K. (mentor)","2015","Previous study in Structural Integrity and Composite group showed that creepforming Dyneema fiber into hemispherical helmet preform is indeed possible. However, the set-up in conventional set-up was complex and a long time was required to generate uniform temperature across the material. This thesis will investigate the possibility of using steam system as heating and pressurizing agent to creep-form the material. Steam is considered as potential agent due to its characteristic to be a good heating agent. The first part of this thesis will cover the analysis of manufacturing process from previous works in order to find their strengths and weaknesses. Using this information a production system that ideally combines the advantages of previous processes will be selected. After manufacturing the molds, the investigation of proposed process' boundary condition can be started. The experiments conducted in this thesis revealed that the available pressure from steam was not enough to creepform Dyneema fiber. The second part of the thesis is directly related with the selection of gas-based system as the main equipment. Since the available pressure is a lot less than the manufacturer's recommended cycle, the result of these experiments revealed several interesting findings. This part will cover the experiments conducted to further clarify the findings. Another consequence of the low available pressure is the final thickness of the product is low. It was then proposed to insert several new layers that are not winded around the mold as a potential solution for this thickness problem. However, the interaction between these ""draped"" layers with the normal creep layers is still unknown. The investigation will cover several experiments to provide better knowledge of the proposed layer combination idea. For further research, it is anticipated that by utilizing compressed water as the working medium, sufficient pressure to successfully creep-form Dyneema\textsuperscript{\textregistered} fiber can be achieved. A possible set-up design of the system is provided in the recommendation section.","Dyneema; Steam; Autoclave; Hemisphere; Creepforming","en","master thesis","","","","","","","","2015-08-31","Aerospace Engineering","Aerospace Structure and Materials","","Structural Integrity and Composites","",""
"uuid:98374b6c-e7d3-4837-b8a8-e134710d2e46","http://resolver.tudelft.nl/uuid:98374b6c-e7d3-4837-b8a8-e134710d2e46","Life cycle assessment of ocean thermal energy conversion: The life cycle impact of electricity supply in small island regions","Aalbers, R.R.D.","De Jong, W. (mentor); Kleute, B.J. (mentor); Brezet, J.C. (mentor); Korevaar, G. (mentor); Tsalidis, G.A. (mentor)","2015","The use of renewable energy solutions in generating electricity constitutes an interesting option in small island regions. Current energy supply generally comes from fossil fuels and besides high costs this also contributes to high CO2 emissions. Ocean thermal energy conversion (OTEC) is a technology that potentially could be implemented. It makes use of the temperature difference of the ocean to generate electricity. However, an OTEC system has a considerable size. The cold water pipe made of composite is 1,000 meters long and has a diameter of 4 meter. Moreover, the large area required for heat exchange implicates large requirements of (energy intensive) titanium. Therefore it is necessary to investigate the environmental impact of the whole life cycle. This thesis is performed to assess the CO2 emissions associated with OTEC. In order to obtain these results the life cycle assessment method is used. The results for OTEC are compared with diesel, wind and PV technology. Both on a 1 kWh electricity basis and in an energy mix scenario context. It can be concluded that renewable energy impact follows mainly from raw materials, manufacturing and transport, while with diesel the impact is a direct result of the use phase. The CO2 emission resulting from 1 kWh of electricity production by a 10 MW OTEC installation on Curacao is 16 times lower than the CO2 emission resulting from 1 kWh of electricity production by diesel generators. In relation to a 3kW peak PV installation the emissions resulting from OTEC are 1.752 lower. The OTEC emissions are 3.9 times higher compared with an 800 kW wind turbine. In an energy mix scenario this slightly changes in favor of OTEC, even despite the favorable wind conditions on Curacao. This thesis shows that OTEC is a very promising technology considering the relatively low CO2 emissions in combination with base load electricity generation.","OTEC; LCA; life cycle assessment","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Process and Energy","","Sustainable Energy and Technology","",""
"uuid:aeba9cd4-3d75-4201-813c-119854c4d010","http://resolver.tudelft.nl/uuid:aeba9cd4-3d75-4201-813c-119854c4d010","Continuous Membrane-assisted Airlift Crystallization","Mohangoo, W.","Kramer, H.J.M. (mentor); Anisi, F. (mentor)","2015","In previous research, batch experiments with an airlift crystallizer on ammonium sulphate, adipic acid and L-ascorbic acid have shown significant reduction of secondary nucleation compared to conventional stirred crystallizers. Furthermore, the crystal size distribution (CSD) achieved by the airlift crystallizer is almost 60% narrower than the CSD achieved by a conventional stirred tank. Optimal process conditions were found for cooling batch experiments on L-ascorbic acid. One of the disadvantages of cooling crystallization is the tendency for scaling on the cooling surfaces. An alternative method to create the supersaturation in crystallization processes is the removal of the solvent from the solution, which is mostly achieved by evaporation, which is however an energy intensive method. Application of membrane separation, either by reverse osmosis or membrane distillation, to assist crystallization is a novel, sustainable, concept. In previous research, a study on Sweeping Gas Membrane Distillation (SGMD) has shown better control on the level and rate of supersaturation generation. Optimal process conditions were found for experiments on L-ascorbic acid. To disentangle crystallization phenomena, such as primary and secondary nucleation, growth, dissolution, attrition and agglomeration, and to investigate these phenomena independently for further optimization and improvement of crystal properties, such as purity, shape of crystals, polymorphic form and CSD, a new experimental setup, called Membrane-assisted Crystallization (MaC), is designed, constructed and automated in this research. The experimental setup is designed and constructed in a modular way to perform experiments with standalone units, both in batch and continuous operation, as well as in combined modes in which the crystallizer is connected to a membrane unit. Therefore, it is possible to perform batch and continuous operated cooling and membrane-assisted crystallization experiments, in both the airlift crystallizer, as well as in stirred tank crystallizer. Process conditions, such as temperatures and flow rates, are automated in this research. The MaC setup consists of an airlift crystallizer, a stirred tank crystallizer, membrane module, feed vessel, buffer vessel, make-up vessel, and instruments for online monitoring and controlling. For the online monitoring and control of the experimental setup, a Distributed Control Station (DCS) of Yokogawa Europe B.V. is connected to the MaC setup. The monitoring and control system with the Yokogawa system has been designed, tested and calibrated in this research. The use of the DCS system allows the monitoring and centralised storage of all the relevant process variables, and the implementation of all basic control loops of the different process configurations. In addition, test experiments have been designed and performed with the different parts of the MaC setup, with water, melamine and L-ascorbic acid for troubleshooting and optimization. Lastly, experiments with L-ascorbic acid were designed and performed to reproduce the results of previous batch experiments. With the optimal process conditions found in previous research, continuous experiments and membrane-assisted experiments have been designed and performed. The results of these experiments were analysed and compared to each other. Batch experiments with an airlift crystallizer on L-ascorbic acid, showed similar results to the previous research. Effect of secondary nucleation is clearly minimized with an airlift crystallizer, compared to conventional stirred crystallizers. Continuous cooling crystallization experiments with L-ascorbic acid resulted in an absence of secondary nucleation, compared to cooling batch experiments. Continuous membrane-assisted crystallization experiments have shown a narrower CSD compared to the cooling batch and the continuous cooling operations. In conclusion, the new MaC setup is a promising new type of crystallizer with many possibilities to optimize the final crystal quality. Important crystallization phenomena such as nucleation and, generation and maintenance of supersaturation can be optimized and controlled with the Continuous Membrane-assisted Airlift Crystallizer.","airlift; crystallization; continuous; membrane distillation; control system; experiments; troubleshooting; L-ascorbic acid","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Process and Energy","","Intensified Reaction & Separation Systems","",""
"uuid:5fc10819-cf6e-44b3-a93e-1efb795ee575","http://resolver.tudelft.nl/uuid:5fc10819-cf6e-44b3-a93e-1efb795ee575","GSVD based blind-beamforming technique for suppression of partially overlapping Bluetooth data packets from WiFi signals","Shukla, S.Y.","Van der Veen, A.J. (mentor)","2015","WLAN 802.11 (WiFi) and WPAN 802.15 (Bluetooth) operate in the same 2.4GHz ISM band. OFDM WLANs are designed to provide very high data rates, resilience to multipath and extended operating range. One of the main barriers to actually achieving the high data rates is the interference from the Bluetooth systems which is one of the main sources of interference in the 2.4GHz unlicensed band. This thesis investigates the interference problem and proposes a novel subspace-based method to mitigate the Bluetooth interference in WiFi signals using spatial filtering with an array of antennas. We assume continuous transmission of WLAN packets and partially overlapping, unsynchronous and intermittent Bluetooth interfering packets. The proposed method estimates the target (WiFi) and interfering (Bluetooth) signal subspaces and uses this subspace information to estimate beamformers for interference suppression. Results show that through the proposed subspace based algorithm the interference of Bluetooth transmission for 802.11 as target model can be reduced and the throughput of 802.11 can be significantly improved at the expense of additional computational complexity.","GSVD; WiFi (WLAN); Bluetooth (WPAN); Beamforming; Interference; Coexistence","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Department of Microelectronics","","Master Electrical Engineering, Track - Telecommunications and Sensing systems","",""
"uuid:c1b38e2d-896c-4081-811e-770308d71267","http://resolver.tudelft.nl/uuid:c1b38e2d-896c-4081-811e-770308d71267","Reallocating Aircraft Stand Capacity","Beudeker, M.R.","Van Wee, G.P. (mentor); Wiegmans, B. (mentor); Kwakkel, J.H. (mentor)","2015","","","en","master thesis","","","","","","","","","Technology, Policy and Management","Integral Design and Management","","Construction Management and Engineering","",""
"uuid:18eaec8f-12d7-448e-927b-42bd5600daa6","http://resolver.tudelft.nl/uuid:18eaec8f-12d7-448e-927b-42bd5600daa6","Wiskundige modellering van de interactie tussen tumorgroei en angiogenese","Rentier, A.M.","Vermolen, F.J. (mentor)","2015","Dit bacheloronderzoek doet onderzoek naar de invloed van zuurstof op tumorgroei en andersom. Voor de zuurstofvergelijking wordt een diffusievergelijking geïntroduceerd die gediscretiseerd wordt met behulp van de Finite Volume Method, en vervolgens met behulp van Euler Achterwaarts geïntegreerd. De tumorgroei wordt met behulp van een exponentiële functie bekeken die afhankelijk is van de zuurstofconcentratie. Vervolgens wordt ook deze vergelijking met Euler Achterwaarts bekeken. Nadat de tumorgroei is gemodelleerd kan er een terugkoppeling gemaakt worden naar de zuurstofdiffusie. Vervolgens wordt de afgifte van groeifactoren bestudeerd die afhankelijk wordt gemaakt van de zuurstofconcentratie. Ook deze vergelijking is een diffusievergelijking die met de Finite Volume method wordt gediscretiseerd. Deze groeifactoren zullen tumorangiogenese in gang zetten. Hoewel dit niet wordt bestudeerd in dit project, wordt wel een aanbeveling gegeven voor een uitbreiding van het model.","angiogenese; tumorangiogenese","nl","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","Numerical Analysis","",""
"uuid:4cb0dc14-0ca0-4296-be74-51d0fd752fc5","http://resolver.tudelft.nl/uuid:4cb0dc14-0ca0-4296-be74-51d0fd752fc5","Comparing and improving steering forces in a race car and race simulator to increase simulator fidelity","Advocaat, R.","Voskuijl, M. (mentor)","2015","As circuit testing days are expensive and limited by regulations, racing teams are more and more dependent on simulation tools. Van Amersfoort Racing built their own racing simulator to train drivers in an fully controlled environment. This environment is based on commercially available simulation software rFactor. However, no research on the accuracy of the physics of this software is available. Since level of fidelity of race simulators is important for the perception of racing drivers, force feedback steering forces are analyzed. Information of the real Formula 3 car is used to upgrade the vehicle model used in rFactor and to develop a Multibody Dynamic vehicle model of the same car. Steering metrics are used to make qualitative comparisons between steering force measurement in the real car, the simulator and the Multibody Dynamic model. It is shown that the baseline simulator vehicle model is less sensitive to steering input compared to the real car. Furthermore the simulator driver theoretically senses higher steering torques for a given lateral acceleration discarding electric power limitations of the force feedback motor. As a desire to improve simulator fidelity, a Pacejka tyre model of the Hankook Formula 3 tyre is converted to an rFactor model together with an improved suspension model using the exact suspension geometry as provided by car manufacturer Dallara. Simultaneously, the Multibody Dynamic vehicle model is constructed from these submodels, which purely focusses on lateral dynamics. In order to use the lateral based Multibody Dynamic model as a tool for simulation and assessment, its response is tested given the same input as the real Formula 3 car experienced during a particular test. Three cases are considered: weaving on a straight, a low speed corner and a high speed corner. Longitudinal load transfer is inherent in low speed corners, which, due to its limitation in the Multibody Dynamic model, leaves the model adjustments inconclusive. Furthermore, tyre relaxation plays an important role in low speed corners following each other up in a short period of time, which affect low speed steering metrics. The Multibody Dynamic model showed close correlation of steering metrics with real car measurements for the high speed corner. The updated rFactor model improved steering torque feedback despite higher required steering angles.","Formula 3; Multibody dynamic model; Pacejka tyre model; Suspension geometry; Simulator","en","master thesis","","","","","","","","","Aerospace Engineering","Flight Performance & Propulsion","","","",""
"uuid:dbec8a3a-4e56-460e-9282-fe843b1a4e14","http://resolver.tudelft.nl/uuid:dbec8a3a-4e56-460e-9282-fe843b1a4e14","Managing the Dutch Waterworks using long-term Maintenance Contracts: Functional Risk Allocation between Public and Private Parties","Brommet, O.D.","Hertogh, M.J.C.M. (mentor); Schoenmaker, R. (mentor); Chen, Y. (mentor)","2015","","","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Integral Design and Management/Construction Management and Engineering","",""
"uuid:a1c74e29-1bf6-4e7e-af68-89ec15e88cad","http://resolver.tudelft.nl/uuid:a1c74e29-1bf6-4e7e-af68-89ec15e88cad","SLAMming with Spheros: An impact-based approach to Simultaneous Localization and Mapping","Kandasamy, S.","Keviczky, T. (mentor)","2015","The Simultaneous Localization and Mapping (SLAM) problem for mobile robots aims at consistently building a map of an unknown environment while simultaneously determining its position within this map. From a control-theoretic viewpoint, it is somehow analogous to simultaneously estimating the states and output map of the system. In the robotics community, SLAM is arguably considered a solved problem on a theoretical and conceptual level, but still it requires considerable maturity on a practical level. The state-of-the-art SLAM algorithms require computationally powerful processors, expensive sensors with dense feature extraction and multiple sensors for uncertainty reduction. An approach to the SLAM problem using minimal sensing information is still lacking in both theoretical and practical aspects. In this context, this M.Sc. thesis aims to study and implement a special type of SLAM solely using the impact information from a spherical mobile robot called Sphero (developed by Orbotix). Such impact data is available from the robot's onboard IMU, however the impact angle and odometry information are subject to significant drift. Thus, the SLAM problem will be restricted to a rectilinear environment in order to allow for calibration and correction of such accumulated IMU errors (assuming that impacts with walls are sufficiently frequent). The impact-based SLAM is an observable estimation problem with downside of a poor robot pose distribution. An accurate representation of the pose distribution is a particle set, with the resulting estimation technique as particle filter. Suitable map representations for the impact-based SLAM problem are formulated and studied, and the most efficient one is implemented. A probabilistic formulation is laid out for the SLAM problem using robot motion model and map representation, and associated challenges are studied for developing an efficient algorithm. The resulting SLAM algorithm uses a Rao-Blackwellized particle filter which is computationally efficient and robust to data association errors. The issue of inconsistency is discussed for the developed SLAM algorithm and suitable modifications are proposed over the developed algorithm for ensuring consistency. SLAM is extended to multiple robots as a map-merging problem since multiple robots can build a perceptually rich map with a lower exploration time.","SLAM; sphero; estimation; histogram; particle filter; Rao-Blackwellized; minimalistic","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Delft Center for Systems and Control","","Masters in Systems and Control","",""
"uuid:053c1ff3-08ee-40b5-b67a-2546f0885b84","http://resolver.tudelft.nl/uuid:053c1ff3-08ee-40b5-b67a-2546f0885b84","Simplified fatigue assessment of offshore wind support structures accounting for variations in a farm","Michalopoulos, V.","Zaaijer, M. (mentor)","2015","The optimal design and preliminary strength assessment of offshore wind support structures gain growing interest given the potential to drive the costs further down. This study develops a framework for Fatigue Limit State (FLS) estimations of monopiles in a simple and quick manner so as to address site variations in an offshore wind farm (OWF). Additionally, it serves the need for optimisation of all structures in the farm in the early design phase. The framework consists of two elements: (a) a stand-alone model that predicts in a simplified way the damage caused by the varying loading and (b) correction factors that increase its reliability. The concept of the model relies on the analytical approximation of the dynamic response, thus by-passing time consuming numerical processes and advanced software. The above step renders it a simplified version of the conventional frequency-domain. Its benchmarking against the time-domain aeroelastic code Bladed yields sufficient accuracy but also certain systematic errors. Effectively, these are tackled by the correction factors that are generated at a reference position where time-domain detailed assessment is necessary. Once calculated, they are transferred to the positions of interest in the farm. A case study examining the variations in a site shows an efficient performance of the proposed scheme: particularly at the parts of the structure close to the seabed with errors lower than 5 % with respect to the outcome of Bladed. Finally, given the fatigue estimations at every location, the foundation piles are re-designed individually in order to fulfil the target of mass reduction. By using the outcome of the case study as input for the tailoring of the geometry, it is shown that a considerable amount of steel, up to 16 %, can be saved.","Windenergy; frequency domain; FLS; tailored design; monopiles","en","master thesis","","","","","","","","","Aerospace Engineering","Wind Energy","","MSc S.E.T. (Fac. of Applied Sciences)","",""
"uuid:282aa7de-cba5-422c-98df-7ad24e89924b","http://resolver.tudelft.nl/uuid:282aa7de-cba5-422c-98df-7ad24e89924b","Acceleration of read alignment with coherent attached FPGA coprocessors","Jaspers, M.J.","Al-Ars, Z. (mentor); Hofstee, H.P. (mentor)","2015","With the advent of Next Generation Sequencing (NGS), the cost of sequencing human DNA has decreased significantly over the past decade. This decrease in cost has attracted a great deal of attention from medical research and is now transitioning to clinical practice. Precision medicine, tailored to a persons's genetic profile, is becoming a viable option in the battle against cancer and rare genetic diseases. NGS sequencers produce millions of small fragments of DNA called reads. Mapping those reads to a reference genome proves to be a tremendous computational task and forms the bottleneck in current DNA analysis flows. BWA-MEM, a state-of-the-art alignment tool, applies the seed and extend paradigm to rapidly align the reads with a reference genome. The Smith-Waterman (S-W) algorithm is widely adopted by these state-of-the-art aligners. We have identified the S-W algorithm to be the main computational bottleneck on IBM's POWER8 processor. This recently released processor includes a new Coherent Accelerator Processor Interface (CAPI), that provides cache coherent access to shared memory for heterogeneous processors. We present a highly parallel FPGA-based accelerator that offloads the Smith-Waterman task. We have integrated the accelerator with software, relying on CAPI, in a tightly coupled fashion. This integrated heterogeneous system is able to achieve a speedup of 1.6X over purely software-based multithreaded execution of BWA-MEM. Furthermore, we propose a more general framework for dividing workload between the processor and accelerator in a fine-grained manner. We expect to achieve the maximum obtainable speedup (bounded by Amdahl's law) of 2X with the proposed framework.","read alignment; reconfigurable computing; heterogeneous system; POWER8; CAPI; Smith-Waterman","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","Computer Engineering","",""
"uuid:a4d94637-3be0-45b7-90af-cd04bb066871","http://resolver.tudelft.nl/uuid:a4d94637-3be0-45b7-90af-cd04bb066871","Cycling to a Railway Station: Exploring the influence of the urban environment on travel resistance","Krabbenborg, L.D.M.","Annema, J.A. (mentor); Van Wee, B. (mentor); Correia, G. (mentor); Snellen, D. (mentor)","2015","","cycling; urban environment; railway journey; access and egress","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Transport & Planning","","Transport, Infrastucture and Logistics","",""
"uuid:430d0a03-da65-4453-ad88-14658d1df18b","http://resolver.tudelft.nl/uuid:430d0a03-da65-4453-ad88-14658d1df18b","Bridging individual and collective comfort in a shared office space","Savvaki, K.","Jaskiewicz, T.J. (mentor); Keyson, D.V. (mentor)","2015","In this project an iterative approach was followed. Starting from a shapeless design through three different stages, the final proposal was formulated. The first iteration was aiming to make employees of a shared office aware of alternative ways to fight discomfort in the workplace.This proposal initiated the design process and it was kept open for enabling exploration of different opportunities. On the second Iteration a more experiential approach was adopted. Through several participatory design activities the emphasis of the iteration was led into finding ways to increase employee's care over their office performance, by opening an open dialogue between the employees and their working environments. This dialogue was further examined in iteration 3 , this time though the dialogue was shifted to colleagues that work together in a shared office. The focus of iteration 3 was he creation of a communication platform amongst the colleagues, After each design , a testing was conducted to evaluate the proposal, During this process, new knowledge was gained and the design goal was shifted. The final proposal reflects all the main findings from the previous iterations to recognise , communicate to collaborate and to act , in order to find their comfort in the workplace.","comfort management; office; indoor enviromental quality","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Design for Interaction","",""
"uuid:92700da6-1ed0-441f-9c21-e5dafa0a3a17","http://resolver.tudelft.nl/uuid:92700da6-1ed0-441f-9c21-e5dafa0a3a17","Flexible hardware accelerator for 2D Convolution and Census Transform","Van den Bor, J.","Bertels, K.L.M. (mentor)","2015","Image Processing is an emerging field: every year new applications are introduced, and these are pushing the hardware requirements. This thesis looks at the design of a hardware accelerator to accelerate several filters used in Image Processing: 2D Convolution, Census Transform, and Local Binary Patterns. At Intel, these filters are used for Convolutional Neural Networks, Gaussian Blur, Stereo Vision, and Face Detection applications. The new hardware accelerator is based on an existing Intel accelerator (the Block Matching and Bilateral Filter accelerator). The new accelerator reuses some components from this accelerator such as multipliers, adder trees, and subtraction units. This allows for a considerable reduction of the area overhead. Furthermore, the new accelerator is more flexible than the existing one because it accelerates both the new filters and the original filters and has a variable window size of 5x5, 7x7 and 11x11 that is realized by combining the results of the smallest window together. In order to analyze the performance of the accelerator implemented in this work, we compare the new accelerator with the original one in terms of speed, processor utilization, throughput, and area. We demonstrate that the average speedup for the 2D Convolution and the 5x5 Census Transform is 1,57x and 1,50x respectively. Note that higher speedups are possible when using multiple instances of the new accelerator; i.e. the maximum speedup for the 2D Convolution is 7,86x, and the maximum speedup for the Census Transform is 4,50x. In addition, the processor utilization is lowered by 12,61x on average for the 2D Convolution and 4,00x for the 5x5 Census Transform. This improvement allows the processor to perform other operations in the background or to reduce the dynamic power consumption. Throughput is obtained by considering real-time video processing. The 2D Convolution is capable of processing 4K video, and the 5x5 Census Transform can handle 8K videos. Finally, the area of the new accelerator increases with 42% compared to the original accelerator, but at system level it results in a total area increase of only 6%. Then, varying the number of accelerators provides a trade-off between speedup, processor utilization, and area usage.","Accelerator; 2D Convolution; Census Transform; Local Binary Patterns; Image Processing","en","master thesis","","","","","","","","2020-08-27","Electrical Engineering, Mathematics and Computer Science","Computer Engineering","","","",""
"uuid:a24ca984-b35a-4da6-b478-3329f7cd1f2b","http://resolver.tudelft.nl/uuid:a24ca984-b35a-4da6-b478-3329f7cd1f2b","Optimized structural design of Plug & Play Core© modular stadia during preliminary design","Van Laar, D.D.D.","Terwel, K.C. (mentor); Nijsse, R. (mentor); Veer, F.A. (mentor); Tünnissen, J. (mentor)","2015","Modular construction is the on-site assembly (installation and connection) of factory made units (Lawson et al., 2014). It allows fabrication of structural components to be moved from the building site to controlled environments. Ballast Nedam adopted modular construction as a key business strategy for the future (Ballast Nedam, 2014). Plug & Play Core is the modular and reusable structural core of a stadium. After realization, the inner core of the stadium can be easily disassembled, transported to another location and reused. Various stadium layouts can be realized, making the concept easily adaptable to the (varying) demands of the client/architect. The Plug & Play Core structural design needs to be easily adaptable to changing (tender) demands. At the same time the design process needs to be quick(er), resulting in more time for actual integral design. The design itself should primarily comply with safety codes, while the financial consequences of structural design decisions on other integral design aspects should be clear. An optimized design process in the form of a structural design tool is proposed to solve these challenges. The design tool should integrate FEM software for structural verification. First a literature search is performed to obtain necessary background information. After, a short summary of key design aspects regarding Plug & Play Core is presented. Then the design tool called Toolbox is explained in the form of a design manual. The main part of the report is ended with a case study of a demountable upper tier for the FIFA WC2022 Al-Wakrah stadium in Qatar. In that chapter the Toolbox design tool is applied to real project data. It is found that the integral design process of Plug & Play Core modular stadia can be optimized by the use of a design tool like the Toolbox. Early-stage consideration of full life-cycle design aspects via a cost analysis in combination with standardized structural analysis, makes the design process quick(er) and allows the designer to generate various design alternatives in a relatively short amount of time. This results in more time for integral optimization of the design. The case study insinuates that cost savings could be achieved by application of the Toolbox, making Plug & Play Core modular stadia more appealing regarding traditional construction alternatives.","modular; construction; stadia; Plug & Play Core; preliminary design; optimization; structural design; process","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Design & Construction / Structural and Building Engineering","",""
"uuid:b25a445c-dbd3-48a2-acca-008a83d06345","http://resolver.tudelft.nl/uuid:b25a445c-dbd3-48a2-acca-008a83d06345","Ultra-high performance fiber-reinforced concrete in incremental bridge launching","Oostra, A.J.","Hordijk, D.A. (mentor); Van der Veen, C. (mentor); Van der Horst, A.Q.C. (mentor); Reitsema, A.D. (mentor)","2015","Incremental bridge launching is one of the many ways in which a bridge can be constructed. In The Netherlands this method is not often used. This may be explained by the fact, that there are not many suitable locations for application of this method. Incremental bridge launching is profitable for long bridges and can only be used for straight bridges or when the superstructure has a constant horizontal and vertical radius throughout the length. However, when the preconditions for use of this method are met, incremental bridge launching can be a great solution for bridge design. Ultra-high performance fibre-reinforced concrete (UHPFRC) is a new concrete. In contrast to regular reinforced concrete, UHPFRC contains fibers to provide for the capacity that is necessary when the concrete is loaded in tension. However, as for incrementally launched bridges, its application is limited as of yet. One explanation for the reluctance to use the material, is that compared to regular concrete, the cost of production are many times higher. To make economical designs using UHPFRC, the high cost of production need to be recovered by material savings, when a structure is executed or during its lifetime. The aim of this thesis is to identify whether a superstructure designed in UHPFRC can increase the application range of incremental bridge launching in The Netherlands, and to explore whether the concept can compete with other bridge designs. In order to make a statement, a case study approach is used. It concerns the launch of the eastern approach bridge of the bridge over “Het Pannerdensch Kanaal”, designed in UHPFRC. The location suits incremental bridge launching perfectly, as there is a constant horizontal and vertical curvature in the alignment for over 550 meters. The most favorable cross-section for incrementally launched bridges is a box girder. A comprehensive analysis on the cross-sectional capacity of a prestressed box girder, designed with different concrete strength classes, is performed to optimize the shape. The design of a box girder takes a special procedure, where both the transverse and longitudinal directions are considered separately. Transverse bending moments and shear forces, due to mobile loading, are obtained with influence surfaces and the differential equation of the Euler-Bernoulli bending beam. For the longitudinal direction, a spreadsheet is developed to identify the bending moments and shear forces that occur during launch and service life. The force method for analysis of indeterminate structures is used to determine the governing bending moments for this multiple span bridge. Also, the sheet contains parts to determine the required amount of central and continuity prestressing and to optimize the length of the steel nose to reduce the peak moments during launch. The use of UHPFRC in the design of a structure requires a special approach. Requirements regarding quality control are strict and need to be prescribed to allow on-site production. The typical characteristics of UHPFRC have an important impact on the execution and production cycle of the incrementally launched bridge, which is therefore investigated. The case study is used to investigate the competitiveness of the design. Cost of production and execution are integrated into a price per cubic meter of concrete and compared to the design of The Zeeburgerbrug, which was launched and built with regular concrete. Efficient use of UHPFRC allows a light box girder design, which can be launched without auxiliary supports. Conventional and shear reinforcement are not necessary. Transverse and longitudinal prestressing provide sufficient bending moment capacity, while the fibers contribute to a huge shear capacity that is more than enough to withstand the shear forces. The required amount of central and continuity prestressing does not fit in the concrete cross-section. Therefore, all tendons are applied externally. The anchors and deviators will not fit in the concrete cross-section either. The cost comparison shows, that a lot of the higher cost of production of UHPFRC can already be compensated during the design and construction phases. The remaining part of the higher cost of production of UHPFRC need to be compensated differently, for instance by savings in maintenance cost due to better durability properties or by a lighter substructure, as we are able to generate proper savings in the amount of concrete for the superstructure. The case study proves that when the superstructure is considered only, it might be hard to design and execute the UHPFRC box girder more economically than the design of The Zeeburgerbrug. However, when we consider the total bridge over the entire service life, we might have a competitive design. Alternative bridge designs, that use different construction techniques should be developed to assess the competitiveness of the incrementally launched UHPFRC box girder for that location.","uhpc; concrete bridge; incrementally launched bridge","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Concrete Structures","",""
"uuid:51b1f334-fc9a-4dce-b0bd-a41fb9ef92a1","http://resolver.tudelft.nl/uuid:51b1f334-fc9a-4dce-b0bd-a41fb9ef92a1","A CANS-preventing posture-coaching shirt accompanied by an application that is positioned in a world of professionals","Moerman, R.A.","Simonse, L.W.L. (mentor); Creusen, M.E.H. (mentor)","2015","Goal of the graduation project is to make a market proposition for an existing innovative product, the FysioPal. This is done by researching the internal and external market environment as well as the stakeholders that can be influencing in the business model network of the product-service FysioPal. By combining the insights found internal as well as external, infographics have led to personas and a customer journey. This has been the basis of the business model of the product that forms, together with the product principles, the product proposition.","proposition; netmap; customer journey; ergonomics; sedentary bahavior; CANS","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product Innovation Management","","Master of Science Strategic Product Design","",""
"uuid:1e544f00-c338-466e-8cbe-eeb6505a0acd","http://resolver.tudelft.nl/uuid:1e544f00-c338-466e-8cbe-eeb6505a0acd","Invoice Financing for Small and Medium-sized Enterprises on an Online Platform: An Action Design Research using a Transaction Cost Perspective on Platform Theories applied in a Start-up","Pieper, S.J.","Reuver, G.A. (mentor); Janssen, M.F.W.H.A. (mentor); Scholten, D.J. (mentor); Keijzer-Broers, W. (mentor)","2015","Access to financing is a serious concern for many Small and Medium-sized Enterprises (SMEs) in need of cash. Invoice financing ? in which a business sells its accounts receivables ? has not been well adopted, seemingly due to the information intensive transactions that it requires. This paper describes the design of a digital Multi-sided Platform that provides invoice financing to SMEs to overcome this problem. It does this by deriving design guidelines from transaction cost literature and concurrently ‘action designing’ a live prototype. The results of the evaluation of the prototype show that the design is a promising solution for SMEs in need of liquidity, as it is being evaluated positively on the criteria aimed at lowering the transaction cost of invoice financing. More design research is suggested on the impact of a platform setup on transaction cost.","Action Design Research; Information System Design; Transaction Cost Economy; Multi-sided Platforms; SME Financing","en","master thesis","","","","","","","","2016-08-27","Technology, Policy and Management","ICT","","SEPAM IA","",""
"uuid:1fe13f50-2352-40e7-8d27-94ded8110e23","http://resolver.tudelft.nl/uuid:1fe13f50-2352-40e7-8d27-94ded8110e23","Exploring Depth Estimation on Intel IPU Platform","Iorga, D.","Bertels, K. (mentor); Nane, R. (mentor)","2015","Numerous applications from autonomous vehicles to surveillance systems can benefit from ""seeing in 3D"". A crucial element of sight is depth detection since this enables evaluation of position and shape. The depth at which objects are located can be estimated by using two or more cameras and comparing the resulting images. Despite the increasing popularity of these algorithms, available solutions require expensive high-end platforms, which are not suitable for commercial applications. These motivate the search for a cheaper alternative and in this work, we provide a low-cost, low-power embedded solution to determine the depth at high speed. A highly parallel but not inherently complex processor architecture is required for this tasks. VLIW processors are the best choices, and the Intel Image Processing Unit is an excellent option. By adding different functional units to it and adjusting an algorithm to take full advantage of them, a 640x480 image pair with 64 disparities can be processed at 36.75fps, which is an improvement of 23\% compared to the best state-of-the-art image processor.","depth; VLIW","en","master thesis","","","","","","","","2020-08-27","Electrical Engineering, Mathematics and Computer Science","Computer Engineering","","Embedded Systems","",""
"uuid:da50ae5f-2188-43d6-ac4a-8b51ca6f1b86","http://resolver.tudelft.nl/uuid:da50ae5f-2188-43d6-ac4a-8b51ca6f1b86","Implementation of sustainable technology into footwear","Heredia, G.H.","Bakker, C.A. (mentor); DaSilva, O. (mentor)","2015","This master thesis explores and develops a sustainable footwear solution. An aesthetics approach was taken in parallel in the attempt of creating a timeless design.","footwear; sustainability; aesthetics","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Integrated Product Design","",""
"uuid:b56e9888-14d7-4113-b523-438354f55fc0","http://resolver.tudelft.nl/uuid:b56e9888-14d7-4113-b523-438354f55fc0","Investigation of the Inhibition Effect of Basic Oxygen Furnace Slag on the Corrosion of Galvanized Steel","Van Dam, J.P.B.","Mol, J.M.C. (mentor)","2015","Basic oxygen furnace (BOF) slag is a by-product of the steel conversion process in a basic oxygen furnace. A previous study at Tata Steel in Ijmuiden has discovered the inhibition effect of BOF-slag on the corrosion of cold rolled- and hot-dip galvanized steel. This inhibition effect and its mechanism was studied in this work and its was attempted to incorporate BOF-slag as a corrosion inhibitor pigment in an organic coating. Its inhibition capacity was first assessed on bare galvannealed and hot-dip galvanized (Zn-Mg-Al) steel and its performance was benchmarked against commercially available corrosion inhibitors. The inhibition effect of BOF-slag on the corrosion of both substrates in a 0.1M NaCl aqueous solution was confirmed by linear sweep voltammetry and it proved to have the highest inhibition efficiency of all tested corrosion inhibitors. The inhibition mechanism was further studied by electrochemical impedance spectroscopy (EIS),ICP-MS, SEM-EDS and XPS. The results showed the slag solution consisted of colloidal silicates, which upon anodic dissolution of zinc react with the zinc cations and precipitate on the surface. A protective gel-like network film is deposited on the surface, hereby suppressing both the anodic and cathodic current and reducing the corrosion current density by almost two decades. A pigment was retrieved from the slag particles and was successfully incorporated into an organic waterborne coating and applied to both substrates. The corrosion resistance and barrier properties were evaluated by EIS and salt spray tests (SST). The results show the slag particles had a negative effect on the mechanical and barrier properties of the coating and caused severe damaging of the coating as a result of minor deformation. The particles showed no tendency to restore some of the corrosion resistance of the coating after damaging. Chemical analysis showed the pigment was retrieved from Ladle furnace slag instead of BOF-slag. This explained inability of the pigment to restore the barrier properties of the coating or to inhibit the corrosion of the underlying substrate.","corrosion; corrosion inhibitors; BOF slag; hot-dip galvanized; EIS; SST; X-ray photoelectron spectroscopy","en","master thesis","","","","","","","","2016-08-01","Mechanical, Maritime and Materials Engineering","Materials Science & Engineering","","","",""
"uuid:3762ee57-0e0e-4012-bb35-157bd14961bf","http://resolver.tudelft.nl/uuid:3762ee57-0e0e-4012-bb35-157bd14961bf","Large Deviations for Markov Jump Processes and Hamiltonian Trajectories","Driessen, D.M.","Redig, F.H.J. (mentor)","2015","This master thesis is concerned with Large Deviation Theory in combination with Lagrangian and Hamiltonian dynamics. In particular, the Large Deviation behaviour of the empirical distribution of n independent two-state continuous-time Markov processes is studied. We start by looking at the general theory of Large Deviations in both the finite dimensional case as well as for infinite dimensional stochastic processes. After this, the connection is shown of Large Deviation Theory with Lagrangian and Hamiltonian dynamics. The Hamiltonian of the empirical distribution of n independent two-state Markov processes is derived and using this, via the Hamilton equations, the dynamics of this process are derived. That is, the most likely path that is taken when in time T we force the path to start in state a and end in state b. The main goal of this thesis is to find out more about the dynamics of this process (behaviour of the trajectories) and to derive an explicit equation for the so-called Action integral. We want to compute the Action for the general case. That is, the case in which the rate going from state one to state two can differ from the rate going from state two to state one. Once the Action integral is computed we look at the asymptotic behaviour of this Action integral. This is important as it says something about the probability of some trajectories occurring for T an extreme. We look at the asymptotics for both T in the limit to zero and T in the limit to infinity.","Large Deviation Theory; Markov Jump Processes; Hamiltonian dynamics; Lagrangian","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","","",""
"uuid:5dc275ca-cdfb-4104-bec8-2d1665cd04a5","http://resolver.tudelft.nl/uuid:5dc275ca-cdfb-4104-bec8-2d1665cd04a5","Design of Convex Guidance for the Final Phase of Satellite Rendezvous: Tested using Hardware-in-the-Loop Simulations","Vromen, S.S.","Mooij, E. (mentor)","2015","Over the past decades the steep increase in the number of space-debris objects have sparked many studies into active space-debris removal. Past collisions have shown that space debris is a very real threat to operational satellites and active debris removal is necessary to stabilize the situation. ESA has, therefore, performed multiple studies on the removal of the no longer operational satellite ENVISAT from orbit. Since ENVISAT lost functionality, it has acquired a tumbling motion, which poses many challenges for a removal mission. A scenario was proposed in which a chaser spacecraft performs a rendezvous with ENVISAT, to actively de-orbit the satellite. To increase the robustness to unexpected events and reduce operational costs it is highly desirable that these operations can be performed autonomously. In this research an autonomous guidance and orbit control system was developed that enables the final phase of the rendezvous with ENVISAT. An approach strategy was adopted that aims to maintain alignment with the spin axis of ENVISAT throughout the approach. The designed algorithms use convex guidance to ensure globally-optimal solutions, while at the same time constraining the trajectory. The guidance algorithm minimizes a weighed combination of the thrust and the state error. Furthermore, the concept of model predictive control is applied to allow for an unconstrained time-to-go. Two guidance and control strategies were examined in this research, one that is solely based on model predictive control and another that employs an additional LQR-controller. The functional simulations were complemented by hardware-in-the-loop simulations using the DLR flat-floor test facility, TEAMS. These real-time tests also include the docking phase. Both the functional and hardware-in-the-loop simulation results show that the baseline model predictive control method can successfully perform the operations with an accuracy well above the requirement. It was found that implementing an extra LQR controller resulted in a similar accuracy, but an increase in mission propellant of 21%. The functional simulation results also revealed that the required mission propellant, compared to the baseline, could be decreased further by 18%, while maintaining the baseline accuracy. This is achieved by optimizing the weight parameters used in the convex optimization. It does, however, lead to an increased mission duration. The designed algorithms were successfully implemented on TEAMS, where it was shown that the addition of an LQR controller again leads to a higher use of propellant and on top of that it results in a longer operation time.","Rendezvous; Hardware-In-The-Loop; Guidance; Convex","en","master thesis","","","","","","","","","Aerospace Engineering","Spaceflight","","Space Exploration","",""
"uuid:9339e436-88c4-4d92-8399-7eac1680c24c","http://resolver.tudelft.nl/uuid:9339e436-88c4-4d92-8399-7eac1680c24c","SMoT: A Smartphone-Based Mobile Testbed for Human-Centric Wireless Networks","Efstathiadis, P.","Langendoen, K.G. (mentor)","2015","Recently, wireless sensor networks (WSNs) are becoming vital to a wide range of application domains, from precision agriculture and smart buildings to health systems and monitoring of humans, animals, crowds and robots. In particular, there is an increasing number of sensor devices that are worn by persons who interact with them on a daily basis. In these applications, networks are formed by the persons who wear the sensor devices and as a result the mobility comes from them. This results in new protocols and applications for this kind of networks and new challenges arise. Human factors are crucial aspects in this case and researchers should consider them in their designs. The protocols and applications developed, should be tested and verified before their final deployment. We argue that a testbed, exposing the human characteristics is needed. In this thesis, we define the fundamental requirements that a testbed for experimentation with human-centric wireless networks must fulfil. We design and implement a fully functional testbed that allows researchers to run experiments in a realistic and controlled testing environment. We show that our testbed has the appropriate features and tools to make the running of the experiments easy and effortless. In addition, our testbed gives the ability to the researchers to observe how human diversity and variability (like body orientation or walking speed) affect their work. Furthermore, we evaluated the mechanisms of our testbed and present how they affect the execution of an experiment.","testbed; wireless sensor networks; wearables","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Embedded Software Group","","MSc Embedded Systems","",""
"uuid:7244dca5-e0f1-4f5f-a893-f8548de5495f","http://resolver.tudelft.nl/uuid:7244dca5-e0f1-4f5f-a893-f8548de5495f","Influence of Seed Surface Pre-Processing on Crystal Growth Behavior in Cooling Batch Crystallization","Westerlaken, T.P.","Kramer, H.J.M. (mentor); Stankiewicz, A.I. (mentor)","2015","Product quality and yield of pharmaceuticals produced by traditional industrial seeded batch cooling crystallization-operations is subject to large fluctuations as a consequence of seed surface quality. In this research, effects of seed pre-treatment by dry- and wet-milling were investigated on subsequent performance in crystallization behavior by measuring crystal growth rate, with comparative reference, in both stagnant and suspended, turbulent media. It has been shown that pre-processed paracetamol-seeds grew at a lower rate compared to non-processed seeds in stagnant conditions, whereas examination of the effect of seed surface healing increased growth rates. Separate experiments with suspended seeds of paracetamol and lactose in turbulent media, analyzed by in situ crystal size-measurements on growth rate, were found subject to attrition and agglomeration respectively. Consequently, processing of image-analysis, relating to crystal growth, was found inadequately performed.","crystallization; seeding; surface quality; milling; crystal growth; paracetamol; lactose; image-analysis","en","master thesis","","","","","","","","2019-08-26","Applied Sciences","Chemical Engineering","","Process Engineering","",""
"uuid:e64fc3c8-5e40-4940-b5f5-c54f842f8feb","http://resolver.tudelft.nl/uuid:e64fc3c8-5e40-4940-b5f5-c54f842f8feb","Multi-Criteria Supplier Selection in the Edible Oil Industry: The Case of a New Oils & Fats Plant in China","Nispeling, T.","Rezaei, J. (mentor); Tavasszy, L.A. (mentor); Pang, Y. (mentor); Wan Ahmad, W.N.K.B. (mentor)","2015","The process of supplier selection is regarded as a critical step in the development of a competitive supply chain. The share of raw material purchasing in the total turnover of industrial companies can range between 50 to 90%, which underlines the importance of selecting the right suppliers for a company. This thesis aims to create a framework for the selection of suppliers. A ranking will serve as the basis for advice on the optimal supply base. Multiple criteria are extracted from the organization and integrated in a framework that ranks the suppliers based on their performance. This is subsequently implemented in a problem situation in order to reflect on the value of the framework for with respect to the supplier selection process. The realization of a new oils and fats plant in China provides the problem situation and it is used as a case for this thesis. Currently the company is not aware of the availability of suppliers and the method of selection. Implementing a framework within a case company will be beneficial in two ways. On the one hand this thesis will allow a scientific theory to be implemented in the structure of a commercial corporation so its actual use can be determined, a step that in literature is often recommended but not taken. On the other hand the company will be provided with an insight in value of academic knowledge and how it can contribute to the development of a supply chain strategy. In order to reap these benefits a literature research is conducted on supplier selection and the related topics like sourcing, selection criteria and sustainability. This will provide a knowledge-base to work from. Subsequently the methodology describes the specific method used to create the framework, which is called the Best-Worst Method. This method is chosen because of its ability to produce reliable results with a low amount of comparison data. An extensive data collection has a twofold approach. Data is required for the design of the selection method. This involves obtaining industry specific criteria and their weights in order to make a distinction on their importance. A more practical approach is required for the rest of the data collection. This is on the available suppliers, located not only in China, but also in Asia and beyond. Once identified, contact with the suppliers is required to determine their abilities and characteristics. Substantial effort is made on the exploration of the transportation market in Asia, as different products with different modes will be transported to the new plant. The analysis of this data will be conducted according to the steps of the Best-Worst Method. The obtained data is used to determine the scores of the suppliers on the different criteria. Together with the weights of the criteria a final score can be calculated, which is the basis for the supplier ranking. To come to a meaningful advise that aligns with the operations of the case company, optimizations are performed on product importance and the transportation mode. This outcome is complemented with a presentation of the practical implications encountered during the research. These regard the transportation, the storage of raw materials, the certification and qualification in the Chinese market and on the management and organization of the new plant. The conclusion provides an answer on how a multi-product company can execute its supplier selection process. Finally the discussion reflects on the method, which is perceived to be a valuable and easy to use tool. A fragility of the method is the possibility for validation as no robust options for this are available. The framework is perceived to be valuable, because it allows the company and its employees a better insight on the selection problem, by which the complexity is reduced. Its ability to deal with extreme values however, is limited and must be kept in mind. A note on the dynamics of the problem situation concludes the thesis. It is incorporated in the thesis, to increase the usability and value of the framework over time. It provides an overview of the most important and likely factors that will affect the problem context in the near future.","Supplier Selection; Multi-Criteria Decision-Making; Best-Worst Method; Edible Oil Industry; China","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Transport, Infrastructure & Logistics","","Engineering","",""
"uuid:3aabc289-22d3-4791-a508-b11cf8312bb0","http://resolver.tudelft.nl/uuid:3aabc289-22d3-4791-a508-b11cf8312bb0","Pool: An activity kit that builds understanding within the families of teenagers with cancer","Dsouza, A.","Rozendaal, M. (mentor); D' Olivo, P. (mentor)","2015","Pool is an activity kit that helps family members to connect with each other and builds family strength, by making them more aware and appreciative of each other. It builds on the idea that more aware and appreciative family members can lead to a greater perception of family strength. This family strength leads to a greater sense of self efficacy; the family feels more capable of handling their challenging situation. Pool was developed under the ‘Meedoen= Groeien!” project, which is a collaboration between the Rehabilitation Fund, the Princess Máxima Center for Pediatric Oncology (PMC) and the Delft University of Technology (DUT).","cancer; teenagers; development oriented care; research through design; family therapy","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Design for Interaction","",""
"uuid:33108b7b-57f6-46f4-b96a-17f4bc3d2c3d","http://resolver.tudelft.nl/uuid:33108b7b-57f6-46f4-b96a-17f4bc3d2c3d","Design of a Variable Mechanical Advantage Mechanism for the Delft Cylinder Hand","Schipperen, R.D.","Plettenburg, D.H. (mentor)","2015","The Delft Cylinder Hand and similar body powered hand prostheses require an input force that is too high for daily tasks. The force is perceived as uncomfortable and leads to a high rate of users abandoning their prosthesis. Reducing the input force by increasing the mechanical advantage of the system is not feasible, as this would unfavourably increase the required input displacement to close the prosthetic hand. The goal of the research is to significantly reduce the input force, without exceeding the input displacement limit by designing a variable mechanical advantage (VMA). The VMA is specifically designed for the Delft Cylinder Hand. The input force, when applying a 30 N pinch force, should always be lower than 50±4 N, without compromising the 53 mm maximum input displacement. Two load cases are used to determine the VMA properties, the worst-geometry load case and the realistic-pinch load case. Calculations show that a VMA design is feasible for the Delft Cylinder Hand. In the case of the worst-geometry load case, a design is only feasible when friction losses are excluded, while for the realistic-pinch load case the friction losses can be included. Simulations confirm that the designed VMA mechanism is able to pinch an object with 30 N, with an input force lower than 50±4 N for the feasible loading conditions. Practical testing was too inconclusive to validate the simulation.","variable mechanical advantage; Delft Cylinder Hand; body-powered prosthesis; hydraulic","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Biomechanical Engineering","","","",""
"uuid:7d147a5f-2f40-4b34-b1d6-13c04f079862","http://resolver.tudelft.nl/uuid:7d147a5f-2f40-4b34-b1d6-13c04f079862","Optimale importance sampling in Markovketens: Efficiënte simulatie zeldzame gebeurtenissen","Scholten, F.J.M.","Meester, L.E. (mentor); Dubbeldam, J.L.A. (mentor); Keijzer, M. (mentor)","2015","Toepassing importance sampling op credit risk probleem met onafhankelijke schuldenaren.","importance sampling; credit risk; monte carlo; variance reduction","nl","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","","",""
"uuid:d5c33e2e-b6d7-4694-a9b4-7a7fe7129ec9","http://resolver.tudelft.nl/uuid:d5c33e2e-b6d7-4694-a9b4-7a7fe7129ec9","Partially prestressed railway bridge","Jongstra, E.","Hordijk, D.A. (mentor); Van der Veen, C. (mentor); Kolstein, M.H. (mentor)","2015","Building and maintenance of the railway track and its sub- and superstructures in the Netherlands are commissioned by ProRail. In addition to the Eurocode ProRail prescribes a wide range of regulations and guidelines related to railway track. Amongst these are a few specifically for the design of civil structures. With respect to prestressed concrete structures ProRail deviates from the Eurocode by demanding fully prestressed concrete. Partially prestressed concrete nowadays is often used in structures carrying road traffic (although not in prefab beams or girders) and is allowed according to the Eurocode. Main reason for fully prestressed concrete for railway bridges would be that partially prestressed structures are more prone to effects of fatigue loadings. However, in prestressed concrete not only prestressing tendons but also reinforcement is applied. Longitudinal reinforcement is present, but is of no use in service phase when a concrete section is almost totally in compression. There may be some economical benefit to allow a lower amount of prestressing and to make use of the capacity of the present reinforcement. In this thesis an existing prestressed railway bridge is used as a case study to determine the minimum prestressing degree leaving all other parameters like concrete dimensions, material properties and applied reinforcement undisturbed. ProRails rule is therefore deliberately ignored. The existing structure is designed according to former Dutch national regulations. A comparative design is performed to determine main differences in design checks between those regulations and the current Eurocode. It turns out that according to the current Eurocode and regulations of ProRail the existing structure is not fully prestressed. It was according to the former Dutch national standards. This means that structures designed according to the Eurocode need to be bigger, heavier, stronger than they would be according to the former Dutch national standards. On one hand the loads on a bridge are higher and on the other hand the regulations of ProRail seem to have become stricter. Since the dimensions of this analysed structure approaches its limits, measures are not easily taken to meet the requirement of fully prestressing. By analysing this structure as a partially prestressed bridge, it turns out that circa 15% of the prestressing could have been saved. The present reinforcement is just about enough to meet the requirement of the limited crack width. It approaches the limits with respect to fatigue, but that is not leading in this case. It is just a slight reduction and the economical benefits regarding a trough bridge will not be that large. But it offers an opportunity to review ProRails rule for fully prestressed concrete. In that case future structures do not need to become bigger than they would be according to the former Dutch national rules. Furthermore existing structures could meet the current requirements according to the Eurocode as well. This may be beneficial in cases where current structures near their service lifetime and need to be reassessed.","railway bridge; partially prestressing; trough bridge; reassessment","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Concrete Structures","","51.709483, 5.350870"
"uuid:3850a8ec-d6aa-4f7d-a3ae-2f48f53cc148","http://resolver.tudelft.nl/uuid:3850a8ec-d6aa-4f7d-a3ae-2f48f53cc148","Citizen Science in Water Quality Monitoring: Developing Guidelines for Dutch Water Authorities for Contributory Mobile Crowd Sensing","Minkman, E.","Van der Sanden, M.C.A. (mentor); Rutten, M.M. (mentor); Wehrmann, C. (mentor); Van Overloop, P.J.T.A.M. (mentor); Van de Giesen, N. (mentor); De Vries, M.J. (mentor); Kaspersma, J.M. (mentor)","2015","The Dutch water management system is confronted with a lack of awareness among citizens and further faces the consequences of climate change and urbanisation. New governance structures with high levels of citizen participation are required to be fit for the future. An implementation of participation could be citizen science, which is rather unexplored in Dutch water resource management. The thesis’ objective was to develop practical guidelines for practitioners at Dutch water authorities on ‘how to set up a citizen science project’. To get to this objective several research methods and steps were taken. This thesis provides an answer to how Dutch water authorities could incorporate citizen science in their activities, by focussing on the driving forces of both citizens and water authorities whether to engage in citizen science projects mediated by a mobile crowd sensing device. A literature review and case study were used to identify key success factors for citizen science projects. A survey, based on the Self-Determination Theory, was used to identify citizen motivations in water quality monitoring. Using a Q methodological approach three viewpoints on citizen science at water authorities were identified. Additionally it is investigated what role modern technology, such as mobile sensing, could play in designing a citizen science project using a Technology Acceptance Model. The developed guidelines answer how citizen science could be implemented at Dutch water authorities to increase citizens’ water awareness and to adopt governance structures with higher levels of citizen participation.","Citizen science; Water authority; Water quality monitoring; Design-based research; Q methodology; Technology Acceptance Model","en","master thesis","","","","","","","","","Delft University of Technology","Applied Sciences & Civil Engineering and Geosciences","","Science Communication & Water Management","",""
"uuid:dff01b69-679e-4426-bc13-225f0ba0fa80","http://resolver.tudelft.nl/uuid:dff01b69-679e-4426-bc13-225f0ba0fa80","Outsourcing maintenance of road infrastructure in Uganda: Performance-based contracting in sub-Saharan African context","Van Ham, J.P.","Hertogh, M.J.C.M. (mentor); Schoenmaker, R. (mentor); De Jong, W.M. (mentor)","2015","","","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Integral Design and Management/Construction Management and Engineering","",""
"uuid:f066fcbc-ba42-4bd5-8d5d-03b17b7984bd","http://resolver.tudelft.nl/uuid:f066fcbc-ba42-4bd5-8d5d-03b17b7984bd","A Vermicomposter for Urban Kitchens","Wadhwa, S.","Van de Geer, S.G. (mentor); Buijs, J.A. (mentor)","2015","High moisture content of kitchen waste makes it unsustainable for it to be transported and incinerated. In comparison, composting at home is a much more sustainable option, upcycling waste into rich compost odourlessly. However, it is inaccessible for apartment dwellers in urban areas in the Netherlands due to space limitations. Vermicomposting is a version of the process using special compost worms that is more manageable indoors, but existing products do not fit kitchen use (where the waste is generated) in form or function, are difficult and messy to use, especially for new users. The HomeComposter is an all new vermicomposting system designed specifically for ‘Cosmopolitans’ and fulfils their wish to be less wasteful but in a convenient way. It holds composting worms safely and securely and can accommodate accommodate 250g of waste on a daily basis (national average for a household of two people). The worms stay in the top region to process incoming waste, while in a couple of weeks the vermicompost starts collecting near the bottom, ready to be ‘harvested’. When the bin is full, the unique ‘compost drawer’ can be pulled open and compost removed in a tray. The rear part of the drawer ensures that no compost falls from above during harvesting. This harvesting design is simple and tidy, unlike any other bin. Vermicomposting also produces a nutritious percolate which the sieve-like tray design guides to a glass bottle below. The bin comes with a ‘conditions’ monitor on top to give feedback to the user on how his new pets are doing. A transparent window in the front with compost behidn it emphases the natural process within.","sustainability; vermicomposting; worms; composting","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Master of Science Integrated Product Design","",""
"uuid:ac447758-5310-445e-b901-59f93afc8f50","http://resolver.tudelft.nl/uuid:ac447758-5310-445e-b901-59f93afc8f50","Challenger brands: Developing guidelines to support the creation of packaging design for challenger brands","Spoelder, L.E.","Mugge, R. (mentor); Van den Hende, E.A. (mentor)","2015","The term challenger brand shows up more and more in the marketing world. These are brands that are not the number one in their category and try to gain market share by acting on a certain challenge. This challenge is embodied by breaking the conventions of the category they are in. The lack of resources that challenger brands characterize makes that packaging is an important medium. For challenger brands, packaging design can be their only asset through which they can advertise. Packaging consultancy CARTILS has been experiencing a new wave of brands that are not established in the market and need to find a way into the category. It is found that their current packaging design tools do not apply to the development of packaging for this type of brands. This thesis will therefore focuses on developing guidelines for the successful development of challenger brand packaging. From literature research and the analysis of existing challenger brands, it is found that challenger brands need to evoke attention. Differentiating their packaging design can draw this attention. Many researches on differentiation and categorization conclude that moderate packaging deviations will give the best result in the trade off between drawing attention and avoiding negative evaluations (Schoormans & Robben, 1997; Blijlevens et al., 2012). However, from the analysis of existing challenger brands across several product categories, the packaging of the brands clearly show high levels of differentiation. This would mean that challenger brands are an exception to this ‘moderate deviation rule’. Next to inducing attention it was found that the packaging design should invite the consumer to gain insights about the brand and find out whether they share values. Challenger brand packaging should be able to express their identity and tell their brand story, but also persuade their target group that their product is for them. This persuasion can only be done when a possible target customer is triggered to gain more insights and explore their shared values. Eventually the challenger brand should find a way to enter social conversation, and let their consumer perform word-of-mouth advertisement. It is through social conversation that challenger brands can reach their audience and find their way into the category. Research is set up to examine the influence of differentiation and brand story elements on product evaluation when dealing with a challenger brand. Although prior research has found that higher levels of differentiation will lead to a negative product evaluation, it is proposed that high levels of differentiation in combination with brand story elements will lead to a positive evaluation. It is also proposed that high levels of differentiation in combination with brand story elements will lead to a want for more information and increase of word-of-mouth advertisement. For two spirit categories, whisky and vodka, a challenger brand story was developed including all necessary challenger ingredients according to literature analysis. For both categories, six packaging designs were systematically designed: a low-, medium- and highly differentiated design, all three with- and without visual brand story elements. The visual brand story elements were developed to tell the challenger brand story as clear as possible. An experimental context (n=147) was used to test how consumers respond to the different levels of differentiation for both packaging designs with- and without brand story elements. After a follow-up test, findings show that high levels of differentiation increase the attention induced by the packaging, and do not have a negative result on the product evaluation. Brand story elements were found to have a positive influence on the evaluation of the highly differentiated packaging designs. For highly differentiated designs it was also found that brand story elements increased the want for information by the respondent, as did it increase the likeliness of word-of-mouth advertisement. The findings from the performed studies provide reasons for packaging designers to design a highly differentiated design and to explicitly tell the brand story through brand story elements. This will give challenger brands the opportunity to express their identity; through their packaging but also because consumers will search for more information about the brand. Finally the brand will enter social conversation, since word-of-mouth advertising is more likely. From the analysis of literature, of existing challenger brands and the conclusions from the studies performed during this project, the Challenger Diamond packaging guidelines are developed. The Challenger Diamond consists of three elements; ‘express your identity’, ‘be different’ and ‘be single-minded’. ‘Express your identity’ is the umbrella guideline. Their brand story should be expressed by brand story elements in order to express their identity; their values and their passion. ‘Be different’ provides systematic design steps in order to decide which category codes should be pursued and which category codes should be discarded in order to develop a highly differentiated packaging design. ‘Be single-minded’ emphasizes the importance of focusing on the specific target audience of the challenger brand. These three elements together form the base for developing packaging design for challenger brands. When each of these aspects is taken into account properly, a strong base can be set for the development of the challenger brand packaging design. This thesis is concluded with a short case study, in which the design guidelines were applied for the development of a packaging design for a fictitious challenger brand. Through a small qualitative research the packaging, and thereby the success of the Challenger Diamond is confirmed.","challenger brands; packaging design; differentiation; brand story","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Strategic Product Design","",""
"uuid:46bfe87b-c334-49e2-b7f4-9f7946ea94f6","http://resolver.tudelft.nl/uuid:46bfe87b-c334-49e2-b7f4-9f7946ea94f6","Improving Feed-in tariff policy design for solar PV: Learning lessons from the experiences of Greece, Spain and Germany","Tsikintikou, M.","","2015","","","en","master thesis","","","","","","","","","Applied Sciences","Energy and Society","","Sustainable Energy Technology (SET)","",""
"uuid:4ef56c0f-1dbd-4edb-8b89-f672dd3597ec","http://resolver.tudelft.nl/uuid:4ef56c0f-1dbd-4edb-8b89-f672dd3597ec","Design and Analysis of Swirl Recovery Vanes for an Isolated and a Wing Mounted Tractor Propeller","Stokkermans, T.C.A.","Veldhuis, L.L.M. (mentor); Eitelberg, G. (mentor)","2015","In light of the energy crisis of the early 1970's, NASA and industry gained a renewed interest in high-speed propellers for improved propulsive efficiency and explored the idea of swirl recovery vanes (SRV) to generate a net thrust from the residual swirl in the propeller slipstream. After this first effort on the aerial application of SRV, only recently research is resumed. When a wing is introduced in the slipstream of a propeller, for instance for a wing-mounted tractor-propeller, conclusions drawn on SRV in isolated condition may not hold. The objective of this research is to gain an improved understanding of the aerodynamic interaction between the propeller and swirl recovery vanes in an isolated configuration and wing-mounted tractor arrangement in the cruise condition and in a high-thrust condition. This study is realized by performing a series of transient Reynolds-averaged Navier-Stokes CFD simulations of a propeller with and without SRV in an isolated and installed configuration. Throughout this research the 6-bladed propeller of the European APIAN project is used. Available experimental propeller performance, blade pressure and slipstream measurements are used to validate the isolated propeller CFD model. Within the limitations of fully turbulent modelling of the boundary layer by means of automatic wall functions, good agreement is found with the experimental data, including the existence of a conical separation vortex at low advance ratios. Simulated performance and slipstream results are presented of the APIAN propeller with SRV designed for the APIAN-INF test program in the DNW-LLF. PIV measurements in a plane spanned by the radial and rotation axis provide a comparison of the slipstream velocity components and vorticity. This simulation combined with the PIV measurements enables an extensive description of the structure of root and tip vortices induced by the propeller blades and swirl recovery vanes. It is found that the propulsive efficiency increase by the addition of SRV is only 0.57% which is much lower than the design prediction of 1.8%. Therefore this design is not used in the remainder of the research and new SRV designs are proposed. An SRV analysis tool based on lifting-line theory modified for non-uniform inflow is presented. In combination with an optimisation routine, this tool allows for the design of SRV for an isolated propeller. From a simplified analysis of an elliptical vane in a uniform swirl flow, it is concluded that optimisation for maximum SRV thrust is preferred over complete swirl recovery to reach the highest gain in propulsive efficiency. Four designs are presented: Design 1 is optimised for the cruise condition with a constraint on stall for the high-thrust condition. Design 2 is optimised for the high-thrust condition with a constraint on the cruise condition for zero or positive efficiency benefit. These are designs where the SRV have a fixed pitch in flight. Also two variable pitch designs are proposed. The effect of cropping and the number of vanes on the propulsive efficiency is investigated as well for the objective of design 1. Design 1 and 2 are used in CFD simulations behind the isolated propeller to validate the predictions from the SRV analysis tool. In general the simulation results show that SRV lead to an increase in propulsive efficiency by increasing the system thrust over a wide range of advance ratios, with minor effect on the system power. Gains in propulsive efficiency of 0.39% and 0.20% are found in the cruise condition and 2.62% and 3.07% in the high-thrust condition for design 1 and 2 respectively. For high advance ratios the prediction is very accurate, while towards lower advance ratios the tool overpredicts the propulsive efficiency gain. The difference is within the limits that can be explained by the set assumptions. Design 1 proves that it is possible to increase the propulsive efficiency of an operating point close to the point of maximum propeller propulsive efficiency. Design 2 shows that if a larger increase in propulsive efficiency at low advance ratios is desired, the design can be changed at the cost of propulsive efficiency benefit at higher advance ratios, for a fixed SRV pitch design. Downstream of the SRV, somewhat less than half of the swirl is recovered on average. An expansion of the slipstream boundary is present, which is the result of the interaction of propeller blade and vane tip vortices. In the last part the wing of a Fokker 50 is introduced behind the propeller and SRV design 1. The loading on the wing induces an upwash upstream of the wing, resulting in a deviation from the SRV design inflow that is different for each vane by such a degree that flow separation degrades the SRV performance to a large extent. Therefore a change in the SRV design is made by turning each vane over an angle to obtain the time- and radial-average design inflow in the cruise condition. For future research it is recommended to find a different design for each vane. Since the effect of the wing upwash on the SRV inflow field varies with advance ratio and with wing loading and thus varies in flight, a variable pitch SRV design is recommended where the pitch of each vane is adjusted individually. For the cruise condition the increase in propulsive efficiency by the addition of SRV without considering differences in wing drag is found to be 0.93%, which is considerably higher than without wing, mainly due to the increased propeller propulsive efficiency, but partly by increased SRV thrust as well. 2.14% for a medium-thrust condition, which is very similar to the value without wing. For a wing-mounted tractor-propeller conclusions on SRV performance can only be drawn from the complete force balance of thrust and lift of the propeller, SRV, wing and nacelle. Considering the drag of all components, the net increase in propulsive efficiency by the addition of SRV is found to be -0.14% for the cruise and 1.00% for the medium-thrust condition with a net increase in lift of 0.35% and net decrease in lift of 0.55% respectively. Careful optimisation of SRV taking the wing into account as well as the lift as a constraint will most likely result in a performance benefit, since already with this non-optimised design an increase in thrust or lift can be found depending on the advance ratio. The propeller slipstream greatly affects the wing lift and drag distribution by its increased axial velocity and introduced swirl. It is concluded that SRV reduce some of the effects of the propeller on the wing lift and drag distribution by a reduction of the swirl, resulting in a smaller deviation from the wing loading without propeller. A design procedure for SRV should include the wing for instance by an additional lifting line and optimise for combined SRV and wing maximum thrust with a constraint on the net lift. This may lead to SRV designs more focussed on providing the optimal inflow for the wing in order to reduce the wing drag.","Swirl Recovery Vanes; SRV; propeller; APIAN; wing; Fokker 50; CFD; propulsive efficiency; slipstream","en","master thesis","","","","","","","","","Aerospace Engineering","Aerodynamics, Wind Energy, Flight Performance and Propulsion","","Flight Performance and Propulsion","",""
"uuid:95f5bbc7-709d-4426-977e-663016684ab7","http://resolver.tudelft.nl/uuid:95f5bbc7-709d-4426-977e-663016684ab7","Flipshade: A design exploration into flexible electroluminescent material","Goossensen, J.P.","Jansen, K.M.B. (mentor); Pasman, G.J. (mentor); Barati, B. (mentor)","2015","At the faculty of Industrial Design Engineering there is a constant search for new materials with a potential value within the field of product design. This graduation explores flexible electroluminescent material, a layered material that can be applied by screen printing. More detailed, electroluminescence is the non-thermal generation of light from a phosphor material when a high electric field is applied to it. The material is analysed on its material properties which concluded in a set of eight design handles. These handles provide both a starting point for ideation as well as an evaluation tool. A conceptual phase lead to the concept of the Flipshade. This is a lighting concept embodying electroluminescence on the surface of a lamp shade. The lampshade is flexible, thus enabling the flipping of the shade inside out. The user has the option to have the illuminated surface either on the outside or the inside. Further exploring electroluminescence and developing the concept of the Flipshade lead to the construction of a prototype. The role of the prototype is to communicate the potential of the flexible electroluminescent material to other designers. The Flipshade is a carrier of information, displaying not only material properties. It also invites designers to deepen their understanding of the material on a sensorial and inspirational way. In that sense presenting the flexible electroluminescent material is favoured over an off-the-shelve sample. This explorative design process adds to the development of electroluminescence and provides other designers a starting point for getting to know the material. Moreover, the project can have implications on other explorative projects in the role of the prototype, realising the prototype and presenting a new or unknown material.","electroluminescence; explorative design research; screen printing; printable light; emerging materials","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Master of Science Integrated Product Design","",""
"uuid:cbe7e928-c213-45d7-ac38-620b90705344","http://resolver.tudelft.nl/uuid:cbe7e928-c213-45d7-ac38-620b90705344","Distributed-Dynamic State Estimation with SCADA and PMU","Pietaloka, D.","Popov, M. (mentor); Rueda Torres, J.L. (mentor)","2015","The purpose of this research is mainly to develop a distributed dynamic state estimation with PMU and SCADA as a response of the challenges in state estimation problems (accuracy, computational time, the use of new technology along with the ability to keep the existing traditional measurement). With the implementation of statistical signal processing technique into state estimation algorithm, this research conducts two different state estimation algorithms: distributed –Extended Kalman Filter based Dynamic State Estimation (distributed-EKF based DSE) with SCADA and PMU; and distributed –Unscented Kalman Filter based Dynamic State Estimation (distributed-UKF based DSE) with SCADA and PMU. As a comparison, the implementation of EKF-based DSE and UKF-based DSE in integrated system has also performed. Variations number of PMU is installed in different buses location to see the effects on the state estimation result of the particular algorithms. The performance of the algorithm is studied using computer simulations and the comparisons are observed and analysed. The result of the simulation has shown that UKF-based DSE is a promising method in a nonlinear model implementation, although the difference with EKF-based DSE is small in this research. The result has also shown that more number of PMU installed give more state estimation accuracy for both algorithms. The concept of distribution state estimation has improved the performance of the state estimation in terms of efficiency (computational time) compare to integrated state estimation.","state estimation; distributed; dynamic; EKF; UKF; PMU; SCADA","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Electrical Power Engineering","","","",""
"uuid:7bb674ce-1dff-4158-ae5b-9dfc2644f21e","http://resolver.tudelft.nl/uuid:7bb674ce-1dff-4158-ae5b-9dfc2644f21e","Auditing a Continuous Controls Monitoring System","Sweep, T.B.","Hulstijn, J. (mentor); De Bruijne, M.L.C. (mentor); Janssen, M.F.W.H.A. (mentor)","2015","A common problem within the accounting profession is the problem of audit timeliness. At this moment, the problem is becoming more urgent in the real-time economy. A potential solution to the problem arises from the introduction of CCM systems. However, for this solution to succeed, the CCM system itself should be audited which turned out to be an unexplored area. This research is aimed at addressing this knowledge gap by exploring how external IT auditors should assess the adequacy of the design and operating effectiveness of a CCM system. The result is a set of 41 guidelines that functions as a frame of reference for the audit of a CCM system.","audit timeliness; continuous auditing; continuous controls monitoring; IT audit; external audit","en","master thesis","","","","","","","","","Technology, Policy and Management","ICT","","SEPAM - IA","",""
"uuid:9033ea68-20ee-4acd-8bd4-91f595d82b5f","http://resolver.tudelft.nl/uuid:9033ea68-20ee-4acd-8bd4-91f595d82b5f","Decision support framework for opening business data","Buda, A.","Ubacht, J. (mentor); Warnier, M. (mentor); Janssen, M. (mentor); Nagel, R. (mentor); Sipis, R. (mentor)","2015","Open data movement is gaining widespread attention and spans across a variety of sectors (public, private, academic and civil). The last ten years have seen significant progress in opening of access to government datasets (Davies, 2010). This openness of public data has brought several benefits as: great transparency, innovation and the rise of new business models (i.e. analytics as a service). One of the primary consumers of open public data is the private sector. Private sector companies not only interact with governmental data but also produce a massive amount of data themselves (Herzberg, 2014). Few initiatives to open up data emerged already in the private sector, but are insufficient to provide a benchmark. Businesses are unsure about the associated costs and benefits of such an action (theodi.org, 2015) and a variety a constraints (privacy, security, proprietary interests and data protectionism) hold back this potential (Verhulst, 2014). This research offer guidance for the private sector towards releasing their data, by providing a decision support framework. This framework is composed by seven building blocks: organizational goals, business drivers to open up data, business open data ecosystem, datasets, barriers, and risks, process change and strategies to release data. The novelty of this research consists on the perspective that is given to the “open data”, where private sector organizations are seen as the main suppliers. The main business drivers for companies to open up datasets (community building, promotion, business innovation, business improvement, new revenue stream) are identified. Next to that, key challenges –pertaining to gathering data, opening-up datasets and on the user side regarding business open data are investigated.","Business open data; Business open data ecosystem; Business drivers","en","master thesis","","","","","","","","","Technology, Policy and Management","ESS","","Management of Technology/ICT","",""
"uuid:6abab443-148c-45de-9105-50bd0428d724","http://resolver.tudelft.nl/uuid:6abab443-148c-45de-9105-50bd0428d724","Compliance Risk Measurement in Global Supply Chain: A Study in Food Import in EU","FEI Tianqi, T.","Hulstijn, J. (mentor)","2015","Global trade needs effective supply chains to ensure global sourcing at cost-effective rates and to position their products on international markets. Global Supply chains involve complex systems and multiple stakeholders among countries and organizations. In addition it requires high visibility and transparency in information flow. Compliance problems and their negative impacts are rising and the corresponding costs are becoming a big burden for global trade during import-export process. Global foods import faces much more challenges because its own specialties. Concerning food safety, sensitivity, perishability, environment impacts, and even animal welfare, regulatory requirements and inspections are complex and complicated during global food supply chains. Also, transparent and fast transportation is essential. However, the combination of small disruptions may cause a lot of delay and negative impacts due to inflexibility of schedule. The measurement of these compliance risks and their impacts are difficult because some risks are less tangible and some are non-quantifiable. Existing coverage of the compliance problems and impacts on companies’ global supply chain management tends to be brief and lacks specifics. There are either less research on compliance problems in food import. The purpose of this research is to identify common customs compliance risks in the food import process and develop a strategic approach to measure these risks in the context of global supply chain management. Based on these risks we could finally identify their negative impacts and costs of compliance. To achieve this goal, the research will be conducted through qualitative research, semi-structured interviews and illustrative cases.","compliance risk; customs compliance","en","master thesis","","","","","","","","","Technology, Policy and Management","ICT Section","","","",""
"uuid:e24df5dd-0a08-4866-8dca-4d6d2b9b082f","http://resolver.tudelft.nl/uuid:e24df5dd-0a08-4866-8dca-4d6d2b9b082f","Architectural and Functional optimizations to the Digital subsystem of Active Digital Aura (ADA) chip","Prasanna Kumar, J.","Al-Ars, Z. (mentor); Arnoldussen, G. (mentor)","2015","The primary objective of this thesis project is to investigate and develop optimal software and hardware architectures to detect the Start Of Packet (SOP) indicator present in a Body Coupled Communication (BCC) based message packet. The SOP detection module is a part of the receiver block present in the digital subsystem of the Active Digital Aura (ADA) circuit [2]. The project is comprised of two tasks. The first task is to investigate alternative solutions to detect the SOP in a received message. Accurate detection of the SOP under varying noise conditions is crucial for reducing retransmissions and improve the data rate. The various investigated solutions are implemented using VHDL and tested for the accuracy of SOP detection using Xilinx ISE simulations. The solutions are also synthesized using Cadence Synthesis tools to determine the hardware statistics such as area utilization, power consumption, and slack. The solution having highest accuracy and optimal hardware resource utilization is chosen as the best possible alternative solution. Furthermore, to verify the SOP detection in a typical BCC scenario, different types of noise such as burst noise and distributed noise with varying intensity are injected to the message packet to introduce errors. Both the current and best alternative solutions are subjected to functionality tests under these noise variations to determine the detection accuracy and limitations of each. The second task is to incorporate necessary modifications to the digital subsystem of existing ADA circuit [2] to develop a prototype model of it on the ML401 (Xilinx Virtex-4 based) FPGA board [3]. The prototype aids in testing of the modifications made to the digital subsystem of ADA chip (such as the SOP detection module) at real time, prior to ASIC manufacturing. A firmware application is also developed for an ARM Cortex-M4F based ?C device (host) which is used to interact with and test the FPGA prototype. The functionality of the existing and alternate SOP detection solutions are verified at real time on the FPGA hardware.","Start of Packet Detection; Digital optimization; FPGA prototyping","en","master thesis","","","","","","","","2016-08-26","Electrical Engineering, Mathematics and Computer Science","Computer Engineering","","Embedded Systems","",""
"uuid:a5d54afd-277f-4895-85eb-eedbcf45aa0a","http://resolver.tudelft.nl/uuid:a5d54afd-277f-4895-85eb-eedbcf45aa0a","Management Guideline for Software Development Projects (Public Version)","Sengur, S.","","2015","The needs of companies are evolving and becoming more and more demanding each year, which result in more complex stakeholder relations. The complexity of the projects increases as well. For instance, stakeholders do not always have the same sense of urgencies and their expectations from the same project might differ. Such variety in demand urges project managers to opt for a new; more broaden management approach that includes more human type of issues as well as hard skills. One area this situation is observed in contemporary projects is software development projects with complex stakeholder environment, where the project managers have responsibility to deliver high quality end delivery at the same time to meet the demands of stakeholders with different sense of urgencies. This study aims for answering the research question “How can software projects having unclear requirement definitions and stakeholders with different sense of urgencies can be managed successfully?” The research is proposing a structured set of methodologies with a guideline to professionals and the researchers to manage software development projects having unclear requirement definition and stakeholders with different sense of urgencies.","software development; different sense of urgencies; unclear requirement definition","en","master thesis","","","","","","","","","Technology, Policy and Management","Multi Actor Systems","","Systems Engineering, Policy Analysis and Management","",""
"uuid:80e98fb4-7c39-4074-bf30-86b7120a288f","http://resolver.tudelft.nl/uuid:80e98fb4-7c39-4074-bf30-86b7120a288f","Innovation Framework for the Research & Technology department of Zodiac Air Catering Equipment","Nijman, J.","De Lille, C.S.H. (mentor); Santema, S.C. (mentor); Gomez Serrano, S.L. (mentor); Verweij, R. (mentor)","2015","During this graduation project, an innovation framework was created for the R&T department of Zodiac Air Catering Equipment","innovation; research & technology; fuzzy front end; framework","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product Innovation Management","","","",""
"uuid:6a20cd5b-3517-488b-bd46-663c12c4aa37","http://resolver.tudelft.nl/uuid:6a20cd5b-3517-488b-bd46-663c12c4aa37","Improving the effectivity of force translation from hand to push rim in sports wheelchairs: A redesign of the interface between push rim, hand and racket","Van der Ham, B.","Kuipers, H. (mentor); Minnoye, A.L.M. (mentor); Koopman, J. (mentor)","2015","Trough developments the wheelchair has become lighter and has less rolling resistance. Athletes can be trained better because there is more knowledge about muscle use. The only thing that has hardly changed is the push rim. It provides that the user can propel the wheelchair. Wheelchair athletes could not propel their wheelchair effectively until now because the interface between the hand and the push rim (and a tennis racket if necessary) was expected to be not optimal. The new shape of the push rim cross- section increased the ropulsion force with up to 12%. Adding texture on one surface of the shape, forces increased with up to 27 %. Tests were executed with a prototype that represented a part of the push rim. Static force measurements were executed. Recommendations were given for subsequent tests, in which participants can actually drive with a complete push rim prototype.","sports; wheelchair; effectivity; propulsion","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Integrated Product Design","",""
"uuid:f60d989c-9101-4f6a-8817-4da09b2075f6","http://resolver.tudelft.nl/uuid:f60d989c-9101-4f6a-8817-4da09b2075f6","Numerical Study of Fluid Structure Interaction in Nuclear Reactor Applications","Ter Hofstede, E.","Van Zuijlen, A.H. (mentor); Shams, A. (mentor)","2015","Flow-induced vibration (FIV) plays an important role in the nuclear industry. In nuclear power plants (NPP), the FIV may cause fatigue problems, stress corrosion cracking, possible failure modes and fretting wear. This in return can lead to nuclear safety issues and substantial stand-still costs due to unplanned outages. It is therefore important to asses this phenomena early in the design process. Most of the experiments or analytical models used to predict FIV, are over simplified or cover only a single operation condition. Therefore using a combination of Computational Fluid Dynamics and Computational Solid Mechanics to model FIV can play an important role for the complex industrial applications. In the present work the numerical simulations are performed using the OpenFOAM Extend open source code, in which both the fluid and structural dynamics are computed using the Finite Volume (FV) method. Moreover, a partitioned approach was implemented, in which the exchanges between the fluid and structure solver take place. This was done through the use of the Interface Quasi Newton with Inverse Jacobian from a Least-Squares (IQN-ILS) coupling method. To gain the confidence of the available numerical methods, their validation is a necessary step that needs to be performed. Firstly the simulation of a well-known benchmark was performed using the IQN-ILS coupling method, where the deformation of an elastic flap, attached to a solid cylinder, is studied. Afterwards, the same coupling method was used to simulate the free vibration of a beam in a fluid and validated with experimental results. Lastly, the validated method was used to model the turbulence induced vibrations of a scaled version of a neutron flux measurement guide tube. From this study it has been found that the IQN-ILS coupling method can be used for strongly coupled problems. It has also been found that the mesh resolution and time step are important parameters for a correct estimation of the frequency and the damping of the oscillation.","OpenFOAM; FSI; IQN-ILS; Nuclear Power Plants","en","master thesis","","","","","","","","2016-08-26","Aerospace Engineering","Aerodynamics and Windenergy","","Aerodynamics","",""
"uuid:684bb201-64a2-461d-b603-1f47590a1341","http://resolver.tudelft.nl/uuid:684bb201-64a2-461d-b603-1f47590a1341","Shortcuts to Quantum Network Routing","Schoute, E.","Wehner, S. (mentor)","2015","Communication is a key part of society that we make huge investments in. Each message has to both arrive quickly and use minimal network resources. Moreover, communications must sometimes also remain private, so encryption is used to prevent third parties from listening in. However, standard classical encryption protocols are proven not to be secure against quantum adversaries. With quantum communication we have a method that does provably attains perfect secrecy, even against adversaries with unlimited (quantum) computational power. It is, however, infeasible to have a direct quantum connection between all users of quantum communications. We thus look into the possibilities of a \emph{quantum network}, which is able to connect arbitrary users of the network as if they had direct quantum channel available. Once such a quantum network is built, we will need to route quantum messages effectively to their destination. In this work, we take the first step in studying network structures for quantum networks on a high level, and their accompanying routing algorithms. Current ongoing research into quantum communication with satellites and the possibility of a global network made the case of a quantum network of satellites relevant. We will consider a simplified model where each satellite can perform quantum communication with its immediate neighbours, and can create quantum virtual links that form shortcuts through the network. The first step towards a quantum network that we take is the structure of the network. Using virtual links as shortcuts we can reduce the maximum distance between nodes (the diameter) by an exponential factor. Let $|V|$ be the size of the set of all vertices in a graph, equal to the number of satellites. Then for the case of satellites we give a network structure with the following properties: \begin{itemize} \item The diameter of the graph is $4\log_2\left( \frac{|V|-2}{10} \right) +3 = O(\log |V|)$. This means that the distance between any two nodes in the graph will scale logarithmically in the number of nodes. \item The maximum degree of a vertex is $12\log_2\left( \frac{|V| -2}{10} \right) + 6 = O(\log |V|)$. The degree of a vertex is directly related to the size of its quantum memory. Since quantum memories are currently limited in size, it is important for feasibility reasons that the degree stays low. \end{itemize} With a logarithmic scaling, the diameter and degree scale well for large graphs. This is especially relevant for networks, which can become large. A lower distance between vertices also allows quantum communications to fail less often, in effect decreasing the communication time. We can thus achieve a much smaller diameter by using virtual links, while the degree of each vertex remains low. We furthermore give a routing algorithm for finding the shortest path on this network structure that only uses local information at each vertex to route, where local information is the nearby surroundings of a vertex. The routing algorithm has the following properties: \begin{itemize} \item The space complexity of the algorithm is $O(\log^5 |V|)$ per vertex. A small space complexity implies little memory usage of the algorithm. Since network routers are typically small computers, the small memory requirement allows them to run this algorithm. \item The time complexity of the algorithm is $O(\log^2 |V|)$ per vertex. A small time complexity allows network nodes to compute the next step in the path in minimal time. The time necessary to communicate decreases with decreasing time complexity. \end{itemize} For large enough $|V|$, our algorithm outperforms standard routing algorithms such as Dijkstra's algorithm by an exponential factor. Furthermore, we have proved that the local routing algorithm always gives a shortest path. Local routing transitions well into a real world implementation, so that every network router can make simple decisions for routing.","quantum networks; routing; quantum mechanics; networks","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Intelligent Systems","","Cyber Security Group","",""
"uuid:a4d92ef7-11d0-40ba-8526-0df67866b77a","http://resolver.tudelft.nl/uuid:a4d92ef7-11d0-40ba-8526-0df67866b77a","Breaking the stigma: Integrating a nurse-call alarm in the homely environment of elderly care facilities","Luik, B.","Vroom, R.W. (mentor); Haagsman, E.M. (mentor); Ringenier, J. (mentor)","2015","The assignment that was the starting point of this project comprised of designing and developing a nurse call corridor lamp that suits the needs, wishes and context of an elderly care facility. The goal is to make the product fit in better into this homely environment, in which the current corridor lamp does not do a very good job. Several stakeholders were analysed and their requirements were taken into consideration during the design of the new product. These stakeholders were the elderly resident, the staff members of the facility, the installation engineers and the Ascom brand itself.","nurse-call systems; corridor lamp; Ascom; elderly care","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Master of Science Integrated Product Design","",""
"uuid:6bc77f7c-964a-41fa-8fc2-f29e7f02c181","http://resolver.tudelft.nl/uuid:6bc77f7c-964a-41fa-8fc2-f29e7f02c181","Systems Engineering for University Satellite Projects","Van der Pas, N.","Guo, J. (mentor)","2015","Many universities have ventured into the design of satellites as educational projects. The Delft University of Technology (TU Delft) has a rich history in this ?eld with the Del?-C3 and Del?-n3Xt projects. Currently the Del? programme is working on its third project DelFFi. Applying and researching systems engineering has been a major part of these projects, and the current study continues in this tradition. Systems engineering methodologies need to be adapted to their environment. Team members, both from Del? projects as other projects, report that currently these methodologies do not function optimal. The aim of this thesis is to propose a new systems engineering methodology for university satellite projects. This goal will be achieved by studying previous and current projects. In addition the stakeholder use cases will be examined to improve the success of the university satellite systems engineering methodology. University satellite projects are undertaken for educational purposes. The teams consist for a large part of students, have a high turnover and ?uctuate in size. The team members use these projects to perform research and receive an education. These needs to be integrated well into the project. It has been found that the performance of the project can be parametrised by looking at the quality of the system, the project length and the project cost. The performance of the students in the project can be measured with their grades and the time they spent on their assignments in comparison to their peers. Based on the stakeholder use cases and taking into account the main parameters, a university satellite Systems Engineering (SE) Methodology was developed. The University satellite methodology should consider the documents that students generate as part of their education as the main project documentation. The system can best be developed from a veri?ed baseline. The system should be broken down into con?guration items, which are developed in a number of consecutive work packages. These work packages are based on the life cycle of the students involved.","space engineering; systems engineering; University Satellite","en","master thesis","","","","","","","","","Aerospace Engineering","Space Engineering","","Space Systems Engineering","",""
"uuid:254da820-8cda-42ab-98f7-541f935a07e5","http://resolver.tudelft.nl/uuid:254da820-8cda-42ab-98f7-541f935a07e5","Self-driving vehicles as public transport in Rotterdam","Hamilton, L.H.M.","Van Arem, B. (mentor); Correia, G. (mentor); Wiggenraad, P.B.L. (mentor); Baggen, J.H. (mentor); Rijsdijk, J. (mentor); Cazemier, O. (mentor)","2015","The development of self-driving vehicles is growing rapidly. The goal of this research is to investigate the possibilities of self-driving vehicles as public transport. Based on development, existing projects and existing public transport systems a suitable system of self-driving vehicles as public transport is determined. Rotterdam is used as a case-study in this research. Three potential locations for a service of self-driving vehicles as access/egress mode are selected. The number of trips for self-driving vehicle as public transport for these test locations is modelled using the OmniTRANS-model in Rotterdam. An access/egress mode choice model is estimated to calculate the number of trips for the self-driving vehicle and bike. For the test locations the results of the model show a 25\% to 59\% share of the number of trips for self-driving vehicles as access/egress mode. Based on this research recommendations are made for further research.","self-driving vehicles; public transport; mode choice","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Transport & Planning","","","",""
"uuid:b04cb88e-901e-4057-945b-bcf2ea1a9375","http://resolver.tudelft.nl/uuid:b04cb88e-901e-4057-945b-bcf2ea1a9375","Improving KLM Customer Ground Handling's Competitive Market Position","Jochems, S.P.M.","Santema, S.C. (mentor); Bakker-Wu, S. (mentor)","2015","The national pride of the Netherlands in the aviation industry, KLM Royal Dutch Airlines, is not only an airline but also a ground handler at Schiphol airport. After landing at Schiphol, the Ground Services (GS) and Customer Ground Handling (CGH) departments of KLM will provide all services that are needed to make sure an aircraft can take off for its next destination. Not only KLM’s own aircraft are being handled, 21 other airlines flying at Schiphol are handled as well. Because of the open ground handling regime at this airport, the companies Aviapartner, Swissport, and Menzies also provide ground handling services to airlines. These companies have ground handling as their core business, and operate on multiple airports. As in almost every industry, companies have to compete on quality and pricing in order to ensure a competitive market position. However, the relatively large amount of ground handling parties at Schiphol, combined with the effects of the economic crisis, have made this business focus on competitiveness and price even more. For KLM as a ground handler, the shift towards a focus on price has been hard to deal with, as the biggest cost for any ground handling party is the salary of its employees. Ground handling employees at KLM enjoy favourable working conditions that were given to them in the uptimes of the aviation industry. It is very difficult to change these working conditions, and therefore it is believed that KLM will not be able to compete with the other ground handlers on price in the near future. The other aspect of a product or service, the quality, is in case of KLM perceived as superior by customer airlines. However, making a ‘fair’ comparison between ground handlers is a near to impossible mission as the customer airlines of each ground handler have very different specifications. The time of arrival, amount of transfer passengers, amount of passengers and amount of baggage are just a few of the many specifications that will determine the difficulty of handling an aircraft. This leaves KLM as a ground handler in a very difficult position, having a higher price while offering a superior quality which is not objectively decided on. The raison d’être for both GS and CGH is the strong transfer product they offer. With Schiphol having an estimated total of 70 percent in transfer passengers, who have no further interest in being in Amsterdam, this transfer product is an important aspect of the ground handling. This Unique Selling Point (USP) consists of many services that ensure that an airline can offer its passengers a lot of connections to other aircraft. Also the time a passenger has to spend at Schiphol is minimized, and aircraft are on the ground for a shorter time. The transfer product may be the USP for CGH and GS, but customer airlines see this transfer product less and less as something that is really differentiating the KLM ground handling from other ground handlers at Schiphol. The challenge is thus to strengthen the transfer product offered by KLM as a ground handler and differentiate the ground handling once again. Within this thesis this is done by ‘making the chain longer’, looking at the passenger of the customer airlines (and not just the customer airline itself), and by not focussing on cutting down the price of the operation but on enabling a lower price in a different way. The new baggage tracking applications and program targeted at KLM, and more importantly customer airlines, do so by giving real-time information to passengers, cabin crew, and ground handling agents. Passengers obtain real-time information about the baggage handling process, making them feel assured while transferring at Schiphol. Besides, the passengers are entertained and educated by providing them with videos of the baggage handling process. KLM and customer airlines cabin crews are informed by messages in case of any disruptions in the baggage handling process. Actions like providing the passenger with an upgrade in case of missing baggage can be taken. In this way, the negative experience can be turned into an appreciation for the airline, approaching the passenger pro-actively. The baggage tracking program for ground handling agents enables them to have a quick overview of the baggage handling process. Problems can be solved faster by combining real-time information from different sources. As a result, the amount of mishandled baggage will drop. In this way, making use of real-time information, the transfer product of GS and CGH is strengthened, a big step in differentiating the ground handling once again and improving the competitive market position of KLM ground handling.","KLM; Customer Ground Handling; Transfer; Schiphol","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product Innovation Management","","Master of Science Strategic Product Design","","52.308056, 4.764167"
"uuid:e9e5bab5-09e0-4bf9-b1c1-9508d381c0c6","http://resolver.tudelft.nl/uuid:e9e5bab5-09e0-4bf9-b1c1-9508d381c0c6","Analysis of the behavior of the Ding well model for off-centered wells and its impact on gradient-based well location optimization","De Zeeuw, J.Q.","Jansen, J.D. (mentor); Ashoori, E. (mentor); Joosten, G. (mentor)","2015","The computer assisted optimization of well locations in reservoirs can result in a better planning of the reservoir development and non-trivial optimal locations can be found. Currently most optimizers use gradient-free methods which require significant computing capacity. Especially when considering decision making under uncertainty there is a need for faster, but still accurate optimizers to handle a variety of reservoir realizations. Some gradient based well location optimization methods have been proposed in literature that make use of the adjoint method to calculate all gradients in the field at the cost of only one forward and one backward simulation. The proposed methods are however using some approximation of the gradient of the objective function with respect to the exact well locations. This study shows a new method to derive the direct gradient of the objective function with respect to exact well locations via a well model for off-centered wells. However, the study shows multiple issues arising from this well model for off-centered wells and what their impact is on this new gradient-based well location optimization method. First, the off-centered well model is found not to be able to model wells located on exact grid block edges. Second, when moving wells from grid block to grid block the well model does not behave smoothly, which jeopardizes its suitability for well location optimization. A mitigation strategy is developed and tested, but this does not solve this issue. Third, the well model is not fully correct in modelling off-centered wells for both single-phase flow and multiphase flow, and again this jeopardizes its suitability for the new gradient-based well location optimization method. The use of an off-centered equivalent wellblock radius instead of the Peaceman wellblock radius is found to solve most of the suspect behavior for single-phase flow for off-centered wells. The issues related to multiphase flow are not solved in this study, but some potential solutions are proposed.","Ding well model; optimization; gradient-based; well location; off-centered well","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Petroleum Engineering","","51.9983106, 4.3764585"
"uuid:5f8a549a-443b-40aa-b928-3c2e205526b0","http://resolver.tudelft.nl/uuid:5f8a549a-443b-40aa-b928-3c2e205526b0","Design Optimization for Enhanced Fuel Mixing and Reduced Combustion Instability: Enhancing Swirler Performance of a Small Turbojet Engine Combustor","Venter, P.","Visser, W. (mentor)","2015","Aero-engine performance is becoming an increasingly regulated aspect in aerospace indus- tries with tighter restrictions on emissions, greater expectations for efficiency and thrust as well as broader requirements for the range of the operating flight envelope. With an increasing consciousness toward these factors during the design of combustors, research led development and improvement of every single aspect of the combustor design needs to be considered in this modern era of aerospace technology. A major contributor to such performance enhancement is the design of flow swirlers used to induce central re- circulation zones in the primary fuel/air mixing region. In the current study, the effect of modification to a swirler’s vane blade angle on mixing effectiveness and combustion stability is investigated, using flow properties such as turbulent kinetic energy, fuel dis- tribution and pressure losses as a measure of combustor performance. The study takes a sensitivity analysis approach and makes use of an existing combustor design that acts as a benchmark for verification of results. A cold flow computational fluid dynamics anal- ysis is used to test the effect of blade angle modifications based on a ‘cause and effect’ methodology. The computational fluid dynamics model is validated against experimental data from a similar combustor. It was found that optimal fuel/air mixing occured in a 70? blade angle swirler however large pressure losses and excessive vortex shedding directly behind the center body indicated a strong likelihood of combustion instability. Good fuel atomisation through strong shear layers and excellent pressure recovery seen in a 30? blade angle swirler was accompanied by poor fuel/air mixing. A swirler design featuring 50? blade angles was found to be the optimum, with good fuel atomisation, stable recir- culation zones, promising flame anchoring potential, dispersive but orderly homogenous fuel/air mixing and desireable pressure recovery characteristics.","swirler; combustion stability; fuel mixing; CFD; cold flow; Optimisation; K ? ?; turbulence model; vortex; recirculation","en","master thesis","","","","","","","","","Aerospace Engineering","Flight Performance and Propulsion","","Flight Performance and Propulsion","",""
"uuid:bd44fc95-d064-41ae-b7c3-a6c0dd8a4652","http://resolver.tudelft.nl/uuid:bd44fc95-d064-41ae-b7c3-a6c0dd8a4652","Reduced-Order Modelling for Production Optimisation","Hewson, C.W.","Jansen, J.D. (mentor); De Barros, E.G.D. (mentor)","2015","Production optimisation of a reservoir simulation problem can be very computationally demanding as the reservoir model may contain many variables and nonlinearities, thus many iterations may be needed to obtain an optimal production schedule. Using Proper Orthogonal Decomposition and Trajectory Piecewise Linearization (POD-TPWL) developed in [1] and [2], simulations were performed on the Delft Egg model 100-200 times faster than the high-fidelity simulation with reasonable accuracy, depending on the distance from the trained solution. Production optimisation was performed using the gradient-based adjoint method. A reduced version of the adjoint equation was used by incorporating POD, as presented in [3] and by performing a first-order Taylor series expansion around a training point (similar to TPWL). This method allowed for time gains of 50-100 times when compared to the high-fidelity adjoint method. The results from the high-fidelity production optimisation compared with POD-TPWL showed a similar Net Present Value (NPV) for both optimisation methods, with an error of 0.1% between the two-values. However, the optimal injection schedules were not the same. When the high-fidelity model was run using the input schedules from POD-TPWL optimisation, the error in NPV was 4%. The speed-up observed for the optimisation loop using POD-TPWL was 6 times faster than the high-fidelity model. This is due to the number of snapshots that needed to be generated and the processing of the data from these snapshots. Robust optimisation was performed on the Egg model ensemble using a POD-TPWL model incorporating geological model parameters, states and well controls. Results showed a 0.7% deviation from the mean NPV value calculated in MoReS and a 4 million dollar increase in the standard deviation of the NPV. POD-TPWL was able to complete the robust optimisation 25 times faster than a high-fidelity simulation. POD-TPWL shows promise as a reduced-order modelling application for reservoir simulation and production optimisation. The accuracy needs to be improved in order to move to an operational application.","reduced-order modelling; reservoir simulation; closed-loop reservoir management; POD; PCA; TPWL","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Petroleum Engineering","",""
"uuid:af89f8ba-fc34-4084-b479-154be397718f","http://resolver.tudelft.nl/uuid:af89f8ba-fc34-4084-b479-154be397718f","Zero-Downtime SQL Database Schema Evolution for Continuous Deployment","De Jong, M.","Van Deursen, A. (mentor)","2015","When a web service or application evolves, its database schema --- tables, constraints, and indices --- often need to evolve along with it. Depending on the database, some of these changes require a full table lock, preventing the service from accessing the tables under change. To deal with this, web services are typically taken offline momentarily to modify the database schema. However with the introduction of concepts like Continuous Deployment, web services are deployed into their production environments every time the source code is modified. Having to take the service offline --- potentially several times a day --- to perform schema changes is undesirable. In this paper we introduce QuantumDB --- a middleware solution that abstracts this evolution process away from the web service without locking tables. This allows us to redeploy a web service without needing to take it offline even when a database schema change is necessary. In addition QuantumDB puts no restrictions on the method of deployment, supports schema changes to multiple tables using changesets, and does not subvert foreign key constraints during the evolution process. We evaluate QuantumDB by applying 19 synthetic and 81 industrial evolution scenarios to our open source implementation of QuantumDB. These experiments demonstrate that QuantumDB realizes zero-downtime schema evolution at the cost of acceptable overhead, and is applicable in industrial Continuous Deployment contexts.","Continuous Deployment; SQL Database; SQL; Schema Evolution; Zero-Downtime; Web-Services; QuantumDB; Nemesis","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Software Technology","","The Software Engineering Research Group","",""
"uuid:d6bcc277-1d35-4605-8cf9-04412ccf17ba","http://resolver.tudelft.nl/uuid:d6bcc277-1d35-4605-8cf9-04412ccf17ba","Effective Task Arrangement in Emergency Dispatch Centers","Van Duijn, S.C.","","2015","Recent policy choices by the Dutch government for improving uniformity of emergency dispatch centers across the Netherlands, which include budget cuts have led to the idea of changing the current organization on and task structure of Emergency Dispatch Centers (EDC’s) in the Netherlands. The initiatives driven by technological changes were initiated in 2012. These current structural revisions make this a good moment to investigate the current functioning and alternatives for the future. Fragmentation is currently visible from the strategic to operational level where each dispatch center involves three co-located agencies of fire-, police-, and ambulance departments. Fragmentation of responsibilities and knowledge within and between emergency dispatch centers increases the complexity of transformation. An understanding of the systems complexity is needed to make well informed policy choices. With the intended transformation, concerns arise regarding the effects of policy choices on the operational level. It is unknown which different preferences exist towards operational task allocation. Operational perspective considerations to their design aren’t known yet. Tensions between organizational layers could become present, but these are unknown, with the risks of becoming known too late in the process when more money is already spent, and the government is locked in to a solution. Research Question To get insight in the problem, the research question for this thesis study is: What are the most important considerations to the effective organization of an emergency dispatch center in order to achieve high quality emergency response considering different possible scenarios to its task arrangement? Approach The answer to the research question is derived by performing literature and empirical research, including an evaluation exercise. To be able to answer the research question an overview of the current system therefore first had to be modeled. BPMN modeling was used to investigate the tasks and processes at the emergency dispatch center. IST-SOLL analysis derived prominent considerations for task change and execution. From both theory and from practice several indicators for performance of the operational system are derived. The research started with of literature review and three initial discussion group meetings with four experts at the Rotterdam-Rijnmond EDC. After this a thorough analysis was done of current and desired situation. Seven interviews with different experts from different domains within the EDC’s of Rotterdam-Rijnmond and Zuid-Holland-Zuid were used to explore the problem situation and identify concerns. To understand the performance of the system, an evaluation survey was set up. Alternative task arrangements were compared using multi-criteria analysis. For this 12 operators were asked to score three scenarios that were used to evaluate opinions about task arrangements. Furthermore 13 interviews were held accompanying the survey, to identify underlying reasons for the evaluation scores. A. Based on results from the evaluation, the best task division could be evaluated. Numerous expert and progress meetings with graduation committee at the TU Delft were used to report and iteratively improve on all aspects of the research. As an important concern is what the effect of future task arrangements/scenarios is on the performance indicators, the results are also interpreted for this. The results gave insight in which considerations are most prominent when designing the task structures at the EDC. The answer to the research question aids policy makers to assess the effect of decisions taken to change the operational task structure within the EDC. Furthermore the apparent considerations to effective task execution that weren’t known and the impact of indicators on the quality of service aid the design and discussion about future task division can now be taken into account. Conclusions When it is looked at possible task arrangements, different task distributions can be chosen, depending on which are deemed the most important criteria and how their relations are seen. It has been found that these differ from different points of view. The political layer is dependent on operators for execution of tasks, while operators have to abide to a complex system of rules. There is a complex dependency between the political and operational layers which together have to provide the best possible service to civilians. The expertise of task execution lies within the operating core. Operational agencies at the EDC are however dependent on the political choices made. With the goal to deliver high quality emergency response, decision makers should take into account the operational view on handling emergency dispatching services. Three possible task arrangement scenarios were found feasible, and were evaluated: 1. Specialist dispatching. This resembles the current situation where the responsibility for emergency dispatching is divided according to operator specialism and emergency call type. 2. Multidisciplinary intake. This displays the operational outcome of the politically desired transformation. Any type emergency call can be treated by the any operator. Backup specialists are available in case of extra knowledge need. 3. One-stop-shop intake. This resembles scenario 2, except no backup specialists are available and a true one-stop-shop is created. The evaluation shows that trade-offs have to be considered to determine the best arrangement. There is no single best scenario. While the current task division is deemed best by operators, because of its overall quality delivery, in general the conclusion can be derived that there is no best task arrangement. Certain arrangements aren’t possible or plausible in general or require very difficult resource scarcity issues to be overcome. In general describing positive and negative effects of different task arrangements is possible based on the identified and evaluated criteria. It has been concluded that quality of service is a trade-off in comparison with other criteria such as costs. Also it has been observed that operators give such high scores to ‘quality of service’ as a criterion that it actually becomes an overall goal, more than a criterion. This leads to that every criterion score that influences the quality negatively is judged badly. Thus quality can’t be traded off in the eyes of operators. There are three considerations that have to be incorporated when designing an effective task arrangement.  Standardization versus professionalization The choice exists between the ‘most uniform service delivery’ and the “best individual judgment”. Specialism increases the judgment of specific emergency calls, but decreases the uniformity of service delivery and increases dependence on specialist knowledge. Protocoling increases uniformity but extra costs might occur due to the difficulty of correct classification of emergencies.  Specialism versus generalism The initially desired situation (2) leads to more generalists and as a starting point, increases the knowledge needed. The complexity and thereby feasibility of performing the multidisciplinary intake should be examined to find to which extent the two alternative options are feasible.  Information sharing for collaboration versus information divide for privacy Regulatory issues are expected when changing task arrangements The consideration is how to improve collaboration without breaking regulatory boundaries and overcoming the issue of losing too much quality by non-collaboration. Recommendations Decreasing the complexity of the situation by improving knowledge is a general concept that has benefits in the transition process. If it is known beforehand which problems arise on an operational level, then this can save money (not turning back measures), Improve decision making consent (operators may agree more) and increase the quality of service (performance) from the new system. Creating commitment increases the chance of success. It is recommended therefore, as the process is already going on, to include operators in the EDC into the process. A proven concept of testing, which is relatively inexpensive can bring to light how to deal with the considerations, is piloting which should be carried out as follows; Before the pilot a consensus about consideration importance should be reached or at least differences discussed. Operators should be educated that not only quality of service is important from a holistic point of view. A pilot can be used to measure the performance. To do this a pilot setup needs to be made with different configurations based on the trade-offs that are found. It is relevant to do further research into the differences between the managerial and operational layers. Current research could be validated and further quantified at other EDC’s in different geographical locations. Other sectors with a similar organizational structure and transformation issues can use this research as reference point. An example is the centralization of power by combining provinces into super-provinces. ?","emergency management; institutional change; emergency dspatching; considerations; evaluation","en","master thesis","","","","","","","","","Technology, Policy and Management","Systems Engineering, Policy Analysis and Management","","Information & Communication","",""
"uuid:b5480136-5082-44fb-9a42-f29e5a3027c5","http://resolver.tudelft.nl/uuid:b5480136-5082-44fb-9a42-f29e5a3027c5","Design of a Solid Rocket Motor for a Transonic Research Vehicle","Motsyk, O.O.","Cervone, A. (mentor)","2015","Hypresearch is a project that has been under development with the collaboration of ATG Europe, TU Delft, TNO for the past 7+ years. The eventual goal of the project is to fly a hypersonic research vehicle at Mach 6 (2 km/s) at an altitude of 42km for a continuous time interval of 360 seconds. Before this goal can be attained, however, several milestones must be achieved, the first of which is the testing of aircraft controls during launch in the transonic phase. The current Hypresearch mission envisions a first-stage separation and second-stage ignition at transonic velocities, hence it is important that all crucial systems function properly in the transonic regime. To achieve this, the Transonic Research Vehicle (TRV) project was set up. The subject of the thesis was the propulsion system of the TRV-1, with the goal of accelerating a glider payload to Mach-2 in vertical launch, and testing the payload separation mechanism while decelerating through the transonic phase. The goal of the thesis project was to design a solid rocket motor for the TRV-1, and to verify its performance through simulations and static motor tests. Firstly, the project goal was broken down into a series of requirements. Main requirements included the velocity (Mach 2) to be attained by the vehicle, the mass (6.25kg) and pre-defined shape of the glider, as well as limitations on the acceleration (40g) and resources in terms of cost, manpower, and materials/facilities accessible to students. The design process started with the preliminary design during which two design concepts were selected based on ballistic performance and trajectory simulations. In the detailed design phase, materials were selected and a detailed manufacturing, assembly, integration, and testing plan was drafted. In order to test the material properties of the selected design on a limited resources budget, a scaled-down test method—the so-called SGM or Single Grain Motor method was developed. Following a series of SGM tests, the final full-scale test configuration was selected, and several defects of the design were eradicated. However, during the SGM test campaigns, and the subsequent full-scale test, it was discovered that the actual performance in terms of total impulse was notably lower than that predicted by the model. Following the test campaigns, an investigation identified the causes of the performance loss to be excess water absorbed by the propellant during the curing process. A manufacturing method to prevent this in the future, as well as a design iteration of the motor to be performed in order to attain the mission goal, was recommended.","SRM; rocket; motor; propulsion; design; MAIT","en","master thesis","","","","","","","","2015-08-26","Aerospace Engineering","Space Systems Engineering","","SSE","",""
"uuid:6cf78eaf-a898-4559-8f2d-6be2474e3aff","http://resolver.tudelft.nl/uuid:6cf78eaf-a898-4559-8f2d-6be2474e3aff","Identification of dynamic soil properties relevant for offshore wind turbines through full waveform inversion of in-situ measured seismic data","Bolderink, I.","Metrikine, A.V. (mentor); Verschuur, D.J. (mentor); Van Dalen, K.N. (mentor); Versteijlen, W.G. (mentor)","2015","Wind energy needs to become cheaper in order to take on the competition with current non-durable energy sources. Innovative design procedures and better understanding of structural behavior are aimed for to improve the current wind turbine design. A better understanding of turbine behavior consists of several fields and one of these fields is soil-structure interaction. Currently input parameters for soil-structure interaction models are based on empirical methods. The objective is to estimate the dynamic soil parameters in the first 50m of soil in an offshore environment. In this thesis, a non-invasive seismic measurement is performed in order to identify dynamic soil parameters relevant for offshore wind turbines. The seabed surface response of an active source is measured through a streamer of hydrophones and results in a so called shot record. The data obtained from this measurement is used in a newly developed routine that can can identify an estimate of the shear wave velocity profile. Furthermore the routine is adapted to incorporate a second unknown parameter, the compressional wave velocity structure. These two parameters are the main contributors to the shear modulus, bulk modulus and Poissons ratio of the soil. An analytical linear-elastic full-waveform calculation is performed for a homogeneous, isotropic representation of the soil where the soil is assumed to be perfectly horizontally stratified and is overlain by a water layer. A genetic inversion algorithm is then used to update an initial guess of the soil model. The results show that full waveform inversion has high potential to successfully estimate the complex shear wave profiles. In addition, material damping has a large influence on the shape of the spectrum and should be included in the inversion.","Offshore wind turbines; foundation design; in situ geophysical measurements","en","master thesis","","","","","","","","2020-08-01","Civil Engineering and Geosciences","Hydraulic Engineering","","Offshore Engineering","",""
"uuid:5c01eb69-0d5b-4016-8b55-b450e87c24e2","http://resolver.tudelft.nl/uuid:5c01eb69-0d5b-4016-8b55-b450e87c24e2","Optical analysis of c-Si quantum dots embedded in a silica matrix","Fusi, A.","Van Sebille, M. (mentor)","2015","","","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Photovoltaic Material and Devices Group","","","",""
"uuid:f110568e-def4-4664-9839-9b30ce5c42b1","http://resolver.tudelft.nl/uuid:f110568e-def4-4664-9839-9b30ce5c42b1","Comparing severe gas transport situations through the network: Similarity or reduction methods","Lindenberg, K.","Vuik, C. (mentor); Dijkhuis, H. (mentor); Steringa, J.J. (mentor)","2015","A number of severe entry-exit combinations is selected, to investigate whether or not all possible future gas transport situations through the gas transport network of Gasunie Transport Services can be met. These severe entry-exit combinations are selected, such that if the transport capacity is manageable regarding the pipeline network for these entry-exit combinations, then it is possible to satisfy all possible entry-exit combinations. In short, these severe entry-exit combinations represent the most severe transport situations through the gas network within contractual limits, describing realistic market behavior, and determining the size and shape of the gas transport network. These are often called shipping variants or stress tests. These stress tests are denoted by vectors which components represent the gas capacities at entry and exit points. If a large set of stress tests is generated, then it takes a relatively large amount of time to evaluatethesestresstests. The aim of this project is, therefore, to reduce this generated set as much as possible. When reducing this set, we have to make sure that we derive a minimal set, which is still a complete set. So, our goal is to delete identical stress tests from the generated set, but also less severe transport situations. This report focuses on the quadratic form distance, which can measure similarities between vectors for which the individual components are correlated. In addition, some generated sets of stress tests are reduced according to reducing criteria.","gas transport; quadratic form distance; similarity search; positive semidefinite","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied Mathematics","","Numerical Analysis","",""
"uuid:fea08faa-5710-4d98-b634-2b3a0ef39bcd","http://resolver.tudelft.nl/uuid:fea08faa-5710-4d98-b634-2b3a0ef39bcd","Product's design concept of trustworthy transition experience in Automated Congestion Driving System: ACDS","Ociepka, W.","Mooij, S.C. (mentor); Happee, R. (mentor)","2015","This thesis had been conducted in order to create design concepts for a trustworthy transition of control between the driver of a car and the automated driving mode in Congested Driving Scenario. The starting point was understanding the interaction of humans with automated systems. Due to the historical background, the initial research had been conducted in the aviation domain. The following issues were identified: Automation irony: Technology is advanced enough to put the user out of the loop, yet still too primitive to handle alone all unexpected events. Automation is not a problem, lack of feedback is: The most dangerous situations occur when the user is not updated on the current automation state. The lack of shared mental model creates out-of the loop situations. What can be automated vs what should be automated: The mere fact that technology allows us to automate almost all aspects of driving a car should not be the main factor. The user needs, emotions and values should be given priority. Automation is based on models, life is not; This finding was exactly paraphrased by Stanis?aw Lem in his book “The Magellanic Cloud”: “Machines are perfect and limited, humans are imperfect and unlimited”. Total or absolute freedom is not possible yet: Therefore, until we are able to provide the automation with the cognitive abilities of simple animals or insects, the human agent will be still indispensable, even for the highly automated systems. Flying is less complicated than driving: Paradoxically, the pilots of enormous Airbuses or Boeings have more freedom and wider safety margins in case of system malfunction than a driver of a middle class sedan on a busy highway. Taking the above mentioned insights into consideration, the concept development had been focused on creating a strategic basis for the automated driving experience based on the proper balance between automation possibilities and human cognition limitations. The proposed solution - ACDS – the Automated Congestion Driving Scenario - exploits the characteristics of human nature and cognition. The outcome of the thesis are three interface concepts: The Stick, The Steering Wheel and The Co-Pilot. Each of them was meant to incorporate the findings related to the human-machine interaction: The Systems should be designed to extend the driver’s abilities instead of replacing them. Optimal, and not minimal, mental workload should be the desired state for designing HMI. Instead of asking “Who does what?”, the users should ask “How do we get along?” (with automation). The first concept: The Stick - was based on extensive usage of skeuomorph as a factor increasing innovation acceptance. The device to initiate a user-generated transition is the stick of an automatic gearbox. In the presented model, the driver changes gears by tilting the stick in a desired mode: Reverse, Neutral, Drive or Braking, subsequently the stick comes back to the initial position. The old device with a new functionality improves organization and creates a feeling that, although the ACDS is a complex system, it is possible to be controlled with a single lever. This simplicity “gives user feeling of control and knowledge, which can be directly linked to notion of comfort”. This, in turn, is crucial for generating trust and, eventually, an emotional bond with the ACDS. The second concept, the Steering Wheel, exploits the same principle of skeuomorph and implements new functions to the existing device. The Steering wheel is a fundamental means of interaction with a car. In contrast to the gearshift stick, it had survived in almost unchanged form since the very beginning of the automotive industry. At the same time in modern cars the stick became obsolete, mainly because of switching to automated or CVS transmissions. Central sticks became more of the entertainment hubs than primary device areas. Therefore this concept anticipates an ongoing trend and uses only the steering wheel to conduct the transition. 4 / 122 Like in the “Stick” concept, there is no need for additional elements in the car’s cockpit, the tool used for transition is implemented into the zone of primary devices, restricted only to these responsible for steering the car. This emphasizes the function of the ACDS as another type of drive mode, which literally takes over the control from the driver’s hands. In contrast to two previous designs, the Co-pilot explores some aspects of anthropomorphism, allowing the driver to clearly see the elements of the ACDS technology, personified as a small helping agent – the Co-pilot. As people prefer receiving orders from other people as opposed to machines, the design of the L.I.D.A.R gave cues for a design which could resemble the face of a team member. Indication of human factors in the design ensures easier triggering of the affective trust, using human’s natural tendency to tame the abstract and not fully understood ideas by treating them as human beings. The Co-pilot has a distinctive and unique design, it is used only for one purpose and its shape is easily recognizable among all the other switches and buttons and it can not be confused with any other device in the cockpit. It states clearly its usage restrictions and status by rotating according to the selected mode. The reference to the appearance of such highly complex and technologically advanced device as L.I.D.A.R helps to create appropriate mapping of functions. Another aspect is simplicity and uniqueness on form level. As mentioned before, there are no other buttons or devices similar in shape, therefore it is easy to label it and create function mapping. Due to the limited resources, this thesis does not include assessment stage of the concepts. It was not feasible, in the given time, to investigate a new domain, create concepts and finally test them with the appropriate number of participants. That does not mean, however, that the assessment part has been neglected. As users’ perception and acceptance of a new concept is crucial for its successful market introduction, a proper research plan and experiment set-up were created. Both of them were based on the Kansei Engineering method and simulator studies. A combination of cognition oriented approach with objective data from simulators should indicate such a design concept, which possesses the highest potential to gain users’ acceptance.","VIP; automotive; HMI; interaction design; concept design","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product Innovative Management","","Master of Science Strategic Product Design","",""
"uuid:69640b8a-6bf3-479a-b794-80724af005cb","http://resolver.tudelft.nl/uuid:69640b8a-6bf3-479a-b794-80724af005cb","Climate Change and Economic Growth: Production Based versus Consumption Based Evidence on the Decoupling of CO2 Emissions from Economic Growth","Mir, G.U.R.","Van Beers, C.P. (mentor); Storm, S.T.H. (mentor); Heijnen, P.W. (mentor)","2015","Of all the issues the world is facing today, Climate Change is the most threatening. The atmospheric concentration of greenhouse gases has increased significantly after industrial revolution and the vast majority of scientists now agree that most of the observed warming in the Earth’s climate system has been caused by these anthropogenic greenhouse gas emissions. To avoid climate induced global cataclysm in the future, there is consensus in the international community that the global average temperature should not exceed by more than 2OC above pre-industrial levels by the end of this century, whereas it has already increased by 0.8 degrees in the last century and would continue to increase due to climate inertia. The challenge is to reduce the emissions to stay below this temperature limit while making sure that the mitigation costs be kept under control in order to minimize risks to economic growth and prosperity. The research question that has been addressed in this thesis is related to this apparent growth-environment conflict, to check the possibility to stabilize climate without sacrificing wealth. Therefore, the following research question was developed and explored in this thesis: “Is it possible to decouple economic growth from climate change?” The answer to this question would decide the way forward and help in developing a framework for sharing climate responsibility. The concept which holds central importance in policy discussions and which is linked to the notion of decoupling is called Environmental Kuznets Curve (EKC). It hypothesizes that with industrialization environment degrades initially but after a threshold level of income environmental deterioration starts to decline resulting in decoupling of economic growth and environmental pollution. Thus economic growth is imperative to improving the quality of environment, and the same concept is widely applied in climate change. In this thesis, literature review was performed, covering the period from 1992-2015, on EKC which use CO2 emissions as indicator of environmental quality. It was discovered that all the studies use production based CO2 emission inventories to study the relation between economic growth and environmental quality. It is primarily because of the guidelines of IPCC which use territorial definition to calculate emissions for individual countries. This definition completely ignores economic linkages between different economies and may put extra pressure on countries which rely heavily on carbon intensive exports. This is usually the case with developing countries that are mostly specialized in emission intensive industries. Thus, it is less likely for them to participate in global effort to fight climate change and pledge an effort to reduce emissions. Since, this emission accounting framework ignores emissions embodied in trade, it may generate misleading insights on mitigation efforts with in specific geographical area and may also result in carbon leakage. Carbon leakage refers to the phenomena where emission reductions due to domestic mitigation result in an increase in emissions outside the jurisdiction. Thus, it is possible for mostly developed countries, which are Annex I countries and are parties to UNFCCC, to relocate their production to other countries with no domestic mitigation or to keep on consuming carbon intensive products which are imported from such countries. To account for carbon leakage and to consider the impact of trade on national emission accounts, consumption based national inventories have been estimated by adjusting production based emission inventories in many studies. In this study, both production based and consumption based CO2 emission inventories were used to test the relation between economic growth and environment. The data was collected from the environmental accounts of World Input Output Database. They provide CO2 emission accounts of 40 different countries for a period of 15 years (1995-2009). This is a new form of dataset and is compiled using a set of harmonized input output tables and data on energy statistics. Data was used for 39 countries for a period of 13 years, i.e. from 1995-2007. The years 2008 and 2009 were dropped fearing that the economic crisis might influence results of the study. Taiwan was also dropped from the panel of countries due to unavailable data on GDP per capita that was retrieved from World Bank database. The study performed panel data analysis to test the relation between CO2 emissions and economic growth. Estimates were generated for the whole sample and for two sample sub-groups which are Annex I and non- Annex I countries. Annex I countries are mostly industrialized nations that are less vulnerable to the adverse impacts of climate change where as non-Annex I countries are usually developing countries and are more vulnerable to the adverse impacts of climate change and may also rely heavily on fossil fuel production and commerce. The results show a difference between production based and consumption based patterns. In terms of production decoupling was observed for the full sample and for Annex I countries. While in terms of consumption the relation was monotonically increasing inside the sample range. For non-Annex I countries the relation was strictly linear both in terms of production and consumption, showing that they are initial part of a larger EKC. The comparison of studies shows that there is a tendency of carbon leakage due to fragmented architecture of global emission mitigation effort. What appears to be the result of structural change in economy is actually a relocation of production to other regions. In terms of consumption patterns, economies do not change or keep on consuming more than before even if there is some reduction in emissions due to technological improvement and energy efficiency. If one leaves countries to grow completely unchecked then there is a high possibility that the world would soon surpass many climate tipping points beyond which recovery is not possible. This finding pushes the case for reforms in the system to move towards low consumption and low growth developmental models that can save the earth from this humanitarian crisis. Moreover, the importance of consumption based CO2 emissions inventory needs to be recognized in the international community and should be reported alongside production based emission inventories annually because it might help in developing a framework for equitable burden sharing for climate responsibility and ensure larger participation in mitigation effort. The research proposes these recommendations under the assumption that patterns observed in the study are representative of the world’s production and consumption based CO2 emission patterns. Also the study warns that the research be complemented with more information on underlying factors that can cause decoupling and the socio- political history of individual countries along with their relative position on power interest grid in order to properly guide policy discussions.","climate change; economic growth; Environmental Kuznets Curve; decoupling; production; consumption","en","master thesis","","","","","","","","","Technology, Policy and Management","Engineering and Policy Analysis","","Economics of Technology and Innovation","",""
"uuid:83bb3cd3-f9b8-41f9-bca3-2cbffafff9e1","http://resolver.tudelft.nl/uuid:83bb3cd3-f9b8-41f9-bca3-2cbffafff9e1","Departures 2020: A vision and concept for the Non-Schengen passenger ground process of KLM at Schiphol Airport using biometrics.","Vervoort, A.L.H.","Santema, S.C. (mentor); De Lille, C.S.H. (mentor)","2015","With the rise of self-services at airports, time has come to take the next step in optimizing KLM’s passenger ground process at Amsterdam Schiphol Airport (AAS). In the current non-Schengen departure process at Schiphol the various touch points that a passenger encounters in the process do not communicate with each other and there is no information exchange between stakeholders in the process. A passenger therefore has to present its boarding pass and/or passport at every touch point which can be frustrating and a hassle for the traveller. Time has come to remove this hassle by creating a smart, automated passenger ground process that allows on one hand its stakeholders to share information and by this take better informed decisions, and at the other hand improve the passenger experience considerably. Based upon a comprehensive internal analysis, external analysis and passenger and staff interviews a vision is created. The vision comprises four main values that are derived from the analysis and interviews. These values are: efficiency, control, comfort and respect. Resulting in the following vision: Subsequently a design framework is constructed that is based on the four main values. Each value consists of several building blocks, together these building blocks form the starting point for the creation phase. In the creation phase two concepts are designed, based on two of the four traveller types that are derived from the customer analysis. The two types that are chosen have the most opposing needs. Where the Human Traveller concept focuses on comfort and respect, the Modern Traveller’s concept main values are efficiency and control. This creates two rich concepts that look at the automated passenger ground process from two very different perspectives and cover the full spectrum of the vision. For the final design the values and perspective of the Modern Traveller are chosen, with the integration of some elements of the Human Traveller concept as these parts can coexist with the Modern Traveller concept. The choice for the Modern Traveller is inspired by the prediction that this group of passengers will become larger in the future whilst the Human Traveller group will shrink. The final design presents a solution in which data can be easily shared between stakeholders, and all stakeholders in the process are able make better informed decisions based on the information that is being shared between them. KLM for example will then be able to tell where a passenger is located in the process and whether or not the passenger has passed the border. For the passenger and for KLM the final design of the automated passenger ground process brings a lot of benefits concerning efficiency, control, comfort and respect. The process consists of the following five distinctive stages: 1. Preparation | Passengers will be able to fully prepare for their trip at home or at their destination. This preparation stage consist of mobile biometric enrolment, baggage labelling and a KLM baggage courier service. All routine departure hall procedures will be moved off-airport this way. By biometric enrolment the passengers face will become its token for the passenger ground process. 2. Service | Throughout their journey passengers are able to receive service and control their itinerary by the KLM Travel Assistant application on their mobile device. Because some passenger will have complex issues that cannot be solved by the app, a dedicated service area is created in the departure hall. This will be the main point of contact for passengers to turn to when they would like to get personal service. 3. Checkpoint | A single touch point is created in between landside and airside. This touch point integrates the boarding pass check, security check and border control in one. By implementing risk based security scanning the touch point is made more efficient and more comfortable for passengers. 4. Dwell time | During dwell time the main channel of contact for the passenger is the KLM Travel assistant app. The app provides passengers with push notifications when to proceed to their boarding gate. But also with personalized context aware e-services and indoor wayfinding. The app will also provide KLM with the necessary location information for the flight management app that is used by the gate agents in the boarding stage. 5. Boarding | The management app uses the information gathered in the passenger ground process to determine the progress of all passengers in the process and their exact location in the terminal. This information is used by the gate agent to make an informed decision whether or not to let a flight depart or to wait for passengers that are on their way to the gate. Subsequently the final design is evaluated against the project assignment and the constructed design framework. Further more recommendations are made and subjects for further study are suggested. Finally an implementation plan is provided, complemented with an implementation roadmap. The implementation plan lists concrete projects and tasks to be undertaken towards 2020. And the implementation roadmap places these projects in a feasible timeline. The projects in the implementation roadmap are divided in three categories: KLM projects, AAS projects and projects that should be executed in a joint effort. One of the first and biggest projects to be undertaken is the implementation of a new IT infrastructure at Schiphol Airport that has a plug-and-play architecture, as opposed to the current direct links and silo-based infrastructure, and that is able to fully facilitate the proposed data sharing between stakeholders. After the execution of all proposed projects, an automated passenger ground process will be in place in 2020 that is more efficient and comfortable, and in which passengers and staff feel in control and respected. It will help all stakeholders to take better informed decisions. And will allow KLM and Amsterdam Airport Schiphol to successfully compete with other major transfer hubs.","KLM; Schiphol; Biometrics; IT; Data Sharing; 2020; Vision; Passenger ground process","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product Innovation Management","","Master of Science Strategic Product Design","","52.310696, 4.768290"
"uuid:ed4c1256-700c-4e04-8da0-d8cb3fa74b8b","http://resolver.tudelft.nl/uuid:ed4c1256-700c-4e04-8da0-d8cb3fa74b8b","Resolving infeasibilities in the PESP model of the Dutch railway timetabling problem","Polinder, G.J.","Aardal, K.I. (mentor); Kroon, L.G. (mentor); Molinaro, M. (mentor)","2015","Many times the railway timetabling problem is infeasible. This means a set of constraints can not be satisfied at the same time. It is hard to solve this by hand. This thesis proposed two algorithm to resolve the infeasibilities and to come up with a timetable. It serves as an extention to the CADANS solver.","CADANS; MIP; PESP; Timetabling; Railways; Optimisation","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","Optimisation","",""
"uuid:11d4567a-63f3-4d6f-a223-e1f61a6f7bb9","http://resolver.tudelft.nl/uuid:11d4567a-63f3-4d6f-a223-e1f61a6f7bb9","On the Influence of Fines on the Sedimentation Velocity in Hopper Dredgers","Bleeker, N.","Van Giffen, I. (mentor); Van der Hout, R. (mentor)","2015","Clay particles, known for their adhesive properties, are commonly encountered in underwater soils. When producing large quantities of sand by means of dredging, fines are a byproduct and cause important viscosity changing effects altering the sand settling behavior. Much is already known in this field but knowledge lacks in the area where sand particles are affected by cohesive carrier fluids in environments similar to hopper settling areas during loading. By taking a closer look at the involved processes, knowledge is acquired in shear- and turbulent-flow sand-clay environments and another step is taken towards quantifying the effect of fines on the sedimentation velocity in hoppers. A versatile experimental setup is built allowing for separate shear flow and turbulence induced configurations. Shear affected sand settling velocities and turbulence induced concentration profiles are measured and analyzed. The shear flow settling effect shows contradicting results and leads to an interesting theory worthy of further investigation. The turbulence effect yields characteristic concentration profiles that are later used to determine key diffusion coefficients. Finally, clay characterizing factors are found using the theory proposed by Wang (1995). A 1DV model is developed using an advection-diffusion equation where the discretization techniques are based on an explicit method, a finite volume and an upwind scheme allowing settling of multi-sized particles. The simulation is used to determine diffusion coefficients for each of the conducted experiments. These diffusion coefficients yield interesting correlations with the input parameters finally resulting in an approximation of the diffusion coefficient as a function of the turbulent energy intensity allowing for a wider range of application.","Dredging; fines; clay; shear rate; diffusion; hindered settling; fall velocity; viscosity; shear settling; sedimentation; settling production; gelling; sedimentation velocity","en","master thesis","","","","","","","","2025-08-26","Mechanical, Maritime and Materials Engineering","Offshore & Dredging Engineering","","Dredging & Deep Sea Mining","",""
"uuid:5b859467-9631-49a0-9ad9-ddd593b33e69","http://resolver.tudelft.nl/uuid:5b859467-9631-49a0-9ad9-ddd593b33e69","Changing behavior during teleoperation by tricking the brain?: Exploring a practical application of body illusions","Wajon, L.V.","Mulder, M. (mentor); Abbink, D.A. (mentor); Van Paassen, M.M. (mentor)","2015","Teleoperation is widely used in human-hostile or otherwise inaccessible environments. However, using teleoperation to perform a task is more difficult than performing the task directly. A main factor for this is limited telepresence due to the absence or distortion of natural sensory feedback. An interesting possibility to increase telepresence and enhance teleoperation performance is inducing a Body Illusion which may give human operators the sensation that the remote tool belongs to their own body. This study investigated the possibility of inducing the Projected Hand Illusion during a teleoperated reaching task, and its effects on accuracy. The participants (n=16) reached for targets while avoiding stationary obstacles, by manipulating a master device coupled to a slave device. Three conditions were randomly presented: the Direct Control (DC) condition, showing the master device with the participants' own hand, the Projected Hand Illusion (PHI) condition, showing the slave device consisting of a 3D-printed hand designed to induce a Body Illusion, and the no Projected Hand Illusion (nPHI) condition, showing the slave device consisting of a 3D-printed object of similar shape designed to not induce a Body Illusion. A questionnaire was used to assess the subjective feeling of the Projected Hand Illusion. Based on the questionnaire responses, participants were grouped in the qualifying group (n=5) or the non-qualifying group (n=11). It was found that the Projected Hand Illusion was consistently induced in both conditions, and for both groups. Also, a significant difference in distance to target in the y-direction and x-direction was found between conditions PHI and nPHI; in the nPHI condition, participants kept more distance to the obstacle than in the PHI condition. This may suggest an increased perception of risk due to a difference in visual perception or due to the Body Illusion. However, as the Body Illusion was present in both conditions according to the metric used, and the differences between conditions were found for both groups, these findings cannot be attributed to the presence of the Body Illusion with certainty. Therefore, more in-depth studies investigating the possible causes are recommended. This research shows that a Body Illusion can be evoked during teleoperation, and possibly affect its performance. Therefore, this exploratory study gives rise to further research into the practical application of Body Illusions in teleoperation.","teleoperation; task performance; telepresence; Body Illusion; Projected Hand Illusion; multisensory illusion; body ownership; psychophysics","en","master thesis","","","","","","","","2020-08-18","Aerospace Engineering","Control & Operations","","Control & Simulation","",""
"uuid:9178f436-a0c3-4365-814a-3b375b2231c9","http://resolver.tudelft.nl/uuid:9178f436-a0c3-4365-814a-3b375b2231c9","Topology Optimisation of Thin Membranes Applied on a Parafoil Rib","Thedens, P.","Abdalla, M.M. (mentor)","2015","Membrane structures have a wide field of application in modern engineering due to their low weight-to-area ratio, which is especially exploited in kite design. The internal pressure of ram-air kites has to be well distributed over all cells in order to maintain the aerodynamic shape. By cutting holes in each rib the stagnated air can provide the required pressure in each cell. The question is, where to cut the holes such that the structural performance does not cause a decrease in aerodynamic performance? For that reason the membrane finite element (FE) solver developed in TU Delft in combination with geometrically non-linear topology optimization was utilized. The membrane FE solver is based on the tension field theory which allows the use of low density meshes and still being able to determine the membrane states: taut, wrinkled, or slack. Topology optimization supplies the user with an optimum material distribution in a design space for a given load. The combination of membrane FE solver and topology optimization resulted in an efficient method, which successfully reduced slack and wrinkled areas in membranes. The rib structure was optimized in a combination of two flight conditions, and the results indicate hole positions similar to the real ram-air rib model.","topology optimisation; membrane; tension field theory; ram-air kite","en","master thesis","","","","","","","","","Aerospace Engineering","Aerospace Structures and Computational Mechanics","","European Wind Energy Master (EWEM)","",""
"uuid:5db7a841-ae07-491a-86a3-630ce267c265","http://resolver.tudelft.nl/uuid:5db7a841-ae07-491a-86a3-630ce267c265","Stakeholder Management Methodologies for Software Development Projects Having Complex Stakeholder Environment with Different Sense of Urgencies","Sengur, S.","","2015","The needs of companies are evolving and becoming more demanding each year, which resulted in more complex stakeholder relations. Stakeholders do not always have the same sense of urgencies and their expectations from the same project might differ. Although current literature suggests successful methodologies for software development projects, it remains inadequate when different sense of urgencies take place among the stakeholders. This creates the risk of developing negotiated nonsense software. There is a need of a more broaden approach where human types of issues are involved together with the traditional project management methods. This research aims to propose a set of stakeholder management methodologies that could be implemented in a software development project environment where different sense of urgencies exist. Suggested methodologies are validated by expert opinion.","stakeholder management; different sense of urgencies; software development","en","master thesis","","","","","","","","","Technology, Policy and Management","Multi Actor Systems","","Systems Engineering, Policy Analysis and Management","",""
"uuid:d6d32d40-6b9f-4711-993f-cb83776ec045","http://resolver.tudelft.nl/uuid:d6d32d40-6b9f-4711-993f-cb83776ec045","A framework towards forward cooperation in the product life cycle of dredging equipment","Van Oeveren, M.I.J.","Ten Heuvelhof, E.F. (mentor); Schoenmaker, R. (mentor); Pruyn, J.F.J. (mentor); Neijens, J.J. (mentor); Tak, C.R. (mentor)","2015","The Dutch shipbuilding industry has a real competitive force in building complex, specialized and multipurpose vessels (Rabobank, 2014). However, the Dutch maritime sector has to deal with strongly growing competition worldwide. For the dredging sector this implies the need to innovate in order to remain competitive. This research focuses on the strategy of vertical forward cooperation to do so; the supplier will move into the maintenance aspects of dredging equipment, benefiting both the client and the supplier by expanding their services. This led to the research question of how a supplier of dredging equipment can achieve forward cooperation in the product life cycle. As a case study the company of Royal IHC is used for this research, in specific the product type of the IHC Beaver dredger is discussed. The research is divided into six parts; (i) a literature study; where the possible strategies for the forward cooperation are studied; a case study, where the (ii) IST (current) situation and the (iii) SOLL (ideal) situation are defined according to the current situation at IHC and a benchmark study. A system characterization for warranty cost analysis by D.N.P. Murthy and W.R. Blischke (2006) that describes how warranty policy, product reliability and product usage ultimately influence the warranty costs is used to structure these situations. Then a GAP analysis follows (iv) where the IST and SOLL are compared. This leads to the (v) fifth part of the research: the framework on how to achieve forward cooperation, which is supported with a model. Finally (vi) the conclusions and recommendations are given. Firstly the current situation (IST) is researched in which the IHC Beaver is provided with one-year warranty at sale. Two important groups of stakeholders are the clients and the sub-suppliers. For the procurement of parts the role of the sub-suppliers is essential because they deliver over 60% of the parts of the Beaver dredger. How agreements are made with sub-suppliers on the warranty period of the supplied parts is therefore essential when IHC has the intention to apply forward cooperation in the future. After the IST situation the ideal situation (SOLL) is defined. Forward cooperation can be achieved with different strategies; with the properties of the dredging market and the intention to achieve forward cooperation in the product life cycle of a standard industrial product, extended warranty has the best characteristics. Compared to the IST situation with base-warranty it is concluded that several uncertainties arise when extending the warranty with 5 years. The result of these uncertainties is that the usage and the reliability of the product cannot be predicted. This is a high risk for the supplier that will be translated in high warranty costs. In the perfect SOLL situation however most of the variables will become fixed, known or manageable. Resulting from the GAP analysis several actions that influence the warranty costs for the supplier are summarized; develop a new warranty policy, conduct a research into the product reliability and develop a method to control the product usage to reduce the risk of intensive or improper use. To implement forward cooperation this is what needs to be done; develop a structure where the variables ‘product reliability’ and ‘product usage’ determine the warranty costs and where the ‘warranty policy’ is the last variable to define the definitive ‘warranty costs’. Thereby the ‘warranty policy’ should also influence the ‘product usage’. With the knowledge of the literature and the case study the following changes are made to the original model of D.N.P. Murthy and W.R. Blischke (2006) to create the eventual framework; (i) the supplier is now considered an integrator; (ii) cooperation with the sub-suppliers (backwards cooperation) is included; (iii) the warranty policies control the warranty costs by in- or excluding parts, non- or renewing warranty and a possible decrease in the coverage of warranty costs for the integrator over time; (iv) the product usage is influenced by the warranty policy so that the usage risks are (more) controlled by the integrator. In the framework in figure 1 the warranty costs are completely dependent of the product performance, which in turn is determined by the product reliability and the product usage. To make a reliable estimation of the covered warranty costs it is of great importance that both the product reliability and the product usage are known. Furthermore the framework shows that the supplier of dredging equipment can rather be seen as an ‘integrator’ that relies on the products of sub-suppliers, therefore the supplier of dredging equipment needs to apply backward cooperation to achieve forward integration. To be able to influence the warranty costs the supplier of dredging equipment needs to offer several warranty policies that suit the product usage profile of the client. By providing different options the supplier is able to reduce the financial risks and the expected warranty costs. Before the supplier of dredging equipment is able to offer the extended warranty, it is highly recommended to take these actions that will form the basis for the extended warranty service; (1) start logging data on product usage and product reliability; (2) cooperate and negotiate with the sub-suppliers; (3) investigate the failure mode of all parts and systems; (4) determine the warranty cost (modelling); (5) define the warranty policies and apply these to determine the covered warranty costs. Only when these actions are undertaken extended warranty can be successfully implemented by the supplier of dredging equipment.","forward integration; forward cooperation; dredging; CSD; product life cycle; warranty; extended warranty; vertical forward cooperation; maintenance; asset management; single case study","en","master thesis","","","","","","","","2016-08-26","Civil Engineering and Geosciences","Structural Engineering","","Construction Management and Engineering","",""
"uuid:c87e2b31-458f-4ffc-8d35-6034114d8f24","http://resolver.tudelft.nl/uuid:c87e2b31-458f-4ffc-8d35-6034114d8f24","Design of a compact bicycle for the urban commuter","Dokter, R.G.","Van Heur, R.J.H.G. (mentor); Brand, D. (mentor)","2015","Even in a bicycle friendly infrastructure as the Netherlands, lack of space is a continually rising problem. Re-urbanization describes the increasing population of especially young adults in the urban environments of conurbation ‘de Randstad’. These young adults have a changing perception on mobility and shift away from car usage in favor of public transportation and cycling. These changes induce more cycling and lead to more bicycles, thus an increasing lack of space. To accomodate this changing perception on mobility and create more space in densely populated cities, a new bicycle concept was created for Amsterdam based bicycle manufacturer Veloretti. The Veloretti URBAN is a compact bicycle designed for the city. Small wheels and a sporty geometry make it optimal for cycling through dense urban environments. With one effortless motion the bicycle can be folded and significantly reduced in size. It can be rolled in tight spaces and the low weight and intuitive shape make it easy to carry around. The bicycle can be easily stored in the home environment of the user, decreasing lack of space on the streets and preventing theft. The bicycle can be taken in different forms of public transportation, adding a level of flexibility and freedom to the mobility of the user.","urban; folding bicycle; commuter; compact bicycle","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Applied Ergonomics & Design","","Master of Science Integrated Product Design","",""
"uuid:ff7acb60-a3e9-4f72-9c8d-bc65398d8d6a","http://resolver.tudelft.nl/uuid:ff7acb60-a3e9-4f72-9c8d-bc65398d8d6a","Empirical Software Linguistics: An Investigation of Code Reviews, Recommendations and Faults","Hellendoorn, V.J.","Bacchelli, A. (mentor)","2015","Communication is fundamental to human nature and underlies many of its successes as a species. In recent decades, the adoption of increasingly abstract software languages has supported many advances in computer science and software engineering. Although in many regards distinct from natural language, software language has proven surprisingly similar to it as well and has been studied successfully using natural language models. Recent studies have investigated this ""naturalness"" property of software in relation to a variety of applications including code completion, fault detection, and language migration. In this thesis, based on three research papers, we investigate three main aspects of software naturalness. Firstly, we investigate the relation between perceived (un)naturalness of source code (according to the statistical model) and the reaction to such code by software developers. In open-source projects, we find that those contributions which contain code that (statistically speaking) fits in less well are also subject to more scrutiny from reviewers and are rejected more often. Secondly, we investigate an application of highly predictable code: code completion. Previous work had evaluated the performance of language models in this application in isolation; we compare the language model approach to a commonly used code completion engine. We find that it compares favorably, achieving substantially higher accuracy scores. In particular, a combination of the two approaches yielded the best results. Finally, we investigate instances of highly unpredictable code in order to automatically detect faults. We find that buggy lines of code are substantially less predictable, becoming more predictable after a bug is fixed. Our bug detection approach yields performance comparable to popular static bug finders, such as FindBugs and PMD. Our results further confirm that statistical (ir)regularity of source code from a natural language perspectives reflects real-world phenomena.","software linguistics; software engineering; fault detection; code completionc; code review","en","master thesis","","","","","","","","2015-08-18","Electrical Engineering, Mathematics and Computer Science","Computer Science","","Software Engineering","",""
"uuid:7abdbffe-dacb-442e-89fd-9747b29d5d84","http://resolver.tudelft.nl/uuid:7abdbffe-dacb-442e-89fd-9747b29d5d84","Bending dual-phase steel: A finite element analysis","Hollenberg, F.","Janssen, M. (mentor)","2015","Bending of dual-phase (DP) steels has introduced new issues concerning the analysis by finite element (FE) modelling. During the investigation of the microstructure of a DP1000 steel, it is found that there is crack formation at lower bending angles and elongations than would be expected based on the forming limit curves (FLCs). The results of an FE analysis with a continuum material model without taking into account damage formation and subsequent softening do not show behaviour similar to what is seen in actual microstructures. The prediction of the FE analysis will therefore not be a good representation of the bendability of the DP steel. An addition to the continuum analysis is made by implementing a damage and softening model. Localization effects due to the softening of the material arise in places similar to the real material. However, mesh sensitivity is still present for different mesh sizes, despite the addition of a delocalization parameter, and alter the results of the simulations. To improve the analysis of DP steels, a new representation of the microstructure is implemented in the finite element model. A zone with a Voronoi diagram is used as a representative volume element (RVE) for the DP steel. The diagram is embedded in the continuum sheet analysed in the simulation and represents both the ferrite and the martensite phases. The interaction of the ferrite and martensite phase in the embedded Voronoi diagram determines the strain patterns that develop during the bending simulation. An investigation of different Voronoi diagrams on the former force versus former displacement is made. It is not necessary to introduce damage and softening to create the strain patterns which are seen in the real material. However, material degradation is still required to obtain the softening behaviour at high former displacement.","","en","master thesis","","","","","","","","2015-08-25","Mechanical, Maritime and Materials Engineering","Materials Science & Engineering","","Materials Engineering & Applications (MEA)","",""
"uuid:4a18c21a-04a6-41ec-b1f1-f437e8177355","http://resolver.tudelft.nl/uuid:4a18c21a-04a6-41ec-b1f1-f437e8177355","Introducing distributed networks to designers: Development of an educational software tool and a methodology for its evaluation","Speek, I.C.T.M.","Jaskiewicz, T.J. (mentor); Jonker, C.M. (mentor); Zuniga, M. (mentor); Van der Helm, A.J.C. (mentor)","2015","Available connectivity in everyday objects has inspired design experts to develop methodologies for designing interactive environments - large-scale environments existing out of multiple embedded devices that interact with a user as if to be a single entity. The computer science community uses ad hoc distributed networks to accommodate scaling complexities. Distributed networks use global-to-local programming to describe complex global behavior of an interactive environment using simple local rules for each embedded device. The resulting emergent quality to these behaviors is similar to the behavior seen in birds in a flock. This thesis uses a multi-disciplinary approach to design and develop an educational software. This software tool introduces the interactive qualities in programming distributed networks to designers, assuming this enables their ability to design interactions for the increasingly large interactive networks. A methodology to measure the effect of methods and tools in the education of designers is designed to evaluate the tool’s educational effect. Quantitative results suggest that the tool both enhances the designer’s understanding of the interactive qualities in programming a distributed network as well as their ability to apply these qualities in their interaction designs. Qualitative results show that while designers remain to have trouble motivating the design for this alternative network topology, they are inspired and excited for further introductions.","distributed networks; designers; tool design; interaction design; interactive environments; ubiquitous computing; pervasive systems; educational tools; evaluation methodology; design; global-to-local programming","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Interactive Intelligence","","Embedded Systems","",""
"uuid:a0bcdbba-3ccc-4622-ab8d-6ac2e4a1e598","http://resolver.tudelft.nl/uuid:a0bcdbba-3ccc-4622-ab8d-6ac2e4a1e598","Improved Design of a High Lift System for General Aviation Aircraft","Florjancic, D.","Veldhuis, L.L.M. (mentor); Steenhuizen, D. (mentor)","2015","Relatively high wing loading leads to increase in fuel efficiency in commercial as well as in small general aviation aircraft, but requires sophisticated high lift devices to keep the take-off and landing distances within acceptable limits. High lift devices can in turn have a detrimental effect on cruise performance, and thus fuel efficiency, in the form of additional parasitic drag of the high lift system mechanism fairings under the wing. In addition, the weight and complexity of the high lift system increases with its performance. The purpose of this research is to increase the payload of a highly efficient propeller driven 4-seater general aviation aircraft by improving its plain flap high lift system while the range stays the same. Therefore a detailed design of the high lift system is required, as well as the evaluation of the overall aircraft performance. A study of existing high lift systems in general aviation aircraft is conducted, based on which a preliminary design decision to implement a single-slotted flap with a dropped hinge mechanism is made. An optimization loop is developed within which the flap geometry is generated based on nine design variables (including the position of the hinge point and the flap deflection angle) and the clean configuration airfoil shape. Two-dimensional aerodynamic analysis of the two-element airfoil section is performed by the MSES code at three different angles of attack. A method of reading the maximum value of displacement thickness on the flap upper surface is implemented to algorithmically detect separated flow and discard the flap designs that suffer from separation at low angles of attack in order to avoid jumps in the lift curve. Three-dimensional aerodynamic characteristics of the aircraft with deployed flaps are estimated using semi-empirical methods. The drag of the mechanism fairings is also estimated by a semi-empirical method. A simple performance model is used to predict the payload, which represents the objective function of the optimization. Landing and take-off distances are also calculated using the performance equations. Matlab's genetic algorithm and pattern search algorithm are used to perform global and local optimization of the flap geometry. The resulting single-slotted flap design increase the maximum take-off weight by 13\% which results in the increase in payload of 42\%. Take-off distance increases by 12.5\% and landing distance increases by 16.5\%. Maximum sectional lift coefficient is improved by 27\% with respect to the original plain flap. The additional cruise drag due to mechanism fairings increases the fuel weight by 3\% for the range of 1000 nm. Limiting phenomena in achieving the highest two-dimensional lift coefficient is the bursting of main element's wake, rather than flow separation off the airfoil surface. The method of monitoring the displacement thickness of the flap wake is successful in ensuring that the optimized flap has no jumps in the lift curve.","high lift system; flap; payload; general aviation aircraft","en","master thesis","","","","","","","","","Aerospace Engineering","Flight Performance and Propulsion","","","",""
"uuid:9070de1a-6b2a-432a-9eea-c60ca9633391","http://resolver.tudelft.nl/uuid:9070de1a-6b2a-432a-9eea-c60ca9633391","Robust Downstream Communication and Storage for Computational RFIDs","Tan, J.","Pawelczak, P. (mentor)","2015","Computational RFID (CRFID) devices are emerging platforms that can enable perennial computation and sensing by eliminating the need for batteries. Although much research has been devoted to improving upstream (CRFID to RFID reader) communication rates, the opposite direction has so far been neglected, presumably due to the difficulty of guaranteeing fast and error-free transfer amidst frequent power interruptions of CRFID. With growing interest in the market where CRFIDs are forever-embedded in many structures, it is necessary for this void to be filled. Therefore, we propose Wisent-a robust downstream communication protocol for CRFIDs that operates on top of the legacy UHF RFID communication protocol: EPC C1G2. The novelty of Wisent is its ability to adaptively change the frame length sent by the reader, based on the length throttling mechanism, to minimize the transfer times at varying channel conditions. We present an implementation of Wisent for the WISP 5 and an off-the-shelf RFID reader. Our experiments show that Wisent allows transfer up to 16 times faster than a baseline, non-adaptive shortest frame case, i.e. single word length, at sub-meter distance. As a case study, we show how Wisent enables wireless CRFID reprogramming, demonstrating the world's first wirelessly reprogrammable (software defined) CRFID.","RFID; wireless reprogramming; CRFID; downstream","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Software Technology","","","",""
"uuid:a4dd7506-88be-42d6-8a82-fc95e57095c1","http://resolver.tudelft.nl/uuid:a4dd7506-88be-42d6-8a82-fc95e57095c1","Ag NWs for Organic Photovoltaic Cells: Semitransparent and Stretchable Devices","Herrera Rocher, F.R.","Smets, A.S. (mentor); Galagan, Y.G. (mentor)","2015","The current developments on organic photovoltaic (OPV) solar cells are inspired by the idea that they can be processed from solution. One of the challenges in developing fully solution-processed OPV devices is the design of well-performing electrodes with low cost of deposition. This has been one of the focus of the academic and industrial community. Nowadays, the use of ITO as a semitransparent electrode has become a bottleneck. This is because it is brittle, has Indium (a rare element), and needs a high energy intensive deposition process. There are many alternatives presented but none of them match the performance of ITO. Here, we report a full solution-processed ITO-free semitransparent OPV device based on silver nanowires (Ag NWs). To demonstrate the potential of Ag NWs in OPV devices, they were employed as a bottom and top electrode without a post treatment to decrease their roughness. Record devices achieved only a decrease of 6.5% of efficiency in comparison to ITO based reference devices. Furthermore, due to its good bending properties, a working stretchable device was fabricated by depositing the different OPV layers on a pre-stretched elastomeric membrane. These results indicate that Ag NWs can successfully replace ITO as an electrode.","Ag NWs; organic photovoltaic cells","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Photovoltaic Materials and Devices","","Sustainable Energy Technology","",""
"uuid:355349b9-d8f2-48f5-8dcb-014c025dc50d","http://resolver.tudelft.nl/uuid:355349b9-d8f2-48f5-8dcb-014c025dc50d","Sustainable consumption and mindfulness: A proposed conceptual model and an empirical explorative study","Studer, M.R.","Quist, J.N. (mentor); Flipse, S.M. (mentor); Wehrmann, C. (mentor)","2015","This thesis was set out to explore the links between mindfulness and consumption, and specifically to gain clarity on how mindfulness impacts household consumption patterns. This to provide insights into whether mindfulness could be a constructive approach to sustainable consumption that would increase personal well-being and reduce environmental impact. The central question of this thesis is: How can mindfulness practice contribute to sustainable household consumption patterns within Western countries? Since little empirical research exists on this topic, we adopted an explorative qualitative research approach to answer this question and focused on describing and understanding the contribution of mindfulness to sustainable consumption rather than quantifying it. In the first part of this thesis, we developed a conceptual model on the relationship between mindfulness and consumption patterns; in this process we interviewed a set of scientific experts and a set of practitioners to improve our preliminary model, which was based on literature. In a second part, we interviewed mindfulness practitioners on the effect (if any) mindfulness had in general on their everyday life practices and in particular on their eating, mobility and living habits.","sustainable consumption; sustainable lifestyle; mindfulness","en","master thesis","","","","","","","","","Technology, Policy and Management","Technology, Dynamics and Sustainable Development","","","",""
"uuid:48f59529-f0c9-4a7e-abd5-c81edce3268e","http://resolver.tudelft.nl/uuid:48f59529-f0c9-4a7e-abd5-c81edce3268e","Efficient and accurate simulation of nonlinearly coupled multiphase flow in porous media","Kardale, M.","Cusini, M. (mentor); Hajibeygi, H. (mentor)","2015","In this work, the non-linear behaviour of saturation transport equations in sequential implicit simulation strategy for multi-phase, immiscible and incompressible displacements are investigated. In reservoir simulation, use of explicit time schemes can lead to severe time-step size restrictions, specially when strong nonlinear terms exist. For highly heterogeneous formations, when a global time step needs to be taken, the CFL numbers can vary by orders of magnitude through the entire domain. In such cases, explicit schemes are not practical, and implicit time schemes are typically followed. The transport equation which describe the fluid flow in porous media in space and time are often highly non-linear and tightly coupled with the flow (pressure) equation. Characterized by S-shaped flux functions, they can also be non-monotone in presence of strong buoyancy (and capillary) forces. Through the phase velocities, which depend on pressure, the transport equation is strongly coupled to pressures equation. In presence of strong capillarity, the pressure solution also depends on the slope of capillary function, which is a function of saturation. An industry standard procedure is to use Newton method to first linearize these coupled governing equations, and iteratively reach a converged solution. To study the nonlinearity within the transport equation, first, a two-dimensional twophase simulator based on all types of Implicit Pressure Explicit Saturation (IMPES), Sequential Implicit, and Fully Implicit strategies are developed. Both capillary and gravitational effects are being considered. As to extend the stability limits of the sequential implicit strategy, flux correction method is investigated and implemented in the transport equation. All cases of viscous, buoyancy and capillary dominated flows are studied, where, in the cases of strong nonlinearities, non-convergence and severe time-step restrictions have been observed. Stability analysis of the flux functions in buoyancy and capillary dominated flows is performed along with a time-step control strategy, which is shown to result in unconditional convergence irrespective of the time-step size selection. Finally, application of flux correction strategies to EOR processes, where foam flows through the rock formation, is presented. Such a study has never been performed in the literature.","reservoir simulation; non-Linear Stability; multiphase flow in porous media","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Section for Petroleum Engineering","",""
"uuid:8f3235ea-6efa-466e-9e48-9eda89bb04e7","http://resolver.tudelft.nl/uuid:8f3235ea-6efa-466e-9e48-9eda89bb04e7","Modelling Turbulent Non-Premixed Combustion in Industrial Furnaces","Kadar, A.H.","Lahaye, D.J.P. (mentor); Vuik, C. (mentor); Keijzer, M. (mentor)","2015","Measuring the temperature distribution inside the rotary kilns, using thermocouples for instance has proven to be difficult due to the harsh operating conditions of the kiln. Numerical modelling of turbulent combustion and the associated physical phenomenon thus proves to be an indispensable tool towards predicting the kiln operating conditions. The purpose of the present work was to make a step towards modelling the cement rotary kiln used by Almatis B.V. in Rotterdam for the production of calcium-aluminate cement. The detailed mathematical model of the rotary kiln would be developed using the open source CFD toolbox OpenFOAM. The main advantage of OpenFOAM is that, contrary to most of the commercial CFD software, it is license fee free and allows access to the source code, which was also the motivation behind this work. To accurately model the Almatis kiln the following important phenomenon have to be taken into account: turbulent non-premixed combustion of hydrocarbon gases in the burner, radiative heat transfer distribution in the kiln and, the conjugate heat transfer through the furnace walls. In the present work the new solver implemented in OpenFOAM for turbulent combustion and radiation modelling was validated using the benchmark Sandia Flame D test case. There was good agreement seen between the results from simulations and experimental data for the Sandia Flame D test case indicating the adequacy and accuracy of the implemented transient solver and its readiness for further combustion application development. Due to the very complex geometry of the Almatis Kiln the relatively simple geometry of the Burner Flow Reactor (BFR) was considered for further simulations. The simulation results obtained for the Burner Flow Reactor (BFR) were compared with the commercial package ANSYS Fluent for consistency. The OpenFOAM toolbox was evaluated in two stages of increasing complexity: isothermal(cold) flow simulation and non-premixed gas combustion simulation using a turbulent incompressible flow solver. The cold flow comparison gave almost identical results for both OpenFOAM and ANSYS Fluent. However the reacting flow results showed varying agreement with ANSYS Fluent. The mass fraction of species showed good agreement but the temperature profile showed some deviations. With more stringent global NOx emission standards, predicting NOx formation in industrial furnaces is now a priority. The CFD modelling of pollutant NOx formation was considered in the present work. A new solver in OpenFOAM was developed for thermal NO prediction. The solver was validated with the ANSYS Fluent NOx post-processing utility using the Burner Flow Reactor geometry. The effectiveness of NOx reduction mechanisms including the variation of air to fuel equivalence ratio and flue gas re-circulation (FGR) was demonstrated using the Burner Flow Reactor test case. From this study it was concluded that OpenFOAM is a promising toolbox for modelling turbulent combustion and can be used for predicting the operating conditions of complex industrial furnaces. The current bottleneck identified with OpenFOAM is the very high computational cost of the implemented transient solver for turbulent combustion and radiation modelling. The computational cost of the transient solver far exceeds that of the steady state solvers available in commercial packages for example ANSYS Fluent. Therefore, to simulate very large scale industrial furnaces such as the Almatis Kiln in realizable time the implementation of a steady state solver for turbulent combustion applications in OpenFOAM is indispensable. It would also be essential to include the accompanying phenomenon of conjugate heat transfer into the solver. These can be accomplished as a part of the future work.","combustion; OpenFOAM; computational fluid dynamics; rotary kiln","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","COSSE","",""
"uuid:cb17208d-53ec-4f0e-817e-5843bc4a7be7","http://resolver.tudelft.nl/uuid:cb17208d-53ec-4f0e-817e-5843bc4a7be7","Flexible Armour","Breedveld, S.C.","Jansen, A.J. (mentor); Silvester, S. (mentor)","2015","Field hockey is a growing sport in the Netherlands, where both the male and female national squads belong amongst the best teams in the world. Field hockey requires a lot of technical capabilities from the player, which not all players possess. This sometimes leads to uncontrolled strikes of the ball, which can lead to accidents and injuries. Players wear protection equipment to prevent as much injury as possible. Current protection equipment causes discomfort, which decreases the level of hockey performance. The goal of the project is to improve a part of the protection gear for field hockey applications by enhancing comfort without compromising safety. The following problem definition is applicable in this project: “How can the current protection gear for field hockey be improved in terms of comfort, while maintaining sufficient protection to prevent injuries?” Field hockey is relatively dangerous, even though protection equipment is mandatory and widely available in all shapes and sizes. According to research conducted by Veiligheid.nl 110.000 injuries occur in the Netherlands alone each year, which is high considering there are 248.859 players. This is 6.2 injuries every 1000 hours, which is three times more then sports in general. 48.000 injuries require medical attention. 10.000 players annually visit the emergency room, for more immediate attention, yet less then 1% has to be admitted in the hospital, which is much lower than sports average(5%). The risk of sustaining an injury is higher, but the effect is less severe can be concluded. Statistics show that the lower leg would benefit most of a new type of protection equipment The interaction between the player and the protection equipment should accommodate each other as much as possible, which in term will effect the perceived discomfort. The lower leg consists of different types of tissue, where muscle, bone, ligaments and nerves all have a specific function and react differently to the product and the surroundings. Drop test experiments show that a collision of equal energy on bone results in three times more stress compared to muscle, due to shorter impact time, impact distance and smaller surface area. A lot of different movements is required in the game, which result in a lot of different joint positions. These all have to be related to the lower leg protector. Current protection uses the same material composition for the protection of these tissues, which is not related to the interaction with the player and cause discomfort. Consumer research shows that comfort could be improved by enhancing the fit, coverage, and regulation of heat and moisture. The same amount of protection is required, but statistics suggest that current protection does not accurately protects the leg. Flexible Armour is a concept of lower leg protection that focuses on specific and accurate protection for the lower leg, while allowing the leg to following the natural movements without causing unwanted friction. The concept consists of a sock with special designed embedded padding structure and a plastic shield. The sock acts as a compression socks and tightly pulls the padding structure as close to the leg as possible. The plastic shield is inserted and makes sure that the entire protection equipment stays in place, while providing extra protection where it is required. Different types of protection are incorporated, specific to the area that is covered. The ankle is protected by a highly flexible and chamfered set of padding in combination with a plastic housing called the APS(Ankle Protection System). The padding allows all ranges of motion of the ankle, without compromising on coverage and protection. Additional coverage for the front-, under- and backside of the ankle provide extra protection compared to current protection. The plastic shield protects the near surface shin and calve bone and acts as a damper that redirects forces to the muscle tissue around the bones as much as possible. The knee is protected by a special padded design, which reduce the peak forces and stresses up to 50% compared to no protection. The sock is a highly flexible material which allows a large range of ankle, calf an knee circumferences to fit within one single size of the product. The padded sides are flexible and follow the curves of the leg without clamping the calf. Both geometry and material allows a better fit for the target group, within a small, medium and large sizing system. Dissipation of heat and moisture is possible via a special vent design in the padding. The vent is shaped like a funnel, which creates a large surface area for ball impact on the outside and a large surface area for thermal regulation close to the leg. Flexible Armour is a design that is much more specifically designed to combine comfort and protection in a harmonic way, without them compromising on each other. Protecting and allowing movement where the human body requires. It can be the philosophy and inspiration for all types of protection equipment in the future.","design; protective equipment; lower leg; field hockey","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Industrial product design","",""
"uuid:8bb83258-74a9-4113-a4e6-bb71d1af12c1","http://resolver.tudelft.nl/uuid:8bb83258-74a9-4113-a4e6-bb71d1af12c1","Information Sharing and Risk over International Trade Lines: The Case of FloraHolland","Morales Velasquez, S.","Hulstijn, J. (mentor); Klievink, B. (mentor)","2015","Multiple frameworks and procedures are used in organizations to analyse and assess risks in the most efficient way possible. COBIT, COSO or ISO as some of the most popular frameworks used to evaluate enterprise threats, but each of them offer an independent view on risks that are not the best solution for chains or well stablished organization networks that could benefit of a chain approach to assure the correct and efficient process in these integrated scenarios. A stronger tie between actors in chain processes, increases the need to design and develop capable information platforms that support the regular and continual exchange of information in the supply chain and assess the risks associated with the development of this integrated network. This research aims to evaluate the applicability of an integrated assurance approach on a complex trade lane as a solution to manage and assess risks, where they aren’t perceived as independent scenarios but dependent of the environment. The CANTOR approach refers to ‘Chain Assurance Network Transference of Obligations and Risk-Control’ and it is basically a model that aims to provide guidance on establishing assurance in chains by approaching the complete process and all the actors involved as one virtual organization. This will be done by analyzing the Kenya trade lane by Air of FloraHolland and validating the current state of the chain and the possible risk scenarios in the process. To reach this objective, the following research question has been defined: “Is the CANTOR approach a suitable solution to performRiskManagement for Information sharing that copes with international regulations and trade compliances within the trade lane for shipping flowers from Kenya to the Netherlands by air?” By combining theoretical knowledge, the analysis of current status, processes and activities and main risk scenarios in the aforementioned trade lane, a first approach on the applicability of the integrated assurance approach and governance model will be verified, exposing the gap between theory and practice, clarifying how risk management can be implemented in the Kenya trade lane with the integral approach: CANTOR. The first part of this research consists of the gap analysis. Theory from literature review on risk management, trust, risk assurance, information integration, among others, are compared with the reality of the process state acquired through interviews with actors fromthe Kenya Trade Lane. The results of these interviews define the main risk scenarios of the process regarding information sharing, that will provide insight in the main points to evaluate the suitability of the integrated assurance approach. The second part consists of the design of the structural interviews that will provide the status of the chain regarding how aligned, equipped and organized are the actors in the trade lane in order to effectively apply the integrated assurance and governance control model. The third and final part explains either the CANTOR approach is suitable for the trade lane or not, why and both the benefits or disadvantages of implementing such an approach. To answer this main question, a complete answer is also provided for each of the four sub-questions defined for the research project. Besides contributing to the extant body of knowledge by providing a certain amount of empirical evidence, the study is rich in practical implications for the Kenya Air trade lane of FloraHolland and the information shared in the process. The conclusions could be used for further research, and the final recommendations could be used as additional findings to be considered by future projects that want to evaluate the suitability of the integrated assurance approach in other processes.","risk management; supply chain management; assurance","en","master thesis","","","","","","","","2016-08-25","Technology, Policy and Management","Management","","Management of Technology","",""
"uuid:8a5482e2-3b55-4628-96e4-45f3adffd1ee","http://resolver.tudelft.nl/uuid:8a5482e2-3b55-4628-96e4-45f3adffd1ee","Multiscale Restriction Smoothed Basis Method for Fractured Porous Media (F-MsRSB)","Shah, S.Y.","Hajibeygi, H. (mentor); Lie, K.A. (mentor); Tene, M. (mentor); Moyner, O. (mentor)","2015","This thesis proposes a novel multiscale method for simulating fluid flow in fractured porous media. Broadly speaking, this pertains to oil, gas and geothermal energy reservoirs.","multiscale methods; fractured porous media; restriction smoothed basis functions; multiphase flow; embedded fracture modelling; scalable linear solvers","en","master thesis","","","","","","","","2016-08-26","Civil Engineering and Geosciences","Department of Geoscience and Engineering, Section Petroleum Enginnering","","Petroleum Engineering","",""
"uuid:2f790d7c-f7b7-42ab-b3a9-9ddb7b9d73b6","http://resolver.tudelft.nl/uuid:2f790d7c-f7b7-42ab-b3a9-9ddb7b9d73b6","Explaining interest rate spreads from a debt sustainability indicator.","Boelee, M.","Oosterlee, C.W. (mentor); Van der Schans, M. (mentor)","2015","The aim of this MSc project is to investigate whether the dynamics of the interest rate spreads can be explained by a debt sustainability indicator. In this thesis, we evaluate the debt sustainability indicator with a new model. The essence of this model is to produce forecasts for several economic variables, where the government debt is one of them, based on historical data. With the obtained economic forecasts, we can estimate with the indicator the risk of a significant government debt increase in the near future.","Debt sustainability","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","Financial Engineering","",""
"uuid:541b878e-9db5-4cca-82b5-d0be6c2f1f9c","http://resolver.tudelft.nl/uuid:541b878e-9db5-4cca-82b5-d0be6c2f1f9c","Stimulating Public-Private Cooperation for the Strategic Replacement of Infrastructure in the Netherlands: The Role and Formulation of Public-Private Arrangements","Van der Beek, P.P.","Ten Heuvelhof, E.F. (mentor); Broekhans, B. (mentor); Ruijgh-van der Ploeg, T.P.M. (mentor); Roovers, G. (mentor); Vergouwen, J. (mentor)","2015","At the dawn of a large infrastructure replacement program in the Netherlands the question rises whether current forms of public-private partnerships in infrastructure projects are sufficient to deal with the complexities involved in large scale replacement of water infrastructure objects. It is stated that the concept of public private cooperation is expected to be able to provide innovative and cost efficient solutions by means of smartly bundling expertise knowledge. Examination of case Stuwen Maas revealed that full cooperation, in the sense of client and contractors becoming equal partners, is not most efficient, however the relationship between public and private parties is strongly moving towards cooperation. In order to further develop public-private cooperation in the Netherlands four recommendations are formulated. First, Rijkswaterstaat (public client) should make performance based governance their core business. Second, Rijkswaterstaat should develop a clear perspective on the future; both with regard to it's own role in infrastructure management, as the development of the infrastructure network itself. Third, both market parties and Rijkswaterstaat should built institutional capacity in order to facilitate cooperative arrangements. Special attention need to be paid to joint development of knowledge, design of clear responsibilities and the creation of a public-private trust relationship in which the cooperative arrangements can thrive. Fourth, further research need to be done into the specification of long-term oriented, flexible and general arrangements, since these arrangements are considered to have the most potential value for strategic replacement of infrastructure.","Public-Private Cooperation; Public-Private Partnerships; Infrastructure Management; Asset Management; Infrastructure Replacement; Case Study; Socio Technical Systems","en","master thesis","","","","","","","","","Technology, Policy and Management","POLG","","SEPAM","",""
"uuid:fab698b7-f540-4770-a1ff-960d1228c8d5","http://resolver.tudelft.nl/uuid:fab698b7-f540-4770-a1ff-960d1228c8d5","Variable Selection","Becker, T.","Van der Meulen, F.H. (mentor)","2015","In this thesis several methods for variable selection for statistical models are examined. There is specific attention for variable selection in so called ""dependent data"", in which there exists a strong correlation between the independent variables.","statistics; variable selection; mathematics","en","bachelor thesis","","","","","","","","2015-08-23","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","Statistics","",""
"uuid:7893b612-275d-4658-a669-165507b7452d","http://resolver.tudelft.nl/uuid:7893b612-275d-4658-a669-165507b7452d","Future fuels for chemical tankers","Kleijn, J.","Hopman, J.J. (mentor)","2015","Feasibility study to the applicability of alternative fuels on chemical tankers. Only summary available because of confidentiality.","alternative fuels; chemical tanker","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Design Production and Operation","","Ship Design","",""
"uuid:4d3c963b-f192-4020-b08c-f9fbe2ef1b53","http://resolver.tudelft.nl/uuid:4d3c963b-f192-4020-b08c-f9fbe2ef1b53","Using Serious Gaming To Make Operations Safer On Anchor Handling Tugs","Bhatt, K.","Koornneef, F. (mentor); Lukosch, H.K. (mentor); Schothorst, P. (mentor); Verbraeck, A. (mentor)","2015","To an observer, it might appear that anchor handling is a fairly simple straightforward and profit making business. However, with deep-water drilling and fluctuations in price of oil, the operation is becoming riskier than ever before. Besides, operational and environmental constraints, the crew also has to deal with pressures of time and money. This causes severe strain on the bridge officers and consequent incorrect decision-making can jeopardise the entire operation. Moderating these human factors via a training simulator can dramatically improve safety of the operation. The objective of the thesis is thus to moderate these human factors by the design of a robust and affordable anchorhanding training simulator. This objective is realised by combining the fields of safety science and game design. The scope of this thesis is limited to the operational aspects with a focus on human factors. The primary audience for this simulator is the bridge crew. The main research question is formulated as: “How can a simulation game be used to improve the safety on an anchor handling vessel?”. Systems oriented approach was used to achieve the objective. The research progressed in non-linear iterative steps. The risk identification part was achieved using the SPEAR methodology in which various aspects of operation description, risk identification, scenario modelling and quantification were performed. Techniques like summary matrices, scenario swimlanes and AHP were used in the SPEAR methodology. Novel and uncertain scenarios were identified and developed for the use in the game. The entire step was supplemented by interviews with experts to understand the practicalities of the operation. This provided the stepping stone for the next stage of game design. Based on risk identification, an online game was created and disseminated to expert mariners. This game was meant to be a prototype for the further development of an adequate training medium. Prior to dissemination the game was verified using cognitive walkthrough method and post-dissemination it was evaluated using Raser's (1969) criteria for validation. This thesis relies on adaptations and modifications in methods from diverse fields for the purpose of this thesis e.g.: SPEAR methodology, AHP, scenario swimlanes, Safe Envelope of Operations (SOE), Raser's criteria and merging Triadic Game Design (TGD) into Game Design & Development (GDD). These means stand uniquely by themselves and are a testament to creative adaptation and the systems engineering approach. The game although verified was not validated fully. This was primarily due to psychological problems. However, overall the game does show the promise of moderating human factors. Hence, a set of recommendations are specified for implementing a realistic training simulator. These specifications are based on the books of GDD and TGD. To answer the main research question: Operations on an AHTSV are definitely dangerous and one wrong decision can capsize the vessel or jeopardize the entire operation. Ensuring safety by moderating human factors is therefore very important. Although in the hypotheses it could not be conclusively proven whether there is lack of training for correct decision making or there exists low situation awareness. One thing is however certain, in case of unexpected and tense situations the decision making and situation awareness will definitely decline. There is also the issue of young officers who have not experienced all situations. Moreover, it is impractical to assume that any mariner would have experienced all possible situations. Therefore, there is a need of a training media such as a simulation game which can help moderate human factors at the trainee's ease thereby making operations safer. It can help increase situation awareness and improve decision making. A simulator is a preferred medium for imparting such training. At least the dimensions of psychological reality and player centeredness must be carefully included in this simulator to make the training realistic and increase the capability of the training simulator. Finally, the following recommendations are for future research: 1. Research into the level of training of the young crew with current traditional methods versus training simulators. 2. Illusory superiority is well documented in literature, but in shipping there is a culture of information opacity or hiding also present the problem of small sample sizes (as is the case with this thesis). Therefore, research is recommended with large sample sizes into the level of training and cognitive issues (not limited to situation awareness and correct decision making) of mariners. 3. Research is recommended into the change of cognitive capabilities of the crew under stressful and unique situations. 4. In the Appendix the problems due to equilibrioception and the lack of suitable motion platforms is discussed. Future research in the development of platforms in anchor-handing simulators that create realism without causing motion-sickness is recommended. 5. Further development of scenario swimlanes as briefing tool and SOE as a debriefing tool by VSTEP 6. In this thesis the stages of elaboration and tuning were not executed. It is recommended to use the results of this thesis as a basis for the complete design of an anchor-handing training simulator.","simulator; training; risk; scenario; triadic game design; gaming; safety","en","master thesis","","","","","","","","","Technology, Policy and Management","Values, Technology and Innovation","","Engineering & Policy Analysis","",""
"uuid:4344e0fa-3d50-4fe0-a4c1-fc935b354f90","http://resolver.tudelft.nl/uuid:4344e0fa-3d50-4fe0-a4c1-fc935b354f90","Model order reduction of nonlinear magnetic problems","Singh, A.S.","Tiso, P. (mentor)","2015","Computational numerical methods are important tools in science and technology today. Numerical simulations of nonlinear problems are usually computationally expensive. Model order reduction is a technique to reduce computation time of mathematical numerical models. Model order reduction of nonlinear problems is still in its developing state. In this thesis, model order reduction techniques are implemented to a special class of nonlinear problems, where the non-linearity is localized in only some parts of the domain. The implementation of model order reduction techniques for this work can be divided into three parts. The first part consists of identification of the part of the domain, that is acting nonlinearly, and then condensing the rest of the domain on this nonlinear part. This method is called nonlinear condensation. The second part consists of finding appropriate reduction basis for the conventional Galerkin projection method. Reduction basis formed using static modes, magnetic modes, modal derivatives and proper orthogonal decomposed snapshots are used. The third part is called hyper reduction and is based on the idea of approximating the nonlinear terms of the analysis, by computing it over a subset of elements rather than the complete domain. To compensate for the energy of the remaining elements, elemental contribution terms from the sampling subset are multiplied by corresponding weights. Hence the name of this method: the Energy-Conserving mesh sampling and weighting (ECSW) hyper reduction method. This thesis concentrates on computational magnetics, but the discussed methods can be applied to any other problem involving localized non-linearities. These methods have been found to yield moderately accurate to very accurate results, while providing a speed-up of an order of magnitude of one to two.","MOR; nonlinear; magnetics; fem; ecsw; nonlinear condensation","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Precision and Microsystems Engineering","","Engineering Mechanics","",""
"uuid:5c82d083-1358-4ba8-845e-4a450ce1729f","http://resolver.tudelft.nl/uuid:5c82d083-1358-4ba8-845e-4a450ce1729f","Mooring Optimization in Time Domain using Harmony Search","Dam, M.A.C.","Kaminski, M.L. (mentor); Romeijn, A. (mentor); Van der Meulen, F.H. (mentor); Schut, X. (mentor); Boorsma, A. (mentor)","2015","The design of a mooring system can be a frustrating and time consuming task, owing to the large number of design cases, software interfaces and sometimes changing requirements. Although frequency domain is a faster method, the behavior of the FPSO and the loads on the turret mooring system in a certain environment is most accurately predicted in the time domain. This does not help in reducing design time. Therefore an automated time domain harmony search based mooring optimization methodology, that uses industry standard software Orcaflex and Ariane7 through a MATLAB interface, has been developed. Harmony search is a phenomenon-mimicking algorithm inspired by the improvisation process of musicians. In the algorithm, each musician (= decision variable) plays (= generates) a note (= a value) for finding a best harmony (= global optimum) all together. The methodology is applied to design a mooring system for a large FPSO in deep water and harsh environment in agreement with SBM corporate engineering standards as a case study. The objective is to minimize the load on the turret chain table with feasible solutions that satisfy all the design constraints without manual intervention. An optimized solution is found within 4 days and the rate at which different mooring configurations are assessed is in excess of 200 per day.","Mooring Optimization; Harmony Search; Mooring Systems; FPSO; Time Domain Approach","en","master thesis","","","","","","","","2020-08-24","Mechanical, Maritime and Materials Engineering","Marine & Transport Technology","","Offshore & Dredging Engineering","",""
"uuid:455fcc07-143b-412b-9f09-1b72547668a6","http://resolver.tudelft.nl/uuid:455fcc07-143b-412b-9f09-1b72547668a6","Development of a Quick Performance Assessment Method for Active Vibration Isolation Systems: Focusing on Photo-lithography Applications","Nizamoglu, A.","Dietz, S. (mentor); Wingerden, J.W.V. (mentor)","2015","The performance of high precision applications highly depend on the ability to reject mechanical disturbances. Extreme accuracies can only be achieved if the object can be isolated from its environment. Vibration isolation is the process of isolating an object from the source of vibration. In active vibration isolation, an entire instrument of sensors, controllers and actuators are used to achieve a better performance. Future systems like Extreme Ultra-Violet (EUV) Lithography are expected to rely more and more on active isolation systems, which puts new requirements on analysis and simulation methods. In high precision applications of complex systems high degree of vibration isolation is needed. In these cases it is required to have a more detailed model of the system, which is usually done with state of the art Finite Element Modelling (FEM) techniques. However, FEM is not appropriate when for example the details of the geometry, location of the isolators or components of the system are not yet known. This typical challenge is to be faced in the concept design phase of the complex systems like EUV-lithography. In this thesis, we discuss how to develop a methodology with low fidelity models, where we can better understand the system and perform quick system assessment techniques to easily compare various design options. As particular case we derive the 3-Dimensional lumped elements model of the Active Vibration Isolation System (AVIS), defining the disturbance inputs in terms of their spectra and quantitatively measuring the performance of the system by using Cumulative Power Spectrum (CPS) and H2 norm. Simulation experiments are done to evaluate the performance for different configurations of the system.","active vibration isolation; vibration criteria; PSSSID; H2 norm; cumulative power spectrum","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Delft Center for Systems and Control","","Control Engineering","",""
"uuid:670b303c-3a83-495e-9834-0d3ffd5bf811","http://resolver.tudelft.nl/uuid:670b303c-3a83-495e-9834-0d3ffd5bf811","The relation between big data and informational privacy in the context of the healthcare","Sippe, R.","Tan, Y.H. (mentor); De Reuver, G.A. (mentor); Rezaei, J. (mentor); Heisenberg, J. (mentor)","2015","Big data is a broad term that is related to the collection, storage and analysis of large volumes of data. The term big data is often associated with the popular 3V’s model, which defined that data is growing significantly in the characteristics volume, variety and velocity. In this research we defined big data as: the collection, storage and transformation of structured and unstructured data from multiple sources into useful information (or knowledge) to improve decision-making within organizations. The significant growth of data is also occurring in the health care sector. A lot of these scattered data sources, possessing large volumes of personal health data of patients, are present in the health care. Big data have shown potential to support health care, by combining and transforming health data. Big data can be used to support medical and healthcare functions, including among others clinical decision support, disease surveillance, and population health (Raghupathi & Raghupathi, 2014). The increasing availability of large data sets from various sources in combination with the development of more advanced analytical tools for big data makes it more and more difficult to ensure privacy. Big data in its current form is still relatively new, and the knowledge on the implications on the security and privacy issues that it brings is still limited. This study explores the relation between big data and privacy in the health care. The research objective of this study is to gather knowledge on how big data affects privacy in the health care. In order to reach this objective, semi-structured interviews have been conducted with eight experts in either big data, health care or privacy in the Netherlands. In this research, a conceptual model of privacy has been created based on existing theories of privacy (e.g. nonintrusion theory, seclusion theory, control theory and restricted access theory). The conceptual model of privacy defines privacy in the elements: natural privacy, normative privacy, control aspect of privacy and the condition of privacy and has been used as a structure to analyze the relation between big data and privacy.","big data; health care; privacy; master thesis","en","master thesis","","","","","","","","2016-08-24","Technology, Policy and Management","ICT","","Management of Technology","",""
"uuid:6c1ee17e-e564-47ff-92d9-f55d2fabe9e5","http://resolver.tudelft.nl/uuid:6c1ee17e-e564-47ff-92d9-f55d2fabe9e5","Numerieke methode in het LWR2D voetgangersmodel","Neijenhuis, R.W.A.","Vuik, C. (mentor); Van Wageningen-Kessels, F.L.M. (mentor)","2015","Ieder jaar zijn er veel evenementen waar duizenden of zelfs miljoenen mensen op afkomen. Denk bijvoorbeeld aan muziek-, cultuur- en sportevenementen. Daarnaast gebruiken miljoenen mensen dagelijks plekken als stations of winkelcentra. Bij al deze voorbeelden ontstaan gigantische mensenmassa's die gecontroleerd moeten worden zodat de infrastructuur efficiënt en veilig gebruikt wordt. Een model is ontwikkeld waarmee de dynamiek van een mensenmassa wordt beschreven. Binnen dit model, het LWR2D-model, is de mogelijkheid om verschillende groepen te laten bewegen in een tweedimensionale ruimte. Het LWR2D-model is de basis van dit onderzoek. Het model en de numerieke methode waarop het LWR2D model is gebaseerd zijn eerst bestudeerd om vervolgens twee onderwerpen te onderzoeken. Bij het bestuderen van het model was in sommige situaties instabiliteit geconstateerd. De twee onderzoeksvragen die zijn onderzocht zijn: 1. Hoe kan de geconstateerde instabiliteit ontstaan en hoe moet het worden opgelost? 2. Kan de gebruikte numerieke methode worden uitgebreid? Bij het onderzoek naar de instabiliteit was het opmerkelijk dat er wel aan de stabiliteitsvoorwaarde werd voldaan. Het bleek om een fout te gaan in de numerieke methode. De instabiliteit werd veroorzaakt omdat er negatieve waarden konden ontstaan wat niet mocht, hier was de methode niet op berekend. De correctiefactor op de uitstroom van een cel binnen het discretisatierooster was geformuleerd op beide voetgangersgroepen samen. Hier moest de aanpassing worden gemaakt om deze correctie per voetgangersgroep uit te voeren. Dit leidt tot de volgende conclusie: De geconstateerde instabiliteit ontstaat doordat er negatieve dichtheden ontstaan binnen het model. Deze negatieve dichtheden ontstaan door een onjuiste implementatie van een correctiefactor. Deze correctiefactor moet per voetgangersgroep uitgevoerd worden in plaats van over alle voetgangers samen. Bij het onderzoek naar de mogelijke uitbreiding van het bestaande model is gekeken naar de Corner-transport upwind methode die veel lijkt op de Donor-cel upwind methode waar het LWR2D op is gebaseerd. Hierin zijn echter meer cellen meegenomen in de berekening van de beweging van de dichtheden binnen het domein. Dit levert een aantal gunstige gevolgen op na een eventuele implementatie. Hieruit concluderen we: Een uitbreiding van de gebruikte numerieke methode is mogelijk, bijvoorbeeld als deze wordt gebaseerd op de Corner-transport upwind methode. Hierbij wordt de simulatie realistischer doordat de dichtheden meer verplaatsen in de daadwerkelijke richting van de snelheid. Daarnaast is een grotere tijdstap dan bij de Donor-cel upwind methode mogelijk waarmee nog steeds stabiliteit kan worden gewaarborgd.","LWR2D; voetgangers; numerieke methode; model; simulatie; stabiliteit; numerieke uitbreiding","nl","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Numerieke Wiskunde","","","",""
"uuid:4060f66b-7352-49d3-a261-375deff25f17","http://resolver.tudelft.nl/uuid:4060f66b-7352-49d3-a261-375deff25f17","The influence of microstructure on the corrosion behaviour of ferritic-martensitic steel","Remmerswaal, T.A.N.","Gonzalez-Garcia, Y. (mentor); Santofimia Navarro, M.J. (mentor)","2015","Modern steel alloys are composed of several phases, for example ferrite and martensite. By varying the fraction or the size of the grains of these phases, the mechanical properties of the alloy can be altered. These microstructural variations were already found before to influence the corrosion properties of the alloy; this has been investigated in this master thesis by means of electrochemical experiments. The prior austenite grain size has been varied for fully martensitic samples; it was found that grain boundaries are less noble sites in the lattice and that an increase in prior austenite grain boundary density would increase the corrosion rate. Grain boundaries were also found to be anodic initiation sites for pits. However, since the fine microstructures have more initiation sites, fewer pits would grow critical due to the lack of compensating cathode area. The depth and size of the pits in the fine-grained material were found to be larger than those in the coarse-grained samples. When the amount of ferrite in the ferritic-martensitic samples was increased, the corrosion potential became more negative. The ferrite formed a galvanic couple with the martensite and corroded preferentially due to its lower (more negative) corrosion potential. The corrosion current density was found to peak at a certain ferrite fraction. However, the anodic dissolution rate of the ferrite was found to decrease with increasing ferrite fractions, since the cathode-to-anode area ratio became less favourable for galvanic corrosion. The nucleation of ferrite also partitioned more alloying elements to the austenite, during annealing, due to the higher solubility of those elements in austenite. The alloying elements were found to sacrificially corrode for the iron, forming a protective layer of reaction products on the martensite surface. The corrosion potential for the martensite was found to increase with increasing amounts of alloying elements, while the current density decreased and the corrosion rate was retarded. These changing electrochemical properties of the martensite also influenced the corrosion properties of the ferritic-martensitic alloy on the macroscopic scale.","corrosion; metallurgy; microstructure; ferrite; martensite; galvanic","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Materials Science & Engineering","","Metals Science and Technology","","52.000303, 4.372521"
"uuid:4dc8276b-7d0b-4374-8c6e-884b97397157","http://resolver.tudelft.nl/uuid:4dc8276b-7d0b-4374-8c6e-884b97397157","Investigation of a generic design method for the preliminary design of a dry dock","Treffers, J.G.","Vellinga, T. (mentor); Hombergen, V.J.W. (mentor); Van Nederveen, G.A. (mentor); Wijdeven, B. (mentor)","2015","For the development of the preliminary design of a dry dock, the present design methods are based on information from experience and manuals. Dry docks are not as frequently designed and built as other maritime structures and due to this many information is lost in time. To improve the process for the preliminary design of dry docks this thesis has investigated the implementation of existing and new design methods for the creation of the preliminary design of dry docks. In the design process of dry docks the first design stages: sketch design, conceptual design and preliminary design are of interest for a DSS, in these phases the design is still on main elements. For these phases engineering firms uses the design manuals on dry docks and experience from designers for the design. In this research the new techniques System Engineering (SE), Decision Support System (DSS) and Building Information Modelling (BIM) are used. SE is used to create in a systematic and structured way a parametric design that can be used for the DSS. The DSS determines the first estimation of the design for a dry dock in a quick and objective manner. To create the preliminary design of a dry dock following SE, the first step is the creation of the basic specification for a dry dock. The basic specification is based out of firstly the Functional Flow Block Diagram, from this diagram all the functions of a dry dock are mapped. To fulfil to these functions from the diagram, objects need to build. These objects are described by the object decomposition. From this object decomposition it becomes clear that the walls, floor and gates needs to be designed for the preliminary design of a dry dock. Finally the requirements are described, the requirements consist out of functional requirements and technical requirements. The technical requirements are used to check which objects are possible for the specific project and to create a parametric design for these objects. The functional requirements are used to rank the possible types within a trade-off matrix. The design of the DSS is created in Excel and with the guidance of the literature study on DSS and the design rules. The DSS gives guidance on which option for construction method, wall type, floor type and gate type are possible and preferred in the preliminary design of a dry dock. The capability to use an alternative is checked by comparing the technical requirements for the different types with the project specific situation. When the types that are possible are determined, these types are weighted against the functional requirements by means of a trade-off matrix, from where they are ranked. To investigate if this generic design method for the preliminary design of a dry dock is implementable a verification and validation is performed. The verification determined if the calculations made in the DSS are correct. This is done by checking the embedded anchored walls and concrete calculations with verified computer programs. For the embedded anchored walls the program D-Sheet piling is used and for the concrete calculation SCIA engineering is used. The validation checks the outcome of the DSS is realistic, by comparing the design of the DSS with the design of a case study from Arcadis. Despite the oversimplification the DSS gives a quick preliminary design for the main objects of a dry dock. This design is inline with the case study, however it is only validated with one case study.","","en","master thesis","","","","","","","","2015-08-24","Civil Engineering and Geosciences","Hydraulic Engineering","","","",""
"uuid:374fb156-5c8f-4e1c-863a-e7b719082263","http://resolver.tudelft.nl/uuid:374fb156-5c8f-4e1c-863a-e7b719082263","Understanding Business Model Innovation Pattern of Small and Medium Enterprises: Analyzing the Changes in Business Model and Operational Area in Response to Firm's External and Internal Factors- A Case Survey Research","Madian, A.C.","De Reuver, M. (mentor); Bouwman, H. (mentor); Verburg, R.M. (mentor); Roosenboom-Kwee, Z. (mentor)","2015","The EU Innovation Union identified that innovations are needed to boost economic growth performance, where SMEs are considered vital for these goals. To achieve this, business model innovation (BMI) is identified as the new area to innovate and also source of future competitive advantage. Furthermore, business model changes as a form of innovation can be seen as a response to the changes of external environment or internal factors of the firm. One of the barriers in changing business model would be the conflict between existing BM and its underlying operation with the new BM. Moreover, by taking account the external and internal factors of the firms, there can be various arrangements in the BM and operational elements that can be modified by the firm, making it a complex and cumbersome process. To overcome these barriers, ontologies or frameworks could be utilized to guide the BMI practice. However, firms are presented with various options of ontologies with different possible changes in both BM and operational elements. Furthermore, while trial-and-error approach could be utilized, firms don't have much time to experiment due to market pressure. Hence, this research found a need to provide SMEs with insights regarding pattern of past BMI practices to help simplify and reduce the time to perform BMI. To achieve this, this research took several steps. First, to have an aggregated learning regarding BMI patterns with a limited time and resources, the author selected the case survey method as the research approach. Case survey method are used because it can provide inexpensive way of tapping the rich insights from various cases in a relatively shorter time than performing individual case studies. Second, the case survey coding scheme was designed by exploring vast amount of literature. Due to the exploratory nature of this research, the case survey coding scheme are made to have open-ended questions. Third step would be the data collection. To collect the BMI cases, the author contacted several researchers in Europe and members of ENVISION project that have done case studies in business model innovation to have a more relevant focus and time-saving (purposive sampling). Fourth, the case survey coding scheme was applied to the BMI cases. To help the coder in assessing the BMI cases, this research included a coding manual that consists of definitions and rules regarding each variables of the coding scheme. Fifth, this research converted the qualitative data into quantitative data by using qualitative content analysis. Quantitative coding was done by counting the frequencies of each answers categories across all cases. Sixth, due to the interpretive nature of the coding, this research used alternative means to measure reliability and validity of the qualitative coding. Reliability of the coding are being measured through dependability (e.g. transparent coding process / coding manual) and confirmability (e.g. member checking). There are several findings regarding the BMI practice done by SMEs. First, the major drivers for SMEs to do BMI would be due to market dynamics, high innovativeness and low business performances. Second, the most BM ontologies used to guide the BMI would be Canvas and STOF, while ArchiMate is found to be the most popular EA framework used. Third, we found that in overall, changes in the BM are mostly related to changes in services, organizational network and target market. And lastly, the changes in BM will create changes in the operational area especially in the process domain, value dependencies and information domain. This research contain many limitations, and the BMI patterns in this research are mainly descriptive insights, which can be improved by using cluster analysis, configuration analysis and network analysis.","business model innovation; business model; enterprise architecture; ontology; framework; case survey","en","master thesis","","","","","","","","","Technology, Policy and Management","ICT","","Management of Technology","",""
"uuid:a65726f9-a873-442e-a186-b27202d9519a","http://resolver.tudelft.nl/uuid:a65726f9-a873-442e-a186-b27202d9519a","Formation Flight: Analysis of wake sensitivity, drag and control in trimmed flight","Windels, E.R.G.","Voskuijl, M. (mentor); Veldhuis, L.L.M. (mentor)","2015","A research simulation model was created to perform extended research into formation flight dynamic behaviour. The principle of aircraft flying in formation is to lower the induced drag and fuel flow. A trail aircraft that flies within the wake vortex field of a lead aircraft encounters an increased effective angle of attack, reducing the induced drag component. This benefit is accompanied by induced interference effects, most pronounced in roll and pitch. Control deflections are required to retain a predefined flight path within the formation flight (trim). These deflections during cruise flight diminish the benefit of drag reduction. This research focuses on quantifying this reduction in benefit. The test case investigated was an Airbus A330-300 in an assumed cruise flight at Mach 0.6 at an altitude of 11,000 meters with a lift coefficient of 0.623. An extended vortex lattice method combined with a simulation model of non-linear equations of motion based on rigid multi body dynamics was used. The aerodynamic results showed a margin of error of 10% around the vortex core. The position for highest induced drag reduction, the sweet spot, was located at -0.15 y/b and 0.1z/b, where the lead aircraft vortex is located at -0.1 y/b and 0 z/b. In close proximity of the vortex, variations in loads with position remained small compared to the deeper wakefield. The untrimmed aircraft had a reduction in induced drag of 52.6%, where the trimmed aircraft had a reduction of 47.5%. The benefit is effectively lowered by 5.1%, and possibly more of the benefit is lost by compressibility and viscous effects that are not within the scope of this thesis. The aileron deflection at the sweet spot is 2.32 degrees. The trail aircraft at the sweet spot showed unstable behaviour in pitch and roll. The aileron hinge moments caused by deflection during cruise formation flight were estimated. When compared to the design limit in solo flight condition, loads were shown to exceed the limit by 6.8% for deep wake field positions. At the sweet spot, the hinge moments were well within the limit. A study on the design of the aileron control surfaces revealed that an increase in area, by using both inboard and outboard ailerons, negatively affects the stability of the formation. Nevertheless the hinge moments are reduced by using both ailerons. A positive effect on trim in formation flight was identified by deflecting the ailerons non-differential, through application of a predefined deflection on the in-vortex aileron to remove the rolling moment. The total benefits for the trail aircraft in formation flight at the sweet spot are 16.59% in total drag and 18.27% in fuel flow. Important to note is the absence of pressure drag for the total drag determination.","formation flight; formation flight trim; induced drag saving; formation flight stability; wake vortex field; A330-300; fuel saving; formation flight control","en","master thesis","","","","","","","","","Aerospace Engineering","Flight Performance and Propulsion","","Flight Performance and Propulsion","",""
"uuid:48c76d6c-a39a-4d1c-a61b-0c2e646233ef","http://resolver.tudelft.nl/uuid:48c76d6c-a39a-4d1c-a61b-0c2e646233ef","Understanding the implications of business model innovation in small and medium enterprises: Measurement development and face validation","Madian, A.C.","De Reuver, M. (mentor); Bouwman, H. (mentor); Roosenboom-Kwee, Z. (mentor); Verburg, R.M. (mentor)","2015","Innovation has been regarded by European Commission (EU) as the important factor for economic growth. Small and Medium Enterprises (SMEs) are known as the source of these innovations, thus the source of economic growth. SMEs role during economic crisis is crucial as they can create employment. But they are still have pressing problems in finding customers and access to financial capital. Innovations can help them in solving these problems, but it should go beyond the typical product or process innovation. In order to capture the value from innovations, a new and innovative business model is needed by SMEs. Thus in a sense, the business model should undergo innovation itself. Business model innovation (BMI) can improve business performance, and it might be moderated by the turbulence in the surrounding environment. Moreover, before SMEs can capture the value of innovation, they require the willingness and the ability to adopt it, or in other word, innovativeness. Policies that support BMI in SMEs are needed. These policies can further enhance the Small Business Act (SBA) that was already implemented. BMI policies should be made based on facts and empirical evidences, but unfortunately, a unified measurement instrument to assess them does not exist, which making it impossible to provide empirical evidence. Being aware of the situation described above, a project called Envision was made to help addressing the problem, and this research is part of the project. While there are several previous studies that have investigated the relationship between business model innovation (BMI) with business performance, less research were focusing on the relationship between BMI and innovativeness. The moderating effect of environmental turbulence was also more commonly found in studies about product innovation, not specifically on business model innovation. Moreover, most of these previous studies were not focusing on Small & Medium Enterprises (SMEs) but rather on a mix of large firms and SMEs. In addition, the definition and measurement of BMI is still not clear and have not gain common acceptance, which yield the primary research question: What are the new face validated measurements that can be used to measure the implication of BMI to both business performance and innovativeness of SMEs, with the moderating effect of Environmental Turbulence? Extensive literature survey, meta-analysis, and secondary research were conducted to find the relationship between the concepts and their existing measurements. From these research strategy, some hypothesized relationship were supported by qualitative meta-analysis and some existing measurement scales (summative scale) were found. Gaps were then identified from this summative scales based on a measurement instrument criteria or blueprint in this research and the feedback were used to construct new measurements (formative scale). Based on the comparison between measurement instrument blueprint and existing measurements, 153 new items were developed out of the total 176 initial items. Face validation was conducted to provide evaluation on the clarity and relevancy of the items by judges. The face validation procedure consists of two stages where six judges were involved in the first stage and only one judge was involved the second stage. The result is 158 items that can be used for further validation in future research. The objective of the research has been achieved, as the research has generated measurements that are face valid. As the theoretical validity assessment procedure was not completed yet in this research (especially in assessing construct validity), the measurements that were generated cannot be said to be completely reliable and valid. Further research should be aimed primarily on continuing the validation procedure. In addition to contributing to the Envision project, this research has made significant contribution to the BMI literatures.","business model innovation; innovativeness; business performance; measurement; environmental turbulence; face validation; business model","en","master thesis","","","","","","","","","Technology, Policy and Management","ICT","","Management of Technology","",""
"uuid:ecd8d3e7-5dd7-44b9-b563-53182ec249c7","http://resolver.tudelft.nl/uuid:ecd8d3e7-5dd7-44b9-b563-53182ec249c7","A scenario analysis of the energy use in the U.S. steel industry: Possibilities for and limitations to energy transition","Dechesne, Q.D.","Stikkelman, R.M. (mentor); Herder, P.M. (mentor); Enserink, B. (mentor)","2015","Much attention is directed towards how to rapidly decarbonise the energy system. Unlike the present energy system based on fossil fuels, an energy system based on renewable energy sources with hydrogen and electricity as energy carriers would be sustainable in terms of CO2 emissions. Whereas in certain sectors (e.g. transport) the opportunities for full decarbonisation are extensively researched and debated, the possibilities for and limitations to an energy transition and decarbonisation in heavy industry is a black box that is recurring on the political agenda. In this research a scenario analysis is conducted for the United States (U.S.) concerning the change in energy use up until 2050 for one of the key industries with the highest emissions in the U.S., namely the steel industry. Two scenarios are developed by means of a workshop and scenario modelling. The scenarios reveal that new technologies show possibilities for transition, but technical, financial and institutional limitations hamper full decarbonisation of the industry. Directions for policy development are provided, but further research is required to analyse modifications of policy to enlarge the incentives for energy transition and to provide detailed recommendations of how to bridge the policy gap between today and the year 2050.","steel industry; scenario analysis; United States; electricity; hydrogen; energy transition","en","master thesis","","","","","","","","2017-08-24","Technology, Policy and Management","Energy & Industry","","SEPAM","",""
"uuid:e264bd6c-cdc9-46de-b9ee-e6019b30d95f","http://resolver.tudelft.nl/uuid:e264bd6c-cdc9-46de-b9ee-e6019b30d95f","General Aviation Radar System for Navigation and Attitude Determination: Deriving aircraft states using multiple on board FMCW radars","Naulais, C.","Hoekstra, J.M. (mentor)","2015","General Aviation aircraft mostly fly with Visual Flight Rules (VFR). These are rules in aviation that permit the pilot to fly on sight if the weather conditions offer enough visibility for the pilot to perform the following tasks visually: collision avoidance with terrain or other airborne object, navigation and attitude determination. VFR flight is therefore a very independent way of flying requiring very few on-board instruments, but it is very dependent on weather conditions. Selfly Electronic Detect and Avoid has therefore developed a Collision Avoidance Radar that can support the pilot to detect and avoid the ground and airborne objects. This Frequency Modulated Continuous Wave radar is small, lightweight and can be mounted almost anywhere on the aircraft. This thesis researched if the radar could also be used as Doppler Navigation System to support the pilot for navigation and attitude determination. A method is proposed which uses the radar data of multiple on-board radars to calculate the aircraft states required for navigation and attitude determination. With this method the height, the roll angle and the pitch angle can be determined with the range measurements and the aircraft velocity vector in the body-fixed reference frame can be calculated using the velocity measurements. Assuming a known heading angle, the ground speed of the aircraft can also be determined. The Doppler Navigation System was modeled in Python and flight data was generated with the flight simulator X-Plane 9. The model was used to determine how the aperture angle would affect the accuracy of the obtained states required for navigation and attitude determination and what the optimum on-board radar configuration is. Navigation with the DNS showed an error in the horizontal position of $455m$ for a flight of $728s$ in which the aircraft traveled $84.339 km$. The height of the aircraft can be determined within $20m$ of the actual height of the aircraft along the whole flight. The obtained roll angle was always within $1^{\circ}$ of the actual roll angle when smaller than $10^{\circ}$ and the pitch angle error never exceeded $1^{\circ}$. These result show that this system could be used to navigate with no visibility conditions for a short duration, for example when trapped in a cloud. These results were obtained for a flight over the Dutch coast using a Digital Elevation Map with an accuracy of 3 arc seconds. The DNS performed best with radars with a low depression angle and the azimuth angle did not appear to significantly influence the accuracy of the states. The terrain was however the largest source of error, as the method to calculate the states assumes a flat Earth. The modeling of the radar signal was too computationally intensive to be integrated in the model, therefore the ground velocity and range measurements are assumed to be perfect. In order to improve the accuracy of the system, terrain recognition could be added which would allow the system to determine three or more geographic positions on the surface and use these positions to geometrically determine its position and attitude using triangulation.","general aviation; VFR; FMCW radar; navigation; attitude determination","en","master thesis","","","","","","","","","Aerospace Engineering","Control and Simulation","","Air Traffic Management and Airport Safety","",""
"uuid:24058bdf-d649-48a7-93c7-bb63918d0887","http://resolver.tudelft.nl/uuid:24058bdf-d649-48a7-93c7-bb63918d0887","Application of ultrasound to remove thrombi from the Left ventricular assist device","Radhakrishnan, A.","Serdijn, W.A. (mentor); De Jong, N. (mentor); Bosch, J.G. (mentor)","2015","Due to limited number of donor hearts and stringent eligibility criteria for heart transplant the Left ventricular assist device (LVAD) has emerged as a relevant treatment option for heart failure. Occlusion in the form of a thrombus (blood clot) is a feared complication associated with the LVAD. The ability of ultrasound to result in effects like cavitation, which is hypothesized to be one of the mechanisms contributing to sonothrombolysis(ultrasound mediated thrombolysis) forms the basis of proposing a solution wherein ultrasound is used to remove thrombi from the LVAD. The proposed solution entails catheter delivery of ultrasound into the LVAD to break down the thrombus. In this master thesis an experimental setup to conduct sonothrombolysis tests on in vitro clots has been realized. In order to understand the mechanism contributing to a high degree of sonothrombolysis a commonly used method - passive cavitation detection is also employed. In the final experiments sonothrombolysis and passive cavitation detection tests are conducted on two sets of 6 clots each. For majority of the clots, sonothrombolysis occurs at a peak negative pressure of 2.71MPa - 3.18 MPa. Clots which underwent a high degree of sonothrombolysis were always accompanied by high counts and violent movement. We assume the intermittent spikes termed as cavitation events being counted are due to physical effects like inertial bubble collapse, shockwaves and microjets, which are characteristic of inertial cavitation. Hence we can conclude that the high counts are indicative of inertial cavitation and play a dominant role in achieving a high degree of sonothrombolysis. The results of this master thesis provide experimental evidence as to why a certain threshold of peak negative pressure must be attained in order to achieve a high degree of sonothrombolysis. This evidence can be utilized in the next step of catheter design. At this stage it can be said that the application of ultrasound to remove thrombi from the LVAD will prove to be successful if high intensity ultrasound resulting in inertial cavitation can be delivered to the site of the thrombi formation in the LVAD.","Ultrasound; Sonothrombolysis; Left ventricular assist device","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Biomedical Engineering","","Biomedical Electronics","",""
"uuid:231a476a-6118-4775-bf29-710ff3e3a94e","http://resolver.tudelft.nl/uuid:231a476a-6118-4775-bf29-710ff3e3a94e","Flexibility of integrated contracts: Impact of contract changes in Dutch DBFM and UAC-IC 2005 based infrastructure projects","Van Leeuwen, N.A.","Wolfert, A.R.M. (mentor); Chao-Duivis, M.A.B. (mentor); Hombergen, L.P.I.M. (mentor)","2015","","","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Design and Construction Process","","Construction Management and Engineering","",""
"uuid:9a8ea2d7-0104-4d9d-9379-253126b1af54","http://resolver.tudelft.nl/uuid:9a8ea2d7-0104-4d9d-9379-253126b1af54","Theoretical and practical limitations of IME-algorithms","Lux, F.G.","Verschuur, D.J. (mentor); Wapenaar, C.P.A. (mentor); Van der Kruk, J. (mentor)","2015","Several internal multiple prediction methods have been proposed in the past and are still actively being researched. Of those, the Jakubowicz method is currently the most attractive and applied one, as it only uses surface data in a convolution and correlation process, and is therefore computationally relatively cheap. This allows its commercial application on 3D data. But due to several assumptions in the prediction process, it has to rely on adaptive subtraction to correct for potential errors. These errors are differentiated and investigated in more detail. Some of them derive from theoretical shortcomings, such as the incorrect implementation of transmission operators, or when neglecting the structural complexity of a 3-dimensional earth in case of 2D or 1D application. The others are introduced because of the unknown properties and simplifying assumptions that have to be made when working with field data. The most important issues are the unknown source characteristics, noise, and the required spatial sampling. These are also of significance for any other method based on the convolution of wavefields, such as Marchenko-imaging. Any advancement that is made regarding these problems, potentially leads to improved results in their application on field data.","IME; SRME; Marchenko; Jakubowicz; multiples; internal multiples; wavefield convolution; adaptive subtraction","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Applied Geophysics and Petrophysics","",""
"uuid:cffaf3a7-6520-4cc6-bcf5-44a3c47a9265","http://resolver.tudelft.nl/uuid:cffaf3a7-6520-4cc6-bcf5-44a3c47a9265","The role of EV adaptive charging in facing higher integration levels of wind energy in Denmark","Sanchez, A.","Palensky, P. (mentor); Rueda Torres, J.L. (mentor)","2015","Denmark aims for a 50% wind integration in 2020. In the current scenario, where wind represents around 34% of domestic consumption, mothballing of conventional power plants and heavy dependency in interconnection lines is already the trend. One of the strategies from the Transmission System Operator is to integrate a big volume of flexible loads to adapt to wind production and mitigate some of its draw backs. Electric Vehicles, even when a significant increase is expected in the following years, will not represent a volume of consumption that can really impact the load curve by 2020 and this type of response will rely in the short term in other flexible loads like Heat Pumps. Due to its configuration and advanced technology, EVs can participate to other services vital to the correct operation of the Electric Power System as it is provision of frequency reserves to maintain balance between consumption and generation. This work presents a solution using the adaptive charging capabilities of an EV to get the best respond in both the day-ahead market and the regulation market. The adaptive scheme will achieve: lower price for purchased electricity in the day-ahead market, with higher levels of wind energy penetration, and the possibility to participate to the frequency regulation market and get revenues. All this features are gained without affecting the normal operation of the vehicle. Two different configurations for the battery of the EV are compared in this work: unidirectional and bidirectional. A fleet of 400 EVs have been modeled based on statistical survey data for EVs users driving profiles in weekdays and weekends. This fleet is managed by the figure of an aggregator who purchases electricity in the day-ahead market and bid on the frequency regulation market. The reference charging profile is a non-controlled consumption scheme of plug-and-charge. This reference model is compared first with a basic adaptive models based on weight coefficients varying according to the State of Charge of the battery and the level of wind penetration. Later on, the adaptive model is optimized, following the same indicators, seeking to maximize wind penetration while bidding to frequency regulation market the most number of times. The optimization algorithms used are Gradient Search, Genetic and Differential Evolution. The decision factor for the adaptive charging strategies is the forecast wind penetration signal with is the coefficient between the level of forecast wind production and the level of forecast consumption. The idea behind using this signal is that it will yield typically lower cost of electricity and high net wind penetration. Allowing high net wind penetration will reduce the presence of energy from other generation facilities and thus the CO2 content in the battery charge. Results show that the owner of an EV with bi-directional capabilities and Genetic Algorithm can reduce the final expenses on the EV by 20% in one year. If GSA is used instead, 36% more wind energy will be integrated in the vehicle. In addition, because currently upward regulation is provided by coal and gas fired units, 60% of the current emissions by providing this service could be cut with a GSA charging scheme.","Wind Energy Integration; electric vehicles (EV); Frequency Regulation; Adaptive Charging","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Electrical Sustainable Energy","","Intelligent Electrical Power Grids","",""
"uuid:18822a53-46b9-4f51-b792-ac014d257e68","http://resolver.tudelft.nl/uuid:18822a53-46b9-4f51-b792-ac014d257e68","Robustness of hinterland container transportation","Van Vuure, B.","Verbraeck, A. (mentor); Lukosch, H.K. (mentor); Cunningham, S.W. (mentor)","2015","Containerisation has dramatically changed international transportation; it has affected the speed and costs of the transportation of goods. The largest share of costs of container transportation is related to inland transportation. The performance of the container transportation chain as a whole determines its competitive position. Disruptive events occur in the transportation chain, and if they are not mitigated effectively, the disruptions will be propagated through the chain. Robustness of the container transportation chain is key to acquiring and maintaining a good competitive position. This research investigates to what extent the hinterland network configuration, like merchant haulage and terminal haulage, influences the robustness of the hinterland container transportation chain. During this research a discrete event simulation model has been developed for the hinterland transport chain between Rotterdam and the Ruhr district. Three different disruption scenarios are studied during the simulation runs: delay of a vessel, low water levels in the Rhine River, and a combination of both. This research shows that changing hinterland network configuration of the transport chain from merchant haulage to terminal haulage is an effective way of increasing the transport chain’s robustness, thereby increasing the competitive position of the terminal. The model results can be used to support container terminal operators with the strategic decision of whether or not to invest in terminal haulage.","robustness; scenario study; disruptions; hinterland container transport; terminal haulage; merchant haulage; discrete event simulation","en","master thesis","","","","","","","","","Technology, Policy and Management","Systems Engineering","","","",""
"uuid:3552d27e-6816-4ea3-85f6-4464deb8f1bd","http://resolver.tudelft.nl/uuid:3552d27e-6816-4ea3-85f6-4464deb8f1bd","Autonomous Collision Avoidance for Swarms of MAVs: Based solely on RSSI measurements","Szabó, T.","Mulder, J.A. (mentor); de Croon, G.C.H.E. (mentor); de Visser, C.C. (mentor); Scheper, K.Y.W. (mentor); Verhoeven, C.J.M. (mentor)","2015","Swarming is a promising solution for extending the flight time and payload carrying capabilities of Micro Aerial Vehicles (MAVs), where recent years have brought many advancements. These allow MAVs to operate ever more autonomously by tackling problems such as obstacle avoidance and autonomous navigation. A major challenge that still remains, however, is to ensure collision avoidance within the swarm itself. Avoiding collisions with other members of the swarm requires knowledge of their relative positions - typically requiring additional sensors to be carried on-board. Using the signal strength of the MAVs’ communication link provides an alternative method for estimating relative distances between the members of the swarm without requiring need for any additional sensors.","","en","master thesis","","","","","","","","","Aerospace Engineering","Control and Simulation","","","",""
"uuid:784b1640-94bd-4221-b5b4-bb73a0128d37","http://resolver.tudelft.nl/uuid:784b1640-94bd-4221-b5b4-bb73a0128d37","The Homecomposter","Van der Veen, B.","Ninaber, B. (mentor); Vroom, R.W. (mentor)","2015","For the urban dwellers who are unfamiliar with vermicomposting and who are dissatisfied with the current sustainable waste solutions our product is a composting solution that provides a simple, charming and appealing product unlike any other vermicompost or urban waste processing system. To achieve this we have assembled the proper worms, a compact and simple to use housing system and a collection of the required knowledge for using those. Phase 1 - Background and application of vermicomposting In the Netherlands about 64 kg of organic material is thrown in the residual waste stream. Splitting this material in separate streams for sustainable reprocessing is made highly difficult as central collection is nearly impossible. Domestic composting is a sustainable method for converting home produced organic waste in a fertile substance that would be able to achieve some level of waste splitting. Vermicomposting is a sub-form featuring compostworms that facilitate the natural composting process. There are various available systems that use the benefits of vermicomposting to allow people to compost all year round and potentially indoors. Maintaining a vermicomposting system can be a challenge however; contemporary systems are found to be unsatisfactory. Even though the base of the system: feeding and harvesting sounds simple, there are several variables that determine whether or not a vermicomposting system will work effectively or will completely fail, thus succeed in the market of 2015. Besides these practical issues retaining to vermicomposting, the mentality of people and their capacity to house vermicomposting systems also influences the commercial viability of a product. As does the user’s perception towards these systems and the inhabiting worms. In the end, a program of demands related to vermicomposting system design was set up. It suggests that both perceived and actual parameters such as ergonomics are important, besides simply allowing the system to operate. Phase 2 - Generating ideas and creating concepts Using the program of demands as a starting point a process of free ideation, creative facilitation and analytic design was performed. This created six design directions. Using complexity and viability as comparison criteria the countertop and c-shape directions were chosen to be continued. These were developed further into two concepts: the wormplate and circular. Following evaluation by representatives from Muilwijk a third concept called Topsplitter was added. Phase 3 - The citycomposter and fruitcomposter A comparison of the circular, topsplitter and wormplate concepts by Cityplot suggests that a combination of the first two will create an optimal system for vermicomposting in urban areas. This combination was developed as the Citycomposter. A 1:1 model of the system was built and was tested for a period of four weeks. It was found to be operating well, but issues arose due to the large size and the perishing of the worm population during heat. Even more so, the feasibility of this system was found to be too limited due to constraints related to production costs and the budget of De Namen. As such, it was opted to develop a smaller lead-in product. This was called the Fruitcomposter (figure 4). This product was also evaluated using a 1:1 prototype. The findings of this test suggested that a fruitcomposter is an interesting system for beginning vermicomposters due to the ability of worms to escape from hostile environments. Phase 4 - Embodying the product Recycled HDPE was initially decided upon as a material based on the low costs and ability to recycle. Biobased materials were explored in conjunction with the HvA as an alternative, more sustainable option. However, structural issues were found that would pose a risk to the success of the product. The product seemed most viable for production when made using injection molding, based on quotations from rotational molders, thermoformers and injection molders. Upon deciding that the product was made to be injection molded a break even series of about 15 000 pieces was found. Based on the requirements of injection molding the product was consequently redesigned to account for the possibilities and limitations of this technique including consistent wall thickness, wall branching and ribs. Simultanously, the findings of the 1:1 prototype were implemented. This included longer funnels, additional alignment support and a more firm attachment for the lid. The new design was shown to experts and based on this consultation the material was altered to PP and the technical drawings were finalised. Phase 5 - A market launch The fruitcomposter as a generic product can be used without additional help, though known worries of the vermicomposting system remain. Augmenting the product using online applications may go beyond the expectations of users and simultanously present interesting revenue streams such as subscriptions. The placement of this product sets it as a problem solver for the beginning vermicomposter. This person can be approached using physical locations including garden centres; be convinced of the potential using campaigns such as the zero waste foundation. The future of using this product lies in expanding not only using stacks, but by adding additional homecomposter products including methods to create worm tea. To reach this state potential allies need to be found first; using partners such as Groenrijk as a launching customer might help push the product onto the market and reach the necessary numbers for a viable homecomposter business soon.","worms; vermicomposting; composting; organic waste","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Design Aesthetics","","52.001644, 4.369994"
"uuid:ebae4f63-7dee-4091-876e-5ff46f15c6d0","http://resolver.tudelft.nl/uuid:ebae4f63-7dee-4091-876e-5ff46f15c6d0","Low Short Circuit Ratio Connection of Wind Power Plants","Golieva, A.","Palensky, P. (mentor); Rueda Torres, J.L. (mentor)","2015","Primary factor for the site selection during the planning process of the large modern wind farms is the wind climate, which is usually favorable at remote and offshore locations where the public grid is not particularly strong. Among the consequences of this solution is the necessity to connect wind farms to weak points of the grid and the necessity to reach this point by the means of long connection lines. All the mentioned factors result in a low short circuit ratio connection of wind farms becoming a frequent condition to deal with. Wind turbine manufacturers and wind farm operators have already faced various engineering problems concerning the wind farms, operating in weak grids. One of them is inability to transfer the desired amount of the active power along the needed distance due to the lack of transmission capability. Besides that the system has to operate at the tip of its PV curve, which makes it vulnerable to voltage instability in case of sudden changes in a system, for instance a load connection or a short circuit. Furthermore, all the modern wind farms are using power electronic converter based drivetrain system, which has numerous advantages in terms of controllability but also demonstrates much lower short circuit current capabilities, compared to the previously used synchronous generator technology. That minimizes the modern wind turbines contribution to fault recovery, which in cases of severe faults might cause a wind power plant to violate the grid codes requirements, resulting in unfavorable consequences for the wind farm operator. Among the consequent instabilities, reported by the wind turbine manufacturers are the slow voltage recovery after system faults and oscillatory voltage instability in response to small disturbances. A peculiarity of the previously held studies is that they are constrained by a range of case-dependent parameters, due to the fact that vast majority of the offered solutions propose the refinement of the turbine voltage controllers gains. The proposed solutions have demonstrated limited positive effect, however they are not universal, due to the fact that the voltage controllers are tuned on a case to case basis. Therefore this thesis carries out a systematic analysis of the nature of the occurring phenomenas instead of a case study solving. The investigated system is modeled, using the per-unitized conventional power system elements, with an emphasis on their mutual relations and not bound by the magnitudes. Therefore system behavior is not conditioned by any specific case peculiarities. On the contrary, the integral dependences are being tracked and the solutions are supplemented by the mathematical derivations, based on the fundamental power system laws. Due to this approach the reason of the occurring instabilities has been detected, explained and resolved. Lack of transmission capabilities, shown by the simulations lays in the insufficient accuracy of the simplified power system modeling with the shunt capacitances neglected. The system, modeled with the shunt capacitances included does not possess the above-mentioned problems. Power system oscillations have been eliminated by means of controller tuning and insufficient voltage recovery has been overcome by means of partial reactive power compensation. The recommendations on modeling and control refinement are given, based on the derived dependences and tracked properties of the high impedance grid with high wind power penetration.","wind power; power system; grid connection; wind turbine modeling","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Electrical Power Engineering","","Electrical Power Systems","",""
"uuid:b8819b00-1ff3-4cda-9d90-83ecf9f7569d","http://resolver.tudelft.nl/uuid:b8819b00-1ff3-4cda-9d90-83ecf9f7569d","Installation Limits of Large Diameter Cold Water Pipes in Deep Water for Land-Based OTEC Plants","Keesmaat, K.","Huijsmans, R.H.M. (mentor)","2015","The growing worldwide demand for clean, sustainable electricity generation and improved energy efficiency offers a valuable opportunity for the large scale implementation of OTEC (Ocean Thermal Energy Conversion) and SWAC (Sea Water Air Conditioning). One of the remaining technological challenges for large scale land-based OTEC and SWAC is the installation of the very large diameter (>2.5 m) cold water pipelines (CWPs) in water depths close to 1000 m, which provide the required cold deep seawater supply. Therefore, the aim of this thesis is to find and expand the limits of the installation of very large diameter deep water CWPs. Currently, the largest diameter CWP installed in deep water is a HDPE pipe with a diameter of 1.4 m. The first part of this thesis analyses the limits of the conventional installation method for marine large diameter HDPE pipes. This is done with both an analytical natural catenary model as well as with a FEM Orcaflex model. From this analysis, it can be concluded that the largest diameter HDPE pipe which can be installed using this conventional installation method is not big enough for large scale OTEC. To expand this limit, some minor adjustments are proposed for the conventional installation method, which might slightly increase the installation capabilities. For a significant increase, alternative pipe materials for use with the conventional installation method and completely different installation methods are proposed. Two alternative pipe materials show promising results to expand the limit of the maximum pipe diameter which can be installed. Four very different alternative installation methods are proposed to increase pipeline installation capabilities. Although these methods are all very promising, further detailed analysis is required to assess the true feasibility.","OTEC; SWAC; cold water pipe; installation","en","master thesis","","","","","","","","2019-08-21","Mechanical, Maritime and Materials Engineering","Offshore and Dredging Engineering","","Offshore and Dredging Engineering","",""
"uuid:98051024-7c8f-4017-b78e-632c65c41579","http://resolver.tudelft.nl/uuid:98051024-7c8f-4017-b78e-632c65c41579","Contextmapping in a healthcare environment","Van Biessum, O.","Buijs, J.A. (mentor); Mejia Sarmiento, R. (mentor)","2015","","medisign; contextmapping; healthcare","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product Innovation Management","","Master of Science Design for Interaction","",""
"uuid:5bf482f6-5910-4346-abd5-785748980bc9","http://resolver.tudelft.nl/uuid:5bf482f6-5910-4346-abd5-785748980bc9","Conceptual Design of Swept Wing Root Aerofoils","Sol, M.B.","Vos, R. (mentor)","2015","For modern transonic transport aeroplanes, it is important to produce low drag at high cruise speeds. The root effect, caused by effects of symmetry on swept wings, decreases the performance of these aeroplanes. During aeroplane design, root modifications are applied to counteract this decrease in performance. Most conceptual aeroplane design tools do not have a method for design of the root aerofoil. However, the design of the root aerofoil has a significant influence on the properties of the final design, since it transfers the loads from the wing to the fuselage. Therefore, having a conceptual method for design of the wing root aerofoil will increase the accuracy of a conceptual aeroplane design. For conceptual design, computational times are important, to allow the designer to try different approaches and get a feel for the design. In this report a method is developed to approximate the root aerofoil design to achieve straight isobars on a wing of any given shape, within computational times that are suitable for conceptual design. First a method is developed for estimating the pressure distribution over the root aerofoil of a given wing. This is done by combining a method for estimation of the root effect due to thickness, a method for estimation of the root effect due to lift, a Vortex Lattice Method (VLM) and a two-dimensional panel method. A full potential method, MATRICS-V, is used to verify the results of the method, because of its proven validity. It is shown that the results of the first part of the method are generally in good agreement with results found by MATRICS-V. The effects of wing sweep, wing taper and addition of a wing kink can be modelled with results that are in good agreement with the verification data. For aft swept wings with positive lift, the pressure near the leading edge is underestimated. For forward swept wings with positive lift, the pressure on the upper surface is overestimated. For wings with a cambered aerofoil an inaccuracy occurs over the forward part of the profile. The general shape of the curve, however, is captured. Secondly, this method is coupled with an optimisation method for the root aerofoil, using Class-Shape function Transformation (CST) parametrisation. The target of the optimisation is set to achieve a similar pressure distribution over the wing root aerofoil as the pressure distribution over the outboard section of the wing. For the developed method, it is difficult to show that the results are valid, since there is no method that has a one-to-one match with the method developed. Therefore, the results are compared to the general characteristics observed in actual root aerofoil designs. The method shows the characteristic behaviour in terms of change in camber, change in location of maximumthickness and change in incidence angle. The increase in thickness, however, is not present. This is caused by the fact that the lower surface pressure distribution is also set as a target. In actual aeroplane design the lower surface is of less importance. In the method developed, however, it is of importance to retain the shape of specific aerofoil designs, like supercritical aerofoils, during optimisation. As a final verification, an optimised root aerofoil design is analysed using MATRICS-V. The results show that the root section pressure distribution is in good agreement with the outboard pressure distribution. In terms of computational time, the method is shown to generally produce reliable results within 30 seconds.","conceptual; design; swept wing; wing root; aerofoil; straight isobars","en","master thesis","","","","","","","","","Aerospace Engineering","Flight Performance and Propulsion","","Flight Performance and Propulsion","",""
"uuid:2d9caa94-62e3-48a8-ab52-b74d8c38816e","http://resolver.tudelft.nl/uuid:2d9caa94-62e3-48a8-ab52-b74d8c38816e","Design and development of a small scale jet head for multi-lateral drilling","Shreedharan, V.A.","Pecnik, R. (mentor); Reinicke, A.B. (mentor)","2015","Extraction of hydrocarbons from the sub-surface is becoming harder with the reservoirs getting smaller and the formations increasingly tighter. Considering the current circumstances, production enhancement otherwise known as “stimulation” techniques, play a vital role in ensuring economic returns from a hydrocarbon reservoir. The use of water jetting for enhancing the connectivity of oil & gas wells to reservoirs is gaining attention these days over hydraulic fracturing in the oil & gas industry due to the enormous costs and rising concerns over environmental impacts associated with fracturing. Water jetting systems operate at high pressures and flow rates in order to effectively drill through tight sandstone formations. Computational fluid dynamics provides the right platform to help design and improve a jet drilling tool before progressing to field trials. Such an optimization process requires insight into the inter-granular interaction between fluid & rock surface at down-hole conditions and the mechanism of rock erosion due to water jetting. Initially, the rock surface is geometrically modeled in order to provide the fluid flow domain to analyse the fluid-rock interaction. Subsequently, empirical rough wall function is utilized to emulate impinging jet flows over rock surfaces. Finally, the most viable wall treatment is employed for simulations of the small-scale rotating jet head in a bore-hole environment. The developed jet head has the potential to lower water usage & power consumption, improve water recyclability and reduce logistics cost when compared to hydraulic fracturing. Additionally, controlled placement of the needle wells allows operations in reservoirs which are in close proximity to underground aquifers, reservoirs with naturally occurring faults and fractures, reservoirs having compatibility issues with fluids and additives used in hydraulic fracturing. The needle stimulation technology is expected to perform comparable to hydraulic fracturing in these challenging reservoirs by offering advantages in health, safety and environment (HSE) aspects.","CFD; jet drilling; impinging jet; rough walls","en","master thesis","","","","","","","","2018-08-31","Mechanical, Maritime and Materials Engineering","Process and Energy","","Energy Technology","",""
"uuid:0c83f71a-5fe9-4f2b-894e-c6f27899a660","http://resolver.tudelft.nl/uuid:0c83f71a-5fe9-4f2b-894e-c6f27899a660","Enhancing the Features of Vertical Axis Wind Turbines with Active Flap Control and Airfoil Design","Ertem, Sercan (TU Delft Aerospace Engineering)","Simao Ferreira, Carlos (mentor); Gaunaa, Mac (mentor); Timmer, Nando (graduation committee); van Bussel, Gerard (graduation committee); Delft University of Technology (degree granting institution)","2015","In recent years, the research on Vertical Axis Wind Turbines (VAWTs) have been paving the way for the very large-scale (10-20 MW) floating offshore applications. For a cost effective utilization, VAWTs need to deliver superior aerodynamic and structural performance. Nowadays, the complex ow phenomenon of VAWTs have been better understood and the computational tools have reached to a mature level. It is time to explore the capabilities of this concept and improve its aerodynamic features by innovative design ideas. The main goal of this thesis is to enhance the performance of the lift-driven VAWTs by customized airfoil design and the active ow control with trailing edge aps. To achieve the research goals, four main lines of work are carried out: 1) performance exploration of an actuator cylinder, 2) design of the azimuthal flap control sequences, 3) comparison between the Actuator Cylinder Model and Panel Model in the presence of the active flap control and 4) airfoil design that is specified for effective flap operation on a VAWT blade. The flap control sequences are optimized with the use of the Actuator Cylinder Model for three aerodynamic objectives. These objectives are aiming to improve the power efficiency by maximizing the CP , provide a rated power control by minimizing the CP and decrease the cyclic load ranges by minimizing the CT . Whereas, RFOIL and NSGA-II genetic algorithm are coupled for the airfoil design, which aims for objectives such as superior single airfoil performance, extended flap sensitivity and high flap-wise bending stiffness. For a rotor solidity of 0.1 operating at tip speed ratio of 4, a 10% active flap is able to increase the CP by 7% , decrease the CP by 10% and alleviate 12% of the CT by sacrificing 3% of the CP . It is shown that depending on the solidity, tip speed ratio and the flap authority these figures could be increased. It is possible to brake the rotor with a relatively larger flap authority. The airfoils designed in this work are slightly cambered and span from 27% to 35% thickness, deliver higher maximum CP than a NACA 0018, show good performance in the dirty conditions and have high flap effectivity. Overall, the performance gains acquired by the new airfoils and flap control promises extensive improvements in multiple features of VAWTs such as power effciency, power control, load control that lead to reduced weight and decreased Cost of Energy.","Windenergy","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:fa5cca08-aa6c-45fb-be90-27840645f8a3","http://resolver.tudelft.nl/uuid:fa5cca08-aa6c-45fb-be90-27840645f8a3","Multi-Stakeholder Aircraft Scheduling Problem: Performance Evaluation and Fairness Analysis at Schiphol Airport","Tripathy, M.","Corman, F. (mentor)","2015","The growth in the aviation industry means that with existing constraints, operational efficiency has to be improved in order to be sustainable. The bottlenecks at airports are usually the runways and consequently, the routing and scheduling decisions from the ATC pertaining to the route and order of the incoming and outgoing flights are of paramount importance. The objective of this research was to evaluate an advanced optimisation algorithm at Schiphol using publicly sourced data on different aspects, which were dual in nature, one was performance as compared to the incumbent practises and the other was fairness which dealt with the fair distribution of the decisions from the ATC for different airlines depending on cost incurred by each airline. The advanced algorithm was devised by drawing an analogy to job shop scheduling problem and solving the same using graph theory and associated (Meta) heuristics. The financial and fairness analysis was carried out through analogising game theory. The experimental design was set up through running the data through an optimisation model followed by financial analysis. The data consisted of schematics of Schiphol, so as to determine the time to traverse resources like approach air segment, glide path and runways, details of the aircraft and time of entry into the terminal control area of Schiphol along with expected time at gates. In total 49 data sets were evaluated through the model in different configurations. The configurations were as follows, 1. First Come First Serve (Incumbent) 2. Solver Scheduling 3. Solver Routing and Scheduling – the proposed algorithm 4. Equity 1 (Priority KLM) – proposed algorithm being partisan to KLM 5. Equity 2 (Priority Non- KLM) – proposed algorithm being partisan to non-KLM airlines The output was in the form of delay for individual aircraft which were then consolidated to delays for airlines. The delay(s) were the result of the decision which was based on the configuration used; this aspect was used to compare the performance of the various algorithms. Furthermore, the delay(s) for different airlines was used to analyse whether decisions which resulted in the delays are commensurate with the payments made by the airlines. The findings were quite consistent with the expected outcome of the experimental set-up. The proposed algorithm, in its normal and original state, performed the best amongst all other configurations. In all the data sets, there was improvement in the performance, by using the proposed algorithm, at a global level i.e. for the whole system as a whole. The factor of improvement from the incumbent practise depended on the initial status of the system. Having established the superior performance of the algorithm, the distribution of decision amongst airlines was analysed to establish fairness. The delays for the airlines were monetised using the value of time specific to aviation operation and the situation was analysed using a cooperative game theory approach, where airlines could agree to implement the proposed algorithm by forming a grand coalition or not agreeing thereby reverting back to the incumbent system for all. Only taking the operational cost incurred by the airlines and performance analysis conducted previously, the Shapley Value gave the fair distribution of the costs based on the marginal improvement each airline brought to the system. For all data sets, the Shapley Value was consistent and comparable to the actual costs albeit with minor inconsistencies; in some cases a few airlines paid more than what they should pay and in some cases they paid less than what they should pay. To tackle the inconsistencies a financial redistribution framework was proposed. The airlines paying less than what they should pay, contribute the default amount to a common fund and then, the money from the fund is redistributed amongst the airlines paying too much according to their Shapley Value ratio to minimise their loss. This system created a system wherein no outside interference is required and by transferring money internally, a sense of fairness could be introduced into the system. Also, this system took care of the local optimal after a global optimal had been established and in fact improved upon the global optimal. In all the data sets, the number of times an airline paid too much or too little was evenly distributed. Also, the grand coalition, wherein all the airlines agree to implement the new algorithm, was inherently stable due the game being inherently convex and the Shapley Value being present in the core. However, owing to the scale of operation of KLM, KLM could impact the performance of the whole system and actually benefitted the most from the proposed algorithm. To summarise, the proposed algorithm can be implemented to give a superior performance in terms of minimising the delay experienced by the whole airport. However, a further detailed study of the financial agreements between the airlines and Schiphol is required so as to align the actual financial transactions with that of the ideal or the fair financial transactions. Also, for any financial framework or agreement between Schiphol and various other airlines, the interests of KLM should always be taken into account since KLM is a dominant player whose individual (local) performance affects the global performance. Hence, it can be concluded that the proposed algorithm is definitely an improvement over the existing system and also a sense of fairness can be introduced in the decision support system to ensure participation of all the airlines.","scheduling; game theory; fairness","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Marine & Transport Technology","","TIL","",""
"uuid:46ac2b0b-db78-4e66-a6e8-4215bd6d4412","http://resolver.tudelft.nl/uuid:46ac2b0b-db78-4e66-a6e8-4215bd6d4412","Space Charge analysis of epoxy based nanocomposites","Saha, D.","Morshuis, P.H.F. (mentor); Tsekmes, I.A. (mentor); Kochetov, R. (mentor)","2015","This project investigates the effect of addition of h-BN (hexagonal boron nitride) nano-particles, of size about 70 nm, to epoxy resin, cast in the form of thin circular plaques, varying in thickness from 0.46 mm minimally till 0.56 mm maximally. Different filler concentrations by volume% have been chosen, with the lowest as 0.2 volume% till the highest of 5 volume%, and incorporated into the epoxy host material. The space charge characterization of the samples is performed by the Pulsed Electro-acoustic technique, and the resultant nano-filler incorporated materials are characterized in terms of space charge accumulation in the samples, depletion rate, accumulation rate, charge accumulation characteristics. 3 distinct techniques of sample production have been adopted, to incorporate the h-BN nano-particles into the epoxy base, in case of the same fill-grade, and the study of these techniques is briefly performed as well. The aim is to isolate (if any) the sample/sample(s) which behave in a relatively better manner to neat epoxy resin (without nano-fillers) and study behaviour. The secondary aim is to investigate if the addition of nano-filler material to epoxy resin influences/changes the threshold field for space charge accumulation in the relatively better performing sample/sample(s).","polymers; nanocomposites; high voltage; space charge","en","master thesis","","","","","","","","2016-02-21","Electrical Engineering, Mathematics and Computer Science","Electrical Power Engineering","","High Voltage Group (DC E&S)","",""
"uuid:5bb5a673-d341-497f-a1ad-6137866a120a","http://resolver.tudelft.nl/uuid:5bb5a673-d341-497f-a1ad-6137866a120a","Designing with Smart Materials: A Case presenting a Tactile Interface Disc for Intuitive Control of Light and Sound in Domestic environments","Stamhuis, C.T.","Karana, E. (mentor); Jansen, K.M.B. (mentor); Guglielmi, M. (mentor); Johannesen, H.L. (mentor)","2015","A growing interest in Smart materials has been reported throughout literature over the last decades. Also regarding current day developments with products classed as ‘smart products and applications’, have led to the start of this thesis. Initially the assignment was aimed to explore the qualities and advantages of smart materials. Through analysis of the current developments in the world of smart materials, this thesis points out that smart material systems, or computational materials, provide the best opportunities to design an example application with. This is mainly due to their flexibility in embodiment material and electronics integration. The final design presents a wireless remote control disc made out of leather and textile, that controls the light and sound output of Spacemotion. Diffus design studio created Spacemotion as an interactive modular system of textile discs, embroidered with conductive yarn. The design focuses on intuitive user interactions and uses smart sensing functions to detect the different performances of the user. Through tactile material exploration, it lets the user take control over the light and sound output of Spacemotion. The method of Material Driven Design was used as approach of the design exploration and provided insights in smart material qualities. It guided the construction of the performances that are elicited by the materials used in the final design. Unique to this thesis is that the design essentially is a tactile interface platform that leaves open many opportunities for further exploration and future research. In a broader sense, it lets the user redefine man-machine interactions through tactile, intuitive and gradual control of any desired systems output.","tactile interface platform; Material Driven Design; smart material system; smart materials; Explorative Design; performative qualities of materials","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Master of Science Integrated Product Design","",""
"uuid:d9fb7a34-cf30-491c-8bd6-4315ce095289","http://resolver.tudelft.nl/uuid:d9fb7a34-cf30-491c-8bd6-4315ce095289","The Affective Storyteller: How Emotion Influences Narrative Generation","Kaptein, F.C.A.","Broekens, D.J. (mentor)","2015","In this research it is investigated how character emotions can be used to aid the narrative generation process. To this end the Affective Storyteller is developed, a narrative generation framework where character emotions are closely interconnected with the narrative generation process. For story generation in the Affective Storyteller, it is first required to define a story-domain. A story-domain exists out of actors, events and locations. The Affective Storyteller can then generate many different stories given such a domain. A story is formed by a sequence of events. As the amount of possible events in such a sequence grows, the computation time for generating all possible story sequences in the story-domain grows exponentially with it. Dependent on the preferences of the audience such a set of stories typically contains both good, desirable stories and less or unsatisfying stories. Two main challenges in narrative generation are addressed. Since stories are valued differently dependent on the audiences’ preferences, it is difficult to generate stories that fit all these individual needs. When we would be able to steer the type of stories shown at runtime, then this would enable coping with this wide range of preferences. The first challenge we address is therefore customization. We aim to show the audience stories that adhere to certain abstract structures. These structures can be build (customized) by the person generating the stories. Another problem in computer-based storytelling is the high cost in computation time and space for longer stories. When presenting stories to users at runtime, it is not desirable if the calculation takes hours. We improve the efficiency of the narrative generation by forcing the storyteller to take the requested customizations into account during the generation of the stories. When the storyteller considers storylines that will not adhere to the customization, then the calculation of those storylines can be cut of before completing them. The Affective Storyteller simulates character emotions using GAMYGDALA, an emotion framework based on the OCC model. The OCC model generates emotions based on how well the characters perform in regards to their goals. These emotions are updated after every story-event, giving us an emotional flow corresponding to the story. We believe this emotional flow to be a powerful abstract representation of the stories. The user can then define a filter that corresponds to these emotional flows. The Affective Storyteller analyzes the emotional patterns and rejects stories that do not comply with a chosen filter. This research shows different methods to analyze these patterns and filter the proper stories given a set of stories and affective data. Further, some experimental evidence supporting the feasibility of this approach, is presented. We tested the impact of affective filtering of stories on readers' affective perception of these stories, and found a significant effect on the perception of positively versus negatively filtered stories, supporting the validity claim of the filtering method. We further tested the impact of using an affective filter during the generation and reduced the calculation time exponentially in an example domain and filtering heuristic. Continuing this research would mainly mean to investigate how the filtering can be optimized for use during generation and to what extend it can be used to find stories that follow affective patterns that are known to produce certain qualities in stories. For example excitement or conflict. The overall conclusion for this research is that character emotions are a promising tool for plot management of stories.","narrative generation; affective storytelling","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Interactive Intelligence","","","",""
"uuid:05c96802-1a35-40ff-a760-092c725d9069","http://resolver.tudelft.nl/uuid:05c96802-1a35-40ff-a760-092c725d9069","Characterization of off-stagnation point pyrolysis in plasma flows using optical measurement techniques","Theuns, Lieselotte (TU Delft Aerospace Engineering)","Schrijer, Ferdinand (mentor); van Oudheusden, Bas (mentor); Eitelberg, Georg (mentor); Delft University of Technology (degree granting institution)","2015","After the invention of the rocket mankind saw a new possibility to study the universe and other planets than Earth by space travel. Since then man has achieved to orbit Earth, land on the Moon and Mars. The constant increase in the demands of future space exploration mission make that also the equipment needs to be _t to the task. For example in 2020 NASA aims at returning a sample from Mars back to Earth [NASA Mars Exploration Program &amp; Missions].","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:7db327b9-af05-4e09-8b79-741ead6eb013","http://resolver.tudelft.nl/uuid:7db327b9-af05-4e09-8b79-741ead6eb013","Change of owner, change of plans: A Method to compare different ownership models of a system, applied to a steam case.","Tempel, K.S.","Stikkelman, R.M. (mentor); Herder, P.M. (mentor); Scholten, D.J. (mentor); Konings, J.G.T. (mentor)","2015","Large investments in renewable energy lead to new possibilities for industries. Such technologically and economically sound projects can be limited by non-optimal ownership settings. The Risk Ownership Assessment(ROA) is developed to integrate the ownership aspect with the technical system. ROA compares different ownership configurations with risks and provides a support tool for decisions on ownership.. The method can be further developed on usability to increase the chance of the future use by other parties.","ownership; risk; method; institutions; systems thinking","en","master thesis","","","","","","","","","Technology, Policy and Management","Energy and Insudtry","","SEPAM","",""
"uuid:8fedc757-e25b-4c72-9e2b-4cb96dfe5692","http://resolver.tudelft.nl/uuid:8fedc757-e25b-4c72-9e2b-4cb96dfe5692","Mm-Wave In-Package Antennas for Short-Range Car Radar Application","Zhu, W.","Cavallo, D. (mentor)","2015","","automotive radar; in-package antenna; eWLB package","en","master thesis","","","","","","","","2020-08-10","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","Telecommunication","",""
"uuid:9b83301b-efdc-408c-9d62-5be6a1508e2b","http://resolver.tudelft.nl/uuid:9b83301b-efdc-408c-9d62-5be6a1508e2b","Finite Element Modelling for Earthquake Loads on Dykes","Winde, H.P.","Jonkman, S.N. (mentor); Brinkgreve, R.B.J. (mentor); Schweckendiek, T. (mentor); Visschedijk, M.A.T. (mentor)","2015","In the last decades, induced earthquakes were caused by the extraction of gas in the Dutch province of Groningen. Both magnitude and frequency of these earthquakes are expected to increase in the following years, causing a threat for the flood defence system. To guarantee the safety against flooding, it is required to take the influence of earthquake loads on dykes into account. One of the most important mechanisms that can damage a dyke during an earthquake is liquefaction. The earthquake motion induces an increase of pore water pressure. Consequently, the effective stress decreases. Hence, the shear strength of the soil is reduced; since the shear strength is related to the effective stress. Liquefaction occurs in case of significant development of excess pore water pressure. The soil may lose its strength and act like a fluid. This can result in settlements, increasing the vulnerability to overflow and wave overtopping, and macro instability. Currently, most methods to determine water pressures are based on tectonic earthquakes; which typically have a deeper hypocentre and larger magnitudes than induced earthquakes in Groningen. Also the EERI MNO-12 monograph, providing probably the most commonly used method to determine the safety against liquefaction, is based on tectonic earthquakes. It is less complicated to include the difference between tectonic and induced earthquakes when using the finite element method. Furthermore, the method according to EERI MNO-12 gives conservative results in terms of excess pore water pressure, which may be predicted more precisely in the finite element method. Lastly, deformations are difficult to predict with EERI MNO-12; whereas this is one of the main purposes of the finite element method. The goal of this research is to gain insight in the value and applicability of both the UBC3D-PLM and the Hypoplastic constitutive model for the design of dykes, regarding induced earthquakes; particularly with respect to excess pore water pressure development. The research focuses on the determination of the earthquake load for the Dutch flood defences, the parameter determination for UBC3D-PLM and the Hypoplastic model and it compares the results of both models with centrifuge tests to evaluate their accuracy with respect to predicted accelerations, excess pore water pressure development and settlements.","earthquake; liquefaction; finite element method; constitutive model; UBC3D-PLM; hypoplastic model; PGA","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Hydraulic Engineering","","Hydraulic Engineering","",""
"uuid:14cf1c54-3b08-4d5d-b5de-aab8735e809b","http://resolver.tudelft.nl/uuid:14cf1c54-3b08-4d5d-b5de-aab8735e809b","Increasing the user adoption of MyOrder","Van Herk, S.","Snelders, D. (mentor); Kooijman, A. (mentor)","2015","In 2008, Thomas Brinkman founded MyOrder as a solution for delayed services in catering. He developed a mobile application that allowed users to order products, without having to wait for a waiter. MyOrder gradually expanded and in 2014 more than 14.000 merchants were connected to its platform. On the user side however, the adoption rate was much lower. In order to increase the user adoption, this project was initiated. Based on the Delft Innovation Model (Buijs, 2012), we analyzed the internal and external environment of MyOrder, developed a new adoption strategy and created concepts to accompany the new strategy.","strategy; user adoption; mobile; ordering; payments; mobile platform; enjoyment; social; innovation","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product Innovation Management","","Master of Science Strategic Product Design","",""
"uuid:6d1cc548-6e25-4631-a584-38ca10b8d31d","http://resolver.tudelft.nl/uuid:6d1cc548-6e25-4631-a584-38ca10b8d31d","Application of seismic interferometry by Multidimensional Deconvolution to USArray data","Al Sadan, R.I.M.","Weemstra, C. (mentor); Ruigrok, E. (mentor)","2015","Seismic interferometry by crosscorrelation has found wide application over the last decade. With which, the Green’s function is retrieved between two receiver positions. Because the bulk of the ambient seismic field consists of surface wave energy, most applications in seismology utilize the surface wave part of the Green’s function. The correct reconstruction of interferometric (surface wave) responses, however, relies on a number of assumptions to be fulfilled. Violation of these assumptions reduces the accuracy of the retrieved responses. Seismic interferometry by multidimensional deconvolution (MDD) has been shown to improve the retrieved response on synthetic data. A point-spread function (PSF) computed from the same ambient noise is deconvolved from the response acquired by crosscorrelation and the result is a better focused response. In this thesis, it is demonstrated with numerical modeling that seismic interferometry by MDD yields better results than seismic interferometry by crosscorrelation. Moreover, a different formulation of the underlying theory is considered. The new formulation obviates the need to separate in-and outgoing wavefields, which is a drawback of the original formulation. The MDD method resulting from the new formulation is also numerically tested and subsequently applied to the data recorded by a passive deployment of broadband sensors (Transportable USArray) along the east of the continental USA. Limited response improvement is achieved mainly due to two reasons: receivers aparature (large nominal receiver spacing/limited width and height of receivers array) and illumination gaps.","Seismic Interferometry; Multidimensional Deconvolution (MDD); USArray; Reflecting boundary condition; Absorbing boundary condition","en","master thesis","","","","","","","","2015-08-20","Civil Engineering and Geosciences","Geoscience & Engineering","","Applied Geophysics / IDEA League Joint Masters Program","",""
"uuid:1b8f60d1-d490-4030-a9d9-329d2075c9ac","http://resolver.tudelft.nl/uuid:1b8f60d1-d490-4030-a9d9-329d2075c9ac","Determinants of forward risk premium: An empirical analysis of the Spanish electricity market","Liu, S.","Espeja, E. (mentor); Belén, A. (mentor)","2015","This thesis contributed to the literature analyzing the functioning of deregulated wholesale electricity markets. In particular, it focused on the empirical analysis of ex-post forward risk premium in the Spanish electricity market. It aimed to investigate the risk drivers behind the forward risk premium, and therefore to gain insights about forward price formation as well as the functioning of forward markets. In this study, future prices for monthly base-load future contracts settled on the last trading day covering delivering time from January 2010 to March 2015 in OMIP, and monthly average spot prices from OMIE were used to calculate the ex-post forward risk premium. A comprehensive multifactor propositional framework was proposed so as to discover the determinants of forward risk premium. It included fundamental influences, behavioural effects, dynamic effects, market hedging, speculative activities and liquidity, regulatory instruments, and shock effects. In addition an econometric model based regression analysis was used to quantify the influence of these determinants on forward risk premium. To summarize, we found significant positive forward risk premium in the Spanish forward markets. The regression results suggested that market agents follow adaptive expectation formation rather than rational expectation. Moreover, the risk premium is positively influenced by regulated auctions, margin shocks, spot price volatility, and negatively influenced by basis.","electricity markets; spot and forward prices; price formation; risk premium; OMIE & OMIP","en","master thesis","","","","","","","","","Technology, Policy and Management","Faculty of Technology, Policy and Management","","Erasmus Mundus Joint Master in Economics and Management of Network Industries (EMIN), 2013-2015","",""
"uuid:b1c0303b-cd4d-4608-90b7-41a9fbe32215","http://resolver.tudelft.nl/uuid:b1c0303b-cd4d-4608-90b7-41a9fbe32215","The dynamic modeling of diesel engines in support of risk control in adverse conditions: TU Delft collaboration in the SHOPERA program","Kouroutzis, S.","Visser, K. (mentor)","2015","Ship accidents are caused daily others not so important with only scratches on the ship hulls and others are fatal for human life and also the environment. Some of the accidents are caused due to human error, but many are generated due to extreme conditions and to the minimized capabilities of the ships' designs. Ships seem to be underpowered in certain conditions with limited maneuverability as a result of being either old ships with less advanced equipment or newly built ships that need to satisfy specific regulations. There are regulations as the new EEDI lines which have as main purpose to minimize carbon dioxide emissions, though they still have the probability to impose risks in the propulsion and the maneuverability of new ships. In this thesis the dynamic behavior of diesel engines in heavy weather conditions is examined in order to identify the risks that threaten its functionality and overall the ship's propulsion. Research has been done in defining the engine's operational limits and the diesel engine's envelope. Furthermore, tests were performed on behalf of a European Commission's collaborative project called Energy Efficient Safe SHip OPERAtion (SHOPERA) and both numerical and software tools were designed for this project that define the engine dynamics and characteristics.","diesel engines; heavy weather; EEDI; simulation; SHOPERA","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Marine & Transport Technology","","Mechanical Systems & Integration","",""
"uuid:9cfa6bb8-da84-4038-8fd0-1a3e4bf9beaf","http://resolver.tudelft.nl/uuid:9cfa6bb8-da84-4038-8fd0-1a3e4bf9beaf","Introducing Product Diversity into a Supply Chain Designed for Bulk","Plooij, O.D.","Veeke, H.P.M. (mentor); Lodewijks, G. (mentor); Meesters, J.R. (mentor)","2015","The beer industry has gone through a change in the last 5 years. The introduction of many new products has caused the beer market to become much more diverse. Beer with sweet flavors for the summer, beers without alcohol for on the road and even a combination of cider and beer have become trendy products in different markets. HEINEKEN was one of the first global brewers to spark this change with their new product innovations. However, as has HNS has always operated with high volume and lower product diversity, the supply chain has started to show its limits in capacity. The processes of brewing, packaging and distributing a low diversity of products in high volume batches has always been the strategy. The breweries have been designed and optimized to operate in such an environment. With the changes taking place in the market, where the innovations are causing a higher frequency of production of smaller volume batches it has impacted the efficiency of both the operations and the supporting organization. The supply chain requires more transparency and certainty on potential bottlenecks as these days there are continuous predictable bottlenecks arising which could have been proactively caught. The term HEINEKEN uses for this perceived impact of product diversity into their supply chain that was designed for bulk is complex. Through a two-step process, the meaning of complexity is discovered and a part of it needed to be made more transparent. This is done through partially relieving the organization of its uncertainty. To understand how the introduction of a diverse product portfolio has created complexity through its impact on the production facilities that were designed for bulk production. Followed by: To select one opportunity within the supply chain that is strongly affected by the diverse product portfolio and finally to reduce this perception of complexity through the creation of transparency in this area. During a thorough analysis of brewing, packaging and distribution it became clear that the diversity of products affects every supply chain process. There are a number of symptoms that were define as the drivers of this efficiency reduction. The increased level of volume to be produced, the movement of productions between breweries, the reduced batch volume of production are just the tip of the iceberg of the impact of the new strategy on HNS. HEINEKEN was indeed experiencing complexity as new process had to be created and more reactive solutions were introduced. The fact of the matter is, the company’s proactivity is becoming less and reactivity is becoming a natural processes. It is this that has caused problems to pile up and now are slowly starting to overflow. This is where the efficiency is lost. Here the opportunities are found and where the knowledge from different companies with an even more diverse product portfolio can be used. Literature has greatly supported the search for areas in the supply chain impacted by the product diversity. Product variety affects the process performance, and, conversely process performance affects the product profitability. “the cost of a product is determined by the performance of the processes that deliver it”. (”Waging War on Complexity Cost”, 2009) From the long list of opportunities found during the initial step of this thesis only one could be selected to further pursue and to ultimately propose a solution. The selection for this opportunity was based on a number of elements. First of all it had to include an area where the product diversity is clearly visible. Secondly, the product diversity had to be continuing to grow in the future and finally current impact of this diversity would have to be unknown to the department of HNS. The search for an opportunity that was not yet seen by HNS was not an easy task. The result of these three elements was found in the outbound logistics warehouse. Every product passes from the packaging lines or third party packagers through this warehouse before it is finally shipped to the customer. HNS makes use of third party production facilities to cope with the product diversity and portfolio expansion. The warehouses at HNS see every product that is sold by the company. They are unloaded, stored and loaded with the highest diversity of products. The warehouses have started to reach their capacity limits and the need for external storage is becoming a more frequent solution. In addition it was discovered that its capacity was calculated in colli (boxes) and/or hL, whereas the physical storage is in pallets. These are only a few of the observations that lead to the conclusion that the perceived complexity is high in this part of the supply chain and that it is understandable for the HNS organization to become overwhelmed. The most interesting observation was that there was no forecasting model that could predict how much stock would be on-hand for the upcoming months. There was no certainty on the number of pallets that needed to be stored or loaded. This in return created reactive processes and the perceived complexity. The decision was made to create a long-term planning model (S&OP Outbound Logistics) which would calculate the capacity for the number of stock pallets and loading pallets on a weekly basis for the upcoming 18 months. The model would be based on the 18 months prior to the start calculation date. The output of the model would allow for a more accurate prediction of external warehouse pallet space hiring and number of required forklift drivers for the future weeks. However it has also shown its potential in proactively solving operational issues by proactively marking them. Designing the model in such a way that proactivity could be introduced into the warehouse to create more certainty in this part of the supply chain. The expectation is that it would allow the efficiency levels to start increasing again. The S&OP Outbound Logistics model takes into consideration a number of product flows; packaging production, third party (co-fill) production, third party (repack) repacking and finally interbrewery (domestic market replenishment) product transport. The model has been designed from a push system perspective as this is also the way HNS operates from packaging to the warehouse. Other options have been discussed in the research. A number of previously unknown variables have been calculated, such as the average time in warehouse of the products. The tool has shown its importance as it is the communication between three different IT systems in the HNS organization. This is the core of the issue, as these different systems are losing some key product characteristics. This is the product characteristic known as loading method. This model reconstructs this information per product and reallocate them for the remainder of the calculations. There are alternative options discussed for this reconstruction of data. Some assumptions have been made for the unfound products and have been confirmed by experts. The model would be based on a number of plans and variables from the three IT systems, ranging from the central packaging plan to the historical product distribution loads. The model is created and fully automated in Microsoft Excel and supported with coding in Visual Basics, hereby reducing the errors when operating it. Designed in such a way that when implemented and refreshed, the output data is supplied within 3 minutes in clear visual graphs with the hard data in the background. The model is verified and validated togetherwith expert on the field of warehousing at HNS. The accuracy of the output on different slices of the tool are calculated and known to be within the boundaries of the desired level, considering the reconstruction of data and the definition of the warehouse. There is still room for improvement in the prediction of the stock level. Finally the tool has been implemented within the HNS processes for the breweries of Zoeterwoude and Den Bosch where it will be reviewed every month. In conclusion to the previously perceived complexity of HNS, the model has provided more certainty on the stock level and loading capacity. Its accuracy for the stock levels are between a range of §20% and still show the opportunity to be improved with the correct measurements of average time in warehouse. The output provided by the required loading capacities are well with acceptable ranges, §15%. The model is highly sensitive to the packaging plan and when this fluctuates significantly when compared to the actual production it can cause unreliable output. This is the greatest threat to the sustainability of the model’s implementation as the forecast accuracy is directly affected by the product diversity. A list of recommendations is made to further increase the levels of accuracy of the model as well as other opportunities to be found from the discovered data. The strongest recommendation reflects back to the introduction of product diversity where currently there is no standardized or simplified method of knowing which product is an NPI and behaves under the the NPI characteristics. This lack of knowledge allows for uncertainties to get into the planning and operational processes, without being made predictable. The current tool for S&OPOutbound Logistics provides significant transparency in the warehousing planning opportunities in a proactive manner which should stand central in an organization of this size that is going through a change. The ability to now test different packaging plan scenarios lets the warehouse to become part of the supply chain and not just the next step. It is hereby reducing the perceived complexity of HNS through its prediction of a 18 month warehouse plan.","beer market; warehouse planning; push model; forecasting; product portfolio","en","master thesis","","","","","","","","2020-08-01","Mechanical, Maritime and Materials Engineering","Transport Engineering & Logistics","","Transport Engineering & Logistics","",""
"uuid:6f135acb-d661-40b0-b2ba-3bce195a86d7","http://resolver.tudelft.nl/uuid:6f135acb-d661-40b0-b2ba-3bce195a86d7","Doubly-Fed Induction Machine for use in Mini-Hydro Power Plants","Syed, Rizwan Rafique","Polinder, H. (mentor); Toftevaag, T. (mentor)","2015","","DFIG","en","master thesis","","","","","","","","2015-08-22","Electrical Engineering, Mathematics and Computer Science","Electrical Power Engineering","","","",""
"uuid:7179edff-b498-4c3b-900d-62d61f8665df","http://resolver.tudelft.nl/uuid:7179edff-b498-4c3b-900d-62d61f8665df","Using Github Profiles in Software Developer Recruitment and Hiring","Nagaram, A.R.","Hauff, C. (mentor)","2015","Social coding platforms can provide initial understanding about the skills exhibited by the developers on these platforms. In contexts where candidates social profile information is useful for recruiting software developers, the information regarding the developers on these platforms can be leveraged by the recruiters with some software knowledge. However, recruiters have to put many efforts in inferring about a developer skill on social coding platforms. In this thesis, we investigate on providing relevant information regarding software developer capabilities on a social coding platform to the recruiters. We used GitHub as our social coding platform for this purpose. We explored regarding, the attributes to use for indicating the skills exhibited by a developer on GitHub. We also investigated GitHub as a resource containing some potential software developer candidates by recommending GitHub developer profile, solely based on skill set requirements of job advertisements. Our results indicate that the generated developer skill profiles have a valid set of attributes when combined, to indicate the regarding three skills exhibited by a software developer on GitHub. However, the generated profile was slightly preferred by the technical recruiters because of the profile's complexity in understanding and incompleteness. In the investigation of recommending developer profiles to suit job advertisement requirements our recommendation strategy could only achieve a precision of 0.39 on average and an Normalized Distance Based Performance Measure (NDPM) ranking accuracy value of 0.43 on average.","GitHub Data; Software Job Advertisements; Content-Based Recommendation","en","master thesis","","","","","","","","2015-08-21","Electrical Engineering, Mathematics and Computer Science","Computer Science","","Software Technology","",""
"uuid:56d99717-f15a-4ffa-b6a1-40c9ddc4eb93","http://resolver.tudelft.nl/uuid:56d99717-f15a-4ffa-b6a1-40c9ddc4eb93","A Dual-Beam Design Concept for the LOUPE Spectropolarimeter","Arts, M.L.J.","Kuiper, J.M. (mentor); Stam, D.M. (mentor); Snik, F. (mentor)","2015","In this thesis, a dual-beam design concept for the LOUPE (Lunar Observatory for Unresolved Polarimetry of Earth) spectropolarimeter is presented based on the work by Karalidi [2012] and Hoeijmakers [2013]. The mission statement of LOUPE is: LOUPE shall do spectropolarimetry of the Earth from the Moon in order to obtain reference data for exoplanet research. The requirements made by Karalidi [2012] and Hoeijmakers [2013] have been extended to a complete quantifyable requirements list from which the actual instrument can be designed. Trade-offs have been made for the choice of the technique to do spectropolarimetry and the polarizing beamsplitter that need to be implemented in LOUPE. The trade-off for the spectropolarimetric technique resulted in the choice of the spectral modulation technique in the form of the SPEX technique [Snik, 2009], because it allows for a compact design without moving components and is capable of doing instant polarization measurements. However, the SPEX technique does not allow for measuring circular polarization, meaning that LOUPE will only be capable of doing full linear spectropolarimetry. The trade-off for the polarizing beamsplitter resulted in the choice for the Savart plate as the beamsplitter, since a Savart plate allows for uniform splitting over the entire field of view. Using a ZEMAX model of LOUPE, it was shown that the aberrations caused by the Savart plate can be solved using a cylindrical lens. The dual-beam concept for LOUPE was determined in this thesis to be an f/4 system that has a field of view of 20 deg. The quarter-wave plate and multi-order-wave plate required for SPEX are located directly after the objective lens. The Savart plate is located in the image plane of a hexagonal microlens array (MLA). The MLA splits up the field of view in 44x35 pieces. Using clever stacking, the two modulated spectra for each MLA element are imaged on a 1024x1024 pixels detector. This results in 3x3 samples over the Earth, which allows for spatially resolving continents and oceans. A Matlab model for calculating the reflected solar flux levels on the Moon was made to analyse the obtainable polarization sensitivity per sample. This showed that with this concept a polarimetric sensitivity of 10^-4 can be achieved for terrestrial phase angles around 0 deg. A polarimetric sensitivity of 10^-3 can be achieved for terrestrial phase angles around 170 deg.","space; instrumentation; optics; spectropolarimetry; LOUPE; polarimetry; dual-beam; moon; Lunar; exoplanets; earth; optical","en","master thesis","","","","","","","","","Aerospace Engineering","Space Systems Engineering","","","",""
"uuid:606be77d-2212-4dfb-b795-aa4a8f098fa9","http://resolver.tudelft.nl/uuid:606be77d-2212-4dfb-b795-aa4a8f098fa9","Modeling of hydrodynamics around in-line structures in installation analysis","Hoekstra, C.F.C.","Metrikine, A. (mentor); De Oliveira Barbosa, J.M. (mentor); Renting, F.W. (mentor)","2015","Thesis on hydrodynamic forcing descriptions on complex shaped in-line structures during the installation phase and their impact on the dynamic behaviour of the catenary.","hydrodynamics; in-line structure; pipeline installation; structure installation; Heerema","en","master thesis","","","","","","","","2020-08-20","Civil Engineering and Geosciences","Structural Engineering","","Offshore and Dredging Engineering","","51.9988687, 4.3756432"
"uuid:33d07a9e-2e76-40c1-af10-9fecba12eb8d","http://resolver.tudelft.nl/uuid:33d07a9e-2e76-40c1-af10-9fecba12eb8d","Surface Wave Analysis for the characterization of granular material deposits","Ashruf, T.N.","Socco, V. (mentor); Ghose, R. (mentor); Garofalo, F. (mentor)","2015","Knowledge of near-surface seismic-wave velocity of granular materials plays a valuable role in seismic exploration data processing. I will use the surface-wave analysis method for estimation of shear-wave velocity profile and P-wave refraction for estimation of pressure-wave velocity on a data set acquired over a sand dune in The Netherlands, a dune area part of The Holland coast. For surface-wave analysis I exploit the fact that in these materials the velocity profile follows a power-law and I invert for the power-law coefficients using a Monte Carlo inversion. A second power-law is introduced into the Monte Carlo inversion to recover vertically varying structures. The P-wave refraction is applied for estimation of the groundwater depth and P-wave velocity. After the seismic data were acquired, several analyses were made on the extracted dispersion curves from different sources, windowing in space domain indicate the presence of lateral variation. The estimated shear-wave velocity profiles demonstrates the usefulness of imposing a power-law trend to the velocity. Although the inverted power-law coefficients results into small differences with the literature and theoretical values, these can be explained by the varying shapes of the grains. Furthermore, the implementation of the second power-law results into velocities that are lower than the first layer. The depth of the shear-wave velocity profiles is limited by the shallow position of the water-table around 3 m. For the best practice in field work the vibroseis source is advised due to the advantage of the continuous sweep covering the whole frequency band in one signal.","surface waves; granular materials; characterization","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Petroleum Engineering/Applied Geology/Applied Geophysics and Petrophysics/ Geo-Engineering/ Resources Engineering","",""
"uuid:37bcdde0-3c16-4312-97ea-82ca8693bc16","http://resolver.tudelft.nl/uuid:37bcdde0-3c16-4312-97ea-82ca8693bc16","Adaptive Port Masterplanning for Europoort at Port of Rotterdam","Arecco, P.H.E.","Vellinga, T. (mentor); Hertogh, M.J.C.M. (mentor); Taneja, P. (mentor); Oosting, M.W. (mentor); Vervoorn, P.H.J. (mentor)","2015","Waterborne transport infrastructures play a crucial role in global integration, and ports are key components to materialise this amalgamation. However they are constantly challenged to keep fulfilling their functions in a changing environment. Port of Rotterdam, the largest port in Europe and the Western hemisphere too, faces those challenges on a daily basis. In order to maintain and enhance the future efficiency of the Harbour Industrial Complex, strategic adaptations based on long-term planning are required. This is more relevant on those existing port areas such as Europoort, where basic infrastructure is approaching the end of their life cycle, and fragmentation of original plots led to inefficient use of the land and some waterfront areas. In order to meet these needs, this study presents the application of Adaptive Port Planning framework (Taneja, 2013) to the existing Europoort Masterplan for increasing its robustness while ensuring that the port has the license-to-operate and the license-to-grow in the long-term. The Adaptive Port Planning approach goes further than the traditional port planning approach throughout incorporating uncertainty and flexibility considerations. Furthermore, this project also integrates the PIANC Green Ports approach (PIANC, 2014), as well as other existing frameworks towards a sustainable growth of the port.","flexible; adaptive; long-term planning; masterplan; sustainable ports; port success; opportunity framing; ecosystem services; social valuation; PIANC","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Hydraulic Engineering","","","","51.9433333, 4.1425"
"uuid:be59e1f6-ff2e-4e2b-b0ed-9b58f7cbea33","http://resolver.tudelft.nl/uuid:be59e1f6-ff2e-4e2b-b0ed-9b58f7cbea33","Cooperative Sequential Composition Control for Compliant Manipulation: An Approach via ""Robot Contact Language""","Shah, A.M.","Lopes, G.A.D. (mentor); Najafi, E. (mentor)","2015","A convoluted manipulation task involves extensive planning and the use of a supervisory controller to execute the desired task. One controller specification is generally unsuitable to perform the complete manipulation task. Manipulation involves contact of the object being manipulated with robots, surfaces and other objects in the scenario. The dynamics of a manipulation change when contact amongst these components are made or broken. Using this paradigm of contact amongst robots, objects and surfaces, the Robot Contact Language (RCL) is developed. Using a combinatory logic, the set of all possible contact combinations of the given components can be generated. Using a few simple rules such as making and breaking contacts, a “contact map” is then devised. On a symbolic level, a potential manipulation task can already be planned with the help of this map by traversing from the initial contact combination or “contact mode” to the goal contact mode. The contact map is enriched with the available geometric information (robot workspaces, surface geometry, etc.) and spatial relationships can then be defined amongst these contact modes for manipulations and mode transitions. Given the initial and final position of an object to be manipulated, planning begins with a simple graph search on the contact map for the shortest path form the initial to the final contact mode. The modes present in this path automatically divide the task into various subtasks. Manipulation planning can then be done “locally” in each of these contact modes with the aim to proceed further towards the final goal. Each of these sub-tasks can be achieved with a dedicated controller specification. A supervisory controller is needed to bring all these set of controllers together and execute them in a hybrid manner. For this purpose, the idea of sequential composition has been used. By defining the domains of attraction of each controller and the goal-sets already lying in the overlapping state-spaces, the controllers are executed sequentially to achieve the overall manipulation task. As contact involves interaction forces, a study is also done to understand the working of a spatial spring based impedance controller to achieve compliance in the robotic arm. Simulation have been conducted on Matlab and VREP software to validate the usage and reliability of manipulation planning based on contact maps as well as the performance and versatility of the compliant robotic arm.","robotics; robotic manipulation; manipulation planning; Robot Contact Language; contact map; compliant manipulation; sequential composition control; Matlab; VREP","en","master thesis","","","","","","","","2016-11-01","Mechanical, Maritime and Materials Engineering","Delft Centre for Systems and Control (DCSC)","","Systems and Control","",""
"uuid:3f4af78b-895f-4ef8-a45c-b37858c203a3","http://resolver.tudelft.nl/uuid:3f4af78b-895f-4ef8-a45c-b37858c203a3","Design of a new packaging solution for the bigger clients of PostNL Parcels","Toetenel, R.W.","Lodewijks, G. (mentor); Veeke, H.P.M. (mentor); Zuurbier, M. (mentor); Moman, M.S. (mentor)","2015","","parcel packaging; e-commerce; Saaty","en","master thesis","","","","","","","","2020-08-01","Mechanical, Maritime and Materials Engineering","Transport Engineering & Logistics","","Transport Engineering & Logistics","",""
"uuid:93e71db0-d7a4-40f1-9bf0-0687233ae2f6","http://resolver.tudelft.nl/uuid:93e71db0-d7a4-40f1-9bf0-0687233ae2f6","Detection of cavities in levees caused by the muskrat and other mammals by use of geophysical methods","Benthem, M.","Hopman, V. (mentor); Slob, E.C. (mentor); Ngan-Tillard, D.J.M. (mentor); Van der Kruk, J. (mentor)","2015","A wide range of wildlife has their habitat around and within levees or other types of embankment structures. In the Netherlands the burrowing of the muskrat causes internal and external erosion, altering the geometry of the earthen structure. As often century-old embankments protect the densely populated land against the water, the burrowing can form a severe thread to the public safety. At present, the problem is managed by placing lethal and non-lethal capturing techniques in and around burrow founds by visual inspection. Although the population of the muskrat has been under control since 2004, a growing opposition of the media and public to the current control policy gives potential to a different way of monitoring embankments for animal cavities. This research focuses on a geophysical approach to detect muskrat burrows and to visualize the spatial extent of the tunnel network. Various methods have been judged on their potential to image the shallow cavities and evaluated on their advantages and disadvantages for field application. As outcome, fieldwork has been conducted with ground penetrating radar using multiple frequencies (250, 500, and 1000 MHz) and electrical resistivity tomography using different array setups (Dipole-Dipole and Wenner). Sites of investigation have been chosen throughout the Netherlands with different sized and shaped embankments and soil constituents. To ground truth the observations, holes have been drilled by hand to confirm several anomalies. This resulted in identification of various animal tunnels, rocks and plastic debris. However many drilled holes did not yield the desired outcome and many anomalous reflections remained unidentified. Moreover some entrances indicated by the muskrat controllers have not been detected by the methods. The 500 MHz antenna showed the highest resolution in the shallow subsurface and has been the best in detecting and mapping the muskrat burrows. The resistivity arrays failed to clearly distinguish any cavity from the surrounding soil. Organizations worldwide have reported similar nuisance activities of wildlife in dams and levee systems. An efficient instrument that reduces the labour-intensive management is highly desired. Optimizing geophysical methods, in particular the ground penetrating radar, for shallow small-sized cavity detection is a future interest.","muskrat; GPR; ERT; cavity","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Section Applied Geophysics and Petrophysics","","Applied Geophysics","",""
"uuid:55fd0ff6-e782-483c-8e17-8b895f1c577c","http://resolver.tudelft.nl/uuid:55fd0ff6-e782-483c-8e17-8b895f1c577c","Gait Chaotification","Lensink, R.A.","Lopes, G.A.D. (mentor)","2015","In multi-legged robots, such as the Zebro robot from TU Delft Robotics Institute, locomotion can be addressed as a Max-Plus Linear (MPL) system. In such MPL systems the gait is generated and controlled by abstracting the continuous motion of the legs to the occurrences of discrete touch-down and lift-off events, which are subsequently described in a linear fashion using max-plus algebra. Ergo the name Max-Plus Linear system. The cyclic gaits that are generated by a MPL model function well as long as the terrain that the robot is walking on remains flat and smooth. However, problems may arise when the complexity of the terrain increases; the robot may have trouble traversing the terrain or, in the worst case, get stuck entirely. The conventional solution to solve this problem is to extend the MPL model into a class of Switching Max-Plus Linear (SMPL) models in order to make the MPL system event varying. Such SMPL models can switch between different gaits. Thus, the current gait can be switched to a more optimal one when problems arise. In this thesis, however, an alternative solution involving chaotic behavior is considered to the above described problem. Chaos is a complex random-like type of behavior exhibited by nonlinear dynamic deterministic systems. This type of behavior used to be seen as useless and undesirable, because it was thought of as unstable and unpredictable. Relatively recently, however, this opinion was revised as the usefulness of chaos and its characteristics and by extension its desirability in certain applications was recognized. Robotic legged locomotion might just be one of these applications in which chaos would be useful and desirable. In this thesis, therefore, it was investigated if the locomotion of a multi-legged robot in complex terrain can be improved by rendering its gait chaotic through chaotification of the (switching) max-plus linear system. For this purpose, firstly, two different chaotification methods have been designed for the (switching) max-plus linear system of the Zebro robot. The first one involves chaotification of the mode of operation, which is the parameterization of the gait that a articular MPL system generates. Chaotic logistic map dynamics are used to create a chaotically switching max-plus linear system that generates a chaotically evolving gait. The second method implements a chaotification procedure from literature to the MPL system of the Zebro. It involves applying a feedback input function dependent on only one state variable into each dimension of the system. Secondly, a method to measure and verify the chaoticity in MPL or SMPL systems based upon lyapunov exponent calculation from a time series was contrived. Instead of measuring the sensitive dependence on initial condition from a sequence of discrete event vectors, it is proposed to measure that of the maximum cycle time. Lastly, the chaotification methods were used to generate a various number of different Zebro models. All of which were subsequently used in a simulation experiment wherein their ability to traverse randomely generated terrain of different levels of complexity was assessed. In general it was found that the chaotic models with chaotic gaits did not perform better than the periodic models. The one exception to this was the Zebro model generated with the second chaotification method.","thesis; gait; locomotion; max-plus; chaos; chaotification; CyberZoo","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Delft Center for Systems and Control","","MSc Systems and Control","",""
"uuid:6b3381e9-3054-4f93-8123-4c7587a249eb","http://resolver.tudelft.nl/uuid:6b3381e9-3054-4f93-8123-4c7587a249eb","Sustainable Solid Waste Management for Ahmedabad, India","Jani Kedar, R.","Quist, J. (mentor); Enserink, B. (mentor); Korevaar, G. (mentor); Dijcker, R. (mentor); Eijsbouts, R. (mentor); Nieuwenhoven, M. (mentor)","2015","Solid waste Management has become severe issue in India. With burgeoning population, the urban utilities are crumbling under pressure of population explosion, lack of funding and political pressure. The focus of this thesis is on Solid Waste Management in city of Ahmedabad. The research investigates the potential solutions and policy packages required for a 'Zero Waste Society for Ahmedabad' using over-arching methodology developed for Backacsting approach including scenario studies, futurology, modelling and participatory group discussions to form solution sets for different scenarios adpapting Policy Package concept developed by European commission.","participatory; backcasting; waste; urban","en","master thesis","","","","","","","","2015-08-20","Technology, Policy and Management","Department of Technology, Dynamics and Sustainable Development","","Energy & Industry","","23.0300, 72.5800"
"uuid:fb784b70-bad4-46be-adfc-fcf1b013e27f","http://resolver.tudelft.nl/uuid:fb784b70-bad4-46be-adfc-fcf1b013e27f","Reward system design for incorporating control performance","Nagaki, K.","Lopes, G.A.D. (mentor)","2015","Reinforcement learning (RL) is a machine learning technique whereby the controller learns the control law by optimizing the received cumulative amount of reward. A reward is an instantaneous evaluation of the applied action at the current state, given by reward function. However in theory the reward function is assumed to be given, in practice it is an effort consuming work to design a good reward function. Reward is the only information about the learning task given to the controller and therefore optimizing the cumulative amount of reward corresponds to fulfilling a particular control performance. Designing the reward function to achieve the desired control specification is thus a crucial task to use RL as a controller synthesizing algorithm. The goal of this thesis is to synthesize a method to design proper reward function to achieve the desired control performance. This thesis focuses on two types of control performance. In the first part, reward function is designed to learn control law fulfilling classical control performance. Hereby an automaton is created to evaluate classical control criteria by mode-dependent reward functions. By modeling the process with an automaton, the control problem is divided into smaller subproblems such that the reward functions are kept simple. In the second part, temporal logic specification is converted into a reward system whereby a petri net is used to model the process suitable for rewarding. To the given temporal formula, reward function is assigned which is a function from the state, i.e. the marking, of the petri net. By putting information about the task into the petri net, reward function becomes simple and structured. Simulation experiments are done for several temporal logic specification.","Reinforcement Learning; Reward function; Petri net; Metric Interval Temporal Logic; MSc thesis","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Delft Center for Systems and Control (DCSC)","","MSc Systems and Control","",""
"uuid:73e9422d-b201-47d0-bdc3-7da693b0d8d6","http://resolver.tudelft.nl/uuid:73e9422d-b201-47d0-bdc3-7da693b0d8d6","Management Information for corporate Learning and Development","Balk, S.P.P.J.","Verburg, R.M. (mentor); Rook, L. (mentor); Kortman, L.J. (mentor)","2015","The corporate learning and development [L&D] environment is currently changing and managers involved in corporate L&D are more and more requesting insight in the contribution of learning towards their business and feedback on how well the department is performing. To meet these business needs the objective of this study was to generate the requirements for a management information system in relation to corporate learning. Specific attention has been paid to the determination of the desired information elements (i.e. measures and metrics) to be constructed and communicated by such a system. The results of this research should help KLM Business Campus [KBC] and other corporate L&D departments with the (further) development of their management information system.","corporate L&D; management information; Learning and Development","en","master thesis","","","","","","","","","Technology, Policy and Management","Economics of Technology and Innovation","","Management of Technology","",""
"uuid:c4d16700-b007-4180-9c42-e9f49a45df24","http://resolver.tudelft.nl/uuid:c4d16700-b007-4180-9c42-e9f49a45df24","Engineering Critical Assessment of Buckle Arrestor","Wu, N.","Metrikine, A. (mentor); Janssen, M. (mentor); Van de Meer, F.P. (mentor)","2015","In the deep water S-lay installation, the buckle arrestor rolls on and drops off the rollers repeatedly when it moves along the stinger. When the buckle arrestor is located on the roller, there is strain intensification at the 12 o'clock position of the pipe section which is close to the buckle arrestor, and the strain can reach 1%. When the buckle arrestor drops off the roller, the strain decreases. The maximum strain occurs around the position where the girth welding is located, a defective girth welding part may fail under this cyclic loading. If an initial flaw exists, it is important to be able to predict the total crack growth under the cyclic loading process. The thesis is conducted in three stages. In the first stage, the global FE model is used to model the buckle arrestor behavior during its passage over the stinger, especially the bending moment variation. In the second stage, the output from the global model is used as input for the local FE model, to obtain the stress and strain of the pipe cross section. In the third stage, based on the local FEM output, Engineering Critical Assessment is carried out on the girth welding part, and the girth welding safety is judged by comparing the predicted crack growth with the limit standard. It is found out that the buckle arrestor is safe under realistic cyclic loading conditions. This is due to the relatively small strain range which cause little influence on the fracture resistance. The total crack growth can be treated as superposition of tearing growth and fatigue growth. In further extension, when the large cyclic strain range is applied, according to some experiments and numerical results, the simplified superposition method is not suitable. The compressive loading could reduce the crack tip fracture resistance. In that case, a proper evaluation of the fracture resistance under the large cyclic loading conditions becomes necessary. Further systematic study should be carried out on the mutual effects of tearing growth and fatigue growth.","stress; strain; tearing; fatigue; crack; ECA","en","master thesis","","","","","","","","2020-08-19","Mechanical, Maritime and Materials Engineering","Offshore Engineering","","","",""
"uuid:1c96c249-9fcf-4559-832a-cb51cda06b91","http://resolver.tudelft.nl/uuid:1c96c249-9fcf-4559-832a-cb51cda06b91","Improving the gas station experience","Hoogeveen, W.J.","Kuipers, H. (mentor); Van Kuijk, J.I. (mentor)","2015","A visit to a gas station is currently often chaotic and full of annoyances and anxiety. The customer at the pump in front of you is taking forever getting a coffee inside the shop, all pumps on the right side of your car are taken or your hands are getting greasy because there are no more plastic gloves in the dispenser. These are just a few examples of issues gas station visitors have to deal with during their visit. Refueling is not really anyone’s hobby, but it should at least be a smooth, easy, fast and relaxed interaction, right? Based on an elaborate onsite and online research to the current user experience at Dutch Shell gas stations, a new design was developed. In this design many issues that were found in the current experience research were dealt with. No more anxiety trying to maneuver in-between trucks, trying to find out where to go, trying to find an available spot at the pumps, searching for a pump on the right side of your car, having picked the wrong queue at the pumps or not being able to find a parking spot close to the shop. The new gas station design introduced in this project creates a more smooth, clear and relaxed gas station experience: guiding the customer to the right pump, but also guiding him/her during refueling, during payment and during parking.","gas station; shell; user experience; user centered design","en","master thesis","","","","","","","Campus only","2017-08-19","Industrial Design Engineering","Applied Ergonomics and Design","","","",""
"uuid:df6d3ad8-c65a-48bf-93cf-f5f38d0b4c1b","http://resolver.tudelft.nl/uuid:df6d3ad8-c65a-48bf-93cf-f5f38d0b4c1b","Better Mobility Support for Radio Spectrum White Space-enabled Devices","Majid, A.Y.","Przemek, P. (mentor)","2015","","Dynamic Spectrum Access; WSDB","en","master thesis","","","","","","","","2017-10-01","Electrical Engineering, Mathematics and Computer Science","Telecommunications","","Telecommunications","",""
"uuid:ec565db0-3445-48c8-8059-0fad62aea7f7","http://resolver.tudelft.nl/uuid:ec565db0-3445-48c8-8059-0fad62aea7f7","Topology optimization using the Finite Cell Method","Groen, J.P.","Ruess, M. (mentor); Langelaar, M. (mentor)","2015","The ongoing demand for better performing designs, has resulted in an increase in the complexity of topology optimization problems. Traditionally, the majority of the corresponding computational cost comes from solving the analysis equations using linear finite elements (FE). In this thesis a topology optimization method is presented, that is based on the finite cell method (FCM). This higher-order fictitious domain method is, due to its decoupled geometry-, integration-, and analysis-mesh well suited for large-scale topology optimization, and reducing its corresponding computational cost. The use of a decoupled density and analysis mesh greatly reduced the computational cost of topology optimization compared to linear FEM. Especially in 3D topology optimization examples, the computational cost has been decreased by more than a factor 10, while maintaining a high-resolution in the density field. The use of a larger length-scale can reduce the computational cost even more, which is especially beneficial for robust topology optimization. It is identified that the choice of the analysis system completely depends on the complexity of the optimization problem. Simple optimization problems showed great increase in computational efficiency using relatively low polynomial degree (p= 1, 2, 3), combined with more density elements per finite cell. For more difficult topology optimization examples, such as problems were the boundary conditions have to be enforced in the weak sense, or stress-constrained topology optimization, a more accurate analysis system is required, hence a larger polynomial degree should be used.","topology optimization; finite cell method; computational efficiency","en","master thesis","","","","","","","","","Aerospace Engineering","Mechanics, Aerospace Structures & Materials","","","",""
"uuid:e60e68fe-d1f6-458b-8a5a-d5036e32fb69","http://resolver.tudelft.nl/uuid:e60e68fe-d1f6-458b-8a5a-d5036e32fb69","Micro - Thruster Development: Propulsion System for the DelFFi Mission","Krusharev, I.","Zandbergen, B.T.C. (mentor)","2015","The format and size specifications of the CubeSat platform require highly miniaturized subsystems, one of the most challenging ones being the propulsion system. Up to date, according to the authors' knowledge, only two CubeSats have successfully operated a propulsion system in space: CanX-2 in 2008 and Defil-n3Xt in 2013. The importance of a miniaturized propulsion system becomes even more apparent when taken into consideration that most, if not all, of the CubeSats launched to date, due to budget constraints, have been piggybacking their launches into space and therefore they may end up in a non-optimal orbit. As a next step, a formation flying technology demonstration mission is planned by the Delft University of Technology (DelFFi), as part of the QB50 project. This thesis gives an outline of the present development status of micro-propulsion systems at Delft University of Technology. The main design driving criteria are provided by the DelFFi satellites requirements. Keeping in mind the educational environment in which the work is performed, safety drives the requirements: thus, propellants have to be non-toxic and easy to handle. Additionally, present requirements aim at a thrust level in the range of 1 to 10 [mN] and a total ?V of 15 [m/s] or more. Wet mass, when installed in triple-unit CubeSats, shall be less than 450 [g], and peak power consumption less than 10 [W]. A number of Commercial-Off-The-Shelf (COTS) systems have been investigated to find suitable candidates that fulfil these minimum requirements. However, it has been concluded that all presently available systems have low Technology-Readiness-Level (TRL) or their performance is out of the required range. It was thus necessary to start working at custom designed system. The design process and decisions made will be presented in this thesis. Furthermore for testing purposes also a test setup and an engineering model propulsion system was made. A general test program using LabVIEW was made that can automate the testing process of the thruster. The system was then tested and from the results, recommendations and conclusions were made for the next iteration of the thruster.","propulsion; CubeSat; DelFFi; satellite","en","master thesis","","","","","","","","2015-08-20","Aerospace Engineering","Space Engineering","","Space Systems Engineering","",""
"uuid:44c5cb07-52b1-414e-a598-61022200bbad","http://resolver.tudelft.nl/uuid:44c5cb07-52b1-414e-a598-61022200bbad","IT Architecture for Entrepreneurial Organizations","Van den Boogaart, M.C.","Janssen, M.F.W.H.A. (mentor); Hulstijn, J. (mentor); Van der Voort, H.G. (mentor)","2015","","IT architecture; Entrepreneurial Organization; Organization Theory; Organizational Life Cycle","en","master thesis","","","","","","","","","Technology, Policy and Management","Engineering, Systems and Services","","Informatie en Communicatie Technologie","",""
"uuid:006c21ee-90e7-4f38-a576-d3d57adbf2b5","http://resolver.tudelft.nl/uuid:006c21ee-90e7-4f38-a576-d3d57adbf2b5","Temperature Regulated Concrete Bridges","Van der Meer, T.E.","Hordijk, D.A. (mentor); Blom, C.B.M. (mentor); Bouwmeester-van den Bos, J. (mentor); Groeneweg, T.W. (mentor)","2015","Concrete bridges are subjected to large lateral deformations, which if restrained will also lead to large (axial) stresses in the structure. If unrestrained these deformations caused by temperature variation and shrinkage, can become problematic for bridges of sufficient continuous length. If deformation is restrained to some degree, then the structure will also be subjected to large stresses proportionally to how much the structure resits deformation. Both deformation and stresses can cause problems if it becomes too large. If the relative weak to tensile stresses concrete is subjected to tensile stresses exceeding concrete tensile strength, than in case of axial stress, large thorough cracks will develop in the bridge deck. To prevent this are expensive and maintenance heavy expansion joints often used to allow free deformation and prevent the development of stresses. In this study an alternate approach was proposed to reduce temperature load. Temperature of the bridge deck can be regulated by embedding hydronic heat exchangers into the concrete. This results in large reduction of temperature and with it temperature related deformation and stresses. Total axial stresses could be reduced enough that in most or all cases no thorough cracks will develop, reducing or removing the need of expansion joints. Furthermore longer bridges are possible as the limiting factor, thermal deformation, can significantly be reduced. The Thermal Energy Reservoir needed to store and extract the thermal energy from the bridge, is smaller in size per square bridge in comparison to similar projects (de-icers). Regulating bridge temperature can due to the relative low thermal energy cost and ease to reduce temperature load be an efficient method to increase the application of continuous bridges and reducing the need of dilatation.","","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","","",""
"uuid:9e5878a3-e7ad-4bb5-bdc5-5d370a1d10c6","http://resolver.tudelft.nl/uuid:9e5878a3-e7ad-4bb5-bdc5-5d370a1d10c6","Seismic attenuation analyses of fracturing in reservoir rocks","Verheij, J.","Barnhoorn, A. (mentor)","2015","In this study seismic wave velocity and seismic wave attenuation in dry Bentheimer sandstone, Indiana limestone, and Whitby shale are studied while continuously deforming and therefore increasingly fracturing the rock samples up until macroscopic failure. A pulse transmission technique at a central frequency of 1 MHz is used in combination with a high pressure system that is constantly applying uniaxial stress. At early deformation stages before yielding, increasing elastic strains correlate with decreasing seismic attenuation suggesting closure of existing fractures. The deviation from a linear stress-strain relationship indicates the yield point, i.e. the onset of plasticity or fracturing. After yielding, increasing plastic strains correspond to increasing seismic attenuation suggesting formation of new micro-fractures. Thereby, P-wave attenuation is more sensitive to the growth of fractures than S-wave attenuation. The existence of fractures is confirmed by postmortem micro-CT-images. Absolute attenuation values are highest for Indiana limestone and lowest for Whitby shale. Furthermore, S-wave attenuation is the most sensitive to fracturing in Indiana limestone, followed by Bentheimer sandstone; P-wave attenuation is the most sensitive to fracturing in Bentheimer sandstone, followed by Indiana limestone. Attenuation in Whitby shale is the least sensitive to fracturing for both P-waves and S-waves. This study confirms that attenuation is more sensitive to fracturing than the seismic velocity; hence attenuation is suggested to be a valuable seismic parameter to identify fractures. Finally, the study presents the possible usage of amplitude decay-over-time analysis of seismic waves for possible borehole applications and the prediction of induced seismicity.","seismic waves; seismic attenuation; Bentheimer sandstone; Indiana limestone; Whitby shale; uniaxial stress; fracturing; Posidonia Shale Formation","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Section Applied Geophysics and Petrophysics","","Petroleum Engineering and Geosciences","",""
"uuid:68fce787-bd45-495f-ac5a-23132038b2bf","http://resolver.tudelft.nl/uuid:68fce787-bd45-495f-ac5a-23132038b2bf","Fracture Mode Analysis, Geomechanics, Petrophysics, and Fracture Characterization: An Experimental Investigation on Whitby Shales and Various Other Rock Types","Primarini, M.I.W.","Barnhoorn, A. (mentor); Bertotti, G. (mentor); Zitha, P.L.J. (mentor)","2015","The rapidly decreasing reserves of conventional gas has forced oil and gas industries to conduct more exploration on unconventional resources, like shale gas. To produce gas from shales in economically viable manner, stimulation techniques like hydraulic fracturing are required. One important factor for a successful hydraulic fracturing is knowing the fracture characteristics such as the fracture mode occurrence. Unfortunately, the factors controlling the fracture mode occurrence are not known yet. This study tries to find out the factors controlling the fracture mode occurrence by investigating the relation between fracture angle, confining pressure, and several rock properties. The fracture mode analysis being developed in this study suggests that for low strength rock like Bad Bentheim sandstone (46.65 MPa) and Indiana limestone (36.5 MPa), fracture modes are not dependent to the confining pressure. Fractures are already at mode II at zero confining pressure, while stronger rocks like Belgium limestone and Granite (125 and 128 MPa respectively) show fracture mode I at zero confining pressure. The experiments convey that the strength of the rock, which is related to its porosity, is the dominant factor controlling the occurrence of fracture mode I and mode II. This study also evaluates the prospectivity of the Whitby mudstone formation in the United Kingdom, which is a depositionally- and time-equivalent shale to the Posidonia Shale Formation (PSF). The PSF is one of the potential resource rocks for shale gas exploration in the Netherlands. Brittleness indices and fraccability indices of WMF from various methods are also determined and analyzed in this study. The results of WMF characterization show that WMF has high heterogeneity, which could imply that it is less favorable for hydraulic fracturing. Comparing the results of WMF to other producing gas shale shows that the WMF has a low range in: porosity, Young’s modulus, and quartz content, and high range in: laminations, and clay contents, suggesting that WMF is less potential for the shale gas resource. However, based on its characteristics, if WMF is divided into four zones, our experiments show that several zones (top and bottom part of WMF) can be considered as the most favorable ones for hydraulic fracturing in the WMF formation.","Whitby mudstone formation; fraccability index; brittlenes index; fracture mode; fracture Angle; hydraulic fracturing","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Section Petroleum Engineering","","Section Petroleum Engineering","",""
"uuid:3b751680-e0c8-4848-a6d7-8951749fee23","http://resolver.tudelft.nl/uuid:3b751680-e0c8-4848-a6d7-8951749fee23","Empowering an Integrated Solution for Better Air in Beijing","Dong, L.","Santema, S.C. (mentor); De Jonge, F.M. (mentor)","2015","A small Dutch company Lightwell B.V. (LW) handles LED light business. It is developing an advanced LED street light pole in which the charging function for electrical vehicles (EV) is embedded, called LightMotion (LM). With this innovative idea, LW tries to enter a new market, Beijing, China. However, the product and service of the LM as well as the business strategy were originally designed for the European market. Facing with unfamiliar business and market, LW therefore encountered a problem: How can we sell the LM to China? Research Question: Which adjustments need to be made for the financial leasing business model of the current EV charging pole design solution to fit the Beijing circumstance in the current situation and coming years? INSIGHTS The instinct feature of LM is the combination of the EV charging and streetlighing functions. It decides LM fitting for outdoor (semi-)public space in a city. Thus the government becomes the primary customer of LM considering the market size, the complexity in the relationship of the stakeholders, the competition in the market and the capability of LW. Besides, the practical needs of the customer and the end users of the LM requires different performance in various situations. In public, it is expected to be fast charging and providing more sockets. RESULTS The results can be seen as the guidelines for making Business Strategy (BS) and Design Solution (DS). Following the BS guideline, LW is suggested to go for the Government Procurement with the accompanying positioning and business model which is a top-down approach for LM to enter the target market. For the DS, the guideline suggests some improvements in the product form and interface, and a more integrated service platform for the entire product as a multi-functional Smart City infrastructure.","integrated solution","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","PIM","","Master of Science Strategic Product Design","",""
"uuid:6cf6c908-0f5d-4096-b3ad-aa96fd1ff382","http://resolver.tudelft.nl/uuid:6cf6c908-0f5d-4096-b3ad-aa96fd1ff382","Parallelizing the Linkage Tree Genetic Algorithm and Searching for the Optimal Replacement for the Linkage Tree","De Bokx, R.","Witteveen, C. (mentor); Bosman, P.A.N. (mentor)","2015","The recently introduced Linkage Tree Genetic Algorithm (LTGA) has shown to exhibit excellent scalability on a variety of optimization problems. LTGA employs Linkage Trees (LTs) to identify and exploit linkage information between problem variables. In this work we present two parallel implementations of LTGA that enable us to leverage the computational power of a multi-processor architecture. These algorithm extensions for LTGA enable us to solve a problem that previously could not be solved, being the problem of finding high-quality predetermined linkage models that result in a better performance of LTGA for intricate problems by replacing the online-learned LTs. This is done by learning high-quality LTs offline by optimizing LTGAs performance as a function of static LTs. This results in a better performance of LTGA than with online-learned LTs as the problem complexity increases. A parameter-free implementation is used to search optimal subsets of linkage sets in the offline-learned LTs. This pruning of the LT results in a further performance improvement of the LTGA by, on average, removing about 50% of the linkage sets from the offline-learned LTs. This suggests that LTs contain redundancies that may possibly still be exploited to improve the performance of LTGA with online-learned LTs.","parallel; optimization; modeling; LTGA; Linkage Tree; Linkage Tree Genetic Algorithm; model optimization","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Software Technology","","Algorithmics","",""
"uuid:a7b12894-6850-4bba-859a-8060caeb6941","http://resolver.tudelft.nl/uuid:a7b12894-6850-4bba-859a-8060caeb6941","Patient journey mapping, a consulting service for Capgemini Consulting","Monninkhof, M.L.","Abbing, E.R. (mentor); Simonse, L.W.L. (mentor)","2015","CONTEXT & GOAL OF THE PROJECT This graduation project was done in collaboration with Capgemini, one of the biggest organizations in the field of management consultancy and information and communication technology. More specifically, the project was done for the Dutch consulting groups ‘Public & Health’, and ‘Digital Customer Experience’ (DCX). The market unit Public & Health sees a trend where patients get more actively involved in the content of care, with their understanding and needs for care as a guideline. However, these changes don’t happen automatically. Care institutions need to adjust to these developments by reviewing their healthcare service on patient experience. Capgemini can accompany care institutions in this transformation by means of a patient experience consulting service, using patient journey mapping. Nevertheless, the practice of patient experience is still fairly new to Capgemini Consulting. However, in other sectors like Consumer Products and Retail, the practice of customer experience and customer journey mapping has already been proven to be valuable. Therefore, the objective of the project is to design a patient journey mapping approach, as a patient experience consulting service for Capgemini Consulting. APPROACH Several exploratory research activities have provided input for a theoretical set of design criteria on the patient journey mapping approach. The research activities included a literature review, a multiple case study on customer journey mapping and a study on the perspectives of patient experience practitioners. Based on the findings and criteria that resulted from the exploratory research activities, a concept was designed for the patient journey mapping approach. The concept was validated and refined by means of a patient journey mapping workshop at Capgemini Consulting. Moreover, the concept was validated by means two accelerated patient journey mapping projects, in collaboration with two care institutions. From the evaluation of the validation projects, a final set of design criteria was defined for the patient journey mapping approach. With these criteria in mind, the final concept was designed for the patient journey mapping approach as a patient experience consulting service for Capgemini Consulting. RESULTS As a result of several research and design activities, a patient journey mapping approach is suggested for Capgemini Consulting. The approach includes an explanation on the similarities and differences between consumer- and patient journey mapping. Moreover, a detailed description is given on the process, activities and tools that are part of the patient journey mapping approach. Finally, the patient journey mapping approach presents an example patient journey, accompanied by suggestions on what building content to include in the patient journey. The example patient journey is available at www.patientjourney.mirthemonninkhof.com. CONCLUSIONS & RECOMMENDATIONS Added value of the patient journey consulting service. Results from the exploratory research and validation projects showed that patient journey mapping could offer much added value to healthcare organizations, especially for the quality of the relation between the organization and their patients. Recommendation in balancing costs and benefits. Whilst patient journey mapping offers great potential for the quality of healthcare organization-patient relations, results also revealed that the approach is quite new to healthcare organizations. This, in combination with the fact that patient journey mapping is not about delivering predetermined solutions, quantifiable results or implementable solutions poses a challenge for Capgemini in selling the service to their healthcare clients. Therefore, to ensure that Capgemini’s consulting service of patient journey mapping presents a good balance in costs and benefits, Capgemini could organize the service in a way that allows clients to choose between a ‘short’ and a ‘full’ customer journey track: The service could be organized as such that clients can start with a short customer journey track. Based on the results from this short track, they can decide to go for the full customer journey track or not. Patient journey mapping compared to consumer journey mapping. Core principles of customer experience practice don’t change much whether you practice it in a healthcare context or consumer industry context. Nevertheless, the purposes for which customer experience is adopted do present some clear differences. For example, goals that are characteristic for healthcare but not for consumer industries are: to reduce readmissions, to identify opportunities for patient-empowering health systems, or to support dialogue between patients and professional caregivers. In addition, a goal that is often set in consumer industries but hardly ever in healthcare is the goal of additional purchases. Finally, there are some customer experience goals that are of interest for both types of industries, these are: increased customer loyalty, customer referrals and identification of the root causes in customer experience bottlenecks. Capgemini’s customer journey mapping approach compared to the patient journey mapping approach. Whilst no major differences were found between the process of patient journey mapping or consumer journey mapping, there are important differences between the suggested patient journey mapping approach and the existing customer journey mapping approach of Capgemini Consulting. These differences are mainly caused by design principles that were inspired from the multiple case study and have been adopted in the patient journey mapping approach. Basically, the influence of the design principles is that they increase the customer/patient perspective, which is considered as one of the key benefits by healthcare organizations. Recommendation in the adoption of design principles. When Capgemini is planning to offer the patient journey mapping service to their healthcare clients, a recommendation is to familiarize a selection of consultants with the design principles that are part of the patient journey mapping approach. After all, they make up an important ingredient of the approach. Another possibility to help internalize knowledge on patient or customer experience design principles would be to hire designers that have experience in the field of customer experience or service design.","customer experience; customer journey; patient experience; patient journey; contextmapping; co-creation; design","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Strategic Product Design","","","",""
"uuid:3f1a5a6f-eaf5-415f-8a40-a9a81e0252e0","http://resolver.tudelft.nl/uuid:3f1a5a6f-eaf5-415f-8a40-a9a81e0252e0","Towards Meaningful and Valuable Data Mining Results in Organizations: Developing a framework for data mining that facilitates interaction between decision makers and data scientists to successfully apply data mining in a business context","Meulenberg, Q.J.J.","Verbraeck, A. (mentor); Oey, M.A. (mentor); Van der Voort, H.G. (mentor); De Koning, H. (mentor)","2015","Data mining is more and more applied in organizations, but often fails to realize its full potential. It delivers too many results, and not all results are useful for the organization. Moreover, by applying DM in organizations, the interface between data mining and decision making has to be crossed. This report presents a framework to apply data mining in organizations. It has been established through insights of literature review and a case study. The framework focuses on a collaboration between data scientists and business stakeholders, making it the first attempt to consider data mining as a socio-technical system.","data mining; socio-technical system; design science research; framework design; decision making","en","master thesis","","","","","","","","","Technology, Policy and Management","Systems engineering","","","",""
"uuid:45e488ee-e96a-484d-89e8-61f81beed1ad","http://resolver.tudelft.nl/uuid:45e488ee-e96a-484d-89e8-61f81beed1ad","A Smart Home: Main Control Unit and Nodes","Abdollahi Jounaghani, S.; Mol, R.G.","De Weerdt, M.M. (mentor); Spaan, M.T.J. (mentor); Morales-España, G.A. (mentor)","2015","In order to cope with various supplies and loads in an autonomous microgrid, a system of sensors and a control unit was developed. The goals of this system are to cope efficiently in the event of an energy supply shortage, and to prevent such events as much as possible. To achieve these goals, the aim was to manage energy in the system as efficiently as possible. The system consists of a collection of sensor nodes, a control unit and an analysis unit. The sensor nodes monitor power flow and collect data from the outlets. The main control unit manages the power flow and prevents shortages, and relays information between the nodes and the data analysis unit. The data analysis unit uses historical data collected from the nodes to make predictions on supply and demand and to make scheduling decisions. This thesis is concerned with the main control unit and the nodes. Theory about power management, node monitoring and communication is discussed, followed by the implementation of the MCU and the nodes. A proof of concept (PoC) has been made with the MCU and some nodes. This PoC is evaluated, followed by the conclusions and recommendations for future work.","microgrid; smart grid; sustainable","en","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Software Technology","","Electrical Engineering","",""
"uuid:9e614bea-1798-4e83-8f4e-0142ee785ce5","http://resolver.tudelft.nl/uuid:9e614bea-1798-4e83-8f4e-0142ee785ce5","Gearbox Control Unit for the Paddle-shift System: Implementation and Verification of the Hardware and Software","Thomas, A.P.","Van Genderen, A.J. (mentor)","2015","In the dynamic domain of motorsport, the most agile is naturally the victor. A race car can only be as efficient as the systems that control it and here lies the importance of automotive embedded systems which offer precise and quick control over the mechanics of the race car. The Gearbox Control Unit (GCU) for the Paddle-shift System is one such product that controls the gearshifting process in the sequential transmission, which is the predominant type of transmission used in the motorsport industry. As a hundredth of a second can be an immense gain, the proposed GCU provides a robust solution for managing the gearbox, to achieve efficient transmission of engine power to the wheels, allowing high vehicle speeds to be maintained and achieving minimal gearshifting durations. The software framework for the Microcontroller Unit is implemented in such a way that the system can respond expeditiously to all possible scenarios that can occur in racing, supported by its complete testing and validation. The control algorithm is versatile, enabling the GCU to meet the requirements of different types/categories of racing vehicles with the same type of transmission, thus making it a universal product. The hardware is also designed to meet the standards of the harsh automotive environment and is also tested in co-ordination with the software in terms of functionality and timing. In this thesis, the design and implementation of the software together with the hardware for the GCU is explained in detail. Furthermore the results of testing the device on a racetrack (in-vehicle) are presented.","automotive; embedded systems; gearbox control unit; microcontroller; sequential manual transmission","en","master thesis","","","","","","","","2020-08-09","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","Embedded Systems","","52.263101, 6.896487"
"uuid:4e8719cb-ad06-475e-99a6-942edaf66c9f","http://resolver.tudelft.nl/uuid:4e8719cb-ad06-475e-99a6-942edaf66c9f","Unsteady Aerodynamic Load Control Using DBD Plasma Actuators: Various Trailing-edge shapes and Multi-DBDs","Rezaeiha, Rahim (TU Delft Aerospace Engineering)","Kotsonis, Marios (mentor); Hansen, Martin (mentor); van Bussel, Gerard (graduation committee); Michelis, Theo (graduation committee); Delft University of Technology (degree granting institution)","2015","Big wind farms with big wind turbines are more cost effective and produce greener electricity compared to smaller ones. This is one of the reasons for the growth of wind turbine size during the last 3 decades. However, as wind turbines become bigger, their blades become longer, thicker and heavier. This results in larger unsteady loads on blades which is an important limitation for their life time and their size growth. Flow control has emerged as the promising solution both for improving the aerodynamic efficiency and controlling the unsteady loads on wind turbine blades. DBD plasma actuator is an active flow control mechanism that has shown high potentials for unsteady load control with the capability to change lift coefficient to a significant amount with a very fast response time. The current research first intends to identify the variations of angle of attack and lift coefficient on wind turbine blades as a result of gravitational loads, mass and aerodynamic imbalances, turbulence, wind shear, yawed inflow and tower shadow and investigate their corresponding frequencies and the fatigue damage from the blade root bending moments. Then, (single and multi) DBD plasma actuator with different configurations will be used on three different trailing-edge shapes (round, half-round and sharp) of modified version of ’NACA64-2-A015’ airfoil to control the aerodynamic loads via circulation control. This is managed either by manipulation of Kutta condition or acting as a virtual Gurney flap. Furthermore, it is intended to investigate the correlation between the frequency of actuation, frequency of vortex shedding and the amount of lift enhancement.","Windenergy","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:19ff7562-8319-4227-9154-5d5b50150377","http://resolver.tudelft.nl/uuid:19ff7562-8319-4227-9154-5d5b50150377","Characterization of traffic events using social media","Dokter, E.","Bozzon, A. (mentor)","2015","Accidents, malfunctioning matrix signs, oil on the road and a bridge that is not able to close are examples of traffic events that happen every day on the Dutch roads. In the Netherlands we are able to measure traffic speeds and calculate travel times on highways and most important secondary roads using a network of connected traffic measuring points. The data that is collected using these points is available for anyone interested and distributed every minute. This distribution frequency makes it possible to detect near real time traffic disturbances. However, the traffic data does not provide information about what is actually happening on the road. During rush-hour or particular city events traffic disturbances are expected, but there also exist many disturbances of the unexpected kind: accidents and car or truck breakdowns for example. In this study we focus on the characterization of traffic events by using Twitter as an information source. Using open traffic data as a traffic event provider we link tweets to traffic events using different linkage strategies in order to extract traffic information. Related traffic tweets can than be used to extract cause types and enrich traffic events. We developed a demonstrating system for the Netherlands that is able to extract traffic cause types using two different Dutch Twitter datasets. The system uses a set of detected traffic events as its input.","traffic; twitter; social media; web information systems","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Web Information Systems","","","",""
"uuid:c0ff4c2f-1a16-4a67-8ab5-add15f100b6b","http://resolver.tudelft.nl/uuid:c0ff4c2f-1a16-4a67-8ab5-add15f100b6b","Numerical and experimental investigation on the resistance of a human upper airway: A study to decrease pressure loss by the introduction of a swirling flow","Hak, Marlies (TU Delft Aerospace Engineering)","Veldhuis, Leo (mentor); van Zuijlen, Alexander (mentor); Kotsonis, Marios (mentor); Bergsma, Otto (mentor); Delft University of Technology (degree granting institution)","2015","This report comprises the research entitled 'Numerical and experimental investigation on the resistance of a human upper airway'. The objective of this research is: To investigate the effects of a swirl producing inlet on the pressure drop in a simplified human upper airway model at high ow rates, by means of numerical simulations and experiments. In the literature study done by the author Hak (2014b) it is found that during exercise up to 15% of the maximum oxygen uptake (V O2;max) is spent by the breathing muscles. The breathing muscles support the breathing process by moving the diaphragm, creating a low pressure in the thoracic region, thereby starting the inflow of air. Since the human upper airway is featured by a complex shape, associated with highly three-dimensional ow patterns, it has a relatively high ow resistance compared to the remainder of the airways. If the ow pattern would be influenced by passive ow control in the form of a breathing aid, the pressure drop could be reduced, thereby decreasing the demand on the breathing muscles. The result is that more O2 can be used in the skeletal muscles and thus the anaerobic-threshold is postponed. This lead to the following main research question: What kind of swirl generating mouthpiece device can influence the inhaled ow, such that a pressure drop reduction is achieved, during intensive exercise? The research started off with an identification and simulation of the the upper airway ow. Typical human upper airway ow behavior which cause losses in pressure are found to be jetlike ow, re-circulating ow, detached ow, secondary ows such as Dean ow. If the upper airway is highly idealized, it can be seen as 'elbow pipe', a pipe with a 90o bend. Dean vortices and boundary layer separation in bent pipe ow are responsible for pressure losses. For the setting up of the simulation, the process of breathing is translated into boundary conditions. Simpli_cations and assumptions are done to the usual periodic behavior of breathing: a stationary inhalation rate is assumed, and only inspiration is considered. The compliance of the airway is not taken into account for simplicity and the ow rate is based on that of an exercising male adult","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:cea0ad67-63a7-4dcc-910e-7727bc4cf06e","http://resolver.tudelft.nl/uuid:cea0ad67-63a7-4dcc-910e-7727bc4cf06e","Sequences of Niche Strategies: An Exploratory Multiple-Case Study in Automotive","Vintila, S.","Ortt, J.R. (mentor); Kamp, L.M. (mentor)","2015","The thesis looked into sequences of niche strategies within the automotive industry. Using an exploratory multiple-case study research design, three technologies were investigated: dual-clutch transmission (DCT), anti-lock brakes (ABS), and polymer exchange membrane fuel cell vehicle (PEMFCV). The concepts of 'niche strategy' and 'sequence of niche strategies' were explicitly defined. The static model of Ortt et al. (2013) was revised to account for the dynamics of market realities. Three change drivers for the barriers to large-scale diffusion were identified and discussed. Lastly, the development of a theory on the topic of sequences of niche strategies was shown to present potential for further development.","sequence; niche strategy; high-tech; diffusion; innovation","en","master thesis","","","","","","","","","Technology, Policy and Management","Economics of Technology and Innovation","","Management of Technology","",""
"uuid:be4c984f-e287-4857-979b-cbe7c7866a90","http://resolver.tudelft.nl/uuid:be4c984f-e287-4857-979b-cbe7c7866a90","Gap Analysis for Energy Network Design: A Socio Technical Perspective","Mattaparthi, G.S.","Herder, P.M. (mentor); Enserink, B. (mentor); Heijnen, P.W. (mentor)","2015","Energy network infrastructures form an integral part of continuous, stable and uninterrupted energy supply and transmission. These structures are complex and mostly consist of wired or pipeline networks. Some examples of these networked infrastructures can be oil and natural gas lines, electricity (grids), heat pipelines, biogas and green gas lines, Carbon dioxide (CO2) emissions capture and distribution etc. These energy infrastructures primarily transport energy from their entries (sources) to exits (sinks). Modern industrialized societies perception of demand for energy is seeing a dynamic change. When energy transport distribution using existing networks becomes insufficient, then topology extensions come into play or the need for new infrastructures is demanded. The big question for the network planners is to identify the positions where these extensions are to be placed, keeping the total extension costs to the minimum. Moreover, in case of rolling out new networks in areas where population density is high and with their associated technical complexity, demand for proper planning techniques to design the network layouts is increasing. On the other hand, many scientific researchers have proposed different types of network optimization algorithms for routing in energy network planning from a system perspective. Models have been developed to simulate the networked infrastructures using several optimization techniques to provide cost efficient networks. Although these scientific models are proposed, either they are not well known or they are too complex for the network planners to use them in decision making for real world cases. These concerns led to the motivation of this research. In simple terms, there is a need to bridge the gap between the scientific knowledge and practical decision making for designing efficient energy networks. The research question for analyzing this situation is formulated as, “In what ways can the scientific approaches for energy network design be enhanced to ensure their usability among decision makers?” To answer the research question, the energy network of biogas and upgraded biogas (greengas) in Netherlands was chosen for this study. The first phase started with an empirical study of the biogas energy network from a Socio-Technical (ST) perspective. This perspective was chosen to understand the network characteristics of the supply chain of biogas production and distribution. Literature study and interviews with experts were conducted to understand the technical aspects, the key stakeholders involved in the network planning and the institutional directives that drive the network design. From the ST study the main factors that can influence the network design, their inter-relations and the interests of the stakeholders were clearly identified. After gaining a system perspective of the biogas/ green gas network the various scientific approaches proposing different optimization techniques for network planning were studied closely. The advantages, limitations and the assumptions of these techniques were carefully studied to understand why they are not used for real world cases so far. After the empirical study, in the conceptualization phase, the factors needed for network design from the ST perspective were base-lined keeping in mind the various stakeholder interests, especially the needs of the network planners. Based on this understanding a design approach was proposed to adapt existing scientific models with the factors obtained from the ST study. In the synthesis phase, the base-lined user requirements of decision makers and the working principles of the adapted algorithms, were combined and a user friendly interface design was proposed. This User Interface (UI) aids decision making for network planners and can be regarded as a Decision Support System (DSS). The DSS is proposed as a software application in the form of use cases, sequence diagram and screen layouts. The DSS incorporates the actual requirements of the decision makers and combines it with the adapted scientific approaches of network planning and optimization, bridging the gap between scientific knowledge and practical decision making. Research Findings and Recommendations The heterogeneity of different energy networks, network characteristics and the different actors involved makes the notion of decision making as “one size fits all” less suitable. The different technical components, energy characteristics and the network equipment are specific to each energy network and they need to be separately considered while planning a network design. The empirical study of the socio technical analysis for biogas energy networks and the study of the scientific optimization methods, have been successful in drafting the characteristics of biogas networks which are important for network planning. A pipeline transporting gas over long distance has larger diameter and has compressor stations spread in the area to maintain the operating pressure of the gas in the pipeline. The article 12b of the Dutch Gas Act governs the rules for gas transmission and distribution in NL. The network facilitators are obliged to connect the gas producers to the grid if they meet the gas quality and grid specifications. In climate sensitive areas, the demand for gas can be low in summer and can be very high in winter. Gas storage's and flexible production units are introduced to balance the demand of gas against supply depending on the specific region and the operating pressure of the pipeline. The desired specifications of these technical components may influence the building costs of network design and have to be considered while designing solutions for network optimization. The non-overlapping factors from the ST study like the passive pipe profile and the active controllable components like compressor station, valves etc. need to be considered by researchers while creating scientific models. A design approach is proposed to enhance the functionality of the existing models through newer cost equations and decision making logic. The sociological study concludes that the main stakeholders display network characteristics of variety, inter dependencies and closeness. All of them share different goals and interests and want to maximize their interest. Using the scientific models directly is still very complex for them. Thus, there is a need for increased collaboration among different stakeholders and a transparent system where all of them can come together and make decisions in the interest of all. The proposed decision support system combines the realistic requirements of the decision makers, simulates a real environment of an energy network and also inherits the benefits of the adapted scientific approaches. Although this is not the scope of this research, mentioning it will boost biogas production in NL. From a policy perspective, Government needs to increase the depreciation period of subsidies for biogas production and also regulate the biogas market. This move can ensure more production and also safety and reliability of the grid. Stakeholder collaboration is also seen as an important aspect and there is a need for conducting Constructive Technology Assessment of biogas through scenario workshops. These moves will bring the different stakeholders together, reduce uncertainty and decisions can be taken in the interest of all.","energy networks; biogas; network optimization; multi-actor; user tool; decision support","en","master thesis","","","","","","","","","Technology, Policy and Management","Engineering and Policy Analysis","","Energy and Industry","",""
"uuid:1c4c9168-41e6-4311-88ba-b8f536cd42a3","http://resolver.tudelft.nl/uuid:1c4c9168-41e6-4311-88ba-b8f536cd42a3","Robotic edge rounding for shipbuilding","Jansen, M.P.","Delgado Lopes, G.A. (mentor); Kistemaker, J. (mentor); Glijnis, P.C. (mentor)","2015","In the wake of several dramatic incidents where cargo ships were lost at sea due to corrosion related structural failure, spilling large amounts of oil, the regulations regarding corrosion preventions have been tightened. Specifically regulations regarding painting and painted surfaces in a ship’s sea water ballast tanks are stricter than ever before. Hence it is now mandatory to round off steel edges before applying paint to ensure long lasting protection against corrosion, a process named edge preparation. Therefore the main objective of this thesis is: “conceptualise, design, build and test a prototype robotic edge rounding system”. The objective is attained by successfully completing three phases: Conceptual, Implementation and Experimental phase. The final concept is found by performing a trade-off between various working principles based on the set requirements and working constraints. The optimal concept is determined to be a quarter radius end-mill on a passive compliant spindle, mounted on a position controlled six degree of freedom robotic arm. The implementation of the proposed concept focusses on the synthesis of a suitable control law using geometric algebra and the mechanical implementation of the passive compliant milling tool. The result is a compact spindle with two sliding axis providing the needed compliance to contact a stiff workpiece. Two point contact bearings enable precise relative positioning of the mill and the edge to be rounded. Furthermore a feedback motion controller is implemented, allowing the robot to adaptively follow planar contours in space. Validation of the proposed solution is obtained by way of full scale experimentation with a test platform on cut-outs in steel profiles. Results show that the chosen concept is capable of correctly rounding variously shaped contours under realistic conditions.","robotics; PSPC; edge rounding","en","master thesis","","","","","","","","2020-08-01","Electrical Engineering, Mathematics and Computer Science","Electrical Engineering","","Signals & Systems","",""
"uuid:2fc5c66a-ae64-484d-a5df-9671f980cf8c","http://resolver.tudelft.nl/uuid:2fc5c66a-ae64-484d-a5df-9671f980cf8c","Solar powered charging station for electric cars- conductive and wireless inductive","Leendertse, M.","Van de Geer, S.G. (mentor); Silvester, S. (mentor)","2015","Charging Station The single beam design allows the solar construction to be placed in all types of parking areas. The integrated street lantern in the construction solves the problem off overshadowing from external street lanterns. Conductive charging The new conductive charger provides charging feedback right in the hand of the user. The improved feedback simplifies the user identification proces. Inductive charging The copper coils in the road and underneath the car provide power to the car while driving.","solar; charging; station; PV","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","","",""
"uuid:f0f0691c-f1a2-48f8-bafe-35a21fc4c408","http://resolver.tudelft.nl/uuid:f0f0691c-f1a2-48f8-bafe-35a21fc4c408","Conceptual Clustering of Patents: Enhancing insight for the decision making process in Strategic Technology Planning","Kruijthoff, K.","Cunningham, S. (mentor); Van Geenhuizen, M.S. (mentor); Van Splunter, S. (mentor); Sanz, A. (mentor)","2015","Within technological R&D companies, the decisions made within their Strategic Technology Planning (STP) process are of great importance due to their financial, legal and competitive repercussions. For this reason their R&D managers want to be as widely informed as possible about the risks and benefits of developing a certain technology. As the subjects for which these decisions are made, are too complex to comprehend, there is exploitation of so-called Decision Support Systems. This research focusses on those Decision Support Systems in the STP process which are based on patent analysis. Patent analysis is relevant to apply in this process as the patent database is considered to be a comprehensive collection of technological concepts. This is due to the fact that companies voluntarily deliver the information, and benefit from describing their technological innovation as complete as possible. Throughout the STP process multiple needs for insight to make informed decisions can be detected. However, as every applied form of analysis will present a representation of the selected subject, which’ outcome is based on assumptions made as well as on the underlying method applied. The user cannot be sure that this given outcome is always correctly representing reality. Hence, they are applying multiple representation methods on the same subject, a process which is also referred to as multiplism. Within this process they are searching for robust outcomes that hold true under all the different representations. Due to this process, there is an ever present interest in new methods of representation and analysis, to extend the R&D division’s decision support toolkit. Due to the ever present need for more insight, alongside a methodological interest, this research focusses on the evaluation of the applicability of conceptual clustering to patents, as well as its potential usability in the STP process. Conceptual clustering is a machine learning technique developed in the 1980’s, which automatically categorizes the entered information, resulting in a tree shaped hierarchy. The conceptual clustering technique hasn’t been found to be applied to patents before and this research will therefore also focus on identifying its potential use within the STP process. To gain insight into the different needs for patent analysis within the STP process, as well as to provide a source for evaluation, a design has been made for the decision support system by applying the Axiomatic Design method. The inputs for this design are customer needs which have been based on a literature study and expert input on the different applications for patent analysis in the STP process. To assess its potential applicability, a prototype Decision Support System, constructed around the method of conceptual clustering applied to patents, has been developed. For which the implementation of the conceptual clustering functionality is done based on the COBWEB algorithm as proposed by Fisher. The prototype entails two software products written in Python which are respectively a text-mining and a conceptual clustering program, combined with a visualization tool based on the D3 JavaScript library, for which an online environment has been developed. To illustrate the evaluation, a complete selection of patents related to additive manufacturing (3D printing) retrieved from Thomson Reuters’ Derwent patent database is used. This patent set (containing 9360 patents) has been parsed through-, and visualized by-, the developed prototype, showing a representation of this technological field’s inter-patent relational structure. Through evaluation based on the design, the prototype has been proven to be usable within the STP process for Exploration analysis, Competitor analysis and Portfolio analysis. The highest added value to the R&D division’s toolkit is perceived to lay in the explainability of the outcome, the accessibility through the online visual representation and the possibility of using the decision support system in an interactive way. Allowing the technology scouts and managers to interact with the data, discussing and continuing exploring based on newly gathered insights. Furthermore implementable solutions are presented, allowing to extend the developed prototype’s applicability for use to the inclusion of Freedom to operate analysis capabilities, trend analysis and to a limited extend inventive problem solving analysis capabilities. Further evaluation of the prototype based on a comparative analysis of the case with the output created with a self-organizing map technique, leads to further conclusions on the conceptual clustering technique. Firstly, the same high level clusters can be detected, however not all inter-relations of these clusters match. Forcing the user to further investigate, increasing robustness of knowledge obtained. Secondly, the conceptual clustering shows more application domains in addition to the technical concepts. Thirdly, multiple representations can be made of the same set based on user needs. Fourthly, the influence of the attribute number, for which it is suggested to perform a high level search first. Then select a subset of patents for reprocessing and visualization, in order to obtain more insight into sub-branching. Finally, the combinational use of the two methods enhances the insight, due to the explanatory value of the nodes in the conceptual clustering output.","Conceptual Clustering; Visualization; Patent Analysis","en","master thesis","","","","","","","","2015-08-17","Technology, Policy and Management","Policy Analysis","","Engineering & Policy Analysis","",""
"uuid:6c752803-6325-4ed9-8b8c-ec52e9fae5db","http://resolver.tudelft.nl/uuid:6c752803-6325-4ed9-8b8c-ec52e9fae5db","MUAC En Route Delay Absorption Capabilities for Schiphol Inbounds","Adriaens, L.M.C.","Hoekstra, J.M. (mentor)","2015","Over the duration of the last year research regarding the en route delay absorption capabilities of the MUAC airspace for Schiphol inbound flights has been performed. Delay absorption currently takes place in the lower airspace, where as a result air traffic controllers and pilots experience increased workloads during one of the most critical periods of a flight. This in combination with the expected fuel inefficiency of delay absorption in the lower airspace resulted in this research to investigate the options of moving delay absorption away from the lower airspace, into the en route airspace. The MUAC airspace is all airspace above FL245 over The Netherlands, Belgium, Luxembourg and West-Germany, encompassing Schiphol inbound flights entering the LVNL airspace (all airspace over The Netherlands up to FL245) from the South, East and North. Traffic data from two sample days was selected (one in high season and one in low season) to reflect the different traffic patterns occuring throughout the year, based on which the planning conflicts were determined. From these planning conflicts the amount of required delay absorption has been obtained, and used as an input to determine which way of en route delay absorption should be used. A range of delay absorption measures has been defined and evaluated: linear holding and dropping for all routes, and detouring and turtling for selected Northern routes. Linear holding means only slowing an aircraft down to the Maximum Range Cruise speed at most, and dropping represents both slowing an aircraft down while lowering its altitude by 2000 ft across its trajectory within the MUAC airspace. Detouring and turtling are the equivalent of linear holding and dropping, respectively, however executed on an extended trajectory. Changing the trajectory of an aircraft may result in conflicts with other traffic, hence it was decided only to use these measures for the Northern routes. This part of the MUAC airspace has a lower traffic density in general, and was the only airspace that could reasonably be provided with detours. The changes were implemented in the scenarios, which were run in the BlueSky Open Source ATM Simulator to gather data on fuel consumption (using Eurocontrol’s Base of Aircraft Data), air traffic controller communications workload, and the number of conflicts with other traffic. The data obtained from the delayed scenarios has been compared to the original scenario to see how the variables were affected by the delay absorption. The delay absorption within the MUAC airspace was found to be 0.4 s/NM for linear holding and 0.7 s/NM for dropping. For the three routes through the Jever sector that were found eligible for detouring and turtling, an additional 8 seconds should be counted for each additionally flown nautical mile. Fuel consumption has been compared to the fuel consumption in the original scenario, from which a slightly reduced fuel consumption was found for linear holding (-0.1%), but a significantly lower fuel consumption for dropping and turtling (-45% and -50%, respectively). This strong reduction in fuel consumption is caused by the earlier initiated descent, during which the aircraft can throttle back to idle thrust. Detouring was found unfavourable in terms of fuel (due to the additional path length), but is nevertheless an effective means of delay absorption. The communication workload was generally found to strongly increase during MUAC peak loadings. Adding more work when a controller is already at his/her busiest is not very desirable, which is why it is unlikely that delay absorption during peak loading can be implemented in the way it was simulated. However, off-peak workloads were sometimes found to be even lower than in the original scenario. This can be explained by the reduction of the number of conflicts, due to which some of the workload assigned for resolving conflicts could be eliminated. During these times of day en route delay absorption would be more than just feasible; it would be very desirable. The ability to predict the change in communication workload has been assessed by computing the correlation between expected and actual change in communication workload, as well as between traffic density and actual change in communication workload, but no relation was found to be strong enough to give a representative indication of the actual change in workload. Overall, the total number of conflicts during linear holding and dropping runs for the low season day were found to lower by 1.1% and 0.4% respectively. The high season saw an overall increase of 0.7% of the total number of conflicts. It is thus expected to be favourable for other traffic if en route delay absorption is performed during low season days, but mostly unfavourable during high season. The Jever sector was the only sector to be equipped with detouring and turtling options, and during all scenarios except for the August linear holding and dropping scenarios a reduction of the total number of conflicts was observed. It can be concluded that when care is taken in when and how en route delay absorption is implemented, it most definitely shows potential to (partially) replace delay methods in the lower airspace.","air traffic control","en","master thesis","","","","","","","","","Aerospace Engineering","Aerospace Design, Integration & Operations","","Control & Operations - ATM, Airports & Safety","",""
"uuid:ab0374fe-be2d-4b89-9d98-9ee847c24ad0","http://resolver.tudelft.nl/uuid:ab0374fe-be2d-4b89-9d98-9ee847c24ad0","Managing the impact of a complex product portfolio on outbound logistics operations","Pigeaud, L.M.","Verbraeck, A. (mentor); Wiegmans, B. (mentor); Vrancken, J.L.M. (mentor); Reimers, S. (mentor)","2015","The past few years have shown a significant increase in demand for diversity in the global beer market. HEINEKEN, the third largest beer brewer in the world, has therefore embraced a global strategy with a diverse product portfolio in beer and packaging types. This strategy towards diversity is directly affecting the supply chain of global supplier HEINEKEN Netherlands Supply (HNS). The organization has to cope with increasing demand and diversity for over 160 countries as their direct customers. The result of increased diversity is clearly seen in the number of produced Stock Keeping Units (SKU’s) at the Zoeterwoude brewery, which almost doubled from 2012 to 2014. The three main processes within the HNS supply chain are brewing, packaging and outbound logistics. The current supply chain planning is mainly focused on packaging, as this is the most expensive process. However, the growing volume and SKU diversity have resulted in additional challenges within outbound logistics operations. These challenges are perceived as complexity by HNS without identifying clear factors and drivers for this perception. In this research is therefore analysed how diversity influences the perceived complexity at the outbound logistics organization of HNS. The main research question is: What is the impact of an expanding product portfolio on perceived complexity in outbound logistics operations and how can the main drivers for this perception be managed in the future? Complexity in this research is defined as the uncertainty in processes as a result of increased diversity. Based on the commercial HEINEKEN strategy, the diversity in the portfolio for HNS is expected to increase in the future. The research goal is therefore not to challenge product diversity but to determine the key factors that drive uncertainty at HNS based on the diversity. Through extensive literature research and expert interviews at HNS, different types of perceived complexity in a supply chain have been defined. These types are structured in the framework for perceived complexity. Market and customer variety form the input of perceived complexity, factors that cannot be influenced by a production organization like HNS. A qualitative analysis based on the framework has revealed the main drivers for each type of perceived complexity. A quantitative case study analysis at HNS has strengthened the framework by analysing trends for the key factors that drive perceived complexity at the breweries in Den Bosch and Zoeterwoude. The results of both the qualitative and quantitative analysis are summarized below. Product complexity - Uncertainty related to the product portfolio. This is driven by the number of SKU’s that are produced by an organization and the volume related to these SKU’s. At HNS specifically, uncertainty is driven by the diversity in loading types requested by the market. The expanding portfolio has reduced insight in the logistical impact per SKU, increasing uncertainty of the expected volume flows in the warehouses at Zoeterwoude and Den Bosch. Technology complexity – Uncertainty related to available technology, both physical and information related. Physical technology is related to capacities of equipment and warehouse layout. As this information is clearly reported at HNS, no specific uncertainty is related to physical technology in this research. At HNS, uncertainty is mainly driven by missing information in the variety of IT systems, perceived as information technology complexity. A very important driver for perceived complexity is the absence of logistics parameters per SKU that determine the impact of a packaging plan on outbound logistics operations. Process complexity - Uncertainty in the logistics processes resulting from a mismatch between products and technology. HNS is faced with a simultaneous increase of SKU diversity and volume, leading to full warehouses and inefficient use of space. Reactive solutions are currently in place to cope with the high storage volume as no clear outlook of expected volumes is provided. Planning complexity - Uncertainty in logistics planning, driven by the absence of the most important logistics parameters per SKU. The current IT and planning structure at HNS limit the possibility to plan the expected stock and load volumes in the long term. From the case study analysis is concluded that information availability is the most important driver for perceived complexity at HNS. The Zoeterwoude and Den Bosch brewery both face an increase in storage volume of finished SKU’s, while the logistics parameters that determine storage demand are not measured. This limits the translation of the long-term packaging plan towards storage and load planning, thereby increasing uncertainty in expected volumes. It is also concluded that HNS can reduce the uncertainty driven by this missing information, as the logistics parameters are all covering internal processes that are controlled by HNS. The planning organization therefore has a large influence on the perceived complexity; measuring the logistics parameters correctly enables HNS to create more clarity in the long term by planning the expected demand for storage and loading. Managing perceived complexity at HNS is therefore focused on designing a long-term logistics planning model that is based on the packaging plan. A functional model is designed for the Zoeterwoude brewery that determines the impact of the main volume flows on outbound logistics processes. The identified flows are the packaging flow at the brewery and co-fill, re-pack and inter-brewery flows that come into the warehouse from other facilities. The main parameters that determine the logistical impact in the model are the following: - Loading type; determines the type of warehouse handlings and demand for storage - Cross-dock percentage; determines how much of the volume can be loaded directly - Storage time: determines how long a certain SKU has to be stored in the warehouse By coupling the 78-week packaging planning with the logistical parameters per SKU, the logistical impact can be calculated for the same time horizon. The model output is a clear overview of expected stock levels and load volumes per loading type in pallets. During model validation can be concluded that the model can predict the expected storage and load volumes with a bias of ±20%. Conclusions based on the model output can be made when using the packaging plan from May 2015 until December 2016 as input. Based on this plan is foreseen that mainly storage demand for Export will often exceed the storage capacity, thereby indicating the need for external storage. This is mainly caused by the large Conventional Truck volume that cannot be loaded directly with the cross-dock lanes. It is already known within the organization of HNS that stock volume for this specific loading type is a bottleneck but this has never been quantified and presented next to the demanded stock volume for other loading types. The logistics model now provides a long-term outlook of the expected volume on stock, which clearly shows the impact that Conventional Truck loading has on the total Export stock volume. Proactive solutions can now be found for the expected capacity shortage. Different packaging scenarios can be run to evaluate the impact on outbound logistics. Several successful experiments have already been completed with the model, illustrating the added value of the model for HNS. A clear implementation plan is also part of the research, ensuring the sustainability of the model for future use. Based on the research, model design and outputs several recommendations can be made to manage and reduce the perceived complexity at HEINEKEN Netherlands Supply. This research has pointed out that the perception of complexity in outbound logistics is mainly driven by a lack of information and planning. It is therefore highly recommended to place logistics planning next to packaging planning in the organization. The developed model provides a good starting point for strategic planning, proven by its application at Zoeterwoude. First experiments have already been completed to tailor the model to Den Bosch and it is recommended to continue this. Besides implementing the model, it is the author’s strong belief that the lack of interchange ability between the different IT systems limits the possibility to plan ahead, mainly in the outbound logistics processes. It is therefore recommended to set up a project that clearly defines what information different stakeholders need to successfully plan and manage their operations. Besides that, it is very important to secure the right information in a more centralized planning system. This will significantly increase alignment and visibility of information across the HNS supply chain. A final remark can be made to the complexity framework. From this research can be concluded that the framework successfully supports the analysis of perceived complexity in an organization, proven by its applicability to HNS. However, given the time constraints attached to this research, it is not assumed that the framework is complete. Further research should point out if the relationships sketched in the framework are also found at other companies, increasing the robustness of the complexity framework.","outbound logistics; logistics planning; product diversity; complexity","en","master thesis","","","","","","","","2020-08-03","Technology, Policy and Management","Transport, Infrastructure and Logistics","","Transport, Infrastructure and Logistics","",""
"uuid:d93866a3-f1e4-4636-a893-ad113867011d","http://resolver.tudelft.nl/uuid:d93866a3-f1e4-4636-a893-ad113867011d","Pipeline Rotation Analysis & Modeling During S-Lay Installation","Katsikogiannis, G.K.","Gerspach, F.G. (mentor)","2015","The safety of offshore pipelines during installation has drawn a great deal of attention due to the combined actions of high external pressure, axial tension and bending moment. Subsea pipelines have the tendency to rotate during installation. This rotation can have multiple causes which are interfering with each other. During S-lay installation, the pipe is exposed to plastic strains when it passes over the stinger, exceeding a certain curvature. That residual curvature causes the pipeline to rotate along its suspended length. Additional causes which contribute to pipe rotation are possible tensioner misalignments, pipeline curves or vessel offsets. Pipeline rotation is also dependent on other factors such as water depth, pipeline characteristics (bending stiffness, submerged weight, etc) and stinger configuration. Pipe rotation is not permissible if inline structures (valves, connections) are installed with the pipeline, it is therefore important to quantify the safety against roll for a given residual strain in the pipe due to plastic deformations over the stinger. The goal of this thesis is to accurately quantify pipeline rotation during installation of inline structures with S-lay method. A sequential model is built based on mechanical principles in order to solve the pipelay and rotation problem simultaneously and identify the effect of the plastic strains and residual curvature on the rotation phenomenon. The model includes also mitigation measures (buoyancy modules) and their effect in the reduction of total rotation as well as the effect of soil friction. The report consists of two main parts. The first part is the analytical mathematical modelling and the numerical solution of the pipe-laying problem, considering the pipeline as tensioned beam and solving the nonlinear bending equation along its suspended length using finite difference method. The second part consists of the rotation problem analysis and solution. Having found the pipeline configuration and its physical quantities along the length, the pipe rotation profile is found based on Hamilton's energy minimization principle using the Lagrangian equation, including soil friction and buoyancy module effect. Finally, a sequential model which simulates the installation of a pipeline including inline structures and buoyancy modules is built in order to investigate the roll profile evolution during real operations. A number of different cases studied based on actual projects were conducted to determine the pipeline configuration and its physical quantities (bending moment, strain, axial tension) along its suspended length. The validity of the pipe-laying model is verified by means of a comparison with results obtained from the commercial finite element software OFFPIPE. Rotation results are verified by results observed in actual projects.","offshore pipelines; pipeline rotation; S-lay Method; residual curvature; energy minimization","en","master thesis","","","","","","","","2020-08-01","Mechanical, Maritime and Materials Engineering","Maritime and Transport Technology","","Offshore and Dredging Engineering","",""
"uuid:0748b602-25e4-406a-80db-ad1b48f39340","http://resolver.tudelft.nl/uuid:0748b602-25e4-406a-80db-ad1b48f39340","New ways for creating value with light content","Verbeek, M.E.J.","Pont, S.C. (mentor); Govers, P.C.M. (mentor)","2015","Analysis and development of a business model for creating a new way-to-market for, and recurring revenue with light content. Provided by Philips Lighting with Dulux as a potential strategic partner.","business model; lighting; partnerships; service","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Strategic Product Design","",""
"uuid:a78ef928-b13d-4a92-bf21-266e562886f2","http://resolver.tudelft.nl/uuid:a78ef928-b13d-4a92-bf21-266e562886f2","Long Span Buoyancy Bridge with Submerged Cable Anchoring","Yip, T.","Bijlaard, F.S.K. (mentor); Abspoel, R. (mentor); Hoogenboom, P.C.J. (mentor); Visser, W.M. (mentor); Gozzi, A. (mentor); Houben, L.J.M. (mentor)","2015","The purpose of this MSc thesis is to find a feasible concept for a circa 4500 m long buoyancy bridge, which is located at the Sognefjord in Norway. The concept should be structurally and aesthetically competitive. In contrast to bridges on shore with fixed supports, a buoyancy bridge is supported on floating pontoons. As result, loads will cause the buoyancy bridge to displace, and displacements will in turn cause internal forces in the structure. For these reasons, the environmental loads on buoyancy bridges are usually minimized by placing the bridge girder as low as possible above the water level (small wind load) and by using small spans (small bending moment and shear force on the bridge girder). In this study, the limits within civil engineering will be tested by trying to find new possibilities for a buoyancy bridge, which consists of 20 spans of 200 m and a large central main span of 465 m. Furthermore, the bridge deck will elevate up to 80 m above water level. This span and elevation are required at the 1000 m deep Sognefjord to create a large fairway clearance. A buoyancy bridge with these properties is unprecedented. For the buoyancy bridge concept in this study, a whole new approach has been made. 22 long, slim cylindrical shaped pontoons are used, which provide upward buoyancy forces and restoring moments to limit the rotations of the structure. The slim shape of the pontoons will lead to smaller water loads. The radii and lengths of the pontoons vary respectively from 12 to 20 m and from 115 to 202 m. For common buoyancy bridges, the relative position of the pontoons is maintained by the superstructure. However in this case, the dimensions of the cylindrical pontoons are so large, that a superstructure with plausible dimensions will not be able to restrain the movements of the massive pontoons. Therefore, an anchoring system, consisting of 2 main cables with diameters of 1200 mm and 44 cables of 350 mm, has been designed to maintain the relative positions of the pontoons as much as possible. From the top view, the anchoring system looks like two mirrored horizontal suspension systems, which restrain the displacements in the direction parallel to the fjord. The displacement due to the maximum combined wind and water load is approximately 6 m for the circa 4500 m long bridge. Separate lattice bridge girders with a width and height of respectively 24 and 25 m are designed, which have hinged like supports, except in the plane transversal to the superstructure. In this plane, the rotation of the bridge girder around its longitudinal axis is coupled to the rotation of the pontoons, and therefore limited by the restoring moment of the pontoon. Furthermore, the torsional rigidity of the lattice girder varies along its length. This way, a light-weight and flexible bridge girder is possible, which is capable of following the rotations instead of trying to restrain them. For the piers, a form study has been done. The concept gives rise to a lot of new possibilities, but it also has limitations. The results of this study are only valid when the recommended erection method is used. Different erection methods will induce different forces into the structure. This can affect the capacity and the displacements of the structure. Therefore, the structural design and the erection design should be defined together. This study provides the first steps to the design of the buoyancy bridge. Much more investigation is needed before the proposed concept can be deemed reliable. The global main structure is considered in this study, but no detailed calculations are done. Designs of several important parts, i.e. the connections, the supports, the piers, etc. should be done in next studies. Also, second order effects, eccentricity, dynamic effects, fatigue, impact loads and more should be investigated. Although the design only have a concept value, this study shows that a structurally and aesthetically competitive buoyancy bridge for the Sognefjord is feasible and it is recommended to conduct further investigations on this promising buoyancy bridge concept.","buoyancy bridge; lattice bridge girder; pontoons; steel cables; anchoring system; steel; bridge; floating bridge; cables; Scia Engineer; modeling; Sognefjord; Coastal Highway E39; Norway; floating; fjord; feasibility","en","master thesis","","","","","","","","2020-08-14","Civil Engineering and Geosciences","Structural Engineering","","Design and Construction, Structural and Building Engineering / Steel Structures","","61.1000, 5.1667"
"uuid:5a7520f7-373d-44a5-9961-931ba9fdca15","http://resolver.tudelft.nl/uuid:5a7520f7-373d-44a5-9961-931ba9fdca15","A methodological approach for optimisation of product development processes by application of design automation","Mulder, A.","La Rocca, G. (mentor); Schut, E.J. (mentor)","2015","In the past decades a clear transition can be seen from fully human-based production techniques towards more automated systems. With the Product Development Process (PDP) being a potential source of competitive advantage the same trend of adopting more automation can be seen in the PDP. The application of automation can lead to large reductions in process lead time. The reduced lead time can be used to enhance product performance by assessing more design options in the same time, or to reduce the cost-of-delay and obtain a larger market share. It is clear that a reduction in lead time is worth an investment for companies and therefore automation can be adopted to improve the PDP performance. Both industry and academia acknowledge the lack of a quantitative method to assess the effect of the application of automation on the performance of a given process. Furthermore no methods are available to assess the effect of incremental automation. Another limitation is that most models investigating automation in the PDP only take into account a binary type of automation: either fully human or fully automated. This research aims at addressing these gaps of knowledge and the goal of this research is to develop a tool that provides more insight in the costs and benefits of automation in the PDP taking into account incremental automation and various levels of automation. To achieve the objectives a novel methodology is developed i) to model any PDP as a combination of a predefined set of specific activities and ii) to define different levels of automation for these activities. Subsequently, metrics are developed to measure the impact of different levels of automation on different activities, both in terms of activity lead time reduction and implementation cost. A simulator using Discrete Event Simulation (DES) is developed which utilises the proposed process model and metrics to analyse, among others, the lead time, automation investment cost and process cost for the overall process (for a given process architecture). Finally, the simulator is connected to an optimiser which tries to find the most convenient level of automation for each of the PDP activities, in order to generate a Pareto front to visualise the trade-off between the lead time reduction and required investment cost. The proposed methodology is extensively verified. Verification is performed for both the simulator and the optimiser. Based on this verification it can be concluded that with appropriate settings the optimiser manages to find Pareto optimal solutions for different levels of automation. Validation however remains limited to positive expert judgement due to scarce validation data. The proposed methodology and the analysis and optimization framework are demonstrated by application to an industrial case study. The case study concerns the conceptual design phase of an aircraft component, performed by a multinational aerospace enterprise. The case study successfully demonstrates the feasibility and applicability of this methodology and accompanying frameworks. Multiple Multi-Objective Optimisations are performed to trade off various objective functions. In this case study, specific activities in the process are identified to be more effective to automate. Results show that compared to the status quo, an investment in the lug sizing tasks of 7,1% of the investment cost of full process automation can lead to a potential lead time reduction of more than 40%. The proposed methodology proves to be successful in objectively quantifying the costs and benefits of automation in the PDP and subsequently selecting the optimal automation level.","optimisation; product development process; aircraft design; methodology","en","master thesis","","","","","","","","2019-08-14","Aerospace Engineering","Flight Performance and Propulsion","","","",""
"uuid:6f3c8dd6-ea77-44c3-be3b-116097b0dc71","http://resolver.tudelft.nl/uuid:6f3c8dd6-ea77-44c3-be3b-116097b0dc71","Design of a Persuasive, Smart Lighting Concept","Fennema, S.","Pont, S.C. (mentor); Song, Y. (mentor)","2015","In this thesis I investigated the use of lighting to nudge people in their decision for a seat in a waiting area. Subconscious effects of several lighting parameters were examined and the results used in an integral lighting concept for Schiphol. This concept enables three functionalities: monitoring of the waiting area, determining the preferred locations for new travelers and adjusting the lighting in order to nudge these travelers to these respective locations. The concept monitors the area using passive infrared sensors, a low-cost solution to determine the crowd densities. The lighting consists of two elements; ambient lighting with variable luminance at the seats and an array of focused lighting at the walkway crossing the waiting area. Travelers can be nudged to specific seats by increasing the luminance level at these respective places. Additionally, the light beam frequency at the walkway can be increased as well, attracting attention from the travelers. As the Schiphol piers can be crowded, the lighting effects are not only designed to illuminate the floor, but also the ceiling. In this way the efficiency of the system is enhanced and its influence on the travelers increased.","persuasive design; nudging; lighting; lighting design; waiting area","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","","",""
"uuid:30a258e8-c64b-4c65-b213-8075fdd3e09e","http://resolver.tudelft.nl/uuid:30a258e8-c64b-4c65-b213-8075fdd3e09e","Treasure Hunt in the museum: Design for a new way of exploring Dutch art and culture in the Mauritshuis","Shih, H.C.","Vermeeren, A.P.O.S. (mentor); Yoon, J. (mentor); Theunissen, R. (mentor)","2015","This project shows a new way to explore Dutch art and culture in the Mauritshuis museum and in Den Haag. Dutch museum sector has a strong connection to the Dutch tourism sector. Museum is an important attraction in the Netherlands that many travel websites recommend as a must-see place to the tourists who visit the Netherlands. The museum sector in the Netherlands will meet three challenges in the near future: the cut of the government budget, the increase of the international tourists and the rise of the digital generation. These challenges, which are also the opportunities, motivate the Mauritshuis (the MH) to look for the new potential visitors, the young adult traveller. The MH as an important attraction, which displays the abundant Dutch history and culture, can build a bridge to connect the tradition to current local culture. It can tell the stories of Dutch history and hot it developed to current local culture to the young adults travellers through the paintings, in such a way that the young adult travellers can explore Den Haag with the better understanding. According to the result of two target group researches in this project, and they have two different types of museum journey while they visit the museum. The value of the young adults’ travel influences their behaviors and focuses in the museum. Among four personas, popular attraction seekers and hipsters are selected as the most potential target group of the MH. Popular attraction seekers are the young adult travellers who want to experience famous attractions to make their trip worthy, and the hipsters are the young adult travellers who travel to find some inspirations for their self-growth. In aaition, popular attraction seekers are interested in the details of the paintings and unique museum interaction; however, the hipsters are interested in the inspiring stories behind the paintings. In order to engage young adult travellers in the museum and motivate them to explore the local culture, positive emotions, anticipation, interest, joy, fun and proud as well as the social interaction are involved in designing a new museum experiences. The museum should not only provide a pleasure environment to the visitors but also evoke the visitors’ interest and motivate them to explore the artworks. The final design is a Treasure Hunting App that provides an interesting game to the young adult travellers that motivates them to explore the details of the paintings. With the app, the young adult travellers can learn the knowledge about the art as well as about the local culture. When the young adult travellers leave the MH, the app will provides useful travel tips to encourage them to keep exploring the local culture in Den Haag. The final design has been evaluated in the user test session, and recommendations to improve the design has been provided at the end of the project.","design for interaction; design for emotion; museum app; art and culture","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Design for Interaction","",""
"uuid:d2f568de-940b-4bf0-844e-a2f776e08a0d","http://resolver.tudelft.nl/uuid:d2f568de-940b-4bf0-844e-a2f776e08a0d","Design of a Persuasive, Smart Lighting Concept","Fennema, S.","Pont, S.C. (mentor); Song, Y. (mentor)","2015","In this thesis I investigated the use of lighting to nudge people in their decision for a seat in a waiting area. Subconscious effects of several lighting parameters were examined and the results used in an integral lighting concept for Schiphol. This concept enables three functionalities: monitoring of the waiting area, determining the preferred locations for new travelers and adjusting the lighting in order to nudge these travelers to these respective locations. The concept monitors the area using passive infrared sensors, a low-cost solution to determine the crowd densities. The lighting consists of two elements; ambient lighting with variable luminance at the seats and an array of focused lighting at the walkway crossing the waiting area. Travelers can be nudged to specific seats by increasing the luminance level at these respective places. Additionally, the light beam frequency at the walkway can be increased as well, attracting attention from the travelers. As the Schiphol piers can be crowded, the lighting effects are not only designed to illuminate the floor, but also the ceiling. In this way the efficiency of the system is enhanced and its influence on the travelers increased.","persuasive design; nudging; lighting; lighting design; waiting area","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","","",""
"uuid:4d585c0f-8382-4860-898c-272ceea741eb","http://resolver.tudelft.nl/uuid:4d585c0f-8382-4860-898c-272ceea741eb","Dynamic Analysis on Failure Modes of Tub Mounted Cranes","Koole, M.","Metrikine, A.V. (mentor); Hoving, J.S. (mentor); Keijdener, C. (mentor)","2015","The trend in Offshore Engineering is towards exploring in deeper waters and more harsh environments. As a consequence, topsides become larger and heavier. In order to keep up with the demand for more lifting capacity, Heerema announced a New Semi-submersible Crane Vessel (NSCV). This vessel will contain two 10 000mt Tub Mounted Cranes (TMC), which will be constructed by Huisman. In order to ensure safety, some level of redundancy has been implemented in the crane’s hoisting systems. However, it was found that there was insufficient knowledge about the consequences of a wire failure in one of the hoisting systems. In this thesis three possible failure cases were investigated: boom hoist cable failure, main hoist cable failure and a drop of the load. In addition, this thesis also looks at possible ways to reduce the dynamic effects of a wire failure. Lagrange’s equations were used to derive the equations of motion of the crane and the main hoist lower block. Using these equations of motion a dynamic model was created in MATLAB, using an Ordinary Differential Equation (ODE)-solver to solve the equations of motion. For all three cases animations were created in order to provide a visual validation of the models. Additional validation was performed by a comparison with results obtained using simpler models with only one or two degree(s) of freedom. Parameter studies were performed on all three cases and different scenarios that could occur. For the boom hoist failure case the conclusion is drawn that none of the investigated parameters have a significant influence on the dynamic overshoot that occurs when one of the two wires fails. The overshoot is governed by the inertia of the load and boom. This is not the case for main hoist failure, where the geometry of the main hoist block had a large influence on the resulting force in the wire. Other parameters that influenced the results of the analysis were the initial length of the main hoist system and the stiffness of the rigging between the hook and the load. With the current design the risk exists that when wire failure happens, the other wires will not be able to cope with the dynamic overshoot and the system will fail. However, it is unlikely that wire failure will happen due to overload in the normal operating case, as a safety factor of three is applied. The third case, a drop of the load, proved to be the least severe case for the wires. Stress waves were witnessed in the results; however the effect of these were not significant. Even with the effects of stress waves taken into account the force in the wires remained below the initial value with the load still suspended from the crane. Further research on this case should focus on the bending of the boom. ?? ?Lastly, the influence of implementing a shock absorber in either the boom or the main hoist system was analyzed. For the boom hoist system the improvements were minimal, and the constant interaction of a damping system is undesired, which leads to the conclusion that it has no further potential. Implementing a shock absorber in the main hoist system resembles much of a Passive Heave Compensator (PHC) and could potentially improve the system. However, current PHC’s do not have the right parameters to have a significant influence. The main reason for this is that the influence of the compensator is divided over many falls, which suppresses the influence. Further research on this subject should focus on the behavior of the sheaves and falls in the system for two reasons: first, for determining the time it takes for a failing wire to un-reeve and lose its carrying capacity; second, in order to determine the effects of the reeving in a system with a shock absorber.","Huisman; Multi-Body; Offshore Cranes","en","master thesis","","","","","","","","2020-08-14","Mechanical, Maritime and Materials Engineering","Structural Engineering","","Offshore and Dredging Engineering","",""
"uuid:2b3a9e2d-4dbd-45e8-a07c-b081d1602241","http://resolver.tudelft.nl/uuid:2b3a9e2d-4dbd-45e8-a07c-b081d1602241","Project Specific Vessel Motion Based Abandonment Criteria","Van Aubel, J.F.","Geers, A.M. (mentor); Demeersseman, P. (mentor)","2015","When harsh weather conditions are expected during an offshore pipeline operation, the decision to start the abandonment procedure has to be taken based on pipeline integrity limits. The pipeline integrity which is analysed by a maximum design sea state does not correspond to the situation offshore, because sea states always occur in a different combination of parameters and therefore difficult to predict. Consequently abandonment decisions based on sea states to prevent the pipeline from buckling are difficult to take. Presently the Allseas’ pipelay vessels are running on-board software (SMD) what combines sea state predictions from multiple sources including metocean data, Wavex information and data from Motion Reference Units (MRU) which measure the actual vessel motions real-time. The SMD software can predict the significant wave height, zero crossing periods and approach directions. Furthermore the exact vessel motions can be predicted in the coming hours with fair accuracy which suggests an opportunity to develop vessel motion based abandonment criteria. With the use of OrcaFlex by Orcina, pipeline installation is modelled for three case situations which differ in water depth and pipe properties. By performing time domain simulations using the Finite Element Method these cases are analysed to find the dominant vessel motions concerning pipeline integrity in a way such that some degrees of freedom can be discarded. Two different types of simulations are distinguished: The first type uses a large sum of short simulations with the model excited by theoretical predefined harmonic vessel motions. These simulations without wave effects are used to determine the direct relationship between vessel motions and pipeline integrity. The second method uses long time simulations with the model excited by stochastic design sea states. These simulations are used to determine which vessel motions and structural responses are expected. For both methods amplitude peaks of the time histories between the quantities are compared to develop and evaluate vessel motion based criteria for the different case situations. For specific deep water operations where the pipeline is leaving the stinger almost vertically (departure angle of about 80°) and the tensioners are modelled on the brakes, the maximum bending moment which occurs in touchdown area is found to be well correlated with bottom tension and vertical velocity of the stinger tip. For deep water operations with an intermediate departure angle of about 45° and compensating tensioners, the maximum bending moment which occurs near the stinger tip is found to be correlated with the top tension and the vertical acceleration of the stinger tip, since the pipeline weight acts in the same direction. For increasing amplitudes and frequencies of the vertical stinger tip motions the correlation with bending moment is affected due to geometric nonlinearities. For deep water operations this happens for unlikely excitations. However, in particular shallow water operations which result into small departure angles it is found that the natural frequencies which occur near the vessel motion peak frequencies result into large dynamic effects and increased geometric nonlinear behaviour. These geometric nonlinearities affect the correlation between stinger tip motions and the pipeline structural response in such way that the found vessel motion based criteria are not applicable. Concluded is that for specific deep water projects with large departure angles, vessel motion based criteria based on vertical stinger tip motions show promising results. It is recommended to further study the applicability of the proposed vessel motion based criteria by analysing it with data generated by SMD during an actual pipelay operation.","marine pipelines; vessel motions; pipeline integrity; response forecasting; abandonment; operational limit; s-lay","en","master thesis","","","","","","","","2020-08-01","Mechanical, Maritime and Materials Engineering","Maritime and Transport Technology","","Offshore and Dredging Engineering","",""
"uuid:15af3a42-051f-4cda-b3c2-3288a84eee8b","http://resolver.tudelft.nl/uuid:15af3a42-051f-4cda-b3c2-3288a84eee8b","H5N8: Designing aesthetically pleasing products from contaminated culled chicken material","Van Spronsen, E.J.A.","Hekkert, P.P.M. (mentor)","2015","Designing aesthetically pleasing products from contaminated culled chicken material.","H5N8; avian influenza; chicken material; alternative materials; MEMM; aesthetic pleasure; experience of alternative materials","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Design for Interaction","",""
"uuid:7c8e2572-3c68-464f-9a21-4b0bdf78ce94","http://resolver.tudelft.nl/uuid:7c8e2572-3c68-464f-9a21-4b0bdf78ce94","Screening of malnutrition in children under 5 years and provision of information in the rural areas of the Great Lakes region","Van Geel, B.","Van Heur, R.J.H.G. (mentor); Albayrak, A. (mentor); Beentjes, T. (mentor)","2015","Globally about 1 billion people (mainly living in developing countries) cannot get the health services that they need. This is a result of the lack of access, lack of trained health personnel, inadequate resources and facilities, and products and services are not affordable to the majority of the people. The company Healthy Entrepreneurs (HE) tries to solve this problem by providing people, living in the rural areas of low- and middle income countries (Rwanda, Democratic Republic of Congo (DRC), Burundi, Uganda and Haiti), with access to a range of reliable and affordable health impact products (e.g. essential medicines) and services of good quality. They focus their products on treatment and prevention of diseases, but forget about the diagnosis in order to ensure the provision of the adequate treatment. The malnutrition screening application helps in establishing a diagnosis about the health status of children under 5 years. In developing countries malnutrition is still one of the major problems and underlying cause of the majority of illnesses that cause death in young children. One of the problems is that malnutrition is not recognized by the parents and they do not have the knowledge and the means to improve their child’s situation. By creating awareness about the problem and providing them with a screening service that can establish a diagnosis and provide them with the information and products that they need, the child’s health can be improved. The screening service uses the assessment of different signs and symptoms and several measurements. The result of these assessments is a distinguishing in; the children who are healthy, children who are dangerously malnourished (and immediately need a referral to an health centre) and children who are mildly malnourished. The last group of children can be treated by improving the nutrition of the child or by the use of HE products. By identifying the cause of the malnutrition, a customized set of informational videos, products, brochures and additional information sessions can be selected. By the mean of this set, the parents are able to treat the condition of their child and to prevent the child from getting malnourished again in the future.","design; developing countries; diagnosis; application; children","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Design for Interaction","",""
"uuid:36824eea-0902-4b23-93d3-8cc17ab21302","http://resolver.tudelft.nl/uuid:36824eea-0902-4b23-93d3-8cc17ab21302","Gas Turbine Diagnostics Based on Gas Path Analysis","Sajeev, A.M.","Visser, W.P.J. (mentor); Bennett, I. (mentor)","2015","Better availability ensures economic operation of the gas turbine, saving in the order of millions. One step towards such an approach is to develop real-time monitoring methods. Real-time monitoring allows users to monitor the performance of the gas turbine and ensure proper functioning of the engine. Moreover changes in gas path components can be used to identify the deteriorated components thereby decreasing the downtime of the engine. This project was carried out in collaboration with Shell Global Solutions. The aim of the project is to develop a performance monitoring method and propose a fault isolation mechanism. The study is carried out on a three shaft gas turbine, GE LMS100. This is the latest developed gas turbine with intercooler and is used extensively by the oil & gas industry. The challenge in developing a performance monitoring method for such an engine lies with the configuration of the gas turbine itself. Gas turbine Simulation Program (GSP) is used to model the gas turbine. Different diagnostic techniques used for performance monitoring of gas turbine is studied and a suitable method is proposed by the end of the project. Component parameters of a healthy engine are simulated using GSP and deviation of operating points from their respective baseline indicates deterioration in performance of the gas turbine. An attempt is made to quantify the deviation in component measured parameters owing to respective deterioration cases. The fault isolation tool created would help in reducing the dependency on expert analysis and reduce downtime of the machine. The proposed method proves to be able to detect, quantify and isolate fault in the gas turbine based on a few indicating parameters. The conclusions and recommendations made from this project can be used to develop a complete engine health monitoring tool.","Diagnostics; Availability; Fault Isolation; Performance Monitoring; Engine Health Monitoring; Condition Based Maintenance","en","master thesis","","","","","","","","2016-08-13","Aerospace Engineering","Flight Performance and Propulsion","","Propulsion and power","",""
"uuid:5bf23d68-83b7-4552-8e7e-a0d5b08885c9","http://resolver.tudelft.nl/uuid:5bf23d68-83b7-4552-8e7e-a0d5b08885c9","Brand Driven Innovation for Computer Futures","Veerman, L.","Calabretta, G. (mentor); Roscam Abbing, E. (mentor)","2015","Creating a user-centred brand and embedding this in the service.","brand driven innovation","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product Innovation Management","","Master of Science Strategic Product Design","",""
"uuid:155cd8cf-b829-49b7-a086-315fec1fd63a","http://resolver.tudelft.nl/uuid:155cd8cf-b829-49b7-a086-315fec1fd63a","Improving the project management of large construction projects in developing countries: Adjusting state of the art project management practices to the Vietnamese context","Zhivkov, P.","Bakker, H.L.M. (mentor); Bosch-Rekveldt, M.G.C. (mentor); De Jong, W.M. (mentor)","2015","","","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Construction Management and Engineering","",""
"uuid:e85b6238-cbe3-42e4-a1b2-8837e7650a90","http://resolver.tudelft.nl/uuid:e85b6238-cbe3-42e4-a1b2-8837e7650a90","High-resolution magnetic susceptibility data interpretation in a well through the Miocene of the Vienna Basin","Nobile, J.","Luthi, S.M. (mentor)","2015","Magnetic susceptibility (MS) represents a very important rock property to be measured. This can be done not only in the laboratory using rocks samples, but also on outcrops or with downhole tools in wells. This property is basically controlled by the type and concentration of magnetic minerals contained in the rock. It can be dominated by minerals that are paramagnetic (clays), diamagnetic (calcite, quartz), or ferromagnetic (magnetite, greigite). It seems to be highly affected by several environmental factors and complex processes, which control its response in the sediments. The present study constitutes a MSc. Thesis carried out at the Delft University of Technology within the Petroleum Engineering and Geosciences track. The apparent lack of correlation between the basic petrophysical properties and magnetic susceptibility acquired in Well Spannberg 21 was the igniter for considering this study. It was planned in order to determine the factor(s) responsible for the variations in magnetic susceptibilities measured in the borehole Spannberg-21 in the Vienna Basin (Austria). The development of this thesis is based on the use of a full data set of LWD and WL logs and drill cuttings available for the whole well interval. The data was acquired back in 2007 by the National Operating Company OMV, together with Schlumberger and Delft University of Technology. Previous researchers have studied the magnetic minerals in the area and some conclusions have been drawn regarding the chronostratigraphy, biostratigraphy, and magnetostratigraphy in this well. However, it was until now when the MS problem was tackled. This study was considered an open-ended research project from the beginning, since this was the first time that a project with such data and such a research objective was being conducted. Therefore, the result of each task was the basis for the next step. The Vienna Basin is very suitable for high-resolution studies like these because it has been widely described through several decennia. Moreover, the rapid sedimentation which occurred in this basin gave rise to the formation of thick sequences. Furthermore, downhole measurements are helpful because they provide a continuous record of the rock properties in the subsurface. The aim of this MSc. thesis is to perform a detailed analysis employing all the data available, combined with new measurements, in order to find an explanation on what controls the rocks' MS property, what are the reasons for its behavior, and what possible applications can be given after its interpretation.","magnetic susceptibility","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Petroleum Engineering","","48.43146, 16.76630"
"uuid:a3f7808a-554e-4522-972d-a076012426ee","http://resolver.tudelft.nl/uuid:a3f7808a-554e-4522-972d-a076012426ee","Gas path analysis for the MTT micro turbine","Bauwens, P.L.","Visser, W.P.J. (mentor); Dountchev, I.D. (mentor)","2015","Gas turbine diagnostics is as old as the gas turbine itself. Over the years, performance based diagnostics allowed for a shift from time-based maintenance to more economical condition based maintenance playing a fundamental role in enhancing the availability and reliability of gas turbines. By monitoring the condition of the engine over time, maintenance actions can be taken based on information collected from the field. MTT (Micro Turbine Technology) is currently developing a low cost 3kWe micro-turbine CHP (Combined Heat and Power)-system by using off-the-shelf technologies. Once the system will be launched on the market an organized, cost-effective maintenance procedure will be required. The objective of this M. Sc. thesis project was to develop and demonstrate a Gas Path Analysis diagnostic concept for the micro-turbine. Gas Path Analysis (GPA) is a method to assess the condition of the gas turbine by using performance measurements from the gas path. The feasibility of the diagnostic concept was demonstrated by some case studies using data from the first generation field test units. After reviewing a number of gas turbine diagnostic techniques, a non-linear model based gas path analysis approach was chosen. For the development of the diagnostic concept, a non-linear model of a healthy reference engine was used to simulate the off-design behaviour of the engine and derive healthy performance parameter baselines. These baselines are used to compare the performance of field engines against. A component based modelling environment called GSP or the Gas turbine Simulation Program was used to simulate the effect of ambient conditions and deterioration on performance. The diagnostic concept relies on the principle that deterioration causes corrected measurement parameters to shift from the healthy reference baselines. Measurement performance parameters are first corrected to standard ISA conditions before being compared against the healthy baselines. By modelling specific types of deterioration in GSP, signature parameter shifts could be recorded for each of the deterioration modes. These signature parameter shifts are used to compare shifts in performance parameters against and determine the closest pattern-match which can be used to identify the most probable cause of deterioration. The proposed concept is capable of performing engine level diagnostics and partially component level diagnostics. Multiple fault diagnostics and quantifying the level of deterioration are more difficult due to the limited number of sensors and the relatively large impact of second-order effects such as heat-loss, auxiliary power take-off, mechanical losses, etc. The performance parameter baselines together with the derived rulesets can easily be implemented in a maintenance tool making the concept flexible and easy to use.","micro gas turbine; gas turbine simulation; performance modelling; trending; diagnostics","en","master thesis","","","","","","","","","Aerospace Engineering","Flight performance and propulsion","","Masters","",""
"uuid:908bdc1f-905d-48b1-a3d2-1afa330fd001","http://resolver.tudelft.nl/uuid:908bdc1f-905d-48b1-a3d2-1afa330fd001","A strategy for district shopping centers in transition","Runderkamp, J.","Christiaans, H. (mentor); Van Amerongen, R. (mentor)","2015","Retail is in transition. District shopping centers have a hard time. Rapid developments in technology and the increasing influence of a new generation, are fundamentally changing retail in all it’s appearances. Shopping Center Schalkwijk is one of these centers that is facing a problematic future. A lot of retail areas in the Netherlands are in a comparable situation. They should evolve from old retail to new retail. Regarding the current situation of several unpopular retail areas in the Netherlands, it can be concluded that these areas are not able to adjust to the changing retail environment. These retail areas can be seen as big, unwieldy and costly organizations that do not fit the modern society anymore. It’s not likely that new retailers or other new entrepreneurs would like to settle in these demotivating areas. Without a new impulse these centers will bleed to death. They need an energy boost. A new challenge. Supported and facilitated by the current organization, but conducted by the new generation. A strategy is designed that functions as a guidance for shopping centers in transition. By implementing this strategy, new retail concepts will arise, ideas will be fused, functions will be mixed and outdated retail concepts will disappear. A district shopping center should be a breeding ground for creativity and innovation. The new generation should have the opportunity to try out and experiment with new concepts.","retail; shopping centers; strategy; transition","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product Innovation Management","","Strategic Product Design","",""
"uuid:f3388a13-276d-4942-9e1f-ab1f9a5cfb7f","http://resolver.tudelft.nl/uuid:f3388a13-276d-4942-9e1f-ab1f9a5cfb7f","All passengers satisfied and on time: Supported by an integrated and up to date Information and Wayfinding system","Aerts, S.N.","Santema, S.C. (mentor)","2015","Schiphol has the ambition to become Europe’s preferred airport within five years. Due to the increasing competitive climate, it becomes progressively important for airports to enhance passenger satisfaction. Schiphol wants to do this by differentiating from its competitors through excellent service and customer satisfaction. Information and wayfinding on the airport is considered of great importance to these aspects. The I&W system at Schiphol has always been rated as ‘high quality’ and several awards have been obtained with an important aspect of the current system; the familiar yellow signs. Schiphol even received a price for the best airport in Europe in 2012 (Skytrex, 2012). Due to the awards and high ranking compared to other European airports, I&W at Schiphol was considered as ‘good’ and did not get the priority it might have needed over the past years. This caused the I&W system to grow without a clear direction and Schiphol has lost its leading position to important competitors like London Heathrow. Factors like new technologies and changing passengers needs concerning I&W ask for an evaluation of the current I&W system at Schiphol to indicate the performance and determine priorities for improvement. This thesis gives insight in which aspects of the I&W system at Schiphol need to be improved to increase passenger satisfaction and become Europe’s preferred airport again.","Schiphol; information system; wayfinding system","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","","","52.30907, 4.763385"
"uuid:2c56b1ec-089f-4657-b045-67c1b3d59b20","http://resolver.tudelft.nl/uuid:2c56b1ec-089f-4657-b045-67c1b3d59b20","A mobile solution for inexperienced passengers of KLM to manage their travel process","Engelshove, L.M.","Santema, S.C. (mentor); Rozendaal, M.C. (mentor); Schnellen, F. (mentor)","2015","Despite a large contribution of KLM offering many information channels and services at Amsterdan Airport Schiphol (AAS), travelling often remains a frustrating and unpleasant experience for passengers. Information is targeted to a mass of people, and is not directed to individual passengers. The sheer amount of available information within these information channels has become an information overload, and thus renders many of these useful information channels less efficient and less effective. This project has focused on the inexperienced Dutch passenger of KLM, departing from AAS, in which the phases at home (from the moment that a booking is paid), transportation, and the process in the departure halls of the airport (until passengers entering security filter) have been considered. The goal of this project has been defined as creating a Product-Service System (PSS) of an integrated platform that supports KLM passengers in finding their targeted destination through AAS on individually and intuitively way. A final concept was made, which has focused mainly on designing parts of the core app. However, the concept is a starting point of an integral system where all information channels of KLM will be connected and provide information in a consistent way. The concept considers three main functions groups. The function groups are the building blocks for implementing several information elements in the core app. The function groups are as following: 1. Checklist: reminds passengers of what to bring regarding the travel process 2. 2A Mandatory steps: informs a passenger on which procedure steps to go through at the airport 2B Airport map: guides the passenger through the airport with navigational directions from one step to the other 3. Transportation: informs the passenger on transportation to the airport and when to leave home Furthermore, an implementation plan with an additional roadmap describes how different information elements of the concept should be implemented. Some of the information elements are completely new, and require new Application Program Interfaces (API’s).","KLM; information; wayfinding; personalization","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product Innovation Management","","Master of Science Strategic Product Design","",""
"uuid:a720e6d7-354a-4441-8df7-58d9fb1a40a0","http://resolver.tudelft.nl/uuid:a720e6d7-354a-4441-8df7-58d9fb1a40a0","Enhancing the in-store experience for female customers of a lifestyle brand","Darkaoui, S.","Christiaans, H.H.C.M. (mentor); De Wit, L.M.M. (mentor)","2015","Tommy Hilfiger is one of the world’s leading lifestyle brands. Its style is recognized as classic American cool with a preppy twist. It delivers premium styling, quality and value to its worldwide customers. The brand has a wide variety of collections as well as a range of products. One of those collections is women’s sportswear (WSW): Womenswear. Although Tommy Hilfiger is a lifestyle family brand, women do not really have a strong connection with the brand. A lack of connection that normally draws the female customer in-store and the fact that in most cases women do not know that Womenswear is sold as there is a stronger focus on the Men’s division (which is often placed in front of the store), result in a lower conversion rate for Womenswear. This thesis will focus on making Tommy Hilfiger more appealing to the female customer by introducing a holistic vision that covers the whole customer journey.","retail; fashion; interior; in-store experience","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","","",""
"uuid:85ca45bd-ae50-4e8c-8819-687b4bd04fdf","http://resolver.tudelft.nl/uuid:85ca45bd-ae50-4e8c-8819-687b4bd04fdf","Feasibility of Offshore Wind Substructures in Arctic Environments","Maier, S.","Bijlaard, F.S.K. (mentor)","2015","Environmental research and in-situ measurements have shown that most regions of the Baltic Sea harnesses a large wind energy potential. The Finnish government has outlined a policy to generate a rapid increase in the use and production of renewable wind energy. In order to achieve these goals, the need arises for the construction of full scale offshore wind farms with a total capacity of around 2,500 MW. However, large parts of the northern basins of the Baltic Sea are covered with ice during the winter season, which is something that to offshore wind farms operational to this date have not yet been subjected to. The scope of this thesis is to provide an insight into the overall feasibility and the preliminary design process of an offshore wind substructure suitable for the conditions as found along to the Northeastern coastline of the Bay of Bothnia. An extensive literature study has been performed, which focusses on the recent development of offshore wind farms, offshore wind substructure concepts, the environment of the Bay of Bothnia and on aspects related to arctic engineering. Using the literature study as a reference, the case study was outlined in further detail, by establishing the design basis regarding the NREL 5MW reference turbine and tower. Governing environmental parameters such as the on-site wind speeds, wave heights and ice conditions are determined, along with the on-site geotechnical parameters such as water depth and soil composition. Based on the case study, the various offshore wind substructure concepts are compared to determine to most suitable concept for application in the Bay of Bothnia. Based on this assessment, the monopile foundation was considered the most suitable for application within the boundaries of the case study. In order to examine the effects of ice loads on the overall feasibility of offshore wind monopile foundations in arctic environments, the increase in structural dimensions and design weight of the monopile foundation due to ice loading is analyzed. For this structural analysis, use will be made of static load cases and a static analysis methodology. Using the case study and determined design loads, three monopile design iterations are presented, ranging from the exclusion of ice loading, including global level ice loading and a design including global ice ridge loading. Each design has been optimized regarding the structural dimensions required to withstand the applicable load cases, by using allowable cross section stresses and deflections as design criteria.","offshore wind foundation; ice loading; Bay of Bothnia; substructure","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Steel, Hybrid and Composit Structures","","64.813850, 24.021335"
"uuid:44f9053d-bccb-463f-850e-8e4c56e543eb","http://resolver.tudelft.nl/uuid:44f9053d-bccb-463f-850e-8e4c56e543eb","Characterisation of Saturated Loose Sand Samples prepared by Fluidization","Paz Noriega, S.","De Jager, R.R. (mentor); Molenkamp, F. (mentor); Vardon, P.J. (mentor); Askarinejad, A. (mentor); De Gijt, J.G. (mentor); Hicks, M.A. (mentor)","2015","The following thesis has three major purposes: (1) to explore the static liquefaction phenomenon in saturated sand as a relevant geotechnical hazard, (2) to show the conventional testing procedures for index characterisation and strength testing of saturated fine sands at low stress levels, and (3) to look into the fluidization mechanism and the ongoing research into its applications in saturated sand testing, done at Delft University of Technology. The exploring on static liquefaction was performed by a literature study, which allowed to relate the macroscopic scale of this hazard in underwater slopes with the common practices performed in laboratory conditions. The literature found shows that a change in the framework of understanding saturated sand behaviour, accounting for anisotropy, may occur within the next years. In addition, the literature supports that improvements on the liquefaction prediction can only be done via: improvements of: the theoretical framework in which the sand behaviour is studied, the constitutive and numerical models used for prediction of the liquefaction mechanism and the testing and the physical modelling methods allowing for both sand characterisation and the determination of the constitutive model parameters. Some tests performed to characterise a fine sand were selected to see how the method can affect the obtained results and how the conditions of the sample preparation and control can affect the liquefaction potential on a saturated sand sample. The results support that idea that the amount of fines on the sand, indicated generally by a sieving test, can affect the results of the index minimum and maximum void ratio, differentiating the properties of a sand with fines and a sand without fines. In addition, several variables such as the degree of saturation, confining stress levels and membrane penetration can contribute to the development of pore pressures and the development of liquefaction. The literature study reveals that fluidization has been used on research on granular soils sedimentation, documented in the work by Allen (1984), and is not as new in earth sciences as it was thought to be. Based on the undrained triaxial testing procedure suggested by Jager and Molenkamp (2015a), where fluidization will be used for sample preparation, some sand batches were prepared, in which layers were removed to characterise the final product. While the results on void ratio distribution along the depth of the column are not sufficient to draw further conclusions, it was found that the discharge rate can affect the porosity distribution during and after fluidization. The study not only showcases two techniques that can allow a quantitative assessment of fluidization mechanism, but also that inclusion of this method in loose sample preparation could bring improvements into granular soils characterisation.","liquefaction; fine sands; sample preparation; characterisation; laboratory testing; fluidization","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Geo-Engineering","",""
"uuid:85830d96-5eb0-415a-bc4c-635a1a19063d","http://resolver.tudelft.nl/uuid:85830d96-5eb0-415a-bc4c-635a1a19063d","Solver-agnostic multi-fidelity coupling framework for the partitioned simulation of fluidstructure interactions","Baptista, Carlos (TU Delft Aerospace Engineering)","van Zuijlen, Alexander (mentor); Scholcz, Thomas (mentor); Delft University of Technology (degree granting institution)","2015","Fluid-structure interactions (FSI) are multi-physical phenomena where the dynamics of a fluid flow and the dynamics of a moving/deforming structure influence one another simultaneously. The accurate modelling, simulation and analysis of FSI is crucial for many engineering applications. However, high-fidelity FSI simulations are currently too computationally expensive for industrial purposes. The industry is in need of more efficient software to perform accurate FSI analyses at reduced computational cost. The complexity of developing such software is acknowledged and accounted for by preserving software modularity. Using black-box mono-physics solvers in a partitioned framework is one step towards ensuring software modularity. Partitioned procedures require a coupling algorithm to iteratively reduce errors related to the partitioning of the physical domains. Implementing coupling algorithms directly into each solver results in duplicitous work. Instead all algorithms related to coupling procedures should be centralised into a single unit. To this end a solver-agnostic framework is developed for the partitioned simulation of strongly-coupled fluid-structure interactions. This framework is named CASMIR (Coupling Algorithms for Strongly-Coupled Multi-physics Interaction Research).","","en","master thesis","","","","","","","","","","","","Aerospace Engineering | Aerodynamics and Wind Energy","Future Fast Aeroelastic Simulation Technologies",""
"uuid:96cd2cc8-5521-4ddc-85e3-e7737823494a","http://resolver.tudelft.nl/uuid:96cd2cc8-5521-4ddc-85e3-e7737823494a","Scheduling elected ambulance transportation","Bruijns, L.A.M.","Van Essen, T. (mentor)","2015","In this research, we constructed a model which makes an optimal schedule for the transport of patients in ambulances. These transportation are called requests. This scheduling problem is an example of Dial-a-Ride Problem (DARP). We define a Mixed Integer Linear Program (MILP), which consists of an objective function and constraints. These constraints are needed to provide a schedule in which working times and patients’ inconvenience is taken into account. Also the constraints which provide a appropriate and feasible route are described. To solve theMILP,we use exact solving methods. Another option is to use heuristics, but during this research we decided to only apply exact solving methods. The method used, is the Branch-and-Cut algorithm used in CPLEX.","ambulance","en","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","Optimisation","",""
"uuid:da4c2e09-fbbe-4690-9e52-86554550d3de","http://resolver.tudelft.nl/uuid:da4c2e09-fbbe-4690-9e52-86554550d3de","Design of a cooling system for the hybrid engine","Fohmann, K.G.","Rao, A.G. (mentor)","2015","In recent times the fuel prices have increased significantly. This implies major reductions in profit margins for airlines. Additionally the increasingly stringent emission standards for aircraft generate the need for better fuel economy. This master thesis aims at providing a contribution to lower the emissions made by future turbofan engines which are propelled by liquefied natural gas. This is done by providing a thermal design of a heat exchanger to exploit the deep temperatures of liquefied natural gas to lower the bleed air temperature required for cooling the high pressure turbine. A sizing tool is generated to facilitate the generation of a preliminary design. To achieve a high thermal efficiency of the engine, a high turbine inlet temperature is favored. This temperature is limited by the melting temperature of the turbine blade material. To overcome this issue, cooling is applied. In current gas turbine engines, large amounts of bleed air are therefore used to cool the high pressure turbine. Due to the elevated pressures present in the high pressure turbine, the high pressure compressor offers the only source for cooling air. Since this cooling air cannot be used for combustion, it does hardly contribute to the generation of thrust. It is therefore of interest to keep the requirements for cooling air as low as possible. By cooling down the bleed air from the compressor, the heat exchanger hence will reduce the mass flow required to cool down the high pressure turbine to its maximum service temperature. This will increase the mass flow going through the combustion chamber and thus the efficiency of the overall engine. The work performed is done for the AHEAD hybrid engine. To structure the thesis it was split in three modules. First the cooling requirements on the basis of the AHEAD’s baseline engine, the General Electric GE90 is determined. This part of the thesis uses the work of a previous master thesis. Next a heat exchanger is designed for steady state take-off that will cool the bleed air down to a required temperature. Finally the savings in the cooling mass flow are monitored and the effect on thrust and specific fuel consumption is measured. The Gas turbine simulation program (GSP) is used for this. The preliminary design of the heat exchanger is the main part of the work. Liquefied natural gas flows at cryogenic temperature into the heat exchanger and is vaporized during the process of cooling down the bleed air. It is then injected as a gas into the combustion chamber. Because of the stringent pressure drop requirement, a shell-and-tube geometry is chosen for the heat exchanger. The different processes involved and the various geometries possible pose a challenge on the problem. It turns out that the evaporation is a critical part of the design, while the pressure drop for the configurations researched is of less importance. Based on the thermal calculations the designed heat exchanger is estimated to lower the specific fuel consumption of the hybrid engine by 0.68 % at take-off and increases the thrust by 8.38 %. To ensure compactness the shell-and-tube heat exchanger is folded three times.","AHEAD; hybrid engine; LNG; heat exchanger; cryogenic","en","master thesis","","","","","","","","","Aerospace Engineering","Flight Performance and Propulsion","","","",""
"uuid:900d7a90-4106-431a-befd-968438709118","http://resolver.tudelft.nl/uuid:900d7a90-4106-431a-befd-968438709118","Light Coal: Development of a torrefaction reactor and business system for Himalayan India","Helmer, R.M.","Roekaerts, D.J.E.M. (mentor); De Jong, W. (mentor); Kroesen, J.O. (mentor); Joshi, Y.V. (mentor)","2015","Novel methods of the implementation of technology can be instrumental in aiding the growth of developing countries. Here, torrefaction has been investigated for its application to rural, Himalayan India, for the production of solid fuel briquettes from pine needles for sale to the food industry. Here, both technical and social aspects are combined to simultaneously develop the entire business system. In the technical research, the design, modelling, construction, and testing of a torrefaction reactor have been carried out. After the design of a locally adapted reactor, a model was developed for the heat transfer, solid decomposition, and gas production in the reactor. Moderate results were achieved, with reasonable mass yields and estimates of the fuel value of the produced gas. In the social research, the design of the business system with emphasis on cultural considerations has been carried out, including the business model, value propositions, stakeholder analysis, logistics system, business management structure, operations and maintenance systems, financial analysis, and environmental analysis. Various measures have been proposed to incorporate a professional work culture with local values into the management structure. In addition, the financial and environmental analyses show strong advantages over local competitors in cooking fuels. Although further research is needed to develop the technology before realization of the project, this novel method of simultaneous development of the technology and business system with contextual consideration has produced a promising foundation of a business with much potential. This project has been carried out in tandem between Vidyut Mohan and Ryan Helmer, and thus methods and findings are divided between the reports of each of the authors.","sustainable development; biomass energy; torrefaction; social entrepreneurship; business culture; India","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Process and Energy","","","",""
"uuid:3bf51189-2b40-47e9-aa78-f395e063c07b","http://resolver.tudelft.nl/uuid:3bf51189-2b40-47e9-aa78-f395e063c07b","Light Coal: Development of a Torrefaction Reactor and Business System for Himalayan India (Reactor Testing, Pine Needle Fuel Evaluation, End User Value Propositions and Logistics System Design)","Mohan, V.","De Jong, W. (mentor); Kroesen, J.O. (mentor)","2015","A three month long field research brought to light that the lack of livelihood opportunities in the Kumaon region of Uttarakhand is leading to outmigration of people from the state. There is a major need to develop sustained income and employment opportunities for the people in the region. The monoculture of pine forests shed huge amounts pine needles on the forest floor during the summer months. These pine needles, however, are the reasons for frequent forest fires in the region, strongly impacting its biodiversity. This makes a perfect case for the establishment of a business employing local people to produce energy out of pine needles. In light of this need, the prospect of biomass Torrefaction to produce a commodity fuel to meet the thermal energy needs for a variety of end users was investigated. This project was done in collaboration with Avani Kumaon, an organization working to create sustainable livelihood opportunities for the people living in the region. Pine needles procured from the Kumaon region were Torrified in a direct convectively heated packed bed reactor, a muffle furnace and a TGA (Thermo-gravimetric Analyser) setup at TU Delft to quantify Mass Yields at Torrefaction temperatures of 230oC, 250oC, 270oC and 290oC and residence times of 15 minutes, 30 minutes and 45 minutes. The Torrified product obtained was checked for its calorific value in a bomb calorimeter and the Energy Yields were established for the different process conditions. A Differential Thermo-gravimetric Analysis (DTGA) for the raw and Torrified pine needles was also performed to understand the trends in Mass Yields and this was compared to the trends in Mass Yields obtained for verge grass through a similar set of experiments. It was found that pine needles by themselves are a better fuel than verge grass, undergoing lesser amelioration of fuel properties (in terms of delayed and lower levels of degradation of volatile fraction of hemicellulose and cellulose) through Torrefaction. However, Torrefaction of pine needles is still justified as they are found very wet and prone to rot. Long term storage of pine needles for year- long sale of a fuel further underscores the need for Torrefaction. During field research in India, two batch reactor designs were also built and tested for Torrefaction using pine needles. The designs gave moderate –poor results for heat transfer to the pine needles, leading to the production of non-uniformly Torrified product. This underscores the need for further research on other reactor designs. However, the second reactor built gave better heat penetration than reactor 1 and hence its geometrical and operational parameters were selected for calculation pertaining to the business model. A final selection of process parameters gave an isothermal Torrefaction temperature of 250oC for a residence time of 15 minutes. This was based on the trends in Mass Yields, Higher Heating Values (HHV) and Energy Yields obtained through Torrefaction experiments and DTGA analysis. The impact of different process conditions on the business profits and the overall efficiency of the reactor also played a role in choosing this process condition. Field research in the Kumaon region was carried out to find out the value proposition for a variety of end users, from domestic cooking to gasification based power plants. The needs and preferences of the end users were established through interviews, generative “Design Sessions” and cookstove demonstrations. In the end it was established that commercial kitchens that use commercial LPG for cooking would benefit most from the use of Torrified pellets, as the cost of commercial LPG is high and its supply chain is not well established in remote areas. Due to the concentration of these businesses in the urban areas, it was decided to focus on the market in these towns. Initial market penetration of 5% gave a daily fuel demand of 1072 kg/day and a raw biomass demand of 8055 kg/day. A cumulative reactor volume 21 m3 would be needed to meet this demand. A logistics system was designed in which the pine needles will be collected on foot by women collectors at 1 Re/kg , aided by a ropeway system. The transportation of the fuel to the market using factory owned pick-up trucks was found to be the most feasible. A 6 year payback time was fixed to recover the capital cost of the plant. Overall, the business gave marginal profits in the first 6 years and strong profits after 6 years, underscoring the business potential for this concept. Although further research is needed to develop the technology before realization of the project, this novel method of simultaneous development of the technology and business system with contextual consideration has produced a promising foundation of a business with much potential.","","en","master thesis","","","","","","","","","Applied Sciences","Process and Energy","","Sustainable Energy Technology","",""
"uuid:f4748388-b590-4a5f-bb6a-d6beef436bb1","http://resolver.tudelft.nl/uuid:f4748388-b590-4a5f-bb6a-d6beef436bb1","Two-part modelling format for modelling marine diesel engines in joules","Zhou, H.","Godjevac, M. (mentor)","2015","The modelling approaches can go to two extremes: fully data-oriented and fully process oriented. Modelling for diesel engines is not excluded. Usually data-oriented is computational friendly and accurate and the latter is detail and flexible. A high-speed diesel engine model is missing in project JOULES. The objective of this work is to develop a generic diesel engine model and use it within JOULES so that it can fill in the vacancy of high speed diesel engine model as well as using for other engines. A two-part modelling format was proposed to provide flexibility and user-friendliness. Modifications including adding three sub-models, changing interface have been made to the DE A diesel model in order to satisfy the outputs requirement from JOULES, be converted into FMUs and fit into the two-part modelling format. A set of six versions of process part were achieved and the data part interface was determined. Sensitivity analysis was done to support the use of newly added sub-models. After validating all model versions, the mode was used in the case provided by Navantia. The results showed that the two-part modelling format is accurate enough for the work and extremely flexible. However, a long simulation time was recorded due to the use of FMUs.","diesel engine; modelling; two-part format; JOULES; FMI/FMU","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Marine & Transport Technology","","SDPO","",""
"uuid:2e8f9865-0613-43ee-9d52-be910f246e6a","http://resolver.tudelft.nl/uuid:2e8f9865-0613-43ee-9d52-be910f246e6a","An Economic, Environmental and Sustainability Assessment of a large scale biofuel industry in Suriname","Diran, D.D.","Pruyt, E. (mentor)","2015","In this study an economic, environmental and sustainability assessment is conducted on a potential large scale biofuel industry in Suriname, South America, by applying System Dynamics. Suriname faces important energy related questions for the future, this with the eye on the growing economy and energy demand and the responsibility in terms of climate issues and biodiversity and forest conservation. Biofuels possess great potential to clean up the energy supply for both power generation and transport. Developing a biofuel industry in Suriname will pay off in the future under the condition that a) sufficient government incentives are implemented as a catalyst in the development of a biofuel industry and market b) the policy not only addresses export, but also establishes a local demand to cope with the uncertainty of the international biofuel market and also to establish local CO2 reduction and energy security and c) sufficient environmental and forest preservation law is implemented with a strict control mechanism. When taking these measures in developing Surinamese biofuel policy, the negative consequences regarding deforestation and the environment are minimized, while the positive impacts regarding energy security, CO2 emission reduction, agricultural development, rural development, renewable energy and economic growth and diversification are maximized.","Bio-fuels; Suriname; Sustainable Energy; System Dynamics; Policy Analysis","en","bachelor thesis","","","","","","","","","Technology, Policy and Management","Multi Actor Systems","","","",""
"uuid:b5189641-9a09-47bb-90d5-3ae0a023f441","http://resolver.tudelft.nl/uuid:b5189641-9a09-47bb-90d5-3ae0a023f441","Aeroacoustic investigation of a stridor patient’s upper respiratory system: A Lattice Boltzmann Method simulation using Exa PowerFLOW","Foucart, Michel (TU Delft Aerospace Engineering)","Hickel, Stefan (mentor); van Zuijlen, Alexander (mentor); van der Velden, Wouter (mentor); Ragni, Daniele (mentor); Delft University of Technology (degree granting institution)","2015","Children and adults suffering from Upper Airway Obstructions (UAOs) are nowadays examined using an invasive endoscopy. Because this diagnostic technique unavoidably exposes the patient to certain health risks, there exists a clear need for a non-intrusive diagnostic tool. Several research programs have been initiated that aim at the development of such a tool. One of these initiatives attempts to determine the nature of the obstruction based on an analysis of the patient’s stridor, a characteristic high-pitched breathing sound that often accompanies UAOs.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:d0be5436-d0c1-4254-bff4-378f9bf4d3f7","http://resolver.tudelft.nl/uuid:d0be5436-d0c1-4254-bff4-378f9bf4d3f7","Torque control design for minimalistic gyroscopic balance assistance","Berry, A.","Vallery, H. (mentor); Babuska, R. (mentor); Lemus, D. (mentor)","2015","A minimalistic robotic device for aiding persons with degraded balancing ability was recently proposed, employing a number of single-gimbal control moment gyroscopes (CMGs) mounted to a backpack-like orthopedic corset. Once a fall is detected, the device must track a predefined moment profile to bring the subject upright or else slow the fall enough for the wearer to self-stabilize. CMGs are gyroscopic momentum exchange devices that are prized due to their ability to output a larger moment than that applied by their constituent motors; however, these actuators have highly nonlinear dynamics and are susceptible to geometric singularities in their output, making their control difficult. Little has been published in the context of singularity-robust CMG control in terrestrial applications, while extensive studies pertaining to spacecraft attitude control have limited relevance due to fundamental differences in the nature of the application and number of actuators employed. This work proposes a controller based on the minimizing solution to a weighted linear least-squares combination of moment tracking errors and control efforts, with additional proximity-dependent terms accounting for performance issues at the two relevant classes of singularities. A second controller is presented for a recently-patented CMG design which utilizes a second elastically-constrained inner gimbal intended to resist disturbances imparted by motion of the wearer. The performance of the two controllers is evaluated through both simulations and hardware testing.","control moment gyroscope (CMG); fall prevention; wearable robotics; torque control","en","master thesis","","","","","","","","2020-07-28","Mechanical, Maritime and Materials Engineering","Delft Center for Systems and Control","","","",""
"uuid:1e3738ab-fbfd-4218-bfc7-a95fb3f56c41","http://resolver.tudelft.nl/uuid:1e3738ab-fbfd-4218-bfc7-a95fb3f56c41","Smart wound patch: Design of an integrated electronic sensor system for continuous wound monitoring","Van Roemburg, S.P.J.","French, P.J. (mentor)","2015","Worldwide ca. 20 million patients are suffering from slow- or non-healing wounds. These problematic wounds have a major impact on the mortality risk, quality of life and mobility of patients. Moreover, non-healing wounds are a major financial burden for health care providers. Currently, wound treatments are selected mainly based on visual inspection and experience of the clinician. One approach to improve wound care is the use of monitoring. Continuous wound monitoring can provide objective measurements of the wound status. These measurements can be used to guide the treatment and provide feedback about the treatment effectiveness. Guided treatments will lead to improved wound outcome and shorter wound duration in many problematic wounds. This thesis describes the design of an integrated electronic sensor system for continuous wound monitoring: a smart wound patch. First, the literature and interviews are used to select six parameters from the complex wound healing process as healing performance indicators: matrix metalloproteinase-9, moisture, nitric oxide, pH, temperature and tissue oxygenation. Different sensor technologies are considered for the assessment of these six parameters. A smart wound patch is designed to assess moisture, temperature and tissue oxygenation. The design includes 4 moisture dependent electrode pairs, 3 silicon-based temperature sensors and 2 pulse oximeters. A flexible foil forms the basis of the design which includes NFC and flexible printed batteries. A brief market research indicates a high commercial potential for a smart wound patch. A prototype is build on a PCB and used to test the proposed design. Conductance measurements of gold electrode pairs provide assessment of moisture levels from wet to dry as well as skin moisture levels. Accurate temperature measurements on healthy skin are achieved using silicon-based sensors. Pulse oximetry provides heart rate and an indication of re-vascularisation. Estimation of tissue oxygenation based on blood oxygen saturation requires further research. Continuous wound monitoring with a smart sensor system can revolutionise wound care by providing objective measurements that enable guided wound treatment.","smart sensor system; pulse oximetry; wound; wound monitor; moisture sensor; temperature sensor","en","master thesis","","","","","","","","2018-08-07","Mechanical, Maritime and Materials Engineering","Biomedical Engineering","","Biomedical Electronics","",""
"uuid:40572f8a-f4da-4341-915f-29de6145636b","http://resolver.tudelft.nl/uuid:40572f8a-f4da-4341-915f-29de6145636b","Design of a Zero voltage switching Flyback synchronous rectification controller for high voltage applications","Nahar, G.N.","Pansier, F. (mentor); Popovic, J. (mentor); Kloet, J. (mentor)","2015","The recent launch of high voltage switching devices of new semiconductor materials such as Silicon Carbide, have shown better performance. This makes it possible to use the single stage Flyback converter for low to moderate power, high input voltage applications, which is attractive due to its inherent advantages of low cost and simplicity. However, the losses in the Metal-Oxide-Semiconductor-Field-Effect Transistor (MOSFET) are aggravated due to the high input voltage, which decreases the efficiency. Additionally, the losses in the secondary diode can be considerable, thus deteriorating the efficiency further. With the current trend towards high power density converters, the replacement of through hole component with surface mounted technology (SMT) components for the active devices is often the solution, under the condition that they require minimal thermal management i.e. using SMT components with minimal footprint without heat-sinks. In the light of thermal management it is important to reduce the losses in the active components, thereby effectively decreasing the generation of heat. Therefore, the objective of this thesis is to design a high power density 40W flyback converter by reducing the losses in the active components. First the nature of the losses are identified theoretically and afterwards the results are verified experimentally. It was found that the switching losses in the primary MOSFET and the conduction losses in the secondary diode are the major loss contributors. To reduce both these losses a synchronous rectification controller was built which ensures zero voltage switching (ZVS) by making the converter bidirectional. The experimental results show that for loads greater than 0.5 Inominal,, the losses in the active components are reduced effectively to levels which allow the use of SMT component with minimal footprint. For light load conditions the converter showed erratic behavior due to the limited blanking time of the primary controller. To address this issue, a solution was proposed which has proven to work successfully for the voltage range of 400V-600V. Under a few special condition for voltages higher than 600V, the proposed solution has shown some erratic behavior, which is expected to be a result of the control loop stability.","Flyback; Zero voltage Switching; Synchronous Rectification","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Electrical sustainable energy","","Electrical power processing","",""
"uuid:b4b1fe9c-acb6-4e2b-adc6-5324dfbaf51c","http://resolver.tudelft.nl/uuid:b4b1fe9c-acb6-4e2b-adc6-5324dfbaf51c","Feasibility study of a novel load alleviation system on the UH-60A Blackhawk helicopter","Verhagen, M.R.","Voskuijl, M. (mentor)","2015","","helicopter; structural load alleviation system; SLA; tailplane; horizontal stabilizer; Flightlab; UH-60A; Blackhawk; agility; safety; flightpath bandwidth","en","master thesis","","","","","","","","2016-08-06","Aerospace Engineering","Aerospace Design, Integration & Operations","","Flight Performance and Propulsion","",""
"uuid:c4dcb648-c053-4093-8ef6-b57eda1ab81a","http://resolver.tudelft.nl/uuid:c4dcb648-c053-4093-8ef6-b57eda1ab81a","Een verbeterd semi-stochastisch model voor wondheling onder infectie","Smits, D.","Vermolen, F.J. (mentor)","2015","Voor dit project is een bestaand semi-stochastisch cell-based model voor wondheling onder infectie bekeken, dat migratie, deling, sterfte, melkzuurproducerende bacteriën en witte bloedcellen omvat. Dit model wordt uitgebreid, onder andere met een dynamische implementatie van celdeling. Daarnaast wordt met behulp van numerieke methoden de benodigde rekenkracht gereduceerd, om zo simulaties mogelijk te maken die met dit model voorheen niet konden worden uitgevoerd.","wondheling; infectie; cell-based model","nl","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Technische Wiskunde","","","",""
"uuid:edf6d5ae-3730-4eba-834b-4c399b0bd39d","http://resolver.tudelft.nl/uuid:edf6d5ae-3730-4eba-834b-4c399b0bd39d","Low Cost Techniques for High-Speed Implementation of Decision Feedback Equalizers for FPGAs","Papadopoulos, C.","Gaydadjiev, G.N. (mentor)","2015","In modern digital communications throughput rates in the order of gigabits per second are not uncommon. Hence there is a need for fast equalizing filters. While all feed forward filters can easily be pipelined, therefore sped up, the feedback filter (FBF) of decision feedback equalizers is the bottleneck of its performance. A simple, extremely fast, reformulation of the FBF, based on an obvious expansion of the Shannon's expansion theorem idea, can easily be devised. This particular design can be retimed in a straightforward manner to reach its iteration period bound, but is ultimately limited by the propagation delay of the registers. Even though we can unfold the circuit in an attempt to limit the register's delay relevance, its hardware overhead is exponentially dependent on the number of tap coefficients (L), therefore, very costly even for relatively small Ls. In order to cope with the exponential area growth a two stage pre-computation schema, similar to the reformulated FBF, will be introduced. We show that the area degrades significantly with the penalty of decreasing the maximum achievable frequency. To reach its iteration bound, this new design has to be unfolded. In our experiments we use the Xilinx ISE FPGA synthesizer, targeting the Virtex 5 family, the XC5VLX20T module, set to speed -2. We will approximate the minimum needed unfolding factor for an FPGA centric design, considering different word lengths and number of tap coefficients, to use as a base for the experimental phase. Our experiments with the unfolding factor will conclude when the performance is comparable with that of the first FBF reformulation. For that final design we will find the L where the hardware overhead improvement outweighs the hit in performance. Finally, based on the experimental results, we will show that the performance can be further increased, with the introduction of a retime approach.","Decision Feedback Equalizer","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Parallel and Distributed Systems","","Embedded Systems","",""
"uuid:b71d978d-7360-49e0-81bd-2af9b751a9e0","http://resolver.tudelft.nl/uuid:b71d978d-7360-49e0-81bd-2af9b751a9e0","Evaluation of the ESReDA Cube Method for the Aviation Sector","Martens, F.J.L.G.","Melkert, J.A. (mentor)","2015","Nowadays accident analysis tools focus on finding the cause of an accident so that lessons can be learned. The ESReDA Cube method is designed to explore a new field in accident analyses. It focuses on the next step, namely analysing the lessons learned out of an accident. It is checked if they are sufficient and if they caused any change(s). With this project the ESReDA Cube method will be evaluated for the first time for the aviation sector. The ESReDA Cube analysis is performed in several steps. First the accident is described. Next a three dimensional overview of the lessons learned is created. This overview, in the shape of a cube, is called the ESReDA Cube. The three dimensions the method explores are: operation level, system level and depth of learning level. To make the overview three questions are asked for every lesson learned. Every question is related to a specific dimension:  Operation level: “What needs be learned?” (content, structure, culture, context)  System level: “Who should learn?” (micro, meso, macro)  Depth of learning level: “How to learn?” (optimize, adapt, innovate) Behind every question, the available answers are presented between parentheses. The three answers represent a lesson learned as a set of three dimensional coordinates. In this way every lesson learned can be located in a specific part of the ESReDA Cube and an overview is created. Using this overview it can be analysed where exactly lessons are learned. By checking the spreading of the items over the cube it is checked if there is still learning potential somewhere. It is also possible to combine the results of several cases into one cube to analyse multiple cases together. The next step is to describe the impact of the lessons learned to check if something changed or if any implementation problems are encountered. With the results obtained conclusions can be drawn and if necessary new learning suggestions can be issued. In this thesis the method is applied on three accident cases. The three analysed cases all have stall as a contributing factor, and due to that they are quite similar. The cases chosen are:  Air France flight 447  Colgan Air, Continental Connection flight 3407  Turkish Airlines flight 1951 The cases are analysed both individually as well as together. The results show that the part of innovation on the depth of learning level is quite empty, which can indicate learning potential. Although new concepts to prevent stall accidents exist, they are not recommended. All lessons on the depth of learning level are learned in the part of adaptation and optimization. Stall accidents still occurred after these three accidents, which confirms that maybe other lessons should be learned instead of always optimizing and adapting. It can be concluded that more research should be done for new innovative concepts to prevent stall accidents. By applying the method on three cases it is seen that in the current method’s state and usage, problems are encountered which prevent a complete analysis. Only one level can be completely analysed, namely the depth of learning level. At the operation level no complete analysis is possible due to lack of input with only public sources and due to an insufficient lay-out. At the system level also no complete analysis is possible due to an insufficient lay-out of the meso and macro part. These problems cause the method to almost always obtain the same results, namely an empty aspect of innovation. Due to this the method is in its current state and usage not applicable for the aviation sector. It is recommended to change the lay-out of the operation and system level. Another recommendation is to change the target group of the method to investigators/instances with access to more than only public sources, like companies or safety agencies. To check if the new lay-out and target group make the method applicable for aviation further evaluation is recommended.","ESReDA Cube; ESReDA","en","master thesis","","","","","","","","","Aerospace Engineering","Aerospace Design, Integration & Operations","","Systems Engineering and Aircraft Design","",""
"uuid:6c3efa8c-5a2e-463e-bdb8-2c44eae39119","http://resolver.tudelft.nl/uuid:6c3efa8c-5a2e-463e-bdb8-2c44eae39119","Modelling of the dynamic behaviour of a fall pipe system","Duijm, L.B.J.","Natarajan, G. (mentor); Visser, C. (mentor); Van Rhee, C. (mentor); Miedema, S. (mentor)","2015","This thesis describes the creation and validation a three dimensional numerical model in Orcaflex of a fall pipe system. It was used to investigate the system’s dynamic behavior under a range of normal and more extreme operating conditions.","Fallpipe; Orcaflex; Tideway; Stone installation; Rollingstone; Dynamic motion","en","master thesis","","","","","","","","2019-08-03","Mechanical, Maritime and Materials Engineering","Offshore and Dredging Engineering","","Dredging Engineering","",""
"uuid:59b18585-a279-4de3-aa14-f784872e34bf","http://resolver.tudelft.nl/uuid:59b18585-a279-4de3-aa14-f784872e34bf","Improvements to the design process of the energy distribution system: A comparison between operational use of the energy distribution system of a naval ship and its expected use during the design phase","Smith, M.G.","Hopman, J.J. (mentor); Godjevac, M. (mentor); De Ruyck, K. (mentor)","2015","After a ship is delivered from a shipyard to a customer, its operational use is not yet structurally compared to its expected use. This lack of structural comparison results in limited verification and self-evaluation of the design process. The objective of this research is therefore to develop a method to analyze operational data and apply this operational data analysis method to the Royal Netherlands Navy Holland class Oceangoing Patrol Vessels (OPVs). These vessels use Combined Diesel Electric or Diesel (CODELOD) propulsion. The data analysis focuses on the electrical energy distribution system, because this determines a large portion of the total fuel consumption of the ships. Operational data from these ships was collected from the Integrated Platform Management System, which is installed on the OPVs. By applying the operational data analysis on the Holland class OPVs, the generator plant setup is evaluated. Based on the results from this analysis, a father-son generator setup is proposed, consisting of two 835 ekW gensets and two 475 ekW gensets. This setup has better redundancy, less fuel consumption, and a lower total installed power, compared to the three currently installed 920 ekW generators. The proposed father-son altenative setup reduces the total installed electric power by 5.1%, and saves 0.4% to 2.4% fuel consumption for electricity generation. To obtain an accurate calculation of fuel consump tion for widely distributed power consumption profiles, a power consumption distribution must be used instead of an average value.","operational profile; data analysis; design evaluation; diesel generator; operational data; clustering algorithm; navy; fuel consumption","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","SDO","","Mechanical Engineering - Mechanical Systems and Integration","",""
"uuid:87a31cf8-9047-48c9-b11f-680ebec43135","http://resolver.tudelft.nl/uuid:87a31cf8-9047-48c9-b11f-680ebec43135","Modelling the impact of large scale sediment dumping on the meso-scale hydro- and morphodynamics in the Western Scheldt","Palaiogianni, N.","Stive, M.J.F. (mentor); Van Rooijen, A.A. (mentor); Van der Werf, J. (mentor); De Vet, L. (mentor)","2015","The current report aims to understand the hydro- and morphodynamic response of the Western Scheldt in a large sediment dumping operation. This study investigates the estuary’s response to sediment dumping in the Everingen channel area, which is located in the middle of the Scheldt Estuary, The Netherlands. Furthermore, it studies whether these sediment nourishments could indirectly feed the nearby-located Baarland tidal flat. In this study, two morphodynamic models for the Scheldt Estuary were set up, using both the newly developed D-Flow Flexible Mesh software, for the numerical modelling, and the more established Delft3D software. The new software allows a local refinement of the grid in the area of interest for better hydraulic and morphological analysis and shorter computational times. Both models were calibrated and validated for the local hydrodynamics, and subsequently used to study several sediment dumping scenarios. As the sediment module within D-Flow FM was not available yet, the morphological impact of each dumping scenario is investigated using offline-predicted sediment transport patterns based on predicted velocities. These large dumping operations can cause intense changes in the local hydrodynamics and also significant morphodynamic changes not only locally but also in the wider macro-cell area. Indications of erosion and accretion in the Baarland flat were found without though having a clear view of the flat nourishment. Based on the study results, further investigation of dumping scenarios close to the area of interest is recommended.","sediment dredging and dumping; sediment transport; sediment management; Scheldt Estuary; Everingen; Baarland; Delft3D; D-Flow Flexible Mesh","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Hydraulic Engineering","","Coastal Engineering","",""
"uuid:17de3d71-a962-4117-bbb1-ecffef13c058","http://resolver.tudelft.nl/uuid:17de3d71-a962-4117-bbb1-ecffef13c058","Longitudinal ultimate bending strength analysis of ship structure for emergency response","Mao, F.","Kaminski, M.L. (mentor)","2015","The last three years have witnessed many maritime accidents (like “Costa Concordia”, “Mol Comfort”, “MV Smart”, etc), which led to serious consequences including the loss of human life and asset and environment pollution. In order to mitigate loss, maritime emergency response requires time-saving. So, a fast numerical tool is very important for supporting decision making and related engineering work in emergency case. Currently, most fast numerical modeling method is either by manually laboriously building or requires 3D or 2D AUTO CAD drawing, which is very difficult to obtain in emergency situation. Thus this thesis is aiming to propose a fast numerical method based on limited information from emergency situation. Based on the fast numerical model, structural analysis, weight estimation, etc, can be assessed, thus supporting decision making and engineering work. In consistent with the emergency situation, global longitudinal bending strength is analyzed based on the fast numerical model in the present work. This thesis is divided into 3 parts: rapid numerical method and a corresponding numerical tool for container ship; verification of this numerical tool in global structural response and longitudinal ultimate bending strength assessment for container ship; longitudinal ultimate strength assessment for other types of structure like OT, BC, FPSO, etc. Firstly, in this thesis, a global data structure for storing ship geometric information from available drawings after emergency situation is developed in this thesis. Based on this data structure, a rapid numerical modeling method is developed in the present work. Then, a corresponding rapid numerical tool in container ship is produced. Secondly, the fast numerical tool is validated in structural response of global FE model of container ship. And the failure mechanism of container ship under sagging is investigated by both numerical model and analytical model. Based on it, the longitudinal ultimate bending moment is obtained by the generated fast numerical model. Finally, for other type of ship structures like OT, BC, FPSO, etc, the failure mode of the structure under pure bending is investigated by nonlinear finite element analysis. Based on the failure mode, a simplified method for assessing ultimate bending moment by NLFEM is proposed and validated with experiment result and ISSC benchmark study. This validated fast numerical tool for container ship can be used for structural analysis, structural weight estimation etc, and thus supporting engineering in emergency case. And the generic fast numerical method can be further applied for other types of ship structure, like OT, BC, FPSO etc. A corresponding simplified NLFEM method can be used for assessing maximum bending capacity and thus supporting lifting engineering work.","ship emergency; generic rapid numerical modeling method; ultimate strength; failure mechanism; non-linear finite element method","en","master thesis","","","","","","","","2017-08-03","Mechanical, Maritime and Materials Engineering","Ship Hydromechanics and Structures","","Offshore and Dredging Engineering","","52.0833, 4.3167"
"uuid:5cbbfac7-6c17-4b8e-a009-198849ccabd2","http://resolver.tudelft.nl/uuid:5cbbfac7-6c17-4b8e-a009-198849ccabd2","Dubbele Buiging in Betonnen Kolommen: Analyse van het werkelijk doorsnedegedrag en sterktevergelijking met het Eurocodevoorschrift in de Ultimate Limit State","Nijgh, M.P.","Braam, C.R. (mentor)","2015","Analysis of the strength of concrete columns subjected to bi-axial bending. Comparison of the true strength with the strength according to the design rules from the Eurocode.","Concrete; Column; Bi-axial bending; Bending","nl","bachelor thesis","","","","","","","","","Civil Engineering and Geosciences","Concrete Structures","","Materials and Environment","",""
