"uuid","repository link","title","author","contributor","publication year","abstract","subject topic","language","publication type","publisher","isbn","issn","patent","patent status","bibliographic note","access restriction","embargo date","faculty","department","research group","programme","project","coordinates"
"uuid:fac9915f-2aab-4200-94b2-46669371b88d","http://resolver.tudelft.nl/uuid:fac9915f-2aab-4200-94b2-46669371b88d","A hierarchically pipelined data acquisition system for single-photon avalanche diode array","Trimananda, R.","Gersbach, M. (mentor); Charbon, E. (mentor)","2009","SinglePhotonAvalancheDiode(SPAD)is a typeof highly sensitive diode that can detect single photons. It is, there fore, useful for certain applications that need photons ensing capability. A system, consisting of 32x32 SPAD array, with its controller along side on Virtex-IIProFPGA on board, has been being developed and tested to evince its reliability and robustness. It utilizes the SPAD array for photon counting( time-uncorrelated) and measuring the arrival times of single photons (time-correlated), which implies fast datarate, and, thus, fast data acquisition. Alas, as it was ?rst developed without any adequate data acquisition capability to cope with the potential of the SPAD, it is then considered important to create one. This thesis report presents a design of a system that is able to perform a robust data acquisition as it works together with the SPAD array and its controller. It has been implemented in Verilog HDL, simulated, synthesized, and tested on the FPGA. Apart from this ?rmware itself, a set of simple DLL functions has been written to control it. Additionally, a particular software is also created based on the DLL functions to provide a standard interface for the users, while the functions also work with many applications, e.g. MATLAB. The entire system has been tested, pro?led, characterized, and even used in some real experiments. In terms of speed and robustness, it shows a great advancement for the SPAD array data acquisition.","SPAD","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","CAS","","","",""
"uuid:f448f04b-9416-4cc3-bc42-6a3368fe4580","http://resolver.tudelft.nl/uuid:f448f04b-9416-4cc3-bc42-6a3368fe4580","Antenna Beamforming for a 60 GHz Transceiver System","Khan, M.N.","Rizvi, U.H. (mentor); Janssen, G. (mentor); Leus, G. (mentor); Niemegeers, I. (mentor)","2009","The main target of a 60 GHz transceiver system is to obtain data rates close to gigabits per second (Gbps) over short distances. The 60 GHz suffers from severe pathloss, inter-symbol interference (ISI) and a limited link budget. In order to improve the link budget, beamforming techniques are utilized. Antenna beamforming, i.e., combining signals from multiple receive antennas is one of the crucial aspects of the 60 GHz transceiver system. Adaptive antenna arrays are considered for the beamforming. A single carrier with frequency domain equalization (SC-FDE) is used for the modulation. In order to suppress the ISI, a cyclic prefix (CP) is used in SC-FDE. The effects of the physical parameters of antenna arrays on the RMS delay spread and BER have been investigated in LOS/NLOS condition. An algorithm for radio frequency (RF) level beamforming is proposed. The effects of perfect channel and non-perfect channel on the BER have been investigated using the proposed beamforming algorithm. The effects of the antenna array physical parameters on the BER using the proposed beamforming lgorithm have also been investigated. It was seen that the BER improves after the implementation of the new beamforming algorithm. The 60 GHz band shows severe ISI which is improved by using the proposed beamforming algorithm.","Habibullah","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Telecommunications","","","",""
"uuid:49086b07-3596-46fd-bcce-bfc9da55a8fe","http://resolver.tudelft.nl/uuid:49086b07-3596-46fd-bcce-bfc9da55a8fe","Performance Evaluation of the Micro Milling Setup","Rozing, M.","Blom, R.S. (mentor); Li, P. (mentor); Munnig Schmidt, R.H. (mentor)","2009","The micro milling process is one of the micro manufacturing processes that have the potential to achieve relative accuracies in the range of 10-3 to 10-5. To conduct scientific research an xxperimental micro milling setup has been designed. Prior to do any kind of research it is required to find out what the contribution of the machine tool to the accuracy of a work piece is and therefore the accuracy of the micro milling setup will be evaluated in this thesis. To evaluate the accuracy of the micro milling setup the volumetric error is introduced and defined as: The volumetric error is the difference between the nominal location of the tool and work piece relative to the machine tool reference frame and the actual location relative to the machine tool reference frame. The actual location of the tool and work piece is the result of the twenty-one geometrical errors. The main question this Masters Thesis research answered was: What is the accuracy of the micro milling setup in terms of the volumetric error which results from geometrical errors? To answer this question two main goals are defined. The first goal is to derive an analytical model of the micro milling setup that calculates the volumetric error as a function of the twenty one independent geometrical errors. This analytical model is called the kinematics error model and calculates the volumetric error as the difference between nominal position of the tool relative to the workpiece and the actual position of the tool relative to the work piece. The kinematics error model calculated a range for volumetric errors that in X direction ranged from -3.87 ?m to 8.67 ?m and in Y direction the volumetric errors ranged from -2.86 ?m to 8.27 ?m. Furthermore the kinematics error model revealed that the volumetric error is most sensitive to the geometrical errors of the X stage. The arms attached to the X stage that convert the rotational errors into translational errors are the largest in magnitude. The second main goal is to perform experiments that verify the model. The model has been verified with experiments and it turned out that towards the end of travel of the stages the the measured volumetric error lied outside the calculated range of the volumetric error. The model calculated a better precision. The measured volumetric errors varies between -1.32 ?m and 9.64 ?m in X direction and in Y direction between -6.60 ?m and 1.36 ?m. To find an explanation for the observed differences the influence of other sources of error on the measurement result is studied. Results found in literature suggest that the difference between the model and the measurements has to be attributed to the influence of heat that originates from mechanical and electrical components in the stages. The observed increase in the measured hysteresis in X direction and Y direction and the increase in the measured position error in X direction indeed hint at the influence of heat on the experimental results. Therefore a small experiment was conducted in which the temperature was measured whilst a circular interpolation test was repeatedly performed. This experiment however could not confirm the influence of heat on the experimental results. Results found in literature and the experiment performed however clearly revealed that the influence of heat is the most likely explanation for the observed differences. The influence the heat has on the volumetric error should be further investigated and should be minimized. The accuracy of the micro milling setup will however never be better than the accuracy that was obtained with the kinematics error model.","Micro Milling","en","master thesis","","","","","","","","2010-01-27","Mechanical, Maritime and Materials Engineering","Precision and Microsystems Engineering","","","",""
"uuid:fe5ea73c-a85b-4a4b-b5d5-fc01d29b2113","http://resolver.tudelft.nl/uuid:fe5ea73c-a85b-4a4b-b5d5-fc01d29b2113","Optical Flow Based State Estimation for an Indoor Micro Aerial Vehicle","Verveld, M.J.","Mulder, J.A. (mentor); Chu, Q.P. (mentor); de Wagter, C. (mentor)","2009","This work addresses the problem of indoor state estimation for autonomous flying vehicles with an optic flow approach. The paper discusses a sensor configuration using six optic flow sensors of the computer mouse type augmented by a three-axis accelerometer to estimate velocity, rotation, attitude and viewing distances. It is shown that the problem is locally observable for a moving vehicle. A Kalman filter is used to extract these states from the sensor data. The resulting approach is tested in a simulation environment evaluating the performance of three Kalman filter algorithms under various noise conditions. Finally, a prototype of the sensor hardware has been built and tested in a laboratory setup. Paper published: Verveld, M.J., Chu, Q.P., De Wagter, C. and Mulder, J.A. “Optic Flow Based State Estimation for an Indoor Micro Air Vehicle” AIAA Guidance, Navigation, and Control Conference, August 2010, Toronto, Canada AIAA 2010-8209, DOI: 10.2514/6.2010-8209","optical flow; sensor fusion; Unscented Kalman filter; bio-inspired flight","en","master thesis","","","","","","","","","Aerospace Engineering","Control & Simulation","","","",""
"uuid:80ea30e9-11c3-4e7e-b250-7de6015f4744","http://resolver.tudelft.nl/uuid:80ea30e9-11c3-4e7e-b250-7de6015f4744","Charge Domain Interlacing CMOS Image Sensor Design","Xu, Y.","Theuwissen, A. (mentor)","2009","This thesis presents a CMOS image sensor which can implement the charge domain interlacing principle. Inspired by the shared amplifier pixel structure and based on a pinned photodiode four transistor (4T) structure, two innovative pixel designs combined with two different readout directions are presented. These novel pixels are designed to fit the charge domain interlacing principle, which used the charge binning technology in the field integration mode of interlaced scan to improve the signal-to-noise ratio of the sensor. To realize this working principle and compared it with other working modes, a programmable universal image sensor peripheral circuit is designed for controlling and driving the pixel array in the most flexible and most efficient way. As a result, the designed sensor can be used not only in the progressive scan mode, frame integration interlaced scan, and voltage domain interlacing mode but also in the charge domain interlacing mode. This is a very unique feature for CMOS image sensors, and without the shared pixel concept, charge domain interlacing was only possible with CCDs. The proposed image sensor is implemented in TSMC 0.18um 1P6M CMOS technology. Some preliminary measurement results of the chip are shown to prove the functional correctness of the image sensor.","CMOS image sensor; charge binnning; interlaced scan","en","master thesis","","","","","","","","2009-09-02","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","","",""
"uuid:36a62709-cb33-4c4a-88b6-0ad9fba1555b","http://resolver.tudelft.nl/uuid:36a62709-cb33-4c4a-88b6-0ad9fba1555b","LC Ladder Based Orthonormal Filter for Impulse-Radio UWB Pulse Generation.","Shamsa, Y.","Serdijn, W.A. (mentor); Meijer, G.C.M. (mentor); Long, J.R. (mentor)","2009","In this thesis, a UWB pulse generator is designed to be implemented in IBM 0.13 um technology. The pulse generator has a high spectral efficiency. Using amplitude control, any mismatch, process variation or temperature variation can be compensated for to comply with the UWB FCC mask. The pulse has an approximate duration of 2ns. The current consumption is 13mA per pulse. The power consumption per pulse is 19.5 mW. The next stage can be a power amplifier or an antenna. In case of an antenna, the effect of bond pads and bond wires are taken into account. A challenging aspect of UWB systems is their interference with narrow-band systems. Narrow-band systems send very high power signals compared to the UWB signals and thus may saturate the UWB receiver and/or prevent reliable detection of the UWB pulses. A possible solution to this problem is filtering. In this thesis, a Wireless Local Area Network (WLAN) band rejection filter for UWB applications is designed using IBM 0.13 um technology. A new filter topology is used to implement the filter. This topology has the ability to actively read all the states of an LC filter without using extra inductors. Both AC and impulse responses are presented. The filter has a notch of approximately 14dB. It can operate over the military temperature range (-40 C to 125 C). The effects of mismatch and process variations on this design are acceptable.","UWB; UWB-IR; pulse generator; filter","en","master thesis","","","","","","","","2010-10-01","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","","",""
"uuid:badbddb8-9f61-48a5-ac50-fc3e0bd719e9","http://resolver.tudelft.nl/uuid:badbddb8-9f61-48a5-ac50-fc3e0bd719e9","Compressive Sampling for PPM and FSK Modulated Signals","Gishkori, S.S.","Leus, G.J.T. (mentor); Van der Veen, A.J. (mentor)","2009","Efficiency of the Analog to Digital Converters (ADCs) has always been an issue of concern, especially, when it comes to sampling wide band signals which require extremely high sampling rates. As the systems with wide band signals are gaining the front position in digital communications, the need to find ways to reduce the sampling rates of ADCs but still maintaining exact reconstruction, is becoming ever more resurgent. In this thesis we present the utilization of a newly discovered technique to reduce the sampling rates much below the Nyquist rates. We explore the combination of Compressive Sampling (CS) with Pulse Position Modulation (PPM) and Frequency Shift Keying (FSK) modulation schemes. CS has been suggested for 'sparse signals'. Sparsity helps represent the signal in much less dimensions. We evaluate the suitability of this technique for PPM and FSK modulated signals in multipath fading environments so as to reduce the complexity at the receiver side. We detect the signals without having to first estimate the channel. We present scenarios where we can achieve the most from the combination of CS and PPM/FSK. We extend this frame work to Ultra Wide Band (UWB) applications. We also give theoretical expressions for the error probabilities of our signal models. The real challenge, with regard to using CS, is to reconstruct the signal from its reduced dimensions. In this respect, we have opted for the Orthogonal Matching Pursuit (OMP) algorithm for most of the cases, nonetheless, we elaborate on other available reconstruction methods as well.","Compressive Sampling; PPM; FSK; UWB; Compressed Sensing","en","master thesis","","","","","","","","2009-09-04","Electrical Engineering, Mathematics and Computer Science","Telecommunications","","","",""
"uuid:e98aac1e-f64b-4a7c-b6eb-b9969218446e","http://resolver.tudelft.nl/uuid:e98aac1e-f64b-4a7c-b6eb-b9969218446e","A Complete Peer-to-Peer Widget System","Van den Berg, A.M.","Pouwelse, J.A. (mentor); Hindriks, K.V. (mentor); Sips, H.J. (mentor)","2009","Nowadays, the World Wide Web is becoming more and more an interactive and social platform than just a means to find information. This is called the Web 2.0. Quite new in the World Wide Web are widgets; small applications that use a little area of a website and displays something specific, often making use of a Web 2.0 application to get its information. The widgets can be combined to create a personal page. Compared to the client-server architecture traditionally used in the Internet, the Peer-to-Peer technology can be used to design and create much more scalable and robust systems. Unfortunately, while they are so promising, P2P systems are mostly used for file transfers. We present a complete P2P Widget System, that introduces social and interactive elements to the P2P paradigm. Using P2P technology, the widget repository (where the widgets are downloaded from) are more scalable and robust than the centralised repositories currently used for widgets. Not only do we present a complete design for this system, we also present a working implementation of this system, which can be deployed in real-life. Furthermore, we show that the system works as it should, by presenting the results of several experiments. From our results, we can conclude that our P2P Widget System is scalable, robust, fast and bandwidth efficient.","P2P; widgets","en","master thesis","","","","","","","","2009-09-12","Electrical Engineering, Mathematics and Computer Science","Parallel and Distributed Systems Group","","","",""
"uuid:e5fe024c-5e94-4588-88c0-92ce19d5f8cb","http://resolver.tudelft.nl/uuid:e5fe024c-5e94-4588-88c0-92ce19d5f8cb","Imaging frozen glacio-fluvial bedrock valley infill using Ground Penetrating Radar","Afanasyev, M.","Storms, J.E.A. (mentor); De Winter, I.L. (mentor)","2009","A Ground Penetrating Radar (GPR) survey was conducted in April of 2008, collecting 27 km of radar profiles in Sandflugtdalen, a permafrosted glacio-fluvial bedrock valley in West Greenland. Due to low electric permittivity of frozen soil, GPR has good depth penetration of permafrost, up to 80 m using low-frequency (50 MHz) antennae. Resolution and visibility of reflections from subsurface structures are improved by gain application and frequency filtering. Migration reconstructs the radar image to make it look closer to the geological structure in the subsurface. Using the principles of radar stratigraphy, 5 types of radar facies are identified in the dataset - chaotic, chaotic with numerous hyperbolic reflections, parallel, oblique and reflection-free; the facies are interpreted respectively as glacial till, push moraine, stratified deposits in (fan) delta bottomsets or lake deposits, lacustrine delta foresets and bedrock. Average bedrock depth in Sandflugtdalen is 50 meters. Bedrock barriers, overlaid by push moraines, divide Sandflugtdalen in 3 subbasins. Radar packages of delta foresets, till and lacustrine deposits in each subbasin are interpreted to be genetically related, having been deposited in moraine-dammed lakes, that formed during progressive stages of glacial retreat, between 10.5 and 5 ka ago. A 3-D model of the bedrock surface is generated and based on the model the sediment volume in the mapped area is estimated as 0.37 km^3. Modeling the bedrock and mapping the sedimentary architecture in a filled glacial valley generates a base-case for model validation of short-term climate changes and effects on glacier and sedimentary system.","glaciology; Greenland; GPR; sedimentology; permafrost","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Applied Geophysics and Petrophysics","","67.074629, 50.261789"
"uuid:7f43f7ee-ef49-4457-acd2-4d696c36ca24","http://resolver.tudelft.nl/uuid:7f43f7ee-ef49-4457-acd2-4d696c36ca24","Multi agent-based control architecture in intelligent transportation system with infrastructure-based sensing","Muhammad, I.H.","Papp, Z. (mentor); Jonker, C.M. (mentor)","2009","Traffic congestion has negative impact in our life. In 2001, the European Commission estimated costs of congestion at around 120 billion Euro. The research of Intelligent Transportation System (ITS) becomes interesting since infrastructure expansion in not always feasible. In order to find out the impact of automated vehicle and intelligent infrastructure to traffic performance, we develop a model of hierarchical vehicle controller and intelligent infrastructure and implement them in a simulated environment using Multi Agent System concept. Several traffic scenarios are deployed to observe the effect of the designed vehicle controller and the model of intelligent infrastructure in traffic.","ITS; traffic simulation; hierarchical control; intelligent infrastructure","en","master thesis","","","","","","","","2009-08-29","Electrical Engineering, Mathematics and Computer Science","Mediamatics","","","",""
"uuid:754dc143-e788-46a6-9af2-436be8faaf4e","http://resolver.tudelft.nl/uuid:754dc143-e788-46a6-9af2-436be8faaf4e","Extending the DEMO methodology for determining information systems requirements","Sandhyaduhita, P.I.","De Jong, J. (mentor); Dietz, J.L.G. (mentor)","2009","High competition and the need to meet market demand are some reasons behind the exploitation of Information and Communication Technology (ICT) to automate activities within an enterprise. The Design and Engineering Methodology for Organizations (DEMO) methodology provides a powerful way of thinking to deal with enterprise complexity. It gives a clear understanding of the business of an enterprise from a social perspective. However, neither the methodology nor its available extensions give tangible and complete explanation for linking the business model to the information system model. Therefore, this thesis’s objective is to contribute in bridging the gap between the business organizational aspect (B-organization) and the supporting information system (I-applications) by extending the DEMO methodology. The DEMO methodology is extended to identify and model intellect organizational aspect (I-organization) of an enterprise to determine a complete set of functional requirements for the I-applications. Literature study and a case study of Mprise B.V. were conducted to achieve the objective. The link between those organizational aspects lies in the Action Model of the B-organization or more precisely on its coordination-specific information. The transaction in the ontological model of the I-organization is defined on the basis of every piece of information needed by the business actor (B-actor). The presence of the I-organization model shows the distribution of the responsibility between the B-actors and the I-actors. The benefits of the extended methodology are shown through the improvement and the application of DEMOUseCase approach to Mprise case study. The extended DEMO methodology is able to produce complete informational/intellectual functional requirements for the I-applications and thus also for the business applications (B-applications) e.g., in providing the basis for modeling of B-applications","information systems; DEMO; enterprise; business model; functional requirements; I-organization","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Software engineerning","","","",""
"uuid:ec2a9074-823a-496b-8918-ea0296f601ee","http://resolver.tudelft.nl/uuid:ec2a9074-823a-496b-8918-ea0296f601ee","Cyclisch onderhoud: Kapitaalvernietiging of de redding van Rijkswaterstaat","Sukhraj, R.S.","Verbraeck, A. (mentor); Jonig, J. (mentor); Cunningham, S.W. (mentor); Renker, B. (mentor); RWS (contributor)","2009","","","","master thesis","","","","","","","","","Technology, Policy and Management","","","","",""
"uuid:070acc67-063f-46d4-9ded-6e18979b8200","http://resolver.tudelft.nl/uuid:070acc67-063f-46d4-9ded-6e18979b8200","Grafische weergave van verkeersproblemen","Deen, G.; De Ridder, M.; Somhorst, M.","Van Nieuwenhuizen, P.R. (mentor)","2009","This thesis describes our internship at Tenuki. The assigment was to impress visitors of Tenuki with the traffic information of Tenuki.","","nl","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Mediamatics","","","",""
"uuid:74069df0-87a2-46be-9a96-0f0df06b922e","http://resolver.tudelft.nl/uuid:74069df0-87a2-46be-9a96-0f0df06b922e","An Ultra Low Power Fully Integrated Sensor Interface IC for Pacemakers","Al-Ahdab, S.","Serd?n, W. (mentor); Lotfi, R. (mentor)","2009","When the heart does not function properly, an artificial pacemaker is needed to correct the heart beat. However, more functionality at limited budget requires less power per function. Therefore, the power consumption of the pacemaker has to be reduced. The analog to digital converter in the pacemaker consumes the largest amount of power in the front-end, called the sense amplifier. Hence, an ultra low power ADC is . In this work, the IECG signal is filtered by band pass filter 50mHz-100Hz. Then, the signal output of the filter is converted to current by transconductance cell(Gm). The output of the Gm-cell is digitized by a Current Successive Approximation ADC. Circuit Simulation predict the overall system consumes the lowest power,416nW reported when compared with the state of the art.","","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","","",""
"uuid:5f7ba046-3a5c-46bb-8368-896a88f5e4a7","http://resolver.tudelft.nl/uuid:5f7ba046-3a5c-46bb-8368-896a88f5e4a7","Implementing Texture Feature Extraction Algorithms on FPGA","Roumi, M.","Gaydadjiev, G. (mentor); Shahbahrami, A. (mentor)","2009","Feature extraction is a key function in various image processing applications. A feature is an image characteristic that can capture certain visual property of the image. Texture is an important feature of many image types, which is the pattern of information or arrangement of the structure found in a picture. Texture features are used in different applications such as image processing, remote sensing and content-based image retrieval. These features can be extracted in several ways. The most common way is using a Gray Level Co-occurrence Matrix (GLCM). GLCM contains the second-order statistical information of neighboring pixels of an image. Textural properties can be calculated from GLCM to understand the details about the image content. However, the calculation of GLCM is very computationally intensive. In this thesis, an FPGA accelerator for fast calculation of GLCM is designed and implemented. We propose an FPGA-based architecture for parallel computation of symmetric co-occurrence matrices. Experimental results show that our approach improves 2x up to 4x the processing time for simultaneous computation of sixteen co-occurrence matrices.","image processing; feature extraction; texture; FPGA","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Computer Engineering","","Computer Engineering","",""
"uuid:0c0a5052-f76c-4ed8-8615-ec45c2870cb2","http://resolver.tudelft.nl/uuid:0c0a5052-f76c-4ed8-8615-ec45c2870cb2","Route determination in disaster areas: Using predictions and introducing the option to wait to improve routing results","Visser, I.","Van Oosterom, P.J.M. (mentor); Quak, C.W. (mentor); Köbben, B.J. (mentor)","2009","Disasters caused by human action or nature are part of life. Preventing disasters from occurring is often not possible. Lives can be saved or lost depending on our response to the disaster. Determining the fastest route to the people in need is therefore important. The determination of this fastest route is however not straight forward, since the environment the route is determined in has become chaotic as a result of the disaster. In this research attention focuses on ways to take the circumstances in the environment into consideration in an automated way. A distinction is made between changes that can be predicted and changes that cannot be predicted. Based on literature the latter turns out to be done best by choosing a process of re-evaluating the route determined. Based on the degree of dynamism a static, semi-static, iterative or dynamic approach can be taken to this re-evaluation. In a static approach the route is determined only once based on the most current information at that time. When the circumstances change re-evaluation of that determined route can take place every time a change occurs (semi-static), every couple of minutes (iterative) or constantly (dynamic). In this research a preference was given to use a combination between the semi-static and the iterative approach. This results in a re-evaluation after a number of changes have occurred and if there are only little changes the re-evaluation should take place after a set time. The incorporation of predictions in the algorithm is a second focus area. By incorporating predictions one is able to anticipate changes to the network and take them into consideration in the route determination process. Incorporating predictions on plume movement and bridge openings and closings introduces also a need to balance between travelling extra kilometres and waiting. To investigate the implications of incorporating predictions into the routing process a routing algorithm was designed. The Dijkstra algorithm was adapted to read the closing times from a file and decide whether it is better to wait or take an alternative route. Tests show that the estimation of travel times are more accurate when these are created with the algorithm that incorporates predictions into the routing process. Based on this research it is concluded that using the adapted algorithm routes can be determined that will prove to be faster and safer than the result of a shortest path calculation based only on the travel costs in the network.","","en","master thesis","","","","","","","","","OTB Research Institute for the Built Environment","GIS Technology","","GIMA","",""
"uuid:1999a3fb-36c2-4898-95a4-bc2040858780","http://resolver.tudelft.nl/uuid:1999a3fb-36c2-4898-95a4-bc2040858780","DEMO applied to Financial Services","Boedhram, V.R.K.; Algoe, S.S.R.W.","Dietz, J.L.G. (mentor)","2009","Often organizations do not exactly know what they desire, when it comes to information systems. Professional companies like ForMetis are needed to give advice and design tailor made information systems for organizations that have the need of it. To do so, one usually uses a software developing methodology. ForMetis has developed such a methodology with their ten year of experience (The ForMetis methodology). The DEMO methodology is a powerful tool that has proven itself successful in the modeling of organizations. DEMO methodology models the essence of an organization and claims to be coherent, consistent, comprehensive and concise. It is a very powerful tool for identifying transaction of an organization and also the communication with the external actors. DEMO can be used as an aid to design information systems and can check the completeness of these systems whether it covers the essential business processes. The ForMetis methodology consists of the following phases: planning, analysis, design, implementation and system. The analysis and design phase are the most important phases. In these phases requirements are retrieved in an informal way and are written on large sheets, which are not reusable. Informal specifications are made and often the implementation is the specification. The new, so called F-DEMO methodology was discussed and a postmortem case (intermediary) was used to illustrate the added value of DEMO. The new methodology is the ForMetis methodology extended with DEMO in the analysis and design phase. In these phases the Construction Model, Proces Model and the State Model are added. These models are a valuable addition to the derivation of requirements and the making of specifications. In order to evaluate the use of F-DEMO a survey was held to check how many of the findings that were raised when producing the information system at the intermediary could be prevented. The findings were categorized in implementation, requirements, usability, misunderstandings, wishes and irrelevant types. From all these findings 33,1 percent could be prevented using the new methodology. The project time is also reduced. Therefore, the recommendation is to start using the F-DEMO methodology in future projects.","DEMO; Financial Service; Services; Business Processes; Business; Intermediary; Software Development; Information System; Methodology; Electronic Dossier","en","master thesis","","","","","","","","2009-08-28","Electrical Engineering, Mathematics and Computer Science","Software Technology","","","",""
"uuid:2ae8b406-6026-4ac0-88f4-33fb052c2dae","http://resolver.tudelft.nl/uuid:2ae8b406-6026-4ac0-88f4-33fb052c2dae","Orbital stability assessments of satellites orbiting Small Solar System Bodies","Ruevekamp, S.","Noomen, R. (mentor); Ambrosius, B.A.C. (mentor)","2009","This thesis presentation will discuss stability assessments of orbits around asteroids, with in particular the asteroid Eros. The gravity field of an asteroid can be estimated using different techniques. For the thesis work presented the Polyhedron, Spherical Harmonic Expansion and Triaxial Ellipsoid methods are implemented on the Eros case. The differences in performance of the different gravity field modelling techniques will be discussed. The irregularity of the gravity field of Eros will have consequences on the orbital stability of satellites orbiting Eros, the influence of this irregularity will be estimated. Furthermore, the influence of the Solar Radiation Pressure and Third-body Perturbing forces on the stability of orbits around Eros will be determined. With the help of the Monte Carlo method and the Particle Swarm Optimization method a search is performed to find stable orbits within the vicinity of Eros.","stability of orbits","en","master thesis","","","","","","","","2009-12-08","Aerospace Engineering","Space Engineering - Astrodynamics and Space Missions","","","",""
"uuid:0cbff722-f550-46d9-8c6b-3a0c8dd51218","http://resolver.tudelft.nl/uuid:0cbff722-f550-46d9-8c6b-3a0c8dd51218","Regeneration of zeolites used for ammonium removal from anaerobic groundwater","Mikkers, Y.","Van Dijk, J.C. (mentor); Heijman, S.G.J. (mentor); De Vet, W.W.J.M. (mentor); Gascon, J. (mentor)","2009","Research performed of the last decades in the waste water treatment field has shown the ability of zeolites to adsorb ammonium via ion-exchange. Recent research has proven that zeolites might also be capable to remove the lower concentrations of ammonium present in groundwater to the for drinking water required standards. This makes it a promising technique as replacement for the traditional biological treatment. Still there is not much known about the effect of multiple regenerations with the different types of regenerant on the adsorption capacity and the durability of the zeolites. This research focuses on the chemical regeneration of zeolites which have been used to remove ammonium from anaerobic groundwater. The main goals hereby have been: - The determination of the effect of multiple regeneration on the ion -exchange capacity of the zeolites - The testing of the effectiveness of two types of regenerant: NaOH and NaCl - To see whether it is possible to reduce the amount of chemicals used for regeneration by reusing the regenerant. Because the adsorption experiments have been done with anaerobic water, an extra objective has been to investigate whether ammonium adsorption is hindered by the presence of Fe2+. A 4 column set-up has been designed in which two types of zeolite, clinoptilolite and aqualite, have been used. At a drinking water treatment plant a side stream of the influent of their rapid sand filters was used as influent for the columns. Two columns (one of each material) have been regenerated with 0,1 M NaOH, the other two with 1,8 M NaCl that was being recirculated.By monitoring the influent and effluent concentration of both ammonia and Fe2+, breakthrough curves could be determined. By comparing these, the impact of the regenerations on the adsorption capacity could be established. Extensive analyses of the used regenerant showed which ions were affected by regeneration and how much regenerant was actually used per regeneration. In the end the zeolites have been loaded and regenerated 11 times. The NaCl also has been used 11 times. Hereby it has been determined that the zeolites do loose some of their ion-exchange capacity by regeneration. This loss is the biggest after the first regeneration. After that the adsorption capacity fluctuates around 80% (NaOH) and 70% (reused NaCl) of it original capacity. The fluctuations are caused by changing lengths of the adsorption phase while the regeneration period stays constant. The reused NaCl shows a higher loss in capacity than the NaOH in combination with a higher chemical usage. From economical point of view NaOH is more feasible. The effect of the extreme pH on the zeolites has not been investigated though. It has been possible to reuse the regenerant and still obtain reasonable results. Whether that really is a reduction of the used chemicals, is not completely clear because no comparative study with single use NaCl has been performed. There has been no evidence that the presence of Fe2+ in the source water interferes with the ammonium adsorption. The positive effect that was found is that the iron is removed by the zeolites to great extent as well.","zeolites; waste water","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Watermanagement","","Sanitary Engineering","",""
"uuid:399fb1c6-189a-4f07-ae9c-81112ab97268","http://resolver.tudelft.nl/uuid:399fb1c6-189a-4f07-ae9c-81112ab97268","RFID in the supply chain","Van Hoff, A.A.J.","Van den Berg, J.F. (mentor); Vranken, J. (mentor); Duin, J.H.R. (mentor); Kroon, J. (mentor); KPN (contributor)","2009","","","","master thesis","","","","","","","Campus only","","Technology, Policy and Management","","","","",""
"uuid:52e442e0-de90-4446-b3af-01f49d0833b5","http://resolver.tudelft.nl/uuid:52e442e0-de90-4446-b3af-01f49d0833b5","Methanol Fuel Cooking","Koppes, R.J.","Weijnen, M.P.C. (mentor); Stikkelman, R. (mentor); Jonker, M. (mentor)","2009","","","","master thesis","","","","","","","Campus only","","Technology, Policy and Management","","","","",""
"uuid:94e3dae7-1eab-4780-8dc5-c648c68e2bd0","http://resolver.tudelft.nl/uuid:94e3dae7-1eab-4780-8dc5-c648c68e2bd0","Numerical simulations of laminar flames relevant for a Jet-in-Hot-Coflow burner","Van der Houwen, M.","Roekaerts, D.J.E.M. (mentor); Sathiah, P. (mentor)","2009","","","en","bachelor thesis","","","","","","","","","Applied Sciences","Multi-Scale Physics","","","",""
"uuid:e551171e-ac6d-470f-a29a-193c7c9f2ace","http://resolver.tudelft.nl/uuid:e551171e-ac6d-470f-a29a-193c7c9f2ace","Occlusion filling in depth-image-based rendering","Overes, J.J.","Heynderickx, I. (mentor)","2009","With the LDV format, it is possible to broadcast 3D content existing of a 2D image and the corresponding depth map. The display system can render this information into two or more views, which can be shown to the users. During this shifting, holes with no content occur in some or all the views. These holes need to be filled to get a better image quality. The process of filling these holes is named de-occlusion, and there are different methods available. Three perceptional experiments were done for testing some methods for de-occlusion. The tested methods were background extrapolation, occlusion layer, mirroring, copy background and depth map filtering. The first two experiments used stimuli synthesized with only two depth levels, a foreground plane and a background plane. In the first experiment, four different background contents were used and in the second, two. The foreground objects stayed the same in the experiments. The third experiment included more realistic content in addition to the two depth level synthetic content. Beside the background extrapolation and mirroring, a newly designed algorithm was used which is a combination of both and a vertical background extrapolation algorithm. Depending on the texture of the content around the hole, one of them is applied. In all the experiments, the images were rendered with two disparities, resulting in more or less depth in the images. In all experiments there was a dependency of the preferred algorithm on the content, which is why the combination algorithm was designed for the third experiment. In the first experiment a dependency on screen disparity was found, but not in the other experiments. The differences in preference between the algorithms were smaller for the realistic content than for the synthetic content. The holes were smaller in case of the realistic content because of smaller depth changes in the content. Therefore it was more difficult for the participants to see differences between the algorithms.","3d; occlusion; hole filling; depth-image-based rendering; dibr; layered depth video; ldv; de-occlusion","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Man-Machine Interaction Group","","","",""
"uuid:f2ecf719-d8d4-4197-be07-1822e84f6968","http://resolver.tudelft.nl/uuid:f2ecf719-d8d4-4197-be07-1822e84f6968","VHDL to SystemC: The Design of a Translator","Schoneveld, G.J.","Van Leuken, T.G.R.M. (mentor); Van der Veen, A.J. (mentor)","2009","VHDL and SystemC are both languages to describe or model circuits and systems. Reasons could exist for wanting to translate a model in VHDL to an equivalent model in SystemC. A system in SystemC can be needed for modeling a system with a software part, for a faster simulation, or because some tools only support SystemC. This thesis presents a tool that performs this translation from VHDL to SystemC. The tool is constructed like a regular compiler: It consists of a front-end that reads and analyzes VHDL code and a back-end that generates SystemC code. The front-end came from the FreeHDL project and we have made the back-end ourselves. The back-end generates SystemC code by traversing the tree that comes from the front-end. We have validated that the tool is suitable for simulation purposes and we have verified that the tool translates VHDL without problems in most cases we have seen in the wild.","VHDL; SystemC; translator; converter; compiler","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","","",""
"uuid:839ac924-ff8d-43b6-ab64-a5b55661dae4","http://resolver.tudelft.nl/uuid:839ac924-ff8d-43b6-ab64-a5b55661dae4","Three dimensional model of a single cell in a alginate construct","Van den Hoogen, F.G.P.","Van Keulen, A. (mentor)","2009","In cell experiments there is an interest to acquire information how a cell responds to external loads. In gel studies these cells are imbedded in gel and the gel is deformed externally. Because the gel is deformed, the cells inside the gel will deform as well. In order to capture the deformation of the cell a confocal microscope is used. A confocal microscope can create stacks of images which visualize a three dimensional environment. Due to the make up of most gelling materials the material around a cell is inhomogeneous. Because of this inhomogeneity of the gelling material there is a need to capture the deformation field around a cell. In order to capture this deformation field the gel was filled with microbeads. These microbeads need to be coated with fluorescent material. Otherwise, it would be impossible to observe them with a confocal microscope. After these images were captured, they are subjected to image analysis to convert the information from the images into data. This data is the exact location of each bead in the field of view. The position of the microbeads in the deformed state and the undeformed state can be used to calculate the displacement of each individual bead. The displacement of the microbeads can be used to create models of the displacement field. The displacement field is used to derive the deformation field. The results of these models depends on the mathematics used to calculate these models. In order to quantify these models, the estimate of the standard deviation is used to calculate the accuracy of these models. However, these results leads to the idea there is an inaccuracy, which in itself is reason for further investigation. This investigation focuses on where a confocal microscope would create its greatest error. In order to calculate this error a matlab model was created which simulates a microbead moving through a sensor field, using this method the error of a microbead displacing through such a field can be quantified. The results of this matlab model showed that the error was significantly higher in one direction (z-direction which corresponds to the depth of the experimental sample) compared to the other directions. Due to this error a new model is used in which all of the displacements from this direction are discarded and all the locations of this dimension are projected into one plane.","three dimensional model; alginate construct","en","master thesis","","","","","","","","2010-01-15","Mechanical, Maritime and Materials Engineering","Precision and Microsystems Engineering","","","",""
"uuid:78ff72ca-2d06-467b-aa61-561947814a46","http://resolver.tudelft.nl/uuid:78ff72ca-2d06-467b-aa61-561947814a46","Residuele stromingen in een getijdenkanaal ten gevolge van de bodemwrijving","Van de Sande, G.E.M.","Schuttelaars, H.M. (mentor); Heemink, A.W. (mentor)","2009","Met behulp van een wiskundig model het bepalen van de invloed van de bodemwrijving op de residuele stroming in een open kanaal.","","nl","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","","",""
"uuid:bc895bba-090f-4ba9-b597-f84ebaff68ec","http://resolver.tudelft.nl/uuid:bc895bba-090f-4ba9-b597-f84ebaff68ec","Design of Fault Tolerant Energy conversion System for Increasing Wind Turbine Reliability","Nie, L.","Polinder, H. (mentor); Shrestha, G. (mentor)","2009","Wind energy promises to become an important source of energy in the near future. Penetrating large-scale wind power into power systems presents a lot of challenges to power system operators, generation companies and wind turbine manufactures. In order to design less expensive and more efficient wind turbines, manufacturers have tried a lot of possibilities. However reliability is also an important issue. For this reason much attention needs to be paid to the reliability improvement. In the beginning, this thesis introduces and discusses modern wind turbines, gives failure rates to express the reliability, analyzes problems and the most critical subassemblies of wind turbines, and gives the possible methods to make wind turbines more reliable. For electrical part of wind turbine, generator is a crucial component. In this thesis a fault tolerant energy conversion system was designed to meet the specification. With certain faults the system can continue operating and output power. Therefore the reliability of wind turbines is increased. Finally the design procedure, and comparisons of this fault tolerant generator system and conventional generator system are given.","fault tolerant; generator system; wind turbine","en","master thesis","","","","","","","","2009-09-07","Electrical Engineering, Mathematics and Computer Science","Electrical Power Engineering","","","",""
"uuid:d7afed76-8f00-4f78-bbb0-193e30d7afc0","http://resolver.tudelft.nl/uuid:d7afed76-8f00-4f78-bbb0-193e30d7afc0","A noise subspace approach for localization","Aqeel, S.","Leus, G. (mentor)","2009","Wireless sensor networks are becoming increasingly popular due to their low cost and wide applicability to support a large number of diverse application areas. Localization of sensor nodes is a fundamental requirement that makes the sensor data meaningful. Energy and cost constraints only allow to equip a few nodes with a GPS device and to localize the remaining nodes with the help of these known locations and a pair-wise range measurements. Multidimensional scaling is an attractive localization technique due to a closed-form solution. It however requires pairwise measurements between all nodes to obtain the unknown node coordinates. In this thesis we investigate the feasibility of an analytical solution when some of the dissimilarity measurements are missing. We propose a least squares method to obtain unknown node positions by projecting the squared distance matrix onto the noise subspace of the weight matrix. We evaluate the proposed method for fully connected, and partially connected networks. We show that the proposed method determines the absolute node locations for a fully connected sensor network. For partially connected networks, though it is infeasible to obtain the global node locations using our method, yet we present scenarios where relative node locations can be obtained. }","WSN; Localization; Partially Connected Networks","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","","",""
"uuid:f2f7fa2f-288c-44a0-b644-4424bd957fae","http://resolver.tudelft.nl/uuid:f2f7fa2f-288c-44a0-b644-4424bd957fae","Het beperken van (reis)tijdverlies in de zakelijke dienstverlening: Of hoe men de arbeidstevredenheid en het aandeel van declarabele uren vergroot","Otto, R.","Sanders, F.M. (mentor); De Boer, E. (mentor); Zuurbier, F.S. (mentor); Baggen, J.H. (mentor); Kop, F. (mentor)","2009","","","nl","bachelor thesis","","","","","","","","","Civil Engineering and Geosciences","Transport & Planning","","","",""
"uuid:3a53a0ff-4279-4492-8eee-5a47da9aad40","http://resolver.tudelft.nl/uuid:3a53a0ff-4279-4492-8eee-5a47da9aad40","Silicon MEMS Micro-Evaporator","Hao, J.","Mihailovi?, M. (mentor); Rops, C.M. (mentor); Creemer, J.F. (mentor); Sarro, P.M. (mentor)","2009","","Silicon; MEMS; Micro-Evaporator","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","","",""
"uuid:8d7ce23b-6875-4e6e-894e-62f394360f7e","http://resolver.tudelft.nl/uuid:8d7ce23b-6875-4e6e-894e-62f394360f7e","Eddy Current Losses Calculation in Rotor Back Iron and Magnet for Concentrated Winding Permanent Magnet Generator","Firmansyah, M.","Jassal, A.K. (mentor); Polinder, H. (mentor); Lehaye, D. (mentor)","2009","The concentrated winding is proposed to replace the distributed winding due to the advantages in a manufacturing process. It is easily wounded by a machine in the former and the impregmentation process that can be carried out separately for each individual coil. These advantages can lead to the automation process in winding processes, reduced time and cost in generator manufacturing. One of the problems of the concentrated winding generator is eddy current losses due to the fact that air gap flux in the concentrated winding contains much more harmonics compared to the distributed winding. These losses should be kept in within the acceptable level of heat removing capability of the generator. Otherwise, higher temperature of magnet could influences the remanence flux of the permanent magnet. In this study, two methods of eddy current losses calculation, analytical and finite element (FE), are presented. Finite Element Method has some advantages due its capability to handle the geometric problem and non linear material which is difficult to incorporate in analytical calculation","Eddy Current Losses; Concentrated winding; Back Iron; Magnet","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Electrical Power Engineering","","","",""
"uuid:11c4a7b4-85a4-4164-bd9b-dd835914fc50","http://resolver.tudelft.nl/uuid:11c4a7b4-85a4-4164-bd9b-dd835914fc50","Milleniumdoelen toepassen in game development: De weg naar Microsoft's Imagine Cup","Van Wijk, F.E.; Van den Heuvel, J.T.A.; Stuursma, R.W.A.","Bidarra, A.R. (mentor); Huijser, R. (mentor)","2009","Beat³ is een computerspel voor alle leeftijden, waarbij de speler woorden moet vinden in een woordveld en deze zo snel mogelijk moet selecteren. Omdat dit spel voor de Game Development competitie van Microsoft's Imagine Cup is gemaakt, zijn de acht millenniumdoelen verwerkt in het spel en heeft deze een sterk educatieve waarde. Daarnaast is een sterke gameplay, gebaseerd op visuele en vooral auditieve terugkoppeling één van de sleutelelementen van Beat³. Beat³ is gemaakt met Microsoft Visual C# 2008, Microsoft XNA Game Studio 3.0 en de Cannibal Game Engine. Beat³ is zowel speelbaar met het toetsenbord als de Xbox360 controller en kan gespeeld worden door meerdere spelers. Tijdens het ontwikkelen, hebben we gebruik gemaakt van de Scrum methode. Deze is vanwege ons complexe studieschema niet geheel tot zijn recht gekomen. De deelname aan de Imagine Cup is gestrand in de halve finale, maar heeft wel een mooie leerzame ervaring voor het team opgeleverd.","imagine; cup; 2009; beat³; cube; xna; microsoft","nl","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Mediamatics","","Media en Kennistechnologie","",""
"uuid:43e5dd6e-39d8-4710-8042-8e4620f8baa1","http://resolver.tudelft.nl/uuid:43e5dd6e-39d8-4710-8042-8e4620f8baa1","Hybrid Rowe cell for measurement of complex conductivity","Shirasagi, S.","Ngan-Tillard, D. (mentor); Ponziani, M. (mentor)","2009","Peat is sediment consisting of incompletely decomposed organic matter deposited in swamp and marsh. It has served for a long time as benefits for human beings. Meanwhile, it has posed huge challenges to geotechnical engineers because of its unique characteristics such as anisotropy, low stiffness, high compressibility and strong creep susceptibility. In order to realise more effective and efficient site investigations, it is highly expected to apply geophysical techniques as well as core-boring, CPTs, sampling and laboratory tests because the techniques promise to be great contributions not only for two- or three-dimensional mapping but also for accurate interpretation of its physical, chemical and engineering properties in non-destructive way. Then, a new apparatus has been developed, called hybrid Rowe cell. It combines the functions of a traditional hydraulic cell and an electrical capacitor. This can simultaneously measure electrical properties and physical, mechanical and hydrological properties of soil samples, allowing to investigate their correlation accurately. This work focuses on the study of the applicability and calibration of the new hybrid cell, and the relationship between electrical conductivities of bulk peat and pore water which saturates the sample. The applicability of the hybrid cell was examined by using water as calibration. The results were then compared with values reported earlier and the experimental set-up was also compared with similar one found in literature. As a result, it was proven that the new cell successfully prevented electrode polarization and was applicable for this type of measurements. The electrical measurements on peat showed a relationship between the electrical conductivities of bulk peat and pore water which could be well predicted by a model previously developed for peat as well as the modified Archie’s law. In addition, the modified Archie’s law could be considered to be a persuasive model for the electrical behaviours observed in this study. For the future research, it is highly expected that the frequency of input currents is extended to lower range (< 20 Hz), input electric currents are properly controlled to avoid non-linear effects, and also hydraulic consolidation tests are performed in parallel with electrical measurements.","Rowe cell; electrical conductivity; electrical double layer; induced polarisation; Archies law; peat; hydraulic conductivity","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geotechnology","","Geo-Engineering","",""
"uuid:e5fb890e-4446-4367-80b5-e4b7768f36d3","http://resolver.tudelft.nl/uuid:e5fb890e-4446-4367-80b5-e4b7768f36d3","Improving Quality of Electron Microscopic Images Using Post-Processing Filters","Arikan, S.","Heynderickx, I. (mentor)","2009","Electron microscopy makes it possible to magnify samples at almost atom level by using electron beams to scan the sample. These images could be improved in terms of noise and sharpness. In this research we looked into the possibilities to use post-processing filters for improving the quality of electron microscopic images.","electron microscopy; electron microscope; scanning electron microscope; SEM; image quality; post-processing; image processing; bilateral filter; deconvolution; denoising; sharpening","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Mediamatics","","","",""
"uuid:dfdd6366-f312-409d-aa94-652cac6795df","http://resolver.tudelft.nl/uuid:dfdd6366-f312-409d-aa94-652cac6795df","Cellular Wall Design with Parametric CAD Models","Li Luyuan, L.","Pasterkamp, S. (mentor); Hoogenboom, P.C.J. (mentor); Borgart, A. (mentor); Schuurman, M. (mentor); Vambersky, J.N.J.A. (mentor)","2009","The primary structure of the cellular wall of Shanghai Natural History Museum (SNHM) can be defined as a grid structure on a single curved surface (developable), with a cell-like configuration. The shape of the wall (surface) is defined by two free-form curves, which explicate a ruled/lofted surface. The cellular wall is one of the most captivating elements in the SNHM design. Besides its architectural appearance it also has an important function in the structural system to distribute both horizontal and vertical forces. It requires large efforts to create the optimal configuration that meets both its architectural and structural objectives. This includes the structural material of the cellular wall. The objective of this Master’s thesis research is to explore an ‘optimal’ grid structure for the cellular wall. Since the geometry of the wall surface is determined in advance, the design exploration will focus on the grid/pattern generation, and the basic purpose of optimization is to explore a pattern in which elements are tuned up by different design constrains (requirements). The chosen approach is to design the structural cellular wall by parametric CAD modeling via parametric design tools (GenerativeComponents, etc). These parametric associative tools generate the complex geometry by applying rules and capturing relationships among model elements and link the geometrical data to the analytical and drafting software. The typical modeling process and advantages of this approach will be exampled by a case study of Nautilus shell model (Chapter 4.2). Chapter 2-4 will give some background information based on literature study, including the main topics of: SNHM project information and structural optimization proposals, Free-form/Special structural design technologies, and parametric associative design approach. In Chapter 5, the design alternatives will be studied: a design exploration diagram will be draw to clarify the design constrains and their requirements, following the proposal of structural parameters. Various structural materials with construction methods will be compared, and some references study for the structural patterns and grid structures will be recorded. Study of grid structures with basic grid types (rectangular, triangular, hexagonal) will be performed to high-light the structural behaviors and design principles of cell-like grid. In Chapter 6 & 7, cell-like pattern exploration by parametric CAD modeling will be conducted, which includes building parametric CAD models and structural analysis. According to the grid generation technologies (pre-studied in Chapter3), the parametric models will be created in 3 categories: 1- Structured grid models Structured grids have advantages of easy to implement and good efficiency, but various grid sizes can’t be introduced or the grid cells will deform too much. Regular grid will result in un-evenly distributed loads and stresses under the design load cases. 2- Modified structured grid models A- Insert triangular elements, following the stiffness requirement: this method increases the total stiffness and creates moment-free nodes, but at the same time, it's easy to cause stress concentration. B- Locally double-up hexagonal grid, following the strength requirement: The implementation of double-up grid is easier and results in a configuration of fractal geometry (local double rhythm). 3- Unstructured grid models Unstructured grid models are generated via Voronoi Diagram. Some experiments have been done to find efficient methods to generate a point-set (grid points) and generate grid on the wall surface. The ‘attract & repel’ method and UV mapping tool were implemented in this design case. When the local densities of the grid structure are fine tuned up with the imposed load cases (structural requirements), the material will be used in an efficient way, which can be read from the analysis results – better forces distribution and low stress level. The local densities/grid sizes are changed smoothly, which brings nice design aesthetic. [Suggestion] In the modified structured grid models, by locally cutting-out triangles will cause stress concentration, which cannot efficiently increase the total stiffness. A suggested method is to corporate Voronoi diagram with the associated Delaunay triangulation, efficiently getting advantages of the stiff triangle components. Member design Another method is to apply different profiles (crosssections) for individual beam elements according to the structural requirements. Although it will bring extra requirements for construction – carefully coded and stored, this approach provides quite an efficient structure. Chapter 8 concludes the findings of this Master’s thesis research as conclusions and recommendations for further research.","","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","","",""
"uuid:bceb21b7-cd1e-4dfc-95cf-a76908c3dd9c","http://resolver.tudelft.nl/uuid:bceb21b7-cd1e-4dfc-95cf-a76908c3dd9c","Consultancy as business activity to stimulate development of University Spin Offs","Duursma, F.D.","Trott, P. (mentor); Scholten, V.E. (mentor); Hartman, L. (mentor); Groenleer, M.P. (mentor)","2009","","","","master thesis","","","","","","","","","Technology, Policy and Management","","","","",""
"uuid:026c9807-3632-4272-b69f-a3b6f5452607","http://resolver.tudelft.nl/uuid:026c9807-3632-4272-b69f-a3b6f5452607","WideBand PLL as a clock multiplier","Donmez, A.","Lassche, G. (mentor); Long, J. (mentor)","2009","In this study, the theory, design and analysis of PLL circuits are examined and a 4.9GHz ~ 5.9GHz Wideband CMOS PLL Frequency Synthesizer is designed and implemented in IBM 65nm digital-process. The objective of this thesis work is to understand the limitations in Wideband PLL systems when the application frequency range extends to multiple gigahertz. This study explores the inband noise contribution of PLL blocks and also investigates solutions to high frequency operation of phase frequency detectors and charge pumps. A high frequency phase-frequency detector topology is presented. With this topology, static phase error of the loop remains close to zero even if the charge-pump has a large amount of current mismatch. A design which is capable correct operation up to a frequency 1.74 GHz is designed. A high frequency differential charge pump circuit with glitch suppression is presented. The VCO of the PLL is implemented with a mutlipath loop ring oscillator. The VCO has a better supply noise performance compared to conventional ring oscillators but however it is still not suitable for applications with noisy supply, thus off chip supply decoupling is used. VCO operates within 4.79GHz ~ 6.54GHz for all process corners. The frequency divider which is used from project library has a constant division ratio of 6. Entire PLL design consumes 14.9 mW from 1.2 V supply, under typical conditions. Total area of the PLL is 1 mm x 800 um including the pads.","Wide Band; PLL; Clock Multiplier","en","master thesis","","","","","","","","2009-09-03","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","","",""
"uuid:8d44eef0-1da0-47fa-b44e-cad4ab3e6a46","http://resolver.tudelft.nl/uuid:8d44eef0-1da0-47fa-b44e-cad4ab3e6a46","Optimization of interplanetary trajectories with deep space maneuvers - Model development and application to a Uranus orbiter mission","Molenaar, S.","Noomen, R. (mentor)","2009","","Deep Space Maneuvers; Orbital Mechanics; Genetic Algorithm Optimization","en","master thesis","","","","","","","","","Aerospace Engineering","Astrodynamics and Satellite Systems","","","",""
"uuid:77bb79d5-8909-40ec-8ae0-e8384594fcbf","http://resolver.tudelft.nl/uuid:77bb79d5-8909-40ec-8ae0-e8384594fcbf","Multivariable feedback control of a Dividing Wall Column","Van Diggelen, R.C.","Kiss, A.A. (mentor); Keesman, K.J. (mentor); Van der Woude, J.W. (mentor); Heemink, A.W. (mentor)","2009","","petlyuk; DWC; dividing wall column; MIMO control","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","","",""
"uuid:24fc2414-51c8-42cf-b173-1657ec30ad04","http://resolver.tudelft.nl/uuid:24fc2414-51c8-42cf-b173-1657ec30ad04","Effects of business incubation on knowledge acquisition of incubatees and incubatee performance","Benjamins, R.","Trott, P. (mentor); Scholten, V.E. (mentor); De Bruijne, M.L.C. (mentor)","2009","","","","master thesis","","","","","","","","","Technology, Policy and Management","","","","",""
"uuid:21123648-f4ba-43e2-bbe1-04d1890f2d5e","http://resolver.tudelft.nl/uuid:21123648-f4ba-43e2-bbe1-04d1890f2d5e","Adaptive Clock Scheduling for Pipelined Structures","Kuiper, B.","Cotofana, S.D. (mentor)","2009","With the advance of fabrication technology into the deep sub-micron era process parameter variations, temperature, and voltage fluctuations start to induce large variations into the delay of integrated circuits. The smaller the feature size the larger the variations become, and thus also their influence on the critical path delay of a logic stage in a pipelined structure. Traditionally, the critical path delay variations are dealt with by augmenting the critical path delay with a safety margin (over design) that is large enough to cover the worst case scenario. Due to the increasing variability the performance gap between this worst-case clocking method and the potential performance is increasing resulting into a massive underutilization of the technology. This thesis introduces a design for variability for pipelined structures called Adaptive Inverter Chain Based Pipeline (AICBP). It can observe and compensate for delay variations in pipelined structures. The main idea is to expose the data and the clock to the same variations such that the clocking of the registers is adapted to the delay of the logic. This results in a substantial reduction of the over design thus on a better utilization of the technology potential performance. Besides the hardware which can compensate for delay variations, the AICBP design also includes a number of smart mechanisms which can resolve timing errors and improve performance. The area overhead of the AICBP design is relatively small in comparison to other state-of-the-art proposals, since it does not require the augmentation of circuitry at the flip-flop level as is the case with some designs for variability. Some high level simulations have been done and these indicate an up to 46% performance improvement. However, this performance improvement depends heavily on the specific delay variations and the properties of the combinatorial logic. Two extensions to the basic AICBP design are presented in this thesis as well. One of these includes an advanced recovery mechanism and the other focuses on data dependent delay compensation techniques. These extensions allow the performance to be improved, but the cost in terms of area and also power is quite high.","","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","","",""
"uuid:bf960362-6fa2-4879-b036-a2d662f3297b","http://resolver.tudelft.nl/uuid:bf960362-6fa2-4879-b036-a2d662f3297b","Front-End for Composable Resource Sharing Using Latency-Rate Servers","Woldegebreal, G.","Akesson, B. (mentor); Goossens, K. (mentor)","2009","In this thesis, the design and implementation of an efficient front-end for composable resource sharing is presented. With composable re- source sharing, every application obtains a service that is not affected by interference from other applications that share the same resource. Since applications are shielded from interference, each one of them can be verified by simulation independently and integrated without reverification. This reduces the verification effort that would, other- wise, be tremendous. Our solution is based of Latency-rate (LR) servers, which are used to model service provided by a predictable resource. The front-end provides composable resource sharing when attached to a predictable resource. A series of tests have been carried out to verify that the front-end isolates applications from each other while sharing a re- source. The design has been synthesized for FPGA as well as ASIC on CMOS 90nm technology to estimate area and operating frequency.","Front-end; composable; predictable; resource sharing; memory controller","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Computer Engineering","","","",""
"uuid:045a4858-deaf-48b0-a9fb-6dfb1d357af2","http://resolver.tudelft.nl/uuid:045a4858-deaf-48b0-a9fb-6dfb1d357af2","Enterprise Ontology of the Flood Control Domain","Mongula, D.B.","Dietz, J.L.G. (mentor)","2009","Floods are among the most hazardous and destructive natural disasters with the potential to wreak havoc on humans, material assets, cultural wealth and ecological resources. Several countries have used different flood management and control measures both structural (e.g. constructing levees, dams, storm surge barriers) and non structural (e.g. applying spatial measures, developing flood forecasting and early warning systems) to reduce their vulnerability and exposure to floods. These flood management and control measures can be addressed using the safety chain concept. Originally, the safety chain concept consisted of four links: mitigation, preparation, response and recovery. Now, the safety chain concept is well adopted in different countries with slight adjustments. Multiple stakeholders and actors are involved in the various links of the safety chain. In many countries, these actors include the government (e.g. national, provincial and local), emergency services (police, fire brigades, medical aid) and the water authorities. However, many more actors are also involved. Due to the involvement of many actors in different activities, it is difficult to compare the construction and operation of Flood Control Domain in different countries. In line with the above problem, the objective of this thesis project is to develop an enterprise ontology that will show how the Flood Control Domain is constructed and operated by identifying the essential operations performed in the domain, highlighting the interrelationships between these operations and information objects that are relevant for the operations in the domain, and illustrating its use in the Netherlands and the United States. The literature research resulted in a concise overview of ontology and enterprise ontology. There are various definitions of ontology. In this thesis project, the chosen definition of ontology is: a formal, specification of shared conceptualization. The notion of ontology as applied in this document is the notion of system ontology whose main purpose is to understand the essence of construction and operations of complete systems; more specifically of enterprises. Enterprise ontology can be described as a conceptual model of an enterprise that is coherent, comprehensive, consistent and concise, and that only shows the essence of the operation of an enterprise model, independent from implementation and realization. The Design and Engineering Methodology for Organizations (DEMO) methodology was selected to develop the enterprise ontology for the Flood Control Domain. DEMO provides a step-by-step procedure that helps to derive the ontology of an enterprise in a systematic way. Following DEMO methodology, the starting point for developing enterprise ontology is the collection of all available documentation about the enterprise. Therefore, a thorough analysis of the Flood Control Domain was conducted through literature reviews, interviews and a case study. Based on the analysis of the Flood Control Domain, an Explanatory Case describing the domain was provided using the safety chain approach, which is described in five links: the pro-action, prevention, preparation, response and recovery. Based on the Explanatory Case, the Perfoma Analysis was conducted to capture the performa human abilities that concern the essential productions in an organization. On the basis of the Perfoma Analysis, the transactions, which represent the essential operations in the Flood Control Domain, were identified. These transactions and their specifications were presented in a Transaction Result Table (TRT). Next, the Construction Model of the Flood Control Domain was developed. The Construction Model shows the identified transactions, the initiator(s) and an executor for each of the identified transactions as well as the information links between the actor roles and the information banks. In the next step of this research, the interrelationships between the identified essential operations in the Flood Control Domain were shown. Here, the Process Model of the Flood Control Domain was constructed. In the Process Model, the logical sequence of steps for which a transaction is performed is provided; hence, the interrelationship between the transactions. The Process Model also enables every transaction pattern in the Construction Model to be seen, as well as the specific transaction pattern of the transaction type. Then, the information objects necessary for the organizations in the Flood Control Domain were presented using the State Model, which can be used as a data dictionary of an organization showing the object classes, the fact types, the result types and the existential laws. In the next phase of the research, the focus was to show how the developed enterprise ontology is used in the Netherlands and the United States. Here, the concern was to show the organizations in the two countries responsible for performing the identified transaction, also regarded as the essential operations, in the Flood Control Domain. In order to do this, the Construction Model was re-drawn whereby the abstract actor roles were replaced with the existing organizations in the Netherlands and the United States. In the final phase of this research, the thesis results were analyzed. In general, the developed enterprise ontology for the Flood Control Domain seems to be generic since most of the actors who acted as initiators and executor of certain transactions could be mapped to the existing organizations in the Netherlands and the United States. However, some differences were evident in the implementation of flood control operations in the Netherlands and the United States. Such differences could be seen in flood management activities. For instance, while a hierarchical relationship exists between the US Army Corps of Engineers and the local sponsors, such as the levee districts, a horizontal relationship can be seen between Rijkswaterstaat and the water boards in the Netherlands. Moreover, the analysis shows that due to the size of the two countries, the local governments in the United States have more roles and responsibilities as compared to the local governments in the Netherlands. The analysis highlights the differences between the two countries on the use of flood insurance policy. While the flood insurance policy is commonly used and highly emphasized in the United States in order to reduce flood losses, such a policy is not applicable in the Netherlands. The recommendations for future work include a mapping of the identified transactions to the applications or existing information systems both in the Netherlands and the United States, development of a high level Construction Model of the Flood Control Domain and the initiation of an Action Model. The thesis results should be shared with a large group of people and an ideal enterprise ontology should be developed for the Flood Control Domain that different countries can use to compare themselves with one another.","Ontology","en","master thesis","","","","","","","","2011-09-01","Electrical Engineering, Mathematics and Computer Science","Software Technology-Information System Design Group","","","",""
"uuid:9bdda531-7925-4e52-aa58-281314117dd9","http://resolver.tudelft.nl/uuid:9bdda531-7925-4e52-aa58-281314117dd9","Stability of morphological cells to dredging-dumping activities","Zimmermann, N.","Wang, Z.B. (mentor); Van Prooijen, B. (mentor); Ranasinghe, R. (mentor); Eelkema, M. (mentor); Stive, M. (mentor)","2009","The Westerschelde estuary in the South-West of the Netherlands displays two meandering flood and ebb channels separated by shoals. The system of flood, ebb channel and shoal between two channel crossings form a morphological cell. The stability of the serial cell system formed by the Westerschelde is important for the navigation route to the port of Antwerp. Wang and Winterwerp (2001) proposed a simplified model to predict the evolution of the flood and ebb channel. They suggest that the cell will remain stable if dredging-dumping activities do not exceed a certain limit. Hibma et al. (2003) modelled successfully morphological cells with the process-based model Delft3D. This report investigates the stability of morphological cells in estuaries by comparing stability results of the process-based model Delft3D to the simplified model of Wang and Winterwerp (2001). Settings of Hibma et al. (2003) are used to generate an equilibrium state suitable for stability analysis. Sediment is then dumped continuously in the flood or ebb channel at various rates to assess stability. The cell geometry, flow and sediment transport characteristics are used to review the applicability of assumptions underlying the simplified model. Results of the two models are confronted to gain further insight into the cell behaviour. Results are applied to the Westerschelde estuary to discuss the safety of the current dredging-dumping strategy. The study shows that the behaviour of the cell can be described in terms of channel dominance. It suggests that the current dredging-dumping strategy in the Westerschelde is generally safe. It also highlights the need for more understanding and control of the outcome of a Delft3D simulation.","Westerschelde; estuary; morphological; cell; channel; stability; bifurcation; dredging; dumping; Delft3D","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Hydraulic Engineering","","","",""
"uuid:3087158a-0b38-49fc-bb76-f90c871f371a","http://resolver.tudelft.nl/uuid:3087158a-0b38-49fc-bb76-f90c871f371a","Relating biodynamic feedthrough to neuromuscular admittance: Understanding the effect of acceleration disturbances on manual control performance","Venrooij, J.","Mulder, M. (mentor); van Paassen, M.M. (mentor); Abbink, D.A. (mentor)","2009","Biodynamic feedthrough (BDFT) refers to a phenomenon where accelerations cause involuntary limb motions which, when coupled to a control device, can result in unintentional control inputs. The goal of this study is to increase the understanding of biodynamic feedthrough, with a focus on the influence of the neuromuscular system. Biodynamic feedthrough has been studied for many years, but its fundamental processes are only poorly understood. Many factors were reported to play a role in the occurrence of biodynamic feedthrough and many of these show mutual interactions. In several studies it was mentioned that the parameters of the neuromuscular system influence the occurrence of BDFT and that these can differ from person to person (inter-subject variability). However, only very little studies have recognized the variability in neuromuscular settings that a single person can express (intra-subject variability) and no known research was devoted to investigating this relation to date. In this study, it was hypothesized that BDFT is strongly influenced by the setting of the neuromuscular system, i.e. the neuromuscular admittance. This hypothesis was tested by performing an experiment in which both the neuromuscular admittance and the biodynamic feedthrough were measured using a motion-based simulator. The neuromuscular admittance was varied using three control tasks, each requiring a different level of admittance. The simultaneous measurement of admittance and biodynamic feedthrough was made possible by offering two disturbance signals that were separated in the frequency domain. The results show a strong dependency of biodynamic feedthrough on neuromuscular admittance. The obtained experimental data was used to develop a biodynamic feedthrough model, capable of describing BDFT for various settings of the neuromuscular system. The BDFT model was constructed by augmenting a neuromuscular model to account for the effect of motion disturbances. An advantage of the proposed modeling approach is that it considerably simplifies the process of parameterization of the BDFT model. In comparison to the measured data, the model proved to describe BDFT dynamics correctly for different subjects and different settings of the neuromuscular system, both in the frequency and in the time domain. However, the parameter values do not readily agree with results that were expected based on theory. Further research is required to investigate the implications of the model approach to the model’s physical interpretability.","","en","master thesis","","","","","","","","","Aerospace Engineering","Control & Operations","","","",""
"uuid:9c2b0263-dcaa-47be-a4e7-06a87752333a","http://resolver.tudelft.nl/uuid:9c2b0263-dcaa-47be-a4e7-06a87752333a","Urban Nomad In Urban Context In Kiev","Oh, S.","Oscar, O. (mentor); Marc, S. (mentor)","2009","Urban Nomade in Urban Conditions that citizens appropriate its place for domestic Acitivities","nomad; domestic activities","en","master thesis","","","","","","","","2009-11-19","Architecture","Architecture","","The Border Conditions In public building","",""
"uuid:c72e6c92-f1dc-43a0-97ae-1fdbcb41e496","http://resolver.tudelft.nl/uuid:c72e6c92-f1dc-43a0-97ae-1fdbcb41e496","Local Buckling Behaviour of a Corrosion Resistant Alloy Liner in Tight Fit Pipe due to Axial Compression","Fathi, N.","Currie, P.K. (mentor); Meek, J. (mentor); Zitha, P.L.J. (mentor); Gresnigt, A.M. (mentor)","2009","A promising possibility to reduce corrosion resistant pipeline costs is the concept of Tight Fit Pipe, which is a double wall pipe where a Corrosion Resistant Alloy liner is mechanically fitted inside a carbon steel outer pipe. The mechanical bonding of the Tight Fit Pipe is made through a thermohydraulic manufacturing process. Problem definition Buckling of cylinders subjected to flexural loads (applied to Tight Fit Pipe during cost effective reeling) correlates in a number of respects to buckling of axially compressed cylinders: in both cases the critical stresses (or strains) are of the same order of magnitude and the failure modes have the same characteristics. Results from the axial compression tests provided better understanding of the buckling behaviour of Tight Fit Pipe during bending and results from this thesis study have been used as input for a bending rig construction. Research The main objective of this thesis is to investigate, theoretically and experimentally, the local buckling behaviour due to axial compression of the Corrosion Resistant Alloy liner, whilst fitted in the outer pipe of the Tight Fit Pipe configuration. The liner of the Tight Fit Pipe as tested is first analysed when not fitted in the outer pipe. Secondly the liner is analysed when fitted in the outer pipe of the Tight Fit Pipe. The liner has a higher capacity in stress and strain when the liner is placed in the outer pipe, i.e. mechanically fitted, compared with the liner alone. Results, Conclusions and Recommendations [a.] Buckling of the liners (of Tight Fit pipes (TFP) used in the experiments), without the outer pipe, occurred outward in a single axi symmetrical wrinkle. [b.] The liners in the tight fit pipes, confined in an outer 12 ¾ inch pipes used in the experiments, buckle inward in a non-symmetrical wrinkle. [c.] Wrinkles (of liners confined in an outer 12 ¾ inch pipe) do not exceed 90º of the circumference. The wrinkles have an axis which is circumferential. Wrinkles do not tend to connect with each other if more than one is present at about the same height. [d.] The maximum force in the load - strain diagram was considered to be the point at which wrinkling occurred. There was a good agreement between the Finite Element (FEM) results and test results for the maximum force. The FEM results for the strain at the maximum force were much higher than in the tests. [e.] Buckling of a liner in a 12 ¾ inch pipe has a larger critical buckling force than a liner which is not confined in an outer pipe. This is due to the resistance to outward buckling. Bigger wrinkles must fit in a smaller radius which costs more energy than free outward buckling. This could also be the reason why the wrinkles do not tend to form as one big wrinkle in a 360 degrees radius. Outward buckling tend to occur in one axi symmetrical wrinkle. [f.] The buckling behaviour of the liner in the TFP is believed to be influenced by three different TFP properties: [f1.] Low or high fit (residual hoop stress), [f2.] Type of CRA (Material strength) and [f3.] Type of outer pipe used, seamless or UOE-pipe (Liner to outer pipe contact irregularities ) [f1] has been proven in the test results; [f2] and [f3] are still to be proven in future work.","Tight fit Pipe; Liner; TFP; Reeling; Finite Element; FEM; Axial Compression; CRA; Buckling; Oil Pipeline; Gas Pipeline; Corrosion; wrinkling; Buckle","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geotechnology","","","",""
"uuid:f4b5b6d0-8b00-44da-8011-cd664bfa96bd","http://resolver.tudelft.nl/uuid:f4b5b6d0-8b00-44da-8011-cd664bfa96bd","Effects of fines on mechanical behaviour of sandy soils","Lupogo, K.","Vos, B. (mentor); Ngan-Tillard, D. (mentor)","2009","In dredging works, fines are encountered in different ways. Fines can be produced during the cutting of rocks or can be found in natural deposited sand. The presence of fines in sand soil is generally recognized as problem in geotechnical engineering. It is believed that fines in a sand increases soil compressibility and tendency to creep. Also it is often assumed that the strength, stiffness, hydraulic conductivity and liquefaction potential of a soil increases with increasing fines content. Therefore, during tender phase of reclamation works, it is always recommended that the soil should contain minimum amount of fines 10% of fines. It has been recognized that the availability of soils which have small amount of 10% of fines is very rare. In most of projects soil with maximum amount of fines above 10% are encountered. The objective of this thesis is to investigate the mechanical behavior of sand soil with different amount of fines. The main interest is on the compressibility of sandy soils. The compressibility of sandy soil is investigated and their results are shown. A series of oedometer test for saturated silt sand mixtures is presented. During testing the following material were used River Maas sand and crushed sand, artificial silt (crushed quartz) and Belgium silt. The mixture were created by mixing River Maas sand and crushed sand with either artificial silt or Belgium silt as percentage of dry mass. Sand silt mixtures with fines contents of 7%, 10%, 15%, 20%, 25%, 30%, and 50%.The samples were prepared in different initial relative densities using slurry deposition methods. In oedometer the mixtures were loaded in interval of 3.5, 6.9, 13.9, 34.6, 69.8, 138.5, 277.1, 554.2 and 1108.3 kPa. Result shows that, the coefficient of consolidation of sand silt mixture increases with fines content from 7% and reaches the peak value at 15% then the coefficient of consolidation decreases with increase of fines contents. The compression index of silt sand mixtures decreases with increase on fines contents from 7% to 30% and then increases with increase of fines contents. The value of compression index for fines contents of 15 to 30% is low due to its highest packing density. The secondary compression on artificial silt sand mixture is very low it is between 0.001-0.004 but for Belgium silt sand the secondary compression is significantly higher. The difference in secondary compression is due to their difference in mineralogical composition and grain size and shape. It can be conclude that the presence of fines on sand does not increase the compression and secondary compression of the sand but it is improving it. Therefore for mixtures with fines content above 10% between 15 to 35% are useful for reclamation activities because of their low primary compression and low secondary compression.","silt; sand; silt sand; oedometer; stiffness; fines content","en","master thesis","","","","","","","","2009-09-30","Civil Engineering and Geosciences","Geotechnology","","","",""
"uuid:8a96521d-9778-40d9-aded-021b9ac54a0d","http://resolver.tudelft.nl/uuid:8a96521d-9778-40d9-aded-021b9ac54a0d","An Approach Spot Market for LNG?","Praet, R.","Weijnen, M.P.C. (mentor); Dijkema, G.P.J. (mentor); Correljé, A.F. (mentor); Chappin, E.J.L. (mentor)","2009","","","","master thesis","","","","","","","","","Technology, Policy and Management","","","","",""
"uuid:76e3a56a-a8b2-478c-ae04-dba5c6a13a2e","http://resolver.tudelft.nl/uuid:76e3a56a-a8b2-478c-ae04-dba5c6a13a2e","FPGA Hardware acceleration of co-occurring aberrations in aCGH data","Van der Leije, M.R.","Reinders, M.J.T. (mentor); Van Genderen, A.J. (mentor)","2009","Unbalanced transaction can lead to addition and deletions in genes, which can be an indication of tumor cells. This is measured with array Comparative Genomic Hybridization. To find co-occurring aberrations in DNA, an algorithm was designed. However the execution takes days to find these DNA aberrations. This thesis proposes a partial FPGA based design were the number of parallel computations can be increased. The FPGA communicates with a computer on a gigabit Ethernet, where on the FPGA a hardware based Ethernet controller is build. This design is scalable for FPGA’s, so its performance is linear to the size of the FPGA resources. On a XC4VFX12 device, a minimum speedup of a factor 3 and a maximum speedup of several hundreds is achieved.","FPGA; DNA","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Computer Engineering","","","",""
"uuid:f4b071c1-8e55-4ec5-86c6-a2d54c3eda5a","http://resolver.tudelft.nl/uuid:f4b071c1-8e55-4ec5-86c6-a2d54c3eda5a","Inversion of multi-transient EM data from anisotropic media","Werthmüller, D.","Hobbs, B.A. (mentor); Ziolkowski, A. (mentor); Slob, E.C. (mentor)","2009","Forward modelling demonstrates that resistivity anisotropy has a huge effect on Multi-Transient ElectroMagnetic step and impulse responses. The earth is never isotropic – even a stack of isotropic layers behaves anisotropically – and there is a great need to ccount for resistivity anisotropy in order to delineate the true target depth and target transverse resistance in ElectroMagnetic surveying. I account for resistivity anisotropy by (a) deriving apparent anisotropy formulae and using them together with apparent resistivities for a fast iterative inversion scheme, and (b) by including anisotropy into a 1D full waveform inversion scheme. Full anisotropic inversions result in much smoother models than isotropic inversions. Sharp resistivity boundaries result in anisotropy anomalies, as horizontal and vertical resistivities are not affected in the same way. Anisotropic inversion results yield a good indication of the present background anisotropy. Carrying out inversions with fixed anisotropies, e.g. determined in a free anisotropic inversion, can improve the result significantly compared with an isotropic inversion.","CSEM; Transient; Anisotropy; Inversion","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geotechnology","","Applied Geophysics","",""
"uuid:bcf5c5d8-e00e-430a-9684-1938a356cf0b","http://resolver.tudelft.nl/uuid:bcf5c5d8-e00e-430a-9684-1938a356cf0b","Discrete Element Modelling: The influence of High Hydrostatic Pressure on the Cutting Processes of Hard Rock","Parasie, N.","Alvarez Grima, M. (mentor); Van Baars, S. (mentor); Dijkstra, J. (mentor); Van Rhee, C. (mentor); Ngan-Tillard, D.J.M. (mentor)","2009","Seafloor Massive Sulfide (SMS) contains high levels of metals such as copper and gold. Water depths of 2000 up to 3000 meter make mining of SMS a challenge. Despite this, mining industry encourages research into feasible extraction methods of SMS, pushed by the high metal prices nowadays. This research focuses on the influence of hydrostatic pressure on the cutting process of hard rock. A 2D numerical model of the cutting process is created using discrete element modelling (DEM). The software package Particle Flow Code 2D (PFC2D) from Itasca Consulting Group is used. The rock material creation in PFC2D consists of reproducing numerically the physical UCS, biaxial and Brazilian tests executed on the benchmark material. SMS is the rock of interest for deep-sea mining, nevertheless Langmeil Sandstone is chosen as benchmark material. This consideration is taken because SMS samples are rare and no strength test results obtained on SMS samples are published. In addition the high heterogeneity of SMS makes their numerical modelling difficult. It was not possible to come up with a singular numerical rock sample matching the mechanical properties of the Sandstone for a large range of confining pressures (0 to 40 MPa). Therefore two samples were created: the first sample is valid for unconfined tests, the second sample is valid for confining pressures between 20 and 40 MPa. It appeared that the material unconfined compressive strength and elastic constants are independent of the particle size. The transition point from brittle to ductile failure is simulated successfully for the second rock sample. Three different cutting scenarios are studied: cutting of dry rock without hydrostatic pressure, cutting of dry rock under hydrostatic pressure and cutting of saturated rock. The boundary particle method is an algorithm capable of simulating hydrostatic pressure. This method applies a force similar to the hydrostatic load on each boundary particle of the sample. The method simulates the transition between brittle and ductile rock cutting successfully, by increasing the effective stress, while fluid and pore pressures are absent. The transition from brittle to ductile cutting is reached at a hydrostatic load of 20 MPa for the Langmeil sandstone. The cutting force (450 kN) obtained by the numerical model for the unconfined calibrated rock is compared with existing semi-empirical models. Goktan’s (1995) model (300 kN) provides the best match , Evans’ (1961) model (75 kN) underestimates the required cutting force. The horizontal cutting force increases with increasing hydrostatic pressure. The increase of hydrostatic load is mainly transferred into an extra load on the cutting tool in horizontal direction. The specific energy calculated from the cutting force obtained by the numerical model (4.9 MJ/m3) is in good accordance to the values for sandstone found in literature (5.5 MJ/m3). The influence of the tool shape, the cutting velocity and depth of cut on the cutting process of dry rock is modelled. The chisel pick tool shows to be more efficient than the pick point tool for shallow water depths. The difference in efficiency between these tools becomes smaller with increasing hydrostatic pressures. Measurement circles in PFC2D are able to register porosity changes during the cutting process. These measurements are used to estimate pressure differences in the crushed zone. This method provides a good qualitative insight in the development of pore pressures during the cutting process. Useful quantitative values were not obtained. The measurement circle method indicates that cavitation will not occur for high hydrostatic loads such as 20 or 30 MPa, which implies that the required cutting force will continuously increase for an increasing cutting velocity. The main recommendations are introducing the Biot poroelastic equations and heterogeneity into a 3D discrete element model. Quantitative estimations for the specific energy and pore pressures during the cutting processes should be obtained. Execution of laboratory tests of rock cutting under varying hydrostatic pressures is of most importance to check the performance of the numerical rock cutting models.","DEM; discrete element modelling; rock cutting; dredging; particle flow code","en","master thesis","","","","","","","","2012-08-24","Civil Engineering and Geosciences","Geotechnology","","","",""
"uuid:5bb7e6f8-c465-4f9b-ab49-8fccda847de5","http://resolver.tudelft.nl/uuid:5bb7e6f8-c465-4f9b-ab49-8fccda847de5","Vrouwezand, eiland in het IJsselmeer: Studie naar de mogelijkheden van pps","Simon, B.","Sanders, F.M. (mentor); Baggen, J.H. (mentor); Van Eck, P. (mentor); De Boer, E. (mentor)","2009","Building a new island? For recreational and living purposes? At first glance this seems like an impossible task due to the economical crises and the political sensitivity of the chosen location. But in fact it is this unique location and the possibility that government and private parties join forces in economical hard times that gives the project great opportunities. An exclusive island that not only improves the recreational possibilities of the region but also stimulates the whole economy of the region. This thesis gives an overview in all the steps and phases that needs to be considered by the realisation of an island. This includes not only an technical and functional design of the island but also the financial feasibility and the possibility of a public private partnership. Based on an extensive study of different functions that accommodate the island a conceptual design is drawn which serves as the input for the financial feasibility. In this financial study the costs of the realisation of the island, infrastructure and real estate is estimated against the profits of developing real estate. To calculate the financial feasibility a model is used that gives an insight in the value of land in according to the use of land. This so-called residual method is derived from the Dutch practise of urban land policy. This model is a fast and an effective way to calculate the actual value of space utilisation. The financial estimation gives an overview of all the costs and benefits in time (see figure). In Dutch this is called “de grondexploitatie”. The multidisciplinary character of the island lends itself to the realisation of the island in a public private partnership. In this cooperation public and private parties work together at an early stage. A project of this size is usually too complex to be realised by one party. Benefits of this partnership are time saving, cost reduction and a better quality as a result of the exchange of information and knowledge. Public private partnership also means that all profits can be utilized for the project. Conclusions The realisation of the island is financial feasible. Public private partnership is the best way to develop the island.","","nl","bachelor thesis","","","","","","","","","Civil Engineering and Geosciences","Transport & Planning","","","",""
"uuid:2ddaef58-3e91-4d52-b5b5-d296dd6a7e79","http://resolver.tudelft.nl/uuid:2ddaef58-3e91-4d52-b5b5-d296dd6a7e79","Improving Global Optimization Methods for Low-Thrust Trajectories","Spaans, C.J.","Mooij, E. (mentor)","2009","Optimization of spacecraft trajectories is an interesting area of research, where a lot of development takes place: in the past years, an optimizer called OPTIDUS was implemented at the chair of Astrodynamics at Delft Univierstiy. This tool is able to do optimization of spacecraft trajectories (and other problems) using an evolutionary algorithm. However, there are other optimization algorithms available which (according to literature) also perform well on trajectory optimizations. These are Particle Swarm Optimization (PSO) and Differential Evolution (DE). For this thesis, a new version of OPTIDUS has been implemented, which not only supports evolutionary algorithms, but also several variants of differential evolution and particle swarm optimization. These algorithms are also implemented in a way that can exploit the availability of multiple processing cores in a computer, which can give a very good improvement in the runtime of optimizations. Also, a local optimizer using Powell's quadratically convergent method has been implemented. This new version of OPTIDUS is benchmarked against several PSO implementations, and it is found that performance on several (mathematical) testing functions is comparable to existing implementations. However, it is not possible to appoint DE or PSO as the best algorithm in general, as that is problem dependent. The software is also applied to improve the optimization of a Solar polar sailing mission. By comparing the number of function evaluations and the best fitness value found for a family of optimizers (several variants of PPO and DE and an EA), it is found that DE gives the best results, giving an reduction in mission cost almost 4% compared to the original result found using an EA. The use of a local optimizer on this best result is able to improve it even further by another 0.15%. Finally, this software is used to find a solution to the GTOC3 problem, where the goal is to find a low-thrust trajectory for a spacecraft to rendezvous with several asteroids. The hard part of this mission are the rendezvous constraints: upon arrival at an asteroid, the location and velocity of the spacecraft relative to the asteroids have very low margins, making a very large part of the solution space infeasible. For that reason, an augmented objective function which takes these violations into account is used. Both an augmentive function in the form of a weighted sum (of violations) and a multi-objective function are considered. The multi-objective variants gives better results, but is not compatible with the local optimizer, Powell's method. Only the first part of the mission, from Earth to the first asteroid, is optimized. Using DE, a solution is found, which almost satisfies the constraints, but not completely. By applying Powell's method to this solution, the constraint violations are further reduced, but still a small violation of the position remains. It is found that doing global optimization using DE can generate solutions with quite large constraint violations, but that subsequent application of a local optimizer can reduce those violations, while not changing the solution considerably. How the solution of this first leg compares to solutions by other teams is not known, as the per-leg results have not been published.","Differential Evolution; Particle Swarm Optimization; Evolutionary Optimization; Spacecraft Trajectories; Orbit Optimization; Global Optimization; GTOC3; Solar Sailing; OpenMP; Optidus","en","master thesis","","","","","","","","2009-08-28","Aerospace Engineering","Astrodynamics and Satellite Systems","","","",""
"uuid:a38f151d-4d13-46d5-aa28-fd9c66c4c894","http://resolver.tudelft.nl/uuid:a38f151d-4d13-46d5-aa28-fd9c66c4c894","WATCH-OVER: A cooperative approach on vulnerable road user protection","Mastenbroek, D.","Van Genderen, A. (mentor)","2009","Every year many vulnerable road users get injured or die in accidents with vehicles that could have been prevented if the vehicle driver and the vulnerable road user were aware of the dangerous situation that was ahead. Besides non-technical aids like road safety education and wearing lights for more visibility, there are numerous road safety projects. Manufacturers and governments aim at the reduction of traffic accidents. Road safety is a major concern of the European Union and therefore they have started amongst others the vehicle-to-vulnerable road user cooperative communication and sensing technologies to improve transport safety [Watch- Over] and cooperative vehicle-infrastructure systems [CVIS] projects. These projects should come up with innovative ideas to reduce the number of accidents and casualties. The innovative concept of Watch-Over is a system based on the cooperation between the vulnerable road users and vehicle drivers. By means of a wearable device for the vulnerable road user and an on-board unit for the vehicle. This thesis work contributes to this project by improving the wearable device capabilities, by increasing the working range and by adding functionality. It also contributes to the CVIS project by the integration of this cooperative approach in the their open service environment, which enables a wider use of this concept.","CVIS; WATCH-OVER; Vulnerable road user","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","","",""
"uuid:dccc1188-0e63-44c5-ba98-5476d65f20c6","http://resolver.tudelft.nl/uuid:dccc1188-0e63-44c5-ba98-5476d65f20c6","Building a visual speech recognizer","Driel, K.F.","Rothkrantz, L.J.M. (mentor)","2009","This thesis describes how an automatic lip reader was realized. Visual speech recognition is a precondition for more robust speech recognition in general. The development of the software comprised the following steps: gathering of training data, extracting meaningful features from the obtained video material, training the speech recognizer and finally evaluating the resulting product. First, research was done to gain insight on the theoretical aspects of automatic lip reading, the state of the art, speech corpus development, face tracking and feature extraction. Gathering training data came down to the recording and composing of a new audio-visual speech corpus for Dutch. With frontal and side images of 70 different speakers recorded at a frame rate of 100 frames per second this is the most diverse corpus currently in existence. Analysis of the new data corpus shows an increase in quality compared to other corpora. Visual information is obtained by searching the video footage. Using Active Appearance Models, points of an a priori defined model of the lower half of the face are tracked over time. Based on the model point coordinates, distance and area, features are computed that are used as input to the speech recognizer. Training was accomplished by presenting labeled training data to viseme-based Hidden Markov Models that model speech production. In a few steps the model parameters were adjusted, so that it could be used to perform recognition of visual speech signals from then on. The recognizer was implemented using tools from the Hidden Markov Model Toolkit. The results of a visual speech recognizer based on training data from a single person depend on the utterance type of the unlabeled data. For the simple word-level task of digit recognition 78% was recognized correctly with a word recognition rate of 68%. For letter recognition tasks it did not perform nearly as well, but considering the limitations that the use of visemes over phonemes imposes, these results are at the expected level. The data corpus and visual speech recognizer will be a valuable asset to future research.","automatic lip reading; visual speech recognition","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Mediamatics","","","",""
"uuid:a6324bce-a3e7-4563-b8e8-2d3b43db837f","http://resolver.tudelft.nl/uuid:a6324bce-a3e7-4563-b8e8-2d3b43db837f","Design, Modeling and Simulation of a 52MHz MEMS Gyroscope Device in 1.5um SOI","Ngana, P.J.","Koning, J.J. (mentor); French, P.J. (mentor)","2009","In this thesis , a simulation model of a MEMS gyroscope is presented. The model enables mode matching and analysis of the dynamic behavior of a gyroscope. Furthermore, the model allows the optimization the design parameters of the gyroscope. The simulated gyroscope operates at a frequency of 52MHz with amplitudes of 10nm and quality factor of 50,000. Finally, the drive mode measurements are presented at different bias voltages.","MEMS Gyroscope; Simulation; Mechanical Sensor","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","","",""
"uuid:7ef6a318-91c5-442d-a54a-50dd70ed8be8","http://resolver.tudelft.nl/uuid:7ef6a318-91c5-442d-a54a-50dd70ed8be8","Incident Management Information and Communication System (IMICS)","Vink, B.","Rothkrantz, L.J.M. (mentor)","2009","In the past few years, traffic incident management has been a subject of interest in both politics and research. After an incident has occurred, incident management measures are intended to clear the motorway for traffic, inform other road users and treat victims as soon as possible. These measures largely constitute formal agreements, procedures and coordination efforts between all parties involved. Although the new incident management measures currently in effect in the Netherlands have improved the time required to clear an incident scene, information technology is expected to decrease the required time even further by improving communication and situational awareness and supporting analysis and evaluation of the incident response. In this scope, a new IT system is developed, called the Incident Management Information and Communication System (IMICS). Based on an existing framework, the Java Agent DEvelopment framework (JADE), IMICS offers a blackboard like functionality through which the police, fire brigade, ambulance, traffic control centres, the shared control rooms and the Department of Public Works can update and share incident and task information both at the control rooms and at the incident scene. In order to provide clear and unambiguous information, an ontology and an information management system have been designed that closely follow the incident management procedures. Finally, a part of the IMICS design has been implemented and tested in a lab setting as a proof of concept. The results show IMICS improves availability and reliability of data in a lab setting.","Incident Management","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Mediamatics","","","",""
"uuid:acb2b912-74e9-437f-9a68-a2bf6601d199","http://resolver.tudelft.nl/uuid:acb2b912-74e9-437f-9a68-a2bf6601d199","Application of Macroscopic Fundamental Diagrams to Dynamic Traffic Management","Qian, X.","Hoogendoorn, S.P. (mentor); Baggen, J.H. (mentor); Daamen, W. (mentor); Hoogendoorn-Lanser, S. (mentor); Taale, H. (mentor)","2009","This thesis project is a part of Dutch project PraktijkProef Amsterdam (PPA), in which the coordinated network traffic management in the regional area is analyzed. One of control levels in the project PPA is sub-networks, where the concept of the macroscopic fundamental diagram (MFD) is applied. Unlike a conventional link fundamental diagram, an MFD relates the output and number of vehicles in a large network, and enables road operators make a real-time control more efficiently. This graduation project makes a first attempt to use MFD in the Netherlands. The study area of the project PPA is the metropolitan area of Amsterdam. Because empirical data are not available, especially on the urban roads, the simulation model is used to generate the traffic variables for deriving the MFDs. In this case, the macroscopic model RBV is firstly used. Compared to the theoretical fundamental diagram as well as the MFDs obtained based on empirical data in previous studies, the MFD derived by using the RBV model shows two special patterns. One is that the flow is always lower when congestion is dissolving than that during the onset of congestion. The other characteristic is that flows keep rising with the increasing of density and the congestion branch in a conventional fundamental diagram is missing. The two patterns are observed in all MFDs for different demand levels and sub-networks. After analyzing the principles of the RBV model, the reasons for two strange characteristics are revealed. The drop of flow between the onset and the resolving of congestion results from the fact that the locations for measuring flow and density are not corresponding in the RBV model. In terms of the missing congestion part, it is due to the assumption of the RBV model that the flow of a link is constant, which is the saturation flow, even during the congestion period. Since the critical density is not visible in the MFDs derived by RBV, they cannot be used for traffic control. Hence, the RBV model is not suited for deriving MFD. Then the microscopic model VISSIM is applied. The congestion branch is observed in the MFDs derived from VISSIM. However, the drop of flow between the onset and the resolving of congestion still exists. The further analysis reveals that the OD matrix used in this project leads to a dramatic decrease of flow when congestion is resolving. The inflow becomes very low when the density is still high on the link. Due to the same problem in RBV with respect to measurement locations, the drop is also observed in the MFDs based on the data from VISSIM. However, this defect does not affect reading the important patterns on MFD such as the critical density and the maximum flow. So the VISSIM is proven a feasible model to derive MFD. Afterwards, two DTM measures, ramp metering and extra lane, are implemented in the VISSIM model. The MFDs in the different networks are derived for each scenario. When ramp metering is applied, the MFD of the whole network almost remains same. But the large decrease of the maximum density is seen in the MFD of the motorways. By contrast, the maximum density on the urban roads increases, implying a worse traffic situation in the urban network after using ramp metering systems. In terms of extra lanes, they are implemented on the different road sections with two speed limits. The simulation results show that only when the A10 west is expanded, the MFDs of the study area experience significant changes. The maximum density decreases greatly and the congestion part disappears from the MFDs. The scenario with a lower speed limit seems a bit better due to a slight smaller maximum density. In addition, this project also investigates the possibility of using the MFD as an evaluation method. A multi-criteria analysis is made to compare the MFD and the conventional method, in which the traffic situation is revealed by travel time and travel speed. By assessing the MFD and the conventional method against the criteria of accuracy, visualization, feasibility and costs, the MFD performs worse than the conventional method, from the viewpoints of two stakeholders in this case, Rijkswaterstaat and the city of Amsterdam. However, using the MFD to evaluate the effects of DTM measures is still possible on the motorways because the traffic data are easily collected. The combination of the MFD and the conventional method will also improve the reliability of the evaluation results.","macroscopic fundamental diagrams; dynamic traffic management measures; simulation models; multi-criteria analysis","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Transport & Planning","","","",""
"uuid:4cb01d39-963e-4241-960c-bb5c00062b0b","http://resolver.tudelft.nl/uuid:4cb01d39-963e-4241-960c-bb5c00062b0b","Improving ZigBee Networks Robustness with Multi-channel Capability","Cui, X.","Yuan, W. (mentor); Jacobsson, M. (mentor); Niemegeers, I. (mentor)","2009","Based on IEEE 802.15.4, ZigBee is developed for low-power and low-data-rate wireless communication and it is building up remarkable position for wireless sensor network (WSN). As ZigBee is using the 2.4GHz Industrial, Scientific, and Medical (ISM) unlicensed frequency band, coexistence issues arise as there are also other wireless technologies sharing the same band, such as 802.11b/g WiFi, Bluetooth, cordless phones and even microwave ovens. Due to the low transmission power, ZigBee is potentially vulnerable to the interference introduced by these technologies rather than vice versa. Therefore, it is desirable to improve the robustness of ZigBee networks. As WiFi is widely deployed and often collocated with ZigBee networks in applications, such as hospitals and home buildings, we take WiFi as the main interference source and work on finding solutions to enhance the robustness of ZigBee networks under WiFi as well as other interferences. To improve the robustness of ZigBee networks, a feature called frequency agility is specified in the ZigBee standard. We found, however, some inadequacies in the standard that needs to be improved before the frequency agility can function well in practice as it is supposed to do. A better periodical window method is proposed to improve the detection time to interference. Besides, in case that there is only a part of the whole network suffering from some local interference, it is neither necessary for the whole network to move to a new idle channel because this movement is costly and risky, nor possible to find an idle channel for the whole network to move to. Therefore, we extend the frequency agility function by enabling a single ZigBee network to work on multiple channels. As some local interference appears, the part of the network which is under the interference can move to a new idle channel while maintaining the communication links with the other part of the network which stays on the original channel and the moved part can move back to the original channel when the interference disappears. OPNET simulations shows that our multi-channel solution can significantly improve the robustness of ZigBee networks in a cost-efficient way.","ZigBee; coexistence; multi-channel; frequency agility","en","master thesis","","","","","","","","2009-08-29","Electrical Engineering, Mathematics and Computer Science","Telecommunications","","","",""
"uuid:5a92a333-17ee-43a5-baf8-37a713b0664d","http://resolver.tudelft.nl/uuid:5a92a333-17ee-43a5-baf8-37a713b0664d","Improving document retrieval in urban development projects","Weers, M.","Bouwman, W.A.G.A. (mentor); Vrancken, J.L.M. (mentor); Mooi, H.G. (mentor); Brion, D. (mentor); Witteveen en Bos (contributor)","2009","","","","master thesis","","","","","","","Campus only","","Technology, Policy and Management","","","","",""
"uuid:914d7761-4a58-4e64-8a3b-e5f19d30e744","http://resolver.tudelft.nl/uuid:914d7761-4a58-4e64-8a3b-e5f19d30e744","Design of a computer-assisted anticoagulant dosing system","Lous, J.J.","Wiggers, P. (mentor); Geers, H.J.A.M. (mentor); Rothkrantz, L.J.M. (mentor)","2009","At the moment current anticoagulation dosing computer programs use of relatively simple algorithms and provide a useful dose proposal in about half the cases. In the other cases medical staff has to come up with a dose and a return date. This thesis investigates the possibilities of supporting medical staff in anticoagulant dosing by extending current computer programs. Research has been done for improving the current algorithms and incorporating expert knowledge in a computer system. A literature survey showed that a lot of effort already has been made in improving algorithms. The ICAD seems to be the most promising, but still fails in about 20% of the cases to provide a dose or return date, mostly due to special circumstances. My aim was to find out whether the medical expert's knowledge was retrievable and if it was suitable for developing an expert system. Therefore I interviewed dosage doctors and dosage advisors in two Thrombosis Service Departments. The majority of the interviews were held at Star-MDC in Rotterdam, where I work as a Laboratory Manager. A couple of interviews were also held at Saltro, a comparable organization in Utrecht. Knowledge elicitation and representation techniques were applied and a prototype was developed. Further interviews were held, based on the prototype and a OODA-Loop technique. A lot of existing protocols at the Thrombosis Service organizations seemed to be suitable for converting in IF-THEN rules, as a basis for a rule-based expert system. Also the reasoning process of the relative low complex cases are obtainable in an expert system. This is specifically interesting, because the low complex cases are the majority of cases that have to be reviewed by medical staff.","expert system; anticoagulant; knowledge elicitation; anticoagulation dosing; ICAD","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Mediamatics","","","",""
"uuid:4935a560-c90b-4f35-963b-18708cecbc5f","http://resolver.tudelft.nl/uuid:4935a560-c90b-4f35-963b-18708cecbc5f","Behaviour of nourishments in quasi 3-dimensional graded sediment models","Ravenstijn, E.","Sloff, C.J. (mentor); Mosselman, E. (mentor); Snellen, M. (mentor); De Vriend, H.J. (mentor)","2009","Bed degradation in a number of Dutch river branches, like the Bovenrijn, can cause various problems in the near future. At low waters the navigation depth at the non-erodible layer near Emmerich can become too small. Other problems could be lower ground water levels and stability of structures in and near the river, like groynes. To diminish negative effects of bed degradation, nourishing material can be an effective solution. For a better understanding of nourishment behaviour and a better prediction of nourishment propagation, a tracer nourishment released in Germany in 1996 has been modelled and compared with field data. This tracer nourishment was released in the river Rhine at Iffezheim, Southern Germany, chainage kilometre 336. Propagation of this tracer has been recorded to approximately 60 kilometres downstream of the dumpsite. The model used in this research, is a quasi-3D model with a graded sediment module. Simulating with a graded sediment module is important, since the mixture of the tracer nourishment modelled is different from the original bed material and there is an interest in the difference in behaviour between the finer and coarser tracer fractions. A quasi-3D format is used, because spatial scales less than the river width and transverse sorting effects might be important, as well as the parameterization of important 3D effects, like spiral flow. For the description of sediment transport a modified Meyer-Peter-Müller formula is used, the sediment balance of the river bed is described by the model of Hirano. Hiding and exposure effects are implemented by the formulation of Egiazar off, modified by Ashida & Michiue. The bed load transport vector is adjusted by formulations for the effects of spiral flow and transverse bed slope. The roughness is calibrated against the water level for several relevant discharges. The sediment transport formula is calibrated against the yearly sediment transport. The discharge is schematized in two ways: either a constant representative discharge that yields the same yearly transport, or a hydrograph with five different discharge levels is used. Results of case studies show that the thickness of the active layer, hiding and exposure effects and the discharge schematization are important parameters for propagation of the tracer nourishment. Hiding and exposure effects appear to be quite different for a number of existing formulations. Simulation with a hydrograph instead of a constant representative discharge shows important differences: the propagation speed of specific sediment fractions is different. The coarsest fractions move just a little bit, but are still hardly mobile, though not completely immobile as in the computations with the constant representative discharge. Compared to the field data, the finer fractions propagate too slowly, but the coarser fractions hardly move at all. To change this, relevant parameters that can be changed within the model concept used are the active layer thickness, critical Shields value and hiding and exposure relation. It is uncertain however, if the model concept used can represent a satisfactory approximation of the behaviour of all nourishment fractions simultaneously. A number of physical processes that occur in the river reach just downstream Iffezheim, are not included in the model concept. Significant dunes appear to be present in this river reach, introducing vertical and horizontal sorting processes and different hydrodynamic conditions. Furthermore, it is questionable if the critical Shields value should not be variable with the sediment diameter. Finally, navigation appears to be possibly important. Development of a model which takes into account these physical considerations could be beneficial for prediction of sediment nourishments. On locations where nourishment could be an effective solution, field data of the propagation of specific tracer fractions could give important information for rough estimations of nourishment behaviour.","nourishment; graded; sediment; model","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Hydraulic Engineering","","","",""
"uuid:9eb6ed7d-2ba9-4332-9d62-73ce72689685","http://resolver.tudelft.nl/uuid:9eb6ed7d-2ba9-4332-9d62-73ce72689685","Phoenix – Non-cooperative bargaining agents deploying computationally bounded optimization strategies.","De Bakker, F.F.","Rothkrantz, L.J.M. (mentor)","2009","The project addresses cost savings and productivity improvement by pooling of resources between independent companies through multi-agent, bargaining-based decision methods. Cost savings are realized by optimizing plans across companies, while the pooling decision and the benefit distribution is done by bargaining. Applications with these characteristics are wide-spread including logistics (pooling of fleets) and manufacturing (joint manufacturing plans). This thesis comprises the project proposal as a research project submitted to the Sixth Framework Programme, Information Society Technologies, and the realization of the proof-of-concept. This proof is provided by the design and implementation a prototype optimizer for the Capacitated Vehicle Routing Problem (CapVRP) in order to simulated pooling versus non-pooling strategies based on a – simplified – business case. The optimizer uses the genetic algorithm meta-heuristic. Extensive experimentation using published CapVRP instances and benchmarks leads to the delivery of the proof-of-concept.","multi-agents systems; non-cooperative bargaining; vehicle routing problem; genetic algorithm","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Man-machine interaction","","","",""
"uuid:430c85fc-0bd6-422d-b1e2-50c909af2a8c","http://resolver.tudelft.nl/uuid:430c85fc-0bd6-422d-b1e2-50c909af2a8c","A System Analysis of Employee Transition at TNT Post","Scheepers, S.J.","Thissen, W.A.H. (mentor); Cunningham, S. (mentor); Van der Voort, H.G. (mentor); TNT Post (contributor)","2009","","","","master thesis","","","","","","","","","Technology, Policy and Management","","","","",""
"uuid:7277beba-eb6e-4ce1-ade5-5a33d489596a","http://resolver.tudelft.nl/uuid:7277beba-eb6e-4ce1-ade5-5a33d489596a","From Broadband to Organizational Productivity","Ngabonziza, S.","Madureira, A.J.P.S. (mentor); Baken, N.H.G. (mentor)","2009","Broadband infrastructures are advanced telecommunication systems capable of providing high-speed transmission of services. Broadband deployment has the potential to bring valuable new services, stimulate economic activity, advance economic opportunity and improve productivity. For example, the European Commission has stated that ""widespread and affordable broadband access is essential to realize the potential of the information society"". Despite this general perception, the announced impacts were not yet backed up with factual evidence. Scientifically grounding this perception is an essential input to the development of telecommunication infrastructures related public and private policies. This thesis contributes to clarify the importance of broadband, by investigating the following research questions: 1) what is the state of the art concerning the impact of broadband to organizational productivity; 2) is there any thorough and generally accepted framework to investigate the relation from broadband to organizational productivity; 3) if not, which framework can be used; 4) how can the applicability of such framework be tested; and 5) which conclusions can be derived about the impact of broadband using this framework. The methodology used to investigate these research questions is based on literature reviews and a survey. From a general observation of the results of the survey, it can be concluded that the majority of the interviewees are conscientious of the impact of the digital information networks and broadband on their productivity, but are not able to distinguish broadband from narrowband. In general, they don't care about the types of networks they are using as long as they can do their job. At this stage, no concrete conclusion can be drawn about the impact of broadband, since users are not clarified about the difference between broadband and narrowband networks. Although the relevance of broadband was validated with a literature review, there is a lack of confirmation of the perceived impacts with an empirical validation. A careful re-design of the questions of the questionnaire should be able to clarify to the target population the difference between these two networks. From a scientific perspective, the novelty of this work lies on the application of a novel framework useful to structure the outcomes of broadband impact studies in a valid conceptual way. From an applied perspective, this work can contribute to clarify utopian and opposite dystopian views of broadband, particularly aiming policy makers and organizational managers.","Productivity; Broadband","en","master thesis","","","","","","","","2009-08-25","Electrical Engineering, Mathematics and Computer Science","Electrical Engineering","","","",""
"uuid:136cd4d6-396a-4520-98bf-d9dc9782f807","http://resolver.tudelft.nl/uuid:136cd4d6-396a-4520-98bf-d9dc9782f807","Improving the linear solver used in the interactive wave model of a real-time ship simulator","Van 't Wout, E.","Van Gijzen, M.B. (mentor); Vuik, C. (mentor)","2009","","variational Boussinesq model; conjugate gradients; preconditioning; deflation","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied Mathematics","","","",""
"uuid:7e6c84a8-919e-4547-ab02-b8983d68a5e4","http://resolver.tudelft.nl/uuid:7e6c84a8-919e-4547-ab02-b8983d68a5e4","Tygron Bachelor Project","Mijnders, S.; Lotgering, T.","Geers, H.J.A.M. (mentor); Hofstede, A.P. (mentor); Sodoyer, B.R. (mentor)","2009","Final report of our bachelor project commissioned by Tygron.","","nl","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Software Technology","","","",""
"uuid:3dfc03b5-c3ae-4e2f-b86c-a21f5dd0df12","http://resolver.tudelft.nl/uuid:3dfc03b5-c3ae-4e2f-b86c-a21f5dd0df12","The influence of tropical operating conditions on the AC and impulse breakdown strength in gas insulated substation (GIS)","Sihombing, H.","Meijer, S. (mentor)","2009","The ambient conditions could influence the breakdown strength of gas insulated substation. It is important to check if this influence will put the GIS into severe condition, especially in the presence of protrusion. A risk assessment is thus important for making decision if the GIS is safe to be operated.","GIS; risk assessment","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Electrical Power Engineering","","","",""
"uuid:3e10679b-32bd-472c-b835-423cb73ff270","http://resolver.tudelft.nl/uuid:3e10679b-32bd-472c-b835-423cb73ff270","Scaling Up Uganda's Electricity Access","Namujju, L.D.","Pruyt, E. (mentor); Yucel, G. (mentor); De Vries, L.J. (mentor); Thissen, W. (mentor)","2009","Access to power is tied to any country’s development. It provides opportunities for increased social welfare, education, health and income generating opportunities all of which Uganda needs. Uganda’s economic development is being stifled by power inaccessibility. Electricity access levels are as low as 9% nationally. The study was aimed at building a working theory on the internal setup and inner workings of Uganda’s power sector, using this theory to facilitate a better understanding of how elements of the power system contribute to the problem and the formulation of effective policies that take into account prevailing local conditions to remedy the situation. System dynamics methodology was applied to build a model showing how Uganda’s power sector is expected to evolve over a period of 80 years in terms of power supply and demand given the existing market structure and prevailing local conditions. Findings from the study show that while physical access to power is a big problem, major problems regarding the nature of power accessed exist for those consumers within the grid covered area: Insufficient power supply to meet an existing and growing power demand, an unreliable power supply and high power service costs. On top of the obvious reasons of Uganda’s lack of cheap high value primary energy resources, poor investment climate so few suppliers and limited negotiating power for the regulator, the study finds the biggest cause to be the nature of the existing capacity planning process in terms of how future capacity requirements are determined and the agreements made with generators as to how and when they fulfill their investment obligations. Policies to do with gradual targeted reduction of Uganda’s extremely high power losses, obligatory upfront capacity investment as opposed to spreading the investment over the period of the awarded concession, among others, are explored to determine their impact on system performance. The investigated policies highlight how slight changes to the capacity planning process requiring little or no investment could yield significant gains on the problems identified.","System Dynamics model; Electricity access; Energy policy; Power supply","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Policy Analysis","","","",""
"uuid:bf975e3c-ec3a-46bd-b23c-1d6f5d6e4153","http://resolver.tudelft.nl/uuid:bf975e3c-ec3a-46bd-b23c-1d6f5d6e4153","Effect of Reservoir Heterogeneity on Immiscible Foam Enhanced Oil Recovery","Olatunji, O.S.","Simjoo, M. (mentor); Zitha, P.L.J. (mentor)","2009","Gas flooding is a widely used improved and enhanced oil recovery (IOR/EOR) method. However, due to low density and high mobility of gas compared to oil and water, gas tends to segregate to the top of the reservoir and overrides both oil and water. In heterogeneous and layered reservoirs gas also tends to channel through high permeability streaks. Hence in gas flooding the sweep efficiency is generally poor which leads to low incremental oil recovery factor. The development of foam leads to lowering the gas mobility and thus can help overcome the above disadvantages and improve the reservoir sweep efficiency. Many experimental and modeling studies have been devoted to describe foam in the last decade, but questions remain about foam performance in EOR. In particular there are still some important questions regarding foam stability and propagation in reservoirs containing oil and the effect of reservoir heterogeneity. Recent experiments done at the Delft University of Technology have demonstrated that adequately selected surfactants produce foams that are stable in presence of oil. However, if oil saturation is too large there is still a risk that foam will not be sufficiently strong to achieve the desired high recovery factor. In this study we investigate the effect reservoir heterogeneity on the performance of immiscible foam EOR. The study addresses four different types of reservoir models, homogeneous reservoir, stochastic permeability reservoir, layered reservoir and layered stochastic reservoir. We adopt six different recovery methods starting with water flooding and NFA as a base case, surfactant flooding, gas flooding, foam co-injection, SAG processes and WAG processes. The simulation results show that foam co-injection has the best sweep efficiency and highest oil recovery. Foam front propagation rate is found to be lower in heterogeneous reservoirs compare with homogenous case and therefore more injection time is needed to reach the same recovery as in the homogeneous case. In all the injection scenarios, the oil recovery in heterogeneous reservoirs is lower.","","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Petroleum Engineering and Geosciences","","","",""
"uuid:1632b098-9596-4de4-8f7b-1f76070da825","http://resolver.tudelft.nl/uuid:1632b098-9596-4de4-8f7b-1f76070da825","Tygron Bachelor Project","Lotgering, T.F.; Mijnders, S.","Geers, H. (mentor)","2009","The final report for our Bachelor project at Tygron Serious Gaming.","","nl","bachelor thesis","","","","","","","","2009-08-21","Electrical Engineering, Mathematics and Computer Science","Software Engineering","","","",""
"uuid:39728108-3402-48ab-9a74-ae0f0ac512c0","http://resolver.tudelft.nl/uuid:39728108-3402-48ab-9a74-ae0f0ac512c0","Diversity and Perfomance in Business Ecosystems","Cevik, Y.","Van Beers, C. (mentor); Den Hartigh, E. (mentor); De Bruijne, M. (mentor)","2009","","","","master thesis","","","","","","","Campus only","","Technology, Policy and Management","","","","",""
"uuid:2b4a1434-8169-481d-9824-fe79e9c4874c","http://resolver.tudelft.nl/uuid:2b4a1434-8169-481d-9824-fe79e9c4874c","RAFFS: Model checking a robust abstract flash file store","Taverne, P.","Pronk, C. (mentor)","2009","This thesis presents a case study in modeling and verifying a POSIX-like file store for Flash memory. This work fits in the context of Hoare’s verification challenge and, in particular, Joshi and Holzmann’s mini-challenge to build a verifiable file store. I have designed a simple file store and implemented it in the form of a Promela model. This file store is robust, meaning it can cope with unexpected power loss without getting corrupted. A test harness is used to exercise the file store in a number of ways. Model checking technology has been extensively used to verify the correctness of my implementation. A distinguishing feature of my approach is the exhaustive verification of power loss recovery.","flash; model; checking; file; store","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Department of Software Technology","","","",""
"uuid:008a3e63-00cf-40d6-95f8-200762568b35","http://resolver.tudelft.nl/uuid:008a3e63-00cf-40d6-95f8-200762568b35","On Wavelet Based Spectrum Estimation for Dynamic Spectrum Access","Ariananda, D.D.","Lakshmanan, M.K. (mentor); Nikookar, H. (mentor)","2009","One of the important functionalities of Dynamic Spectrum Access is spectrum estimation. Accuracy and speed of estimation are the key indicators to select the appropriate spectrum estimation technique. In this thesis work, the possibility of employing wavelet packet decomposition as a basis for a new spectrum estimation approach is investigated. Once the new approach is developed, four types of sources, namely partial band, single tone, multi-tones, and swept tone, are used to investigate the performance of the proposed wavelet based approach. Preliminary comparative analysis between the performance of wavelet based approach with conventional techniques, such as Periodogram and Welch technique has also been conducted. The studies show that the wavelet based approach offers great flexibility, reconfigurability and adaptability. Key to the successful operation of the wavelet based spectrum estimation is the choice of the wavelet used. Commonly known wavelets are not suitable for spectrum estimation because they result in estimates with poor frequency resolution. To alleviate this problem, we design and develop a family of wavelets that are maximally frequency selective in nature as our second contribution in this thesis work. To this end, the design constraints are first enlisted. Then the problem, originally non-convex, is reformulated into a convex optimization problem and solved using Semi Definite Programming (SDP) tools. Through simulation studies the benefits of the newly designed wavelets are demonstrated. The next contribution of this thesis work is to combine the existing wavelet packet multi-carrier modulation (WPMCM) technique with our wavelet based spectrum estimator in order to form a wavelet packet transceiver for a dynamic spectrum access environment. To enable the wavelet packet transceiver cognitive radio (CR) system to co-exist with other Licensed Users (LU), a common spectrum pool is maintained and the WPMCM transmission waveform characteristics are shaped to communicate in the idle time-frequency gaps of the licensed user. This is achieved by dynamically vacating wavelet packet carriers in and near the region of the licensed user spectrum. The spectrum estimation unit is tagged to the WPMCM transceiver structure by exploiting the filter bank infrastructure used for Discrete Wavelet Packet Transform implementation. Thus spectrum analysis is done at no additional cost. In the studies, four types of LUs are employed, namely, partial band, single tone, swept and multiple tone. The simulation results show that in the presence of an LU, the proposed spectrum adaptation method offers significant BER improvements allowing the CR to operate invisibly to the LU.","spectrum estimation; Wavelet Packet Transform; frequency selectivity; dynamic spectrum access; filter bank","en","master thesis","","","","","","","","2009-08-28","Electrical Engineering, Mathematics and Computer Science","Telecommunications","","","",""
"uuid:d7fb915f-65a5-46e0-a8d3-0dd60f4f1abe","http://resolver.tudelft.nl/uuid:d7fb915f-65a5-46e0-a8d3-0dd60f4f1abe","The role of CO2 footprint during order acquisition","Van Slooten, W.M.C.","Van Beers, C.P. (mentor); Scholten, V.E. (mentor); Schoenaker, H.J.G. (mentor); Rousseva, R.I. (mentor)","2009","","","","master thesis","","","","","","","","","Technology, Policy and Management","","","","",""
"uuid:8e4e436a-de0a-40c8-b41b-e2d6e0bacb67","http://resolver.tudelft.nl/uuid:8e4e436a-de0a-40c8-b41b-e2d6e0bacb67","Moblie Rail Survey System: Een nauwkeurig en betrouwbaar systeem voor spoormetingen?","Hellemons, J.F.L.","Tiberius, C.C.J.M. (mentor); Hanssen, R.F. (mentor)","2009","","GPS; INS; Laserscanner; Kalman filter","nl","master thesis","","","","","","","","2009-08-28","Aerospace Engineering","Geomatics Engineering","","","",""
"uuid:1ceb1bb9-af85-43b4-a88f-c3af4686a096","http://resolver.tudelft.nl/uuid:1ceb1bb9-af85-43b4-a88f-c3af4686a096","Scooter Logistics from a Cradle-to-Cradle perspective","Peters, F.H.J.","Van Wee, G.P. (mentor); De Brito, M.P. (mentor); Mulder, K.F. (mentor); Van Vloten, F. (mentor); Eco-movement (contributor)","2009","","","","master thesis","","","","","","","","","Technology, Policy and Management","","","","",""
"uuid:59f97729-5098-4d80-a5b1-be4e02d23cdc","http://resolver.tudelft.nl/uuid:59f97729-5098-4d80-a5b1-be4e02d23cdc","Immersiveness in serious gaming","Hooijkaas, R.; Rens, T.P.; Rentmeester, M.; Van Rijn, Y.","De Haan, G. (mentor); Borgers, H.J. (mentor); Krijnen, R. (mentor)","2009","De opdracht van deze stage was het onderzoeken van de mogelijkheden en beperkingen van verschillende input devices om het spelen van (serious) games realistischer te maken. Een ander doel van de stage was het onderzoeken van de mogelijkheden en beperkingen van de verschillende simulatie-engines. Als eindproduct is een werkend prototype gemaakt.","","nl","bachelor thesis","","","","","","","","2009-08-19","Electrical Engineering, Mathematics and Computer Science","Computer Graphics and CAD/CAM group","","","",""
"uuid:889a8830-9e61-4d21-bdef-624f7aec18e3","http://resolver.tudelft.nl/uuid:889a8830-9e61-4d21-bdef-624f7aec18e3","Free-space Emulator of 60GHz Directional Antenna Equipment","Dabbagh, H.","Wang, J. (mentor); Niemegeers, I. (mentor)","2009","","","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Telecommunications","","","",""
"uuid:a18b62c5-e73e-44fc-9336-83a78275f266","http://resolver.tudelft.nl/uuid:a18b62c5-e73e-44fc-9336-83a78275f266","Plagiarism detection by similarity join","Schellenberger, R.","De Vries, A.P. (mentor); De Bruijn, S.T.J. (mentor)","2009","Since the internet is so big and most of its content is public, it is very hard to find out where the information came from originally. There are many websites that publish news articles, so people and organizations can easily lose track of where their articles are reused with or without their permission. This paper presents a plagiarism detection algorithm that allows us to quickly compare online news articles with a collection of personal news articles and detect plagiarized passages with the same quality as a human. The algorithm uses a basic shingle index and a Signature Tree as a more advanced pre-filtering step to narrow down the viable documents to a query. The algorithm achieves a score of 0.96 precision and 0.94 recall but is too resource intensive to be considered scalable. When only the pre-filtering step is used, it achieves 0.85 precision and recall creating a speedup of nearly one order of magnitude.","plagarism detection; similarity join; shingles; signature tree; news articles","en","master thesis","","","","","","","","2011-08-18","Electrical Engineering, Mathematics and Computer Science","Media and Knowledge Engineering","","","",""
"uuid:e97a87ed-506f-449d-92ec-5b3d5a9206ff","http://resolver.tudelft.nl/uuid:e97a87ed-506f-449d-92ec-5b3d5a9206ff","Exploring the Greening of energy sector: An Actor Network Analysis of electricity sector in the Netherlands","Jafargholi, S.","Thissen, W.A.H. (mentor); Haan, A.R.C. (mentor); De Vries, L.J. (mentor); Frantzeskaki, N. (mentor)","2009","","","","master thesis","","","","","","","Campus only","","Technology, Policy and Management","","","","",""
"uuid:a91d6dc5-bdeb-4ee3-9a34-75a72c89f806","http://resolver.tudelft.nl/uuid:a91d6dc5-bdeb-4ee3-9a34-75a72c89f806","Data assimilation of GRACE terrestrial water storage data into a hydrological model using the Ensemble Kalman Smoother: A case study of the Rhine river basin","Widiastuti, E.","Van de Giesen, N.C. (mentor); Steele-Dunne, S.C. (mentor); Gunter, B.C. (mentor)","2009","Terrestrial water storage (TWS) can be defined as the storage of water on and below the land surface, and includes snow, ice, surface water, soil moisture, and ground water. TWS is a key component of the terrestrial and global hydrological cycles, which have important control over the water, energy and biogeochemical fluxes, and plays a major role in the Earth’s climate. An accurate estimation of terrestrial water storage is thus important for improved water management. However, direct determination of TWS is difficult due to insufficient in-situ data. TWS estimation can be obtained through hydrological modelling, although models are not free from uncertainties due to inaccurate forcing data and weak modelling assumptions. However, the launch of the Gravity Recovery and Climate Experiment (GRACE) twin satellite mission has provided the first space based dataset for TWS estimates, although with coarse resolution and limited accuracy. It is expected that combining GRACE observations and estimates from a model could improve TWS estimates, and one way to this through data assimilation. In this thesis, the ensemble Kalman filter (EnKF) and the ensemble Kalman smoother (EnKS) have been applied to assimilate the GRACE TWS variation data into the HBV-96 model, a conceptual rainfall-runoff model over the Rhine river basin, for the study period of February 1st 2003 to January 31st 2004. Two TWS variation estimates were inferred from two sets of GRACE solutions, one from DEOS – TU Delft, and another from CSR - University of Texas. Both solutions use different filtering methods which yield different estimates, and therefore can be expected to have different effect on the data assimilation. The EnKF and EnKS have been successfully applied, fulfilling the expectation of having a new estimate with lower variance than both the prior model estimate and the GRACE observation estimate. The model estimated discharge after the data assimilation was compared with measured discharge at several stations. The discharge estimates were improved at the beginning of the experiment, but the degree of improvement decreased with time. Both of the GRACE data sets gave comparable results. Longer experiment period and comparison with other validation data could lead to a more definitive conclusion.","GRACE; Data Assimilation; Ensemble Kalman Filter; Ensemble Kalman Smoother; Terrestrial Water Storage","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Watermanagement","","","",""
"uuid:f07c6eed-09f3-4543-9506-a219a10021d7","http://resolver.tudelft.nl/uuid:f07c6eed-09f3-4543-9506-a219a10021d7","Refrigeration With And Of Solid State Devices","Amar Ashok, J.","Sarro, P.M. (mentor); Hoekstra, J. (mentor); Klapwijk, T.M. (mentor)","2009","Solid state coolers are reliable, cheap and easy to scale down to microscopic scales, hence very promising for on chip refrigeration in microelectronics. The previous decade has shown tremendous interest for applications both in science and industry. In this thesis we present an overview on the state of the art possibilities and applications of solid state cooling in Microelectronic industry. A study based on the different types of coolers, their applicability and limitations. This includes the operating temperature ranges, cooling power and effciency. Physical and practical advantages and drawbacks of different systems are analysed. Also presented is a brief literature on cryogenic NIS coolers, their operating principles,effiencies, and limitations are touched upon. In that respect, the problems limiting the effiency of these refrigerators is the excessive heating, of the superconducting leads. The diffusion of hot quasi-particles is of critical importance. The physical processes behind are of strong fundamental interest, especially at low temperatures. To address the above problem of heating, we conduct an experiment which allows us to study the diffusion and energy relaxation of quasiparticles in a superconducting wire which aids in the design and optimization of the NIS coolers. An attempt has been made identify the relevant physical processes involved. This involves study of nonequilibrium superconductivity, tunnelling, diffsion and relaxation processes. We present the the basic physics, fabrication technology and experimental techniques.","","en","master thesis","","","","","","","","","Applied Sciences","Kavli Institute of Nanoscience","","","",""
"uuid:1d9487dd-cb76-4c6a-9182-7c242ae75707","http://resolver.tudelft.nl/uuid:1d9487dd-cb76-4c6a-9182-7c242ae75707","Succes and failure factors of academic Life Sciences spin-off creation","Tolsma, A.D.","Ortt, R. (mentor); Van der Steen, M. (mentor); Van Geenhuizen, M. (mentor); Wiedhaup, K. (mentor)","2009","","","","master thesis","","","","","","","Campus only","","Technology, Policy and Management","","","","",""
"uuid:033d8f85-d9d4-4710-aae8-28eb12d2a19b","http://resolver.tudelft.nl/uuid:033d8f85-d9d4-4710-aae8-28eb12d2a19b","The freedom of light characteristics in atmosphere perception for the living room","Choy, H.Y.","Heynderickx, I. (mentor)","2009","With the introduction of LED lighting, nowadays designers and architects have more flexibility to evoke emotions and create certain atmospheres in a space by means of artificial lighting. The perceived atmosphere in a space is an experience of the surroundings in relation to ourselves; it is an affective evaluation of the environment (Scholten et al., 2003; Vogels, 2008). Previous studies related to atmosphere perception have given valuable insight into the relation between white light and the perceived atmosphere (Vogels et al., 2008). Moreover, in (Seuntiens and Vogels, 2008) four atmospheres (cosy, relaxing, activating and exciting) were designed by professional lighting designer for a standard living room and verified by end users. This study found clear commonalities between the professional lighting designers with respect to the chosen light characteristics to evoke a certain atmosphere in the room. However, it was not clear how much variation in light characteristics was allowed before an initially perceived atmosphere disappears. In the present research three experiments were conducted to investigate the allowed variation in light characteristics (luminance, color temperature, hue and saturation) on two atmospheres, namely cosy and activating. In the first study, a tuning experiment was conducted in order to investigate the allowed variation in light characteristics on the initially perceived “cosy” and “activating” atmosphere. In general, the results of the first experiment showed that participants allowed quite some variation in light characteristics in both atmospheres. On average participants allowed an increase in luminance of the white light sources of a factor two to four compared to the initial luminance level, and a decrease in luminance of at least a factor of two. Furthermore, a consistent change of about 800K was allowed for the increase in color temperature in the “cosy” atmosphere and the decrease in color temperature in the “activating” atmosphere. Due to technical limitations, the decrease in color temperature in the “cosy” atmosphere and the increase in color temperature in the “activating” atmosphere were not investigated in this study. Finally, the allowed change in hue and chroma of the colored luminaires was found to be larger in the “activating” atmosphere than in the “cosy” atmosphere. In order to investigate the effect of a change in light characteristics on the perceived atmosphere, a difference scaling experiment was conducted. In this experiment, participants compared the average allowed change in light settings as obtained from the first study to the light settings corresponding to a “cosy” or “activating” atmosphere as reference. A short version of the original atmosphere questionnaire of Vogels (2008) was used to assess the perceived atmosphere in the room. The results showed that an increase in luminance of the white light sources reduced the cosiness and tenseness of the atmosphere, and enlarged its liveliness and detachment (with a reverse effect for a decrease in luminance). A decrease in color temperature was found to increase the cosiness, and to reduce the liveliness and detachment of the atmosphere. With regard to the colored luminaires, a change in hue was found to mainly affect the cosiness and detachment, whereas a decrease in chroma mainly affected the liveliness and detachment. In a follow-up experiment participants assessed the perceived atmosphere for the allowed change in light settings without the initial “cosy” and “activating” atmosphere as a reference to compare with. In general, similar trends with respect to the changes in the atmosphere were found, however, the effects were considerably smaller. This indicates that participants found it more difficult to distinguish the atmosphere related to the different light settings when they could not directly compare them. In this study, boundaries for the allowed variation in luminance, color temperature, hue and chroma were obtained for the “cosy” and “activating” atmosphere. In addition, the results gave further insight into the relation between light and perceived atmosphere. However, this research also has its limitations in the sense that some light characteristics, such as the spatial distribution of the light, and its dynamics, as well as the spatial configuration of the light sources, were not included. More research is needed to investigate the effect of these aspects on perceived atmosphere further.","atmosphere; lighting; experience; perception; living room; home","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Man-Machine Interaction Group","","","",""
"uuid:5ca702e5-dfe7-4ec0-9ec6-8d270af6bb0a","http://resolver.tudelft.nl/uuid:5ca702e5-dfe7-4ec0-9ec6-8d270af6bb0a","Decision framework for selecting a suitable software development process","Sharon, I.","Dos Santos Soares, M. (mentor); Barjis, J. (mentor); Van den Berg, J. (mentor); Bergman, C. (mentor); ING (contributor)","2009","","","","master thesis","","","","","","","","","Technology, Policy and Management","","","","",""
"uuid:08deaede-9417-4cb0-ac08-410679b680de","http://resolver.tudelft.nl/uuid:08deaede-9417-4cb0-ac08-410679b680de","Process-based Modelling of Late Quaternary Morphology and Stratigraphy of the Northern Adriatic Basin","Meron Teklesenbet, M.O.T.","Dalman, R.A.F.D. (mentor); Weltje, G.J.W. (mentor)","2009","The thesis is devoted to calibration of a process-based numerical model and its application to simulation of the Late Quaternary history and stratigraphy of the Northern Adriatic Sea. Tests aimed at assessing the sensitivity of the model to initial and boundary conditions were conducted, based on geomorphologic and stratigraphic data culled from literature. Based on these tests, wave-generated erosion and diffusion coupled with current-induced removal and transportation algorithms were adopted to simulate intensification of the Western Adriatic Coastal Current (WACC) by the Bora Wind during the Late Holocene. Different scenarios have been assessed to examine the model’s ability to reproduce the stratigraphic architecture of the Adriatic Basin. Model results for the prodelta of the Po River at the north-western low-gradient shelf are represented by a continuous subaqueous delta, which forms an elongated coast-hugging deposit. The central Apennine part of the western shelf, which has a comparatively steep gradient, is characterized by the presence of fluvio-deltaic lobes deposited by the Apennine Rivers. The sediment budget has been calculated based on the isopach maps of modelled stratigraphy. A total sediment mass of abut 800 Gt was supplied to the basin over the time span corresponding to TST and HST (~19 kyr). Volumetric estimates indicate that roughly 87% of the supplied sediments have been preserved on the shelf. This suggests an export of ~13% to the MAD and to the southern part of the basin. The result is compatible with literature, where 10% of the sediment has been reported to move south of the Gargano promontory. Over the past 5.5 kyr, 256 Gt of sediment has been preserved on the shelf and is stored in the HST, corresponding to an average rate of deposition about 46 Mt yr-1, which is ~4 Mt yr-1 more than study reports. The rate of fluvial sediment supply (52 Mt yr-1) during formation of the HST suggests an export of ~6 Mt yr-1 to deeper parts of the basin below the effective hydrodynamic base.","Adriatic Basin Stratigraphic Modelling; Process Based Modelling; Numerical Modelling","en","master thesis","","","","","","","","2009-09-01","Civil Engineering and Geosciences","Geotechnology","","","",""
"uuid:9fe84fa1-0f2a-4a75-8c5b-739527ddbaa7","http://resolver.tudelft.nl/uuid:9fe84fa1-0f2a-4a75-8c5b-739527ddbaa7","Identifying Cross-Cutting Concerns Using Software Repository Mining","Mulder, F.","Zaidman, A. (mentor); Van Deursen, A. (mentor)","2009","Cross-cutting concerns are pieces of functionality that have not been captured into a separate module. They form a problem as they hinder program comprehension and maintainability. Solving this problem requires first identifying these cross-cutting concerns in pieces of software. Several methods for doing this have been proposed but the option of using software repository mining has largely been left unexplored. That technique can uncover relationships between modules that may not be present in the source code and thereby provide a different perspective on the cross-cutting concerns in a software system. We perform software repository mining on the repositories of two software systems for which the cross-cutting concerns are known: JHotDraw and Tomcat. We evaluate the results we get from our technique by comparing them with those known concerns. Based on the results of the evaluation, we make some suggestions for future directions in the area of identifying cross-cutting concerns using software repository mining.","cross-cutting concerns; software repository mining; aspect mining; frequent itemset mining","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Software Engineering","","","",""
"uuid:1eace7da-9f06-42ca-9f99-b877e78a718a","http://resolver.tudelft.nl/uuid:1eace7da-9f06-42ca-9f99-b877e78a718a","Quantifying Seismic Time-Lapse Effects of Solution Salt Mining - A Feasibility Study","Van Noort, G.","Drijkoningen, G.G. (mentor); Arts, R.J. (mentor)","2009","In the northern part of the Netherlands the (magnesium containing) salt minerals carnallite and bischofite are extracted using solution mining methods, such as squeeze mining. As a consequence subsidence up to the surface is taking place, potentially causing harm to the environment. Given this fact the local government allows extraction of this salt under the condition that subsidence at the surface does not exceed a pre-defined limit. This makes the importance of salt mining induced subsidence evident. For an accurate prediction the 3-D characteristics of the caverns are important. Currently it is impossible to predict what effect squeeze mining has on the characteristics of the caverns, and thus on the subsidence. This thesis addresses the question whether time-lapse seismic reflection techniques can be used to image and quantify the effects of mining magnesium salt in the north of The Netherlands. The use of seismic time-lapse techniques to indentify produced salt zones has not been investigated before and this study must be considered as a feasibility study, using synthetic seismic data. The questions addressed in this thesis are:  Can the effects of solution salt mining be detected in seismic time-lapse mode?  If so, can these effects be quantified? In our approach we studied the time-lapse effects of different scenarios; representing a vertical and a lateral extension of the mine due to salt production have been evaluated. These scenarios have been transformed into different subsurface models that were an input to an acoustic and elastic finite difference scheme in order to create synthetic data. The geometric and material properties in the scenarios are based on the interpretation of real seismic data. A combination of well data and empirical relations has been used to derive the necessary seismic parameters. The main findings can be summarized as: 1) A seismic reflection of the salt mine is visible in seismic shot records, CMP-gathers and migrated sections. The exact geometry of the mine cannot be distinguished in the data, because of interference effects. 2) To derive time-shifts and amplitude changes caused by geometry and property changes in seismic time-lapse mode, 2-D cross correlation on migrated data was used. This technique allows deriving a horizontal shift as well as a time-shift. The amplitude changes were calculated by comparing the amplitude maximum from a 2-D cross correlation window with the maximum amplitude from a 2-D auto correlation window. The difference is expressed as a percentage. 3) A vertical extension of 5 m causes a potentially detectable time shift of 1.5 ms for the acoustic case and 2.0 ms for the elastic case. The amplitude changes are respectively 5.3% and 7.1%. For a purely lateral extension of 100 m of the caverns no time shift is found for the acoustic and elastic case and the amplitude change is 0.2% and 2.0% respectively. These results show that the amplitude change caused by a vertical extension is significantly higher than the one caused by a lateral extension of the mine. In order to make lateral changes of the salt mine visible one could opt for 1-D cross correlation. The time shifts and amplitudes found are comparable as those found in literature for the oil and gas industry. The final conclusion yields that the effects of solution salt mining can be detected and quantified in seismic time-lapse mode. Some effects in this seismic study are large enough to be seen in real seismic data. It is therefore feasible to use time-lapse seismic to monitor geometric and material changes of an underground solution salt mine.","salt; seismic; mining; time-lapse; geophysics; magnesium","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Section of Applied Geophysics and Petrophysics","","","",""
"uuid:b8d8b473-4d3a-4964-ab86-e7ffd8dcf8da","http://resolver.tudelft.nl/uuid:b8d8b473-4d3a-4964-ab86-e7ffd8dcf8da","Services in Game Worlds: A Semantic Approach to Improve Object Interaction","Kessing, J.","Tutenel, T. (mentor); Bidarra, R. (mentor)","2009","To increase a player's immersion in the game world, its objects should behave as one would reasonably expect. For this, it is now becoming increasingly clear that what game objects really miss is richer semantics, not eye-catching visuals. Current games' lack of semantics is mostly due to the complexity of designing semantic objects. If game designers would have to design all semantics by themselves, and game programmers would have to implement the handling of these semantics, game development time would increase enormously. The goal of this research is to improve the semantics of game objects (or more properly, entities) in virtual worlds, resulting in more and better object interaction in games. This thesis proposes a solution in the form of services, describing interaction possibilities between entities, and a structure that makes it easier to specify them. An example of this is the service of a vending machine, which exchanges a coin supplied by a player for a soda. By introducing several components, such as classes, attributes and actions, a service is defined as the capacity of an entity to perform a particular action, possibly subject to some requirements. To incrementally specify and add services to game objects, a three-phased methodology is presented. This approach has been implemented and validated by means of a prototype system, which enables a simple and intuitive definition of services in an integrated environment. By using two different editors, services can be defined during the game development process. In turn, a semantics engine is charged with all service handling during a game itself. It is concluded that if game designers are presented with the tools to easily add semantics to game objects, these objects become aware of their services, therefore facilitating more and better object interaction, resulting in a much deeper gameplay experience than in current games.","game worlds; services; semantics; object interaction","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Mediamatics","","","",""
"uuid:74705c27-d5ad-4ab6-999e-bc4566f0efdd","http://resolver.tudelft.nl/uuid:74705c27-d5ad-4ab6-999e-bc4566f0efdd","Monin-Obukhov similarity theory applied to offshore wind data - validation of models to estimate the offshore wind speed profile in the north sea","Venora, A.","Sathe, A. (mentor); Van Bussel, G.J.W. (mentor)","2009","The offshore wind energy is gaining more and more importance in the scenario of the European renewable energies. Due to high costs of installation and maintenance, it is important to have a good assessment of the wind speed profile. The wind speed at the turbine hub level is used for energy yield evaluations and the knowledge of the wind shear helps estimating turbine structure loads. The wind speed profile in a marine environment is investigated using the data provided from the German offshore research platform FINO-1, the meteorological mast of the Dutch offshore wind park Egmond aan Zee and the weather forecast model COSMO-EU of the Deutscher Wetterdienst DWD. The data are compared to the Monin-Obukhov Similarity Theory using the Richardson Bulk Method, the Richardson Gradient Method and the Profile Methods. The results show that the models do not predict the wind speed profile well and large scatter is present. The weather forecast model COSMO-EU for offshore wind energy purposes is validated using FINO-1 measurements and the results are promising.","","en","master thesis","","","","","","","","","Aerospace Engineering","AEWE - Windenergy","","","",""
"uuid:19535c16-c7ce-4e1c-8135-9ff6e9f536ce","http://resolver.tudelft.nl/uuid:19535c16-c7ce-4e1c-8135-9ff6e9f536ce","Monin-Obukhov Similarity Theory Applied to Offshore Wind Data: Validation of Models to Estimate the Offshore Wind Speed Profile in the North Sea","Venora, A.","Sathe, A. (mentor)","2009","The wind speed profile in a marine environment is investigated using the data provided from the German offshore research platform FINO-1 and the meteorological mast of the Dutch offshore wind park Egmond aan Zee. The data are compared to the Monin-Obukhov Similarity Theory using the Richardson Bulk Method, the Richardson Gradient Method and the Profile Methods. The results show that the models do not predict the wind speed profile well especially for stable stratifications and large scatter is present. Each model shows different ways to estimate the wind speed profile. The Richardson Bulk Method provides more accurate estimations as compared to other methods and thus it is preferred in further analyses. A sensitivity study is conducted for the model input parameters. The effects of sea surface and air temperatures, coast distance (fetch), reference wind speed and surface boundary layer height are analyzed in terms of mean wind speed estimation and its standard deviation. The model is indeed sensitive to those parameters, especially to air temperature and surface boundary layer height. The use of satellite model database for offshore wind energy purposes is shown in the last part of this work. The weather forecast model COSMO-EU, stored in the database of the Deutscher Wetterdienst DWD, is analyzed consequently and the data are compared with the measurements of FINO-1 for validation. Combinations of real and estimated measurements, respectively from FINO-1 and DWD, are shown for sea surface and air temperatures and relative humidity.","Windenergy","en","master thesis","","","","","","","","","Aerospace Engineering","","","","",""
"uuid:661db69c-b21d-49f9-8a8b-7ac01ca8220c","http://resolver.tudelft.nl/uuid:661db69c-b21d-49f9-8a8b-7ac01ca8220c","Indonesia's Education Policy","Van Schaik, B.","Van Beers, C. (mentor); Cunningham, S.W. (mentor); De Jong, W.M. (mentor)","2009","","","","master thesis","","","","","","","","","Technology, Policy and Management","","","","",""
"uuid:f06946e0-a51c-4e67-a26a-b5f15042e167","http://resolver.tudelft.nl/uuid:f06946e0-a51c-4e67-a26a-b5f15042e167","Draadloos netwerk in een dijklichaam","Van Oosterum, M.G.J.; Kers, J.W.B.; De Haan, E.J.","De Graaf, A.C. (mentor)","2009","Nederland wordt omringd door dijken. De dijken beschermen de bewoners in het achterliggende land tegen overstromingen. Momenteel worden dijken eens in de paar maanden visueel geïnspecteerd, maar dit blijkt niet voldoende te zijn. Het doorbreken van dijken wordt vaak niet voorspeld. Een aantal bedrijven ziet deze tekortkoming in een goede inspectie, en maken producten om real-time grondverschuivingen waar te nemen. De daarvoor benodigde sensoren zijn middels kabels aan een netwerkcontroller verbonden. Het dijklichaam dient echter zo min mogelijk aangetast te worden, omdat het de bescherming van de dijk doet afnemen. Dientengevolge was de vraag van de opdrachtgever om een draadloos netwerk te ontwerpen voor in een dijk, dat het huidige bedrade netwerk grotendeels vervangt. Het doel van deze thesis is dan ook het onderzoeken van de mogelijkheden van draadloze communicatie voor een dijkwaarnemend sensorsysteem. Daarbij is de thesis speci?ek gericht op het softwareontwerp voor deze toepassing, wat uiteindelijk moet leiden tot een prototype. Aan een draadloos netwerk zijn andere eisen verbonden dan aan een bedraad netwerk. Zo dient er rekening te worden gehouden met het feit dat de signaaldemping groter is. Daarnaast ontbreekt de mogelijkheid voor een centrale stroomvoorziening, waardoor ieder knooppunt individueel moet worden voorzien van energie. Mede daarom is energiezuinigheid een strenge eis aan het protocol. Daarnaast behoort het bereik en de uitleesfrequentie tot de belangrijkste eisen. Het is belangrijk dat de netwerkcontroller een volledige lijst heeft van alle knooppunten die zich in zijn netwerk bevinden. Vier verschillende initialisatiemethoden zijn beoordeeld op het aantal hertransmissies en de eenvoud van implementatie. Uit de beoordeling bleek dat initialisatie met back-off de beste optie was. Een geschikte netwerkcon?guratie moet worden gekozen om te kunnen voldoen aan de eisen aan het netwerk. Een aantal mogelijke con?guraties zijn: een maascon?guratie, een multipoint-to-pointcon?guratie en een GSM-con?guratie. Deze drie concepten zijn getoetst op bereik en betrouwbaarheid, energieverbruik, datasnelheid en kosten. De multipoint-to-pointcon?guratie werd daarbij het beste beoordeeld. Het ontwerp van het protocol wordt op deze con?guratie ingericht. Verschillende kanaaldelingstechnieken worden onderzocht om te zorgen dat meerdere knooppunten eerlijk gebruik maken van de beperkte netwerkcapaciteit. De meest geschikt bevonden techniek is Netwerk polling, een techniek waarbij de netwerkcontroller de data van alle knooppunten één voor één opvraagt. Tot slot worden een aantal foutbeheersingstechnieken beschouwd. Een bericht dat wordt verzonden in een draadloos netwerk zal namelijk regelmatig fouten bevatten. Het ontvangen van fouten wordt opgevangen door gebruik te maken van een combinatie van hertransmissies en foutcorrectiecodes. Het Stop-and-Wait protocol is ge?mplementeerd voor het regelen van hertransmissies en Hammingcode als foutcorrectiecode. De foutcorrectiecode Reed-Solomon als beste beoordeeld, maar door praktische redenen is gekozen om een Hammingcode te implementeren. Met het implementeren van de initialisatie met back-off, de kanaaldelingstechniek netwerk polling en de gecombineerde foutbeheersingstechniek in een multipoint-to-pointcon?guratie is de hoofdvraag van deze thesis beantwoord. Daarbij is voldaan aan de belangrijkste eisen om het energieverbruik te beperken, een bereik van 300 meter te halen en een uitleesfrequentie van de eens in de vijf minuten mogelijk te maken. Het is aanbevolen om bij verder onderzoek te kijken naar: een andere microprocessor, het aspect synchronisatie, foutenverdeling in een ontvangen bericht (om de foutcorrectiecode beter af te stemmen) en als laatst het optimaliseren van het inregelen van de datasnelheid. Uiteindelijk zal nog een uitgebreide test met software en hardware gecombineerd moeten worden verricht.","protocol; draadloze; dijk; draadloos; communicatie; netwerk","nl","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Circuits and Systems","","","",""
"uuid:64ad2b3d-2628-4720-94ec-d07af131ed47","http://resolver.tudelft.nl/uuid:64ad2b3d-2628-4720-94ec-d07af131ed47","Certification for Small Urban Wind Turbines: Verification of tlie lEC 61400-2 design methodology for a small wind turbine operating in the built environment","Chaves dos Santos, N.P.","van Bussel, G.J.W. (mentor); van Sark, W. (mentor); Simao Ferreira, C.J. (mentor)","2009","Microgeneration is a growing type of energy conversion used for generation of electricity in built environments such as urban areas. Among the different microgeneration technologies present in the market, small wind turbines have been showing a significant growth. The significant dissemination of its use and production and safety issues that arise from its deployment in urban areas have led to concerns in the insurance of its correct and safe design. Therefore the certification of the design process of these turbines is seen as an essential aspect to preserve this growing wind market worldwide. Currently, the design certification for Small Wind Turbines is set by the International Electrotechnical Commission in its lEC 61400-2 Ed.2 standard. It was considered that the present standard resulted from an adaptation and simplification of the lEC 61400-1 standard (used for the design large wind turbines), not considering some specific aspects typical of small wind turbines, nor the specific conditions of built environment wind conditions. The lEC 61400-2 standard introduces a methodology for load calculations based on a simplified load model by application of some simple equations. In order to validate this method for a small wind turbine operating in built environment wind conditions, aeroelastic modeling was used. Using real wind data obtained measured at an urban site (top of the Aerospace Engineering building), the loading on a 1.94 m rotor diameter turbine was analyzed by used of NWTC's FAST code. It was proven that the simplified load model underpredicted the loads for the maximum thrust load case. It was also proven that for the load case for Yawing, the simplified load model underpredicted the loading at yaw rates lower than the prescribed maximum. It was also proven that the high turbulence, typical of built environment wind conditions, generated higher loads than the ones predicted by the standard. Still, these results were considered complaint with the standard due to the large safety factor set for this load calculation methodology. However, these safety factors were considered to be not too informative or precise, limiting the validity of the simplified load model as a good load calculation method for the safe design of a small wind turbine.","Windenergy","en","master thesis","","","","","","","","","Aerospace Engineering","","","","",""
"uuid:10230245-e5b9-4888-8d97-29cc972727c3","http://resolver.tudelft.nl/uuid:10230245-e5b9-4888-8d97-29cc972727c3","Customer Complaint System","Aryan, A.; Ennaciri, C.","Pronk, C. (mentor)","2009","Inter IKEA Systems B.V. uses this application in order to track the complaints they get from their consumers.","","en","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Computer Science","","","",""
"uuid:f2d82a5b-3c11-483a-b01c-b059e9b61daa","http://resolver.tudelft.nl/uuid:f2d82a5b-3c11-483a-b01c-b059e9b61daa","Doublet Spacing in the “Delft Aardwarmte Project”","Den Boer, C.A.","Bruining, J. (mentor)","2009","In the “Delft Aardwarmte Project” cooled geothermal water is planned to be injected back into the producing formation. This paper describes the mechanisms occurring during injection and he prediction of the thermal breakthrough that are studied using a reservoir simulation model developed for the “Delft Aardwarmte Project” field properties. Using COMSOL it is shown that flow driven by the density difference between the cold injected water and the warm reservoir water occurs but is not expected to give large errors in production temperature prediction. Furthermore, numerical simulations of fluid flow and heat transfer between the doublet in the reservoir where performed using COMSOL. It was found that the currently planned 2000 meters will give the first temperature change in the production well after about 44 years. Considering the lifetime of the wells is about 30- 40 years this spacing would be more than enough. A more optimal spacing between the wells would be between 1500 and 1600 meters. The use of temperature dependent rock and fluid properties give the same thermal breakthrough time but a more favorable post-breakthrough behavior, in terms of a higher temperature for a longer period. Heterogeneous aspects are expected to be the key for more accurate temperature prediction as the thermal front movement follows the fluid flow with a certain lag. The combination of heterogeneity and temperature dependant fluid properties was analyzed. It was found that viscous crossflow can occur retarding the thermal breakthrough.","geothermal; doublet spacing; thermal breakthrough","en","bachelor thesis","","","","","","","","","Civil Engineering and Geosciences","Petroleum Engineering","","","",""
"uuid:364a2de9-3e91-4e59-b43d-4c9d14deedfb","http://resolver.tudelft.nl/uuid:364a2de9-3e91-4e59-b43d-4c9d14deedfb","Exploring the impact of emission trading on Schiphol","Priem, L.J.","Van Wee, G.P. (mentor); Annema, J.A. (mentor); Künneke, R.W. (mentor); Spring Associates (contributor)","2009","","","","master thesis","","","","","","","","","Technology, Policy and Management","","","","",""
"uuid:6c1078b2-a2a0-4dad-bbd5-1d576b1ae526","http://resolver.tudelft.nl/uuid:6c1078b2-a2a0-4dad-bbd5-1d576b1ae526","Expected Value of an Enterprise Architecture Function","Kobussen, W.A.A.","Van Veenstra, A.F.E. (mentor); Van Eeten, M.J.G. (mentor); Janssen, M.F.W.H.A. (mentor); Accenture (contributor)","2009","","","","master thesis","","","","","","","","","Technology, Policy and Management","","","","",""
"uuid:62518200-98ad-457a-8768-e28d809ae143","http://resolver.tudelft.nl/uuid:62518200-98ad-457a-8768-e28d809ae143","Evaluating and improving Lean Six Sigma by integrating leadership and communication","Boom, B.","Van Wee, G.P. (mentor); Ludema, M.W. (mentor); Dicke, W.M. (mentor); Heere, M.B. (mentor); Stork Fokker AESP B.V. (contributor)","2009","","","","master thesis","","","","","","","","","Technology, Policy and Management","","","","",""
"uuid:5f619f07-c6b4-4aa5-9dcd-963070d760f3","http://resolver.tudelft.nl/uuid:5f619f07-c6b4-4aa5-9dcd-963070d760f3","A System Dynamics Model for Operations Management Improvement in Multi-plant Enterprise","Mussa, Y.M.","Weijnen, M.P.C. (mentor); Lukszo, Z. (mentor); Slinger, J.H. (mentor); Behdani, B. (mentor)","2009","","","","master thesis","","","","","","","","","Technology, Policy and Management","","","","",""
"uuid:06fa7fde-019a-443e-9a6e-d606f311373c","http://resolver.tudelft.nl/uuid:06fa7fde-019a-443e-9a6e-d606f311373c","Analyzing Policies Stimulating Energy-Efficient Building in Thailand","","Thissen, W.A.H. (mentor); Bots, P.W.G. (mentor); Van Bueren, E.M. (mentor)","2009","","","","master thesis","","","","","","","","","Technology, Policy and Management","","","","",""
"uuid:7912f839-fa44-450b-afba-aca7696c7575","http://resolver.tudelft.nl/uuid:7912f839-fa44-450b-afba-aca7696c7575","Development of a mix design method in the laboratory for mixes with recycled asphalt pavement in a drum mix facility","Mengiste Merine, G.","Molenaar, A.A.A. (mentor)","2009","","","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Road and Railway Engineering","",""
"uuid:cb3bcde0-374b-4f9b-b5f4-865c12e424ce","http://resolver.tudelft.nl/uuid:cb3bcde0-374b-4f9b-b5f4-865c12e424ce","Crossing the Energy Vally of Death: Financing of low carbon electricity production technologies in the demonstration phase","De Vaan, S.","Groenewegen, J. (mentor); Correljé, A.F. (mentor); Bouwmans, I. (mentor); De Connick, H. (mentor); ECN (contributor)","2009","","","","master thesis","","","","","","","","","Technology, Policy and Management","","","","",""
"uuid:0ae4d52e-0202-4779-b5ef-8cfea1054c13","http://resolver.tudelft.nl/uuid:0ae4d52e-0202-4779-b5ef-8cfea1054c13","Ant Based Logistics Self-organization: Starting Fundamentals and Research Design","Gebremedhin Shibeshi, A.","Van Wee, G.P. (mentor); Ludema, M.W. (mentor); Den Hartigh, E. (mentor)","2009","","","","master thesis","","","","","","","","","Technology, Policy and Management","","","","",""
"uuid:0d4b1e0e-4bfb-4925-b696-98ac82f3c52a","http://resolver.tudelft.nl/uuid:0d4b1e0e-4bfb-4925-b696-98ac82f3c52a","Maintenance Strategies for the TANZAM Highway in Tanzania","Mwinchande, A.K.","Molenaar, A.A.A. (mentor)","2009","","","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Road and Railway Engineering","",""
"uuid:4aa2ada8-0cbe-4a97-a9eb-f97ba79182b9","http://resolver.tudelft.nl/uuid:4aa2ada8-0cbe-4a97-a9eb-f97ba79182b9","The Betuwelijn, or the failure of democracy as we know it?","Van Bergem, R.","Groenewegen, J. (mentor); Correljé, A.F. (mentor); Koppenjan, J.F.M. (mentor)","2009","","","","master thesis","","","","","","","","","Technology, Policy and Management","","","","",""
"uuid:0685d61f-5674-4168-8df4-e1b0c4713f7c","http://resolver.tudelft.nl/uuid:0685d61f-5674-4168-8df4-e1b0c4713f7c","Supporting Drug Development Projects: Finding the requirements for an information management system","Schuit, M.R.","Honig, H.J. (mentor); Van der Voort, H.G. (mentor); Verbraeck, A. (mentor); Bastiaanse, L. (mentor)","2009","","","","master thesis","","","","","","","","","Technology, Policy and Management","","","","",""
