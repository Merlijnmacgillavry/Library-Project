"uuid","repository link","title","author","contributor","publication year","abstract","subject topic","language","publication type","publisher","isbn","issn","patent","patent status","bibliographic note","access restriction","embargo date","faculty","department","research group","programme","project","coordinates"
"uuid:b7621fd0-3014-4b67-9749-fe866866afcf","http://resolver.tudelft.nl/uuid:b7621fd0-3014-4b67-9749-fe866866afcf","A clearing amidst movement","Treffers, Nils (TU Delft Architecture and the Built Environment)","Pimlott, M. (mentor); Koskamp, G. (graduation committee); Rosbottom, D.J. (mentor); Delft University of Technology (degree granting institution)","2020","Traffic square and station Marconiplein, the project site, has become a cacophony of highly controlled and isolated traffic domains which one wants to passage and exit as quickly as possible. Like many other metrostation in Rotterdam the passage of time dominates the passage of place and the notion of the station as real-estate prevails over it being a public landscape. This project translate an agency for architecture to merely materialise the real-estate for traveling consumers into an interest and potential agency for landscape and infrastructure to establish a more shared and public experience amongst strangers. The proposal re-establishes a sense of place, of arrival somewhere specific and significant. Crucial approaches to establish this are (1) a re-organisation of the site based on the re-introduction of historically present qualities and characteristics and (2) both the act of clearing and the clearing as physical interior to experience. In the proposal Marconiplein has become both park and station linked to bigger networks of transport and green fragments on a much bigger scale. Is has become a central public space, cleared from transport systems and framed by a bridge and tree canopies. The bridge and trees provide a functional route and shelter between all transport platforms whilst acting as decor of movement unfolding behind, up and underneath it. A carpet of different ground floor materialisations address different uses and complexities as a critical means of operating without fences, walls or buffer zones. Canopy and carpet together create a clearing and a series of different urban interiors around it that address the very different urban fragments surrounding the site. It has become a place where the station and parks benefit from and open up to each-others surprise and quality.","Station; Park; Transport; place; public space; infrastructure","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Interiors Buildings Cities","","51.913278, 4.432722"
"uuid:aba3f2eb-92c1-434a-97ce-ea523c896474","http://resolver.tudelft.nl/uuid:aba3f2eb-92c1-434a-97ce-ea523c896474","Curvature recovery using splines","Kromhof, Oscar (TU Delft Electrical Engineering, Mathematics and Computer Science)","den Ouden-van der Horst, D. (mentor); Delft University of Technology (degree granting institution)","2020","An analysis of curve interpolation with splines as a means to recover the curvature of a ordered set of discrete data points that originate from a closed smooth planar curve, in the context of the levelset method.","Splines; Curve interpolation; Level-set method; Curvature","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:ab1aab60-e7ad-4d32-bb82-1a5e2efd78fd","http://resolver.tudelft.nl/uuid:ab1aab60-e7ad-4d32-bb82-1a5e2efd78fd","Ramsey theory","Titulaer, Björn (TU Delft Electrical Engineering, Mathematics and Computer Science)","Hart, K.P. (mentor); Delft University of Technology (degree granting institution)","2020","In this report we will take a look at various proofs of Ramsey's theorem, some of the bounds that result from those proofs and applications of Ramsey's theorem. We will consider the proof of Ramsey himself, the proof of Skolem, the proof given by Erd\H{o}s and Szekeres and the proof of again Erd\H{o}s and Rado. The best upper bound for higher order Ramsey numbers is obtained by following the proof of Erd\H{o}s and Rado and this bound has only marginally improved since then. We will also state and prove the lower bound given by Erd\H{o}s and Hajnal. In the end we will apply Ramsey's theorem to both the Happy Ending problem and the monotone subsequence problem. The bounds we get for both problems using Ramsey's theorem, however, are quite weak compared to bounds that do not use Ramsey's theorem, so the theorem is more useful in proving the existence of a certain number than it is to find strong bounds for it.","Ramsey; Coloring; Hypergraph","en","bachelor thesis","","","","","","","","","","","","","",""
"uuid:1aeeaec7-e8ba-45b5-a9f2-64f61d97f9cc","http://resolver.tudelft.nl/uuid:1aeeaec7-e8ba-45b5-a9f2-64f61d97f9cc","Floor slab optimization: Reducing the environmental impact of concrete construction through fabrication-aware, structurally optimized floor slabs","Leemeijer, K. (TU Delft Architecture and the Built Environment)","Asut, S. (mentor); Schipper, H.R. (mentor); Delft University of Technology (degree granting institution)","2020","The building sector is responsible for 40% of worldwide carbon emissions, of which 8% can be attributed to concrete construction. With an increased demand for housing, this percentage is bound to increase. This thesis sheds light on strategies for reducing the environmental impact of concrete construction by investigating the potential of structural optimization and additive manufacturing. It concludes that in its current state, additive manufacturing is not able to address the environmental impact. Therefore, other potential strategies were explored, resulting in the following hypothesis: Fabrication-aware, structurally optimized floor slabs can significantly reduce the environmental impact of concrete construction. This hypothesis resulted in a derivative-free – fabrication aware – optimization methodology combining shape and size optimization to find the optimal form of a thin-shell inspired flooring system. A life cycle assessment resulted in an overall environmental footprint reduction that ranges from 60.1% to 79.8% compared to conventional flooring systems in a hypothetical office building. This shows the effectivity of flooring systems that take advantage of membrane action and the impact of increasing structural efficiency to reduce the environmental footprint of concrete structures.","Floor slab; Membrane action; LCA; Derivative-free optimization; Concrete; Fabrication aware structural optimization","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Building Technology","",""
"uuid:05998137-5d7d-4234-b8f7-d6c0ef517569","http://resolver.tudelft.nl/uuid:05998137-5d7d-4234-b8f7-d6c0ef517569","A THz Lens Antenna fed by a Photoconductive Connected Dipole Array","Pelekanidis, Antonios (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Microelectronics)","Neto, A. (mentor); Llombart Juan, N. (graduation committee); Mastrangeli, M. (graduation committee); Sberna, P.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","Photoconductive antennas have been used extensively for THz radiation the last few years. In this thesis, we propose a photoconductive connected dipole array consisting of 36x36 elements that is used as a feed in a THz silicon lens and radiates in a band ranging from 100 GHz to 5 THz. Specifically, we compute theoretically the radiated field patterns of the array as well as the secondary field beyond the lens. Furthermore, we investigate the feasibility of the fabrication of such a photoconductive connected array, given the challenges in 3D printing of a um-sized microlens array that is used to focus the laser power to the excitation gaps of the dipoles. We conclude that microlenses of sufficient accuracy can be fabricated in the premises of TU Delft without compromising the efficiency expected in theory. Lastly, we build a Matlab GUI that computes the far field radiated by various types and sizes of lens antennas in transmission, provided that the field radiated by the feed is already known. This tool has been successfully validated and supported the work in the first part of the thesis at the calculation of the far field of our proposed THz silicon lens antenna.","THz antenna; Photoconductive antenna; Microlens array","en","master thesis","","","","","","","","","","","","","",""
"uuid:00bdb306-13c1-431c-be5b-713fc03f42ea","http://resolver.tudelft.nl/uuid:00bdb306-13c1-431c-be5b-713fc03f42ea","GPU Acceleration of the PWTD Algorithm for application in High-Frequency Communication and Fotonics","Gravendeel, R.J. (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Delft Institute of Applied Mathematics)","Cools, K. (mentor); Vuik, C. (graduation committee); Lin, H.X. (graduation committee); van Driel, R (graduation committee); Delft University of Technology (degree granting institution)","2020","When creating electronic devices, it is essential to model what happens when an electromagnetic field hits the device and it scatters. Conventionally, this can be modelled using the Marching-on-in-Time algorithm. This can become computationally expensive for complex systems. To speed up the algorithm, the Plane-Wave Time-Domain algorithm is combined with the MOT algorithm. To accelerate the process even more, part of the algorithm is implemented using a Graphics Processing Unit, or GPU. <br/><br/>To test if using GPUs for this type of problem is actually beneficial, three experiments are set up. The first one tests the basic operations of addition and multiplication on matrices and vectors of various sizes, to determine if and when the computation time of the GPU is lower than that of a CPU. The second experiment tests the use of Fast Fourier Transform planner functionality and compares the CPU computation time with that of the GPU for the FFT of matrices of various sizes. The third experiment compares an example of the PWTD algorithm on the CPU and the GPU. These experiments are performed on three different devices. <br/><br/>The results from experiment 1 and 2 show that, after a certain point, the GPU is almost always faster, no matter the operation. Experiment 3 shows that the current GPU implementation is currently not as fast as the regular PWTD algorithm, though one of the devices is only 0.003\% slower. <br/><br/>In conclusion, theoretically a decrease in computation time is expected. From experiment 3 it follows that it is not the case yet, though with more optimisation the GPU implementation would almost certainly become faster.","GPU computing; Plane wave time domain; FFT; PWTD; Scattering","en","master thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:da0743aa-1598-403f-b142-c2cef0fb0e02","http://resolver.tudelft.nl/uuid:da0743aa-1598-403f-b142-c2cef0fb0e02","Usability of Physical Internet characteristics for achieving more sustainable urban freight logistics: barriers and opportunities revealed by dominant stakeholder perspectives","van Son, C.B.H. (TU Delft Civil Engineering and Geosciences)","Tavasszy, L.A. (mentor); van Duin, J.H.R. (mentor); van Binsbergen, A.J. (mentor); Delft University of Technology (degree granting institution)","2020","Urban freight logistics currently has to deal with multiple unsustainabilites. Physical Internet characteristics can be promising to make urban freight logistics more sustainable. It was researched if this can be the case and, what opportunities and barriers there are belonging to this change. With Q-methodology different stakeholder perspectives were revealed. This resulted in four different perspectives from which three had a positive attitude towards PI characteristics. One perspective was more moderate in relation to this and stated that a lot is possible already without changes happening. Opportunities and barriers are defined and it was concluded that there is currently no real need to change. Because an increase of national coordinated regulation was also assessed positively a policy framework was created that states individual and collaborative actions for stakeholders. With this 'an environment where efficiency pays off' should be created.","Physical Internet; Urban Freight Logistics; Sustainability; Q-methodology","en","master thesis","","","","","","","","","","","","Transport, Infrastructure and Logistics","",""
"uuid:d4c4d12b-111e-4992-b23d-f889b7bd3b19","http://resolver.tudelft.nl/uuid:d4c4d12b-111e-4992-b23d-f889b7bd3b19","Design of a decision making algorithm to support operators in a real-time production environment","Koot, S.N.J. (TU Delft Mechanical, Maritime and Materials Engineering)","Beelaerts van Blokland, W.W.A. (mentor); Schott, D.L. (graduation committee); Pruijn, J.F.J. (graduation committee); Delft University of Technology (degree granting institution)","2020","","","en","master thesis","","","","","","","","","","","","","",""
"uuid:20e81133-c326-4fc1-920e-74d313bd8ce5","http://resolver.tudelft.nl/uuid:20e81133-c326-4fc1-920e-74d313bd8ce5","Combined Ab-initio and Experimental Study of Hydrogen Sorption in Dual-Phase Steels","Sagar, S. (TU Delft Mechanical, Maritime and Materials Engineering)","Dey, Poulumi (mentor); Popovich, Vera (graduation committee); Delft University of Technology (degree granting institution)","2020","The formability of Advanced High Strength Steels is critical for their usability in automotive applications. It has been observed that the presence of hydrogen, even in concentrations of the order of 1 ppm, leads to a considerable drop in formability. Hydrogen atoms may get absorbed during steel-making and are known to get trapped at various sites in the lattice. When sufficient activation energy is made available, hydrogen atoms that are weakly trapped can diffuse towards critical regions in the microstructure, such as crack tips and voids, where one or more embrittlement mechanisms might be activated. On the other hand, a strongly trapped hydrogen atom remains immobile and plays no part in the embrittlement process. Precipitates of transition metals are known to be strong traps for hydrogen. It is speculated that by promoting the formation of strong traps in the microstructure, the amount of freely diffusible hydrogen can be limited, which would lead to an improvement in mechanical performance.<br/><br/>In this work, a combined ab-initio - experimental approach was used to study the absorption of hydrogen in dual-phase steel. Density Functional Theory (DFT) calculations were employed to study and compare the trapping of hydrogen by carbide and nitride of titanium and vanadium. A carbon or nitrogen vacancy in the bulk of the precipitate was found to be the most efficient trap site. When coupled with the vacancy formation energy, trapping was found to be more efficient in off-stoichiometric vanadium carbide and nitride than that in titanium carbide and nitride. To validate the theoretical findings, cyclic voltammetry experiments were conducted on two grades of DP800 steel with different concentrations of vanadium and titanium. The amount of diffusible hydrogen in the vanadium grade was found to be approximately 25 \% higher than that in the titanium grade. This was in contradiction to the theoretical results. Characterisation of the specimen post testing revealed that an oxide film had formed on the sample surface and while the film on vanadium grade was uniform and dense, that on titanium grade was sparse and irregular. It was evident that the oxide layer contributed to trapping of hydrogen, however the amount of hydrogen trapped by the oxide could not be specified. Overall, designing steels resistant to hydrogen embrittlement by promoting the formation of precipitates of a particular element is theoretically attainable, however, it was not possible to obtain experimental validation with the method employed.","Cyclic voltammetry; Density Funtional Theory; hydrogen embrittlement","en","master thesis","","","","","","","","","","","","Materials Science and Engineering","",""
"uuid:505123cb-125b-4877-a159-94f8d49c58e6","http://resolver.tudelft.nl/uuid:505123cb-125b-4877-a159-94f8d49c58e6","PUNet: Temporal Action Proposal Generation with Positive Unlabeled Learning using Key Frame Annotations","Zia, Noor ul Sehr (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Gemert, J.C. (mentor); Kayhan, O.S. (graduation committee); Delft University of Technology (degree granting institution)","2020","A good action proposal method should generate proposals with high recall and high temporal overlap with groundtruth. The quality of the proposals relies on the labeled data available during training. Obtaining labeled data for untrimmed videos is a time consuming, expensive and error-prone task. The labels obtained are also subjective and the temporal bounds are inconsistent between different human annotators. We propose using a single key frame label for each action instance instead of the start and end point labels to generate temporal proposals. This reduces the number of labeled action frames in the dataset leading to class imbalance. To overcome this, we replace the learning setting with a PU-learning setup. We demonstrate that using key frames as labels give high quality proposals and yield results comparable to using full annotations while being faster to annotate as the exact temporal bounds no longer need to be annotated. We evaluate our method on THUMOS'14 and ActivityNet v1.2 dataset. Further experiments indicate that by combining existing action classifier on our proposals, our method is able to achieve high mean average precision (mAP) for action localization.","Deep Learning; Action localization; Computer vision","en","master thesis","","","","","","","","","","","","","",""
"uuid:69f3db7f-1bf4-46a2-9aed-2e1021b1e8a2","http://resolver.tudelft.nl/uuid:69f3db7f-1bf4-46a2-9aed-2e1021b1e8a2","An Experimental Investigation of Shock-Induced Panel Flutter Using Simultaneous PIV and DIC","Quesada Allerhand, P. (TU Delft Aerospace Engineering)","D'Aguanno, A. (mentor); Schrijer, F.F.J. (mentor); Oudheusden, R.W.H. (mentor); Delft University of Technology (degree granting institution)","2020","The vibration of panel structural elements immersed in a supersonic flow is a poorly understood fluid-structure interaction (FSI) that can affect the performance and structural integrity of supersonic aircraft and spacecraft systems. These adverse effects are further amplified when a shock-wave/boundary-layer interaction (SWBLI) is formed over the panel. A better understanding of this phenomenon—referred to as shock-induced panel flutter—is therefore crucial for the design of future high-speed vehicles.<br/>An experimental method is developed to study shock-induced panel flutter at Mach 2 using planar particle image velocimetry (PIV) and stereographic digital image correlation (DIC) to obtain simultaneous, full-field structural displacement and flow velocity measurements. High-speed cameras are employed to conduct spectral analyses of the panel’s motion and the low-frequency dynamics of the SWBLI during the interaction. To avoid optical interference between the PIV and DIC systems, an optical isolation system is devised using fluorescent paint, dedicated light sources, and color lens filters. <br/>The devised experimental setup is used to study the effects of an impinging oblique shock on the dynamics of a flexible panel during flutter, and the effects on the mean flow separation and interaction length of a SWBLI when a rigid wall is substituted by a compliant plate. The coupling of the panel and SWBLI is also studied, identifying the regions in the flow of maximum correlation between the panel’s motion and the flow velocity fluctuations. The obtained results suggest that the inviscid flow region upstream of the SWBLI may play a significant role in the fluid-structure interaction. In addition, a parametric study is conducted to determine the effects of panel aspect ratio and edge boundary conditions on the three-dimensionality of the panel dynamics. The reported findings serve as a reference for future researchers when designing both experimental and numerical simulations of shock induced panel flutter, particularly if two-dimensional flutter is to be recreated.<br","Panel Flutter; SWBLI; PIV; DIC","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:cb109771-d367-42e2-bab0-702a9ccfc921","http://resolver.tudelft.nl/uuid:cb109771-d367-42e2-bab0-702a9ccfc921","Planning for Uncertainty: Adaptation Strategies for Agricultural Self-Reliance in the Lower Mainland of British Columbia, Canada","MacDonald-Nelson, James (TU Delft Architecture and the Built Environment; TU Delft European Master of Urbanism)","Hausleitner, B. (mentor); Nijhuis, S. (graduation committee); Delft University of Technology (degree granting institution)","2020","Despite relatively progressive policies put forth by the Canadian government to tackle the challenge of climate mitigation, cities and regions across the country are only beginning to address the equally important task of adaptation. This conversation typically focuses on the spatial adaptability of shorelines, dense urban environments, and the enhancement of green spaces. While these measures are undoubtedly important to implement, there is a lack of public awareness regarding how our region’s food systems and the agricultural landscapes that sit on edge of cities across Canada, must also adapt. <br/>Agriculture is a key part of the Canadian economy, both in the export of products grown domestically and the importation of products from the United States, Mexico, and Asia. This reliance on imported food is a standard part of the food supply chain in Canada. However, with a changing climate affecting places like California (where a lot of fresh produce is imported from) and global challenges such as the COVID-19 pandemic, these supply chains are becoming more vulnerable to unexpected disruptions. This, in turn, threatens the food security of all Canadians. This thesis explores the adaptive potential of the local and regional food system in Canada’s only urbanized delta region, the Lower Mainland of British Columbia. As with all delta regions around the world, this low-lying metropolitan region will increasingly face many challenges related to flooding, ongoing urbanization, and the unpredictability of extreme natural disasters that threaten communities and food production. The Lower Mainland is one of the most agriculturally dynamic regions in Canada and is unique as a considerable amount of arable and cultivated land is integrated closely with the urban fabric of the territory. However, with decreasing self-reliance in regional food production and an over-reliance on cheap imported products, the Lower Mainland is at a crossroads when it comes to the future of its food system. The intent of the design proposal is to find ways in which to rebalance regional food cultivation by expanding how and where production takes place. Integrating agriculture tightly within communities and using it as a catalyst for new public spaces, urban development, and agri-tech innovation along a key regional corridor will serve as the basis for the design exploration. <br/>The objective of this thesis is therefore to demonstrate how the spatial and functional organization our food systems can, and must, adapt given the uncertainty of our collective future. Vulnerable supply chains, unexpected disasters and shifts in the global economy significantly risk our ability to adequately feed people. If we take this issue seriously and begin planning for an uncertain future by first addressing what makes us most vulnerable, we can begin to adapt and build the capacity to face these challenges with confidence. <br","Agriculture; Urbanism; Adaptation; Self-reliance; Canada; British Columbia; Lower Mainland","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Landscape Architecture","",""
"uuid:fc019b06-1f1f-4b4a-8735-52ff1ddf9018","http://resolver.tudelft.nl/uuid:fc019b06-1f1f-4b4a-8735-52ff1ddf9018","Circularity in the Dutch train","van Oudheusden, A.A. (TU Delft Industrial Design Engineering)","Baha, S.E. (mentor); Balkenende, A.R. (graduation committee); de Vos van Eekeren, Ilse (graduation committee); Delft University of Technology (degree granting institution)","2020","This graduation project makes a contribution to this complex challenge by researching the question “How can NS achieve circular inflow and outflow during building, modernisation and end-of-life for the train interior, car body and bogies?”. A contribution to this challenge was made by creating a design concept for a sustainable interior side wall panel. The current panel is made of glass fibre polyester composite, which is difficult to reuse or repurpose, and cannot be recycled. The sustainable alternative is made use of recyclable aluminium honeycomb materials, and has a dismountable structure due to the use of reversible Niaga adhesive. The flat shape of the panel combined with the optimized surface distribution increase the available panel size, which increases the potential for reuse or repurpose. Additionally, the wall panel is finished through the use of coloured foil instead of paint as this reduces toxic substances and improves cleanability, readjustability and recyclability. It also gives additional customization options to the panel, such as integrating a honeycomb pattern to illustrate the circular construction. <br/><br/>This report also reflects on the application of design methodology by researching the question “How can design methodology be used to structure a complex design project?”. Two design methods were chosen for this: the 1:10:100 approach and the Design Roadmapping methodology. The 1:10:100 approach was chosen as this is suitable for open-ended projects. I found that the 1:10:100 method was very useful to quickly determine a project scope but it lacked structure within the ‘100’ cycle. I found the midterm and green light graduation deadlines to be useful additions to further structure the iterative process. Design Roadmapping was chosen as it combines future roadmapping and design. NS was interested in creating a roadmap towards fully circular trains, whereas the Industrial Design Engineering department was interested in my skills as concept designer. The roadmap has not been finished within the timespan of this project, but this report makes good progress along the analyses steps of this method. Additionally, I felt this method helped me to keep focus on the future instead of focusing too much on current practice.","Sustainability; Circularity; Trains","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:3e700e76-2c43-43ec-96b2-a2d327fffb86","http://resolver.tudelft.nl/uuid:3e700e76-2c43-43ec-96b2-a2d327fffb86","Viability of a service-oriented approach on Dutch infrastructure projects","Biese, Matias (TU Delft Civil Engineering and Geosciences)","Bakker, H.L.M. (mentor); Schraven, D.F.J. (mentor); Straub, A. (graduation committee); Rijnen, Rob (graduation committee); Delft University of Technology (degree granting institution)","2020","The Dutch public infrastructure faces several challenges in the coming decades. A significant portion of public infrastructure such as bridges need to be replaced or renovated in the coming decades, and the public infrastructure authorities have set an ambitious goal to become completely circular by 2030. Service-oriented infrastructure (Infrastructure-as-a-service) is presented as a solution to require contractors to increase circularity as they would be incentivized to retain the value of assets. This study aims at developing a research framework to be used by public clients assessing the viability of a service-oriented approach. The study uses the Double Diamond design framework to first conduct interviews and codify them, followed by designing a framework through iterative designs and validating it in an interview with a public client (Dutch water board). Grounded theory is used for analyzing the interviews from specific infrastructure assets to general theory. The framework presents six criteria [Innovation, Integrality, Public authority &amp; ownership, Supply, Circularity and Duration] on which a service-oriented approach should be analyzed. The study finds that clients first and foremost focus on their statutory duties, while optimization of infrastructure is seen as risky if the fines for failing to provide an adequate service are manifold in comparison to the perceived benefit. The study finds that a service-oriented approach should be considered only in specific (mostly high-technology) cases where the benefit of continuous improvement through the service-delivery is evident. The study contradicts an earlier study in the Netherlands, which declared that all stakeholders should shift towards a service-oriented approach in order to guarantee circularity. The timeline to become completely circular is too short to let the market build up a complete supply of circular infrastructure and supply it on a service-oriented basis.","Infrastructure-as-a-service; Service-oriented; PaaS; Bridges; Pumping stations; PV Systems","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:dafb58d8-37c5-4585-990b-218870c5de28","http://resolver.tudelft.nl/uuid:dafb58d8-37c5-4585-990b-218870c5de28","Numerical modelling of underwater sand cutting process","Wang, Xiuqi (TU Delft Mechanical, Maritime and Materials Engineering)","Miedema, S.A. (mentor); Chen, X. (graduation committee); Delft University of Technology (degree granting institution)","2020","To realize sustainable development, offshore wind energy has been a highly valuable solution to meet the demand for renewable energy. Accompanied with the construction of the offshore wind turbines, cable casting and the following cable trenching process in the underwater condition are necessarily required. The research on the underwater sand cutting process so far has been limited to some extent. (Miedema, 2014) has suggested the analytical solution and performed the experiments of underwater sand cutting. But all the work until then was in 2D and the description of the water influence was in the scope of statics. Thus, it is necessary to carry out the numerical simulation to describe the cutting process and the effect of the fluid by means of DEM-CFD coupling. (Chen et al., 2015) suggested a framework of modelling the underwater excavation process. The method is to describe the particle phase by Discrete Element Modeling (DEM) and the flow phase by Finite Volume Method (FVM). Starting from this method, the software package CFDEM coupling, LIGGGHTS for DEM calculation and OpenFOAM for CFD calculation, is applied. In the coupled simulation, DEM transfers the particle information to CFD. CFD solves the governing equations and updates the pressure field and velocity field. Then the fluid-solid interaction forces are calculated in CFD and transferred back to DEM. Sand particle is not spherical in reality. To describe the sand particles more accurately, a constant directional torque is added to each spherical particle to restrict its angular movement. And the sphericity of the particles is adjusted to make the sand sample in the simulation have reasonable permeability. Two sets of the numerical simulations of underwater sand cutting are conducted in this research, the simulations of 2D effect and 3D effect. The results from the simulations of 2D effect are validated with the analytical and experimental results, while the ones of 3D effect are mainly analyzed to investigate the fluid flow field and the fluid-solid interaction force. Many factors are analyzed to find out their effects on the cutting process, such as the blade geometry, the cutting layer thickness, the hydrostatic pressure, the cutting speed and the particle size. Many conclusions are found from the simulation. It turns out that the stress on the blade increases with the blade angle, the cutting layer thickness and the cutting speed. The relation between the stress and cutting layer thickness is approximately linear. And the stress has nothing to do with the hydrostatic pressure and the particle size. The features of the fluid flow field show some differences according to low, medium and high cutting speeds. The dilatation happening in the shear zone can be observed from the distribution of the fluid pressure. With a higher cutting speed, the pressure gradient in the shear zone is larger. For the fluid-solid interaction force, the effect of the cutting speed is very obvious. Besides, the dimensionless cutting forces from the simulation matches good with those from the experiments by (Miedema, 2014). From the simulation with large blade angles, a wedge between the blade and the layer cut is observed both from the velocity distinction of the particles and the stress on the blade. With the good matching in the validation work, this research confirms the reliability of DEM-CFD coupling to describe the underwater sand cutting process. Although the analysis is into depth in many aspects, further research is still needed. Using spherical particles with a constant counter torque to describe sand particles gives reasonable results. Non-spherical particle is another possible solution that is worthy to try. And the analysis about the cavitation is necessary to be performed.","Numerical modelling; DEM; CFD; sand cutting","en","master thesis","","","","","","","","2025-12-31","","","","Offshore and Dredging Engineering","",""
"uuid:2f431d6e-e61d-443a-9f3e-9459d50a4492","http://resolver.tudelft.nl/uuid:2f431d6e-e61d-443a-9f3e-9459d50a4492","Reinforced hybrid concrete beams with a U-shaped SHCC mould: Developing the system and extending the multi-layer model to predict its bending behaviour","Yassiri, Ammar (TU Delft Civil Engineering and Geosciences; TU Delft Concrete Structures)","Lukovic, M. (mentor); Pavlovic, M. (graduation committee); Šavija, B. (graduation committee); Sligman, S.A. (graduation committee); Delft University of Technology (degree granting institution)","2020","Hybrid concrete-SHCC beams are a new development in construction techniques. SHCC stands for Strain Hardening Cementitious Composite. In such beams, the tension zone could for example consist, next to the traditional reinforcement, of a material that shows strain hardening behaviour. That helps with controlling the crack width. In traditional (non-hybrid) beams, the steel reinforcement would have to control the crack width on its own. This means that there are situations that the steel reinforcement fulfills the strength requirements, but additional steel reinforcement is needed to limit the crack width. Therefore, a certain amount of steel reinforcement is needed for meeting the SLS (Serviceability Limit State) requirements, while it is not used for the ULS (Ultimate Limit State) requirements. The use of hybrid beams consisting of an SHCC layer applied in the tension zone in which the reinforcement is embedded, solves this problem. This was shown in previous MSc studies by Huang and Singh. In this study, the concept of the hybrid beam is extended. A design was made of a reinforced U-shaped SHCC mould, to be used for casting a hybrid beam. In that way, a reinforced hybrid concrete beam is created, in which the webs of the U-shape prevent the need of temporary moulds at the side of the beam, which reduces costs. A complete design is presented which is ready for further research. Next to that, it is investigated how the bending behaviour of beams, that are made using this concept, can be modelled. This was done by extending the multi-layer model, that was first proposed by Hordijk in 1991. Different from the previous built models, the model proposed in this thesis includes additional aspects, such as imposed deformations caused by drying shrinkage, and the possibility to model hybrid beams (with a U-shape). After this model was extended using VBA in Microsoft Excel, it was successfully verified by comparing its results with experimental and analytical results from previous research. Comparing the force-to-displacement curves showed that the end-resistance of the beams is predicted well by the extended multi-layer model, and that generally the same trend of the curve is followed by the model. The bending resistance of the proposed experimental setup of a hybrid beam containing a U-shape was also modelled. However, as this experiment has not been performed before, there were no experimental results to compare with. Therefore, the results for this setup are to be compared with the results that follow after experimenting with the presented design of the beam.","mulit-layer model; SHCC; hybrid concrete beams; U-shaped mould","en","master thesis","","","","","","","","","","","","Civil Engineering | Structural Engineering","",""
"uuid:6e236ba3-b69e-4771-b24a-42c42887159a","http://resolver.tudelft.nl/uuid:6e236ba3-b69e-4771-b24a-42c42887159a","Monte Carlo Sampling Techniques for the Efficient Estimation of Risk Metrics of a Stochastic Distribution Grid Power Demand Model","Betge, Julian (TU Delft Electrical Engineering, Mathematics and Computer Science)","Tindemans, S.H. (mentor); Droste, Barbera (mentor); Heres, Jacco (mentor); Rueda Torres, J.L. (graduation committee); Ziar, H. (graduation committee); Delft University of Technology (degree granting institution)","2020","The Distribution System Operator (DSO) Alliander has the ambition to explore possibilities of improving its predictive demand modelling applications. This research aims to contribute to one of these, the Advanced Net DEcision Support (ANDES) model, which provides detailed predictions for long-term capacity planning. This thesis pursues two main objectives: Firstly, the creation of a probabilistic power demand model which reflects the volatile nature of real customer demand in an adequate manner. Secondly, the development and evaluation of methods to estimate certain model output quantities of interest in a computationally efficient manner. To this end, variance reduction techniques have been investigated. Self-tuning Importance Sampling (IS) methods giving different weight to time steps and/or customer load profiles have been developed. In order to make the optimisation stage superfluous, additionally an approach to find a generalised asset distribution has been investigated. The essential finding from evaluating all considered methods was that their performance in terms of efficiency and accuracy depends mainly on two variables – the order of magnitude of the estimated quantity and the number of customers connected to an asset in question. For small assets and an estimated overload probability of the order 1e-5 or smaller, all profile IS methods and especially the generalised bin probability IS showed the strongest performance with average speed-ups of 5-30 times with respect to the reference method of sampling full annual traces. For assets with more than 80 customers and small overload probabilities, the profile IS methods were found to frequently produce estimates of a significantly too small order of magnitude. Conventional Monte Carlo (MC) sampling and time step IS, in turn, produced reliable estimates regardless of the number of customers. For assets of all sizes with an estimated overload probability of the order 1e-4 and larger, conventional MC sampling showed the best performance with speed-ups above 5 times. Overall, conventional MC sampling performed robustly in all circumstances, while IS demonstrated its potential to significantly increase the estimation efficiency of rare event probabilities in certain cases. To determine which magnitudes demand maxima and minima can potentially reach, Extreme Value Theory (EVT) has been applied. The computationally more efficient methods and extreme value inference were considered not compatible, sampling full annual traces appears to be required for a reliable estimation of maximum and minimum demand return levels. Based on the findings of this thesis, a flexible algorithm could be investigated in future research which employs IS for rare event probabilities and conventional MC sampling otherwise. For an integrated evaluation of all risk metrics, the algorithm could initially sample 200 entire annual traces to be used for extreme value inference.","Monte Carlo Simulation; Importance Sampling; Rare Event Estimation; Power Demand Modelling","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:bb04dfea-34f1-4907-b61e-8b4bc86bb56b","http://resolver.tudelft.nl/uuid:bb04dfea-34f1-4907-b61e-8b4bc86bb56b","Make Food Great Again: An Architectural Spatial Strategy to implement the Technological Advantages of the 4th Agricultural Revolution in the Built Environment for Reciprocal Benefit","Scho, Alex (TU Delft Architecture and the Built Environment)","Vink, J.A. (mentor); Holst, J.P.G. (graduation committee); Kuzniecow Bacchin, T. (graduation committee); Rizoretti, Francesca (graduation committee); Delft University of Technology (degree granting institution)","2020","Make Food Great Again is a prototype for the future of Urban Agriculture. Thereby its a spatial strategy to address the urgencies connected to the biochemical pollution of agricultural enterprises on the example of the Netherlands. It aims to find a solution for the burden of ultra effective state of the art agriculture on the environment, while sustaining the foodsupply in a circular economical manner.<br/>It’s the architectural answer to the question of how can our food become local and approachable again, while being an actually integrated part of infrastructure in contemporary urban society?","Urban Agriculture; Society Acceptance; Urban & Industrial Infrastructure; Circular Economy; Agriculture 4.0","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Transitional Territories","North Sea: Landscapes of Coexistence","51.819410, 4.686540"
"uuid:a6480af1-bd42-4426-b588-b6334a854a85","http://resolver.tudelft.nl/uuid:a6480af1-bd42-4426-b588-b6334a854a85","Fault Tolerant Control of Multirotor UAV for Piloted Outdoor Flight","Narasimhan, Abishek (TU Delft Aerospace Engineering)","Delft University of Technology (degree granting institution)","2020","The thesis aims to develop a Fault Tolerant Control (FTC) architecture, for the case of a damaged actuator for a multirotor that can be applied across multirotor platforms based on their Attainable Virtual Control Set (AVCS). The research is aimed to study the AVCS and identify the parameters that limit the controllability of multirotor UAV post an actuator failure. Based on the study of controllability, the requirements for a FTC is laid out. The implemented control solution will be tested on a quadrotor, Intel® Shooting StarTM UAV platform in indoor and outdoor flights using only the onboard sensors. The attitude control solution is implemented with reduced attitude control, and the control allocation is performed with pseudo-inverse based model inversion with sequential desaturation to ensure tilt priority. The model is identified with an offline Ordinary Least Squares routine and subsequently updated with the Recursive Least Squares method. An offline calibration routine is implemented to correct IMU offset distance from the centre of rotation to correct for accelerometer bias caused during the high-speed spin after failure in a quadrotor.","UAV; MAV; quadrotor; Quadrotor Control; Attitude Control; Sensor fusion; System Identification; INDI","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:d5143594-80d1-465f-8dce-8cae5432bf6b","http://resolver.tudelft.nl/uuid:d5143594-80d1-465f-8dce-8cae5432bf6b","Improvements of the classical simulation of quantum circuits: Using graph states with local Cliffords","Rijlaarsdam, Matthijs (TU Delft Electrical Engineering, Mathematics and Computer Science)","Al-Ars, Z. (mentor); Elkouss Coronas, D. (mentor); Borregaard, J. (mentor); Coopmans, T.J. (graduation committee); Delft University of Technology (degree granting institution)","2020","With this thesis project, we improve the classical simulation of quantum computers using stabilizers in the GSLC formalism. We do this in two ways: we present new algorithms that speed up their simulation and extend their applicability by defining new operations and subroutines for existing general circuit simulation using GSLC. To be precise: we present multiple new algorithms that speed up the simulation of the CZ gates, the most computationally expensive quantum operation in GSLC formalism. We define two new operations on GSLC that are useful when simulating stabilizer circuits: calculating fidelity (a measure of 'closeness' between two quantum states), and tracing out qubits (throwing away the information about the state contained in these qubits) from a GSLC. Finally, we present a new GSLC-based subroutine for a state of the art general quantum circuit simulation algorithm by Bravyi et al. that allows for the usage of the faster CZ algorithms. We show that the GSLC formalism can give a speedup in practical simulation tasks by evaluating the complexity of simulating an algorithm with possible applications on near-term quantum hardware: the quantum approximate optimization algorithm.","","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:74d6427b-8623-4cae-9030-c26e76853eb5","http://resolver.tudelft.nl/uuid:74d6427b-8623-4cae-9030-c26e76853eb5","The Terrascope: Earth’s Atmosphere as a Telescopic Lens","Alpert, Shane (TU Delft Electrical Engineering, Mathematics and Computer Science)","Visser, P.M. (mentor); Stam, D.M. (mentor); Delft University of Technology (degree granting institution)","2020","This research contains the design, modeling, and analysis of the Terrascope. This apparatus intends to use the Earth’s atmosphere as a lens to bend light rays from celestial objects and focus them into a detector placed at a distance from the Earth, for example, the Moon. We develop an independent model from that of David Kipping, on whose Terrascope research this work is based. Our Terrascope model uses gradient-index optics to calculate the light bending through the Earth’s atmosphere. We also model three different atmospheric effects which modify the light passing through the atmosphere: turbulence, Rayleigh scattering, and ozone absorption. Our results show that turbulence has the largest impact on the light, and, consequently, on the functioning of our Terrascope. It causes the light to spread out, decreasing the image resolution and amplification. Without atmospheric effects, our model simulations predict a maximum amplification of about 55,000, the same results as Kipping. This occurs when using a 1m detector aperture, 1.5×10ዃm detector distance, and 1000nm wavelength light. Using the same parameters, when scattering and absorption are considered, the amplification decreases by 14%. When turbulence is considered, the amplification decreases by 99.98% to a total of 10. This is much lower than Kipping’s prediction of 22,500. We conclude that turbulence is the most important aspect of the Terrascope to consider in any future work. The Terrascope continues to be interesting concept for study and may have promise for observing celestial objects if a farther detector distance, longer light wavelength, and different atmosphere are considered.","","en","master thesis","","","","","","","","","","","","","",""
"uuid:3b085f0e-39dc-4aca-ae15-d11453cca589","http://resolver.tudelft.nl/uuid:3b085f0e-39dc-4aca-ae15-d11453cca589","Machine Learning of Synthetic Lethality: Data Integration, Generalisation, and Selection Bias","Seale, Colm (TU Delft Electrical Engineering, Mathematics and Computer Science)","de Pinho Gonçalves, J.S. (mentor); Reinders, M.J.T. (graduation committee); Hauff, C. (graduation committee); Delft University of Technology (degree granting institution)","2020","Synthetic lethality (SL) arises between two genes when loss of function of both genes would lead cells to become inviable. This can be exploited for therapy, where a drug is used to selectively kill diseased cells by perturbing one gene of an SL pair where the other gene is inactive (e.g. through naturally occurring mutation). Computational prediction of SL relationships is very appealing as it can help reduce cost- and labour-intensive experimental testing to the most promising candidate pairs. Even though machine learning models have shown promising results for SL prediction compared to traditional statistical approaches, crucial questions remain. First, which sources of molecular data are most useful for SL prediction? Many approaches rely on either cell line or patient tumour data separately, and ignore data from healthy tissue. We argue these should be combined to leverage relevant data sources that are exclusively available for cancer cell models and patient tumours, and to enable the transfer of knowledge between models and actual patient tumours. Likewise, changes in the relationship of gene pairs between healthy and tumour tissue may be informative for SL prediction. We assess several machine learning techniques to best leverage molecular profiles for cancer-specific or pan-cancer SL prediction. Second, what are the effects of selection bias on SL prediction methods and which techniques are most robust? This has been insufficiently addressed, as models in the literature are often tested using data from one or two cancer types or datasets. We investigate robustness to cancer representation and gene selection biases, which are inherent to most SL datasets. We hypothesise that approaches based on matrix factorisation will be especially sensitive to the latter, as they are dependent on an a priori SL network structure, which also determines the scope of the prediction space.","Machine-learning; Synthetic lethal; generalisation","en","master thesis","","","","","","","","","","","","Computer Science | Data Science and Technology","",""
"uuid:ef7f5a6f-556d-43a7-8e29-153b546cb04b","http://resolver.tudelft.nl/uuid:ef7f5a6f-556d-43a7-8e29-153b546cb04b","Evaluation of the feeder nourishment concept for the Atlantic southeast coast of the United States: A case study for Hilton Head Island, South Carolina","Crielaard, Roy (TU Delft Civil Engineering and Geosciences)","Hopkins, J.A. (mentor); de Schipper, M.A. (graduation committee); Storms, J.E.A. (graduation committee); McFall, Brian (graduation committee); Aarninkhof, S.G.J. (graduation committee); Delft University of Technology (degree granting institution)","2020","About 80-90% of U.S. East Coast barrier beaches have experienced erosion in the last 100 years. South Carolina’s coastline forms no exception, a third of its developed shoreline experiences erosion. Among these eroding shorelines is Hilton Head Island, the second largest barrier island on the U.S. East Coast. Until now, erosion here has been addressed through traditional local beach nourishments. An alternative approach to the traditional nourishment method, are so-called feeder nourishments or feeder beaches. The potential advantages of the feeder nourishment concept over the traditional method are reduction of the nourishment frequency, containment of the ecological stress in a relatively small area, and a short to medium term increase of local available space for recreation and the environment. Given the potential advantages above, the residents of Hilton Head Island asked TU Delft to investigate the possibility of applying a feeder nourishment at their shoreline. Currently, a pilot project known as “The Sand Engine” is examined along the Dutch coast. Several studies into its morphological behaviour show that this feeder nourishment can be beneficial to the sediment budget of a larger coastal cell. Because of the promising results at the Sand Engine pilot project, it is tempting to state that a feeder-nourishment could also be applied at Hilton Head Island. The problem, however, is that the conditions at Hilton Head Island and the Sand Engine are different. There are two main differences between Hilton Head Island and the Sand Engine. First, Hilton Head is subjected to a relative calm wave climate in comparison to the Sand Engine. Second, the presence of two tidal inlets at Hilton Head, compared to a relative straight and uninterrupted coastline at the Sand Engine. As a result, the conclusions drawn from the Sand Engine pilot project do not necessarily hold for Hilton Head Island as well. The main objective of this thesis is to analyse the morphological behaviour of a feeder nourishment located at Hilton Head Island. First, to study its potential as a measure against erosion at Hilton Head. Second, to compare its morphological behaviour to that of the Sand Engine. And third, to be able to examine the potential of the concept for the Atlantic southeast coast of the U.S. in general. The morphological development of a feeder nourishment at Hilton Head Island was simulated with Delft3D over the course of 1 year for different model scenarios, with varying forcing conditions and varying bathymetric features. The effect of the relative calm wave climate at Hilton Head Island in comparison to the Sand Engine is twofold. First, the contribution of wave forcing to the total erosional volume of the feeder nourishment after 1 year is smaller as compared to the Sand Engine. Eliminating all driving forces besides wave forcing reduces the total erosional volume to 58% at Hilton Head, in comparison to 75% at the Sand Engine. Second, the contribution of storm events to the total erosional volume after 1 year from the feeder nourishment is smaller at Hilton Head compared to the Sand Engine. It measures 23% at Hilton Head, in comparison to 60% at the Sand Engine. To assess the impact of the two tidal inlets on the feeder nourishment, they were closed off. Closing of the tidal inlets eliminates any (potential) residual currents. This reduces the total amount of sediment that is eroded from the feeder nourishment by 7% compared to a reference scenario with open tidal inlets. Before construction of the feeder nourishment the coastline south of the nourishment experienced a net sediment outflux of approximately 4000 m3/year. After construction of the feeder nourishment, the southern section experiences a net import of sediment of approximately 100.000 m3/year. Meaning that the southern section, on average, has transitioned from being erosive to accreting. Up to 500 meter away from the nourishment the cross-shore profile shows a seaward movement of the shoreline position of approximately 25 m compared to the original situation without nourishment. Before construction of the feeder nourishment the coastline north of the nourishment experienced a net sediment outflux of approximately 40.000 m3/year. After construction of the feeder nourishment, this net outflux of sediment has decreased to approximately 25.000 m3/year. This shows that the feeder nourishment is feeding sediment to the northern section, but at a rate that is not sufficient to keep up with the underlying erosion rate. The northern domain, on average, still experiences a sediment outflux and stays erosive. Roughly 50 m of coastline directly north of the feeder nourishment experiences a seaward movement of the shoreline position. However, moving further away from the nourishment, the shoreline remains erosive. The Atlantic southeast coast of the United States is made up of North Carolina, South Carolina, Georgia and Florida’s east coast. The South Carolina and Georgia coastline are comparable in both hydrodynamic conditions and geomorphological setting. They are mixed-energy coasts, broken up by numerous tidal inlets, and home to short barrier islands with complex sediment transport patterns. North Carolina’s and Florida’s east coast are wave-dominated, with relative straight shorelines. Which is distinctly differences from the conditions found at Hilton Head Island. Therefore, the potential of the feeder nourishment concept is only analysed for South Carolina’s and Georgia’s coastline. The presence of numerous tidal inlets leads to strongly varying conditions along the coastlines of both states. The developed locations along South Carolina’s coastline that require erosion mitigating measures are south Debidue beach, North Island, Hunting Island and Daufuskie Island. Along Georgia’s coastline there are only some erosion hotspots along Sea Island’s coastline that require erosion mitigation measures. The wave climate at all the above mentioned location is similar to Hilton Head. A southeast swell, with a narrow range of directions and an annual wave height of roughly 1,0 m. The same goes for the tidal range. The results at Hilton Head show that erosion on adjacent coastal sections can be lessened and/or prevented by constructing a feeder nourishment. Given that these locations are subjected to similar conditions, the construction of a feeder nourishment could potentially be an effective measure to prevent or lessen the occurring erosion.","Feeder Nourishment; Hilton Head Island; DELFT3D","en","master thesis","","","","","","","","","","","","Civil Engineering | Hydraulic Engineering","",""
"uuid:c91ff997-644d-4637-9a7a-d7c8bffc34e1","http://resolver.tudelft.nl/uuid:c91ff997-644d-4637-9a7a-d7c8bffc34e1","Design of a data collector for HEMS crew during OHCA","Zhang, Yu (TU Delft Industrial Design Engineering)","Goossens, R.H.M. (mentor); van Heur, R.J.H.G. (graduation committee); Dos Reis Miranda, Dinis (graduation committee); Delft University of Technology (degree granting institution); Erasmus Medical Center (degree granting institution)","2020","The HEMS crew is planning to conduct research on implementing ECPR treatment during OHCA cases. A data collector that collects time and chest compression data is needed for the research. Thus, this graduation project is focused on the design of a data collector for HEMS crew during OHCA. This report describes the whole process of developing the design of the data collector. The process starts with a design brief that elaborates the design assignment. Then four cycles of project development are carried out: the first cycle is focused on context analysis and exploration of possible solutions; the second cycle is focused on the electronics prototype and data transfer system building; the third cycle is focused on the housing design of the collector; the last cycle is concluded with a validated final design and recommendations on implementation. This project collaborates with Dr. Dinis Reis Miranda from the HEMS lifeliner 2 and Erasmus MC - University Medical Center.","HEMS; CPR; ECMO; OHCA; Data collector","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:20738ae9-011f-4002-8f5e-9168c9176f02","http://resolver.tudelft.nl/uuid:20738ae9-011f-4002-8f5e-9168c9176f02","Accuracy-Diversity Trade-off in Recommender Systems Via Graph Convolutions","Pocchiari, M. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Isufi, E. (mentor); Cesar Garcia, P.S. (graduation committee); Hauff, C. (graduation committee); Krijthe, J.H. (graduation committee); Delft University of Technology (degree granting institution)","2020","Recommender Systems assist the user by suggesting items to be consumed based on the user's history. The topic of diversity in recommendation gained momentum in recent years as additional criterion besides recommendation accuracy, to improve user satisfaction. Accuracy and diversity in recommender systems coexist in a delicate trade-off due to the complexity in capturing user tastes through a limited amount of interactions. Graphs have been employed for recommendation, given their ability to efficiently represent user-item interactions. Graph convolutions, as learning over graphs tools, have reached state-of-the-art accuracy on recommender system benchmarks. However, the potential of graph convolutions to improve the accuracy-diversity trade-off is unexplored. Here, we develop a model that learns from a nearest neighbor and a furthest neighbor graph via a joint convolutional model to establish a novel accuracy-diversity trade-off for recommender systems. In detail, the nearest neighbor graph connects entities (users or items) based on their similarities and is responsible for improving accuracy, while the furthest neighbor graph connects entities based on their dissimilarities and is responsible for diversifying recommendations. The information between the two convolutional modules is balanced already in the training phase through a regularizer inspired by multi-kernel learning. Numerical experiments on three benchmark datasets showed the joint convolutional model can improve substantially the catalog coverage or the diversity among recommended items; or boost both by a lesser amount. We compared our model against state-of-the-art accuracy-oriented algorithms, showing diversity gains up to seven times by trading as little as 1\% in accuracy. We also compared the joint model against algorithms proposing a different accuracy-diversity trade-off, evidencing our model achieves better accuracy while preserving a wide diversity range. Our findings highlight that the joint convolutional model offers a balance in each setting that is difficult to be achieved with a single model.","Accuracy-Diversity; Collaborative filtering; Graph filters; Graph convolutions; Graph convolutional neural networks; Graph signal processing","en","master thesis","","","","","","","","","","","","Computer Science | Data Science and Technology","",""
"uuid:a68da48d-747b-4714-a5ad-75c1a802969f","http://resolver.tudelft.nl/uuid:a68da48d-747b-4714-a5ad-75c1a802969f","Stationary sets and on the existence of homeomorphisms between them: Stationaire verzamelingen en het bestaan van homeomorphismes tussen deze","Vermeulen, Joop (TU Delft Electrical Engineering, Mathematics and Computer Science)","Hart, K.P. (mentor); Delft University of Technology (degree granting institution)","2020","Stationary sets are important tools in proofs of properties in sets of uncountable cardinality. In this thesis we look at mapping properties between stationary sets. First, the theory necessary for the construction and evaluation of stationary sets is made. That is the theory of ordinal, cardinal and regular cardinal numbers is build up from the level of knowledge of a mathematics student. Two important theorems for stationary sets, Fodor's theorem and the theorem of Ulam and Solovay, are proven. Next mapping properties of stationary subsets of a regular cardinal $\kappa$ under measurable functions is looked into. With these properties we construct a necessary condition for the existence of homeomorphisms between stationary sets; they may only differ on a non-stationary set. Lastly the amount of stationary subsets of a regular cardinal k without a homeomorphism between them is estimated as the cardinality of the power set of k. We find that there are 2 to the power k topologically incomparable subsets of k.","Stationary set; Regular cardinal; Homeomorphism","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:b4ddc548-c1f6-47f3-9b5a-9ae27cab9738","http://resolver.tudelft.nl/uuid:b4ddc548-c1f6-47f3-9b5a-9ae27cab9738","An Optimization Model to Upgrade the Charging Network of Electric Vehicles","Fu, Dawei (TU Delft Civil Engineering and Geosciences)","van Arem, B. (mentor); Delft University of Technology (degree granting institution)","2020","The current city charging network for electric vehicle (EV) is mainly composed of low-speed charging points. When the number of EVs increase dramatically in the future, the current charging network needs to be upgraded with more charging stations and fast-charging (FC) facilities. We build a mixed-integer programming (MIP) model to propose an upgrading scheme for a city’s public EV charging network, in which new stations can be constructed and some low-speed chargers will be upgraded to fast chargers. The model considers two charging patterns. Drivers can stay at the charging station or walk to their activity places during the charging process, which affects drivers’ satisfaction to a large extent if the waiting time or walking distance is unacceptable. Hence, our optimization model has the objective of minimizing the network upgrading cost and the drivers’ sacrifice of waiting at charging stations and walking to their activity places. In the case study, we obtain the features of the driver’s charging behavior from the analysis of Den Haag’s EV charging database and utilize these features as model inputs. The optimal solution shows that about 40% of the old charging stations are upgraded with faster chargers in the new charging network, and the network adopts more FC stations at the territory with a high vehicle density. Meanwhile, half of the drivers choose to charge at FC stations after upgrading, and every driver can find a charging position at their desirable charging time within an average walking distance of about 160m from the activity place. The new charging network has a great utilization situation during the day, and more than 65% of the charging positions are in operation at night. Through varying the budgets for network upgrading, waiting time cost and travel penalty, our model provides many different upgrading schemes for decision-makers. The solutions reveal that the travel penalty and budget have a noticeable influence on the network capacity, while the waiting time cost mainly influences the number of super-fast charging stations. If we take customer’s satisfaction level into the first place, the investor ought to provide an adequate budget for network upgrading and install a few super-fast charging stations to improve the charging speed.","Public charging network; electric vehicles; MIP model; charging demand satisfaction; upgrading cost; charging behaviors","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:1dd1f4c9-8c9e-4d92-93bb-872291d3d4d3","http://resolver.tudelft.nl/uuid:1dd1f4c9-8c9e-4d92-93bb-872291d3d4d3","A Cloud-Based DevOps Toolchain for Efficient Software Development","Ding, Ruiyang (TU Delft Electrical Engineering, Mathematics and Computer Science)","Epema, D.H.J. (mentor); Drocan, Mikko (mentor); Rellermeyer, J.S. (graduation committee); Specht, M.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","In the traditional software development life cycle, development and operation are divided into different departments. The conflict between departments and, besides, the lack of automation usually leads to low software development efficiency and slow software delivery. Thus, the concept of DevOps is introduced, which combines different departments and automates the process to make software delivery faster and easier. The DevOps toolchain is one important component for adopting DevOps. On the other hand, the adaptation of cloud technology, especially serverless computing makes it tempting for us to investigate what benefits serverless computing brings to the DevOps toolchain. In the first research question, we examine the benefits that AWS serverless platforms bring to DevOps toolchain. To answer this research question, we develop a DevOps toolchain hosted in Amazon Web Services (AWS) and leverage the serverless computing service. In addition, we examine what does each serverless computing service brings to the DevOps toolchain, examine how does the performance of the DevOps toolchain changes with or without using serverless computing service. Our research shows that serverless computing services such as AWS Fargate could reduce the cost, operation effort, and improves performance by enabling parallel execution. Our experiments show that in contrast to a toolchain hosted in a traditional cloud server vs the toolchain that was developed by us using serverless computing service could reduce the total runtime of parallel execution up to 65%. In the second research question, we focus on the integrated toolchain build with AWS DevOps tools from AWS serverless platform. We build a demo integrated DevOps toolchain with AWS DevOps tools and compare the integrated toolchain with the non-integrated toolchain that we built. We find that the integrated toolchain significantly reduces the development time by providing an out-of-box solution for the software team. In addition, the better integration with underlying cloud infrastructure provides more functionality such as global monitoring and blue/green deployment. However, we also find that from the experiment that the performance of the integrated toolchain is lower due to the limitation of resources which also come with a high cost.","Cloud Computing; DevOps; AWS; Serverless Computing","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:cf50ef4b-801b-4645-aab5-31c55abf07a1","http://resolver.tudelft.nl/uuid:cf50ef4b-801b-4645-aab5-31c55abf07a1","Tilting at windmills: Data augmentation for deep pose estimation does not help with occlusions","Pytel, Rafal (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Gemert, J.C. (mentor); Kayhan, O.S. (mentor); Reinders, M.J.T. (graduation committee); Liem, C.C.S. (graduation committee); Delft University of Technology (degree granting institution)","2020","Occlusion degrades the performance of human pose estimation. In this paper, we introduce targeted keypoint and body part occlusion attacks. The effects of the attacks are systematically analyzed on the best-performing methods. In addition, we propose occlusion specific data augmentation techniques against keypoint and part attacks. Our extensive experiments show that human pose estimation methods are not robust to occlusion and data augmentation does not solve the occlusion problems.","Deep Learning; Computer Vision; Human Pose Estimation; Occlusions; Data augmentations","en","master thesis","","","","","","","","2020-08-24","","","","","",""
"uuid:c96fc91d-b95b-4227-b373-9e62aaba0ccd","http://resolver.tudelft.nl/uuid:c96fc91d-b95b-4227-b373-9e62aaba0ccd","Design and Fabrication of an Irradiance Sensor for Bifacial PV","Kaul, Annanta (TU Delft Electrical Engineering, Mathematics and Computer Science)","Isabella, O. (mentor); Ziar, H. (mentor); Delft University of Technology (degree granting institution)","2020","With the rapid growth of bifacial modules in the market, it is becoming increasingly important to have sensors that provide data for both sides of the module. Such sensors can give more information about the performance of PV modules and PV plants. The collected data from such sensors can also help to optimize the tilt/orientation of the PV structure and give valuable information about albedo. However, such sensors need to account for the different spectral reflectance properties of different surfaces. Most sensors in the market measure the total irradiance across the entire solar spectrum; and ones which do yield spectrally resolved data can be quite expensive. In light of the above, the aim of this thesis was to design and fabricate a cost-effective sensor that will measure the irradiance in different parts of the solar spectrum. The goal was to obtain an initial prototype which can subsequently be improved. To this end, the different hardware components were procured and assembled. Diffusers were used on top of the sensor to provide a uniform cosine response. Silicon photodiodes were used as sensing elements and optical filters were used to divide the solar spectrum into different wavelength ranges. The irradiance passing through the filter and diffuser reaches the photodiode, where it generates an electrical current. The magnitude of this current is directly proportional to the incident irradiance; and this relation is used to calculate the irradiance value. A transimpedance amplifiers used to convert the output current from the photodiodes into voltage. This analog voltage signal is converted to a digital signal using a microcontroller. The resulting data is transmitted to the PC. The LabVIEW software program is used to convert the incoming voltage signals to their corresponding current values, which in turn are used to calculate the irradiance. In this way, the total irradiance over 300-1100nm and the irradiance values across 3 separate wavelength ranges (300-700nm, 700-900nm, 900-1100nm) can be estimated. The device was calibrated and validated using outdoor measurements at the monitoring station and a final Irradiance Sensor V1.0 was developed. The irradiance values measured by the device were compared with the measurements of the EKO MS700 Spectroradiometer. This comparison was used to obtain a calibration factor for the sensor. After accounting for this factor, the root-mean-squared error (RMSE) of the total irradiance measurement (300-1100nm) dropped from 25.16% to 14.15%. The RMSE for measurements in separate wavelength ranges also reduced: 23.11% to 8.87% over 300-700nm; 7.8% to 6.4% over 700-900nm; and 8% to 3.5% for 900-1100nm. Using the same calibration factors, the RMSE of measurements taken on a second day were also seen to reduce. In this way, the Irradiance Sensor V1.0 was developed. The final device weighs 1.02kg, has a volume of 122x120x80mm3, and costs€345.","Irradiance Sensor; albedo; calibration","en","master thesis","","","","","","","","2023-08-31","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:deb6815e-0f79-4571-b607-c4d051f1f755","http://resolver.tudelft.nl/uuid:deb6815e-0f79-4571-b607-c4d051f1f755","MDO with composite aeroelastic tailoring","Deshmukh, Piyush (TU Delft Aerospace Engineering)","Veldhuis, L.L.M. (mentor); De Breuker, R. (mentor); Vos, R. (mentor); van Gent, I. (mentor); Rajpal, D. (graduation committee); Delft University of Technology (degree granting institution)","2020","With the focus on the reduction of fossil fuel emissions, aircraft are continuously growing towards higher fuel efficiency. The traditional limits of aircraft performance can be surpassed through the use of composite materials which offer a reduction in aircraft weight. Due to the multidisciplinary nature of aircraft design, integration of different disciplinary analyses is required to arrive at a feasible design. The inclusion of composite design in the preliminary design process, however has become a challenge. This is due to the high computational cost associated with the composite aeroelastic tailoring tools used in the design process. A possible solution is available in the form of surrogate models which can reduce the computational costs. The current work focuses on the development of a methodology that allows the inclusion of surrogate-based model in the optimization for a computationally expensive aeroelastic tool (PROTEUS) developed at TU Delft. The resulting methodology can be expanded to a generic, computationally expensive tool in a multidisciplinary optimization setting. Wing design optimization is carried out based on surrogate modeling methodology and metal based design method. Comparison is made of the final optimized designs based on structural and performance parameters.","KADMOS; surrogate modeling; Composites; PROTEUS","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:332e9781-93f8-4738-8951-e97c9452a8c2","http://resolver.tudelft.nl/uuid:332e9781-93f8-4738-8951-e97c9452a8c2","Circular Collaborations in Urban space: A tool-kit for scaling through engagement","Odayakulam Balasubramaniam, Dheebak (TU Delft Industrial Design Engineering)","Mulder, I.J. (mentor); Calderon Gonzalez, A. (graduation committee); Brown, P.D. (graduation committee); Delft University of Technology (degree granting institution)","2020","A circular economy is a means to an end of achieving a sustainable world, a lot of traction has been gained in the recent years into the concept of a circular economy and many new products and business models have been created around the concept. But most of the exploration of the concept lies in the possibilities of new product and market opportunities, this makes the concept difficult to move towards a societal level change, where circular economy becomes the norm. To enable this societal level change, ecosystem level innovations are important and collaborations play a key role in enabling eco-system innovation. This is what this project tries to explore, collaborations for a circular economy, in the context of the urbanspace. The findings suggested that a shared vision is important for collaboration to take place but the organisations did not actively pursue for having a shared vision and values with their various collaborators, instead the thing that they focused on for operationalizing their innovation was engagement. They focused on engagement to showcase the value of their organisation’s offering beyond the end product. As they increased their visibility in the urbanspace and increased their ways and number of engagements, the organisations grew and people with similar values collaborated with the organisations. They scaled through engagement. Scaling through engagement is a mindset for growth of the organisation based on engagement as opposed to the linear model of thinking of making more. The final design, tried to enable organisations operating in the urbanspace to scale through engagement. This was pursued by creation of an online tool-kit for circular organisations operating in the urbanspace, which aimed at creating awareness into the concept of scaling through engagement, it’s relating ideas and also help organisations create ideas around scaling through engagement for their own organisation. In conclusion, this project is a step in the right direction away from scaling by making more and towards scaling through engagement. Apart from the tool-kit, the findings from the research add valuable insights into how circular organisations operating in the urbanspace innovate and collaborate in a circular economy. On a broader perspective, this project gives a glimpse into how societal level transitions for a circular economy could take place and what it would mean in practice.","Participatory City Making; Delft Design Labs; Designscapes; Systems thinking; Circular Collaboration; Circular economy; Collaboration; Ecosystem innovation; Urban Space; Engagement","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:30496d1c-f5bb-402f-ac3c-6eba27598859","http://resolver.tudelft.nl/uuid:30496d1c-f5bb-402f-ac3c-6eba27598859","Identifying Author Fingerprints in Texts via Graph Neural Networks","Sipko, Tomas (TU Delft Electrical Engineering, Mathematics and Computer Science)","Isufi, E. (mentor); Delft University of Technology (degree granting institution)","2020","The world is generating more and more network data in many different areas (e.g., sensor networks, social networks and even text). A unique characteristic of these data is the coupling between data values and underlying irregular structure on which these values are defined. Thus, researchers developed Graph Neural Networks (GNNs) to use deep learning approaches on these irregular network data. GNNs developers tried to replicate the recent success of Convolutional Neural Networks (CNNs) and developed its graph counterpart Graph Convolutional Neural Network (GCNN) and more different variations of GNNs (e.g. EdgeNet). However, all these architectures are relatively young, and the impact of different parameters to classification result is not well researched compared to regular neural network architectures. To address this issue, we propose to use authorship attribution problem to research the impact of different architectures and their variations to classification accuracy and how GNNs can be used to improve on authorship attribution task compared to the baseline architectures. Explicitly, we define the dataset which is going to be used throughout the experiments and the method to convert text excerpts of authors into the network that can be classified with GNNs (called WAN). WAN is as a network that captures unique author fingerprint. We also define the set of GNN architectures (and different combinations and variations of them), baseline architecture (SVM) and experiments that are used with those architectures. This experiment setting allows us to compare different GNN architectures among themselves and the baseline architecture. Also, we define a method to reduce the dimensions of author fingerprints (WANs) and use these sparse author fingerprints for the same experiments with the same architectures. Numerical results show the improvement over the baseline architectures in nearly all defined experiments. Also, we found that more complex GNN architectures (e.g. EdgeNets) are superior to shallower architectures with more laborious experiments (e.g. classification by gender). More complex architectures also require hyperparameter re-tuning in order to achieve optimal results. Furthermore, experiments with sparse author fingerprints showed that we could achieve comparable results to standard fingerprints with faster training times and significantly reduced dimensions. GNN architectures used with sparse author fingerprints were usually superior to baseline architectures.","Authorship attribution; Graph neural networks; Graph signal processing","en","master thesis","","","","","","","","","","","","","",""
"uuid:e29efa73-a52c-4047-a9db-287e6b8b4e07","http://resolver.tudelft.nl/uuid:e29efa73-a52c-4047-a9db-287e6b8b4e07","Exploring the Synthesis and Optoelectronic Properties of Cs<sub>2</sub>AgSb<sub>x</sub>Bi<sub>1-x</sub>Br<sub>6</sub> Double Perovskites: A Combined Computational and Experimental Study","Phadke, S.A. (TU Delft Applied Sciences)","Savenije, T.J. (mentor); Delft University of Technology (degree granting institution)","2020","Perovskite photovoltaic (PV) cells have become one of the most highly researched topics in photovoltaics and have achieved unprecedented increases in device efficiencies, but their commercialization remains hindered by their low stability and high toxicity. The currently best performing perovskite PV cells contain lead, a neurotoxic material whose use is prohibited under many national consumer protection laws, thus impeding adoption by industry. A class of materials called double perovskites offer an elegant pathway to lead-free, low-toxicity perovskites for PV cell applications by replacing the Pb<sup>2+</sup> cation in the perovskite with a mixture of charge 1+ and 3+ cations. A promising double perovskite, Cs<sub>2</sub>AgBiBr<sub>6</sub>, was first synthesized in 2016 and has been used in the fabrication of PV devices with efficiencies of ≤2.5%. While numerous research groups have attempted various synthesis routes and produced various final materials, little is known about the dynamics of the double perovskite synthesis or the effect of further metal substitution on the material’s optoelectronic properties. In this work, the solution phase synthesis of Cs<sub>2</sub>AgBiBr<sub>6</sub> was studied via Density Functional Theory (DFT) and the optoelectronic properties of Cs<sub>2</sub>AgSb<sub>x</sub>Bi<sub>1-x</sub>Br<sub>6</sub> thin films were explored, with antimony substitution presented as a method to lower the band gap to make a more favorable perovskite for PV cell applications. <br/><br/>The synthesis method of the thin films involved mixing all of the precursors in DMSO solvent and spin coating. However, only BiBr<sub>3</sub> and SbBr<sub>3</sub> were found to dissolve individually in solution, indicating a sequential pathway to double perovskite crystallites in solution. Geometry optimizations of Bi-Br-DMSO complexes were performed via DFT using the BLYP functional, with COSMO used to approximate a solution phase system. While COSMO was found to be incompatible with the corrected method of calculating the interaction energy, the relatively low (~11%) basis set superposition error was accepted and the uncorrected calculation method was used to find the most stable Bi-Br DMSO complexes in solution. These complexes were analyzed using TD-DFT and the CAM-B3LYP functional to simulate absorbance spectra and match them to experimental solution spectra. While one of the transitions at ~3.9 eV may be ascribed to a larger cluster of [Bi<sub>4</sub>Br<sub>20</sub>]<sup>8-</sup>, the source of the stronger experimental transition at ~3.5 eV could not be determined. The dominant electronic transition of the Bi-Br-DMSO system was a metal-to-ligand charge transfer from the 6푠 orbital of the central bismuth ion to the 3푝 orbital of the bromine ligand. <br/><br/>A facile synthesis method reported in literature was attempted for the synthesis of Cs<sub>2</sub>AgSb<sub>x</sub>Bi<sub>1-x</sub>Br<sub>6</sub> thin films, described briefly above. The method was found to produce thin films of high crystallinity but with a tendency to degrade upon exposure to ambient conditions, as evidenced by x-ray diffraction (XRD) measurements. A reduced annealing temperature of 90°C rather than 250°C led to the successful substitution of Sb<sup>3+</sup> for Bi<sup>3+</sup> in the double perovksite while simultaneously avoiding material degradation (at the cost of optoelectronic performance). Shifts in the lattice parameter of ~0.05 Å and shifts in the absorbance onset energy of ~0.2 eV were found by XRD and absorbance measurements, respectively, for antimony replacement of up to x = 0.7. The optoelectronic properties of the materials were studied using time-resolved microwave conductivity (TRMC) measurements, and showed a decrease in photoconductance of two orders of magnitude and a reduction of charge carrier lifetime as the annealing temperature was lowered from 250°C to 90°C. Low temperature absorbance measurements combined with TRMC measurements indicated that the peak in the absorbance spectra was most likely the result of an excitonic transition.","Perovskite; Double Perovskite; Non-Toxic; Sustainabilty; Thin Films; Density Functional Theory","en","master thesis","","","","","","","","","","","","","",""
"uuid:3e595d78-726d-4c55-b59e-bf6695791e31","http://resolver.tudelft.nl/uuid:3e595d78-726d-4c55-b59e-bf6695791e31","Comparative case study into the barriers that prevent QKD and Tokamak nuclear fusion power plants from large scale diffusion","Stam, B.C. (TU Delft Technology, Policy and Management)","Ortt, J.R. (mentor); Vermaas, P.E. (graduation committee); Delft University of Technology (degree granting institution)","2020","This research has the aim to investigate the large pre-diffusion period for two<br/>technologies: quantum cryptography and nuclear fusion power plants. Both technologies originate from basic physics research, have a high societal value and are a business to business product. First, a status overview of the technologies is given together with its principles and (dis)advantages. Hereafter, the high-tech products are positioned in a life cycle pattern and pre-defined factors that could create a barrier to large scale diffusion are investigated. <br/><br/>In the following chapters, other literature is investigated and different reasons for a long pre-diffusion period are explored. The literature that is used to determine the position in the life cycle pattern and investigation of factors, is critically reviewed and discussed. Different factors outside the existing framework are found that apply to the cases of quantum cryptography and nuclear fusion power plants. Additionally, a bias due to the telecom industry data that has been used to build the framework has been observed in different aspects of the diffusion theory. <br/>This research is conducted by the means of a comparative case study, including a literature review and the opinion of an expert. <br/><br/>The final delivery of this research is a proposition for an extended diffusion theory and a thorough discussion on validity and decision making within the framework. In this proposition the diffusion theory is extended with additional factors: type of funding, potential misuse of a technology, competition, managing expectations and a case specific factor. The current and additional factors are categorized into different types of factors. Additionally, a distinction between niche applications, innovations and split-offs in the life cycle pattern is made and discussed. Finally, notes on the validity of the assessment of factors are given. <br","Diffusion theory; Innovation theory; Breakthrough technology; Nuclear fusion power plants; Quantum Cryptography","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:0a71876b-9a9d-4d22-8a9b-9c8dcb508ea6","http://resolver.tudelft.nl/uuid:0a71876b-9a9d-4d22-8a9b-9c8dcb508ea6","Quasi-Newton Methods for tSNE","Chaves De Plaza, Nicolas (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Comp Graphics & Visualisation)","Vilanova Bartroli, A. (mentor); Hildebrandt, K.A. (mentor); Delft University of Technology (degree granting institution)","2020","TSNE is a popular technique for visualizing high-dimensional data. It finds a low-dimensional representation of the data, also known as embedding, by optimizing a highly non-linear cost function. The optimization process is done iteratively, often with first-order methods such as gradient descent (GD). The performance of iterative optimization procedures depends on the time that it takes to execute each iteration and the number of iterations that are required to converge to an optimum. In the context of tSNE, different methods that tackle these issues have appeared, but, despite their success, they are still limited by their separate development. For instance, BH-SNE, one of the most popular variants of tSNE, uses the Barnes-Hut algorithm to accelerate each iteration, but still uses GD, which needs a large number of them to converge. On the other hand, quasi-Newton optimization methods are effective at reducing the number of iterations, but available implementations are constrained by the additional per-iteration cost. In our work, we attempted to reconcile these two research branches. For this, we investigated the usage of Line Search (LS) and Trust Region (TR) based quasi-Newton methods for tSNE and improved their performance by identifying and addressing several of their bottlenecks. Among the different aspects of quasi-Newton optimization for tSNE that we covered were the selection of a suitable Hessian approximation, the usage of approximate gradients and cost function evaluations, and the choice of linear solver, which the algorithm uses to find the next iterate. The resulting techniques, which we denote SD-LS-CG and SD-TR-CG, have a lower per-iteration cost than alternative quasi-Newton methods and converge in fewer iterations than the traditional implementation of tSNE, which uses a highly tuned version of GD. The results suggest that these quasi-Newton methods could be a better alternative to fast tSNE implementations such as BH-SNE, given their overall faster convergence. Furthermore, we observed that SD-LS-CG was able to consistently avoid local optima if initialized with PCA, suggesting that the choice of Hessian approximation can have a similar role to the early exaggeration phase in tSNE.","data visualization; dimensionality reduction; t-SNE; nonconvex optimization; quasi-Newton methods","en","master thesis","","","","","","","","","","","","","",""
"uuid:3c80ae32-9162-4efe-a7ac-3ab6192f2f70","http://resolver.tudelft.nl/uuid:3c80ae32-9162-4efe-a7ac-3ab6192f2f70","Time-Efficient Video Annotation with t-SNE","Poorgholi, Soroosh (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Gemert, J.C. (mentor); Kayhan, O.S. (mentor); Loog, M. (graduation committee); Höllt, T. (graduation committee); Delft University of Technology (degree granting institution)","2020","Video understanding has received more attention in the past few years due to the availability of several large-scale video datasets and improvement in the computational power of computers. However, annotating large-scale video datasets are cost-intensive due to their complexity. In this work, we propose a time-efficient video annotation method using spatio-temporal feature similarity and t-SNE dimensionality reduction to make the annotation process more efficient. Placing the same actions from different videos near each other in the two-dimensional space based on feature similarity helps the oracle to group label the video clips. We evaluate the performance of our method on two subsets of the ActivityNet (v1.3) dataset. We show that our method can outperform conventional video labeling tools time-wise while maintaining a reasonable test accuracy on video classification task compared to the ground-truth labels. To further evaluate the generalization of our method, we test our performance on Sports-1M and Breakfast datasets.","t-SNE; Annotation cost; Video Annotation; Dimensionality Reduction","en","master thesis","","","","","","","","","","","","","",""
"uuid:443faa26-5141-4bb6-b36b-97e269b69471","http://resolver.tudelft.nl/uuid:443faa26-5141-4bb6-b36b-97e269b69471","The aftermath of multiyear droughts: A case study in Australia","van Terwisga, Stijn (TU Delft Civil Engineering and Geosciences; TU Delft Water Management)","Hrachowitz, M. (mentor); Coenders-Gerrits, Miriam (graduation committee); Vizcaino, M. (graduation committee); Delft University of Technology (degree granting institution)","2020","In this report the hydrological response to multiyear droughts has been researched. Long-term droughts have resulted in an increase in tree die-off in affected areas. As the hydrological response is related to the vegetation in a catchment, it is of interest to find out whether catchment response regarding rainfall-runoff is different after a long-term drought relative to the situation before the drought. It is important to know this, because a good prediction of water availability is required for making decisions regarding water resources. The research is conducted in Australia, where a long-term drought took place from 1997 up to 2008. The two research questions that have been investigated during this research are: 1) Is there a change in runoff ratio (the fraction of precipitation that becomes runoff) in catchments after a long-term drought relative to the situation before the drought? 2) Is there a change in the root-zone storage capacity (the amount of storage available in the root-zone of the soil) determined with the mass curve technique following a multiyear drought? In this research, the runoff ratio observed after the drought has been compared to the runoff ratio before the drought. This is done to determine whether a change has taken place in the rainfall-runoff relationship of the catchment. In the catchments where the rainfall-runoff relationship shows a change from the situation before the drought, a decrease in runoff ratio is mostly observed. In 54 out of the 196 analyzed catchments, the runoff ratio is lower than the 10 percentile of the runoff ratio before the drought. In 27 catchments, the runoff ratio after the drought is above the 90 percentile of the runoff ratio before drought. In most of the studied catchments no clear difference in the rainfall-runoff relationship can be found due to a long-term drought. Factors that were found to play a role in the differences between the responses to a drought were the drought severity, which is a combination of the drought length and the intensity of the drought, and the seasonality of the precipitation. Catchments that had an increase in runoff ratio were more likely to have a longer drought period and a summer-based precipitation pattern. For the second research question, the root-zone storage capacities have been determined using an earlier derived mass curve technique method, combined with a method that has been developed for recovering ecosystems. In order to compare root-zone storage capacities before and after a drought, a variable is introduced that describes the differences between the values for the root-zone storage capacities before and after the drought. Catchments that showed an increase in the runoff ratio were also more likely to have a negative change in the root-zone storage capacity. This indicates that the root-zone storage capacity decreases in catchments that show an increase in the runoff ratio after drought.","Droughts; Root-zone storage capacity; Australia; Hydrology; Runoff ratio","en","master thesis","","","","","","","","","","","","Water Management","",""
"uuid:7b0f3919-0e78-4264-9e8f-028cf3fcde31","http://resolver.tudelft.nl/uuid:7b0f3919-0e78-4264-9e8f-028cf3fcde31","Reconstruction of Phylogenetic Networks: An algorithm for deconstructing and reconstructing Level-2 Binary Networks based on their distances","Mol, Riche (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Iersel, L.J.J. (mentor); Murakami, Yukihiro (graduation committee); van Elderen, E.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","Van Iersel, Moulton, and Murakami (2020) proved that a level-2 binary phylogenetic network can be uniquely reconstructed based on the matrix of mulitsets of the distances of the leaves. Using a handful of lemma’s each<br/>describing the steps of identifying cherries, uncontained leaves and blobs in the network, I created an algorithm for deconstruction the theoretical network corresponding to the matrix, and constructing the network based on the deconstruction steps. Unfortunately, this algorithm is not of polynomial time, as in the deconstruction programs are run that take time proportional to the sizes of the multisets of distances, which are upperbounded by 4n, where n is the number of leaves in the network. This algorithm is tested on more than 35000 networks with 10 to 24 leaves, and resulted in no errors.","","en","bachelor thesis","","","","","","","","","","","","","",""
"uuid:14a9cf28-1833-40dc-8fca-dcc8c48a5dea","http://resolver.tudelft.nl/uuid:14a9cf28-1833-40dc-8fca-dcc8c48a5dea","Fenton Oxidation Initiated by FeOCl Pre-Coat for Cleaning Persistent Gel-Like Fouling of Ceramic Nanofiltration","YAO, Lu (TU Delft Civil Engineering and Geosciences)","Rietveld, L.C. (mentor); Pidko, E.A. (mentor); Heijman, Sebastiaan (mentor); Lindeboom, R.E.F. (mentor); Delft University of Technology (degree granting institution)","2020","Ceramic nanofiltration (NF) is a newly developed technology for municipal sewage reclamation for drinking water production, agricultural and industrial utilisation, but organic fouling limits it to pilot-scale application. Herein, Fenton-based cleaning catalysed by FeOCl pre-coat was performed on ceramic NF membrane to clean persistent gel-like fouling. FeOCl pre-coating on ceramic NF membrane was conducted by pressure-driven filtration. Gel-like fouling was simulated by Ca-alginate. The compact fouling layer was proposed to impede the diffusion of H2O2; therefore, NaCl was introduced to perform Na-Ca ion exchange to relax the fouling layer and improve the mass transfer in Fenton-based cleaning. The cleaning efficiency of Fenton cleaning and NaCl treatment were evaluated individually, and their synergistic effect was determined by a mixture of NaCl/H2O2. In pre-coating, the iron loading could be controlled by permeate flux. Moreover, the iron loading on the membrane had a linear relationship with FeOCl dosage. The pre-coated FeOCl layer slightly decreased membrane permeability (by 4%), presumably because the porous FeOCl pre-coat provided abundant channels for water permeation. NaCl pre-treatment displayed high efficiency in the removal of the reversible fouling layer, which contributed to 50% of flux decline. The FeOCl pre-coat catalysed Fenton-based cleaning, which achieved a complete flux recovery in 1 hour. The addition of tert-butanol (an ∙OH scavenger) in Fenton-based cleaning system decreased the cleaning efficiency, which confirmed the participation of ∙OH in Fenton-based cleaning. No remarkable synergistic effect was observed between NaCl induced fouling layer swelling and Fenton oxidation. It was likely due to the effect of turbulent flush on improving the diffusion of H2O2 in Fenton-based cleaning, which surpassed the effect of fouling layer swelling induced by NaCl treatment.","","en","master thesis","","","","","","","","2021-08-31","","","","Civil Engineering","",""
"uuid:295d285d-7f01-40ea-8b50-b7453c027b12","http://resolver.tudelft.nl/uuid:295d285d-7f01-40ea-8b50-b7453c027b12","Real Time Market Based Control of Flexible Distributed Energy Resources","Ramkumar, Subhitcha (TU Delft Electrical Engineering, Mathematics and Computer Science)","Tindemans, S.H. (mentor); Abdelghany, H.A.M.F. (mentor); Popov, M. (graduation committee); van der Blij, N.H. (graduation committee); Delft University of Technology (degree granting institution)","2020","Advancements in the field of Information and Communication Technologies (ICT) has enabled the possibility to utilize the flexibility offered by responsive assets in a better way by employing Demand Response (DR) schemes. This thesis analyzes the performance of one such DR scheme developed at TU Delft called Forecast mediated Market Based Control (F-MBC), which aims to coordinate such flexible assets by communicating ""self-fulfilling forecasts"" [1]. The main aim of the project is to investigate the applicability of this method in real-world settings. To do so, several simulation scenarios were formulated to understand how well F-MBC coordinates heterogeneous populations of uninterruptible time shiftable loads over an extended time horizon, both from the system perspective and devices' perspective. The thesis also proposes an approach to test the mechanism in a rolling horizon setup. First, the performance of F-MBC is examined under several combinations of deferrable loads having identical deadlines. Then, its ability to coordinate devices with dynamic load profiles under a complex realistic setting is investigated. Trade-offs adopted when simulating such a setup is also highlighted. Results indicate that while F-MBC achieves good overall performance when coordinating devices with uniform power consumption profiles, its performance in scheduling heterogeneous populations of devices with dynamic load profiles was quite variable. When devices that consume high power when they start was considered for coordination, F-MBC was able found to allocate the devices in such a manner that steered towards overall cost minimization. However, its performance if used to schedule devices which consume low power when it starts was found to be undesirable. Hence, several recommendations were provided to deduce better conclusions about the applicability of the mechanism in reality. References: [1]Hazem A. Abdelghany, Simon H. Tindemans, Mathijs M. de Weerdt, Han la Poutré, Distributed coordination of deferrable loads: A real-time market with self-fulfilling forecasts, Sustainable Energy, Grids and Networks, Volume 23, 2020, 100364, ISSN 2352-4677. http://www.sciencedirect.com/science/article/pii/S2352467720302952","Market based control; Demand Response; Flexibility; Rolling horizon; F-MBC","en","master thesis","","","","","","","","2021-08-31","","","","","",""
"uuid:e379f998-ff23-4580-a41c-36e9c8eb7e68","http://resolver.tudelft.nl/uuid:e379f998-ff23-4580-a41c-36e9c8eb7e68","Active Safety Control for Semi-Autonomous Teleoperated Road Vehicle","Saparia, Smit (TU Delft Mechanical, Maritime and Materials Engineering)","Schimpe, Andreas (mentor); Ferranti, L. (mentor); Shyrokau, B. (graduation committee); Kober, J. (graduation committee); Delft University of Technology (degree granting institution)","2020","The progress in technology has made vehicles safer and the quest to make them even more safe is never ending. Autonomous cars present the solution to make cars much more safer by eliminating the primary cause of road accidents, human error. However, autonomous cars tend to fail in decision making especially in complex traffic environment prompting human intervention, since the technology is not yet mature. The transition to autonomous cars can be achieved via teleoperated driving which allows human operator to remotely control the vehicle via mobile network. This thesis presents Model Predictive Control (MPC) based driver assistance system for semi-autonomous teleoperated road vehicle that helps avoid collision with static and dynamic obstacles. This system aims to mitigate some of the key challenges in teleoperated driving like reduced situational awareness and latency. The proposed system posses the ability to correct lateral and longitudinal motion of the vehicle and explicitly defines its authority to override human operator. To enhance trust in the human operator over the system, visual feedback of the vehicle behaviour is proposed as an additional set of information to the human operator. Simulations were done using high fidelity vehicle model and the results validate the expected behaviour of the system, as designed for teleoperated driving system setup of Institute of Automotive Technology, Technical University of Munich. The designed system is ready for implementation in the actual experimental vehicle and hence real tests can be conducted.","Teleoperation; Shared Control; Collision Avoidance; Model Predictive Control","en","master thesis","","","","","","","","2021-08-31","","","","","",""
"uuid:43a89cff-4d4b-4a82-98a2-db169c478b23","http://resolver.tudelft.nl/uuid:43a89cff-4d4b-4a82-98a2-db169c478b23","Internal Sulphate Attack in Slag Blended Systems: A Susceptibility Study","Arul Kumar, Priya (TU Delft Civil Engineering and Geosciences)","Copuroglu, O. (mentor); Šavija, B. (graduation committee); Anupam, K. (graduation committee); França de Mendonça Filho, F. (graduation committee); Pluis, Math (graduation committee); Delft University of Technology (degree granting institution)","2020","With rapid industrialisation, the infrastructure sector has seen exponential growth in prefabricated concrete elements due to their speedy construction and efficient usage of material. Precast concrete elements have thus observed some deterioration due to increased internal temperature as a result of rapid curing, and also through deliberate heat curing techniques. This has led to researchers in the past to study the effect of such curing conditions on the durability aspect of the binders, especially their impact on Delayed Ettringite Formation. Precast elements such as railway sleepers, exposed to in the humid environment were thus prone to internal sulphate attack and needs to be investigated. Use of Ground Granulated Blast Furnace Slag (GGBFS) as a substitution for binder content in conventional portland cement in the Netherlands has been prevalent since the early 1900s primarily because of its abundant resource from iron industry. The benefits of slag have been then exploited as it was one of the supplementary cementitious systems which along with being a sustainable solution, provides good resistance to environmental degradation such as chloride penetration resistance. However, their advantages surrounding extreme curing conditions have to be studied, unless used at optimised quantities. The research focused on the potential of blast furnace slag systems to undergo internal sulphate attack due to high internal temperatures. The simulation of high internal temperature was done through heat curing inside an oven following which continuous storage under lime solution was carried out in order to saturate the system. Slag systems at low and high substitution levels (20% &amp; 50%) were used along with a combination of coarser and finer surface areas, to investigate their subsequent influence was chosen for the study. Also, since infrastructure industry adopts CEM II &amp; CEM III-A cement type, where the former was low slag concentration with moderate fineness and the latter with higher substitution level of slag in combination with high overall fineness, their potentials for DEF have also been studied. For all the mixes, the influence of high curing temperature and exposure to moisture was studied through microstructural changes, pore size variations and mineralogical composition effect along with fineness on paste specimens. All studies were compared to reference systems of CEM I, which was observed to be the most detrimental due to DEF. Test results indicate that at lower substitution levels of slag secondary ettringite forms in significant quantities in neat systems along with traces of carbo-aluminate phases in the case of slag systems. Also, higher substitution levels does not appear to completely suppress the formation of ettringite after exposure. Its formation in both the cases showed more or less no influence of fineness of slag added, except in the case of pore size distribution. The significant presence of carbo-aluminates was observed in the case of all slag systems that could prove to be beneficial as they do not translate to deteriorative expansion.","Internal Sulphate Attack; Prefabrication; Cementitious binder; Ettringite","en","master thesis","","","","","","","","","","","","Civil Engineering | Structural Engineering","",""
"uuid:c665220a-b9e6-4007-b679-f7f1151fc0d8","http://resolver.tudelft.nl/uuid:c665220a-b9e6-4007-b679-f7f1151fc0d8","Assessing Traffic Network Resilience Using Agent-Based Modeling and Simulation","Pronk, Erik (TU Delft Technology, Policy and Management)","Tavasszy, L.A. (mentor); Warnier, M.E. (graduation committee); Aydin, N.Y. (graduation committee); Walraven, Erwin (graduation committee); van der Tuin, Marieke (graduation committee); Delft University of Technology (degree granting institution)","2020","Urban areas are seeing influx of population and therefore are experiencing increasing stress on the systems currently in place. In traffic networks, a larger population means that their are inevitably a short term increase in mobility demands. To accommodate this, governments and and the private sector are proposing new solutions for mobility. One such focus is the introduction of new transport modes. A common classification for these modes is Mobility-as-a-Service (MaaS), which includes modes such as carsharing, shared last-mile transportation like bicycles, and ridesharing. MaaS also overlaps with other new modes such as autonomous and electric vehicles. Modeling these types of modes and their subsequent interactions with each other and traditional modes requires more complex modeling techniques than have been traditionally used in transport modeling.<br/><br/>The purpose of this thesis is to propose a method for using agent-based modeling and simulation (ABMS) to assess traffic network resilience, as ABMS has the dynamic qualities that match well with the time variant nature resilience.. This gap is especially prevalent when considering novel modes of transport, such as ridesharing. Data from the metropolitan region of Rotterdam and The Hague (Metropoolregio Rotterdam Den Haag or MRDH) is used for a case study on the corridor between Rotterdam and The Hague. The goal is to prove feasibility of a method for assessing resilience in traffic networks using ABMS.<br/><br/>A resilience framework for urban mobility is proposed that uses six categories to characterize resilience: (1) reflective, redundant, flexible, resourceful, inclusive, and integrated. Using this framework as a guide, three metrics are proposed for measuring resilience using agent-based simulation: origin-destination (OD) travel time, link travel time, and link volume. These metrics are used to compare scenarios that either include a disturbance in the network or do not, which in this case occurs for a 30 minute period on the A4 roadway between Rotterdam and The Hague. While the OD travel time metric is limited in its usability, the link travel time metric makes apparent the the recovery time to achieve normal operating conditions after a disturbance. In the presented case study, scenarios that included ridesharing had worse recovery time then the car only scenario, as well as a higher maximum travel time across the disturbed link. The link volume metric contextualizes these results, showing that while the overall volume throughout the simulation is lower for the ridesharing cases, the volume during the disturbance across the disrupted portion of the A4 roadway is higher. The higher volume shows why the travel time is higher with the presence of ridesharing in the disturbance scenario. These results are subject to the limitations of the model, though, which include dynamic routing that may not avoid the disturbed portion of the network when the disturbance occurs.","Agent-Based Modeling & Simulation; Ridesharing; MaaS; Resilience","en","master thesis","","","","","","","","","","","","","",""
"uuid:78653abb-7d82-40e7-971d-3a726696b2e2","http://resolver.tudelft.nl/uuid:78653abb-7d82-40e7-971d-3a726696b2e2","RTK-GNSS augmentation data spoofing","van Tol, Pepijn (TU Delft Civil Engineering and Geosciences)","Tiberius, C.C.J.M. (mentor); Teunissen, P.J.G. (mentor); van Gelder, P.H.A.J.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","The use of Global Navigation Satellites Systems is increasing rapidly. More and more applications use positioning and/or timing information form a Global Navigation Satellite System (GNSS). Also more and more people and applications rely on high-precision positioning based on GNSS. The high-precision solution of GNSS is achieved with the use of example augmentation data. For example real-time kinematic (RTK)-GNSS enables centimetre-level positioning. Commonly the augmentation data is sent with the use of internet. At the moment an unsecure internet link is used to sent this augmentation data from the reference station to the user. The aim of this study was to find out if it is possible to manipulate the augmentation data for DGNSS using a cyber attack without being detected, and what the consequences could be for the final estimated parameters of interest. The parameters of interest can be the position and/or the timing. The augmentation data is sent using the Networked Transport of RTCM via Internet Protocol (NTRIP). What is found is that this is an unsecure connection. For an attacker it is possible to use a man-in-the middle attack, where the augmentation data is sent from the reference station, via the hacker, to the user. The data is not encrypted and therefore it is possible for the hacker to see and alter the data. Based on a man-in-the-middle attack this study found that it is possible to manipulate the DGNSS augmentation data, without detection. The model that is used to manipulate the augmentation data is based on a Single Point Positioning model. As long as the manipulation is in the range of the design matrix of the used model, it is not detectable. This means that the manipulation only contributes to the so called influential bias and not, or minimal, to the testable bias. As the name suggest, the result of this manipulation is that the final solution is manipulated due to the effect in the influential bias, and without detection since the testable bias is not changed. GNSS processing is based on non-linear observation equations. This means that those models are linearised before the final solution is estimated based on the least squares estimation. The effect of this non-linearity is minimal, but it means that a (very) small part of the manipulation contributes to the testable bias. This study points out that this small increase of the testable bias is insignificant when the observations are tested based on an overall model test and the w-test. The conclusion of this study is that it is possible to spoof the augmentation data when NTRIP is used to sent the augmentation data. Furthermore, the consequence of augmentation data spoofing is that it can be exactly manipulated by the hacker, based on a certain direction and distance, as long as the magnitude of the manipulation is in the order of 2 to 3 meter.","GNSS; augmentation data; spoofing","en","master thesis","","","","","","","","","","","","Geoscience and Remote Sensing","",""
"uuid:c15b4c99-78b7-4ce6-bda5-f4fc7fe912ea","http://resolver.tudelft.nl/uuid:c15b4c99-78b7-4ce6-bda5-f4fc7fe912ea","A process-based modelling study on the morphological response of the Bacton Sandscaping project","van der Veen, Jeroen (TU Delft Civil Engineering and Geosciences)","de Schipper, M.A. (mentor); Aarninkhof, S.G.J. (graduation committee); Luijendijk, A.P. (graduation committee); van Prooijen, B.C. (graduation committee); van der Boon, C.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","The last couple of years, the interest in large nourishments, that also feed the adjacent coast, has increased. A feeder nourishment is suggested to be cost effective as well as ecological more beneficial than traditional nourishments. However, their behaviour is more complex and the need for better morphological predictions has increased. Earlier research has given insight in the morphological behaviour and the driving forces of a feeder nourishment in the Netherlands (the Sand Engine). A new feeder nourishment was constructed in October 2019 at the coast of Bacton (UK). This provides a new opportunity to evaluate the feeder nourishment behaviour outside the Netherlands. This thesis describes the results of a numerical morphological model of this feeder nourishment called Bacton Sandscaping (hereafter: BSS) A full bathymetric survey was conducted three times with echo-sounder, LiDAR scanner and photogrammetry during the first half year of the BSS. The surveys showed that the erosion of the first two months is four times higher than the erosion volumes of the months following, indicating a strong initial response. Moreover, a clear link between the morphological response of the sub-aerial beach and submerged beach was found. The numerical model has been calibrated and validated extensively with the bathymetric data of the first half year of this nourishment. The model is very well capable of representing beach volume changes and scores excellent on the Brier skill score. To obtain this excellent score, similar calibration parameters for waves were used as in the Sand Engine case in the Netherlands. The strength of this model was then used to evaluate the effect of offshore wave heights on the erosion volumes of the nourishment and showed that significant wave heights lower than 1 meter are causing 57% of the observed erosion. As the model is well capable of simulating the first half year it is then assumed that the model is also capable of simulating beach volume changes for a different grain size as well as different wave event intensities. The model predicted that sediment grain size and wave event intensities do not have a significant effect on the morphological behaviour of the BSS, therefore the initial state of the nourishment is more important in how the nourishment will evolve. The BSS model is a step forward in the understanding of the morphological behaviour of feeder nourishments and can be used for future modelling purposes of the BSS.<br/>For future feeder nourishments it is advised to focus more on the design shape of the nourishment and not so much on the wave event intensity and grain size of the nourishment. In addition, future calibration of feeder nourishments can further point out if feeder nourishments can use similar calibration parameters for waves.","Feeder Nourishment; Bacton; DELFT3D; Sandscaping; UK; Coastal engineering","en","master thesis","","","","","","","","2025-08-31","","","","Civil Engineering | Hydraulic Engineering | Hydraulic Structures and Flood Risk","Bacton Sandscaping","52.862390, 1.464015"
"uuid:bd3a5fbd-430b-4af6-bc33-eab436f4f7db","http://resolver.tudelft.nl/uuid:bd3a5fbd-430b-4af6-bc33-eab436f4f7db","Technology Stack for Decentralized Mobile Services","Skála, Matouš (TU Delft Electrical Engineering, Mathematics and Computer Science)","Pouwelse, J.A. (mentor); Delft University of Technology (degree granting institution)","2020","The Internet was created with the idea that any two computers connected to the shared network should be able to communicate with each other. It has also been built on the principles of decentralization, without any central entity having the power to take the network down. Yet, 50 years later, we live in a world where most of the services are centralized and user data are stored on the servers owned by a few large profit-oriented companies. In recent years, the idea of decentralization has attracted many in the engineering and research community. Since the introduction of cryptocurrencies in the last decade, there have been many discussions on whether we can decentralize other services, such as social media, or web. With the trend of decentralization, applications are shifting from the client-server model to peer-to-peer, which brings many challenges and calls for a new networking stack. This thesis proposes and implements a protocol for peer to peer (P2P) communication between any two devices. It is implemented as a Kotlin library which can be used on a desktop, smartphones, tablets, and IoT devices. It can be used to deploy a truly ubiquitous network overlay which is available anytime and everywhere. The protocol allows any two devices to establish a direct connection by taking advantage of NAT traversal techniques to connect peers behind different types of middleboxes. When the Internet connection is not available and peers are located in proximity, the connection can be established using Bluetooth Low Energy. The robustness of the NAT traversal mechanism has been tested by conducting a connectivity check between devices using the networks of major mobile network operators and home broadband providers in the Netherlands. The mechanism has been shown to be capable of establishing a connection in all tested network conditions. To demonstrate the usage of the library, a decentralized social network with public feeds and private end-to-end encrypted messaging has been implemented. To get feedback on the APIs and general usability of the library, 4 teams of MSc students have been asked to develop non-trivial distributed applications on top of it. Compared to the state of the art solutions, the proposed library combines both nearby and Internet connectivity, does not require any central server, works on a variety of devices under challenging network conditions, and is completely open source.","","en","master thesis","","","","","","","","","","","","","",""
"uuid:bc4a5c0d-a756-4488-a32a-f0d481bbd482","http://resolver.tudelft.nl/uuid:bc4a5c0d-a756-4488-a32a-f0d481bbd482","Plankton populaties in rivieren: Analyse van patronen in planktonmodellen voor rivierstructuren","Adriaens, Michael (TU Delft Applied Sciences; TU Delft Electrical Engineering, Mathematics and Computer Science)","Dijkstra, Y.M. (mentor); de Roode, S.R. (mentor); Vuik, C. (graduation committee); Rohde, M. (graduation committee); Delft University of Technology (degree granting institution)","2020","Er wordt geschat dat 80% van al het zuurstof op aarde geproduceerd wordt door fytoplankton. Dit is een soort eencellige plant die voorkomen in wateren over de hele wereld. Deze kleine planten worden voornamelijk gegeten door zoöplankton, kleine organismen bestaand uit meestal enkele cellen. Afsterving of overbevolking van fytoplankton heeft ook verregaande gevolgen voor de rest van het maritieme ecosysteem. Fyto- en zoöplankton hebben populaties die een oscillerend patroon kunnen volgen. De groei van de ene beïnvloed het voorkomen van de ander en zo ontstaat een interessante wisselwerking. Er zijn vele modellen die dit gedrag proberen te simuleren om zo inzicht te krijgen in de verschillende patronen die zichtbaar zijn in planktonpopulaties. Een van deze modellen is het model van Steele en Henderson uit 1992. Dat model is echter gemaakt voor wateren zonder ruimtelijke structuren. Om het model van Steele en Henderson ook toe te passen op stromend water in een rivier wordt in dit onderzoek een model beschreven voor planktonpopulaties in rivieren, waarbij de volgende onderzoeksvragen zijn gesteld:<br/> - Welke patronen zijn er te vinden in het model van Steele en Henderson zonder convectie en diffusie?<br/> - Wat is het effect van convectie in een rivier op de uitkomsten van het plankton model van Steele en Henderson?<br/> - Wat is het effect van diffusie in een rivier op de uitkomsten van het plankton model van Steele en Henderson?<br/> - Wat is het effect van convectie én diffusie","","nl","bachelor thesis","","","","","","","","","","","","Applied Mathematics | Applied Physics","",""
"uuid:68f06142-9704-4d57-ab1f-f081e73dd8e2","http://resolver.tudelft.nl/uuid:68f06142-9704-4d57-ab1f-f081e73dd8e2","Influence of operational profiles on optimum SOFC hybrid system configurations for maritime applications","Bhakare, Agney (TU Delft Electrical Engineering, Mathematics and Computer Science)","Purushothaman Vellayani, Aravind (mentor); Stam, Jelle (mentor); Delft University of Technology (degree granting institution)","2020","The International Maritime Organization (IMO) has imposed strict emission guidelines for the shipping industry to meet the Paris agreement. This has led the maritime industry to search for alternative fuels and prime movers. An electric propulsion system powered with a Solid Oxide Fuel Cell (SOFC)-Internal Combustion Engine (ICE) is one of the possible solutions. In such a system the SOFC is made to run at a constant load while the engine is expected to cover the transient loads. <br/>The main purpose of the thesis is to get an insight into the optimum power split required between Solid Oxide Fuel Cell (SOFC) and Internal Combustion Engine (ICE) for a particular maritime load profile. This has been achieved by analyzing system performance of three different power split configurations (30-70, 50-50,70-30) between SOFC and ICE. The operational profiles from three different case studies have been considered; Cruise, Oil tanker and Yacht. The system analysis has been performed with steady state results for SOFC-ICE system modeled in Matlab Simulink. SOFC has been modeled as 1D model with 3 elements whereas, the engine has been modeled as a lookup table with datasheets for two stroke dual fuel CI engine. From the power split study it has been found that, in general, the ship with high frequency of full load operation benefits from a large installed SOFC and the ships with high frequency of anchoring load or part load benefits from small installed SOFC power. Owing to large heat demand, the Cruise ship benefits the most from the SOFC-ICE system. A 50-50 power split or SOFC installed at base load for a Cruise ship leads to carbon emission reduction by almost 56% compared to diesel electric system while achieving a system efficiency (heat and power) of 74%. Thus, the SOFC-ICE system running on natural gas can help in reducing the emissions by almost 50% while allowing high electrical and system efficiencies. Thus, allowing the maritime industry to attain the greenhouse gas emission and energy efficiency goals. With commercialization of green hydrogen and storage, the system could also help in achieving the zero emission goals.<br","SOFC; Maritime Power Plant; SOFC-ICE Hybrid System; Power Split Study; SOFC Model","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:67f63bb4-85a6-4570-bd03-42e1325798ef","http://resolver.tudelft.nl/uuid:67f63bb4-85a6-4570-bd03-42e1325798ef","Adaptations for CNN-LSTM Network for Remaining Useful Life Prediction: Adaptable Time Window and Sub-Network Training","Borst, Nick (TU Delft Aerospace Engineering)","Verhagen, W.J.C. (mentor); Santos, Bruno F. (graduation committee); Zarouchas, D. (graduation committee); Delft University of Technology (degree granting institution)","2020","Estimating the RUL (Remaining Useful Life) of machinery is a useful tool for maintenance and performance operations. This results in lower costs, improved safety and operational improvements.<br/>This paper proposes two adaptations to the CNN-LSTM network provided by Li et al. \cite{Li2019APrediction}, as well as exploring reproducibility, accuracy and sensitivity of the original DAG (Directed Acyclic Graph) network. The network at hand is an ensemble network combining LSTM and CNN neural networks to provide an accurate regression RUL prediction using the NASA CMAPSS dataset \cite{NasaNasaReprository}.<br/>The Adaptable Time Window (ATW) adaptation increases the amount of time cycles that can be predicted and increases the accuracy, allowing for earlier predictions and better RUL predictions. Allowing state-of-the-art predictions accuracy for complex datasets. The Sub-network training adaptions did not surpass the accuracy of the original network with the current implementation settings, however is promising for further research.","Prognostics; RUL prediction; Regression model; CNN; LSTM; Ensemble Method; CMAPSS","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:b621dc6c-1b7c-4f32-bb58-d0ba011bc99b","http://resolver.tudelft.nl/uuid:b621dc6c-1b7c-4f32-bb58-d0ba011bc99b","Pointing analysis and fine pointing controller design for a CubeSat laser communication system","Ackaert, Gilles (TU Delft Aerospace Engineering)","Speretta, S. (mentor); Dirkx, D. (mentor); Monna, G.L.E. (mentor); Delft University of Technology (degree granting institution)","2020","For any space mission, the communication subsystem is an indispensable part of the satellite that carries the payload. Traditionally, on-board antennas transmitting Radio Frequency (RF) waves to the receiver have been used. Nowadays, laser communications is becoming increasingly popular due to its potential to become a license-free, secure and high data rate technology that can fit into a small, light-weight form factor with modest power consumption. Therefore, Hyperion Technologies B.V. is involved in the design of CubeCat, a space-to-ground laser communication system (terminal) optimised for integration in nano-satellites (CubeSats) that aspires a downlink data rate of 1 Gbps.<br/><br/>The root cause for the above benefits lies in the possibility to create a very low beam divergence of the transmitted laser light at optical wavelengths. This turns the pointing problem into a challenging task, especially for nano-satellites equipped with standard Attitude Determination and Control Systems (ADCS). This thesis has focussed on multiple aspects of the pointing problem. <br/><br/>First of all, an analysis regarding the error performance in pointing a laser beam from Low-Earth Orbit (LEO) to an Optical Ground Station (OGS) has been set up. This takes into account all aspects of the CubeCat system and its host spacecraft, of which the most important ones are the host satellite ADCS and the Fine Pointing System (FPS) integrated in the CubeCat terminal itself. Root error causes are identified and propagated to eventual beam pointing error in a qualitative and quantitative fashion. In-depth characterisation of the FPS hardware was required in order to understand the impact of this system on the pointing performance and to model in how far the integrated Fine Steering Mirror (FSM) and beacon detector reject the body pointing error to such extent that the stringent pointing requirements can be met. Next to analysing the control dynamics mathematically, a simulator has been built that integrates all aspects of the pointing problem. <br/><br/>Secondly, a controller for the CubeCat FPS has been successfully designed and integrated into the FPS control diagram and simulator. Control theory techniques have been used for this purpose. The aforementioned analytical models and simulator have been used together in order to evaluate the eventual pointing error performance. From this, it is concluded that the designed controller enables to meet the pointing requirements that have been generated from the CubeCat top-level requirements in the beginning of this thesis. <br/><br/>As a consequence, it follows that a 1 Gbps optical link between a CubeSat in LEO and an OGS is feasible. This opens the door to an era in which laser communications increases the data throughput capabilities of (small) satellites by several orders of magnitude. This will eventually contribute to bridging the gap between ever-increasing data volumes collected by powerful payloads and the lack of (scalable) satcom systems that can keep up with these growing data volume demands.","Lasercom; Precision pointing; Fine pointing system; Communication system; CubeSats; Controller Design; Pointing error engineering; CubeCAT","en","master thesis","","","","","","","","2025-08-31","","","","Aerospace Engineering","CubeCAT",""
"uuid:36564076-3268-47b7-9959-5614bfb37d1d","http://resolver.tudelft.nl/uuid:36564076-3268-47b7-9959-5614bfb37d1d","Sub-contraction in waste management: Evaluation of the performance of a waste collection service. A case study at Avery Dennison","Xydianou, Theonymfi (TU Delft Civil Engineering and Geosciences)","Rezaei, J. (mentor); Maknoon, M.Y. (mentor); Duinkerken, M.B. (mentor); Wagner, Dennis (mentor); Delft University of Technology (degree granting institution)","2020","The aim of this thesis is to investigate how the collection of industrial waste can be managed with different types of sub-contraction. Literature review was conducted in order to obtain knowledge about how this type of problems can be modelled along with the types of sub-contraction and how the logistical performance could be assessed. Interviews were performed to get a better understanding of the decision making for this type of problems. Thereafter, two mathematical models were formulated in order to model the decisions at tactical and operational level. In order to get more insights the developed models were implemented with real-life data. Following, further testings were performed to determine the efficiency of the developed models and to obtain managerial insights. A key conclusion was that among the three types of sub-contraction that were examined, the results obtained from the route based and the tour based type give the most realistic solutions. Overall, the results indicate that the introduction of sub-contraction in waste collection brings considerable cost-savings.","Inventory Routing Problem; Optimization of decision making; Sub-contraction; Waste management","en","master thesis","","","","","","","","2022-08-31","","","","Transport, Infrastructure and Logistics","",""
"uuid:8e2ac04a-c88e-46a9-8a1f-e1f95b1d1e95","http://resolver.tudelft.nl/uuid:8e2ac04a-c88e-46a9-8a1f-e1f95b1d1e95","Video-Based Two-Dimensional Kinematic Analysis for the Evaluation of Lower Limb Function in Patellar Tendinopathy","Molenaar, Mitchel (TU Delft Mechanical, Maritime and Materials Engineering)","Harlaar, J. (mentor); Seth, A. (mentor); de Vos, R.J. (mentor); van Middelkoop, M. (mentor); Oei, E.H.G. (graduation committee); Delft University of Technology (degree granting institution); Universiteit Leiden (degree granting institution); Erasmus Universiteit Rotterdam (degree granting institution)","2020","Patellar tendinopathy (PT) is a common manifestation in jumping sports characterized by pain and a reduced load bearing capacity. The exact cause of PT has not been determined, which makes it difficult to prevent and treat. A stiffer landing technique might be a risk-factor for PT. Retraining of the landing technique into a less stiffer technique could be an important treatment for PT. Therefore, the aim of this study was to determine whether athletes with PT exhibit altered lower limb kinematics in the landing technique of a drop vertical jump test (DVJT) compared to asymptomatic athletes. DVJTs were performed by athletes diagnosed with PT and asymptomatic athletes. The DVJTs were recorded on video in the sagittal plane with a single camera in the Erasmus MC University Medical Center (Rotterdam, the Netherlands). A convolutional neural network was trained to extract coordinates of lower limb landmarks from the videos. The knee and ankle joint angles were calculated on the coordinates using least-squares. Functional Principal Component Analyses (FPCA) were performed to determine differences in lower limb kinematics between athletes with PT and asymptomatic athletes. In addition, the following kinematic features were compared between athletes with PT and asymptomatic athletes: angle at landing, maximal angle during landing, range of motion and time to maximal angle. Video-based 2D kinematic analysis of the landing DVJT was performed in 69 athletes with PT (53 men, mean age 24.6 ± 3.8 years) and 32 asymptomatic athletes (16 men, median age 20.5 (4) years). FPCA of knee (FPC1: p=0.5, FPC2: p=0.3) and ankle (FPC1: 0.7, FPC2: 0.1, FPC3: 0.5) joint angles did not show significant differences in the landing technique between these two groups. No significant differences were observed in angle at landing, maximal angle during landing, range of motion and time to maximal angle (knee: p=0.3, p=0.8, p=0.7, p=0.4; ankle: p=0.5, p=0.6, p=0.4, p=0.1). Athletes with PT do not have altered lower limb kinematics during the landing phase of a DVJT compared to asymptomatic athletes. These findings implicate that landing technique is not an important factor to address during rehabilitation of patients with PT. <br","Patellar tendinopathy; Video recording; Deep learning; Neural Network; Lower extremity; Kinematics; Humans; Treatment; Prevention; Retraining","en","master thesis","","","","","","","","2021-08-31","","","","Technical Medicine | Sensing and Stimulation","",""
"uuid:bf2741eb-19e3-4390-90b6-086a4851694a","http://resolver.tudelft.nl/uuid:bf2741eb-19e3-4390-90b6-086a4851694a","Stimulating urban redevelopments through value capturing: An explorative study into the characteristics, benefits and ideal context for enabling the developers’ contribution to public space","de Koning, Jeroen (TU Delft Architecture and the Built Environment)","Van den Berghe, K.B.J. (mentor); Koppels, P.W. (graduation committee); Delft University of Technology (degree granting institution)","2020","There is a big demand for housing in the Netherlands and a significant portion of that demand can be facilitated through urban redevelopments. Urban development is hindered by financial barriers that cause public financial deficits. Stimulating urban redevelopment can be achieved by stimulating feasibility. The developers’ contribution is a value-capturing tool that can facilitate private contributions to public space. Through contributions in public space, feasibility can be stimulated by optimizing and widening the developers’ business case. Using the Delphi method, a panel of developers was formed to analyse the relation between the developers’ contribution and developer decision-making in practice. Decision-making is determined by the type of contribution, benefits for the developer, a context and conditions. Private contributions to public mean taking responsibility in some way. Doing this can add value in various ways, but developers are mainly driven by financial aspects. There are certain conditions to doing the contribution, of which the level of financial feasibility is the most important. The willingness to contribute is highest when a municipally adopts a passive role. Developers should be aware of the benefits and municipalities must be aware of the context that enables private contributions. Further research could improve the significance and confidence in the findings.","urban redevelopment; financial deficits; value capturing; developer decision-making; developer’s contribution","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Management in the Built Environment","",""
"uuid:81f39147-f0dd-4ffd-9cac-e5fb661a9e52","http://resolver.tudelft.nl/uuid:81f39147-f0dd-4ffd-9cac-e5fb661a9e52","Steady-State Two-Phase Flow Conductance in a 2D Micromodel","Obbens, Ewald (TU Delft Civil Engineering and Geosciences)","Rossen, W.R. (mentor); Bruining, J. (graduation committee); Delft University of Technology (degree granting institution)","2020","This study is part of a larger effort to evaluate the use of microfluidics to represent foam generation and flow in geological porous media (Rossen, 2008). Specifically whether it is possible to have flow in a microfluidic device without fluctuating occupancy of pores and pore throats. Although there is no foam created during the study, three of the main foam generation mechanisms are discussed. The 2D network consists of a 32x32 square lattice of cylindrical pillars, where all the pillars are surrounded by at the top and bottom by a liquid film that constricts the gas flow. The pores and pore throats are filled with gas or water. The gas flow paths are gas filled pores connected with gas filled pore throats. The water flow paths are pillars connected with water filled pores or pore throats. Liquid/gas bridges are necessary for the two phases to flow simultaneously through the network. An equivalent conductance for the gas networks is obtained by Hadjisotiriou (2020). But for that value to have any relation with that of the water network, the gas and water flow should be simulated within shapes that fit into one another under the same conditions. Because the paths in the network could have countless different variations, these paths are broken up into the smallest repeated segments. Then the total resistance of a path is obtained from a combination of these segments. Two unique segments are identified for the gas paths and four for the water paths. The segments are created in COMSOL™. A conductance value is obtained for each segment. With these values it is possible to calculate the total conductance for both the gas and water networks. The result is a fraction of water flow relative to gas flow of around 0.015. This means that only a small amount of water flow can be sustained by the network without fluctuating the occupancy of pores and pore throats. This makes it hard to explore foam generation in a microfluid device. It also means that two-phase flow in a microfluidic device is not representative of that in 3D geological porous media, except for in some exceptional circumstances.","","en","bachelor thesis","","","","","","","","","","","","","",""
"uuid:f44fce98-40cb-48f2-8609-3d0e7e9df9d6","http://resolver.tudelft.nl/uuid:f44fce98-40cb-48f2-8609-3d0e7e9df9d6","Modelling and Simulation of Energy Storage System for Frequency Stability Studies","Zhang, Chenrui (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Intelligent Electrical Power Grids)","Rueda, José L. (mentor); Rakhshani, E. (graduation committee); Veerakumar, Nidarshan (graduation committee); Delft University of Technology (degree granting institution)","2020","The frequency stability of the power system is challenged by the high penetration of power electronic interfaced renewable energy sources (RES). This paper investigates the improvements of frequency responses of fully decoupled wind power generators (FDWG) by proposing a novel implementing of ultracapacitors (UC) within a hybrid scheme in real-time simulations of wind power plants. UCs are selected as ideal power sources in fast active power-frequency control due to their high power density and fast-reacting speed. Batteries and UCs combined hybrid energy storage systems (HESS) are formed to complement their characteristics. Droop-based and derivative-based control and virtual synchronous power (VSP) are the selected strategies to control power system frequency stability. The best frequency performance trading off with HESS cost is found by solving an optimization problem. The proposed optimization algorithm is used to define the HESS size and controller parameters. The optimization results are analysed to illustrate the improvements of frequency stability control comparing the results of droop and derivative-based control with the VSP control strategy.","Fast active power-frequency response; ultracapacitor model; hybrid energy storage system; fully decoupled wind power generator; mean-variance mapping optimization; RTDS","en","master thesis","","","","","","","","2022-07-31","","","","Electrical Engineering | Electrical Power Engineering","",""
"uuid:944cf99e-b773-49d1-8694-a91bbd3c4578","http://resolver.tudelft.nl/uuid:944cf99e-b773-49d1-8694-a91bbd3c4578","Advanced Control of Coating Weight in a Hot-Dip Galvanizing Line: An adaptive time delay compensation strategy","Sarawgi, Saket (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Delft Center for Systems and Control)","Ferrari, Riccardo M.G. (mentor); Boeder, Cor Jan (graduation committee); Delft University of Technology (degree granting institution)","2020","Flat steel strip processing is carried out through a sequence of continuous methods, commonly recognized as hot rolling, pickling, cold rolling, annealing, and hot-dip galvanizing. Among all these processes, hot-dip galvanizing is a process that has been popularly used to produce high quality galvanized cold-rolled sheets that are extensively used in the manufacture of automobile and domestic electrical appliances. In particular, the main objective of galvanizing is to protect the steel strip from corrosion by applying a suitable coating of zinc-based alloy. <br/><br/>During hot-dip galvanization, the steel strip after leaving the annealing furnace is dipped into a bath of molten zinc, enabling the formation of zinc coating. The amount of this coating is controlled by the widely used air-knife wiping system installed just above the zinc bath. The coating thickness obtained after the wiping process depends mainly on the strip speed, wiping gas pressure, and strip-to-knife distance. After a significant distance from the air knives, the cold coating gauge is located to measure the thickness of the zinc coating. <br/><br/>The quality of the product depends on the amount of zinc-based alloy deposited at the strip's surface. The over-deposition of zinc at the strip surface results in excessive use of zinc, which is expensive, and under-coated strip results in a product of poor quality. The control of the coating deposition is based on the air-knife wiping pressure, and therefore, the challenge is to determine and control the pressure, given the operating conditions, which are the strip speed, strip-to-knife distance, and the target coating thickness.<br/><br/>One of the main concerns in the closed-loop control of coating thickness is the need to account for the measurement delay arising from the time-varying strip speed across the gap between the air knives and the cold coating gauge. In this thesis, different modeling and control strategies have been studied to improve the quality of the galvanized sheet produced at Hot-dip Galvanizing Line 1 (HDGL1) of Tata Steel in IJmuiden.","Coating Weight; Air-Knives; Time Varying Delay; Smith Predictor; NEPSAC","en","master thesis","","","","","","","","2022-08-20","","","","Mechanical Engineering | Systems and Control","",""
"uuid:c7d52141-1218-4754-bf16-8cbb1a46fee0","http://resolver.tudelft.nl/uuid:c7d52141-1218-4754-bf16-8cbb1a46fee0","Offshore Wind Farm Optimisation: A Comparison of Performance between Regular and Irregular Wind Turbine Layouts","Sickler, Maaike (TU Delft Aerospace Engineering)","Zaaijer, M B (mentor); Ummels, B.C. (mentor); Dykes, K. (mentor); Melkert, J.A. (graduation committee); Schmehl, R. (mentor); Delft University of Technology (degree granting institution); Technical University of Denmark (degree granting institution)","2020","Wind farm layouts in industry show a range of patterns with an overall trend from regular to irregular patterns over time. Wind farm layout optimisation studies in literature generally result in irregular wind turbine patterns. Review of existing literature shows that the performance of irregular and regular wind farm layouts has not been compared in a consistent way. Although there are indications that irregular layouts outperform regular layouts, it is yet to be determined if this is the case for the overall performance and if so, to what degree. In this research the effect of regular and irregular wind farm layouts on selected performance indicators is quantified. This quantification is performed through means of a comparative case study.<br/>The performance of both regular and irregular wind farm layouts is assessed on the basis of three performance indicator groups: (1) power performance; (2) wake-induced tower fatigue; and (3) inter-array cabling system. The performance indicators in these groups are affected by a change in wind farm layout, feasible, site independent, and technical as concluded from a multi-criteria decision analysis.<br/>The irregular wind farm layout has a higher annual energy production and a higher persistence to wind direction. The net present value of this increase in cash flow over the lifetime of the wind farm is estimated at 10 million Euros. A higher persistence to wind direction means that the power output is less sensitive to fluctuations in wind direction. This characteristic increases the predictability of the wind farm power, which can indirectly lead to a decrease in imbalance cost on the electricity market.<br/>The wake induced tower fatigue is found to be negatively impacted by an irregular wind farm layout. Implementation of the Frandsen model shows that the maximum effective turbulence of the irregular wind farm is 23.8% higher than that of the regular wind farm layout. For fatigue-driven tower design, this leads to an increase in tower wall thickness, which in turn results in an increase in tower material consumption. The increase in tower cost in the wind farm is estimated at 4 million Euros. Application of a minimum inter-turbine spacing to ameliorate the negative effect on effective turbulence is can lead to a decrease of 20 % (as compared to the case study).<br/>The inter-array cable design results show a marginal increase in cable cost of 1.15 % for the irregular wind farm. The analysis reveals that this performance indicator is strongly dependent on site-specific input data. Due to this marginal change and dependency on site specific input data, this performance indicator is omitted from further conclusions.<br/>Comparing the negative effect of the tower cost and the increase in revenue due to the higher AEP, the net present value is computed. With a discount rate of 5 %, the net present value of the AEP reduced by the increase in tower cost results in an increase of 6 million Euros.<br/>For improved performance in future wind farm layouts, the implementation of irregular wind turbine patterns is advisable. That is, with the proviso that the minimum inter-turbine spacing is taken into consideration with respect to wake-added turbulence levels.","Offshore; Wind Farm; Layout Optimization; Regular; Irregular; Performance","en","master thesis","","","","","","","","","","","","European Wind Energy Masters (EWEM) | Rotor Design Track","",""
"uuid:656665a6-f457-440f-8392-d5f311c4f68d","http://resolver.tudelft.nl/uuid:656665a6-f457-440f-8392-d5f311c4f68d","Flocking Algorithm for Formation Control of Non-Holonomic Networked Euler-Lagrange Multi-Robot Systems: Towards swarm intelligent networked mobile multi-robot systems","Tatar, S. (TU Delft Mechanical, Maritime and Materials Engineering)","Steur, E. (mentor); Delft University of Technology (degree granting institution)","2020","Recent activities in the research on swarm robotics have emerged from the application of concepts from swarm intelligence into multi-robot systems (MRSs) that model the realistic interaction between robots in the system and the environment. Fundamentally, the literature on swarm robotics is biologically inspired by systems as insect colonies, flocks of birds, schools of fish and bacteria colonies. Recently, the flocking formation control behaviour in multi-agent systems (MASs) has encouraged astounding attention among the researchers. Researchers from various disciplines including physics, biophysics, computer science and control engineering have been fascinated by the emergence of flocking, swarming and schooling in MASs under local interactions. In this research, we focus on flocking algorithms for MRSs. The flocking phenomenon is characterized as a form of collective behaviour of a swarm of robots with a distributed architecture that involves locality of the computation, sensing, communication and effector capabilities. Flocking algorithms have the potential to introduce selfhealing, self-organizing and self-configuring capabilities in the functioning of distributed MRSs. However, despite an exhaustive list concerning flocking formation control algorithms is given in the literature, most of the existing results deal with simple mathematical modelled robots. In practice, mobile robots embrace more complex nonlinear dynamic mathematical models and involve non-holonomic constraints. Therefore, it is of scientific and practical interest to study the effectiveness of the flocking algorithms for such complex nonlinear systems involving non-holonomic constraints. This thesis study, expanding novel features on the existing literature, presents a connectivity-preserving artificial potential function (APF)-based flocking algorithm for formation control of mobile networked non-holonomic Euler-Lagrange (EL) dynamical agents under a proximity graph interaction architecture involving a limited sensing radius. In specific, we consider three algorithms: (i) flocking; (ii) (virtual) leader-following flocking; (iii) flocking with obstacle avoidance. Proximity graphs are viewed as a useful and decent mathematical tool to incorporate the practical time-varying communication topology of MRSs in flocking algorithms. The preservation of the network connectivity is of significant importance for the flock stability and synchronization (i.e. consensus) since they firmly depend on it. The use of APF, to encode the local interaction rules for achieving global performance, is inspired by the observations and models of the biologists. APF-based flocking control algorithms are mainly interesting as they are not limited to higher-level models and can be exploited for more advanced nonlinear dynamic models and control strategies for flocking and collision avoidance purposes. The aforementioned algorithm setting improves the practical relevance of the problems to be addressed in this study and meanwhile, it poses technical challenges to the design of the flocking control algorithm and theoretical stability proof, respectively. In all proposed algorithms in this study, being the first author in the literature to study flocking algorithms for non-holonomic EL systems in specific, novel theoretical results for this class of systems, exploiting nonlinear control theory concepts where a nonnegative lower bounded ”energy-like” Lyapunov function candidate is defined, are obtained. Advanced numerical simulation studies and some performance metrics are presented as a complement to the analytical framework in order to verify the effectiveness of the theoretical results.","","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:63e2d096-18cf-405e-a877-be8200c0817e","http://resolver.tudelft.nl/uuid:63e2d096-18cf-405e-a877-be8200c0817e","Ouderen in de stad: Hoe kan de gemeente effectief sturen op de realisatie van gemeenschappelijke woonvormen voor ouderen door professionele investeerders?","van Loo, Marloes","Haffner, M.E.A. (mentor); Heurkens, E.W.T.M. (mentor)","2020","Afstudeerscriptie in het kader van de opleiding Master City Developer 2018 – 2020, Erasmus Universiteit Rotterdam / Technische Universiteit Delft. In dit onderzoek staat de effectiviteit van het sturingsproces van de gemeente centraal, met als doel om professionele investeerders in beweging te krijgen om de gemeenschappelijke woonvormen voor ouderen te realiseren. Wat betreft effectieve sturing levert dit onderzoek voor gemeenten kennis op over hoe gemeenten invloed kunnen uitoefenen op de investeringsbeslissing van de markt. Door de vergrijzing verandert de samenstelling van de bevolking. Terwijl het aandeel ouderen stijgt, is het huidige woningaanbod voor ouderen echter ontoereikend en sluit het lokale aanbod niet voldoende aan bij de verschillende woonwensen van de ouderen. Een deel van de ouderen wil zelfstandig wonen, met bijbehorende privacy maar heeft tegelijkertijd ook behoefte aan sociale contacten en controle over hun eigen leven. Wanneer het de wens is om zelfstandig wonen te combineren met het samen leven, ondernemen van activiteit en wanneer nodig het zorgen voor elkaar in een wooncomplex, dan biedt de gemeenschappelijke woonvorm de oplossing. Dit onderzoek geeft dan ook inzicht in het nut en de noodzaak van gemeenschappelijke woonvoren. Ondanks de gebleken, concrete vraag naar gemeenschappelijke woonvormen, en de voordelen die deze woningen bieden, blijft het aanbod echter achter. Om het gewenste aanbod gerealiseerd te krijgen is sturing door de lokale overheid op realisatie van gemeenschappelijke woonvormen voor ouderen gewenst. Daarom luidt de hoofdvraag van dit onderzoek als volgt: In hoeverre kunnen gemeenten effectief sturen om de realisatie van gemeenschappelijke woonvormen voor ouderen te faciliteren?","investeerders; ouderen; gemeenschappelijke woonvormen; gemeente; beleid","nl","master thesis","","","","","","","","","Architecture and The Built Environment","","","Master City Developer 2018 – 2020","",""
"uuid:5fa74566-2d5c-4e26-8bb8-2645642c182d","http://resolver.tudelft.nl/uuid:5fa74566-2d5c-4e26-8bb8-2645642c182d","A finite element investigation of the mechanical effect of ply drops in blended laminates","Skitsas, E. (TU Delft Aerospace Engineering)","van Campen, J.M.J.F. (mentor); Delft University of Technology (degree granting institution)","2020","Weight reduction in vehicles offers many advantages. Especially in aircraft, one of the advantages of weight reduction less need for power which is translated into less fuel consumption and lower emissions. Composite materials are now a popular construction material in new passenger aircraft, making them lighter by taking advantage of their high specific properties. However, composite materials can offer even greater specific properties and as a result lighter structures, by utilizing composite laminate blending. Laminate blending is the local optimization of laminates while taking into account the continuity, structural integrity and manufacturability guidelines. The main project started by developing an algorithm that blends laminates with a large number of sections and then a blended laminate with 25 sections was manufactured using the algorithm mentioned above. The manufactured laminate showed improved stiffened driven buckling performance and out of plane displacement imperfections due to thermal stresses in the autoclave caused by the stiffness mismatch in the ply drop areas of the laminate.<br/><br/>This thesis project has to do with the investigation of the mechanical behavior in blended laminates under buckling loading, by building FEM models that accurately simulate the stresses and out of plane displacement as well as the thermal effects taking place during the cooling down in the autoclave. A global-local modelling technique is used to model the stresses, where the local ply drop section FEM models are simulated by 3D elements and the global laminate model by 2D elements. As far as the out of plane displacement is concerned, an algorithm that calculates the stiffnesses of the ply drop sections in order to transfer them back into the global model is built, that works for any blended laminate. Finally, a 2D thermal FEM model is built that simulates the imperfections of a blended laminate due the thermal stresses in the autoclave caused by the stiffness mismatch in the ply drop areas of the laminate. All in all, the results show that the stress and out of plane displacement results of the FEM models built in this thesis project can in many cases be substantially different from simple FEM models that do not take into account the ply drop sections. Furthermore, the thermal FEM model showed that imperfections due to thermal stresses can be accurately simulated. <br","Laminate Blending; FEM analysis; thermal analysis; Coding; ABAQUS; python","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:81155d92-38e7-4eaf-9782-ff442cd84477","http://resolver.tudelft.nl/uuid:81155d92-38e7-4eaf-9782-ff442cd84477","Using soft robotics as a medium for gender accessible STEM education of preschoolers","Prakash, Shreyas (TU Delft Industrial Design Engineering)","van de Geer, S.G. (mentor); Scharff, R.B.N. (graduation committee); Pennings, Ellen (mentor); Delft University of Technology (degree granting institution)","2020","Only 35 percent of the recent graduates are women. The figures are even lower for traditionally male dominated workforces such as engineering and robotics as women constitute only 12 percent of the engineering workforce. It is quite evident that we cannot ignore the gender equation when it comes to bringing in more equity in the workforce. As even the toys are heavily gendered, to take an example. Right from the way girls are prompted to play with Barbies and boys with G.I. Joes, this societal conditioning influences their future interest towards professions. In order to counter act the disparity in the STEM professions, a play based learning approach through the medium of soft robotics is used to get preschoolers equally interested towards the field of robotics in a gender-accessible manner. Silly Stompers consists of a reconfigurable base to which wide range of soft actuator blocks could be connected in various ways to create custom body movements. This provides a very tangible, screen-free, open ended experience for pre-schoolers through a fun way by allowing creating to create various pumping patterns. This provides compatibility with LEGO providing more open-ended outcomes. The learning outcomes mainly focus on constructive play and role play for pre-schoolers through the medium of soft inflatable actuators.","Soft Robotics; gender bias; Lego bricks; Soft actuators; education","en","master thesis","","","","","","","","","","","","","",""
"uuid:26048b06-fa9a-4a61-9f73-6e4bf35c2275","http://resolver.tudelft.nl/uuid:26048b06-fa9a-4a61-9f73-6e4bf35c2275","Happiness within Organizations: a process to aid in achieving a happiness mindset","Khan, Maaz (TU Delft Industrial Design Engineering)","Desmet, P.M.A. (mentor); Heijne, K.G. (graduation committee); Delft University of Technology (degree granting institution)","2020","Happiness is something we, as humans, seek to attain yet we are not entirely familiar with what exactly it means. Typology of fundamental needs (Desmet &amp; Fokkinga, 2020) explains comprehensively, yet detailed enough, the needs we must fulfil in order to be happy. An average person spends a third of their life at work (Pryce-Jones, 2010) and in that one-third of life, how those needs get fulfilled or harmed influences the happiness of an individual. Scholars of positive psychology argue that “positive states help people to thrive, mentally flourish and grow psychologically” (Frederickson, 2001). At the same time, happy people have been proven to be up to 20% more productive (Sgroi, 2015). Therefore, not only as a social responsibility should an organization put their focus on employee happiness but as an economic benefit as well. However, the vast science of happiness and the nature of the context (an organization) makes it an “open” or “wicked” challenge (Bijl-Brouwer et al., 2019). The challenge starts from analyzing happiness of employees within an organization, then introducing initiatives to improve happiness and finally, tracking the progress and effectiveness. However, the current scenario and limitations of happiness within organizations combined with the multi-faceted nature of happiness hints towards an even bigger challenge: achieving a happiness mindset.This project is an attempt to operationalize the typology of fundamental needs within the context of an organization in order to aid in achieving a happiness mindset. Borrowing knowledge from systems thinking and phenomenological hermeneutics, a theoretical framework is developed which is translated into a practical approach and tested on 4 different cases. The learnings and real life narratives obtained from this practical approach are utilized in developing the final outcome: “Ajar Process”. It is a 4 step process: Awareness, Alignment, Action and Acknowledgement. It starts with making the participants aware of the typology of fundamental needs, making them capable of sorting their real life experiences according to the need fulfillment. This awareness is then mutually aligned with all participating individuals, so that the perception of what happiness means in that context is similar for everyone. This prompts meaningful conversations leading everyone into a pro-active attitude, coming up with mutually decided initiatives to improve the happiness through need fulfillment. Eventually, the effectiveness of those initiatives is evaluated and a decision is made which step of the process to go to next. In this way, the process never ends and a repeated use results in a happiness mindset. Design concepts are proposed per step of the Ajar process which aid in executing that step effectively. Ajar process is presented as a service expansion for Emotion Studio (design agency) where they would offer to execute the first sprint of the process within the organization and hand it over to them for future executions.","Happiness; Organizations; Mindset; Ajar Process","en","master thesis","","","","","","Typology of Fundamental Needs used as a core for this project is a work by Desmet and Fokkinga, 2020. Desmet, P.M.A., & Fokkinga, S.F. (2020). Beyond Maslow’s pyramid: Introducing a typology of thirteen fundamental needs for human-centered design. Multimodal Technologies and Interactions, 4(3), 38 (DOI mti4030038)","","","","","","Strategic Product Design","",""
"uuid:935ff6e5-a73c-4864-9572-d4070351add3","http://resolver.tudelft.nl/uuid:935ff6e5-a73c-4864-9572-d4070351add3","Towards BIM-based automation of the vertical load calculation","Willemsen, Robert (TU Delft Civil Engineering and Geosciences)","Kiefte, S.T. (mentor); Schipper, H.R. (graduation committee); Pasterkamp, S. (graduation committee); van Nederveen, G.A. (graduation committee); Delft University of Technology (degree granting institution)","2020","The work processes of structural engineers have been changing over the last decades. Digitalisation and automation play an important role in this change. One of the major developments in this context has been the introduction of Building Information Modelling (BIM). In a BIM model the geometry of the actual building is represented. To this geometry additional information regarding the design, construction, and maintenance of the building is attached. In current engineering practice, BIM software is only used for drawing purposes. This is unfortunate, as a lot of the information present in the model can be used for calculation purposes as well. At the same time, structural calculations still contain manual and time-consuming tasks. This also holds for the vertical load calculation (Dutch: Gewichtsberekening). An important calculation in the design of a building, as it is used to determine how the loads acting on the building are distributed to and carried by the foundation. The aim of this thesis is therefore to research and develop a method and tool that can be used to automate the manual processes in the vertical load calculation based upon a BIM model. The focus is specifically on multi-storey residential buildings. As a basis for the development of a method, the state-of-the-art in research and practice of the vertical load calculation and its automation has been investigated using interviews and a literature review. A framework is developed in which the different steps of the vertical load calculation are described using a number of flowcharts. Furthermore, responsibilities are assigned to the different persons involved. Adjustment scenarios are developed using which the structural engineer can correct the information that is retrieved from the BIM model. The practical applicability of the developed method is tested using Dynamo, a parametric engineering software connected to Revit. It is concluded that the vertical load calculation can be automated based on a BIM model. It is important to clearly specify the different steps of the process and to provide the structural engineer with the means to interfere with the outcomes of the calculation. The potential of BIM-based automation of structural calculations is demonstrated. Using the developed tool, schematisations could be quickly generated and directly calculated using the connected structural analysis software. By supporting the structural engineer in documenting design choices early, the introduction of errors and misunderstandings is prevented. In the end this results in time-saving, time that can be spend on the more detailed and complex parts of calculation processes.","BIM; Automation; Vertical load calculation; Framework; Tool; Analytical model; Building Information Modelling,; Schematisation","en","master thesis","","","","","","","","","","","","Civil Engineering | Building Engineering - Structural Design","",""
"uuid:c87c7d8d-80a6-4e9a-8aab-f61fe3441bdc","http://resolver.tudelft.nl/uuid:c87c7d8d-80a6-4e9a-8aab-f61fe3441bdc","Integrating stakeholder analysis models to gather more stakeholder insight","Aerts, Simon (TU Delft Civil Engineering and Geosciences)","Heintz, J.L. (mentor); Koenders - van den Ban, I.S. (mentor); van Nederveen, G.A. (graduation committee); Schipper, H.R. (graduation committee); Delft University of Technology (degree granting institution)","2020","Stakeholder management is one of the elements of project management within the building industry. Stakeholder management consist of stakeholder analysis and stakeholder engagement. Current stakeholder analysis models, methods and tools are often very focused around one central issue: individual characteristics or relations between stakeholders. Stakeholder analysis theory often strands in theoretical models, where an operational approach is missing. Combining stakeholder analysis models, methods and tools is necessary to get better stakeholder insight. However this combined approach is missing from the building industry.","Stakeholder analysis; Social network analysis; Integrated stakeholder analysis; Salience Model; Construction stakeholder management","en","master thesis","","","","","","","","","","","","Civil Engineering | Building Engineering","",""
"uuid:f99a43a5-0fc7-4d34-9f65-b613d2602f6a","http://resolver.tudelft.nl/uuid:f99a43a5-0fc7-4d34-9f65-b613d2602f6a","Design for Calibrated Trust For Acceptance of Autonomous Vehicles","Valentine, David (TU Delft Industrial Design Engineering; TU Delft Design, Organisation and Strategy)","Kim, E.Y. (mentor); Smit, I.R. (graduation committee); Delft University of Technology (degree granting institution)","2020","The advent of a society in which autonomous technology coexists with humans is an inevitability. The project focuses on one such autonomous technology in the form of autonomous vehicles or self driving cars. The benefits of such automation is well documented in academia and is supported by the investment by some of the biggest automobile and technology manufacturers in the research and development of autonomous vehicles. However, there exist certain challenges in realizing the full potential of autonomous vehicles. One such challenge is the attribute of trusting an autonomous vehicle. The project looks at the idea of trust in automation and dives deeper into the concept of calibrated trust as an approach to designing autonomous vehicles for increased acceptance of autonomous vehicles. The project is conducted in association with the Cities of Things Design Lab and People in Transit. Calibrated trust is defined as the balance between the capabilities of autonomous vehicles to the expectations of the end user. In essence it is the creation of an appropriate mental model by the end user. Through literature research and qualitative analysis, prominent challenges in achieving calibration were identified as: approach to designing for socio-technical systems, misalignment in communication between stakeholders, product branding and customer experience. Since, the focus of the project was towards the design and development team, the first two challenges i.e. approach to designing for socio-technical systems and misalignment in communication between stakeholders were selected to define the final design question and direction. The final design intervention is a Calibrated Trust Toolkit that can be used by development teams during the product development process to aid in designing for calibration of trust. It consists of four parts: A sensitizing session package, autonomous function visualization canvas, user decision matrix and trust enhancing communication. Collectively, the four parts allow for addressing the two challenges as selected previously. Each part of the toolkit was tested with designers and engineers and further iterated. The complete toolkit was validated by conducting interviews with experts and triangulating the data with the test data gathered during the testing phase of the design process. The testing and validation of the final outcome shows merit in the use of the toolkit for designing for calibration of trust and at the same time provides the flexibility for further modifications and adjustment. During the testing phase the participants found the use of the toolkit easy and intuitive. The digital method of testing suggested the deployment of the toolkit was possible in a digital setting. However, there were certain limitations to the project, the toolkit was not tested as a whole because of the time required and the unavailability of the necessary stakeholders. These limitations have been detailed out in the recommendation section of the report. Further research directions have also been suggested as a continuation of this project or start of new projects. In conclusion, the project is a step in the right direction when designing for calibrated trust by building on the work of other researchers like Ekman et al.(2016) and Mirning et al.(2016), but requires further research and design in other areas to fully realize the idea of designing for calibration of trust, such as the work of Anika Boelhouwer at TU Twente and David Abbink at TU Delft . In a broader perspective the insights and toolkit designed should not be limited to autonomous vehicles but extrapolated to designing other social robots or autonomous technologies that will coexist in future societies.","Calibrated Trust; Autonomous Vehicles; Product Development Process; Strategic Design; vulnerable road users; mobility; communication; Socio-technical system; design automation; trust in technology","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:23d834e5-e4ca-4848-88e7-86626902b22d","http://resolver.tudelft.nl/uuid:23d834e5-e4ca-4848-88e7-86626902b22d","The future of interurban forest structures ?!: A proposal for a new critical approach towards the design of drought adaptive interurban forest structures","Wijntje Santamaría, R.A. (TU Delft Architecture and the Built Environment)","van der Velde, J.R.T. (mentor); Ursem, W.N.J. (graduation committee); Delft University of Technology (degree granting institution)","2020","This graduation project proposes a new critical approach towards the design of drought adaptive interurban forest structures. The increasing drought during the summer is currently neglected in the design (and management) of green structures in the Netherlands. Several studies underpin the importance of taking drought stress in consideration for the future well-being of trees and forests. Gerrits (2010) provides insight into the cause of drought stress following the hydrological cycle of trees. De Vries et al. (2000) gives an overview of the indirect factors that can contribute to the level of drought stress that trees perceive. The research of Brunner (2010) reveals the response mechanism of trees. Zadworny et al. (2014) and Pretzsch et al. (2012) showed that changing the current forestry practice can result in more drought adaptive forest. However, these studies do not look into the spatial implications of the drought-stress. Since, they do not consider forests as part of a spatial structure which is embedded in a landscape that is defined by its palimpsest, scale-continuum. The Utrechtse Heuvelrug serves as a case to map the spatial implications of transforming the current forest structure into an expanding drought adaptive interurban forest structure. The desk analysis of the Utrechtse Heuvelrug provided more insights in about everyday functioning of indirect factors. The soil conditions, water cycle appears, and human interference seems to make existing vegetation less capable of dealing with increasing extreme climate conditions. Furthermore analyses the forest structure shows that it contains four tree constellations: lanes, estates, forest plantations and nature reserves. A new framework is proposed that include these neglected spatial aspects. The framework combines the drought stress cycle with scales of urban forestry. The framework is applied to develop a vision Utrechtse Heuvelrug which is elaborated in regional design for the area between Austerlitz and Woudenberg. The vision proposed a new forest structure which will be realized in two stages. The first stage is the transformation of the structure, which consists of the addition of seasonal buffers in between the forestry, agricultural and urban cores. The second stage consists of the expansion of the forest in patches between the forestry, agricultural and urban cores. The regional design proposes a new green and blue system that adapts the current grid to make it drought adaptive. Moreover, the adapted grid will facilitate further expansion of the forest. The central element is regional water bodies. They buffer excesses of rainwater and diminish the amount of water that drained into the river Eem and river Rhine through the local canal ‘Valleikanaal’. Two different subsystems are connected to these regional water bodies. The purpose is to retain water and distribute it later. Lastly, the different corresponding constellations which are needed to transform and expand the current grid are described. This includes seven different constellations. Changing a new forest structure consists of four types of tree constellation. The catchment valleys and network of ditches are two primary constellations that will be constructed to prevent exciting forest of further deteriorating from drought stress. The sprengbeek and the zigzag are constellations mainly let circulates the retained water. The sprengbeek is responsible for disposal whereas the zigzag take care of the (emergency) supply of water. The constellation of expansion contains four types of tree constellation. These tree-constellations are the backbone of both developing agriculture and urban patches. The food clearing consists of wooded banks and swamp forests. The living clearings is the last constellation which is part of dense forest patchwork which will develop in between food clearings. This graduation project resulted in the design of seven tree-constellations. They illustrate spatial implications which are necessary to designing drought adaptive interurban forest structure in the Utrechtse Heuvelrug.","drought stress; urban forestry; Utrechtse Heuvelrug","en","master thesis","","","","","","","","","","","","","",""
"uuid:087da2de-62c1-4489-b943-7c44c40f3fb3","http://resolver.tudelft.nl/uuid:087da2de-62c1-4489-b943-7c44c40f3fb3","Temperature Based Water Content Measurement in Mud (Soil) With Fiber Optics","Van Ballaer, Frederik (TU Delft Civil Engineering and Geosciences)","Meshkati, Ebi (mentor); Vardon, P.J. (graduation committee); Doornenbal, Pieter (graduation committee); Draganov, D.S. (graduation committee); Klitsch, Norbert (graduation committee); Delft University of Technology (degree granting institution); RWTH Aachen University (degree granting institution); ETH Zürich (degree granting institution)","2020","This research has demonstrated the applicability of a DTS system to estimate the volumetric water content in saturated mud material. 2 samples of synthetically generated mud and 1 sample of natural mud from the port of Rotterdam were investigated, first by conventional methods and subsequently also with DTS. The system set-up and heating strategy were optimized by testing with different media (air, water) and with different FO coil diameters. A step-by-step approach was then designed to translate the thermal response recorded in the muds into volumetric water contents. Early- and late- time cutoffs were applied to the slope selection procedure (∆T vs ln(t)), and a mud dependent correction factor was applied to obtain the effective heat flux. The average VWC’s (ϴ) subsequently derived from the DTS data were in good agreement with those obtained by conventional methods (core sampling); the standard deviation in the VWC’s (ϴ) of all three tested muds was between 0.030 and 0.040 m<sup>3</sup>/m<sup>3</sup>. For saturated conditions, Sayde et al. (2010) and Striegl and Loheide (2012) published larger standard deviations of 0.046 m<sup>3</sup>/m<sup>3</sup> and &gt;0.050 m<sup>3</sup>/m<sup>3</sup> respectively. The approach detailed in this investigation has enabled DTS to perform as a guideline on the continuous volumetric water content profile in saturated muds.","Distributed Temperature Sensing; Volumetric water content; Thermal Conductivity","en","master thesis","","","","","","","","","","","","","",""
"uuid:d23e82b2-480c-4f73-99ec-d23c0b461671","http://resolver.tudelft.nl/uuid:d23e82b2-480c-4f73-99ec-d23c0b461671","On the behaviour of fine sediment in settling basins: Improving the understanding and prediction of return water quality assessments by a comparative modelling study","Veenman, T.F.J. (TU Delft Civil Engineering and Geosciences)","van Koningsveld, M. (mentor); Wang, Z.B. (graduation committee); van Prooijen, B.C. (graduation committee); De Vries, Jurre (mentor); Delft University of Technology (degree granting institution)","2020","In this study, the behaviour of fine sediment in settlings basins has been investigated. The understanding and prediction of return water quality assessments is improved by a comparative modelling study. Settling basins are required to decrease the exhaust of fine sediment particles when dredging and reclaiming land. Fine sediment particles can cause turbidity, which damages underwater life and the environment. Turbidity should therefore be prevented. <br/>The study focusses on the assessment on settling basins during a tender phase. Often, limited information is available and time pressure is high. Therefore, it is required to have a straight-forward but robust method to evaluate the effectiveness of a settling basin design in meeting outflow criteria, based on a solid process understanding. <br/>With a comparative modelling study, the main assumptions of the current assessment by Van Oord (width-uniform conditions, neglectable density effects) are researched. The models compared are an inhouse tool of Van Oord (RWQ model) and Delft3D. Next to the main assumptions, different types of settling behaviour throughout the basin are researched. <br/>The research shows the importance of density driven currents in distributing the sediment concentration over the settling basin. This leads to width-uniform sediment concentration. This explains why the Delft3D model and the RWQ model predict the same outflow concentration (order of magnitude) while having different assumptions. Wind causes additional mixing and therefore higher outflow concentrations. The settling velocity of particles has a very high influence on the outflow concentration. <br/>For future assessments the RWQ model can be used. For better process understanding, a Delft3D model could be added. When outflow concentrations are near critical, mitigating measures should be implemented. Mitigating measures are often a fraction of the costs compared to cancelling dredging vessels. <br","Dredging; environmental; settling basin; Fine sediment; Turbidity","en","master thesis","","","","","","","","","","","","","",""
"uuid:0d1bf0ca-f8ee-4a95-b8df-0040eff3806b","http://resolver.tudelft.nl/uuid:0d1bf0ca-f8ee-4a95-b8df-0040eff3806b","A strategy towards a fair coffee chain","Ildarabadi, Saeed (TU Delft Industrial Design Engineering)","Calabretta, G. (mentor); Keller, A.I. (mentor); Lanjouw, R.P. (mentor); Delft University of Technology (degree granting institution)","2020","It is all about increasing fairness in the coffee industry. The coffee chain is not fair. This unfairness has been hidden from most of the actors in the coffee chain. The lack of communication is considered to be a vital element of the mentioned injustice. Moyee, a newly born company, has taken a different approach by shifting the value-adding activities to the countries of origin of coffee. Moyee has started investing in and developing roasting and packaging facilities in Ethiopia since 2012. What can help Moyee leave more of a positive impact? Moyee is doing very well in terms of leaving an impact in coffee-growing countries. However, Moyee’s relation with customers and consumers in coffee-consumer countries is not fruitful enough. By means of Vision In Product Design methodology, Strategic Design approach, Design Roadmapping methodology, Cultural Strategy and Road Map for Creative Problem Solving, Moyee’s values were translated to a future image called Vision. The process was followed by creating three steps (to be called Horizons) towards the Vision. The goal is to have a balance between Ecological, Social and Financial costs of the coffee and achieving a system that consuming coffee leaves equal or more Ecological, Social and Financial Impact than the costs it causes. Horizon 1 It is about building up a Conscious Community of consumers. Consumers will be reached to with content addressing their concerns such as sustainability, equality and quality. Excellent customer experience and personalized communication between Moyee, farmers and consumers add up to loyalty. Simultaneously, customers will receive engaging information about the coffee chain to increase their awareness about the existing injustice. Meanwhile, in the coffee-growing countries, Moyee will expand the roasting and packaging facilities to Kenya, starts Experimenting with True-costing and Living Income. Furthermore, a dedicated team starts the farm project. Horizon 2 The next step is to give the community the power to shift and adjust their impact. It will be possible to trace back a bag of coffee and see who has been involved in the process of making that coffee. Customers will receive real blockchain-proved impact points based on their purchase and contribution to the chain. At the same time, Moyee expands the roasting and packaging facilities to Colombia and run projects to achieve zero CO2 emissions. Horizon 3 Finally, any person in the coffee chain can connect to any other person directly. This system causes extraordinary transparency and builds up a personal connection. Meanwhile, by partnering with other businesses, the impact points can be used as a new currency to receive services or experiences. The Mizan Farm Project is getting matured and is ready to be executed in another context.","Coffee; Fairness in Coffee; Supply Chain; Cultural Strategy; Roadmap; Strategic Design; Strategy; Coffee Chain","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:98934a43-957c-4c0b-9a9f-e4276b11822f","http://resolver.tudelft.nl/uuid:98934a43-957c-4c0b-9a9f-e4276b11822f","When Effective Stakeholder Alignment Actions Are Carried Out, Within Infrastructure Projects: A single case study at Schiphol Landside Infrastructure","de Jong, Nena (TU Delft Civil Engineering and Geosciences; TU Delft Integral Design and Management; TU Delft Design & Construction Management; BAM Infraconsult)","Houwing, E.J. (mentor); Chan, P.W.C. (graduation committee); Hertogh, M.J.C.M. (graduation committee); van Hees, Susan (mentor); Messchaert, Hetty (mentor); Roest, Clementine (graduation committee); Delft University of Technology (degree granting institution)","2020","In infrastructure construction projects, stakeholder alignment is an important factor that contributes to project success and prevents excessive delays. Literature shows that it is known how to align stakeholders and what to do, however, when to carry out those actions, it not yet clear. This research contributes to that knowledge gap by analysing the Landside Infrastructure project of Schiphol as a single case study. Interviews with project stakeholders, project documents and field observations were used to collect data in order to develop a model.","stakeholder alignment; Infrastructure construction projects; timing","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:51f3e8ba-e5f4-46f4-af73-f34f4fbdffa0","http://resolver.tudelft.nl/uuid:51f3e8ba-e5f4-46f4-af73-f34f4fbdffa0","Architectural Profiles: Procedural Content Generation using Tile-based Architectural Profiles","van Aanholt, Levi (TU Delft Electrical Engineering, Mathematics and Computer Science)","Bidarra, A.R. (mentor); Hildebrandt, K.A. (graduation committee); Visser, E. (graduation committee); Delft University of Technology (degree granting institution)","2020","Procedural content generation (PCG) for architecture is widely used in a variety of digital media, most notably in games. However, such methods are often limited in their expressive range, and require considerable technical knowledge to create non-trivial architectural structures. We present a novel tile-based PCG approach for generating architecture, that proposes the use of architectural profiles, a declarative characterization of architectural typology, within a generic tile solving framework. An architectural profile consists of a set of tiles, representing atomic architectural building blocks, and a set of declarative constraints and rules, specifying which conditions a tile configuration has to satisfy to be valid. These conditions are translated into logic constraints, and used by a tile solver to control tile placement in a bottom-up manner. Eventually, each valid model output by the solver is a representative instance of its architectural profile. We describe an implementation of this approach with Answer Set Programming, using an off-the-shelf constraint solver for model generation. We performed an expressive range analysis, and concluded that our declarative method is quite controllable and can be steered over a broad range of architectural structures, regarding density and repetitiveness. Due to this expressive range and control, our tile-based method is very suitable for the customized development of urban environments for games. We also explore the adaptability of architectural profiles by application on pre-existing terrains.","Procedural Content Generation; Architecture; Tile Solving; Expressive Range Analysis; Settlement; Design methodology; architectural typology","en","master thesis","","","","","","","","","","","","","",""
"uuid:ea341330-08ce-44ac-abf4-65140c49c682","http://resolver.tudelft.nl/uuid:ea341330-08ce-44ac-abf4-65140c49c682","Financing Green Innovation: Public finance and eco-innovation diffusion: an evolutionary modelling approach","Papazotos, G. (TU Delft Technology, Policy and Management)","Storm, S.T.H. (mentor); Warnier, M.E. (mentor); Delft University of Technology (degree granting institution)","2020","Fostering green innovation diffusion is one of the goals of the European Green Deal, European Commission's ambitious plan of eliminating greenhouse emissions in the European Union by 2050. This study approaches diffusion of green innovation through the lens of evolutionary economics by considering concepts like path-dependency and technology lock-in. The aim is to gain insights on the effectiveness of different public financing tools in supporting the diffusion of green innovation. For this purpose, an agent-based computational model is developed consisting of four entity types: a commercial bank, a state investment bank, consumers, and innovative firms.The model is used to study the interaction of financial policies, consumer preferences, firm's innovation activities and the conditions under which the desired behavior, green innovation diffusion, emerges.","Innovation diffusion; Public finance; Eco-innovation; Agent-based modeling","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:62359caa-e4d0-4c65-bd60-6ecccaca94ea","http://resolver.tudelft.nl/uuid:62359caa-e4d0-4c65-bd60-6ecccaca94ea","Revitalizing De Doelen in Rotterdam: Promenade Architecturale as public connecting element","Ip, K.C. (TU Delft Architecture and the Built Environment)","van der Zaag, E.J. (mentor); van Dooren, E.J.G.C. (graduation committee); van de Voort, J.A. (mentor); Stead, D. (graduation committee); Delft University of Technology (degree granting institution)","2020","Classical music oftenly is associated as boring, muddy; as an activity for the older people. Eventually this older generation will be gone for good, leaving even less pubic than it now has. As this problem grows the relationship between classical music and the public shifts. The lack of connection becomes more obvious, making it more and more distant. Through the case study of the concert building De Doelen in Rotterdam, a design study with the concept of the ""promenade architecturale"" is held to explore the insights on how to revitalize this subculture by making connection with the public on many different levels. In order to also design an acoustic well-functioning concert hall, a research paper is written about the architectural interventions in optimizing the acoustic aspects of a concert hall.","concert hall; acoustic; de doelen; rotterdam; promenade; routing; revitalizing","en","master thesis","","","","","","","","","","","","","","51.9218244, 4.4732896"
"uuid:183fed4b-fda6-42cf-8de2-d690d28545b4","http://resolver.tudelft.nl/uuid:183fed4b-fda6-42cf-8de2-d690d28545b4","New Port Authority Bus Terminal: Manhattan Future Gateway","Yang, H. (TU Delft Architecture and the Built Environment)","Smidihen, H. (mentor); Koskamp, G. (graduation committee); Delft University of Technology (degree granting institution)","2020","New York City is the most cosmopolitan city with great influence in the world, but the transportation problem has always been its urgent task. The Port Authority Bus Terminal, located at the entrance of the most congested tunnel in NYC, Lincoln tunnel, is the largest bus station in the nation and the busiest in the world. However, it shows the strong contradiction between mobility and infrastructure facilities now. How can a bus terminal in NY Midtown meet the existing need and adapt to changes of new mobilities that may arise in the future? The design of the New Port Authority Bus Terminal aims to reorganize regional transportation to improve transport efficiency and cater for the future development of new mobilities. It could also provide a possibility to the current and potential future problems in metropolitans as NYC: the mismatch of the infrastructure buildings’ design and the new citywide mobility.","terminal design; New York City; Lincoln Tunnel; Mobility hub","en","master thesis","","","","","","","","","","","","","","40.7574637,-73.9961686"
"uuid:cec9cd2c-1b7b-4ea1-8086-b9a1e83bcc03","http://resolver.tudelft.nl/uuid:cec9cd2c-1b7b-4ea1-8086-b9a1e83bcc03","Uncertainty Quantification of the Mixing Enthalpy, Excess Heat Capacity and Gibbs Energy parameters of the LiF-KF System Using CALPHAD Modelling and Polynomial Chaos Expansion","Rooijakkers, Fleur (TU Delft Applied Sciences)","Smith, A.L. (mentor); Perko, Z. (mentor); Delft University of Technology (degree granting institution)","2020","In the recent years, there has been a growing interest in molten salt reactors as a source of energy. To ensure molten salt reactor safety, it is vital to know the thermodynamic properties of the systems involved. An investigation into the uncertainty of the mixing enthalpy, excess heat capacity and Gibbs energy parameters of the LiF-KF system is presented in this study. The program FactSage 7.2 [19] is used, which takes optimized Gibbs energy parameters as an input and uses these to calculate phase diagram data and the values of different thermodynamic properties. The uncertainty is quantified using the polynomial chaos expansion, which analyzes the relationship between the input Gibbs energy parameters and the output; which is the phase diagram data, mixing enthalpy and excess heat capacity of the system. Firstly, an investigation into the accuracy of the polynomial chaos expansion, when applying different settings, is given. Once the most accurate settings are found, this expansion is used to generate many different samples of phase diagrams and the corresponding mixing enthalpy and excess heat capacity values. A margin of 10 Kelvin is then introduced as a maximum deviation from the experimentally determined phase diagram. The input Gibbs energy parameters and the mixing enthalpy and excess heat capacity values, that correlate with the phase diagrams within the margin of the experimentally determined phase diagram, can then be extracted. Once these values are known, the maximum uncertainty half width of the mixing enthalpy and excess heat capacity can be given that is still consistent with sensible phase diagrams. The found values for the maximum uncertainty half range are 1.65 kJ/mol for the mixing enthalpy which is a 35.6% deviation from the mixing enthalpy value computed with the original Gibbs energy parameters. For the excess heat capacity, 1.676 J/K/mol was found as a maximum uncertainty half range which is a 44.7% deviation from the excess heat capacity value computed with the original Gibbs energy parameters. The one-dimensional uncertainty half range (the uncertainty half range of one parameter assuming all other parameters possess zero uncertainty) of Gibbs energy parameters were calculated. Additionally, scattering plots are generated to illustrate the two- and three-dimensional uncertainty of the different Gibbs energy parameters.","","en","bachelor thesis","","","","","","","","","","","","","",""
"uuid:072f52d2-ef93-4e8f-82d9-044eddfad288","http://resolver.tudelft.nl/uuid:072f52d2-ef93-4e8f-82d9-044eddfad288","Climate customized façade: A prefabricated façade system customized for Ecuadorian climate regions","TAPIA ARBOLEDA, A.C. (TU Delft Architecture and the Built Environment)","Stoutjesdijk, P.M.M. (mentor); Janssen, C.J. (graduation committee); Delft University of Technology (degree granting institution)","2020","The Ecuadorian construction sector lacks thermal comfort standards, causing building’s design to disregard the existing variations between the climatic regions in the country. Indoor comfort levels are generally poor, encouraging the use of unsustainable cooling and heating systems. A building´s envelope plays an important role in the energy and environmental performance of a building. This research investigates whether indoor comfort can be improved by renovating existing facades with a prefabricated facade system that can be mass-customized to respond to different types of climate conditions. A project that uses state-of-the-art technologies, such as CNC milling, to mass-customize construction elements is the WikiHouse. It provides construction solutions with multiple variations, easy assembly processes and the demountability of its components. It guarantees its reusability and reduces the high demand for resources in the construction industry. This research focuses on the design of a facade system that can be mass-customized by combining the construction system of the WikiHouse project and multiple layers with different properties to build one modular and symmetric component with several variations. The replication of the components variants on an existing building´s facades should improve the indoor comfort by responding to the localtions weather. During this research, components variants are developed, by using computational prototyping and simulations. The most suitable components combinations for each facade orientation are selected. This study highlights the influence of climate factors in all its design steps, as well as setting a circular workflow throughout the manufacture, use and return processes. The final outcome of this study is a prefabricated facade system that can be mass-customized to respond to different types of Ecuadorian climate conditions to improve the current indoor comfort levels and allows its demountability and reusability.","mass customization; climate design; prefabrication; cnc milling; Ecuador; indoor comfort","en","master thesis","","","","","","","","","","","","","",""
"uuid:1bce48dd-5596-4f0b-b046-888c73aeb8a5","http://resolver.tudelft.nl/uuid:1bce48dd-5596-4f0b-b046-888c73aeb8a5","Creating an impact: Bridging the gap from research to product in multidisciplinary innovation to enhance business value","Elbo, G. (TU Delft Industrial Design Engineering)","Calabretta, G. (graduation committee); Kranzbühler, A. (mentor); Harinck, Joost (mentor); Delft University of Technology (degree granting institution)","2020","In recent years, design has become a crucial component of corporate innovation. Large corporations such as Deloitte have implemented design capabilities as a method to enhance employee experience, achieve innovation and maintain a competitive advantage. This research aims to demonstrate how design can perform as a catalyst of innovation within a corporate environment.<br/><br/>This report will touch upon the role of employee experience teams within organizations, and the way in which economic and societal change creates a demand for ethical employers with a clear purpose. It will further discuss challenges and opportunities in multidisciplinary collaboration, as a process to achieve innovation. Lastly, it will demonstrate the business value of design as a tool for communication, co-creation and user centred research.<br/>This master thesis is done in collaboration with Deloitte Amsterdam. The project focuses on the digital@deloitte team, a multidisciplinary employee experience team that develops digital solutions using agile, design thinking and user centred research in co-creation with Deloitte employees. The team is driven by use of design methodologies in their approach, collaboration and research techniques.<br/>By investigating a team within Deloitte Netherlands, this thesis will explore ways in which design can improve multidisciplinary collaboration, foster innovation and enhance business impact. Through interviews, creative workshops and co-creation sessions, this project will reveal ways in which the team can enhance their business value and create a bigger impact on employees.<br/>This thesis will introduce the development of a curated tool-kit that aims to improve the team’s collaborative process and perform as a catalyst for multidisciplinary collaboration, by creating focus and bridging the gap between research and product development.<br/>The primary use of the tool-kit will be for team alignment and discussion. <br/><br/>This report will demonstrate how the tool-kit was developed, and how it can be implemented and used to enhance the team’s creative collaboration, communication and finally business impact. A road map will reveal the potential of implementing the tool-kit into the collaborative process of the team, and how it can evolve into an evaluation tool for products, enabling the team to set clear measurable targets. Eventually, the tool-kit has the potential to perform as a decision making tool that can enable the team to become more self steering and enhance their value.","multidisciplinary design teams; Impact of Innovation; Deloitte","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:2849dc3a-3b7a-4cf6-ae96-9399d24e13c5","http://resolver.tudelft.nl/uuid:2849dc3a-3b7a-4cf6-ae96-9399d24e13c5","Redesign the brand book of Blue Tulip Awards","Yin, Chong (TU Delft Industrial Design Engineering)","Calabretta, G. (mentor); Bakker-Wu, S. (mentor); Delft University of Technology (degree granting institution)","2020","The Blue Tulip Awards is a year-round innovation awards aiming to find the most innovative innovations in Benelux area. It was previously named as Accenture Innovation Awards for 12 years, which was very famous and well-known among innovation communities. Even if the brand is very famous and successful among innovators, the branding style of Blue Tulip Awards is very chaotic and confusing. To establish a new brand look, a new brand book is designed with a three phase process: Explore-Orientate; Research-Define; Design-Validate. In the explore-orientate phase, the context of the project was explored and analyzed from different angles. We conducted company and brand analysis, stakeholder analysis, competitor analysis, and an literature review. As the conclusion, we identified that in order to maintain a brand with both high dynamics and consistency, the brand book should be redesigned into one that reflect the leading principle. Three research questions were raised based on the conclusion: Why do Blue Tulip Awards need a new brand book? What should be in the new brand book? What leading principle should we reflect by the brand book? In the research-define phase, a qualitative interview and a quantitative survey with internal stakeholders was performed to answer the three research question. The data were analyzed using Grounded Theory Method. The final results are shown in several infographics. Three brand personality traits and ten design requirements were identified from the research. The personality traits is the starting point of the leading principle. An collaborative and agile approach was chosen to define the leading principle. As the results, the leading principle consists of four components: brand personalities, slogan, mood board, and design examples. They were tested with the audience and designer. The leading principle and ten design requirements are used to guide the design of the new brand book. As the results, a brand book with four chapters were designed. The final design was validated with three designers in an validation session. It was proved that the new brand book is helpful in a brand experience design process, and it performs better than the previous brand book in two dimensions: creativity and brand fit. As the conclusion, an systematic reflection and future recommendations are provided in the last chapter.","branding; brand guideline; branding design; marketing design; brand book; brand experience design","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:87bc6e12-a0bd-4b91-8b46-4e9883dbd27f","http://resolver.tudelft.nl/uuid:87bc6e12-a0bd-4b91-8b46-4e9883dbd27f","Establishing shared positive moments between elderly caretakers and their families","Ho, Tsai Cheng (TU Delft Industrial Design Engineering)","Sonneveld, M.H. (mentor); Sleeswijk Visser, F. (mentor); Delft University of Technology (degree granting institution)","2020","In Europe and Asia, people face a significant aging society(Gilroy, R., 2007). In Asia, Taiwan underlies one of the most aging countries (Chan, A., 2005). To give care to elderly citizens, some Taiwanese elderly people live at home, while others live in a care institution. For those who live in institutions, they may lose the connection with their family member. Some problems were defined in the context:<br/><i> 1) Due to distance, busy work, or Covid-19, when visiting is not accessible; young people can' see caretaker.<br/> 2) Elderly people may not be familiar with a touchscreen, which lead to a barrier with younger people<br/> 3) Residents who newly moved to an institution lose the connection with their family members, and have less and less shared moments with their family</i><br/>The objective led to the design goal :Establishing shared positive moments between an elderly caretaker and family members.This thesis involves exploration, conceptualization, and evaluation phases. An iterative design approach was taken to gain relevant insights from the user and context in the conceptualization phase. Several experience prototypes (Buchenau &amp; Suri, 2000) were designed and made to understand the current context and user experience, evaluate ideas, and communicate with stakeholders.The exploratory activities had lead to the main insights:<br/><i> 1) Elderly people who live apart from their families experience a happiness drop after a big family meeting.<br/> 2) The camera position affects the engagement of a video call.<br/> 3) Elderly caretakers rely on a caretaker's help to contact. They may lose their one on one personal relationship after they lose their autonomy of reaching people.<br/> 4) The usability problem for Elderly people to interact with a smartphone can be lead by the lack of haptic feedback on buttons, less agility on fingers, and the massive information on the screen.<br/> 5) Remote talking with visual reference is a handy way for young people; it triggers more shared topics to talk about with elderly people.<br/> 6) Elderly people can be engaged more in family members' life from video calling. </i><br/>Thus, I envision the future scenario to have more tiny enjoyable moments for an elderly caretaker to establish shared moments by video calling with family members.""Tiny Moments"" is a product-service system design that comes out of the project. It involves a control panel and a software concept. It establishes the connection for elderly caretakers and their families enables more engagement for each other's lives.The research led to five scenarios of use in the future:<br/><i> 1) Providing for confidence with a better look for an elderly caretaker<br/> 2) Remote selfie with beautiful scenes<br/> 3) Picture as a reference to talk about (Family members)<br/> 4) Activate a link again<br/> 5) Polite refuse when busy</i><br/>For elderly caretakers, the shared positive moments can bring them to the novelty of family members' lives, have more bonding from loved ones; for family members, they bring memorable moments for them. For family members, it brings the moments, and the pictures can be the memories in the future.","Caretaker; Elderly; Design for Interaction; Human Computer Interaction; experience design; Interaction Design; Medisign; Smartphones; Inclusive design; Elderly care; Family interaction; Universal design","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:e34ff3a1-2454-419a-9770-072729e3c6e9","http://resolver.tudelft.nl/uuid:e34ff3a1-2454-419a-9770-072729e3c6e9","Syngas Purification: Design of a Rectisol® based purification plant for the removal of impurities and simultaneous capture of CO<sub>2</sub> from the works arising gases of an integrated steel mill","Kolf, D.I. (TU Delft Mechanical, Maritime and Materials Engineering)","de Groot, F. (mentor); de Jong, W. (graduation committee); Kortlever, R. (graduation committee); Ramdin, M. (graduation committee); Delft University of Technology (degree granting institution)","2020","The steel making industry is highly energy intensive and a great contributor of greenhouse gas (GHG) emissions. It generated between 7% and 9% of direct emissions from the global use of fossil fuels in 2017 [1]. Gas emissions in an integrated steel mill (ISM) arise mainly from three streams: coke oven gas (COG), blast furnace gas (BFG) and basic oxygen furnace gas (BOFG).<br/><br/>This study focuses on the short term solutions to become a carbon neutral steelmaker where blast furnaces (BF) and basic oxygen furnaces (BOF) are still a fundamental part of the steel making process. The Rectisol® process is used to capture CO2 from the works arising gases (WAGs) of an ISM and to generate syngas which can be used as a chemical building block to produce liquid fuels among others.<br/><br/>The Rectisol® wash is a patented process by Air Liquide and Linde which uses chilled MeOH as a solvent. Both processes were first validated against stream data provided by the patents. PC-SAFT EOS was used to simulate the purification plant because of its strong theoretical foundation and its ability to adapt the parameters to predict component behaviour. Various binary interaction parameters proposed in literature were used to simulate the purification plants. From these simulations, it was found that the standard binary interaction parameters with the adjusted parameter for H2S-CH3OH, as proposed by Sun et al. [2], showed the best results.<br/>The configurations of Air Liquide and Linde were used as base configuration to clean the feed stream. From these simulations, it was observed that in both configurations large portions of CO2 are lost in the stripping process of both configurations. Enhanced CCS configurations were investigated to increase the CO2 recovery of both configurations. The desorption of CO2 was altered by introducing multiple intermediate flashes to increase the desorption of CO2. Without optimisation, the downstream constraint for the CO2-rich stream of 95% CO2 content was almost met in the Linde configuration and requires further upgrading in the Air Liquide configuration. The decision was made to use the Linde enhanced CCS configuration as a base configuration since this would solely require a change in operating conditions to meet the downstream CO2 requirement of 95% content in the CO2-rich stream.<br/><br/>HCN and H2O require a seperate wash to avoid accumulation in the main wash. To treat these components together with H2S and COS, two pre-wash configurations combined with the Linde enhanced CCS configuration were looked into. A pre-wash configuration with a separate absorber column and dividing wall column (DWC) and a pre-wash configuration with a separate absorber column and rectifier with purge were examined. Both configurations meet the downstream requirements for the purified gas stream and CO2-rich stream. The main difference between the two configurations is the difference in thermal utility consumption and make-up MeOH. The decision was made to move forward with the pre-wash integrated configuration comprising of a rectifier and purge since additional make-up MeOH would be more cost-effective. The energy recovery method proposed by Linnhoff [3] was used to identify any potential energy saving of the purification plant. A heat exchanger network was designed which reduced the cooling duty by 57% to 54,9 MWth and the reboiler duty by 50,6% to 26,8 MWth. Finally, an economic evaluation was made of the final energy integrated configuration. Equivalent annual cost and operating expenditures of the purification plant were estimated at €12.32m and €51.13m respectively per year. This gives a cost per ton captured CO2 of €37,87.","Syngas purification; Rectisol; Methanol; Carbon capture and storage; Techno-economic analysis","en","master thesis","","","","","","","","2025-08-28","","","","Mechanical Engineering","",""
"uuid:f5868ada-df51-48c1-9796-e2259efdcf40","http://resolver.tudelft.nl/uuid:f5868ada-df51-48c1-9796-e2259efdcf40","Progression of Aggregate Loss on Porous Asphalt","Pan, L.Y. (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Delft Institute of Applied Mathematics)","Jongbloed, G. (mentor); Schouten, L. (mentor); Anupam, K. (graduation committee); Chen, P. (graduation committee); Delft University of Technology (degree granting institution)","2020","Porous asphalt resides on most top layers of Dutch roads. Scheduling maintenance for these roads is generally dependent on several factors, but ravelling, the loss of aggregates in the top layers, is the main reason for maintenance on Dutch roads. With the recent framework of the DOS-LCMS scheme generating values for aggregate loss in percentages, a prediction for the remaining lifetime of a road section surfaced with porous asphalt with respect to ravelling can be performed. The lifespan for porous asphalt layers is dependent on the most suffered 25% of the section on the respective 100 meter length. <br/>The current threshold is set at 10%, implying that road sections of 100 meter need maintenance if more than 25% of the road (75<sup>th</sup> percentile) measures aggregate loss over 10%. The present work approximates these 75<sup>th</sup> percentiles throughout the years using parametric and non-parametric approaches, whereafter the estimates of the 75<sup>th</sup> percentiles are used to construct smooth monotonic increasing convex curves. These curves, which are in fact functions built on <i>P</i>-splines, are then used to perform extrapolation and hence predict the dates on which the threshold is going to be surpassed. The study reveals problems in the raw data which is particularly prominent in the sequence of 75<sup>th</sup> percentiles, frequently showing a lack of monotonicity and convexity. Putting the monotonicity and convexity constraints on a more granular level were found to be helpful for the predictions and improved the consistency of lifetime predictions over consecutive years.","ravelling; aggregate loss; porous asphalt; road maintenance","en","master thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:ffd0a082-ce51-4b24-8aa6-9a8943b983d1","http://resolver.tudelft.nl/uuid:ffd0a082-ce51-4b24-8aa6-9a8943b983d1","Activating youth 12-15 years old in Rotterdam for circular behaviour - a strategic action plan for the municipality of Rotterdam","de Vries, Celia (TU Delft Industrial Design Engineering)","Diehl, J.C. (mentor); Brouwer, W. (mentor); Delft University of Technology (degree granting institution)","2020","This graduation project focusses on the circular economy as a broader topic and stimulating specific circular behaviour within adolescents as a scope. The municipality has a specific division called Rotterdam Circulair tasked with the assignment of accelerating the city of Rotterdam towards a circular economy. The designer of this project has done extensive research into the target group of adolescents 11 -15 years old (early adolescence) and has found a couple of interesting facts. This age group does not know the concept of circular economy, is highly influential through their peers and parents and are still conducting non-circular behaviours such as littering on the street and wasting food at school. In order to stimulate the right kind of behaviour (refusing to buy excessive products, sharing more products amongst each other and buying more experiences than products) different concepts have been designed. A short term-strategy concept is an escape van, in which all elements are in the theme of a circular economy and every action causes a respective reaction as also happens in real life on the environment. This van serves as a promotional van which can drive to any location in the city. Another short-term concept is a minimal emission game, in which the players ultimate goal is to finish the quest without using raw materials or by minimizing their CO2 emissions. This game can be played online and is promoted on the platform of the municipality. The third concept is a long term one, in which a special addition is added to the already existing Rotterdampas. A new valuta, the golden ‘Deelders’ is granted to everyone which experiences an activity in the city. With these Deelders the holder of the card can vote on green and circular projects online on the website of Rotterdampas. The projects with the most votes will receive funding of the municipality and will be carried out. This concept stimulates a democratic system where citizens are more actively involved in the sustainable aims of the municipality. Next to the concepts, 30 + ideas where turned into an idea card deck which can be used by the municipality in future creative sessions or projects. Critical criteria for designing for the target group are grouped in a list and can serve as future knowledge when carrying out a project for this specific age group. An estimation of the business model of each concept is explained in detail, as well as a mini timeline in correspondence with the timeline of strategy of Rotterdam Circulair. The project concludes with a few recommendations for the municipality as to how they could proceed in the future: involving their target group more in sessions, using the idea card deck for inspiration and involving multiple divisions of the municipality to make the concepts work.","Circular behaviour; Adolescents","en","master thesis","","","","","","","","","","","","","",""
"uuid:7c5385ae-867d-41a0-8764-b7107c59a33b","http://resolver.tudelft.nl/uuid:7c5385ae-867d-41a0-8764-b7107c59a33b","Forest landscape restoration for climate-adaptive estates in the Baakse Beek region, Gelderland","Wang, Yanjiao (TU Delft Architecture and the Built Environment)","Nijhuis, S. (mentor); Ursem, W.N.J. (mentor); Wilms Floet, W.W.L.M. (graduation committee); van de Pas, R.R.J. (graduation committee); Delft University of Technology (degree granting institution)","2020","The research focuses on the estate zone of the Baakse Beek region which is facing environmental problems mainly caused by historical human intervention and climate change. Besides, in the Vorden cluster, as the land use changing caused by intense land reclamation and consolidation, the current agriculture productive landscape makes it not easy to perceive the rich historical layers.<br/>The main research method of this study is research by design and the main goal is to explore the potential of forest landscape restoration to increase the resilience of the estate landscape in the face of climate change and to promote their cultural-historical values and identity. By restoring forest landscape, it provides a green infrastructure to the estate zone to gain more spatial experience, ecological benefits, as well as cultural value, so that vulnerable aquatic eco-environment and cultural identity can be promoted.<br/>The research aims to design a climate-adaptive estate landscape as a green infrastructure that connects the estates, local history, ecology value and societal value through forest landscape restoration. This thesis primarily focuses on the territory of two estates, Het Medler and De Wiersse, where ecological restoration of the aquatic eco-system and cultural-historical landscape experience can be strengthened utilizing forest landscape restoration.","estate landscape; Baakse Beek; forest landscape restoration; climate change; culture heritage","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Landscape Architecture","","52.100039, 6.393811"
"uuid:44d9518f-1272-4e5f-a4de-025bddf1eb7c","http://resolver.tudelft.nl/uuid:44d9518f-1272-4e5f-a4de-025bddf1eb7c","MPC-based motion cueing algorithm for a 6 DOF driving simulator with actuator constraints","Khusro, Yash Raj (TU Delft Mechanical, Maritime and Materials Engineering)","Shyrokau, B. (mentor); Zheng, Y. (graduation committee); Happee, R. (graduation committee); Ferranti, L. (graduation committee); Wang, M. (graduation committee); Grottoli, M. (graduation committee); Delft University of Technology (degree granting institution)","2020","Driving simulators are widely used for understanding Human-Machine Interaction, driver behavior and driver training. The effectiveness of such simulators in this process depends largely on their ability to generate realistic motion cues. Though the conventional filter-based motion cueing strategies have provided reasonable results, these methods result in poor workspace management. To address this issue, linear MPC-based strategies have been applied in the past. However, since the kinematics of the motion platform itself is non-linear and the required motion varies with the driving conditions, this approach tends to produce sub-optimal results. In this thesis, a nonlinear MPC-based algorithm is presented which incorporates the non-linear kinematics of the Stewart platform within the MPC algorithm to increase the effectiveness and utilize maximum workspace. Further, adaptive weights-based tuning is used to smoothen the movement of the platform near its physical limits. Full-track simulations were carried out and performance indicators were defined to objectively compare the response of the proposed algorithm with classical washout filter and linear MPC-based algorithms. The results indicate a better reference tracking with lower root mean square error and higher shape correlation for the proposed algorithm. Lastly, the effect of the adaptive weights based tuning was also observed in the form of smoother actuator movements and better workspace utilization.","Driving simulator; Motion Cueing Algorithm; Model Predictive Control; Nonlinear; Actuator Constraints","en","master thesis","","","","","","","","2023-09-01","","","","","",""
"uuid:aa53d4cb-df91-434c-9974-5dd744fa4057","http://resolver.tudelft.nl/uuid:aa53d4cb-df91-434c-9974-5dd744fa4057","Identifying Structural Hazards in Building Construction Projects: A research into structural failure databases and risk assessments","Develi, Ali (TU Delft Civil Engineering and Geosciences)","Terwel, K.C. (mentor); Nijsse, R. (graduation committee); van Gelder, P.H.A.J.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","Building failure incidents are occurring within the Netherlands and these incidents can be a valuable source of technical data regarding improvements in structural safety. This research has attempted to utilize this information gained to develop a tool to aid the building construction sector in identifying hazards during building construction projects. For that purpose, this research has investigated risk assessments and structural failure incidents. To be able to develop a tool, deeper knowledge of risk assessments is required and therefore risk assessments were studied to understand how they should be performed and what characteristics makes them effective. The research of Terwel (2012) on the Cobouw database formed the basis for the analysis of structural failure incidents. This thesis investigated how other research used structural failure databases to improve structural safety and studied the data available from the Cobouw database for developing a tool. The analysis of risk assessments has shown that identifying hazards is a crucial step in the assessment process. It was concluded that it would be beneficial to a project team if it had information on which hazards related to structural failure can occur, the probability of occurrence of hazards and the possible impact they can have. An investigation into structural failure databases showed that no other research could provide a tool that fulfilled the above requirements and in addition it was concluded that the database available to this research was only sufficient to provide information on which hazards can occur. There was not enough data available to make a justified estimate regarding the consequences of a hazard or probability of occurrence. Therefore it was chosen to use a different approach to analyze the database. The Cobouw database has been restructured into a fault tree format, to relate hazards to specific components of a building structure. Afterwards an attempt was made to discover why many hazards have occurred or which building components were prone to hazards. There was not enough data available to draw conclusions on that subject either. Finally this research concluded that the most efficient way of developing a tool, from the data available to this research, is to create a guide which can be used during the design phase to caution the project team about frequently occurring hazards. The method that was used to create the tool can also be used as an inspiration for future research, because this research was limited not only by the amount of available incidents, but also by the source of the incidents, which was from a news site that would most likely not focus on low-profile failure incidents and the reporting of precise technical details. Therefore the most important recommendation this research has, is to introduce a large scale collaboration in the construction industry focused on gathering accurate data on structural failure incidents.","Building Damage; collapse; risk; Hazard Analysis; Hazard Detection; tool development; Building; Database; Structural Failure; Risk assessment; Identification; Hazard; Structural Safety","en","master thesis","","","","","","","","","","","","Civil Engineering | Building Engineering - Structural Design","",""
"uuid:d69bb846-d51d-4293-9343-2ba28f408422","http://resolver.tudelft.nl/uuid:d69bb846-d51d-4293-9343-2ba28f408422","Hypersonic Point-to-Point Travel for the Common Man: Optimizing the Optimization","Bislip-Morales, Carlos (TU Delft Aerospace Engineering)","Mooij, E. (mentor); Delft University of Technology (degree granting institution)","2020","Hypersonic travel typically involves increased sustained mechanical loads. Excluding technical and economic limitations, this largely remains available to trained individuals whose health is certified prior to travel. This work seeks to create a framework where it is possible to identify, for a chosen route and vehicle, a set of parameters such that an individual could participate without health screenings or prior training. A point-mass translational motion simulator is developed in C++ and an extensive design space exploration is executed to inform the selection of a series of optimization parameters. The optimization strategy encompasses a coupled and decoupled approach (combined ascent/descent optimization versus separate optimization per phase). Decoupling, as performed, did not allow for the identification of a linkable trajectory. An optimal trajectory was identified with the coupled approach that required a significant amount of additional mass, yet maximum total mechanical loads approached the constraint of 1 g0.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:5847f8da-b0cb-4dad-81d2-3494cfecf5a7","http://resolver.tudelft.nl/uuid:5847f8da-b0cb-4dad-81d2-3494cfecf5a7","Mindful Urban Dwelling: Care and conviviality as a means to community resilience and adaptation","Kesisoglou, Iosif (TU Delft Industrial Design Engineering)","Baha, S.E. (graduation committee); Price, R.A. (mentor); Becks, Michel (graduation committee); Delft University of Technology (degree granting institution)","2020","In the midst of climate change, a global pandemic, and an increasingly complex world, urban communities are in need for novel ways to adapt to the new climatic conditions.<br/><br/>Through a vision-led iterative design process, I explored how community resilience can flourish, by focusing on human relationships. Focusing on the values of care and conviviality, the process of commoning, and the act of being mindful, I investigated how urban dwellers can contribute directly towards the wellbeing of their community.<br/><br/>A digital platform is proposed for the empowerment of urban dwellers, to address collectively, great challenges, as the heatwaves, through the proactive sharing of relevant information, and awareness of community needs. A prototype of the concept provided depth on the potential of commoning. A pilot is proposed in collaboration with the Netherlands Red Cross.<br/><br/>An extensive literature review was performed on the areas of heatwaves, urban heat islands, international environmental agreements, the impact thereof in national policy and local resources, participatory practices and the commons, volunteering, care and conviviality.<br/><br/>A transition towards collective futures becomes a necessity in order to address the climate crisis, its effects on our communities and most importantly, personal and collective resilience and adaptation.<br","community resilience; heatwaves; care; conviviality; mindful urban dwelling; designer identity; climate change; commons","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:5bd2f042-74d1-4dc1-903d-dbe2d49f9f79","http://resolver.tudelft.nl/uuid:5bd2f042-74d1-4dc1-903d-dbe2d49f9f79","Dynamic Port-City Scapes: From Liminal ""Non-Places"" to Imaginative and Synergistic Adaptive Ecosystems","Höller, Lukas (TU Delft Architecture and the Built Environment)","Hooimeijer, F.L. (mentor); Hein, C.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","This research investigates the case of Kirkenes, Norway. The region with its 10.000 inhabitants is located around 400 km above the Arctic Circle within the municipality of Sør-Varanger, Finmark, and is known as the capital of the Barents Region and the gateway to the east. Located around 15km away from the Norwegian-Russian border, Kirkenes has strategic importance, being one of the main areas expected to change due to increased navigability as well as new reachability of resources benefited by a changing climate and melting Arctic sea-ice extent. The region is foreseen to become Europe’s gate and new logistic node towards the soon-to-be ice-free Northern Sea-Route, creating a 40% faster trading-route between Asia and Europe. Founded in 1905 as a harbor-town for the trans-shipment of iron ore extracted from the Sydvaranger Mine, around 8 km inland in Bjørnevatn, new port development is planned, serving as a potential strategic part for China´s “Polar Silk Road” Initiative. Despite the efforts for reinventing Kirkenes and changing its face from industrial development towards a future-proof, sustainable, and resilient Capital of the Barents Region, mining, as well as manufacturing and industrial development, never stopped being an essential factor. The municipality envisions a new and massive extra-urban port development along the neighbouring Tømmerneset Peninsula, transforming the small port into one of Scandinavia´s biggest container ports, equivalent to the current capacity of the Port of Gothenburg. The thesis focuses on the need for rethinking, adapting, and complementing current approaches on port-cities, thus spatial planning, and design as a holistic and interdisciplinary profession can gain operative power to become a mediator between the different institutional and non-institutional actors and their values to emerge a new port-city paradigm within Kirkenes. The complexity and diversity of the project-area depict the necessity to shift the perception of the port-city relationship away from a static, line-like interface of management between (in the meaning of separating) port and city towards dynamic and pluralistic “scapes” betwixt of in-between (in the meaning of belonging to both) port and city. The goal of the project is to imagine an alternative design of the new port-development driven by a place-specific, actors- and values-based approach, which aims for the in-between scapes, where port and city become intertwined and embedded within each other. The multiple of port and city and therefore the emergence of an additional dimension in-between the territorial economic force of the port and the local urbanity and culture helped to define the new Port-City Scapes as one synergistic adaptive ecosystem, in which needs of the port, city and ecology are united.","Port-City; Synergistic Adaptive Ecosystem; Paradoxsynergy; Kirkenes; Arctic Norway; design fiction","en","master thesis","","","","","","","","","","","","","","69.728578, 30.043259"
"uuid:850e12df-c75f-4941-a166-c391a661fc54","http://resolver.tudelft.nl/uuid:850e12df-c75f-4941-a166-c391a661fc54","Development of a strategy to obtain CE marking for MarginGuide: a system for intraoperative assessment of resection margins in oral cancer surgery","van der Sar, L.C. (TU Delft Mechanical, Maritime and Materials Engineering)","Koljenovic, Senada (mentor); Puppels, Gerwin J. (mentor); Lamego Barroso, Elisa M. (mentor); Aaboubout, Yassine (mentor); Ottevanger, Lars (mentor); Delft University of Technology (degree granting institution); Erasmus Medical Center (degree granting institution); Leiden University Medical Center (degree granting institution)","2020","The most frequent type of head and neck cancer is oral cavity squamous cell carcinoma (OCSCC). Surgery is the mainstay of treatment and aims for complete resection of the tumor with adequate margins, while sparing healthy tissue as much as possible. Adequate margins lead to higher survival and a marked reduction in local recurrence in OCSCC patients. However, recent studies have shown that adequate resection margins are often only achieved in the minority (15-26%) of the oral cavity cancer cases. Achieving adequate margins is difficult due to the complex anatomy and that surgeons solely rely on visual inspection, palpation and preoperative imaging.<br/><br/>Therefore, SurGuide B.V., Erasmus MC, RiverD International B.V. and art photonics GmbH joined forces to develop MarginGuide: an objective, fast, easy to use, intraoperative tool based on Raman spectroscopy for intraoperative assessment resection margins (IOARM) in soft tissue OCSCC specimens. The team is currently taking steps to further develop MarginGuide into a commercially available product by obtaining CE-marking. The goal of this thesis is to develop and partially carry out a strategy to obtain CE-marking for MarginGuide.<br/><br/>A strategy that will demonstrate MarginGuide’s compliance to the General Safety and Performance requirements from the In Vitro Diagnostic Medical Device Regulation (IVDR) was developed. The strategy includes 1) a review of literature, investigating the performance of the current standard of care for IOARM in OCSCC surgery and diagnostic alternatives (predicate devices), 2) a risk analysis, and 3) the design of studies to evaluate MarginGuide’s performance.<br/><br/>The literature review showed that 1) the most frequently used method for IOARM in OCSCC, i.e. frozen section, is prone to sampling errors since only a fraction of the resection surface can be assessed and 2) there are two marketed devices that use spectroscopy for IOARM in breast cancer surgery, but they did not meet the criteria of a predicate device. This indicates the need to generate new safety and performance data with MarginGuide.<br/><br/>The risk analysis was performed to identify the risks associated with MarginGuide for patients, operators and bystanders. All identified risks were mitigated by control measures, of which the new control measures were added to the requirements of MarginGuide.<br/><br/>To evaluate MarginGuide’s performance, the following studies were designed: 1) a pilot study to investigate the accuracy of MarginGuide in measuring resection margins in OCSCC specimens at specific measurement locations with a precision better than 1 mm, 2) a usability study to evaluate a designed measurement protocol for IOARM, and 3) an observational study to demonstrate the non-inferiority of MarginGuide to IOARM as performed in Erasmus MC in predicting margin status.<br/><br/>A performance evaluation plan containing the performance of the current methods for IOARM, the risk analysis and the designed studies (including a post-market follow up plan) should be forwarded to the Notified Body (NB). The studies will be carried out after the NB gave permission. The results should be reported in a performance evaluation report, that will be assessed by a NB to determine whether MarginGuide receives CE-marking.","intraoperative assessment of resection margins; oral cavity cancer; MarginGuide; CE-marking; IOARM","en","master thesis","","","","","","","","2025-08-28","","","","Technical Medicine | Imaging and Intervention","",""
"uuid:21c742b5-686a-49e6-a670-c2ec396c8c60","http://resolver.tudelft.nl/uuid:21c742b5-686a-49e6-a670-c2ec396c8c60","Accessible last-mile mobility support for children in Artis: a product-service proposal","Hoeksma, Lotte (TU Delft Industrial Design Engineering)","Oberdorf, J.E. (mentor); Kroon, C.P.J.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","As the oldest zoo of the Netherlands, Artis aims to provide her visitors with a carefree experience. Artis offers mobility support by means of freely available carts to ease the visit of young children and their caregivers. The identified shortage of children carts influences the visitor experience negatively. Increasing the number of carts is not considered an option because of the lack of space in the park and high costs per cart. Furthermore, the cart retains an iconic status within the park, which makes Artis hesitant to change. This research aimed to redefine the mobility support service for children and caregivers in Artis. The goal was to design a product-service combination that fulfils both the needs of the visitor, Artis staff and management. Wide-ranging research including interviews, observations and desk research brought together the views of the internal stakeholders and visitors. Synthesis of data points and insights showed that there is not only a shortage of carts and a lack of space, but that the current service does not meet the expectations of the visitor. The service was thought to be unpredictable, inaccessible and unavailable and the cart was considered unsafe, not suitable for all relevant ages, and had many physical shortcomings. Also, the service blueprint showed that the service challenges the organization by high demand for maintenance, unpredictable daily servicing and unwanted involvement of the front office. Concluding, both the service and cart needed to be redesigned to tackle the identified problems. Key challenges and design criteria were formulated to guide the design process; the service-product combination should provide suitable and safe mobility support for caregivers and children aged 1 up to and including 3 years of age which can be picked up, left and parked any time. A self-service is sought that is predictable and accessible. The service should provide sufficient capacity, require minimal (daily) maintenance, fit the park vision and should use minimal space in the park. An intensive design process followed and resulted in a product-service proposal. The proposed service provides readily available and predictable mobility support that fits children and their caregivers with different age-dependent needs. A large number of inviting and safe, one person pullcarts is offered which can be picked up and left at any of the ten compact stations throughout the park, thus stimulating intermittent use. It is a nonsupervised self-service using tokens. The cart is made of simply bent powder-coated steel tubes and weather-resistant wood, making the cart durable, relatively easy to produce and maintain. The carts nest in stations allowing for minimal use of space, they are unobtrusive and can be scaled up easily. The proposal was evaluated with visitors and main internal stakeholders. Visitors saw value in the possibility to take and leave a cart at the different stations and the availability of information made it accessible. Furthermore, the cart was considered safe. The Artis staff considered the concept valuable in the short term and long term and concluded that implementation of (parts of) the concept would improve the visitor experience. Review of the newly designed product-service concept leads to the conclusion that the proposal is an improvement on the current service. Time restrictions limited further development of the concept. Before the cart is production-ready, several parts need further development and testing with 1:1 scale prototypes. Meanwhile, elements of the proposed service can already be integrated to improve the current service. Interactions with new service touchpoints can then be validated in the park. When the new service is launched, practice must show if the stations are located in the right place and if the number of the proposed carts and stations suffices to stimulate the sharing of carts. <br","Product-Service System; Integrated Product Design; Mobility support; Children","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:8e45b2a6-eaa3-47b5-a4de-2205d834dff8","http://resolver.tudelft.nl/uuid:8e45b2a6-eaa3-47b5-a4de-2205d834dff8","Seasonal Energy Storage: An optimized district heating system for solar thermal operation in combination with seasonal heat storage","Wolbert, Gijs (TU Delft Electrical Engineering, Mathematics and Computer Science)","Infante Ferreira, C.A. (mentor); Pecnik, R. (graduation committee); Moultos, O. (graduation committee); Delft University of Technology (degree granting institution)","2020","","Thermal; Energy; Storage; Seasonal; STES; District; Heating; Solar; DHS","en","master thesis","","","","","","","","2025-08-28","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:7a73d882-adea-4d44-b835-2dcee89341c3","http://resolver.tudelft.nl/uuid:7a73d882-adea-4d44-b835-2dcee89341c3","Analysis of a Data Processing Pipeline for Generating Knowledge Graphs from Unstructured Data: Data Processing Pipeline for Knowledge Graphs","Kumar, Paras (TU Delft Electrical Engineering, Mathematics and Computer Science)","Epema, D.H.J. (mentor); Delft University of Technology (degree granting institution)","2020","With the rapid growth of unstructured data across different mediums, it exposes new challenges for its analysis. To overcome this, data processing pipelines are designed with the help of different tools and technologies for the analysis of data at different stages. One of the applications which we find useful for our company is the creation of knowledge graphs for better representation and understanding of relations in the data. Knowledge graph is a structure of representing information where nodes represent the entities and edges define the relationships among them. The construction of a knowledge graph is a process of extracting meaningful information of entities and relations from unstructured textual data and storing it in a graph database. In this project, we are using Neo4j as a graph database for the efficient storage of data in the form of nodes and relations. To achieve this goal, our first research question proposes the architecture and implementation of a data processing pipeline for the construction of knowledge graphs using unstructured textual data. There are three major stages involved in our pipeline and each component is implemented in a microservice architecture. The first stage starts with the parsing of textual documents in two different formats which are PDF and PPT. In the second stage, we are applying natural language processing techniques for the extraction of meaningful information out of this raw text. In the final stage, key pieces of data are stored into a graph database(Neo4j) for the construction of knowledge graphs. We are running our pipeline on a local machine for evaluating the performance and results of each component. The core aspect of retrieving insights from this unstructured data is achieved with the use of natural language processing. In order to investigate more on this component, our second research question examines the cloud based natural language processing services from three renowned providers which are Amazon, Google and IBM. For choosing a suitable service among them, we evaluate their performance on a common data set of category Marketing from wikipedia. Based on our experimental analysis, IBM stands out among them from the perspective of the quality of output, execution time, features and cost. The adoption of a cloud based service not only leads to a faster development of business solutions but also reduces the engineering effort, its cost and maintenance of our custom implementation only with a little cost per our usage.","Data Processing Pipeline; Knowledge Graph; Natural Language Processing","en","master thesis","","","","","","EIT Digital Double Degree Programme","","","","","","Computer Science","",""
"uuid:ff7dc597-c30f-4aaf-b06e-63a0593d68a0","http://resolver.tudelft.nl/uuid:ff7dc597-c30f-4aaf-b06e-63a0593d68a0","Make Some Noise Schiphol: A study on a parametric architectural strategy for the design of aircraft noise abatement landscape elements within cities","Tsionis, Ioannis (TU Delft Architecture and the Built Environment)","Tenpierik, M.J. (mentor); Turrin, M. (graduation committee); Delft University of Technology (degree granting institution)","2020","This research focuses on aircraft noise exposed urban spaces around Amsterdam Schiphol airport. In particular, a case site in Rijsenhout is studied, where a representation of the noise wave propagation due to refraction is performed. Subsequently, a series of landscape configurations regarding geometry are gradually tested through acoustic simulation and noise maps are imported inside a parametric design environment. Finally, a conceptual design proposal is structured in order to explore the potential of such configurations in the urban environment.","aircraft noise; noise reduction; atmospheric refraction; landscape design; urban soundscape; Rijsenhout","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Building Technology | Sustainable Design","",""
"uuid:2b89d013-5aaa-4e52-8849-c5d26ecb26ca","http://resolver.tudelft.nl/uuid:2b89d013-5aaa-4e52-8849-c5d26ecb26ca","Online recognition of oral activities","Vijayaragavan, Jaya Rupini (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Biomechanical Engineering)","van der Helm, F.C.T. (mentor); Gallo, Luigi (mentor); van de Ruit, M.L. (graduation committee); Jafarian, M. (graduation committee); Delft University of Technology (degree granting institution)","2020","Temporomandibular disorders (TMD) affect about 5-12 percentage of individuals with consequences such as jaw noises, clicking, myofascial pain, discomfort, limited mandibular range of motion and stress. Treatments depend on the cause and extent of the damage and part of the joint or jaw affected. When exact aetiology of TMD is unclear, generic treatments (splint therapy) are offered. Different oral activities performed on a daily-basis result in different loading conditions on the joint, possibly triggering TMD. These need to be investigated to know the usage of the masticatory system and the potential damage, in order to perform speciﬁc treatments. Our work aims at developing an online algorithm that can classify oral tasks performed by individuals. It can be used during daytime or overnight’s sleep to see how often different activities are performed by subjects. A 4 stage wavelet decomposition was employed to the signals and then subjected to feature extraction to train a support vector machine algorithm with. The prediction accuracy was found to be 90 percent for a group of selected oral activities (static, jaw opening, chewing and maximal voluntary clenching). The algorithm had about 80 percent prediction accuracy when classifying both functional (chewing, jaw opening and static) and parafunctional activities (grinding, incisal biting, maximal voluntary clenching, protrusion and laterotrusion) together. However, 80 percent accuracy is regarded as a set back due to the lack of more data. On reviewing the recognised activities, further research on any overuse of muscles or loading on the jaw joint during each activity can be conducted to give speciﬁc treatment and therapy preventing any deteriorating actions. Thus,the developed classiﬁcation algorithm works as a prototype for future studies on online recognition of oral activities.","TMJ; TMD; myofascial pain; time-frequency analysis of sEMG; online classiﬁcation","en","master thesis","","","","","","","","","","","","Biomedical Engineering","",""
"uuid:3c7d46f2-f737-4b2b-9c3d-8d239e44786c","http://resolver.tudelft.nl/uuid:3c7d46f2-f737-4b2b-9c3d-8d239e44786c","Recursive Tensor Network Bayesian Learning of Large-Scale LS-SVMs","Lucassen, Max (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Delft Center for Systems and Control)","Batselier, K. (mentor); Delft University of Technology (degree granting institution)","2020","Least-squares support-vector-machines are a frequently used supervised learning method for nonlinear regression and classification. The method can be implemented by solving either its primal problem or dual problem. In the dual problem a linear system needs to be solved, yet for large-scale problems this can be impractical as current methods suffer from the \textit{curse of dimensionality}. This phenomena causes the computational and memory requirements to exceed the capabilities of standard computers for large datasets. In this thesis, a tensor network Bayesian learning method was developed to avoid these burdensome complexities. The developed method performs competitively with the current state-of-the-art, and unlike other low-rank approximation methods, allows for incorporation of user-knowledge, noise, early stopping, and yields confidence bounds on the obtained model.","LS-SVM; Bayesian learning; tensor networks; fixed size LS-SVM; Supervised learning; Regression; Classification; Nystrom method; Kalman filter; large-scale","en","master thesis","","","","","","","","2021-08-28","","","","Mechanical Engineering | Systems and Control","",""
"uuid:2d83a658-ba66-488b-bce4-5601a310e847","http://resolver.tudelft.nl/uuid:2d83a658-ba66-488b-bce4-5601a310e847","Re-thinking the Role of Citizens in Evaluating Quality of Life in the Smart City","Venkatachalam, Siddharth (TU Delft Architecture and the Built Environment; TU Delft Urbanism)","Barba Lata, Iulian (mentor); Rooij, R.M. (mentor); Delft University of Technology (degree granting institution); Wageningen University & Research (degree granting institution)","2020","Cities around the world are struggling to cope with global challenges such as climate change, resource constraints, overpopulation, energy, and infrastructure management. To this effect, the “Smart City” concept over the last 20 years has promised to be the gateway to sustainable development and improved quality of life in cities through the use of innovative technologies and participation with citizens and users in the urban environment. Despite these promises, the concept has been largely criticised for being largely technology and market-driven rather than being able to solve problems for people living in the city. Existing research has identified that the citizen is largely just a bystander in the development of smart cities and that solutions more often than not fail to address the needs and wants of citizens. Still, the concept is being adopted all around the world and smart projects are being implemented continuously through public funding. Although there are multiple definitions of the concept, citizen engagement is understood as a crucial part of the approach and improving quality of life the overall goal of the smart city. <br/><br/>This study attempts to find out what role citizens can play in evaluating for quality of life by attempting to describe the relationship between the two in the context of smart city projects in Amsterdam. The inability of smart cities and smart projects to be able to identify their impact with respect quality of life demands the involvement of citizens in the process. Therefore, this research takes an interpretive approach to contextually study the setting of Amsterdam as a smart city and projects within it. The results show that Amsterdam despite being labelled a “smart city” does not call itself as such and is moving away from the term. Furthermore, its approach to development is inherently citizen-centric and places a large importance on the quality of life although, challenges exist. The smart city projects explored in this research highlight that there is a strong relationship between citizen engagement and quality of life. To this, the research finds that without engaging with citizens it would not be possible for developers and policymakers to assess the subjective values that matter to citizens as experienced in two out of the four projects studied. Despite the challenges observed within projects, results from this study support the assumption that that citizen engagement can help in identifying and understanding factors affecting the quality of life and improve assessment for it. <br/><br","Smart Cities; Quality of Life; Participation; Citizen Engagement; Impact Assessment","en","master thesis","","","","","","","","","","","","Metropolitan Analysis, Design and Engineering (MADE)","",""
"uuid:38653645-7e0e-4e80-9c73-c894d1bb885b","http://resolver.tudelft.nl/uuid:38653645-7e0e-4e80-9c73-c894d1bb885b","Direct or Indirect?: Unraveling the bandgap nature of metal halide perovskites","Ackermans, Marnix (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Precision and Microsystems Engineering; TU Delft Micro and Nano Engineering)","Staufer, U. (mentor); Ehrler, Bruno (mentor); Hutter, Eline M. (mentor); Steeneken, P.G. (graduation committee); Savenije, T.J. (graduation committee); Delft University of Technology (degree granting institution)","2020","Since the discovery of the photovoltaic properties of metal halide perovskites in 2009, the material has rapidly gained interest in the scientific community. In less than 10 years, the power conversion efficiency of perovskite solar cells (PSC) has increased from 3.9% to over 25%, reaching levels of conventional silicon cells. PSCs have multiple favorable properties, such as low manufacturing costs, thin film flexibility, and a tunable bandgap, which is promising for tandem solar cells that can surpass the Shockley-Queisser efficiency limit of conventional (single-junction) solar cells. Other applications are color-tunable LEDs and super sensitive (x-ray) photodetectors. However, there are still mysteries surrounding perovskites that need to be solved in order to fully understand the extraordinary properties of the material. For a specific perovskite, CH3NH3PbI3 (MAPI), it is debated whether it has a direct or indirect bandgap. In this work, a new Photothermal Deflection Spectroscopy (PDS) setup is designed and build that can perform sensitive below-bandgap absorption measurements under hydrostatic pressure (up to 400 MPa). Measurements performed with this setup resulted in absorption spectra of MAPI at different pressures, showing a transition from a primarily indirect bandgap at ambient pressure to a more direct bandgap at 375MPa. The data provides new empirical evidence indicating an indirect-to-direct bandgap transition at 325MPa, which opens a novel perspective on unraveling the nature of the bandgap of metal halide perovskites.","Perovskite solar cells; MaPbI3; Direct-Indirect bandgap; Photothermal Delfection Spectroscopy","en","master thesis","","","","","","","","2021-08-31","","","","Mechanical Engineering | Micro and Nano Engineering","",""
"uuid:d6558e54-098f-48be-9951-9c4ea1969350","http://resolver.tudelft.nl/uuid:d6558e54-098f-48be-9951-9c4ea1969350","At the Crossroads: Design for Railway Freight Capacity Decision-Making","Remijn, Ivan (TU Delft Technology, Policy and Management)","Warnier, Martijn (mentor); van Duin, Ron (mentor); Delft University of Technology (degree granting institution)","2020","Growing demand for railway-based transport stresses railway infrastructure on safety, punctuality, and robustness. The Port of Rotterdam and ProRail desire a process of executing simulation model supported capacity studies wherein inputs, methods and outputs are coordinated upfront. However, interorganisational capacity studies are currently conducted ad hoc in lengthy processes, in which there is disagreement about inputs, methods, and outputs of the process. They can be considered misaligned as the internal capacity management processes do not fully fit each organisation’s objectives, while also not being sufficiently adaptive towards the dynamic railway capacity context. Alignment is the result of coordination activities between collaborating organisations. An aligned rail freight capacity management process is necessary for the successful matching of demand and supply for rail freight transport services, and can be supported by simulations of the railway capacity. Thus, the question arises: How to improve the alignment of collaborating organisations on quantitative metrics for railway freight capacity in the Port of Rotterdam with the use of meso-level simulation models?<br/><br/>This research presents a process design for an interorganisational capacity planning process that has the potential to improve alignment between the collaborating organisations. The principle-based design method presents a novel approach to addressing alignment problems in the domain of decision-model supported capacity planning collaboration between networked organisations. The process design is formulated through a design science method, wherein specific coordination challenges are matched to literature-derived principles regarding technical and interorganisational coordination of capacity planning processes. The design is evaluated against stakeholder defined requirements and through discussion of the proof of concept: an executed capacity study using the formulated design.","Interorganisational Capacity Planning; Railway Capacity; Planning & Control; Capacity Management; Design Science","en","master thesis","","","","","","","","2020-08-26","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:bf0c3ee6-51c0-40aa-8a96-fc5e20ea1bdd","http://resolver.tudelft.nl/uuid:bf0c3ee6-51c0-40aa-8a96-fc5e20ea1bdd","Valuation of electricity storage contracts based on the COS method: with underlying polynomial electricity prices","Boonstra, B.C. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Oosterlee, C.W. (mentor); Delft University of Technology (degree granting institution)","2020","In this thesis we introduce valuation techniques to price electricity storage contracts, where the electricity prices follow a structural model based on polynomial processes. In particular we focus on a Fourier-based pricing method known as the COS method, which performs impressively to price the contracts accurately. We provide details on how to formalize an electricity storage contract, taking into account the physical limitations of an electricity storage and the operational constraints of the electricity grid. In addition to the electricity storage contract, other well-known options are being considered, such as the European option, Bermudan option and Bermudan option with multiple early-exercise rights, where the same asset price model is used based on polynomial processes. We propose an approximation of the characteristic function, so that the Fast Fourier Transform (FFT) can be applied to significantly reduce the computational complexity of the COS method, which is especially suitable for pricing Bermudan options and Bermudan options with multiple early-exercise rights. With the FFT-based algorithm, the computation time of the valuation of the discussed Bermudan-type options with the COS method is reduced from seconds to milliseconds. Furthermore, the Least Squares Monte Carlo (LSMC) method is presented to value the discussed financial derivatives and used to validate the results obtained with the COS method.","Electricity storage contract; Valuation; COS method; Polynomial processes; Least Squares Monte Carlo; Options; Electricity Prices; Energy markets; Characteristic function","en","master thesis","","","","","","","","2020-08-20","","","","Applied Mathematics | Financial Engineering","",""
"uuid:da4ed7f1-62d5-4871-8475-5b5f68183ab0","http://resolver.tudelft.nl/uuid:da4ed7f1-62d5-4871-8475-5b5f68183ab0","Local Explanation Methods for Isolation Forest: Explainable Outlier Detection in Anti-Money Laundering","Bergþórsdóttir, K.B. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Oosterlee, C.W. (mentor); Haasdijk, Evert (mentor); Fontanari, Andrea (graduation committee); Parolya, N. (graduation committee); Delft University of Technology (degree granting institution)","2020","Machine learning methods like outlier detection are becoming increasingly more popular as tools in the fight against money laundering. In this thesis, we analyse the Isolation Forest outlier detection algorithm in detail and introduce a new local explanation method for Isolation Forest, the MI-Local-DIFFI (Multiple Indicator Local-DIFFI) method. The method uses the structure of the isolation trees and the traversal of individual outliers down the trees to determine an importance weight for each of the features. These weights are then combined into feature importance scores that are used to explain why a specific outlier is identified as such. In anti-money laundering (AML), such explanations are very valuable when determining whether an outlying customer is suspicious or not. MI-Local-DIFFI is based on a global explanation method called DIFFI and while we were conducting our research, another local version, Local-DIFFI, was also introduced. In the thesis, we use a synthetic data set to compare the performance of four different explanation methods including our MI-Local-DIFFI, Local-DIFFI and the state-of-the-art TreeSHAP method. Our MI-Local-DIFFI shows excellent results in terms of performance and runtime. Furthermore, we use a data set from Triodos bank to apply the explainable outlier detection methodology consisting of the combination of Isolation Forest and MI-Local-DIFFI. This resulted in interesting findings like the revealing of data quality issues in the current system and references to EDRs and SARs. However, after further inspection, no SARs were filed but some customers were put to higher risk classes. This procedure will be performed on a monthly basis with the goal of continuing to improve the AML processes of the bank.","Machine Learning; Outlier Detection; Anti-Money Laundering; Explainable Machine Learning","en","master thesis","","","","","","","","","","","","Applied Mathematics | Financial Engineering","",""
"uuid:f142dfad-6cb4-4e0a-b02d-fa1b0320d162","http://resolver.tudelft.nl/uuid:f142dfad-6cb4-4e0a-b02d-fa1b0320d162","MMC performance evaluation concerning different dc breakers and converters","Kidambi Murali, Pragati (TU Delft Electrical Engineering, Mathematics and Computer Science)","Popov, M. (mentor); Lekic, A. (graduation committee); Gholizad, B. (graduation committee); Koreman, Kees (mentor); Delft University of Technology (degree granting institution)","2020","Renewable energy resources are the most successful, promising, and economical mode of energy generation. Moreover, wind energy is also one of the victorious candidates in generating renewable energy. Currently, High Voltage Direct Current (HVDC) systems are designed to integrate the energy harvested in the Offshore Wind Farms (OWF) to the grid system. The HVDC system uses AC-DC converters, and then with the help of DC cables, the power is transmitted from the offshore to the onshore area, where it again gets converted back to AC. The converters used here are called high voltage converters, where these power electronic components have the ability to sustain high voltages and current. Further, in this thesis, Modular Multilevel Converter (MMC) is used for the conversion of AC to DC and vice versa. The MMC is built using stacked Insulated Gate Bipolar Transistors (IGBTs), where these power electronic components are current sensitive in nature. Thereby, if there is a fault, and if this fault current flows through them, then these components get damaged permanently. Moreover, if the offshore MMC goes down, the OWF system has to undergo a restart. Therefore, the DC Circuit Breaker (DCCB) is used in order to clear the DC fault in an HVDC system. Meanwhile, designing a DCCB for the HVDC system is not easy, one major reason is that there are no natural zero crossings in a DC fault. Also, the fault must be cleared very quickly because DC faults have a very high rate of rising in fault currents. Earlier, the MMC protects itself by using the blocking algorithm. Here, the switching devices turn off temporarily until the fault is cleared. When they are turned off, the fault current flows through the freewheeling diodes, as diodes have the capability to withstand high currents. Indeed, if the MMC is blocked, the purpose of DCCB is not satisfied. Therefore, in this thesis, the performance of the MMC is examined with the presence of DCCBs for a 525 KV system. Besides, there are two types of DCCBs used, in order to evaluate the more suitable breaker for the system. Further, with the initial performance, the fault behavior of MMC is analyzed and illustrated. Consequently, the DC inductance, converter inductance, and arm inductance were modified in order to improve the performance of the system. On the other hand, there are two types of MMC, namely Half Bridge MMC (HBMMC) and Full Bridge MMC (FB MMC). Generally, the HB MMC are called fault feeding converters, whereas the FB MMC are called fault blocking converters. This is due to the topology of the FB MMC, where it completely blocks the fault current by itself. Therefore, the performance of the HB MMC with a DCCB is compared with the FB MMC with blocking protection for a 320 KV network.","HVDC; DC circuit breakers; Modular Multilevel Converter (MMC); DC faults; Half bridge MMC; Full bridge MMC; PSCAD; MTHVDC","en","master thesis","","","","","","","","","","","","Electrical Engineering","",""
"uuid:bedf3432-0793-46cd-9746-5c2b97eec81d","http://resolver.tudelft.nl/uuid:bedf3432-0793-46cd-9746-5c2b97eec81d","Can you really help me?: Supporting empathic dialogue to understand care service for assisting women against violence","Lopez Reyes, M.E. (TU Delft Industrial Design Engineering; TU Delft Design, Organisation and Strategy)","Sonneveld, M.H. (mentor); Sleeswijk Visser, F. (mentor); Espeleta Olivera, Mariana (mentor); Delft University of Technology (degree granting institution)","2020","Even though there has been an enormous effort to tackle the problem of gender-based violence against women in Mexico, within legal terms, the landscape still seems uncertain, and the need for innovative approaches that bring new meaningful ways to look at the problem becomes highly relevant.<br/><br/>In those lines, the University Center for Dignity and Justice Francisco Suárez, SJ (CUDJ for its initials in Spanish), is working in making a diagnosis of the problem to propose strategies that ensure a life free of violence for women by triggering the discussions with the authorities in charge.<br/><br/>This report presents the research, analysis, design and development process of a proposal that seeks to provide tools to foster dialogues for an empathetic perspective, which encourages the emergence of shared knowledge and meanings, unveiling new perspectives to drive innovation and promote change.<br/><br/>Through a service design study, a set of dialogic visual tools translated women’s experiences into visualizations that enable the viewer to understand, empathize, and take an active responsibility towards women’s needs.<br/><br/>At the end of each chapter, a summary of the key insights that drove the design process is presented. The project aims to contribute to the discussion of the role of visualization in the emerging design landscape and how it is possible to contribute to the understanding, in human-scale, of complex contexts such as violence against women.","Empathy; Dialogue; Dialogic-Design; Service-Design; Violence Against Women; Care-Service; Data-Visualization; Human-Centered Design","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:c6d43d2d-cb33-450f-b59a-636ec07bc34a","http://resolver.tudelft.nl/uuid:c6d43d2d-cb33-450f-b59a-636ec07bc34a","Automatic Depth Matching for Petrophysical Borehole Logs","Garcia Manso, A. (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Microelectronics)","Leus, G.J.T. (mentor); Przybysz-Jarnut, Justyna (mentor); Epping, Willem (graduation committee); Isufi, E. (graduation committee); Delft University of Technology (degree granting institution)","2020","In the oil and gas industry a crucial step for detecting and developing natural resources is to drill wells and measure miscellaneous properties along the well depth. These measurements are used to understand the rock and hydrocarbon properties and support oil/gas field development. The measurements are done at multiple times and using different tools. This introduces multiple disturbances<br/>which are not related to physical properties of rocks or fluids themselves, and should be tackled before data is used to build subsurface models or take decisions. One important source of this disturbances is depth misalignment and in order to compare different measurements care must be taken to ensure that all measurements (log curves) are properly positioned in depth. This process is called depth matching. In spite of multiple attempts for automating this process it is still mostly done manually. This thesis addresses the automation problem and proposing a model based approach to solve it using Parametric Time Warping (PTW).<br/><br/>Based on the PTW, a parameterised warping function that warps one of the curves is assumed and its parameters are determined by solving an optimization problem maximizing the cross-correlation between the two curves. The warping function is assumed to have the parametric form of a piecewise linear function in order to accommodate the linear shifts that take place during the measurement process. This method, combined with preprocessing techniques such as an offset correction and low pass filtering, gives a robust solution and can correctly align the most commonly accruing examples. Furthermore, the methodology is extended to depth match logs with severe distortion by applying the technique in an iterative fashion. Several examples are given when developed algorithm is tested on real log data supplemented with the analysis of the computational complexity this method has and the scalability to larger data sets.","Automatic depth matching; Piecewise Linear Time Warping; PLTW; Depth matching; Warping; Curve alignment; dynamic time warping; Borehole log; Petrophysics; Parametric; parametric warping; parametric time warping; time warping; depth warping","en","master thesis","","","","","","","","","","","","Electrical Engineering","",""
"uuid:e4b9e788-a502-4aee-8330-6ebf141e75f5","http://resolver.tudelft.nl/uuid:e4b9e788-a502-4aee-8330-6ebf141e75f5","Unconventional permeable microstructures: An engineered porous material: Designing the microstructure of a dynamic insulation component using additive manufacturing and evaluating its effect on airflow rate and pattern","Mousavi, Kiana (TU Delft Architecture and the Built Environment)","Turrin, M. (mentor); van der Spoel, W.H. (graduation committee); Delft University of Technology (degree granting institution)","2020","Designing energy-efficient facades can have a significant impact on reducing the building's energy consumption while providing comfort for the occupants. While highly-insulated buildings have good thermal insulation and high airtightness, they deal with the risk of overheating issues. Dynamic insulation, a technology consisting of porous materials, is a responsive building element that has been introduced to the built environment to tackle these problems. Due to the current lack of information and available resources on dynamic insulation, and its possible contribution to the built environment, the presented research focuses on the effect of complex geometries as the air channels in dynamic insulation, and as part of the overall building wall. This thesis aims to discover whether and how a designed microstructure (now possible by Additive Manufacturing) in dynamic insulation can offer a solution for controlling the airflow passing through the wall and therefore, improving the performance of the dynamic insulation. The methodology of the thesis started with the literature review and studying different articles and books. Then in a design-through-research approach, various parameters were identified that could affect the airflow rate and pattern. These parameters were categorized in two groups with relation to geometry and texture. The dominant factors were then selected to be further analyzed. Next, different geometries were generated using the 3D sampling method, based on different textures with different properties. The engineered geometries are texture-based metamaterials with cavities. To investigate the behavior of airflow in these geometries, CFD simulations were performed in Ansys Fluent. The results were evaluated based on their correspondence to the research objectives and conclusions were drawn to answer the research questions. Keywords: Texture-based metamaterials with cavities, complex geometries, dynamic insulation, porous materials, airflow behavior, responsive building elements.","Texture-based metamaterials with cavities; Complex geometries; Dynamic insulation; Porous materials; Airflow behavior; Responsive building elements","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Building Technology","",""
"uuid:e4077b7c-1b05-4193-bddb-ea3e4fdb4b4c","http://resolver.tudelft.nl/uuid:e4077b7c-1b05-4193-bddb-ea3e4fdb4b4c","Object Detection As A Safety Check For Human Factors In Operating Remotely Controlled Bridges","de Groot, Ernst (TU Delft Civil Engineering and Geosciences)","van Gelder, P.H.A.J.M. (graduation committee); Ding, A.Y. (graduation committee); Schraven, D.F.J. (graduation committee); Kraaijenbosch, C.L. (mentor); Delft University of Technology (degree granting institution)","2020","According to a report published by the Dutch Safety Investigation Board in early September 2019, the safety of remotely controlled bridges is not su_cient (Onderzoeksraad voor de Veiligheid, 2019, pg.58). This report was published after the occurrence of two severe accidents in Zaandam, on the Den Uylbrug and the Prins Bernhardbrug. On both occasions, the victims were standing on the movable part of the bridge deck during the opening of the bridge, and despite being visible for over a minute on the camera screens, were not observed by the operators, making the accidents human factor-based. The Dutch Safety Investigation Board concluded that part of the problem was safety mainly being considered a technical problem, instead of an integral one. In this research, the goal was to analyse how object detection could provide decision support for mitigating human factors for operating remotely controlled bridges. This was done by identifying the problems through literature studies, interviews and observations, and by building a proof of concept to mitigate these problems. Finally, this model was evaluated to gain experimental insights into the possibilities of object detection as a decision support tool.","Object Detection; Asset Management; Remotely Controlled Bridges; Decision Support","en","master thesis","","","","","","","","","","","","Civil Engineering","",""
"uuid:96639fb6-0b15-4584-b019-74bd4257a9b9","http://resolver.tudelft.nl/uuid:96639fb6-0b15-4584-b019-74bd4257a9b9","Using a Physics-Informed Neural Network to solve the Ideal Magnetohydrodynamic Equations","Bouma, Jort (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Applied Sciences)","Möller, M. (mentor); Toshniwal, D. (mentor); Akhmerov, A.R. (mentor); Dubbeldam, J.L.A. (mentor); Kenjeres, S. (mentor); Delft University of Technology (degree granting institution)","2020","In this work we investigate neural networks and subsequently physics-informed neural networks. Physicsinformed neural networks are away to solve physical models that are based on differential equations by using a neural network. The wave equation, Burgers’ equation, Euler’s equation, and the ideal magnetohydrodynamic equations are introduced and solved with physics-informed neural networks. The solutions to the first equations were captured well. The solution to the ideal magnetohydrodynamic equations contained some problems. These problems include transitions between different types of behaviour and exact values of constant sections. On the other hand, general shape and behaviour of the curve and locations of contact discontinuities were predicted well.","PINNs; MHD; Neural Networks; magnetohydrodynamic; Feed Forward; physics-informed","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics | Applied Physics","",""
"uuid:968aa2e8-042e-437b-a7b7-d26835067757","http://resolver.tudelft.nl/uuid:968aa2e8-042e-437b-a7b7-d26835067757","Modeling the physics of RRAM defects: A model simulating RRAM defects on a macroscopic physical level","Hol, Tijs (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Computer Engineering)","Hamdioui, S. (mentor); Ishihara, R. (graduation committee); Vollebregt, S. (graduation committee); Taouil, M. (graduation committee); Fieback, M.C.R. (graduation committee); Delft University of Technology (degree granting institution)","2020","Resistive RAM, or RRAM, is one of the emerging non-volatile memory (NVM) technologies, which could be used in the near future to fill the gap in the memory hierarchy between dynamic RAM (DRAM) and Flash, or even completely replace Flash. RRAM operates faster than Flash, but is still non-volatile, which enables it to be used in a dense 3D NVM array. It is also a suitable candidate for computation-in-memory, neuromorphic computing and reconfigurable computing. However, the show stopping problem of RRAM is that it suffers from unique defects, which is the reason why RRAM is still not widely commercially adopted. These defects differ from those that appear in CMOS technology, due to the arbitrary nature of the forming process. They can not be detected by conventional tests and cause defective devices to go unnoticed. Therefore, new tests need to be developed that properly include the physics of a defective device in a RRAM model. Device-aware testing (DAT) is the state-of-the-art solution to this problem. By accounting for the unique physics of an RRAM device, DAT is able to detect unique RRAM defects. However, DAT bases its results on relatively compact electrical models, which do not account for randomness present in e.g. the forming of the filament and local temperature fluctuations. Meanwhile, many low-level physical models exist already that can model this randomness and provide accurate insights into the physical specifics of RRAM. These models do, however, hardly ever analyze the effects of defects. The contribution of this work is to expand and improve one of the state-of-the-art physical models to analyse manufacturing defects on a low, near atomic-level scale. For the first time, the characteristics of a defect can be described in the physical shape of the defect, rather than only the electrical consequences of a black box device. This enables deep level analysis and characterization of defects, the results of which improves DAT to detect even more unique defects. The model is applied to four types of RRAM-related defects: oxygen vacancy density fluctuation, oxide thickness variation, electrode roughness, and contamination by impurities. The effect of the defects on the conductivity of the device are observed and explained, and their unique non-linear behavior is confirmed by simulation. Dynamic defects are not yet included, but the model does provide an extensive static characterization of unique RRAM defects, providing insights into their behavior and improving the quality of DAT. Finally, a discussion is presented which criticizes the reproducability of the referenced defect-free model, but also shows the potential of this work's model to be improved.","RRAM; ReRAM; OxRAM; defects; macroscopic modelling; physical modelling; defect modelling","en","master thesis","","","","","","","","","","","","Computer Engineering","",""
"uuid:5312925b-f24a-4c9e-9691-0ee1499a3836","http://resolver.tudelft.nl/uuid:5312925b-f24a-4c9e-9691-0ee1499a3836","Betweenness: Tangible &amp; Intangible boundaries for formulating a complex estate landscape in Gelders Arcadie","Peng, Y. (TU Delft Architecture and the Built Environment)","de Wit, S.I. (mentor); Schoonderbeek, M.G.H. (mentor); Delft University of Technology (degree granting institution)","2020","Connection and separation, or synthesis and dissolution, to draw on Georg Simmel’s expression, are each the precondition of the other. It lightens me to rethink the core of boundary. In the estate landscape of Veluwe Zoom, the elites and noble use flowing water, shrubs, walls, fences to declare their own territory and maintain bridge, passage to connect. The past boundary in estate landscape is functional and programmatic. The current huge grey infrastructure for connecting disrupt the original estates landscape and became the insurmountable boundary. <br/>The estate landscape in the veluwe zoom of Netherlands have undergone a quite dramatic transformation from rural hinterland to residential suburb and some have been part of the larger urban landscape. The boundaries between the estates landscape and urban built area is shifting and changing and have threaten the protection of estate landscape. The future transformation of these unique estate landscape needs to be negotiated with the urbanization process and the ecology integration.The current boundaries system needs to take responsibility of the disconnectedness of estate ensemble, ecology corridor and disorderly urban sprawl. An explicit boundary could better ensure the quality and quantity of “void”, the landscape patch and corridor.<br/>The revitalization of estates landscape relies on the redefining of these boundaries. The transition and separation are understood as the inner concept of boundary. The function of separation will ensure the uniqueness of estate landscape and the transition echo to the land fragmentation which is one common issue of Europe urbanization process.","Estate landscape; boundary; Fragmentation; Heritage landscape; Urban sprawl","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences","Flowscapes Graduation Studio | Garden of Gelderland",""
"uuid:efa8dd54-ee76-4c48-ae7f-f12b10f74073","http://resolver.tudelft.nl/uuid:efa8dd54-ee76-4c48-ae7f-f12b10f74073","Distributed Model Predictive Control for Multi-Vehicle Autonomous Driving: Cooperative vs. Non-cooperative Control","Vermeer, R.F.T. (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Delft Center for Systems and Control; TU Delft DISC)","Grammatico, S. (mentor); Bianchi, M. (mentor); Dabiri, A. (graduation committee); Gonçalves Melo Pequito, S.D. (graduation committee); Delft University of Technology (degree granting institution)","2020","In this thesis, we consider the problem of controlling multiple autonomous vehicles in a highway scenario, via MPC. By iteratively solving a motion planning OCP, MPC is perfectly suited for unknown dynamic environments, while optimally computing path and vehicle inputs. Moreover, MPC can ensure the satisfaction of collision avoidance constraints, a prerequisite for safe automated driving. <br/><br/>The collision avoidance constraints render the OCP non-convex. This thesis tackles this non-convexity by either designing nonlinear MPC controllers, or by convexifying these non-convex constraints.<br/><br/>Moreover, control of a large, networked system of automated vehicles is achieved by designing local, subsystem-based controllers. We analyse three different algorithms to distribute the plantwide OCP. All controllers are subjected to an objective analysis and compared to see which is the most efficient and most practical to implement. Centralized MPC is used as benchmark, since this gives the plantwide optimal solution. The first decomposed algorithm is decentralized MPC, where subsystems communicate a single time every MPC iteration and compute their new trajectory based on the previously communicated trajectory of neighboring subsystems. The second method is based on sub-optimal cooperative distributed MPC. Here, vehicles perform multiple sub-optimal iterations of a Gauss-Jacobi type distributed optimization. For the last method, based on a Generalized Potential Game, the vehicles sequentially solve and communicate the solution of their local OCP in order to find an $\epsilon$-Nash Equilibrium. By relying on additional constraints or fixed ordering among vehicles, all three controllers are able to recursively feasible compute their own trajectory while avoiding other vehicles.<br/><br/>The distributed controllers are assessed in two different scenarios, using three different criteria, i.e., the overall effectiveness of the controller, the local effectiveness of the controller and the progress made, by each vehicle in the simulation. The first criteria gives an indication of the level of cooperation among vehicles, the second shows the individual satisfaction of each vehicle with respect to its reference, and the last represents the overall progress each vehicle has made in the highway simulation.","MPC; Distributed Control; Game Theory; Networked systems; Automated driving","en","master thesis","","","","","","","","2020-08-14","","","","Mechanical Engineering | Systems and Control","",""
"uuid:5a7175fd-3910-40d1-83e4-1a1be9e6a515","http://resolver.tudelft.nl/uuid:5a7175fd-3910-40d1-83e4-1a1be9e6a515","Oscillator based Analog-to-Digital Converter for Action Potential Readout in Microelectrode Arrays","Baladari, Nikhita (TU Delft Mechanical, Maritime and Materials Engineering)","Valente, V. (mentor); Serdijn, W.A. (graduation committee); Dekker, R. (graduation committee); Delft University of Technology (degree granting institution)","2020","The functioning of the brain depends on the interplay between a large number of neurons. To understand the information processing in neuronal networks, we need tools to record the electrical activity of cells at high resolution. Microelectrode arrays (MEAs) are predominantly used to measure neuronal activity<br/>at high spatial and temporal resolution. With the advent of complementary metal-oxide-semiconductor (CMOS) based MEAs, it has been possible to design high-density MEAs with electrode sizes comparable to that of the individual neurons, allowing sub-cellular resolution. CMOS technology has also facilitated the on-chip signal conditioning needed to record the low-amplitude bio-signals with superior signal quality. In this thesis, a readout architecture for in-vitro MEAs has been proposed for a low-noise extracellular action potential (AP) readout.<br/><br/>One of the challenges in MEA implementation is the design of thousands of low-noise readout channels for simultaneously recording the signals. There is a need to design low-noise ADCs with optimal power and area consumption. In this thesis, a unique low-noise oscillator based sigma-delta ADC has been designed for MEA applications. With the advantages of oversampling and time-encoding techniques, the in-band noise has been optimized, without increased hardware complexity. The simple implementation of this proposed ADC makes it efficient in terms of area and power consumption.<br/><br/>The integrated circuit for this oscillator based sigma-delta ADC has been implemented in 0.18 um CMOS technology to demonstrate the feasibility of high-order oscillator-based ADCs for low-noise extracellular AP readout. It was possible to obtain a noise below 5 uV<sub>RMS</sub> (simulations) and power consumption under 3 uW using this ADC, which approximately occupies an area of 0.002 mm<sup>2</sup>. The action potential readout system implemented with this ADC has been taped-out for further analysis through measurements.","Microelectrode arrays; Oscillator based ADC; Sigma-delta; Bioelectronics; Neuronal sensing; Active pixel sensor; CMOS","en","master thesis","","","","","","","","2022-12-31","","","","Biomedical Engineering | Bioelectronics","",""
"uuid:7c829bb9-84c1-46af-8c4d-b70501728880","http://resolver.tudelft.nl/uuid:7c829bb9-84c1-46af-8c4d-b70501728880","Improvement of impulse voltage distribution of transformer windings","Zhao, Weichuan (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Electrical Sustainable Energy)","Ghaffarian Niasar, M. (mentor); Vaessen, P.T.M. (mentor); Delft University of Technology (degree granting institution)","2020","With the aid of the analytical formulas of the disc pair model inter-shielded by different type of shield wires, the total series capacitance of the disc pair could be calculated. After introducing a number of inter-shield pairs to the disc pair model, the influence on the mutual inductance between discs has been thoroughly discussed. Last but no least, after comparing the figures for the voltage response distribution among different configurations and different type of inter-shield pairs, the case which could contribute to the best voltage response performance is selected.","voltage response distribution; inter-shielding methods; turninterleaving methods; improvement factor; decrease factor; disc series capacitance; mutual inductance; lightning overvoltages; eddy currents; fringing effect; skin effect","en","master thesis","","","","","","","","2022-12-31","","","","","",""
"uuid:2be87866-e368-401c-93a0-01c37efe69ad","http://resolver.tudelft.nl/uuid:2be87866-e368-401c-93a0-01c37efe69ad","Effect of High Frequency Harmonics on High Voltage Insulation","Seshadri, Shruti (TU Delft Electrical Engineering, Mathematics and Computer Science)","Vaessen, P.T.M. (mentor); Ghaffarian Niasar, M. (mentor); Delft University of Technology (degree granting institution)","2020","","","en","master thesis","","","","","","","","2022-12-31","","","","","",""
"uuid:ede8ac6f-bf3e-4233-80c4-5f63add30cac","http://resolver.tudelft.nl/uuid:ede8ac6f-bf3e-4233-80c4-5f63add30cac","Mitigation of Silica Scaling by Closed-Circuit Reverse Osmosis","Flambouris, Stelios (TU Delft Civil Engineering and Geosciences)","Heijman, Sebastiaan (mentor); Spanjers, H. (graduation committee); Sudhölter, Ernst J. R. (graduation committee); Delft University of Technology (degree granting institution)","2020","Reverse osmosis (RO) is considered the most reliable and cost-effective membrane desalination technologyworldwide. However, it suffers significant performance limitations due to mainly inorganic foulinggenerated in the highly concentrated brine. Especially, scaling caused by silica and silicates depositionsresults in irreversible damages with considerable economic implications. Recently, a different ROconfiguration, termed as closed-circuit reverse osmosis (CCRO), has been claimed to exhibit substantialbenefits over conventional RO in terms of both energy savings as well as higher scaling resilience.CCRO is operated in batches, during which the generated brine is continuously recycled inside theclosed loop until a desired recovery has been accomplished, after which the brine is released and replacedby fresh feed. Regarding CCRO scaling resistance superiority, an experimental-based proofis missing from the relevant literature. The current thesis was realized in collaboration with LenntechB.V., aiming at investigating the intrinsic propensity of CCRO to withstand and delay silica scaling. Tothat end, a campaign of filtration tests was carried out by means of a single-module CCRO pilot setup,during which two scaling indicators were periodically monitored. The used indicators were the masstransfer coefficient (MTC) and the applied feed pressure (Pfeed). Prior to the filtration trials, preliminarybatch tests, of 4-hour duration each, were carried out in order to simulate and more thoroughly examinethe circulated brine conditions. Various synthetic brines were prepared and silica polymerization wasmonitored. The effects of silica supersaturation level, pH and hardness ions were investigated. Of greatimportance was whether silica existed in its monomeric or polymeric form, since this greatly impactsthe scaling occurrence probability. Batch tests results revealed that at high pH conditions (pH&gt;10)monomeric silica concentration remained unchanged in pure silica solutions (even at high supersaturationlevels), owing to the great silica solubility level. Nevertheless, when Mg2+ and/or Ca2+ werepresent in the solution, the quantity of silicic acid rapidly reduced. This was the result of the instantaneousformation of metal-silicate precipitates. Batch tests at pH 7 were also performed. In that case,monomeric silica concentration in pure silica solutions remained constant up to initial concentrations ofabout 450 mg/L SiO2 for the examined 4-hour duration. However, at higher SiO2 concentrations, suchas at 750 mg/L, rapid polymerization occurred. When hardness cations were included in the neutral pHsolutions, they showed an accelerating effect on silica polymerization process, but they did not reactwith either monomeric or polymeric silica. This effect relates to the suppression of the silica colloidsdiffuse double layer by the hardness cations, which subsequently facilitates colloids agglomeration.Regarding the CCRO filtration tests, they were conducted in sequences with duration of 20 or 40 min,which in its turn determined the achieved sequence recovery. For most of the carried out sequencesthe initial feed composition was: 120 mg/L SiO2 and 24 mg/L Mg2+. Only the final 5 out of the total40 sequences were realized in the absence of magnesium in the feed solution. All the filtration runswere performed at pH 7, at ambient temperature and at constant flux 15 L/m2h. The outcome was ascaling-free desalination process for a total cumulative operational period of approximately 11 hours,during which recoveries as high as 90.9% were reached, whereas severe scaling took place only afterabout 14 hours of total operation. The obtained results were contrasted with filtration tests results ofconventional RO received from literature resources and in that way the higher efficiency of CCRO towithstand and delay silica scaling was proved. Additionally, through silica mass balance calculations itwas shown that during all filtration tests significant silica polymerization took place. Also, cations analysisbe means of IC excluded the participation of Mg2+ ions in the formed scale layer. It was concludedthat the scale development was the result of an initial attachment of silica colloids to the membranesurface followed by monomeric units adsorption onto them. Finally, a simple customized method forthe prediction of silica scaling potential in CCRO operations based on batch tests was proposed.","CCRO; silica scaling; reverse osmosis; pilot-scale; brine","en","master thesis","","","","","","","","2022-08-28","","","","Civil Engineering | Environmental Engineering","",""
"uuid:a3eebd7b-1214-4e2e-8b80-032f273a399f","http://resolver.tudelft.nl/uuid:a3eebd7b-1214-4e2e-8b80-032f273a399f","The effects of country wealth on the energy mix","Konings, Daan (TU Delft Electrical Engineering, Mathematics and Computer Science)","Geerlings, J.J.C. (mentor); Akkerhuis, Thomas (mentor); van Cranenburgh, S. (graduation committee); Herder, P.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","The total investments in the global energy system amounted to 1.85 trillion in 2018 [1]. Globally over 400 exajoule [2] was provided to energy consumers. The energy consumption is closely related to the emission of green house gasses [3] [4] [5]. In the Kyoto and Paris agreements the international community formalized the intention to reduce the emission of green house gasses in an effort to mitigate global warming [6] [7]. Economic progress has long been linked to increased energy consumption [8] [9]. Mitigation of green house gasses whilst facilitating economic growth poses one of the major challenge of the twenty first century [10] [11]. Development of climate policy and business strategy that facilitates both the mitigation of global warming and economic growth requires understanding of the energy market. In an effort to expand the understanding of the energy market we examine the historic effects of a country’s wealth on the country’s energy mix by applying a multinomial logit choice model for energy carriers to various sectors on a global scale. We find evidence for ordered wealth effects in sector categories Heavy Industry, Agriculture &amp; Other Industry, Passenger Transport Rail, Freight Transport Rail, Residential Heating &amp; Cooking, and Services.","Energy; Energy Mix; Wealth Effects; Country Wealth; Energy Consumption; Energy carriers","en","master thesis","","","","","","","","2022-08-28","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:356fa133-49a2-435e-b7cc-5ff6059d3d8b","http://resolver.tudelft.nl/uuid:356fa133-49a2-435e-b7cc-5ff6059d3d8b","Development of radar-based vital sign detection and indoor target localization algorithms","Wan, Lin (TU Delft Electrical Engineering, Mathematics and Computer Science)","Yarovoy, Alexander (mentor); Fioranelli, F. (mentor); Mercuri, Marco (mentor); Varon, Carolina (graduation committee); Delft University of Technology (degree granting institution)","2020","In the last two decades, radar-based contactless vital signs monitoring (heartbeat and respiration rate) has raised increasing interest as an emerging approach for healthcare and complementary for other more established technologies. Heartbeat and respiration induce only very subtle rhythmic changes in the reflected radar signature, whereas the signals reflected by larger objects in real scenarios and even themovements of body parts of the subjects being monitored are typically larger. Radar reflection paths are multiple and often vary strongly, especially indoors. It is therefore extremely challenging to determine the correct number of targets and to perform concurrent localization and reliable vital signs monitoring on multiple people in real-world environments. The multipaths (ghost signals) from the reflected signal of one individual, combine with the reflected signals and multipaths of other subjects and with clutter, jeopardizing individual vital signs extraction and localization. The main research activities in this thesis aimed to extend the work of a previous master thesis from SISO (single input single output) radar to a SIMO (single input multiple output) radar framework. The core idea is that the usage of multiple receiver channels that SIMO radar provides can enable an additional degree of freedom (the estimation of the angular position) to distinguish real targets from ghost targets due to multipath, hence improving their rejection and cancellation. Simulation results are then generated to compare SISO and SIMO frameworks for recognition of the number of subjects in a given environment, for their localisation, and for the estimation of their vital signs. Unfortunately, due to access limitation caused by the COVID-19 pandemic to the offices of IMEC, Eindhoven, where this thesis work was mostly performed, the initially planned experimental validation with SIMO radar was not possible to perform.","FMCW radars; Vital signs; Multipath effect; Localization; SVD","en","master thesis","","","","","","","","2022-08-28","","","","Electrical Engineering","",""
"uuid:003440ce-7b38-473b-b224-0d0a0513f26a","http://resolver.tudelft.nl/uuid:003440ce-7b38-473b-b224-0d0a0513f26a","Single Electron Readout Circuit: SERCuit","Al Disi, Matthew (TU Delft Electrical Engineering, Mathematics and Computer Science)","Fan, Q. (mentor); Nihtianova, S. (mentor); Delft University of Technology (degree granting institution)","2020","Particle detection circuits are used for a wide range of applications from experimental physics to material testing and medical imaging. State-of-the-art imaging systems demand the detection of small amounts of charge with small time-resolution and limited power consumption, creating an implementation dead-end for the typical readout topology. In this thesis, a particle detection readout based on an intersymbol interference cancellation scheme is introduced to address this issue. Evaluated in post-layout simulations, the proposed architecture can detect generated charge as small as 160 aC with 97.8 % certainty. The readout can operate with event-rates up to 400 MEvent/s while only consuming<br/>2.85 mW of power.","","en","master thesis","","","","","","","","2022-08-28","","","","","",""
"uuid:164d7900-ef53-4347-be1d-7cd81ed5bc1d","http://resolver.tudelft.nl/uuid:164d7900-ef53-4347-be1d-7cd81ed5bc1d","Material Recovery from Dutch Wind Energy: A dynamic material flow analysis on Dutch wind turbines towards 2050 including recycling approaches for recovery of key materials","Roelofs, Bas (TU Delft Technology, Policy and Management; TNO Energy Transition, Petten)","van der Voet, Ester (mentor); Yang, Y. (graduation committee); Delft University of Technology (degree granting institution); Universiteit Leiden (degree granting institution)","2020","The transition to a renewable electricity system requires more intensive material use, causing problem shifting in environmental impacts. To conserve resources for the future and mitigate environmental impact, circular economy principles are needed. This study analyses material flows in Dutch wind energy towards 2050 to identify the potential for material recovery. This reveals material demand, stock, secondary material supply and required recycling infrastructure within environmental and economic context. Material compositions, current stock and future installed capacity result in inflow, stock and outflow of materials in Dutch wind energy. Inflows or demand for materials is increasing rapidly due to strong expected growth in the near future (2023), additional inflows are required after 2030 for stock maintenance. Outflows fluctuate, partly due to an early peak in onshore decommissioning and late peak in offshore decommissioning caused by a more mature stock of onshore wind turbines and currently developing stock of offshore wind turbines. The outflow of scrap materials is used to determine secondary materials through various recycling routes. For steel, iron, aluminium and copper minor processing losses occur as materials oxidize or get lost to slag. Due to partial removal of monopiles, a hibernating stock is expected for structural steel that increases towards 0.5 Mt in 2050. Current steel and iron recycling results in dilution and therefore loss of function of valuable and critical alloying elements. Composite waste management in wind energy is a major challenge as closed-loop recycling of composites is not feasible. The cascading effect of material quality results in low-value materials, with varying potential demand. Repurposing of blade segments requires minimal processing and could be implemented at present, provided that there is enough demand for composite sheet and beam segments. Cement co-processing uses existing cement production infrastructure and could be implemented at present, with ample demand for cement clinker. Dutch wind energy could exclusively provide sufficient composite scrap material to run industrial-scale mechanical grinding after 2030 and pyrolysis facilities after 2040. Critical materials include vanadium in gear steel alloys, magnesium in cast iron and rare earth elements in permanent magnets. These critical materials are subject to high economic importance and supply risk. Secondary supply through recycling can mitigate this criticality. Vanadium in gearbox steel and magnesium in cast iron can be functionally recycled by selective collection within existing recycling infrastructure for specialty steels. It is estimated that with maximum recycling efforts, secondary supply of critical materials can meet up to ~15% of REE, ~30 of V and ~25% of Mg demand by 2050. Dutch wind energy will not provide sufficient scrap magnet material for an industrial size recycling facility dedicated to magnet or REE recovery before 2050. <br/>By determining the potential for material recovery from Dutch wind energy, a timeline is created for potential implementation of domestic recycling and secondary material availability. This is a first step towards circularity goals in 2050 and is intended to provide a sense of scale and timing for material demand, secondary supply and required recycling infrastructure for Dutch wind energy.","Material Flow Analysis; MFA; Wind Energy; Material recovery; Recycling; Composites; Wind Turbine; Blade; Dynamic material flow analysis; Circular; Circular Economy; Circulaire economie; Materiaalstroom analyse; Windmolen","en","master thesis","","","","","","","","","","","","Industrial Ecology","",""
"uuid:8c8fa515-cd5f-4766-8659-20ef8a436928","http://resolver.tudelft.nl/uuid:8c8fa515-cd5f-4766-8659-20ef8a436928","Validation of 3D-printed guidance systems for genioplasties in orthognathic surgery: A retrospective validation study &amp; preparation for a multicenter intervention study","Sabelis, Juliana (TU Delft Mechanical, Maritime and Materials Engineering)","Dankelman, J. (mentor); Becking, A.G. (mentor); Maal, T.J.J. (mentor); van Riet, T.C.T. (mentor); Schreurs, R. (mentor); Delft University of Technology (degree granting institution); Universiteit Leiden (degree granting institution); Erasmus Universiteit Rotterdam (degree granting institution)","2020","class=""MsoNormal"" style=""margin: 0cm 0cm 3pt; line-height: 16.8667px; font-size: 11pt; font-family: Calibri, sans-serif;"">A chin deformity does not rarely accompany dentofacial deformities. A correction of the chin (genioplasty) is sometimes indicated in addition to orthognathic surgery. Computer-assisted surgery allows virtual planning in orthognathic surgery in three-dimensions (3D). The virtually planned movements will be transferred to the patients through 3D-printed devices, such as occlusal splints for the maxillomandibular complex. Computer-assisted surgery also enables the evaluation and quantification of the surgical result in 3D, through comparison of the virtual surgical planning and postoperative imaging. The OrthoGnathicAnalyser is a software tool that enables semi-automatic quantification of the surgical result for repositioning of the mandible, maxilla and rami in orthognathic surgery. The goal of this master thesis was to validate the application of 3D-printed guidance systems for the execution of genioplasties in the context of orthognathic surgery with a new version of OrthoGnathicAnalyser.</p><p class=""MsoNormal"" style=""margin: 6pt 0cm 3pt; line-height: 16.8667px; font-size: 11pt; font-family: Calibri, sans-serif;""><br/></p><p class=""MsoNormal"" style=""margin: 6pt 0cm 3pt; line-height: 16.8667px; font-size: 11pt; font-family: Calibri, sans-serif;"">A new version of OrthoGnathicAnalyser was developed, to allow for analysis of the genioplasty. The effect of two factors (calculation of chin analysis and registration technique) on the precision and accuracy has been evaluated. This has led to two important conclusions which are implemented in the software: 1) The difference between the postoperative chin and the planned chin with respect to the realized mandible (instead of the planned mandible) should be calculated, to isolate the mandibular positioning error from the chin error. 2) Surface-based matching resulted in more accurate pitch values and was therefore implemented in the newest version.<i/></p><p class=""MsoNormal"" style=""margin: 0cm 0cm 6pt; line-height: 16.8667px; font-size: 11pt; font-family: Calibri, sans-serif;"">To present and validate the newly developed software, a multicenter study was executed. A total of 25 patients were included in the study. The inter-observer and intra-observer reliability were evaluated. It was concluded that the reported results demonstrated an excellent reproducibility (ICC &gt;0.92) of the quantification of the skeletal movements between two image sets by the OrthoGnathicAnalyser 2.0. By implementing the chin analysis in the software tool, the complete orthognathic surgery result could be quantified and compared to the virtual plan. The results of this study will be submitted to a scientific journal. </p><p class=""MsoNormal"" style=""margin: 0cm 0cm 3pt; line-height: 16.8667px; font-size: 11pt; font-family: Calibri, sans-serif;""><br/></p><p class=""MsoNormal"" style=""margin: 0cm 0cm 3pt; line-height: 16.8667px; font-size: 11pt; font-family: Calibri, sans-serif;"">To validate the 3D-printed guidance system for genioplasties, a multicenter randomized controlled intervention study was initiated. To acquire ethical approval of the local ethics committee, extensive preparations were required. Approval to start the study has been acquired within this graduation project and patient inclusion will start when COVID-19 circumstances allow continuation of clinical studies and regular patient care.</p><p class=""MsoNormal"" style=""margin: 6pt 0cm 3pt; line-height: 16.8667px; font-size: 11pt; font-family: Calibri, sans-serif;""><br/></p><p class=""MsoNormal"" style=""margin: 0cm; line-height: 16.8667px; font-size: 11pt; font-family: Calibri, sans-serif;"">To validate 3D-printed guidance systems for the execution of genioplasties different projects were undertaken. A new version of the OrthoGnathicAnalyser was developed and validated. Advantageous of the OrthoGnathicAnalyser 2.0 was the implementation of the chin analysis, independence on any planning software and reduced manual input. Possible improvements were the implementation of automatic 3D landmarking and adapting the voxel-based matching algorithm to allow exclusion of the fixation material. A multicenter intervention study to evaluate the accuracy of the 3D-printed guidance system for genioplasties with the newly developed software was initiated. This study will enable a definitive conclusion about the effect of the 3D-printed guidance system on the accuracy of chin repositioning.","3D Printing; Orthognathic surgery; Quantification; patient specific implant; surgical instrument","en","master thesis","","","","","","","","","","","","","",""
"uuid:548f6026-768a-48ab-8abf-eca47ceb4912","http://resolver.tudelft.nl/uuid:548f6026-768a-48ab-8abf-eca47ceb4912","User Plane Optimization in a 5G Radio Access Network","Aguwamba, Chinedu (TU Delft Electrical Engineering, Mathematics and Computer Science)","Noldus, R.A.C.J. (mentor); Raftopoulou, M. (graduation committee); Delft University of Technology (degree granting institution)","2020","5G as a future network is expected to be commercially deployed in 2020 and beyond. At the present time facilitated by industry need, the deployment option is to introduce 5G base stations alongside the existing 4G base stations in order to expedite 5G deployment. This deployment option is what presently is referred to as the Non-Standalone Architecture (NSA). To fully unlock the 5G potential such as enhanced end-user experience, service agility, Ultra Reliable Low Latency Communications (URLLC), improved network capabilities, critical Internet of Things (IoT) and industrial automation use cases, it becomes imperative to deploy a full 5G architecture with its own New Radio (NR) access and 5G Core Network (5GCN).<br/>The goal of the thesis is to design a 5G standalone architecture that leverages on the principle of Control and User Plane Separation (CUPS) to be introduced in the 5G Radio Access Network (RAN). Such separation enables scaling of each plane’s resources and also allows for a flexible deployment of the architecture as chosen by the Mobile Network Operator (MNO). To this effect the New Radio-New Radio (NR-NR) architecture is introduced which makes use of two 5G base stations such that a user can connect simultaneously to the two base stations in what is called Dual Connectivity (DC). One base station, which is referred as the Next Generation NodeB (gNB-CP), specifically handles all the Control Plane (CP) signalling in the RAN and the second base station, called gNB-UP, is dedicated specifically to handle User Plane (UP) traffic. To investigate how the new architecture handles control signalling and optimizes the UP as a result of decoupling the UP functions from CP signalling, IP Multimedia Subsystem (IMS)-based voice telephony, that is voice call made over a 5G network specifically called Voice over New Radio (VoNR), is chosen as an application and two distinct use cases are considered. The first use case is to investigate through signalling messages how the proposed architecture handles control signalling for setting up a VoNR call. The second use case is to investigate through signalling messages and data flow path how user mobility and handover procedures are handled during an ongoing VoNR call. Finally, a comparative study was conducted with the NSA.<br/>From the results obtained and from the comparative study conducted, it is shown that the NR-NR architecture decouples the UP functions from CP signalling. For handover procedures in the NR-NR architecture involving a VoNR call, the gNB-CP initiates and handles all control signalling while maintaining the VoNR call, which allows for the direct forwarding of a voice call from the serving gNB-UP to the target gNB-UP. This handover procedure eliminates any interruption of the ongoing voice call. Finally, we foresee there is a possibility of increased signalling load in the NR-NR architecture proposed because proper co-ordination is needed between a gNB-CP and a gNB-UP to ensure optimal network functionality when compared to the NR architecture which uses a single 5G base station.<br","Control and User plane separation","en","master thesis","","","","","","","","","","","","Electrical Engineering | Embedded Systems","",""
"uuid:1bc598be-87bb-4c31-9938-7b5022d4866e","http://resolver.tudelft.nl/uuid:1bc598be-87bb-4c31-9938-7b5022d4866e","Real Estate Development in a Circular Built Environment: A research what the current and future role of the real estate development process is in delivering circularity in the built environment","Habekotté, Jordi (TU Delft Architecture and the Built Environment)","Chan, P.W.C. (mentor); Luoma, Tuuli (graduation committee); Delft University of Technology (degree granting institution)","2020","The built environment is a major polluter of the environment and a significant contributor to carbon emissions. It is responsible for more than half of the world’s raw resource extraction. After a review of 337 previous studies on circularity in the built environment, 40 have been identified useful for the study. The literature is organised in five key themes: circular strategies, circular business models, management reporting systems, organising systems in construction practice and the resource processing. However, while the literature seems to be focused on questions surrounding the five themes, the real estate development process is underrepresented. Hence the research question this research paper focuses on is: What is the current and future role of the real estate development process in delivering circularity in the built environment? By conducting interviews with various practitioners engaged in circular real estate development processes, current practices and future aspirations have been identified. Additionally, barriers have been identified and analysed. The thesis ends with a proposed circular real estate development process, harbouring flexibility in the construction phase, mitigation regarding government regulations, a changed value proposition for materials, involvement of stakeholders with the same, open mind set and the use of material passports in the design, construction, exploitation and end of life phase.","circular economy; real estate development process; built environment; barriers; current practice; future aspirations","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Management in the Built Environment","",""
"uuid:8c431757-23ca-447f-ac88-bd857305b574","http://resolver.tudelft.nl/uuid:8c431757-23ca-447f-ac88-bd857305b574","Dynamic Time-Division Multiple Access in Noisy Intermediate-Scale Quantum Networks","Skrzypczyk, Matthew (TU Delft Electrical Engineering, Mathematics and Computer Science)","Wehner, S.D.C. (mentor); Delft University of Technology (degree granting institution)","2020","Quantum networks are networks composed of quantum processors that facilitate the exchange of information in the form of quantum bits, also called qubits. Qubits observe a physical phenomenon known as entanglement that enables the transmission of quantum information over long distances as well as the realization of novel protocols and applications that are impossible in classical networks such as the Internet. Due to the limitations of state of the art Noisy Intermediate-Scale Quantum (NISQ) devices, the establishment of entanglement over multi-hop networks demands strict coordination among the network nodes that connect two hosts. The delivery of entanglement in multi-hop quantum networks is further complicated when the network must support Quality of Service requirements for multiple users at the same time. The main challenges are ensuring that connected quantum processors agree when to establish entanglement with their neighbors and that processors use the correct pieces of entanglement to connect source/destination pairs. In this thesis, we propose a novel dynamic time-division multiple access (TDMA) method for multiplexing network resources used to connect multiple users in quantum networks. We investigate the behavior of scheduling heuristics in constructing the TDMA schedules and the effects of resource allocation on network performance. We additionally propose a novel scheduling problem and heuristic based on limited preemption that improves achievable network throughput in the case that devices may tolerate interruptions during connection of users.","quantum network; scheduling; RCPSP","en","master thesis","","","","","","","","2021-12-28","","","","","",""
"uuid:7c7fd8e6-df73-4eb7-81f5-c26c96cbce26","http://resolver.tudelft.nl/uuid:7c7fd8e6-df73-4eb7-81f5-c26c96cbce26","Paving the Way for Automobili Pininfarina Brand Success: Brand Vision 2025","Moll, Jordy (TU Delft Industrial Design Engineering)","van Grondelle, E.D. (mentor); Brand-de Groot, S.C.M. (graduation committee); Connell, D. (graduation committee); Delft University of Technology (degree granting institution)","2020","Success doesn’t come by following the beaten track, by following in the footsteps of the great visionaries of the past. No, success comes to those who dare to think differently, who dare to challenge and to do the unexpected. Starting a new brand requires this mindset, because only those who dare to think differently succeed. Back in 2018, Automobili Pininfarina was founded as a new luxury car manufacturer bearing one of the most celebrated and revered names in the industry: Pininfarina. A design house known for their iconic masterpieces. Starting a new brand with such a famous and recognizable name is a beautiful opportunity, but also a risky operation. Paving the way for Automobili Pininfarina brand success, that was the goal of this thesis done in collaboration with the new Italian luxury car manufacturer. A new brand strategy and vision needed to be developed, hence the brief for this project was as follows: “Create a design driven brand strategy, delivering a brand vision for the year 2025.” This graduation project focused on analyzing the company’s existing brand strategy and compares that with external influences that create opportunities for the brand to grow. The synthesis of this is a brand vision for the year 2025. Based on this vision, a proposal for the visual identity of the new brand strategy is made, including a roll-out plan for implementation and further development. The steps provided are forming the roadmap that paves the way for Automobili Pininfarina brand success.","Branding; Brand Strategy; Design Strategy; Automotive; Strategic Design","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:85911308-c453-4970-bcf7-512e51469a2d","http://resolver.tudelft.nl/uuid:85911308-c453-4970-bcf7-512e51469a2d","Explore embodied interactions to help people reduce worries and improve their well-being: Design for worrying","Long, J. (TU Delft Industrial Design Engineering)","Rozendaal, M.C. (mentor); Vroon, J.H. (mentor); van Beek, E. (mentor); Delft University of Technology (degree granting institution)","2020","Many people experience worry once in a while. Chronic worry can have a severe impact on people's daily life. Many things, like health conditions, social relationships, sleep quality, and work performance, are all influenced by worrying [Joseph 2017]. So, this is something we would like to address. This assignment aims to explore embodied interactions to help people reduce worries and improve their well-being. To understand what people are worried about, how they start worrying, and what people do when worrying, I designed a culture probe, with wristband, stickers, and reports. The culture probe aims to capture the moment when the users are worrying. There were 16 participants in this research, providing 90 worry reports[Appendix-2]. From the analysis of culture probe, I narrowed the scope into the design goals: Monitor people's worry level, relieve people's negative feelings, remind people who are stuck in the negative feelings and distract people when they perceive low controllability. After that, I did competitive research about mental health Apps and therapeutic robots on the market. This research is to analyze the interactions they provide, why they work/do not work. Combining with literature reviews, I came up with the interaction vision describing how the interaction should be. The most essential visions are Inviting, subtle&amp; natural, socially autonomous, and meaningful. Then, in the ideation phase, I did two brainstorming sessions to explore interactions to relieve people's negative feelings, how to detect their worrying feelings and how to make the interaction intuitively relate to the worries. There were also two evaluation sessions in the ideation phase, which helped me develop the ideas into three concepts. In the conceptualization phase, I developed three concepts further and arranged a peer evaluation session to determine the final concept, the zen stone concept. Then I did a low-fi prototype test to find out it the idea fits the design goal &amp; interaction vision. The result was very promising; the interaction helped the user to relieve their negative feelings. So I decided to develop the concept further with an App providing guidance. Then I arranged the final usability test and iterated the concept with some details. The final design's name is Zen stone. It can recognize the user's emotions with emotion recognition by speech software and remind the user when they are worrying, though shining and vibrating. The zen stone will mimic the user's heart rate through a sensor, helping the user be aware of their mental state. It will also provide meditation guidance to help to user calm down and focus on the moment.","Worry; Mental health; Interactions","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:57b46e24-10e2-4ca0-a5ed-d12a70ce251b","http://resolver.tudelft.nl/uuid:57b46e24-10e2-4ca0-a5ed-d12a70ce251b","Persistent Architecture","Kloeg, L. (TU Delft Architecture and the Built Environment)","Koorstra, P.A. (mentor); van der Zaag, E.J. (mentor); Spoormans, L.G.K. (mentor); Delft University of Technology (degree granting institution)","2020","Since the dawn of the early twentieth century, there has been a strong emphasis in the architectural discourse on defining an idea of how a building is intended to be used. This has resulted in a tendency in contemporary architectural practice of capturing the use of a building in a strictly defined programme. This programme is an illusion however: the ‘use’ of a building is not something which is definitive, but instead organic. In modern society, demands of users and owners constantly change. A building defined by its programme will lose its raison d’etre and in some cases ends up being demolished. This practice is not by any means sustainable, as it is a waste of resources and capital. Moreover, these continuous acts of building and demolishing also negatively impact the development of a consistent urban form: if architectural elements survive a few generations, they become more organic and picturesque. The architecture becomes embedded in the context and defines its identity.<br/>The project questions the relation between the building and its use. The research investigates a series of buildings which have accommodated multiple functions throughout their existence. The findings of this research were implemented and tested in an architectural project in the Vierhavens-area in Rotterdam. The main objective of the project was to produce a building that can accommodate a range of uses: a framework which offers possibility for adjustments and which can be reinterpreted by its users. A structure changing over time, embedded in its context, lived instead of consumed. Sustainable by its longevity. <br/>The project questions the relation between the building and its use. The research investigates a series of buildings which have accommodated multiple functions throughout their existence. The findings of this research were implemented and tested in an architectural project in the Vierhavens-area in Rotterdam. The main objective of the project was to produce a building that can accommodate a range of uses: a framework which offers possibility for adjustments and which can be reinterpreted by its users. A structure changing over time, embedded in its context, lived instead of consumed. Sustainable by its longevity.","Rotterdam; Adaptive re-use; Sustainabilty; Framework; Flexibility; Function; Polyvalence; Programme","en","master thesis","","","","","","","","","","","","","","51.908022, 4.430032"
"uuid:4c0eecd7-28e1-46c4-a82a-b43e339923ba","http://resolver.tudelft.nl/uuid:4c0eecd7-28e1-46c4-a82a-b43e339923ba","Implementing textile pressure sensor into car seats","Ma, Yixuan (TU Delft Industrial Design Engineering)","Jansen, K.M.B. (mentor); Buso, A. (graduation committee); Delft University of Technology (degree granting institution)","2020","The smart textile technology shows its strength in seamlessly merges the electrodes within the soft fabric. The textile pressure sensor has been used in many types of research for sensing pressure distribution. However, the existing sensors are not made for daily use. Sensors like the XSENSOR have a high price and contains plastic films, making it not breathable and not friendly for the skin. A sensor made entirely out of fabric is desirable. According to research (Techtextil, 2015), the car has around 30 kilograms of textiles. This project aims to show a new design using smart textile technology - the fabric pressure sensor. This project considers two aspects: 1. Technical aspect- Learn the sensing principle and sensor structure from literature. Make the textile sensor work. If possible, make the sensor work under the automotive context. 2. Societal aspect- Identify user needs. Determine where and how to use this new technology. Design around the sensor and make the data output fulfill the demands of the user. The design approach is the co-evolution model. Five design phases are included based on the basic design cycle- Analysis, preliminary tests, synthesis, embodiment, and evaluation. In general, this project sets the start of the implementation of the textile pressure sensor in the car. The project starts with technology in researches and reached the level of a working prototype validated in the laboratory.","Smart textile","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:a048e431-4659-4ac5-816d-eeb9e0f654f8","http://resolver.tudelft.nl/uuid:a048e431-4659-4ac5-816d-eeb9e0f654f8","Frequency-Domain Modelling of Reset Control Systems using an Impulsive Description","Buitenhuis, R.N. (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Mechatronic Systems Design; TU Delft Delft Center for Systems and Control)","Hossein Nia Kani, S.H. (mentor); Saikumar, Niranjan (graduation committee); Verhaegen, M.H.G. (mentor); Kok, Manon (graduation committee); Delft University of Technology (degree granting institution)","2020","The ever-increasing industry desire for improved performance makes linear controller design run into its fundamental limitations. A nonlinear controller, such as Reset Control (RC), is needed to overcome these. RC is promising since, unlike other nonlinear methods, it easily integrates into the PID design framework preferred by industry. Thus far, closed-loop behaviour of RC has been analysed in the frequency domain either through Describing Function analysis or by direct closed-loop numerical computation. The former method computes a simplified closed-loop RC response by ignoring all harmonics, an approach which literature has found to inflict significant modelling errors. The latter method gives an accurate solution but does not provide understanding of how open-loop RC design affects closed-loop performance. No methods link these aspects, which impairs RC design and tuning. The main contribution of this work is aimed at providing this link, while achieving an accurate closed-loop RC model. A novel approach for modelling RC is considered, which uses state-dependent impulse inputs. This approach is shown to permit an accurate computation of closed-loop RC behaviour starting from an open-loop model, thus linking both aspects, enhancing system understanding. A frequency-domain description for closed-loop RC is obtained, as needed for the PID design framework, which is solved for analytically by inserting several well-defined assumptions. This solution is verified using a simulated high-precision stage, critically examining sources of modelling errors. The accuracy of the proposed method is further substantiated using controllers designed for various specifications.","Reset Control; Closed-Loop; Nonlinear Control; Impulsive Modelling; Describing Function; Frequency Domain; Precision Control; Mechatronics; Motion Control","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:d6d50861-86a3-4dd3-a13f-42d84db7af66","http://resolver.tudelft.nl/uuid:d6d50861-86a3-4dd3-a13f-42d84db7af66","Capelin: Fast Data-Driven Capacity Planning for Cloud Datacenters","Andreadis, G. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Iosup, A. (mentor); van Beek, V.S. (mentor); Epema, D.H.J. (graduation committee); Gousios, G. (graduation committee); Erkin, Z. (graduation committee); Delft University of Technology (degree granting institution)","2020","Cloud datacenters provide a backbone to our digital society. Crucial to meeting increasing demand while maintaining efficient operation is the activity of capacity planning. Inaccurate capacity planning for cloud datacenters can lead to significant performance degradation, denser targets for failure, and unsustainable energy consumption. Although this activity is core to improving cloud infrastructure, relatively few comprehensive approaches and support tools exist, leaving many planners with merely rule-of-thumb judgement.<br/><br/>We propose Capelin, a data-driven, scenario-based capacity planning system for cloud datacenters. We design Capelin to address requirements we have derived from a unique survey of experts in charge of diverse datacenters in several countries. Capelin introduces the notion of portfolios of scenarios, which it leverages in its probing for alternative capacity-plans. At the core of the system, a trace-based, discrete-event simulator enables the exploration of different possible topologies, with support for scaling the volume, variety, and velocity of resources, and for horizontal (scale-out) and vertical (scale-up) scaling. The approach centers around a notion of portfolios of scenarios as a framework for probing alternative decisions and courses of events. Capelin gives detailed quantitative operational information for each scenario, which could facilitate human decisions in capacity planning.<br/><br/>We implement and open-source Capelin, and show through comprehensive trace-based experiments it can aid practitioners. Although Capelin is designed to work across many kinds of datacenters, in this work we focus on private-cloud, business-critical workloads, and on public-cloud operations. The results give evidence that choices that seem reasonable and common in practice could be worse by a factor of 1.5-2.0 than the best, in terms of performance degradation or energy consumption. We also show evidence of Capelin identifying meaningful choices that are different from the baseline proposed by a team of professional datacenter engineers. We open-source Capelin and release data artifacts for public inspection and reuse.","capacity planning; cloud; datacenter; data-driven","en","master thesis","","","","","","Public dataset on Zenodo containing the results of the systematic literature survey in this work (Chapter 3): https://zenodo.org/record/3989102","","","","","","","",""
"uuid:228aaffe-b730-4175-b880-70e14ff4cd87","http://resolver.tudelft.nl/uuid:228aaffe-b730-4175-b880-70e14ff4cd87","Homogeneous detached composite breakwater: CFD study of the design sensitivities in the 2D geometrical layout using a detached homogeneous low-crested structure to reduce sea wall overtopping","Jonker, R.G. (TU Delft Civil Engineering and Geosciences; TU Delft Hydraulic Engineering)","Antonini, A. (mentor); Hofland, B. (graduation committee); Smith, G.M. (graduation committee); Zoon, Arthur (mentor); Delft University of Technology (degree granting institution)","2020","In this research OpenFOAM is used to model and determine the complex hydrodynamic behaviour of a Homogeneous low-crested structure (HLCS) consisting of cubipod artificial concrete elements. The validated model is used to gain insight in the design sensitivities of a two dimensional cross sectional layout to reduce sea wall overtopping. HLCS and Low-crested structure (LCS) in general dissipate energy from the incoming wave field by wave breaking over the crest of the structure and porous flow through the structure. By energy dissipation milder wave conditions are created inside the basin between the HLCS and the sea wall. Milder wave conditions result in reduced hydrodynamic loads on the sea wall and reduced flood risk. However not only the milder wave conditions determine the amount of sea wall overtopping. Additionally wave-induced water level set-up and basin hydrodynamics (i.e. seiching and resonance) contribute to the amount of overtopping. The relative importance of these different hydrodynamic interactions on sea wall overtopping depend on the main geometrical layout parameters of the system. The main geometrical layout parameters that are analysed in this research are the crest height of the HLCS (푅c ), the crest width of the HLCS (퐵) and the basin length between the HLCS and the sea wall (퐿pool). These geometrical layout parameters can be used by the engineer to steer the hydrodynamic behaviour towards the most cost effective design to reduce sea wall overtopping. However, due to the complexity of physical processes involved and their interactions, theoretical analysis is cumbersome. Therefore advanced OpenFOAM Computational Fluid Dynamics (CFD) simulations are performed in this research. These simulations are used to capture the complex hydrodynamics and gain more insight in the design sensitivities of these types of hydrodynamic systems. A coupled numerical model using both OceanWave3D and OpenFOAM has been set-up in this research. Model dimensions are based on conducted physical model experiments to assess the amount of wave transmission over HLCS as described in J. Medina et al. (2019). No raw data was available from these physical model experiments. Therefore the wave flume hydrodynamics (i.e. irregular wave characteristics) have been calibrated using a grid resolution study. In this study also simulations with varying courant numbers have been performed. Both extracted statistical wave parameters of the coupled model and a standalone OceanWave3D model have been compared. Additionally the separate output of OceanWave3D and OpenFOAM within the coupled model have been compared. Grid convergence has been found for increasing OpenFOAM grid resolution. The measured mean overtopping discharges from the OpenFOAM model are validated against Eurotop 2018 prediction guidelines. The grid which showed the most accurate results in comparison to the required computational time has been selected for the remainder of the study. This OpenFOAM grid is characterized a grid resolution of Δx = Δy= 퐻s/10. In order to assess the hydrodynamic behaviour related to wave transmission for HLCS, the van Gent (1995) parameterization of the extended Darcy Forchheimer equation has been used to model the amount of flow resistance that is exerted on the flow by the HLCS. Based on the differences between conventional rubble mound low-crested structures and HLCS a detailed analysis on the input parameters of the van Gent (1995) parameterization (i.e. the 퐷n , 퐾퐶, np and the closure coefficients 훼 and 훽) has been conducted. Large porosity gradients are found near the boundaries of the artificial cubipod elements. This effect has been implemented in the numerical model using two numerical layers with different porosity values resulting from the derived porosity distribution for artificial cubipod concrete elements. Additionally the effect of numerical outer layer schematization has been addressed. Both numerical additions only show to have minor effect on the modelled wave transmission behaviour (i.e. &lt; 2% on 퐾t ). The closure coefficients 훼 and 훽 have been calibrated and validated based on the conducted physical model experiments J. Medina et al. (2019). Additionally a sensitivity analysis is included which can be used for the calibration of different artificial concrete elements. The best agreement between the modelled transmission coefficient and the experimental transmission coefficient is v vi Summary found for 훼 = 500 and 훽 = 1.0. A parametric study is performed using the validated OpenFOAM model including the HLCS and sea wall to describe the complex hydrodynamic interactions within the hydrodynamic system and assess the design sensitivities. For this parametric study multiple simulations on 6 parallel processors were performed with a duration of 500 waves. Each simulation took approximately 48 hours to complete. The most important findings and implications of the parametric study are in summary: • For all varying geometrical parameters a decay in the form of an exponential function of the mean overtopping discharge is found. The most influence on the overtopping reduction is found for varying crest height of the HLCS. • Wave transmission is found to be the dominant over the water level set-up, seiching and resonance inside the basin for the overtopping assessment of varying crest height and crest width of the HLCS. The most striking result for wave transmission over HLCS is that HLCS shows a constant trend in wave transmission for emergent structures (i.e. 푅c &gt; 0). A further increase of crest height does not result in reduced wave transmission, contrary to conventional rubble mound LCS where a further reduction is observed. • Furthermore a large dependency is found for varying basin length. The propagation of broken waves (i.e. hydraulic bores) due to wave breaking over the crest of the HLCS result in a significant increase in mean overtopping discharge. It is observed that these hydraulic bores die out for larger basin length. Additionally low-frequency wave motion (i.e. seiching and resonance) is observed for varying basin length. However this effect is smaller compared to the dissipating bores. • By comparing the estimated overtopping discharge using the Eurotop guidelines solely based on the amount of wave transmission and the obtained overtopping discharge from the OpenFOAM model a mean underestimation of 69% is found by only using the transmission coefficient for the assessment of the amount of mean overtopping discharge. This concludes that the water level set-up cannot be neglected for overtopping assessments. Furthermore the use of advanced CFD modelling (e.g. using OpenFOAM) or physical modelling is of added value for the assessment of the amount of overtopping for these complex hydrodynamic systems due to the influence of dissipating bores, seiching and resonance inside the basin. The ability of OpenFOAM to gain insight and to study the interactions for complex hydrodynamic systems has been demonstrated. Moreover design sensitivities of the hydrodynamic system under consideration are presented. These results can be used during early design stages for the assessment of the most cost effective design for these types of hydrodynamic systems. Additionally the sensitivity of the geometrical layout parameters can be used by the engineer to make targeted adjustments. Furthermore for comparable hydraulic boundary conditions (i.e. the same order of 퐻s , 퐻s/ℎ, ℎ/퐿p) and the use of low-crested structures (i.e. 푅c/퐻s,i ≈ 0) this OpenFOAM model can be used during design stages without further calibration.","OpenFOAM; Coastal Engineering; Breakwater; Detached breakwater; Coastal structures; Coastal defense; OceanWave3D; Concrete armour unit; Cubipod; Overtopping; Wave Transformations; Wave transmission; Water level set-up; Seiching; Basin hydrodynamics; Numerical modeling; Hydrodynamic system; Porosity; Porosity distribution; Design sensitivities; Porous Media; Homogeneous breakwater; Low-crested structure; Homogeneous low-crested structure; Coupled numerical model; Parametric study; Seawall; Flood Risk","en","master thesis","","","","","","","","","","","","Civil Engineering","",""
"uuid:b4193a86-229d-4868-a5a6-3941737a53a9","http://resolver.tudelft.nl/uuid:b4193a86-229d-4868-a5a6-3941737a53a9","Developing a go to market strategy for an assistive technology product","Passanha, J.E. (TU Delft Industrial Design Engineering)","Hultink, H.J. (mentor); van den Hende, E.A. (graduation committee); Mahadevan Karthik, Karthik (graduation committee); Delft University of Technology (degree granting institution)","2020","The number of visually impaired cases have been exponentially rising in recent time; there are 30Mil visually impaired people in Europe . This has lead to the creation of a big industry of assistive technology devices for the visually impaired community. Envision, a start-up developing artificial intelligence products for the visual impaired, wanted to introduce the new Envision Glasses. The project aims to develop a go to market strategy for the Envision Glasses. To answer this research question, the case study approach was used. Furthermore, Root's 1994 international market entry model was used as a framework. Thus, splitting the research question into two: first, what are the market dynamics that impact the business model, and secondly, what are the factors that influence the consumer purchasing behaviour. Multiple perspectives from the different stakeholders were gathered through qualitative and quantitative research. The final outcome of the project was a market entry strategy with a desired customer journey map that can be replicated across the markets selected. <br","Go to market strategy; new product launch; assistive technology; artificial intelligence; International market entry strategy","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:53aa3e5f-7d9a-4a4f-af22-3c98e3f6eef5","http://resolver.tudelft.nl/uuid:53aa3e5f-7d9a-4a4f-af22-3c98e3f6eef5","Het rendement van verschillende ontwerpen van de trebuchet bij het afschieten van een voorwerp","Huisman, A.E. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Meulenbroek, B.J. (mentor); Visser, P.M. (graduation committee); van Elderen, E.M. (graduation committee); Budko, N.V. (graduation committee); Delft University of Technology (degree granting institution)","2020","In dit project worden vier vereenvoudigingen van de trebuchet onderzocht. Er wordt gekeken naar het rendement met betrekking tot de energie overdracht van het zware tegengewicht op het afgeschoten voorwerp. De invloed van het toevoegen van extra armen en wielen wordt onderzocht. Bij meer energie overdracht kan het voorwerp verder weg geschoten worden en zal het voorwerp meer impact hebben als het op de grond terecht komt.","Trebuchet; Rendement; Euler-Lagrange methode","nl","bachelor thesis","","","","","","","","","","","","","",""
"uuid:b1d66af3-0acb-475e-a4d4-06bf948aea17","http://resolver.tudelft.nl/uuid:b1d66af3-0acb-475e-a4d4-06bf948aea17","Timber Creep of Historic Urban Quay Walls: The influence of timber creep on the assessment of inner-city quay walls","Spannenburg, Trevor (TU Delft Civil Engineering and Geosciences)","Korff, M. (mentor); Peters, D.J. (graduation committee); Gard, W.F. (graduation committee); van de Kuilen, J.W.G. (graduation committee); op de Kelder, M. (graduation committee); Delft University of Technology (degree granting institution)","2020","Amsterdam and many other cities consist of a network of old quay walls, which sometimes have been constructed over a century ago. A large uncertainty exists concerning the current safety of these quay walls and their remaining service lifetime. In the current framework for the assessment of old urban quay walls, the influence of timber creep in the structure is being omitted. It had been expected that a part of the excessive deformations occurred are part of this timber creep as opposed to progressive failure. Hence, this research studied the influence of wood creep on the structural behaviour of old urban quay walls, using a case study based on the Herengracht. For the modelling of the quay walls, use has been made of the Embedded Beam Row (EBR) elements in Plaxis 2D. As this element type has no material model which takes into account creep,<br/>use has been made of pseudo-elasticity. The behaviour over time had been modelled by reducing the elastic stiffness of the EBR elements with increasing creep factors. To force Plaxis to perform calculations, this stiffness reduction has been introduced as a reduced strength in the form of a custom moment-curvature diagram. At the time of writing, the Embedded Beam Row had not yet been validated for cohesive soils. Hence, a verification has been executed of the EBR using a full-scale load test performed on a pile group in Salt Lake City. In<br/>this case, a 3x5 pile group driven in multi-layered cohesive and non-cohesive soils had been laterally loaded. The results included deformations, total horizontal load and bending moment distributions over depth. It<br/>has been found that the EBR provides reasonable results when modelling laterally loaded pile groups. The force-displacement curve from the field test was only slightly stiffer compared to those obtained using Plaxis 2D. Maximum bending moments obtained using the EBR had been found to be 20 to 30% compared to the experimental data. The group efficiency of the pile group was initially lower for small displacements, which was likely caused by the lack of installation effects of driven piles in the Plaxis model. It has been observed<br/>that the Interface Stiffness Factors (ISF) that are used to calibrate the EBR behaviour have a limited range. Increasing the ISF values beyond a certain limit will no longer affect results, as the interface connecting the EBR to the soil will have become practically rigid at this point. Nevertheless, it has been concluded the EBR can be used in this case to model laterally loaded pile groups. The influence of the timber creep on the structural behaviour of quay walls has been studied using a model based on the Herengracht in Amsterdam. A maximum creep factor has been applied of Φ=1.6. Two methods have been used to apply the final creep factor. With the ""Direct"" method, the maximum creep factor was<br/>applied in the same phase as the load. With the ""Indirect"" method, the creep factor has been applied incrementally in steps of 0.1. It has been observed that the results from these methods deviate significantly. With the Indirect method, larger creep displacements have been calculated, as well as lower maximum compressive stresses in the piles. The creep behaviour has been studied in more depth using the Indirect method. In this case study, creep displacements of 2.22 times the initial displacement have been calculated. When plotted against the increasing creep factors, it has been observed a power function could be fitted to the data. In addition, a stress reduction of 0.590 times the initial maximum compressive stress has been observed in the front two pile rows. This stress reduction was achieved at φ=0.4. In the most landinwards pile row, stresses<br/>continued to decrease, with a reduced rate beyond φ=0.4. A sensitivity analysis has been performed to study which parameters have significant influence on the creep behaviour. Conclusions were drawn based on the relative change in horizontal displacement and maximum compressive stress in the front pile row. It has been concluded that the shear strength parameters of the top layer, the elastic modulus of the timber, surface load and the geometry have the largest influence on the creep behaviour. Furthermore, it has been discovered<br/>that the size of the creep factor steps influences the final stress and displacement. With decreasing stepsize, convergence occurred in the results. From the results it has been concluded that the structural behaviour of<br/>old urban quay walls is significantly influenced by timber creep. The inclusion of timber creep resulted in large displacement increases, but also in stress reduction. The results suggest that excessive deformations of quay walls does not mean that an ultimate limit state has been reached. It is recommended to include the timber creep in the modelling and assessment of existing quay walls.","Quay structures; Quay walls; creep; timber creep; timber; urban quay walls; historic quay walls; old quay walls; wood; wood creep; timber quay walls; plaxis 2d; EBR; Embedded Beam Row; Laterally loaded pile; pile group; horizontally loaded piles; Laterally loaded pile group; ISF; Interface Stiffness Factor; Herengracht; Amsterdam; FEM; soil; modelling; pseudo-elasticity; creep factor","en","master thesis","","","","","","","","","","","","","",""
"uuid:94431ada-bec3-44bf-bb7b-bb25fce19229","http://resolver.tudelft.nl/uuid:94431ada-bec3-44bf-bb7b-bb25fce19229","Towards a Sustainable Bridge Design: With the support of optimisation processes and decision making systems","Vigorito, Alessio (TU Delft Architecture and the Built Environment)","Smits, Joris (mentor); Turrin, Michela (graduation committee); Joosten, Stijn (graduation committee); Delft University of Technology (degree granting institution)","2020","This research aimed to design a new bridge for the city of Rome, Italy, through the support of modern optimisation and decision-making processes that can be implemented to make informed choices regarding aesthetic performance, structural firmness, and environmental impact. The bridge’s design was carried forward considering the city’s plans for the new connection and the relationship with the context dominated by a rationalist architecture. The architectural relationship with the context, the parametric optimization, and the minimization of the material used were the main drivers behind the final design.","Bridge Design; Parametric Design; Structural Design; Optimisation; MCDM","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences","",""
"uuid:77529c0c-04bc-4e2e-b9d5-816b0a7526fa","http://resolver.tudelft.nl/uuid:77529c0c-04bc-4e2e-b9d5-816b0a7526fa","Using machine learning to assess the predictive capabilities of fetal cardiotocography with reference to the time of the measurement relative to time of birth","Csuvár, Zsombor (TU Delft Mechanical, Maritime and Materials Engineering)","Goos, T.G. (mentor); Delft University of Technology (degree granting institution)","2020","Abstract—Background: cardiotocography (CTG) has long been used in clinical decision making to help assess the fetus’ condition during pregnancy. However it’s usefulness in the detection of fetal acidosis is debated due to high inter and intraobserver variability and general difficulty in interpreting the signals. The introduction of automatic analysis methods aims to decrease these issues originating from human limitations, but additional questions still remain. There is no clear concession when is it most useful to perform CTG measurements and which time periods posses the highest predictive capabilities. Method: a database of 1932 patients was analyzed after baseline and feature extraction. Several machine learning methods (SVM,logistic regression, random forest, KNN) were compared based on accuracy, F1 score, recall, precision, sensitivity and specificity.Furthermore the database was divided, based on when the measurement was taken (relative to time of birth), and the accuracy of the methods was compared again at intervals of 1 to 24 hours.<br/>Results: from the machine learning methods the support vector machine using polynomial kernel achieved the highest scores(sensitivity of 55% and specificity of 56%). The inclusion of older measurements caused a decrease (≈20%) in the predictive performance of the models.<br/>Conclusion: the results show that in clinical decision making the most crucial fetal heart rate measurements are the ones that are taken the closest to birth.","biomedical signal analysis; Fetal heart rate; CTG; Machine Learning; Time dependency; Diagnoses","en","master thesis","","","","","","","","","","","","","",""
"uuid:71ef1169-bcdb-4953-b9af-c36339faefcb","http://resolver.tudelft.nl/uuid:71ef1169-bcdb-4953-b9af-c36339faefcb","Feed your city: local farming in Hembrug","Sadeghi, M. (TU Delft Architecture and the Built Environment)","Marx, M.C. (mentor); Koopman, F.W.A. (mentor); Delft University of Technology (degree granting institution)","2020","The design project, that is part of the Heritage &amp; Architecture graduation studio, is dealing with the transformation of the ensemble area ‘Plots in the wood’. This area lays in the centre of the former military complex of Hembrug in Zaandam. The design leads to transform this area to residential and commercial area, which is combined with local farming. The whole area should be preserved due to the unique landscape and the buildings characteristics. These buildings require an important way of protection since they still preserve their historical functionalities. They might not have their old potentials which is in the field of military, in order to preserve their historical values based on functionality, however considering its spectacular identity and unique elements, we have to protect this area. Creating environment with roots in circularity design can help spreading the circularity in other words de design reduce negative impact on environment and exciting buildings.","heritage; Architectcture; Landscape architecture; reuse; Material Circularity; recycle; cultural value; Military","en","master thesis","","","","","","","","2020-08-27","","","","Architecture, Urbanism and Building Sciences","",""
"uuid:024213b7-b839-4561-a26d-c6190e451684","http://resolver.tudelft.nl/uuid:024213b7-b839-4561-a26d-c6190e451684","Story ARtist: Story Authoring in Augmented Reality","Kegeleers, M. (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Comp Graphics & Visualisation)","Bidarra, A.R. (mentor); Guerra Marroquim, R. (graduation committee); Tielman, M.L. (graduation committee); Delft University of Technology (degree granting institution)","2020","Most of the content creation applications that are currently common in use are regular PC applications with simulated 3D visualisation on a 2D screen and indirect interaction through a mouse and keyboard. Augmented Reality (AR) is a medium that can provide actual 3D visualisation and more hands-on interaction for these applications. This thesis explores how AR can be used for story authoring, a specific type of content creation. Both types of existing AR interfaces, tangible and touch-less were explored and combined in a useful way. The Story ARtist application was developed to evaluate the designed interactions and AR visualisation for story authoring. Its interface combines tangible and touch-less interactions in the form of physical markers and hand tracking input. A tabletop environment is used to visualise the story authoring elements dynamically, using the 3D space that AR provides. Story authoring is kept simple for accessibility, with a plot point structure focused on core story elements like actions, characters and objects. A user study was done with the concept application to evaluate the designed AR interaction and visualisation for story authoring. The results show that AR has considerable potential for story authoring.","Story authoring; Augmented Reality; Interaction design; Content creation","en","master thesis","","","","","","","","","","","","","",""
"uuid:2ec47289-dd3d-49a3-a1c8-addcdff405bf","http://resolver.tudelft.nl/uuid:2ec47289-dd3d-49a3-a1c8-addcdff405bf","Scenario Discovery in land use change models","Cox, M.E. (TU Delft Technology, Policy and Management)","Kwakkel, J.H. (mentor); Quist, J.N. (mentor); Jafino, B.A. (graduation committee); Delft University of Technology (degree granting institution)","2020","There are bidirectional interactions between land-use and environmental systems: the way land is used has impacts on the environment, while changes in the environment have impacts on the way land is used. The use of Land Use Change models enables policy makers to gain insights into possible developments of the land-use system, the possible causes of these developments, and their consequences. Due to assumptions, simplifications, or lack of data many uncertainties remain concerning these forces and how they could play out in the future. Currently, a deductive scenario approach is the main method used to deal with these uncertainties. Using this approach, normally two to six scenarios are developed, for which values of the uncertain driving forces vary in accordance with the different scenarios. However, such a deductive approach only characterizes a small part of the uncertainty space, and therefore increases the chance of overlooking certain regions of the uncertainty space, corresponding with the real future, which were not characterized by any of the scenarios considered. This research aims to explore the use of Scenario Discovery with the aid of land use change models. To answer this research question, the Land Use Scanner model is used. This model was used in earlier research in the simulation of future land use patterns using the so-called Delta Scenarios. These Delta Scenarios and their corresponding future land use patterns simulated with the Land Use Scanner model are used to compare to the results of this research. This research resulted in six scenarios which differ from the Delta Scenarios in the narrative and the corresponding land-use patterns. However, the Scenario Discovery scenarios differ in other ways as well. Firstly, the development of the Scenario Discovery scenarios makes the analyst aware of under which conditions a combination of similar driving forces lead to different land-use patterns. Also, this approach makes the analyst aware under which conditions combinations of different driving forces still yield similar land-use patterns. Next to this, the Scenario Discovery scenarios show which driving forces are most important. Overall, this means that the scenarios identified with Scenario Discovery differ from the Delta Scenarios in the way that they provide analysts and policymakers with several insights, which can support sufficient informed decision making, which are overlooked when with the development and use of the Delta Scenarios. As this research demonstrated the potential of Scenario Discovery in the land-use change modelling field, it is recommended for land-use change model users, such as LUS model users, to use Scenario Discovery for the development of scenarios. As for the decision-makers in spatial planning, it is recommended to involve land-use change models more into the decision-making process. Lastly, on a more general note, the use of story and simulation approaches in model-based decision making should be reconsidered, and instead, it is recommended to research the possibilities of Scenario Discovery in various modelling fields.","Land use change modelling; Scenario Discovery; Exploratory Modelling and Analysis; Kappa","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:7c09a506-7bc0-4b26-a2f3-5f69ceeb74f4","http://resolver.tudelft.nl/uuid:7c09a506-7bc0-4b26-a2f3-5f69ceeb74f4","Perspective Discovery in Controversial Debates: An exploration of unsupervised topic models","Liu, J.C.M. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Tintarev, N. (mentor); Houben, G.J.P.M. (graduation committee); Finavaro Aniche, M. (graduation committee); Draws, T.A. (mentor); Delft University of Technology (degree granting institution)","2020","Since the introduction of the Web, online platforms have become a place to share opinions across various domains (e.g., social media platforms, discussion fora or webshops). Consequently, many researchers have seen a need to classify, summarise or categorise these large sets of unstructured user-generated content. A field related to this task is also known as opinion mining in which various applications have focused on sentiment analysis techniques to classify opinionated documents based on sentiment. More recent, researchers have focused on stance classification to classify opinionated documents based on stance in controversial debates. However, in the case of such controversial debates it would be equally interesting to know the underlying reasons behind a stance in order to truly understand a discussion. We can call these underlying reasons as perspectives. Few have focused on distilling such perspectives from text and in this research we aim to explore the use of an unsupervised model - called joint topic models - to perform the task of perspective discovery. We define perspective discovery on a controversial debate as the process of automatically finding and extracting a structured overview of perspectives from unstructured text. The aim is to quantify how well existing joint topic models can extract human understandable perspectives between and within stances for more fine-grained opinion mining on textual debates. To perform this evaluation we propose an evaluation setup with an extensive user study. This setup focuses on the topic model’s clustering ability of perspectives as well as the human understandability of the topic model’s output. Based on the results we may derive that topic models can discover some of the perspectives from text. Moreover, the results suggest that users are not influenced by their pre-existing stance when interpreting the output of topic models.","sentiment analysis; controversial debates; topic modelling; joint topic modelling; opinion mining","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:b9cfa548-219c-41f8-9fe1-36db508a10af","http://resolver.tudelft.nl/uuid:b9cfa548-219c-41f8-9fe1-36db508a10af","A Conceptual Study of a Novel Biorefinery based on Supercritical Water Gasification of Wet Biomass Residues from Farming and Food Production Practices","Goel, A. (TU Delft Mechanical, Maritime and Materials Engineering)","de Jong, W. (mentor); Mohammadzadeh Moghaddam, E. (mentor); Delft University of Technology (degree granting institution)","2020","Due to growing awareness and rising concern over the climate change impact, the demand for renewable energy has been increasing. In the coming decades, biomass is expected to play a crucial role as it is one of the most plentiful and well-utilized renewable resources in the world. Biomass can be sustainably converted to solid/liquid/gaseous biofuels which in turn can be used to produce both, power and heat. Among the many thermochemical conversion technologies, conventional gasification technology is one of the widely used conversion routes. However, the use of conventional gasifiers for the conversion of biomass feedstocks with more than 70% moisture content is not suitable without their pre-treatment. Having the advantage of avoiding energy- and cost-intensive drying process, Supercritical Water Gasification (SCWG), offers a promising approach in converting these biogenic residues into valuable biofuels.<br/><br/>SCWG is an alternate thermochemical conversion route and is suitable for the conversion of wet biomass feedstocks having very high moisture content. The thermochemical conversion takes place in Supercritical Water (SCW) having temperatures and pressures higher than 374.29 °C and 221 bar, respectively. At such conditions, the thermo-physical properties of water change in a way that causes water to act as a solvent and catalyst at the same time. With the use of SCWG, large amounts of wet biomass wastes such as cattle manure, fruit/vegetable waste, and cheese whey residual streams which get disposed from farming and food processing industries globally, can be sustainably treated. Since an in-depth investigation of SCWG of the noted real wet biomass wastes is still at an early stage, in this study, we have therefore concentrated on the SCWG of these specific classes of waste. To this end, different modelling scenarios, including global, constrained, and quasi-thermal thermodynamic equilibria models have been pursued so as to effectively predict system behavior. We used Factsage and MATLAB modelling tools to develop and analyze these models. We observed reasonable agreements between experimental results and predictions from constrained and quasi-thermal equilibrium models, effectively emanating from conceptual improvements due to experimental data.<br/><br/>The results showed that the superimposition of carbon conversion efficiency together with the use of a constant molar amount of specific compounds can improve the accuracy of the global equilibrium model. For example, deviation of CO2 yield from experimental data significantly improved from 55% to 0.3% for fruit/vegetable residue gasification using a constrained equilibrium model. Furthermore, comparisons revealed the advantage of using a quasi-thermal equilibrium model which uses the ‘’approach temperature” concept over the constrained equilibrium model. Results for fruit/vegetable waste showed an approach temperature between 60 and 80 °C for H2 yield. Overall, the quasi-thermal equilibrium approach has its advantages of lumping all the additional constraints to be used in constrained equilibrium model into an effective approach temperature, offering a much better prediction of the compositions with an error margin of maximum 0.001%.<br/><br/>Furthermore, the results of this effort assisted us in designing a conceptual bio-refinery model based on the SCWG process. Using the ASPEN modelling tool, we were able to optimize and analyze the entire process for its chemical and thermal behavior. Using the results, the SCWG process was found to be thermally self-sustaining for the assessed reactor conditions. However, with the reactor conditions; temperature (600 and 650 °C), pressure (240 bar), and fruit/vegetable waste feed concentration (11wt%), the process was assessed to be practically infeasible as larger part of the produced gas stream (i.e. more than 70%) was getting recycled back to the system. Finally, we compared the process modelling results based on global and constrained modelling scenarios and the use of GTE modelling for process designing was found to have its limitations. Overall the result of this thesis shows the great potential of using SCWG for thermochemically upgrading wet biomass feedstocks. Comparing the results from different modelling scenarios gave an insight into the process and the reactions taking place inside an SCW gasifier, thereby assisting in better reactor designing.<br","Wet biomass; Supercritical water gasification; Thermochemical conversion; Modelling; Equilibrium; Process model","en","master thesis","","","","","","","","","","","","Mechanical Engineering","EU FACCE-SURPLUS Supervalue project (Contract number ALW.FACCE.15)",""
"uuid:5503b2cd-061e-420b-a778-a546bf0ef05a","http://resolver.tudelft.nl/uuid:5503b2cd-061e-420b-a778-a546bf0ef05a","Design of Midway Energy (Middleware System) as part of Illuminator: Energy System Integration Development Tool Kit","Trichy Siva Raman, S.K. (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Intelligent Electrical Power Grids; TU Delft Electrical Sustainable Energy)","Cvetkovic, M. (mentor); van der Meer, A.A. (mentor); Popov, M. (graduation committee); Bourgeois, J. (graduation committee); Delft University of Technology (degree granting institution)","2020","Using the energy system is part of our daily routine but the complexity of power systems and its understanding have both been confined to the experts in the field. Furthermore, the advent of the Information and Communication Technology (ICT) and the Internet of Things (IoT), power system integration is becoming even more complex for the system planners and operators. Various clean energy technologies like solar power, massive offshore wind, Electric vehicle as well as the increasing dependency of the Prosumers to move towards a future decentralized and transactive energy market. There is hence a need to educate the general public about the important problems encountered during the energy transition as well as to provide a demystifying version of the existing power system to exhibit its complexity and its benefits of intelligent multi-energy systems.<br/><br/>Energy System Integration Development (ESID) kit could solve this issue.<br/><br/>This project concerns the design and development of a Middleware software system based IOT application, which runs on Raspberry PIs (RasPi), contribute to the layered bottom-top approach of the Illuminator - Energy System Integration Development Tool Kit and has the main goal to help in assisting the application layer to simulate energy system integration scenarios and will be prototyping simple proofs-of-concept for validation purpose. It’s realized as part of the master thesis curriculum of the author. On the completion of this project, there will be a generic middleware system that can be used by the end users/application layer to demonstrate energy system integration scenarios, which is scalable, reconfigurable, inter portable.<br/><br/>Illuminator - Energy System Integration Development Tool Kit aimed to become an open-source platform depicting energy integration problems, an education tool kit, and research to prototype control algorithms for counteracting the energy transition challenges. The general public and system integrators would benefit as well as the stakeholders as it can help them analyze the energy integration challenges in a user-centric fashion.vii<br","Transcative energy; Decentralised network; middleware system; Energy System Integration Demonstrator; MQTT; IoT; Raspberry Pi; Library","en","master thesis","","","","","","","","","","","","Electrical Engineering | Electrical Power Engineering","IEPG | Illuminator",""
"uuid:e4d53563-b513-4777-95d5-93d379967eba","http://resolver.tudelft.nl/uuid:e4d53563-b513-4777-95d5-93d379967eba","Diffusion of clean cooking practices in refugee settings: An agent-based exploratory modelling study of market-based interventions","Werntges, A.K. (TU Delft Technology, Policy and Management)","Comes, M. (mentor); Warnier, M.E. (mentor); Delft University of Technology (degree granting institution)","2020","Access to clean energy has long been neglected within the humanitarian agenda. As a result, refugees are often locked into unsustainable and risky energy practices, especially in low-income countries. This study focuses on market-based interventions to deliver clean cooking fuels in refugee camps in protracted crises. The outcomes of market-based interventions are highly dependent on whether beneficiaries adopt and continuously use the products. However, clean cooking practices often face various adoption barriers. The aim of this study is to gain insights into the mechanisms and path-dependencies driving the adoption of clean cooking fuels in refugee camps and, by taking a modelling approach, to develop a method to analyse the effect of market-based clean cooking interventions. To this end, this study combines agent-based modelling with exploratory modelling techniques to capture social interactions, human decision-making behaviour, and deep uncertainties. The model formulation is grounded in a case study of a Rwandan refugee camp, and Diffusion of Innovation theory. Different interventions, including financial assistance for fuel purchase (cash transfers or vouchers), information campaigns, and maintenance activities, are simulated under a wide range of scenarios. Scenario discovery is applied to identify circumstances for success or failure of interventions. For both types of financial assistance, supporting information campaigns and maintenance activities are critical to create robust, timely, and long-term impact. Based on the findings, policy recommendations and guidelines for future interventions are derived.","Agent-based Modelling; Exploratory Modelling; Refugee camps; Innovation diffusion; Clean cooking","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:f565be94-8fa5-4be8-a46c-471a3495e6a0","http://resolver.tudelft.nl/uuid:f565be94-8fa5-4be8-a46c-471a3495e6a0","Non-Linear Finite Element Analysis and Parametric Study of Four-Pile Pile Caps","Asefa, Sali (TU Delft Civil Engineering and Geosciences)","Hendriks, M.A.N. (mentor); van der Meer, Lex (mentor); Hoogenboom, P.C.J. (graduation committee); Lantsoght, E.O.L. (graduation committee); Delft University of Technology (degree granting institution)","2020","Piles and pile caps are commonly used in the Netherlands due to the soft shallow subsurface soil that is predominant in the country which does not have suﬃcient bearing capacity to support heavy structures. Pile caps are currently designed analytically using the strut and tie model (STM). This is believed to be conservative and results in an over-reinforced structure with higher cost and unsustainable design due to ineﬃcient use of materials. The main objective of this thesis is to investigate the application of Non Linear Finite Element Analysis (NLFEA) to design pile caps. Five experiments were selected from literature and modelled in DIANA. These pile caps had ﬂexural, corner shear, ﬂexure-induced punching and combined ﬂexure and corner shear failure modes. Quarter of the pile caps were modelled using Finite Element Model (FEM) as it saves computational time and cost by making use of symmetry while still predicting the failure mechanism and failure load within 99% of the full model. The reinforcement was modelled using both embedded and Shima bond-slip. The FEM results were subsequently compared with the experiment to gain insight into how accurately FEM can capture the structural response of pile caps. The comparison shows that failure mechanism and crack pattern can be accurately predicted for all pile caps. However, the accuracy of the failure load depends on the failure modes of the pile cap as ductile failures are captured more accurately than those with brittle failure. The diﬀerence between the peak load in the FEM and the experiment is observed to be 5 - 7% for ductile failures while it varies between 25 - 42% for brittle failures. These diﬀerences are liberal estimates. Moreover, three pile caps that were designed using STM were modelled numerically to obtain the design resistance and compare the results. The comparison show that STM overestimates the stresses in the concrete by 40% – 70% as well as the crack width by 60 – 65%. This is because the eﬀect ﬂank reinforcement and post cracking contribution of concrete are not accounted in the STM. Numerical model results are also closer to the experimental results than analytical calculations by 50% on average. The comparison between STM and numerical model revealed that optimization of pile caps is possible. Subsequently, four parameters: pile cap geometry, bottom rebar percentage, number of ﬂank rebar and concrete quality were reduced to evaluate the eﬀect on the structural response of pile cap. These parameters were selected based on the interview with experts and results of the comparison between the FEM and experimental results. The parametric study was performed on a pile cap with punching failure. It was found that reducing the pile cap depth by 0.1m increases the rebar stress by 25 - 35% and reduces the failure load by 2 - 8%. Reduction of the bottom rebar percentage by 10% increases the crack width by 15 - 30% and lowers the failure load by 2 - 8%. A 50% decrease in the number of ﬂanks is found to increase the stress in the bottom reinforcement by 20 - 25% but not aﬀect the failure load signiﬁcantly. Change in these three parameters does not change the failure mode and the failure load remained greater than the design load. However, decreasing concrete quality accelerates the onset of crack which decreases failure load and changes the failure mechanism from punching to corner shear. Cost analysis and environmental impact assessment also show that geometry optimization has more environmental and cost advantage than reducing the reinforcement. For every 0.1 meter reduction in depth, there is a 6% reduction in cost per pile cap and a 70 - 200 kg reduction in the CO2 footprint. Two sets of experiments were designed to validate the key ﬁndings of this thesis. The ﬁrst set was designed to investigate if punching failure can be accurately predicted by FEM. This will be conducted on a scaled down pile cap with expected punching failure. A second set of experiment was designed to explore if the optimization observed in the numerical models can be achieved in reality. Two pile caps, with brittle and ductile failure were selected. Each will have a variable geometry, bottom rebar percentage, ﬂank reinforcement and concrete quality. The current STM approach does not capture all the failure modes of pile caps since the unity check does not distinguish between certain failures such as concrete crushing and punching. It also does not account for the contribution of ﬂank reinforcement and concrete contribution to the tensile strength post-cracking. Therefore, future designs of pile caps should take these parameters into account to obtain a safe design without underestimating the capacity of the pile cap. This would result in a more eﬃcient design with lesser material and lower cost.","Pile cap; Strut-and-Tie model; Parametric study; Numerical analysis","en","master thesis","","","","","","","","","","","","Civil Engineering | Structural Engineering","",""
"uuid:39108e4a-60da-4711-89ad-f48a20ec2878","http://resolver.tudelft.nl/uuid:39108e4a-60da-4711-89ad-f48a20ec2878","A dynamic optimization model on the routing and maintenance scheduling of aircraft for individual tasks","Steenkamp, A.S.A. (TU Delft Mechanical, Maritime and Materials Engineering)","Schulte, F. (mentor); Negenborn, R.R. (graduation committee); Möller, M. (graduation committee); Pahlavan, L. (graduation committee); Delft University of Technology (degree granting institution)","2020","Increasing competition amongst airlines necessitates them to improve the efficiency of their operations. Even though maintenance, repair, and overhaul (MRO) represent a significant portion of an airline’s operational costs, aircraft maintenance scheduling is often still a manual process, producing suboptimal solutions. Airlines typically operate by congregating the bulk of the required maintenance tasks in extensive checks, called letter checks (A, B, C, or D). Letter checks require the aircraft to be taken out of operations and result in many tasks being executed before they are due, leading to more required maintenance over the aircraft's lifetime. The purpose of this study is to develop a methodology that provides flight routes to aircraft and plans the maintenance tasks individually within these routes over a given planning horizon with the objective of maximizing the utilization of the total remaining flying time of the fleet. To achieve this, tasks are planned as late as possible on overlays at a maintenance station, while being given a due date and a remaining number of legal flight hours that can be flown before execution is mandatory. For this purpose, we develop a mixed integer programming (MIP) model based on a city-day network representation. Because the computational burden of exact methods becomes too hefty for increasing problem sizes, several matheuristics have been developed to provide good solutions in quick fashion. The presented matheuristics either decompose the problem by aircraft or into time periods. The former constructs the flight routes and maintenance schedules aircraft per aircraft while the latter constructs them simultaneously in a rolling horizon fashion. For the rolling horizon matheuristics, several forecasting strategies have been designed as well. In an experimental study, one of the selected rolling horizon matheuristics was able to remove the need for aircraft to be taken out of operations for an A-check (the most frequently occurring letter-check), potentially saving up to \$ 7.2 million per aircraft over a time period of ten years. Furthermore, the lost flying time, incurred by planning maintenance tasks before they are due, was decreased by over 98\%, resulting in a higher utilization of the task intervals and less required maintenance over the aircraft's lifetime. Finally, the dissection of the A-check into its individual tasks led to a more phased maintenance schedule by attenuating the peaks in workload for the mechanics workforce. Our presented approach can be used by mid-sized airlines to optimize their maintenance schedules through increasing aircraft availability and reducing maintenance costs over the aircraft's lifetime.","Aircraft Routing; Maintenance Scheduling; Matheuristics","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Transport Engineering and Logistics","",""
"uuid:cc4949a5-36c7-4d38-b24f-b69b61a1e849","http://resolver.tudelft.nl/uuid:cc4949a5-36c7-4d38-b24f-b69b61a1e849","Sub-national Government Fiscal Sustainability: A Research on Fiscal Risks and Fiscal Federalism in Times of COVID-19","De Biase, P. (TU Delft Technology, Policy and Management)","Kwakkel, J.H. (graduation committee); Storm, S.T.H. (mentor); Sirenko, M. (graduation committee); Delft University of Technology (degree granting institution)","2020","The world is now facing what seems to be the biggest crisis since the Great Depression. An unparalleled pandemic of a highly contagious virus in a globalized word. Early economic indicators and the death tolls are suggesting a gloomier situation than expected. Sub-national governments (SNGs) are at the forefront of this crisis, since they are both responsible for the provision of critical health and social protection services and are severely hit financially by it. SNGs may be impacted by a “scissors effect” of SNG expenditures surging, while at the same time their revenues collapsing. This thesis analyses how SNGs' revenue and expenditure compositions affect their fiscal vulnerability to the COVID-19 crisis. To that avail, fiscal sustainability at the sub-national level is defined, the SNGs' revenue and expenditure composition are analysed and compared between 24 countries. Also, the impact of external variables on their fiscal sustainability is assessed under different scenarios.<br/><br/>Through the use of the machine learning technique, LASSO (least absolute shrinkage and selection operator), different external variables were tested and only the economic activity (i.e. gross domestic product - GDP) was selected as a good predictor and only for SNGs' revenue. The impact of the GDP on SNGs' revenue differ significantly depending on their revenue composition in terms of taxes and inter-governmental grants. A panel data model was used to estimate each revenue item elasticity and those elasticities were used to simulate the expected revenue under six different GDP scenarios for the COVID-19 crisis. For the SNGs' expenditure, sixteen scenarios were made considering different policies (e.g. expansionary, contractionary), shocks on health and social protection expenditure and SNGs' expenditure composition.<br/><br/>In total, 96 scenarios were created through the combination of the six GDP scenarios and sixteen expenditure scenarios. The experiments' results revealed that the higher the property taxes and inter-governmental grants share as a proportion of the revenue the smaller the impact of the COVID-19 crisis on SNGs' fiscal sustainability. For income taxes, the opposite is true. Regarding expenditures, the higher the investment and capital transfers budget share, the better SNGs adapt and handle the crisis. Social protection expenditure share, on the other hand, has negatively affected fiscal sustainability.<br","Subnational finance; Fiscal risks; COVID-19; Public finance; Revenue elasticity; Subnational fiscal sustainability","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:6c00ce52-22ee-46df-93f5-8aafada6ec74","http://resolver.tudelft.nl/uuid:6c00ce52-22ee-46df-93f5-8aafada6ec74","Small and medium sized enterprises’ construction logistics in urban areas: A framework to decrease the emissions caused by small-scale construction projects’ logistics in urban areas","le Blanc, O.L.R. (TU Delft Technology, Policy and Management)","Ludema, M.W. (mentor); Enserink, B. (mentor); Delft University of Technology (degree granting institution)","2020","The world is facing climate change which has sever impacts on extreme weather events, biodiversity and rising seas. Greenhouse gas emissions need to be reduced to counteract climate change. One specific way to contribute to that reduction is setting Zero-Emission (ZE) zones to ban fossil fuel vehicles in urban areas which will presumably lead to a reduction of 1.0 Mton CO2. The ZE zones will be initiated from 2025 in the 30-40 largest municipalities in the Netherlands for passenger cars and delivery vans. Prior research has been applied to large construction projects and not on small-scale construction projects. A literature review resulted in how to classify small-scale construction projects into groups. The difference of these groups is necessary to structure the small-scale construction projects on logistics characteristics and finally on feasible logistics solutions. The three groups are micro (&lt;150 m2; &lt;€0.3 mln), small (150 – 1,000 m2; €0.3 mln – €3 mln) and medium (1,000 – 10,000 m2; €3 mln - €20 mln). The vehicles used for small-scale renovation projects are mostly delivery vans, box trucks and loader crane trucks. Occasionally, tractors and heavy trucks are used. There are three kinds of transport movements: material transport, personnel transport and equipment transport. A list of feasible logistics solutions has been determined grouped on micro, small and medium construction projects and on the type of transport movements. A stakeholder analysis has been conducted to understand the different roles and perspectives of the stakeholder. The basic design cycle has been used to design the feasible logistics solutions and to summarize the findings in a booklet that can be used by the key stakeholders (contractors, wholesalers, transporters, municipalities) to know which logistics solutions are possible for them.","Construction Logistics; Small-scale construction projects; Urban areas; Logistics solutions","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:d644192f-d3e1-470e-bf66-63ad6d77888f","http://resolver.tudelft.nl/uuid:d644192f-d3e1-470e-bf66-63ad6d77888f","Water resilient industrial transformation","Li, Yijing (TU Delft Architecture and the Built Environment)","Nijhuis, S. (mentor); Qu, L. (graduation committee); Delft University of Technology (degree granting institution)","2020","In history, Shunde is famous for its water village culture with dense water networks and a beautiful fish-pond system. After the reform and opening-up policy in 1978, the manufacturing industry is rapidly developed in Shunde. Followed by that, the water village culture is gradually declining. Instead, a large number of factories are scattered in the whole district, which results in severe water problems. Now it is the phase of industrial transformation. This project proposes water resilience strategies and industrial transformation strategies to guide future development in Shunde. It starts from the analysis of existing water management, the relationship between the industrial area and water problem points and the existing condition of the industrial area. Then by doing design exploration, it explores possibilities for water resilient industrial transformation. This project not only provides the possibility of regenerating the industrial area, keeping industrial memory but also improves the water capacity and reshapes the relationship between people and nature.","Water resilience; Industrial transformation; Water logging","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences","",""
"uuid:2ac45023-675e-421a-a726-4411be41c4bf","http://resolver.tudelft.nl/uuid:2ac45023-675e-421a-a726-4411be41c4bf","Modulation Enhanced localization microscopy improves precision with factor five","Sterrenburg, Jaap (TU Delft Mechanical, Maritime and Materials Engineering)","Delft University of Technology (degree granting institution)","2020","Recently, several methods were introduced that combine the powers of Structured Illumination Microscopy (SIM) and Single Molecule Localization Microscopy (SMLM). This results in a powerful instrument that enables researchers to reconstruct images with a resolution improvement of a factor two compared to SMLM. In this thesis I show that increasing the number of phase steps in structured illumination improves the precision improvement. Furthermore, I show that for photo-activated fluorescent labels, we can amplify and exploit the non-homogeneous resolution of patterned illumination by additionally making use of patterned activation (PA-SIMFLUX). Simulations show an improvement of 4.78 compared to SMLM in the case of uniform illumination. I have designed a microscope setup using two Digital Micromirror Devices (DMDs). This optical setup enables DMD-SIMFLUX with nine phase steps per direction and perform with a frame rate of 440fps, currently limited by the frame rate of the camera. The pattern pitch of the excitation light is 231nm, whereas the pitch of the activation light is 233nm. To finish the assembly of this microscope, I present a plan to finalize the alignment of the illumination path, as well as controlling the polarization for the desired interference patterns. To assess the timing feasibility of the experiments and create a benchmark for the precision, a PALM-TIRF setup with uniform illumination was used based on the work of Kwakwa et al. in [1]. A benchmark was set for 10nm in uniform illumination. The on-time of the photoactivatable dye PA-JF646 enables PA-SIMFLUX experiments with three non-equidistant phase steps. The on-time of the STORM dye Alexa-647 limits the amount of phase steps we can use for DMD-SIMFLUX or lead to discarding a large portion of the blinking data.","","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:63a9a55e-cabf-4dfb-aca7-40904704f439","http://resolver.tudelft.nl/uuid:63a9a55e-cabf-4dfb-aca7-40904704f439","Sustainable Luxury in 2040 City Mobility","Hilhorst, Bas (TU Delft Industrial Design Engineering)","van Grondelle, E.D. (mentor); Hiemstra-van Mastrigt, S. (mentor); Delft University of Technology (degree granting institution)","2020","This Master Thesis is created in collaboration with Mercedes-Benz AG, Society and Mobility Pioneering department.<br/>The project focuses on ‘sustainable luxury in 2040 city mobility’. With ‘Personal Luxury Sharing’, Mercedes-Benz will be able to be a role model in the future city center. Where cities change into ‘livable cities’, seeing a declining role for the car as king of the roads, Personal Luxury Sharing brings Mercedes-Benz in the city center as future role model.<br/>Personal luxury Sharing is a service where personally owned Mercedes-Benz’s are part of the MaaS-system by sharing a personally owned vehicle. As cities will have more strict regulations on vehicles, such as bans for polluting cars or single-occupancy vehicles, using Personal Luxury Sharing enables the car owner to enter restricted city areas, by combining the best of both worlds; the advantage of a personally owned vehicle and a shared vehicle. <br/>Personal Luxury sharing is as a personal mobility assistant. Connected to your agenda, it creates the best route to your preferences, taking into account your mood, willingness to share, openness and possible travel options. It introduces you to other Mercedes-Benz drivers to extend your network.<br/><br/>Explorative research and design are done to get an understanding of the three pillars ‘luxury’, ‘sustainability’ and ‘mobility’ in a future city environment. All in order to create a ‘2040 city worldview’ and vision for the future concept. As Mercedes-Benz is strongly represented in the ‘hardware’ luxury, with their vehicles, Personal Luxury Sharing focuses on luxury in freedom, feeling privileged with a trustful and demand less concept within the familiar Mercedes-Benz environment. the user perceives benefits on multiple levels. This enables the user to have a behavioral change to both experience luxury as well as being sustainable. Luxus mit gutem Gewissen. Inspiration was taken from hotel-like luxury, having it always with you, without being demanding.<br/><br/>The ideation led to a full concept, with an interior concept and exterior design for a suitable vehicle, together with the personal luxury sharing service, connected to your personal device agenda. To add a ‘status object’, an interactive token was added. After evaluation and validation, the concept was brought back to the Personal Luxury Service, connected to your mobile agenda and ring to interact with, having a useful status object that is always with you<br/><br/>Besides city access and the possibility of extending your network, The personal luxury service will provide the best of both worlds, owning and sharing.<br/><br/>A personal car is more than something to go from A to B with, as it is one of the most expensive products owned, after a house, for example, most people do have an emotional bond with their car. It is a sign of freedom, being able to bring you wherever you want, or doing with it whatever you want. With buying one, you are able to choose the one (Mercedes-Benz) that suits you most, with your preferred options, design, or layout. As a disadvantage, it can be a ‘burden’ when looking for a parking lot and takes a lot of space when it is not used, or only used by one person.<br/><br/>A shared car brings advantages as the freedom of parking it wherever you want for free, having multiple ones available, and access to more city areas. On the other hand, there are also some disadvantages. As people don’t see it as ‘theirs’ you never know how the previous owner leaves it for you. As you share it with a lot of others, you never know what happened before. This also means that personal items cannot be stored or left in the car. If you have special needs, or a baby in a fixed seat, this option becomes even less interesting.<br/><br/>Combining both, and thus having the luxury of a personal car with your personal belongings, that you can share with others brings the best of both. Having the access and privileges the same as a shared vehicle, joining one when your personal car is not available or to extend your network with other Mercedes-Benz owners. All this in your own hands, available when you want, not used when you don’t want to. Together this makes Personal Luxury Sharing the best option for city mobility, Luxus mit gutem Gewissen.","future; mobility; sustainable; luxury; city; automotive; service; design; urban","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:592bcf60-9df9-4986-b2a7-e4cea1a53ae2","http://resolver.tudelft.nl/uuid:592bcf60-9df9-4986-b2a7-e4cea1a53ae2","Shift Happens: Digital Transformation in the Humanitarian Sector: Towards an actionable assessment framework for Digital Transformation in the humanitarian sector","Ziere, T.G.J. (TU Delft Technology, Policy and Management)","de Bruijn, J.A. (mentor); Auping, W.L. (mentor); van Wegberg, R.S. (mentor); van der Veen, Maarten (mentor); Delft University of Technology (degree granting institution)","2020","To provide insight into factors that play a role for DT in the humanitarian sector, a combination of literature and expert interviews was used to identify relevant criteria for the humanitarian sector. In accordance with prevailing literature, these factors have been categorised in people, process and technology factors. People factors include leadership, human resources, culture, organisational structure. Process factors were: alignment operations &amp; IT, long term commitment Management, long term commitment network, long term commitment donor, crisis response, Legal issues. Finally, technology factors included both data and digital. The identified critical DT factors were translated into an assessment framework making use of the CMMi Maturity Model approach. For each factor and maturity level combination, there is an explanation of what a humanitarian organisation has to comply with, before advancing to the next level. This ensures that national societies can generate an overview where they currently are and what steps to take to advance. To adequately deal with the barriers and increase practical applicability of the framework, separate barrier-overcoming-strategies have been formulated.","Digital transformation; Humanitarian Sector; Assessment Framework","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:01dfe848-7c5d-4d7a-b68f-c2f60bcdb4a3","http://resolver.tudelft.nl/uuid:01dfe848-7c5d-4d7a-b68f-c2f60bcdb4a3","Structural Sizing Method for Propulsive Empennage System: Weight Estimation of Ducted Propeller Systems that Provide Longitudinal and Lateral Stability","Stavreva, M.N. (TU Delft Aerospace Engineering)","Hoogreef, M.F.M. (mentor); Delft University of Technology (degree granting institution)","2020","Flight Performance and Propulsion department of Aerospace Engineering, Delft University of Technology has proposed an effective and sustainable solution to the main challenges aviation is currently facing, namely the raising concerns regarding the environmental and health impact of the industry. Delft University Unconventional Concept (DUUC) has a conventional fuselage coupled with clean wing that is expected to facilitate laminar flow. Furthermore, two ducted propellers are positioned aft on the tail cone installed via pylons. The ducts are designed such that they perform multiple functions: they provide sufficient longitudinal and directional stability, resulting in no tail-configuration and possible weight reduction, improve propulsive performance by increasing static thrust, assure higher safety in blade-loss and reduce cabin and community noise. This research proposes a physics-based design-sensitive weight estimation method of such propulsive empennage suitable for conceptual design phase.","Ducted propellers; Weight Estimation; Conceptual design; Propulsive Empennage","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:8657c881-7dfb-4179-abbe-184affb97507","http://resolver.tudelft.nl/uuid:8657c881-7dfb-4179-abbe-184affb97507","The influence of suction on the shear strength of a clay dike","Buiten, H.W. (TU Delft Civil Engineering and Geosciences)","Jommi, C. (mentor); Brinkgreve, R.B.J. (graduation committee); Aguilar Lopez, J.P. (graduation committee); Hopman, P. (mentor); van Duinen, A. (graduation committee); Delft University of Technology (degree granting institution)","2020","","","en","master thesis","","","","","","","","","","","","Applied Earth Sciences","",""
"uuid:f0cd6b41-b314-4c03-8dcd-d751c11c80ce","http://resolver.tudelft.nl/uuid:f0cd6b41-b314-4c03-8dcd-d751c11c80ce","Contextual Personalized Re-Ranking of Music Recommendations through Audio Features Based User Preference Models","Gong, B. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Tintarev, N. (mentor); Houben, G.J.P.M. (graduation committee); Liem, C.C.S. (graduation committee); Delft University of Technology (degree granting institution)","2020","With advancements in Internet and technology, it has become increasingly easy for people to enjoy music. Users are able to access millions of songs through music streaming services like Spotify, Pandora, and Deezer. Access to such large catalogs created a need for relevant song recommendations. Music recommender systems assist users in finding the most relevant songs by consistently matching them with the user’s preference. Accurately representing these preferences is essential to creating accurate and effective song recommendations. User preferences are highly subjective in nature and change according to context (e.g., music that is suitable for running is not suitable for relaxing). Preferences for songs can be based on characteristics of high level audio features, such as tempo and valence.<br/>This thesis proposes a new contextual re-ranking algorithm, which belongs to the group of contextual post-filtering techniques, to leverage users’ contextual information. The algorithm uses two models, a global and personalized model, to model user preferences. These models use audio features to represent user preference in specific contextual conditions. The algorithm is able to re-rank any given music recommendation list. First, we analyze the correlation between audio features and contextual conditions. This analysis shows that the correlations are significant, thus audio features are suitable for representing user preference in contextual conditions. Thereafter, we implement and evaluate the re-ranking algorithm using accuracy metrics on the #NowPlaying-RS and InCarMusic datasets, using various initial recommender algorithms. Results show there<br/>is merit in applying such a re-ranking algorithm to increase recommendation accuracy. The personalized model, given enough historical data, consistently outperforms the global model.","Music Recommender Systems; Contextual Post-Filtering; Audio Features; Personalization","en","master thesis","","","","","","","","","","","","Computer Science | Data Science and Technology","",""
"uuid:bed38b53-935b-4a91-b26c-b825209c1092","http://resolver.tudelft.nl/uuid:bed38b53-935b-4a91-b26c-b825209c1092","Robotic process automation or Chatbots? : A Framework to evaluate the impact of new IT systems on organizational business processes","Kolari, A. (TU Delft Technology, Policy and Management)","Janssen, M.F.W.H.A. (mentor); Werker, C. (graduation committee); Delft University of Technology (degree granting institution)","2020","Today market success and competitive advantage depends on information, and the proper flow of information using information technologies is critical to maintain competitive advantage. To improve their business processes and networks, organizations need to leverage new information systems/information technologies (IS/IT). These new IT systems, which see a constant flux of innovations in software, computational and automation capabilities, include technologies such as robotic process automation (RPA), chatbots, analytics using machine learning and artificial intelligence to name a few. These technologies are currently gaining a lot of traction and popularity as solutions to bolstering an organization’s competitiveness. Organizations are struggling with managing these technologies to maintain competitive advantage. A challenge for organizations is to judge the effectiveness and the impact the new technology would have on their respective business processes before implementing the IT system. Organizations lack a framework that encompasses both the short-term and the long-term view of implementing these technologies as well as the challenges they would face because of these technologies. Through this research, we hope to allay this issue by asking and answering: How can an organization effectively evaluate the impact of new IT systems to improve its business processes? There exist various frameworks and measures in management literature that help organizations choose between multiple IT investments and there exists frameworks such as the balanced scorecard that help organization as performance measuring tools. The IT scorecard, a subset of the balance scorecard, was developed to measure performance of existing IT products and services in use. However the use of existing frameworks to evaluate new IT systems has not been empirically recorded. Existing frameworks also do not take into consideration the uniqueness of individual IT systems and the challenges that are associated with these systems. Other challenges include a greater focus on short- term monetary gains rather than long-term benefits, a lack of standardised parameters for accurate measurements of performance and the ethical challenges that come with using these new controversial technologies. The proposed evaluation framework aims to accommodate the weaknesses of the earlier frameworks. This is why an integrated approach has been taken in the framework. The framework consists of three levels with the evaluation of the IT system conducted at the final level. The top most strategic level offers the organization a perspective on the needs and goals of the business. This allows them to see if the IT system truly aligns with the organization’s strategic objectives. The next level is the business process level. The reason IT systems are introduced into organizational business processes is to improve efficiency of the business process by automating certain activities or reducing certain steps in the process, improve performance of employees or enhance customer experience thereby boosting overall productivity. However, if the IT systems are introduced into the existing business process without correcting for inefficiencies, these inefficiencies are carried into the new business process (the existing business process with the IT system introduced) which is detrimental to the organization in the long run. Therefore analysing the business process helps us identify these gaps existing in the process, solve for them and redesign the business process with the implementation of the IT system. This is achieved at the business process level of the framework. Finally the level of the IT system where its impact on the business process is evaluated. The IT system is evaluated from different perspectives which include the customer, the business value the system provides, the internal processes that are affected by the IT system and the future readiness of the organization to the IT system. This integrated approach, similar to the Balanced and IT scorecards, is augmented and made more dynamic and robust enough to evaluate new IT systems by using KPIs derived by the system developers and engineers as metrics of measurement. The framework also brings to light the ethical values and challenges that come with using new IT systems. To the initial four perspectives, the two new perspectives will provide a more complete view of the impact the IT system has on the business process. The better the evaluation, the better the decision making of the organization. To demonstrate the utility of the evaluation framework, it is applied to the incident management process which is a common business process of the service based enterprises. This business process is analysed and the common challenges found in this process are discussed. In order to improve the business process, two new IT systems are introduced separately; the robotic process automation (RPA) and the chatbot. The proposed evaluation framework is applied to both the situations and the results are compared to see which IT system better improves the business process. This work has shown that including the distinctive nature of the new IT systems such as RPA and chatbots improves the results of the impact evaluation. In case of RPA, aside from the obvious benefits of the technology organizations might not be aware of the improvement in compliance the system provides or the increased quality of data being processed due to fewer errors or the heightened security risks that increased automation can cause. Organizations must also be wary of any underlying biases and stereotyping when implementing chatbots into their business processes. The idiosyncratic properties of each technology can influence the evaluation results and hence the decision on whether the IT system will be implemented. Therefore, by including the indicators specific to these systems, organizations can be aware of the potential impact these systems have on a particular business process. In this way undesired effects such as the inherent challenges of the IT system as well as the consequences of ethical issues are captured. Besides the impact evaluation of the IT system itself, the analysis at the strategic level ensures that there is a strategic alignment with the objectives of the business and the IT system and the modelling of the business process ensures that a detailed analysis can be done to find the inefficiencies and challenges in the business process. Through the proposed framework, this study focuses largely on the IT system and the impact it has on a business process of an organization. Once these IT systems are more prolific in their applications and use, higher levels of evaluation such as at the strategic level will be possible. This will also be very useful for organizations interested in choosing the right IT system for their organizational structure, culture and business processes and therefore be an interesting field for future research. A limitation of this research is that while this paper explains the working of the evaluation framework, a detailed analysis of the application of the framework has not been made. This can be captured by future research through in depth empirical studies with organizations implementing these new IT systems and using this framework to conduct the impact evaluation on the business process. Comparative studies can also be conducted such as comparing this framework with other integrative evaluation approaches such as the multi-attribute utility theory, the voting analytic hierarchy process and information economics.","Evaluation framework; Robotic Process Automation; Chatbots; IT systems; business process management; Evaluation","en","master thesis","","","","","","","","","","","","","",""
"uuid:f999c3fc-d9c2-4e53-9209-d863136b0dc1","http://resolver.tudelft.nl/uuid:f999c3fc-d9c2-4e53-9209-d863136b0dc1","Designing for Usability: A Statistical Disclosure Control Tool for Microdata Sets","Rawat, A. (TU Delft Technology, Policy and Management)","Janssen, M.F.W.H.A. (mentor); Gürses, F.S. (graduation committee); Bargh, M.S. (graduation committee); Delft University of Technology (degree granting institution)","2020","Governments across the world looking to implement Open Government Data (OGD) initiatives undergo many problems. One such problem is the risk to privacy from opening data sets as most of the data is at a microdata level which corresponds to specific individuals. A solution to such a predicament is the application of Statistical Disclosure Control (SDC) techniques on microdata. SDC methods anonymize microdata that reduces the risk of disclosure while also maintaining the value of the data. SDC methods can be applied by using software tools, however, these tools are designed from the perspective of experts or for the purpose of demonstration. Moreover, ongoing research has led to the slow progress in not only the development of these tools, but also their adoption. Resulting in limited support material and even smaller user base. As a consequence, individuals or organizations looking to adopt these tools to satisfy their data privacy objectives cannot use them. Out of many SDC tools, ARX is a stable application that equips its users with an arsenal of techniques to anonymize microdata sets. It also undergoes regular updates, thus keeping pace with the current developments in the field of SDC techniques. Despite this, ARX is not widely used due to its perceived complexity. This thesis addresses the problem of the complexity that is associated with ARX which makes it difficult to adopt them to anonymize their data sets. The thesis provides a solution to this problem by developing a prototype tool which reduces the complexity of SDC techniques through a simplified, user-friendly approach to data anonymization. The thesis does not aim to enhance privacy methods or improve the functionalities of already existing tools by proposing a replacement. The thesis tries to bridge the gap which implicitly occurs when privacy tools are designed from the perspective of experts. It is understood that the protection of private data should only be handled by experts. However, to build that expertise, people have to be introduced to simpler tools without being overwhelmed by the complexity that is immanent with concepts of SDC.","Open Data; Statistical Disclosure Control; Privacy Management; Microdata","en","master thesis","","","","","","","","","","","","","",""
"uuid:2c5f0b4d-966d-4eb1-a26a-ca0893afb8aa","http://resolver.tudelft.nl/uuid:2c5f0b4d-966d-4eb1-a26a-ca0893afb8aa","MultiTune: Dynamic budget allocation for hyperparameter tuning","Dev, Shikhar (TU Delft Electrical Engineering, Mathematics and Computer Science)","Chen, Lydia (mentor); Yorke-Smith, Neil. (graduation committee); Rellermeyer, Jan (graduation committee); Delft University of Technology (degree granting institution)","2020","Hyperparameter optimization(HPO) forms a critical aspect for machine learning applications to attain superior performance. BOHB (Bayesian Optimization and HyperBand) is a state of the art HPO algorithm that approaches HPO in a multi-armed bandit strategy, augmented with Bayesian optimization to drive configuration sampling. However, BOHB requires predefined distribution of fidelities for each tuning task. The challenge in this is that it is impossible to define fidelities a priori, since each machine learning model is uniquely complex and requires different amount of compute resources for convergence. Furthermore, in our empirical analysis, we found that each HPO task rendered different performance trajectories on different fidelity (budget) types. Thus, the challenge of defining fidelities also extends to choosing an optimal budget type. To alleviate these challenges, we present MultiTune: a budget allocation scheme that builds on top of BOHB to dynamically define fidelities for optimization. MultiTune incorporates an algorithm to dynamically choose a preferred budget type for an HPO task, coupled with 2D gradient based budget constraint explorations to enable granular definition of fidelities. Through our empirical analysis, we show that MultiTune can consistently converge to a well performing configuration without significant computation overhead.","AutoML; Hyperparameter Optimization; Multi-fidelity Optimization; Bayesian Optimization; Machine Learning","en","master thesis","","","","","","","","","","","","","",""
"uuid:2f575d8c-1ed4-4cfc-b0a9-6d8f7ad2f7ac","http://resolver.tudelft.nl/uuid:2f575d8c-1ed4-4cfc-b0a9-6d8f7ad2f7ac","Dynamic Electrochemical Promotion of Catalysis","Sharma, S. (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Process and Energy)","Goetheer, E.L.V. (mentor); Delft University of Technology (degree granting institution)","2020","Electrochemical Promotion of Catalysis (EPOC) is a method for enhancing a catalytic reaction by modifying the surface properties of the catalyst through the application of a small amount of current or interfacial potential. It can also be used to enhance the selectivity of heterogenous catalytic reactions. It was first discovered by M. Stoukides and C. Vayenas in early 1980s. This phenomenon can increase the catalytic rate by 10 to 10^5 times compared to the electrochemical rate of supply of ions to the catalyst which is given by Faraday’s law. Therefore, the process is no longer faradaic and hence, it is also known as “Non-Faradaic Electrochemical Modification of Catalytic Activity (NEMCA)"".<br/><br/>Today, the EPOC mechanism has been widely researched by different research groups, and many reactions have been investigated, but unfortunately, no commercial application of the technology is available. The main problem with EPOC is the lower activity per unit mass of the catalyst compared to the commercially used catalysts in conventional reactors. This drawback has been hindering the commercialisation of this idea.<br/><br/>A new route has been proposed, which is called ""Dynamic Electrochemical Promotion of Catalysis (DEPOC). The difference between EPOC and DEPOC comes from the dynamic operation of the system. In DEPOC, the current or the potential over the catalyst is varied periodically at different frequencies, symmetries and amplitudes of the wave-forms. This periodic modification is expected to have a role on selectivity of products and reaction rate.<br/><br/>The main application that is considered for this mechanism is the Fischer-Tropsch (FT) reaction. It is a polymerization process which leads to hydrogenation of carbon monoxide forming liquid hydrocarbons. Controlling the selectivity of this reaction is hard, and normally a wide distribution of carbon chain lengths are obtained. With periodic application of voltage on the DEPOC catalyst, it is expected to be able to control the selectivity of the reaction or in other words the product distribution of the reaction. <br/><br/>In this thesis, the DEPOC effect will be mainly studied from a theoretical perspective. First, the EPOC phenomenon will be analysed and the theory will be extended to the DEPOC effect. The study will be based on understanding the thermodynamics and the kinetics of these mechanisms. Lastly, a conceptual reactor design approach will be studied for the process.<br","catalysis; electrochemical promotion; selectivity; Fischer Tropsch","en","master thesis","","","","","","","","","","","","Mechanical Engineering","",""
"uuid:68b5fa74-66f9-40a7-8b93-4c7fe66895b9","http://resolver.tudelft.nl/uuid:68b5fa74-66f9-40a7-8b93-4c7fe66895b9","Robust Low-cost Planar Positioning Stage: For Smartphone Microscope to Diagnose Malaria in Developing Countries","Zult, M.J. (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Precision and Microsystems Engineering)","Spronck, J.W. (graduation committee); Delft University of Technology (degree granting institution)","2020","In 2018, there were more than 200 million reported cases of malaria worldwide, most of which were in Africa. Adequate diagnostics are required to properly treat the disease. According to the WHO, microscopic examination of a blood smear is the Gold Standard of malaria diagnosis. Currently, it is a labor-intensive process requiring trained personnel, expensive equipment and a lab-environment, which makes it unsuitable for use in field environments. Most of these problems can now be tackled with a smartphone microscope, which automatically identifies malaria parasites in a bloods smear. This solution is low-cost, suitable for use in field environments and excludes the need of a trained microscopist. However, it is still a labor-intensive process: 300 unique fields of view of a blood smear must be examined and doing this by hand takes a lot of time. To solve this problem, an (semi-)automated planar positioning stage is needed, which moves the smear in 2-dof, such that 300 unique images of the surface are acquired. The stage must be low-cost, robust and suitable for field environments. At the moment, there is still a lack of such a stage. Therefore, this research aims to fill that technology gap. The stage is designed to perform a motion pattern in 300 steps, whilst ensuring that the sample remains in focus and that there is no overlap between images. The design encompasses a coarse motion stage stacked atop a fine motion stage (combined, it is an $Rθ stage). The fine motion stage consists of a compliant rotary stage actuated by a stepper motor, generating cyclic motion of 40 steps (220 μm step size). After each cycle, the hand-actuated coarse motion stage displaces the sample one step (500 μm step size). The operation is completed after 8 cycles. A demonstrator is built to investigate whether the stage meets the requirements. The 3σ step precision of both stages ensure no overlap between images (11 μm and 30 μm) and the 3σ focus error during operation is small (δz ≤ 2 μm$). Consequently, we have successfully designed a low-cost and robust stage capable of meeting the requirements for this application. For future work, the stepper motor can be replaced 1-on-1 by a mechanical variant, eliminating the need of a power source and electronic components, whilst significantly reducing costs.","positioning stage; Microscopy; Malaria; Robust; Low-cost; 2-DOF; Planar precision positioning","en","master thesis","","","","","","","","","","","","","",""
"uuid:a30730ae-162b-4dac-92fb-527b39c3b99e","http://resolver.tudelft.nl/uuid:a30730ae-162b-4dac-92fb-527b39c3b99e","Alkaline Pre-treatment of the Air Electrode in a Silicon-air Battery","Prins, Jasper (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Swaaij, R.A.C.M.M. (mentor); Isabella, O. (graduation committee); Wagemaker, M. (graduation committee); Delft University of Technology (degree granting institution)","2020","The objective of this research is to evaluate the effect the air electrode has on the discharge performance of an alkaline silicon-air battery. Experiments are conducted to show that alkaline pre-treatment of the air electrode of up to eight hours leads to an increase in both discharge time and discharge potential of the battery. Furthermore, it is shown that alkaline pre-treatments of sixteen and 24 hours also increase the discharge time and discharge potential of the battery with respect to no pre-treatment. However, the increase in discharge time and discharge potential for these pre-treatments is much smaller than for pre-treatments between three and eight hours. A pre-treatment of 110.75 hours results in a discharge time and discharge potential similar to that of no pre-treatment. In the experiments it is also shown that pre-treating the air electrode with water only, instead of an alkaline solution, has no effect. Finally, the experiments show that discharging the battery at a current higher than 150 μA is not supported. A computer model is then used to evaluate the impact of some qualities of the air electrode on the discharge performance of the silicon-air battery. It is found that the electrical conductivity of the air electrode has very little impact, with a very large increase in electrical conductivity resulting in only a very small increase in discharge potential. The micro-pore surface area in the air electrode has slightly more influence on the discharge performance. Still, a relatively large increase in this parameter only results in an increase of approximately 0.2 V in discharge potential. Both of these parameters are found to have no effect on the discharge time of the battery. To explain the significant increase in both discharge potential and discharge time after alkaline pre-treatment found in the experiments two possible reasons are suggested. Firstly, the adsorption of OH- ions contributing to the oxygen reduction reaction activity of the air electrode material. Secondly, other atmospheric gases besides oxygen might be suffocating the micro-pores of the air electrode. Increased micro-pore area as a result of alkaline pre-treatment could explain the extended time before the air electrode is fully suffocated.","Silicon-air; Battery; Air-electrode; Alkaline; Pre-treatment; COMSOL; Model","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:17c729a6-713b-4f9a-9c11-0a9d4906ee97","http://resolver.tudelft.nl/uuid:17c729a6-713b-4f9a-9c11-0a9d4906ee97","Improving the Meta-Grip: Redesigning for unsupervised use","den Hengst, N. (TU Delft Industrial Design Engineering)","Huysmans, T. (mentor); van de Geer, S.G. (mentor); van der Kamp, John (mentor); Delft University of Technology (degree granting institution)","2020","The Meta-Grip is a tool for climbers to measure hand and finger strength. A climber uses the Meta-Grip by hanging on either a sloper or crimp. The Meta-Grip measures the force through a load cell and transfers the data to a computer where the data can be viewed and analyzed. The current Meta-Grip is built for research. Because of this, the current Meta-Grip cannot be used unsupervised, the embodiment needs improvements and the price of 2520 euros for the costs is too high for the intended market. The current Meta- Grip can only do measurements, an addition to its functionalities would be the ability to also train on the Meta-Grip. This let to the following goal for redesigning the Meta-Grip: “Redesign the Meta-Grip in such a way that it becomes an affordable and recognizable tool that measures finger and hand strength and provides immediate and understandable feedback to the climber, that can be used unsupervised by climbers and is an addition to the currently available training tools.“. <br/><br/>To redesign the Meta-Grip, the design process is structured in four phases: analysis, ideation, concept design and final validation. The following methods were used: literature research, online market research, online surveys, sketching, prototyping, user testing, hosting creative sessions and expert interviews. <br/><br/>The redesigned Meta-Grip is a product-service system. The Meta-Grip, made for fanatic climbers, has a range in holds that differ in type and difficulty. Holds are available in alder wood for skin friendliness or polyurethane coated with quartz sand for high friction, to the user’s discretion. With two load cells and a Bluetooth module , a connection can be established to the mobile phone application of the Meta-Grip. This application, the service, is used to execute measurements, follow exercises and training plans and determine climbing goals. A button on the Meta-Grip allows users to turn the Meta-Grip on and connect the Meta-Grip via Bluetooth to the application on their phone. To instruct the user on how to use the Meta-Grip before the Bluetooth connection is available, instructions are placed on the left side of the Meta-Grip. The system is powered by a 9V battery. The installation of the Meta-Grip is made such that it will fit any normal climbing gym with two M10 bolts. <br/><br/>This research has shown the potential of a redesigned Meta-Grip. Through the application, the Meta-Grip can be used unsupervised and changing the design has made the Meta-Grip more versatile and recognizable for climbers. The cost price is estimate at 120 euros, making it a large price reduction. The next step is to further elaborate the concept and all parts of the product-service system to make it ready for launching the Meta-Grip to the market. <br","Climbing; Hand and finger strength; Hangboard","en","master thesis","","","","","","","","","","","","","",""
"uuid:02052c10-bf63-40d7-a21c-b85554141716","http://resolver.tudelft.nl/uuid:02052c10-bf63-40d7-a21c-b85554141716","The effects of available complexity in verbal commands on robot imitation task performance and user satisfaction","Folmer, Martijn (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Cognitive Robotics)","Broekens, D.J. (mentor); Abbink, D.A. (mentor); Neerincx, M.A. (graduation committee); Delft University of Technology (degree granting institution)","2020","Programming robots with verbal commands is limited by the capabilities of the utilized natural language parser. A simple natural language parser which can understand only keywords and small phrases may be easy to use, but limited in what it can interpret and convey. Alternatively, a natural language parser which understands more complex commands can be used to convey more nuance, but can be more difficult to use and create. It is unclear when having complex verbal commands available is preferable to having only simple verbal commands available. Here we show that using natural language parsers which understand more complex commands are preferable when teaching a robot, both in terms of user preference and objective metrics such as completion time and accuracy, but only when the task is complex as well. During a preliminary wizard of oz experiment, we observed what types of phrases users use to correct the robot during a pose imitation learning task, in order to create multiple natural language parsers which allowed for different levels of complexity in given verbal feedback. In a follow up experiment, in which 24 users utilized these parsers in a similar task, the users reported finding the more complex ones to be more useful and satisfying to use. Additionally, the more complex parsers also led to a higher objective similarity between the pose that the user wanted to convey and the final attained pose by the robot. However, this last result was only found for poses which required a comparably high effort on part of the user.","man-machine interaction; natural language parser; humanoid robot; robotics; pose imitation","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Biomechanical Design - BioRobotics","",""
"uuid:5e7fc380-acbe-4427-82c4-270cc2432885","http://resolver.tudelft.nl/uuid:5e7fc380-acbe-4427-82c4-270cc2432885","Design, fabrication and validation of an ankle-foot orthosis simulator system to optimize mechanical characteristics of AFOs for humans with impaired locomotion","Wouterse, Lars (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Cognitive Robotics)","Harlaar, J. (mentor); Smit, G. (graduation committee); Breedveld, P. (graduation committee); Delft University of Technology (degree granting institution)","2020","The muscles around the ankle (calf and dorsal flexors) are essential for performing activities in daily life, like walking. Neurological and muscular pathologies, such as stroke, cerebral palsy, spinal cord injury, muscle atrophy and post-polio syndrome, affect the ability of voluntary muscle control and/or muscle strength of such muscles. This severely impairs the gait function of many people worldwide. An ankle-foot orthosis (AFO) or ankle brace, which is an assistive device that provides support to the ankle and foot, are in many cases a solution. Therefore, patients are fitted with an AFO to promote a functional gait pattern. To optimize the resulting gait pattern, the mechanical characteristics of the AFO should be matched to the specific malfunctioning muscles of a patient. This especially holds for the stiffness of the AFO. Generally, the AFO should be stiff enough to support the ankle's function, but also compliant enough to not restrict voluntary motion.<br/><br/>The optimal stiffness of an AFO for a patient can vary a lot, as the severity of the pathology differs and hence, the consequences, ranging from spastic to paralyzed muscles. It was found that issuing a sub-optimal AFO in the longer term may contribute to deterioration of physical function and gait. Thus, finding the optimal AFO joint stiffness for this group of patients and improving the speed of doing so, is an important clinical treatment goal.<br/><br/>Currently, this is achieved by a trial-and-error method consisting of fitting the patient with several orthoses. This method is time consuming and can possibly result in a sub-optimal AFO prescription. Ideally a human-in-the-loop setup is developed to find the AFO characteristics during tests using an AFO simulator. The corresponding AFO can then be fabricated and fitted to that specific patient. Hence, increasing the speed and quality of providing an AFO to a patient. However, current solutions are too expensive.<br/><br/>This assignment aims to create a proof of principle of a simplified, affordable, human-in-the-loop solution to vary the AFO stiffness, that enables clinicians to tune the AFO stiffness to a specific patient. This report describes the process of designing a lightweight AFO simulator with a continuously variable stiffness mechanism (VSM) and a predetermined torque-angle curve. The resulting design combines two key elements: A leaf spring of varying stiffness by changing the active length, and a cam part the serves as the transmission between the leaf spring and the AFO mockup. The design was fabricated and then validated with a dedicated AFO stiffness tester (BRUCE) based on manual deflection of the ankle-foot orthosis.<br/><br/>It was shown that the predicted plantarflexion stiffness range closely resembled the measured stiffness values. However, the measured dorsiflexion stiffness range was roughly two times smaller than predicted.<br/><br/>Concluding, the designed AFO simulator can change its stiffness, while being compact and lightweight. The potential of the design has been shown. Now it can be developed further into a fully functional AFO simulator system that can be worn by patients in a clinical gait laboratory setting.<br","Ankle Foot Orthosis; variable stiffness; Human-in-the-loop; AFO; Adjustable stiffness; AFO prescription; Leaf spring","en","master thesis","","","","","","","","2020-08-27","","","","Mechanical Engineering | Biomechanical Design - BioRobotics","",""
"uuid:9cc6b59f-7355-4f65-826c-b219bcd9fad0","http://resolver.tudelft.nl/uuid:9cc6b59f-7355-4f65-826c-b219bcd9fad0","Data Driven Health &amp; Safety Management: Leveraging Real Time Data Management to Improve Health &amp; Safety Environment on Construction Sites","Mathur, Pulkit (TU Delft Civil Engineering and Geosciences)","Wamelink, J.W.F. (mentor); van Nederveen, G.A. (mentor); van Gelder, P.H.A.J.M. (graduation committee); Blaauw, Sebastiaan (graduation committee); Delft University of Technology (degree granting institution)","2020","The construction industry has always been plagued with a high number of accidents and fatalities. The Dutch construction is not an exception in this case and had the highest percentage of workplace accidents among all industries in the national economy, in the year 2019. The high number of accidents and resulting fatalities can be attributed to a plethora of factors. Traditionally, the construction industry has relied on inspections by safety coordinators and supervisors to monitor compliance to the safety regulations by the workers. However, in this manual approach, accuracy of recognizing hazards and making proactive interventions is subject to experience and competency of the supervising personnel and has often proven to be unreliable. Thus, a more objective approach is required to for recognizing hazards and thereby making proactive interventions to prevent accidents.This can only be achieved by analyzing observational data from the construction site in real time. The problem is that with increased use of technology, the sheer volume of data generated by construction projects has surged exponentially. Massive amounts of data are being generated throughout a project’s life cycle but there is a dearth of data management processes which can help construction organizations manage health &amp; safety of workers on construction sites in real time. Thus, this research develops a process map to achieve data driven health &amp; safety management in the construction industry. Various causal factors of accidents in the construction industry and have been identified from literature and co-related with the ones found in archival health &amp; safety data from AECOM Netherlands and opinions of industry experts. The common factors are discerned and later steer the design of the process map. Moreover, type of data, specific data management technologies and best practices to implement these technologies to mitigate the risks, have also been identified. Based on the findings and the researchers’ critical thinking, ten requirement specifications have been formulated. The ten requirement specifications and the identified best practices are then used to design subsets pertaining to the four stages of data management process proposed by Mello et al. (2014), which are data acquisition, data organization, data analytics and data application. Furthermore, an integration framework has been developed, which is used to integrate the individual subsets and develop the final process map. The integrated process map clearly demonstrates checkpoints, placement of data acquisition technologies, data &amp; information flows, actors &amp; responsibilities, to achieve data driven health &amp; safety management on construction sites.The process map is then validated by interviewing experts from construction organizations, which have deployed the innovative technologies used to develop the process map in this research, albeit not in an integrated manner. From the information shared by the experts and their opinions, it has been deduced that the developed process map will secure the construction site against specific risks. Moreover, the developed process is expected to expedite a cultural shift towards a more organized and consistent approach to construction and establish consistency of work environment across an organization’s project portfolio. However, the developed process also has certain shortcomings as well, which in turn may give rise to secondary risks. The findings of this research are not limited to a specific type of construction projects. However, it is more suitable for implementation on large construction projects, in order to realize return on investment. The integrated process is also likely to find suitors in the upstream oil and gas industry, wherein ensuring safety of workers is more complicated. On a holistic level, this research determines that there is immense potential in data acquisition, organization, analytics and application, for the construction industry to exploit. By discerning the primary techniques and real-world solutions, the research establishes the necessary groundwork for the development of a real time health &amp; safety management system, which would help construction organizations in achieving semi-automated management of health and safety conditions on construction sites.","Big Data; Real Time Data Management; Health & Safety Management; Construction Industry","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:85d88ba6-33a2-4517-8ce0-2434aa2adc38","http://resolver.tudelft.nl/uuid:85d88ba6-33a2-4517-8ce0-2434aa2adc38","Effect of Pore Size and Distribution on the PEC Properties of Si-Based Porous Monolithic Water-Splitting Devices","El Makkaoui, Mohammed (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Electrical Sustainable Energy)","Smets, A.H.M. (mentor); de Vrijer, T. (mentor); Delft University of Technology (degree granting institution)","2020","A potential approach to minimizing cabling losses in Photoelectrochemical (PEC) water splitting devices is adapting a wireless stand-alone configuration. With all components integrated into a single device, this configuration also helps in reducing system cost, size, and complexity. The issue with this structure, however, is that the proton transport distance between the electrodes is quite large, as ions need to travel around the cell to reach the opposite electrode. This leads to a pH gradient between the electrodes, resulting in high ohmic losses and risking cross-over between the product gases, which is a safety hazard. This problem can be eliminated by integrating pores into the device that serve as ionic shortcuts between the electrodes, resulting in a Porous Monolithic Photoelectrochemical (PMP) cell. In this thesis, the effect of pore size and distribution on the performance of PMP cells was analyzed in pursuit of finding a range of optimal pore patterns for this application. A theoretical method involving 2D COMSOL simulations of PMP cells is devised to evaluate losses associated with proton transport (Electrochemical) and the active area available for light absorption (Photovoltaic). It was found that optimal pore size and distribution for proton transport trends towards smaller pore dimensions (diameter and pitch). It was also found that for pore diameters between 20 – 80 µm, the PMP cell can retain up to 70% of the ideal (lossless) photocurrent, if the pH gradient can be suppressed to &lt; 0.36 pH units. Moreover, two pore-processing techniques were compared, namely Deep Reactive Ion Etching (DRIE) and Pulsed Laser Drilling (PLD), to determine their suitability for this application. DRIE processed holes can be near perfectly cylindrical compared to PLD processed pores, which have rougher sidewalls and exhibit significantly more tapering, in comparison. However, DRIE requires lithographic patterning, which is a more expensive and tedious process that adds several steps to the fabrication process.","","en","master thesis","","","","","","","","","","","","Electrical Engineering | Electrical Power Engineering","",""
"uuid:0f92bb19-d5ee-41bc-9018-ab2873c2caa7","http://resolver.tudelft.nl/uuid:0f92bb19-d5ee-41bc-9018-ab2873c2caa7","International Competitiveness in the European Monetary Union: The case of Greece","Sevdalis, Panagiotis (TU Delft Technology, Policy and Management)","van Beers, Cees (graduation committee); Storm, S.T.H. (mentor); Pesch, U. (graduation committee); Delft University of Technology (degree granting institution)","2020","The Global Financial Crisis caused by the collapse of the U.S. financial system had immense repercussions for the Eurozone countries. The fall-out of the global crisis turned out to be quite different for the “economically healthy” economies of Northern Europe and “core” and the economies of the Southern “sick periphery”, with the latter still suffering and trying to recover. The problem was acknowledged to be the difference of international competitiveness between the countries of these two groups, while its increase was considered to be substantial for the recovery of those countries which were most forcefully hit from the crisis. Countries of the periphery tried to improve their price/cost competitiveness by implementing internal devaluation and fiscal consolidation policies expecting an improvement on their international competitiveness and balance of payments performance. However, the adopted policies did not bring about the anticipated recovery and extended the period of turbulence for the Member States of the Eurozone and especially for those in South Europe like Greece. The negative experience of Greece and other countries of the periphery confirmed the perceptions of those economists who argued that a country could enhance its international competitiveness in a meaningful and lasting way only through the development of its non-price/technological competencies and structural strengthening of its technological capabilities and national innovation system. Thus, this research investigates how the international competitiveness of Eurozone Member States is affected on the one hand, by its international cost/price competitiveness, and on the other hand by its technological competencies. The econometric findings of this research lead to the recommendation of a policy orientation focusing on the case of Greece.","International Competitiveness; Technological Capabilities; EMU Crisis; Convergence in EMU","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:ffe0739b-5890-493d-a991-b65613757f97","http://resolver.tudelft.nl/uuid:ffe0739b-5890-493d-a991-b65613757f97","From traditional agriculture to AgTech: Towards a Sustainable Business Model","Stoccuto, Stefania (TU Delft Technology, Policy and Management)","Ding, Aaron Yi (mentor); van de Kaa, G. (graduation committee); Delft University of Technology (degree granting institution)","2020","Agriculture is a fundamental element of every economy. However, global issues such as climate change, land deterioration, and a continuously growing population are strongly impacting the sector. It is estimated that by 2050 the population will increase by two billion, reaching 9 billion people to be fed. In the past 34 years, researchers investigated the use of potential technologies such as Artificial Intelligence (AI), Internet of Things (IoT), Machine Learning (ML), robotics, etc. The readiness of these technologies and the positive impact that they have on the sector is proven by numerous studies. However, these technologies are still not diffused enough within common farming practices. Adoption rates are very low, as well as full understanding of the technologies from the farmers’ perspective. Without a shift towards the digitalization of farming practices, the agriculture sector could be damaged, impacting both the future of society and general economy. This is why a change in the actual regime of production is needed: from traditional agriculture to AgTech. In this work, through interviews with winegrowers and analyses of technologies proposed by vineyards start-ups, an understanding of future market development is derived. The concept of sustainability is investigated as one of the major drivers towards the change of regime. More specifically, the study has been conducted on the viticulture domain, tackling in a very context-specific manner the problems concerning this branch of the field. A set of to-be-used criteria for start-ups business model creation is derived by the main needs of the growers and the degree of technology adoption observed. The criteria, or archetypes, have been developed on the base of the Sustainable Business Model Archetypes. A new model is proposed, which is a starting point towards the shift of regime and the digitalization of the agriculture field.","Sustainability; Business Model; Archetypes; Agriculture; Artificial intelligence; IoT","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:092fad41-4cc0-4786-946d-b8196cfe8363","http://resolver.tudelft.nl/uuid:092fad41-4cc0-4786-946d-b8196cfe8363","Drivers and barriers of Reverse Innovation: An exploratory study of factors influencing Reverse Innovation in India","Vipparthi, Sarath Meghna (TU Delft Technology, Policy and Management)","Roosenboom-Kwee, Z. (mentor); Kamp, L.M. (mentor); van Beers, Cees (mentor); Delft University of Technology (degree granting institution)","2020","The paradigm of innovation approaches has changed over the years. This thesis has been designed to understand one such unconventional innovation approaches called as Reverse Innovation. Reverse Innovation is an innovation approach where the innovation is first launched in an emerging country and then transferred to the developed countries. The geographical focus of this research is India and the research aims to document innovations of Indian EMNEs that are an example of Reverse Innovation. India’s recent developments show that the country is in forefront in terms of disruptive and breakthrough innovations that are further launched in developed countries. As India is moving towards being self-reliant and self-sufficient with a motive to boost its economy, Reverse Innovation can be one of the essential innovation approaches to achieve the same. The focus of this thesis is from the perspectives of EMNEs (Emerging-market Multinational Enterprises) and the main aim is to find the list of drivers and barriers of RI (Reverse Innovation). For EMNEs in emerging economies to undergo RI and transcend their innovations to developed countries, they struggle in many ways. For example, in terms of funding, technology, operation costs and so on. However, RI approach also brings EMNES, new employment opportunities, inspires firms to produce cutting-edge technologies, FDI spillovers and more. Hence, the motivation is to understand what are the influencing factors of RI, i.e., drivers and barriers for EMNEs undergoing the RI approach. Documenting this will help the business leaders to grasp the concepts of RI and work with a finer comprehension as they advance to different stages in the RI lifecycle. This may in turn galvanise investors’ interest to fund and support the innovation, thereby strengthening the stakeholder relationships. To attain this objective the research has two major parts of data collection. One from literature review and the other from case studies. Before proceeding with data collection, the first step lies in identifying the different stages of RI lifecycle. Then the first set of lists of drivers and barriers are derived from the existing literature studies which are placed in different stages of RI. Later another set of lists of drivers and barriers are derived from three cases studies which are selected in accordance to the designated stages of RI. The case studies comprise of innovations by three Indian EMNEs. They are Tata Group’s Tata Nano, Godrej Group’s Godrej ChotuKool and the Suzlon Group itself. The cases pertain to both B2B and B2C innovations which cater to different sectors of the society. The case study lists of drivers and barriers are obtained by recording interviews, converting audios to text and in turn the transcribed texts are run on Atlas.ti to form codes. The deliverable of the research is to assemble and analyse both set of lists from literature and case studies. After the data collection, the analysis has been sectioned into four parts. The first analysis is a cross-case analysis which helps to understand the relative occurrences of factors amongst the case studies. It is an aggregate level analysis to understand the holistic occurrence of factors in all the three case studies. It is seen that Tata Nano has more common drivers to Godrej ChotuKool than with Suzlon. Similarly, Godrej ChotuKool has more common drivers to Suzlon. It could mean that as the innovation proceeds or has the potential to further to next stages of RI, a similarity of factors is found in the innovation which is already in the immediate next stage of RI. Similar trend is also seen for barriers. The second analysis is the comparison of all the three case studies together in different categories where it is seen that there are a greater number of common factors in the earlier stages of RI. In the later stages of RI when the innovation is transferred to the developed country, the factors are more towards the international elements that can affect an innovation’s penetration in the country. For example, ‘forex transaction’. Further, more fiscal factors can be seen when the innovation moves to developed countries. For example, ‘relying on tax-benefits’. Whereas in the initial stages of RI, when the innovation is trying to be widespread in the emerging country itself, technical and business-model related factors are seen profusely over other factors. For example, ‘local R&amp;D’, ‘collaboration with partners’, and so on. The third analysis is the case comparison with the literature findings in three stages of RI where the factors are divided according to different categories. It is an adjusted list of all the factors from both literature and case studies. This analysis gives new factors from the case studies which have not been mentioned in the literature before. The final and fourth analysis is the inclusive list of common factors from both literature and case studies. This list includes the factors from literature and the generalizable factors from all the three case studies. There is only one factor that is generalizable from all the three case studies in the drivers and none in the barriers. The topic of Reverse Innovation is fairly novel and the results obtained from this research cannot be generalised to the entire population. However, the sample size of case studies can be increased to provide more factors and views on the already documented factors. It may increase the reliability of the results. This thesis is an addition to the existing list of drivers and barriers of RI from literature which have not been assimilated in a stage-wise manner of RI lifecycle before. This research adds to literature, the practical relevance and experiences of EMNEs with the help of elaborate case studies in terms of RI. The research deliverable may aid future researchers and managers to understand the pivotal factors for EMNEs that undergo RI approach. It captures an essence of Management of Technology course which is to analyse technologies and new approaches and understand the commercial impact for firms. This research also provides an analysis, review and explanation to new and challenging business contexts by discussing challenges faced by case studies which also adheres to the course structure of Management of Technology.","","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:95435515-c2ed-423a-9a9f-880e41dd1253","http://resolver.tudelft.nl/uuid:95435515-c2ed-423a-9a9f-880e41dd1253","A Research on The Changes on the Carbon Emissions in China in The Phase of New Normal","Cai, Shitao (TU Delft Technology, Policy and Management; TU Delft Economics of Technology and Innovation)","Verburg, R.M. (graduation committee); Schröder, E. (mentor); Kamp, L.M. (mentor); Delft University of Technology (degree granting institution)","2020","Global warming is one of the most significant concerns for human beings today in the 21st century. Under this circumstance, countries and regions around the world are taking action to reduce greenhouse gas emissions. China, as the world's largest emitter, plays an important role in reducing carbon emissions worldwide. This paper aims to find the changes in China's carbon emissions from 2000-2014 and find the main driving forces for it which can provide suggestions for China's further carbon reduction strategies.","Environment; CO2; carbon reduction","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:720a5b8e-ec79-472d-bd92-7f078d152fb1","http://resolver.tudelft.nl/uuid:720a5b8e-ec79-472d-bd92-7f078d152fb1","Design of a Pneumatically Powered Hand Prosthesis for Toddlers: Introducing an underactuated 3-DOF linkage-based finger transmission mechanism","Vervaet, joost (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Biomechanical Engineering)","Plettenburg, D.H. (mentor); van der Helm, F.C.T. (graduation committee); Delft University of Technology (degree granting institution)","2020","A large proportion of upper extremity prostheses are abandoned by their users. <br/>Commonly, the main reasons for abandonment are related to comfort, control and cosmetics.<br/>Prostheses are often experienced as too heavy and have limited functionality. <br/>A pneumatic power source is able to provide a relatively high force using a small and lightweight actuator.<br/>However, state-of-the-art pneumatically powered upper extremity prosthesis offer either high grasp forces or the ability to adapt to the size and shape of an object.<br/>This article presents the design of a pneumatically powered hand prosthesis for toddlers, which focuses on being lightweight and highly functional.<br/>An underactuated 3-DOF linkage-based finger transmission mechanism was created and served as a proof-of-principle.<br/>The resulting prototype was 3D printed and tested following an elaborate list of criteria.<br/>The results demonstrate that the mechanism is capable of transmitting an actuator force of 100.5 N to a fingertip force of 32.3 N using 5 bar of pressure.<br/>The proposed mechanism also offers the functionality of adaptive grasping.<br/>The conceptual design and prototype show promising capabilities for the development of a lightweight and highly functional prosthesis for toddlers.","prosthesis; hand; finger; pneumatic; transmission; linkage; adaptive","en","master thesis","","","","","","","","","","","","Biomedical Engineering","",""
"uuid:ced96a5f-8174-473b-a20d-298804db712b","http://resolver.tudelft.nl/uuid:ced96a5f-8174-473b-a20d-298804db712b","3D Robotic Ultrasound System: A 3D Volumetric Ultrasound Imaging System using a CMUT Phased Array and a Robotic Arm","Teye, Joshua (TU Delft Mechanical, Maritime and Materials Engineering)","van Heesch, Chris (mentor); Dekker, R. (mentor); Hendriks, B.H.W. (graduation committee); Theuwissen, A.J.P. (graduation committee); Delft University of Technology (degree granting institution)","2020","Diagnostic imaging is a fundamental requirement for the effective treatment of about 25 % of patients globally. Ultrasound imaging is considered the safest, least expensive and most convenient diagnostic imaging modality. Its widespread adoption has been in the area of 2D imaging. However, the accuracy of diagnosis with 2D ultrasound imaging is highly dependent on the experience and expertise of the sonographer because the sonographer has to mentally create a 3D impression from multiple 2D images of the region of interest and this could lead to erroneous diagnosis. 3D ultrasound imaging addresses this concern, however, it drives up the cost of ultrasound imaging. Also, disadvantages such as difficulty in taking quality images, prolonged time in learning how to effectively take these images and human distress during the acquisition of these images have been reported. By leveraging the high level of precision, accuracy and maneuverability provided by robotic systems in conjunction with low-end ultrasound imaging platforms, 3D ultrasound images can be captured, the problem of human distress alleviated and subsequently reducing the cost of 3D ultrasound imaging. This project sought to explore the feasibility of designing a low-cost 3D ultrasound robotic system. The design followed a distributed system approach using ROS (Robotic Operating System) where the data acquisition decoupled from the processing and visualization unit. The performance of the design was tested by constructing 3D ultrasound images of custom made phantoms. These results were compared with 3D ultrasound images of the phantoms acquired using the Philips EPIQ 7 - a high-tier ultrasound machine. The results obtained with this design had a low resolution in comparison with those obtained with the Philips EPIQ 7 however, a 3D point cloud representation of the object embedded in the phantom can be seen. Also, a full 3D image of the phantom could not be acquired due the transducer movement limitations of the design. This design successfully demonstrates the feasibility of integrating low-end electronics with robotic systems to acquire 3D ultrasound images.","Ultrasound; CMUT; Robotic; 3D","en","master thesis","","","","","","","","","","","","Biomedical Engineering","",""
"uuid:934e3c57-0c1d-41e8-9a53-ecfeda0fbb63","http://resolver.tudelft.nl/uuid:934e3c57-0c1d-41e8-9a53-ecfeda0fbb63","Design and Development of Integrated Displacement Sensors for Engineered Heart Tissue Platforms","Shojaei Baghini, Mahdieh (TU Delft Mechanical, Maritime and Materials Engineering)","Mastrangeli, M. (mentor); Dankelman, J. (mentor); Sarro, Pasqualina M (graduation committee); Ghatkesar, M.K. (graduation committee); Delft University of Technology (degree granting institution)","2020","Cardiac cells derived from stem cells exhibit cellular contractions when cultured in vitro. They can be integrated with polymeric platforms consisting of micropillars, which act as anchors and pre-load for engineered heart tissue (EHT). The biomechanical response is often characterized using optical microscopy to track the displacement of pillar tops and assess the contractile properties of the EHT. This requires bulky instruments with sophisticated imaging algorithms, which are often prone to optical misalignment. The efficiency of the imaging algorithms is highly dependent on the structure of the top surface of the pillar.<br/>In this thesis, an alternate approach to microscopy is presented. A novel sensor is designed, fabricated and characterized which converts the pillar response such as strain or displacement to a measurable output which can be further conditioned and read-out by an instrumentation module. As the first step, in-depth multiphysics simulations have been carried out analysing the response of the micropillar system integrated with sensors utilising piezoelectric, piezoresistive and capacitive sensing techniques. A quantitative and qualitative comparison based on the derived simulations was performed and the most optimal sensing platform was chosen.<br/>Spiral sensors inspired from co-planar waveguides are designed and developed in such a manner so as to provide seamless integration with the process flow for the micropillars developed at ECTM and fabricated at EKL in TU Delft. The integrated sensors exhibit a change in capacitance due to warping of fringe electric field lines with the application of force to pillar boundaries. The simulated sensitivity of the sensors are 1.51-4.86 pF/N depending on the metallization ratio and average path length.<br/>The sensors are fabricated via clean room processing and encapsulated within two layers of PDMS. On account of their low line widths (5−40 um), they have been successfully patterned with inductively coupled plasma. Simultaneously, the steps required for the fabrication of the EHT platform have been carried out.<br/>The characterization of the sensors has been performed using on-wafer probing and equivalent lumped element circuitry also derived. The resulting capacitances are in excellent agreement with the optimised simulations in COMSOL. The sensors exhibit a stable base-line response to AC signals with frequencies up to 1 MHz and voltages up to 20 Vrms, the highest limits to the test signals of the instrumentation setup. Preliminary characterization of the sensor’s response to mechanical loading exhibits promising outcomes. The read-out circuitry of the time varying capacitors is simulated in SPICE leading to a successful first level assessment of the designed novel sensors for biomechanical characterization of tissues grown on EHT platforms.","Organ-on-a-chip; Multiphysics; MEMS; Capacitive Sensor; integrated sensors; Engineered Heart Tissue","en","master thesis","","","","","","","","2021-08-27","","","","Biomedical Engineering","",""
"uuid:d8e3b242-ec5a-4ddf-92df-4f5cc237d376","http://resolver.tudelft.nl/uuid:d8e3b242-ec5a-4ddf-92df-4f5cc237d376","Spatially explicit WEF modelling in transboundary river basins: A new methodology to study the value of cooperation in regional water management","Verhagen, Jeroen (TU Delft Civil Engineering and Geosciences)","Abraham, E. (mentor); van der Zaag, P. (graduation committee); Pande, S. (graduation committee); Delft University of Technology (degree granting institution)","2020","Water, energy and food resources are fundamental for human survival and are critical for supporting economic development. However, ensuring adequate supply is a major concern for the entire world, specifically in some countries and regions. Under the pressure of population growth, economic development, international trade, urbanization, diversifying diets, cultural and technological changes, global projections indicate a significant further increase in demand for water, energy and food over the next decades. Moreover, the development of these water, energy and food resources are intertwined. As a result, when demand grows, but resources are no longer abundant, competition between sectors increases. Especially in regions with upstream-downstream water connectivity, a national sectoral approach may result in friction, a decrease in mutual trust and international conflicts. On the other hand, the synergistic effects associated with regional resource coordination can contribute to improved resource availability and downstream livelihoods.<br/><br/>To overcome the shortcomings of the current generation of hydro-economic and WEF-nexus models in describing resource cooperation at regional level, in this study a new WEF-framework has been developed in which the heterogeneity in agro-climatic, socio-economic and resource availability, as well as the description of water and electric conveyance infrastructure is included spatially and temporally explicitly. The aim of this research is to create an integrated WEF-framework and to investigate the possibilities for, the relevance of and the challenges and difficulties associated with the implementation of such an integrated model.<br/><br/>The proposed framework includes the river conveyance infrastructure in a multi state river basin by means of a dynamic network model. In addition, a novel approach is used to describe both irrigated and rainfed agriculture in great detail on a regional scale, enabling a good representation of crops with multiple growing cycles per season, a distinction between annual and perennial crop management and the inclusion of agricultural losses. The framework is implemented as a model predictive control (MPC) problem. In this control problem, the reservoir operations and agricultural planning resulting in maximum economic value creation with the available resources are determined with the help of a non-linear problem solver. Receding horizon control accomplishes as part of the MPC framework feedback against uncertain disturbances (e.g. deviations in climate forcing) by applying only the optimal outputs in the first instance of the horizon in simulation and then updating the system states using new information. In addition, this control technique enables information exchange between riparian states within each MPC iteration. This allows us to add two new cooperation scenarios between the often studied scenarios of unilateralism and full coordination, with which the value of information exchange of river flows and trade flows can be studied. <br/><br/>Once developed, the framework is applied in the Eastern Nile basin. The Eastern Nile Basin is home to a large and rapidly growing population. Along with future population growth, changes in socio-economic conditions are expected, which will improve the coverage of the electricity grid and alter diets and water consumption. To meet the growing demand for food and energy, the Nile riparian countries have developed, and intend to further develop, their water resources. However, currently this development takes place unilaterally and can thereby threaten the livelihood in the downstream countries that are highly dependent on these water resources. The application of the proposed model framework aims to describe the qualitative and quantitative benefits and impacts of further collaboration in resource management within a predefined structural environment.<br/><br/>Simulation experiments with a monthly time step are conducted over a historical period between 1990-2010 and a future period between 2020-2040, by screening and incorporation of data on structural, socio-economic and climate constraints and demands. In addition to the four named cooperation scenarios, experiments are compiled to determine trade-offs between hydropower and agricultural water demand, the robustness of the solutions to imperfect climate foresights and the economic trade-offs related to different levels of agricultural self-sufficiency.<br/><br/>Comparative research with trade data from the FAO database indicates that historically every riparian state in the Eastern Nile basin could have benefited from the proposed integrated resource management, even in the unilateral national cases. Despite the variability in extent, all proposed and included forms of cooperation would have been beneficial for all individual states. Regionally, the flow-information, trade-information and regional coordination scenarios could have provided additional benefits of $32, $37 and $50 billion respectively throughout the period. Sharing information about the expected border flows would have generated, relatively in Sudan and absolutely in Egypt, by far the largest additional benefits. However, these benefits appear to correlate strongly with perfect climate foresight information. Because of its upstream location, Ethiopia could not have benefited economically from this flow information sharing. Overall, the benefits of resource optimization would have been relatively small in Ethiopia due to the limited infrastructure present during this period. In addition to the quantitative benefits mentioned, regional coordination also would have enabled the states to increase their resilience against long-lasting droughts and price fluctuations in the external market.<br/><br/>Results of the future model experiments suggest that every state will be disadvantaged in a regional coordinative scenario. To correct these physically and mathematically incorrect results, the current soft constrained implementation of the non-smooth complementarity relations for the reservoir filling process will have to be reconsidered. These non-smooth functions are the first out of three major difficulties encountered when implementing the proposed framework. Other difficulties arise when describing processes on different time scales (e.g. annual crop seasons) and when keeping the problem robust (in case predictions deviate from real events).<br/><br/>Overall, the case study illustrates that the proposed framework can account for spatial and temporal multisectoral trade-offs while finding non-trivial solutions for varying forms of national and regional cooperative resource management. Moreover, the operational resource reallocation choices proposed by this new framework and the spatial diversity in productivity that were discovered indicate that inadequate inclusion of these heterogeneities in WEF-nexus studies results in incomplete and potentially incorrect conclusions<br","WEF model; Eastern Nile basin; MPC; IWRM; Cooperation; Transboundary basins; Optimization; SDG; Resource management; Surface water reservoirs; Hydropower; Agriculture","en","master thesis","","","","","","","","2021-08-31","","","","","",""
"uuid:acbd73bf-3547-456b-8f9d-4b72d5b7b54a","http://resolver.tudelft.nl/uuid:acbd73bf-3547-456b-8f9d-4b72d5b7b54a","Automatic detection of waterbeds in shallow muddy water bodies in the Netherlands using green LiDAR","Alexandridis, Vasileios (TU Delft Architecture and the Built Environment; TU Delft Urban Data Science)","Peters, R.Y. (mentor); Stoter, J.E. (graduation committee); Delft University of Technology (degree granting institution)","2020","Bathymetric Airborne LiDAR technology is used to map the depth of water bodies. It uses a green light sensor which is able to penetrate the water surface and reach the bottom part of the interesting water areas. However, water conditions affect the capability of the green laser penetration. Factors such as the water clarity, the water turbidity (waves) and the vegetation are some of the crucial restrictions for green light to penetrate the water; particularly in shallow inland water areas. This research examined the capability of green LiDAR data to improve the bathymetric surveys in case of muddy and shallow inland Dutch water bodies. The potential of green LiDAR increases as the monitoring of water depths is getting easier, faster and more efficiently in terms of cost than manual GPS measurements. The main challenges of this thesis are concentrated both on the existence of various sparse and dense parts in the point-cloud and on the limitations of the data in terms of quality due to the not ideal water conditions. Specifically, this thesis presents a workflow with required procedures that aim to process a raw green LiDAR point clouds of water bodies and then classify them into three classes: water surface, underwater and bottom points. Pulse and Neighbourhood based algorithms were implemented in order to perform a classification process with high level of automation. Point characteristics such as intensity, number of returns, return number were analysed per pulse. Voxelization was used as a spatial method to divide the 3D space into water columns (3D Voxels). The spatial distribution of the water points into the water columns was examined based on different factors such as elevation, density, intensity. By comparing and partially combining those methods the detection process was improved to deal with shallow and muddy water bodies. A classification confidence value was calculated and stored for each potential bottom point. The resulting output is a classified green LiDAR point cloud based on the confidence values. Using elevation, density and confidence values, raster DTMs with multiple bands were created for each water body. To sum up, this thesis proposed an efficient workflow to process and automatically classify green LiDAR water-body data using both voxel and pulse based methods.","Green Bathymetric LiDAR; Pulse-based method; Voxelization; Waterbody; Point cloud data; Classification","en","master thesis","","","","","","","","","","","","Geomatics","",""
"uuid:097e469c-9937-463c-8f00-782ef2b18454","http://resolver.tudelft.nl/uuid:097e469c-9937-463c-8f00-782ef2b18454","City Hall of Brussels: a community's gathering point","Sideri, Christilena (TU Delft Architecture and the Built Environment)","De Vocht, S. (mentor); Parravicini, M. (graduation committee); Rosbottom, D.J. (graduation committee); Pimlott, M. (graduation committee); Delft University of Technology (degree granting institution)","2020","The project is about the design of the city hall of Brussels as a critique of the proposal of BruCity. One of the characteristics of Brussels is the heterogeneity at its urbann fabric and most of all its society. So, this project is aiming to investigate the design of the building that can work as a gathering point, strength the bonds between the people and bridge the gap between administration and citizens, by adding new uses to the building and introducing the nature to its interior.","City Hall; administration building; offices; nature","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences","",""
"uuid:6ab4964d-4215-433f-81d1-60417eab369a","http://resolver.tudelft.nl/uuid:6ab4964d-4215-433f-81d1-60417eab369a","Optimal Sensor Placement for Calibration-Involved Radio Astronomy Imaging Applications","Zhang, Kaiwen (TU Delft Electrical Engineering, Mathematics and Computer Science)","Leus, G.J.T. (mentor); Wijnholds, Stefan (mentor); Uysal, F. (graduation committee); Delft University of Technology (degree granting institution)","2020","In radio astronomy (RA), one of the key tasks is the estimation of the celestial source powers, i.e. imaging. To maximize the performance, it is crucial to optimize the receiver locations before the construction of a telescope array. However, although system calibration is an integral and crucial process of imaging, it has rarely been addressed for RA sensor placement problems previously. This motivates us to investigate whether incorporating calibration can result in better array designs. In this thesis, we focus on the calibration of the sensors’ complex-scalar gains in particular, which are treated as nuisance parameters for the image estimation. The associated Cramer-Rao bound (CRB) is derived and employed as the design criterion. The nonlinear CRB-based sensor placement problem is cast as an NP-hard combinatorial optimization problem, and we adopt two approaches to solve such by approximation: (i) greedy algorithm and (ii) convex optimization with semidefinite relaxation. The former is chosen for simulations due to its good performance and lower computational complexity. Extensive simulations shows that compared to the calibration-excluded design, the proposed one only provides slight improvements to the imaging quality. However, the proposed array demonstrates the potential of accelerating the convergence of the gain estimation procedures. Through further investigation, we conclude that the lack of imaging quality improvident can be a consequence of the gain and image being near-orthogonal parameters.","Sensor selection; Radio interferometry; Cramér–Rao lower bound; Greedy algorithm; Convex semidefinite relaxation","en","master thesis","","","","","","","","","","","","Electrical Engineering | Circuits and Systems","",""
"uuid:0aedd11f-905c-47da-afd4-2d147659a0ec","http://resolver.tudelft.nl/uuid:0aedd11f-905c-47da-afd4-2d147659a0ec","The effect of climate change on the residual lifetime of the Haringvliet and Hollands Diep","de Waal Malefijt, W.B. (TU Delft Civil Engineering and Geosciences)","Kok, M. (mentor); Kanning, W. (graduation committee); van den Eijnden, A.P. (graduation committee); Knops, D. (graduation committee); Slomp, R. (graduation committee); Delft University of Technology (degree granting institution)","2020","","Haringvliet; Hollands Diep; Fragility curves; Climate Change","en","master thesis","","","","","","","","","","","","Civil Engineering | Hydraulic Engineering","",""
"uuid:7d524bb3-f194-4deb-8591-aa9442ad562c","http://resolver.tudelft.nl/uuid:7d524bb3-f194-4deb-8591-aa9442ad562c","Assessing circular buildings: A balance between circularity and life cycle costs of a building","Rudraraju, K. (TU Delft Civil Engineering and Geosciences)","Wamelink, J.W.F. (mentor); van den Boomen, M. (graduation committee); Schraven, D.F.J. (graduation committee); Boks, Charles (graduation committee); Muntinga, Annebeth (graduation committee); Delft University of Technology (degree granting institution)","2020","Being one of the world’s largest waste generator, the construction industry is responsible for a train of events such as global warming, climate change, and depletion of natural resources. Materials are exhausted globally to a large extent and the waste produced in the process is not treated properly. A “take-make-dispose” or popularly known as linear economy is the process that is adopted to treat the waste currently, where large quantities of resources end up as waste after demolition of the building. This grabs our attention towards the concept of Circular Economy (CE) with the goal to potentially minimize the pending issues arising from the construction sector through recirculation of building materials. However, due to the unfamiliarity of its economic feasibility, many are still reluctant for investing in circularity as they believe circular construction to be more expensive. The main challenge is to overcome the lack of understanding of the available circular strategies and their effect on their business. Therefore, the objective of this research is to investigate how buildings can be made more circular. Furthermore, the aim is to compare the alternatives based on the life cycle costs and a circularity measure, so that stakeholders are in a better position to invest/favor circularity in general. Finally, the objective is to present a way to invest in circular projects by merging the methods used in this study.<br/><br/>Firstly, literature review was conducted to develop a better understanding of the most important concepts in relation to this research. It reveals the need for several methods to conduct the research, and hence three methods are further elaborated. An inventory of possible circular interventions was made and categorized based on strategies and layers of the building. The methods discussed were applied to a case study. The application of interventions on the base case intends to gradually increase the circularity of the building. This gradual increase in circularity calls for a comparison of a traditional building with its circular twin. Based on the analysis, it can be concluded that a comparison as such can help in a parallel tracking of both circularity level and life cycle costs of a building, which in turn aids in taking both the factors into account for decision making. Thus, both the costs and circularity of a building are quantified. <br/><br/>The main findings are: A building can be made more circular by searching for circular activities that can replace a non-circular activity by using a circular strategy framework- in this case, R-strategy was used. The application of circular activities or interventions can be categorized layer-wise to carefully examine the impact of the activity on the circulatory level and costs associated with the building. This can be done by diving the building into different layers- in this case, Stewart Brand layers was used. The circularity of the building is to be increased gradually. Further, several alternatives can be generated to analyze the best-case scenario that can justify both the circularity and cost of a building. This is done by using a circularity measure and life cycle costing- in this case, material circularity index and discounted cash flow analysis were used respectively. Finally, the results can be analyzed by quantifying both circularity and cost. This makes sure circularity in a building is not compromised for the costs associated with the building. This way, stakeholders are better aware of the opportunities and can make better decisions in selecting circular projects which could lead to enhance the acceptance of circularity within the building sector.<br","Circular economy; Circularity; Built environment; Life cycle costing; Circular buildings; Circular interventions; Sustainability","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:7bedb60a-ced8-4fcf-97ca-80208861a413","http://resolver.tudelft.nl/uuid:7bedb60a-ced8-4fcf-97ca-80208861a413","Safe Reinforcement Learning for Automated Vehicles","Cornet, R. (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Cognitive Robotics)","Pan, W. (mentor); Wisse, M. (graduation committee); Shyrokau, B. (graduation committee); Zheng, Y. (graduation committee); Delft University of Technology (degree granting institution)","2020","Fully automated vehicles have the potential to increase road safety and improve traffic flow by taking the human element out of the driving loop. They can also provide mobility to people who are unable to operate a conventional vehicle. Safe automated vehicles must be able to respond in emergency situations or drive on slippery roads in bad weather conditions. Therefore it is crucial to have a safe and robust control strategy that can use the full handling capabilities of the vehicle.<br/><br/>This thesis presents how safe reinforcement learning can be used to design a steering policy that can drive an automated vehicle at the limit of friction.<br/><br/>The steering policies are trained using the Lyapunov Safe Actor-Critic (LSAC) algorithm. LSAC is a combination of the Soft Actor-Critic (SAC) algorithm and a Lyapunov stability analysis to solve constrained control problems.<br/><br/>The performance of LSAC is tested in a vehicle simulator against SAC and Model Predictive Control (MPC) in a series of tests that include changing lanes at different speeds, recovering from a destabilizing collision, and driving on a race track at the limit of friction.<br/><br/>The experiments show that LSAC outperforms MPC and SAC control strategies in terms of safety and vehicle stability. LSAC can recover from larger disturbances than MPC and SAC. A control strategy is presented that will keep the vehicle stable when driving at the limit of friction but can use the maneuverability of an unstable vehicle when is it necessary to avoid dangerous situations. Additionally, a policy is presented that can find the fastest way around a race track while staying within the track limits. <br/><br","safe reinforcement learning; Reinforcement Learning; Automated Vehicles; Automated driving","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Vehicle Engineering","",""
"uuid:c6dde33a-3400-4472-9674-b8167a53528d","http://resolver.tudelft.nl/uuid:c6dde33a-3400-4472-9674-b8167a53528d","Joint Estimation of Object and Aberration for High Numerical Aperture Microscopy","Trevisan, E. (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Delft Center for Systems and Control)","Verhaegen, M.H.G. (mentor); Nguyen, H.T. (graduation committee); Delft University of Technology (degree granting institution)","2020","Microscopic imaging has a resolution that is often far from the diffraction limit due to aberrations induced by the optics or by the sample itself. It is therefore of interest sensing these aberrations either directly or indirectly to improve image quality in post-processing or with adaptive optics. To avoid the use of extra hardware, several techniques are available to algorithmically retrieve aberrations in microscopy, but they often require images of an isolated point source, which is seldom a reasonable assumption as even single fluorescent beads often have a non negligible size. A different technique, known in literature joint estimation or phase diversity, was first developed by Gonsalves to estimate phase aberrations when imaging extended objects.<br/>In this master thesis we will derive a simple physical model that accounts for the vectorial nature of light and use it to expand the algorithms derived from Gonsalves seminal papers. We will show with numerical simulation that the effect of polarization is indeed non negligible when imaging through high-NA lenses, and therefore a vectorial model can substantially decrease model deviation and improve the quality of the estimates. The novel algorithm is thoroughly tested both in simulation and with experimental data.","phase retrieval; Microscopy; optimization; system identification","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:7ff9b284-0b7b-4f70-8ed5-4d81f1eb113f","http://resolver.tudelft.nl/uuid:7ff9b284-0b7b-4f70-8ed5-4d81f1eb113f","Turbofan Condition Monitoring using Evolutionary Algorithm based Gas Path Analysis: at KLM Engine Services","Rootliep, Tim (TU Delft Aerospace Engineering)","Visser, W.P.J. (mentor); Delft University of Technology (degree granting institution)","2020","In this thesis, a hybrid Gas Path Analysis (GPA) tool is developed for next-generation turbofan engine condition monitoring purposes at KLM Engine Services. The main drawback of these new engines is that fewer gas path sensors are installed. However, this is compensated by a greater quantity in-flight data, including information on bleed valves, active clearance control systems and variable geometry positions. With the availability of this data optimal near steady-state operating points can be selected and a Multiple Operating Point Analysis (MOPA) can be implemented. Then, an Evolutionary Algorithm (EA) optimization approach is combined with the non-linear GPA program GSP in order to predict engine component health parameter deviations. Using this method it is possible to track fan, LPC, HPC, HPT and LPT deterioration. The tool has been verified with simulated data and validated using on-wing data from the General Electric GEnx-1B engine.","Gas Path Analysis; Condition Monitoring; Turbofan; Evolutionary Algorithm - EA; Multiple Operating Point Analysis - MOPA","en","master thesis","","","","","","","","2025-08-27","","","","Aerospace Engineering","",""
"uuid:fb7170b2-09e4-4e18-94bc-f83eb5167e5a","http://resolver.tudelft.nl/uuid:fb7170b2-09e4-4e18-94bc-f83eb5167e5a","Visual Analysis for Narcolepsy","Bhaskar, Priyanka (TU Delft Electrical Engineering, Mathematics and Computer Science)","Vilanova Bartroli, A. (mentor); Westenberg, Michel (mentor); Brinkman, W.P. (graduation committee); Höllt, T. (graduation committee); Delft University of Technology (degree granting institution)","2020","Narcolepsy is a chronic neurological condition that results from the dysregulation of the sleep-wake cycle occurring in an early stage, specifically in adolescence. Patients with narcolepsy experience excessive daytime sleepiness, cataplexy, hypnagogic hallucinations, sleep paralysis and disturbed nocturnal sleep and these symptoms together form the narcolepsy symptom pentad. However, the symptoms related to narcolepsy are not limited to the pentad and cover a broad range of other symptoms, some of which are not directly related to sleep, like, increase in weight, binge eating, anxiety, agitation. Therefore, researchers from sleep medicine center, Kempenhaeghe wanted to understand how a selected set of 20 symptoms are related to narcolepsy. <br/><br/><br/>In this thesis we present a visual analytics framework to help the researchers understand these symptoms in relation to narcolepsy and identify patterns among them. Using relevant attributes interesting population subsets are formed and the results are compared. The thesis comprises of three main tasks, the first being visualizing the distribution of individual attributes of patients in which a symptom is present and not present and for severity level. Then, pairs of symptoms are visualized based on their agreement and association to identify groups of related symptoms and trends present. Lastly, multiple symptoms are visualized to identify patterns amongst them. <br/><br/><br/>The visual analytics framework was implemented and evaluated through a user study. The study showed that the visualization developed was useful in gaining new insights to form interesting hypothesis along with possible extensions for future development. This is the first step towards an extensive visual analytics framework in the study of narcolepsy symptom spectrum.","Visual Analytics; Narcolepsy; Symptom Analysis; Distribution; Patterns; Clusters; Comparison","en","master thesis","","","","","","","","","","","","","The Narcolepsy Monitor: insight in narcolepsy",""
"uuid:190e87c7-9309-470f-a821-43b7c3b8867b","http://resolver.tudelft.nl/uuid:190e87c7-9309-470f-a821-43b7c3b8867b","Computationally Efficient Conical Horn Antenna Design: A theoretical design approach","Dash, Tworit (TU Delft Electrical Engineering, Mathematics and Computer Science)","Yarovoy, Alexander (mentor); Prinsloo, David (graduation committee); Delft University of Technology (degree granting institution)","2020","In this thesis, a computationally efficient model is proposed to determine different performance parameters of a conical horn antenna of arbitrary profile numerically over a wide range of frequencies. The model is developed using mode matching technique that solves the waveguide junction problem and an integral equation technique that solves the waveguide aperture free-space transition. It has functions to evaluate the S parameters, near-fields and far-fields of the antenna. Rigorous testing of the proposed novel technique has been done using MATLAB and the results have been verified by comparing them with the results obtained from commercial tools like FEKO and CST. This technique is capable of finding the performance parameters of the antennas faster than the available solvers in commercial tools like FEKO and CST. Furthermore, various goal functions are proposed for the optimization of some of the performance parameters such as the S parameters, the cross-polarization levels, and the aperture efficiency. These goal functions can be used to find optimum horn antenna feed profiles for radio astronomy applications.","Antenna design; electromagnetic modeling; Electromagnetic theory; ASTRON; SKA; Theoretical framework","en","master thesis","","","","","","","","2022-08-27","","","","","SKA",""
"uuid:87864337-0fbb-49f2-b800-d845ea5c9900","http://resolver.tudelft.nl/uuid:87864337-0fbb-49f2-b800-d845ea5c9900","Compliant shape adaptive chicory gripping: for robotic sorting processes","Hester, Thomas (TU Delft Mechanical, Maritime and Materials Engineering)","Smit, G. (mentor); Breedveld, P. (graduation committee); Mirzaali Mazandarani, M. (graduation committee); Delft University of Technology (degree granting institution)","2020","This thesis contains the design process of a compliant shape adaptive chicory gripper for robotic sorting processes. The robotic sorting line consists of an input and output conveyor-belt. The input line contains unsorted chicories which are scanned by a robotic vision system. Overhead FlexPicker robots, equipped with chicory grippers, sort the chicories size by size onto the output line. The output line can contain a transportation crate or flowpack in which the chicories will be packed and shipped after sorting. Chicories are vulnerable for internal and external damages when touching the outer skin which makes robotic sorting difficult. The acceleration forces performed by the robot requires a strong but gentle grip on the chicory without any damaging marks. By designing a specific compliant shape adaptive gripper, sorting can be done faster, cheaper and more accurate than manual sorting. Current patents, academic literature or business applications had no solution for this chicory gripping problem. The design process for a suitable gripper started with an analysis of current patents and literature within compliant gripping in general. This provided insights in the the possibilities of compliant gripping. Based on the design requirements for the robot sorting setup, several concepts are obtained and selected. The concepts have been translated into four working gripper prototype layouts which are evaluated on force and damage requirements. Based on the results of these experiments, a first iteration prototype was made. Three additional optimizing iterations were needed to result in a prototype which reached the damage and force requirements. Further evaluation of this prototype proved a sufficient performance on robustness, endurance, operational speed and food grade requirements. The iteration 4 prototype reached therefore 17 of the total 19 gripper design requirements. To be able to accomplish the two remaining requirements, several recommendations are provided for a final gripper end product which is ready for industrial application.","compliant; gripper; chicory; shape; adaptive; robotic; sorting; processes; 3D Printing; additive manufacturing; robot; gripping; grasping; grip; end effector","en","master thesis","","","","","","","","2022-08-27","","","","","",""
"uuid:becf8006-b462-454c-808d-d28ef226dea1","http://resolver.tudelft.nl/uuid:becf8006-b462-454c-808d-d28ef226dea1","Musculoskeletal Driver Model for the Steering Feedback Controller: Investigating the influence of driving posture on the steering response","Schenk, Lydia (TU Delft Mechanical, Maritime and Materials Engineering)","Happee, R. (graduation committee); Shyrokau, B. (mentor); Schwab, A.L. (graduation committee); Bruzelius, F. (mentor); Chugh, T. (mentor); Delft University of Technology (degree granting institution)","2020","Haptic feedback from the steering wheel is one of the most important cues for driver to vehicle interaction. The right feedback is provided by ensuring that the haptic controller provides the required steering feel. Steering feel assessment and design is divided into a subjective and objective approach. The subjective approach entails experiments on the proving ground during which steering parameters can be tuned by steering experts. However, using only subjective assessment is time-consuming, costly and non-repetitive. Since there is no direct method to tune the steering feel objectively, a driver model is required to find a mathematical justification in the mechanical interaction between driver and vehicle during steering. A 3-dimensional multibody arm model is constructed to investigate the influence of driving posture on the nonlinear steering response. It was found that the torque acting in the shoulder joint is higher than in the elbow. The relation between joint torque and joint angles is<br/>linear in the shoulder, whereas nonlinearities were found in the elbow joint. Nevertheless, a change of driving posture (i.e. a change of haptic interface) leads to a different steering response. Findings from the driver model were validated by two steering experiments. Muscle contraction was measured in order to analyse the forces acting on the joints.<br/><br/>This study shows promise to lead to a different approach for tuning steering parameters. Further investigation and detailed experiments are required to convert this driver model into a method to tune steering feel objectively.","Musculoskeletal Model; driver modeling; Nonlinear; steering response; Cybernetics","en","master thesis","","","","","","","","2022-08-27","","","","Mechanical Engineering","","57.728452, 11.860822"
"uuid:65d3cba8-a9a6-492c-9a28-42015f5d7734","http://resolver.tudelft.nl/uuid:65d3cba8-a9a6-492c-9a28-42015f5d7734","Development of a Computational Model of Respiratory Mechanics in Mechanical Ventilation","Mousa, Amne (TU Delft Mechanical, Maritime and Materials Engineering)","Batselier, K. (mentor); Schoe, A. (mentor); Somhorst, P. (mentor); Delft University of Technology (degree granting institution); Erasmus Universiteit Rotterdam (degree granting institution); Universiteit Leiden (degree granting institution)","2020","","","en","master thesis","","","","","","","","2022-08-31","","","","Technical Medicine | Sensing and Stimulation","",""
"uuid:642a18fd-229d-4192-940c-e5a03362de59","http://resolver.tudelft.nl/uuid:642a18fd-229d-4192-940c-e5a03362de59","Assessing alternative heating strategies in a Dutch neighborhood using a life cycle perspective and multiple household decision-making factors: Contributing to the heat transition in Dutch dwellings","Wessels, Rik (TU Delft Technology, Policy and Management)","Korevaar, G. (mentor); de Vries, G. (mentor); Luteijn-Nava Guerrero, G.D.C. (mentor); Delft University of Technology (degree granting institution); Universiteit Leiden (degree granting institution)","2020","","","en","master thesis","","","","","","","","","","","","Industrial Ecology","",""
"uuid:10466647-1259-44f7-bd75-5de19a115a4e","http://resolver.tudelft.nl/uuid:10466647-1259-44f7-bd75-5de19a115a4e","Schedulability analysis of limited-preemptive moldable gang tasks","Marcè Igual, Joan (TU Delft Electrical Engineering, Mathematics and Computer Science)","Nelissen, Geoffrey (mentor); Nasri, Mitra (mentor); Delft University of Technology (degree granting institution)","2020","Gang scheduling, has long been adopted by the high-performance computing community as a way to reduce the synchronization overhead between related threads. Gang schedulling allows for several threads to execute in lock steps without suffering from long busy-wait periods or be penalised by large context-switch overheads. If several threads use the same data, it also reduces the number of memory transactions by allowing the program to load those data only once for all threads rather than once per thread. To avoid reloading large amount of data after each preemption and hence incur large execution-time overheads, in this work, we assume that the tasks adhere to a limited-preemptive execution model. We further assume that each gang task is moldable, that is, it has a minimum and a maximum number of cores on which it may be executed. The actual execution time of a job depends then on the number of cores allocated by the scheduler at run-tiem. In this work, we consider the case for which tasks are scheduled according to a global job-level fixed priority scheduling algorithm, and present a worst-case response time analysis for limited-preemptive moldable gang tasks. Additionally, we propose a new scheduling policy to improve the<br/>schedulability of moldable gang tasks.<br","real-time systems; schedulability; multi-core; multiprocessor platforms; job-level fixed-priority; moldable gang tasks","en","master thesis","","","","","","","","","","","","Electrical Engineering | Embedded Systems","",""
"uuid:b97b4cf7-13c0-46f8-a620-a06c7cbd72c1","http://resolver.tudelft.nl/uuid:b97b4cf7-13c0-46f8-a620-a06c7cbd72c1","HVDC GIS Magnetic Field Antenna System Characterization","Nayak, Avinash (TU Delft Electrical Engineering, Mathematics and Computer Science)","Mor, A. R. (mentor); Muñoz Muñoz, F.A. (mentor); Castro Heredia, L.C. (mentor); Vaessen, P.T.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","class=""MsoNormal"">Partial Discharge (PD) measurements are of great importance to enable the monitoring and diagnostics of HV systems. The requirements of the Paris Agreement and climate goals have fuelled the increase in penetration and demand of HVDC for offshore wind. The HVDC Gas Insulated Switchgear (HVDC GIS) is a reliable technology to support the necessary electrical infrastructure. Nevertheless, some in-service failures may occur. These failures can occur in the insulation system and thus developing a measurement system for PD detection is essential for monitoring and diagnostics. To monitor and diagnose the HVDC GIS, a novel Magnetic Antenna (MA) is being developed to operate in the high-frequency (HF) (30-300 MHz) range. The well-established UHF method for the GIS is typically used due to its high sensitivity and resilience to electromagnetic interference. However, the UHF method is unable to calibrate to apparent charges as this information is in the low frequency (up to 30 MHz) until HF range. The knowledge of charge calibration indicates the discharge type which is important in DC as DC does not have phase-resolved information as with AC. The appropriate frequency range of the MA should enable the measurements of the apparent charge and localize the defects when monitoring and diagnosing a HVDC GIS setup. The overarching goal is to develop a measurement system to measure PDs in the HF range in a GIS setup. For this purpose, MAs are created and investigated. A workbench has been built and developed to characterize the MAs and measure its frequency characteristics. A 380 kV GIS measurement setup has been developed. This enabled the measurement and acquisition of data of the discharges using the MAs. The Threshold Peak detection (TPD), Energy Criterion (EC), and Phase Method (PM) localization methods are investigated and implemented for localization of the source of defects. The PM is unable to localize the pulse due to its sensitivity to noise and reflections. The TPD and EC are both suitable with the TPD being the preferred method due to its 95% accuracy of localizing the defect within ± 1.5 m.   ","","en","master thesis","","","","","","","","2022-09-27","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:fab655a3-d58f-46f4-b1b1-d3223584863e","http://resolver.tudelft.nl/uuid:fab655a3-d58f-46f4-b1b1-d3223584863e","Project Strategy Generation and Visualization Assistant for Schedule Delays: Integrating Evolutionary Algorithm in Lean + BIM Approaches","Guha, Soumik (TU Delft Civil Engineering and Geosciences)","Binnekamp, R. (mentor); Hoving, J.S. (graduation committee); Delft University of Technology (degree granting institution)","2020","Projects in the Complex Engineer-to-order (ETO) sector are subjected to frequent schedule delays caused by engineering changes, supply chain delays and fabrication delays. Project organizations are faced with the challenge of realigning the project duration within the pre-determined time. Schedule delays often lead to 3-5% rise in project cost. This requires an efficient on-the-go reactive approach. At present, the development of strategy to realign the project is extensively manual in nature. This makes the exploration of alternative realigning strategies cumbersome. Lean Project Planning (LPP) and advances in Building Information Modelling (BIM) has enriched on-the-go planning. However, no existing tool equips the project organization to generate, visualize and evaluate possible set of alternative strategies in the event of a triggered change. No attention has been provided to integrate strategy generation algorithms like Evolutionary Algorithm with the LPP and BIM approaches. In this research, a tool was developed to enable the project organizations to generate and visualize strategies integrating Modified Evolutionary Algorithm (MEA) with LPP and BIM from a metaheuristic approach. Furthermore, by undertaking a case study on strategies adopted in real-life change events in a representative Complex ETO project, the reliability of the generated strategies was investigated. The application of the proposed tool in the real-life test case showed the advantages of having multiple alternative realignment strategies.","Delay reduction; Project planning; Project strategy; Evolutionary Algorithm - EA","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:876a4547-435d-43cd-a6bc-dece19018bad","http://resolver.tudelft.nl/uuid:876a4547-435d-43cd-a6bc-dece19018bad","Schiphol indoor navigation application","Li, Jianghui (TU Delft Industrial Design Engineering)","Tassoul, M. (mentor); Bakker, M.F. (mentor); Danckaerts, Carolien (graduation committee); Delft University of Technology (degree granting institution)","2020","Base on the preliminary research results, the design goal of this project is defined: Providing departing, arriving and transferring travellers a seamless experience, which makes them feel confident and relaxed during the whole process of their journey in Schiphol, including wayfinding, searching information, learning of the Dutch transport system,<br/>check-in and even passing border control, Etc. This can be achieved by facilitating the Schiphol information providing and wayfinding to help travellers understand the Schiphol service, wayfinding and transportation system and meet all their varying needs. The emphasis of this project is not to improve the Schiphol's service system or add new service in Schiphol, but to help travellers understand and utilize Schiphol's current service system by building a new efficient app information architecture and AR navigation system. <br/><br/>This project explores which information structure is more suitable for Schiphol (Public transport system). Through continuous testing and iteration, the information architecture of the new Schiphol app is confirmed, which would combine with the liner pattern and Hub and spoke information structure to build the underlying information architecture of the app. Choosing the Hub and spoke as the primary parent pattern and applying liner pattern for subsections.<br/><br/>In the user testing phase, it was discovered that functionality, ease of learning, and fun are all essential factors that affect user performance with the new Schiphol app. The focus of the second iteration is to ensure that users can understand and use the app. Make the layout of each interface and visual elements of the app more familiar to all users. The third iteration mainly focuses on the ease of use and fun of the new app. More attractive visual elements and dynamic effects are added to enhance the app's interest. After three rounds of testing, the new Schiphol app can meet the needs of all participants and combines functionality and fun.<br/><br/>Overall, the new app can help travellers quickly obtain the information they need and learn about Schiphol (Schiphol wayfinding system, Schiphol service system, Dutch public transportation system). At present, only about one per cent of passengers will download the Schiphol app in advance, so how to help them realize this app and download it is still an issue that Schiphol needs to consider in the future.","Schiphol; Indoor navigation; Application","en","master thesis","","","","","","","","","","","","Integrated Product Design","","52.3105386，4.7682744"
"uuid:628e1a4a-319e-494c-9b69-f1bd41f5b00b","http://resolver.tudelft.nl/uuid:628e1a4a-319e-494c-9b69-f1bd41f5b00b","Governance of Multi-level and Multi-actor Systems for EU Customs Supervision","Das, Moorchana (TU Delft Technology, Policy and Management)","Zuiderwijk, AMG (mentor); de Bruijne, M.L.C. (graduation committee); Rukanova, B.D. (graduation committee); Delft University of Technology (degree granting institution)","2020","The vessels transporting the cargo can face change in itinerary because of various factors. The ENS documents are submitted to the customs office of first entry before loading the cargo onto the vessel. The issues that the customs faced were unavailability or incomplete Entry Summary Declarations (ENS) to perform the risk assessment because of the change in itinerary of the vessels. Due to this unavailability and incomplete ENS documents, it is difficult for customs to perform their risk assessment processes. This results in an inefficient process and incurs costs. <br/>Due to the growing amount of trade into the European Union, these issues cause a serious problem in the functioning of the customs authorities of the EU. In 2018, the PROFILE research project of the EU investigated the possibility of using blockchain technology for availability of information to the customs. The blockchain technology is a decentralized platform. In the PROFILE project it was examined whether blockchain can be used as a system to define access control to ENS data. Such a system can be seen as complementary to ICS 2.0 EU system that is currently being developed in the EU. Governance issues surrounding the blockchain-based platform arose such as who will develop the platform and be held accountable for the platform. The networked organizations around this blockchain-based platform consists of actors from the supra-national level (EU), national level (EU Member States) and business organizations (ocean carriers). Since the goals of these actors are different (carriers are interested in monetary profits and one of the interests of customs authorities is safety), a governance solution for multi-level network of actors to form a collaboration is required. Thus, the objective of this research is to look for a governance solution that enables multiple actors to join forces and form a collaboration. <br/>The research question that has been formulated for this research is: What governance solution can enable the collaboration of multiple organizations to develop blockchain technology for EU customs supervision? A collective network of customs organisations comes with its own challenges like who is in charge of governance, and legal barriers specific to countries associated. Governance solution is required to ensure smooth collaboration.<br","","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:364b1a17-7e47-4eae-ba1b-e9eae58d14ab","http://resolver.tudelft.nl/uuid:364b1a17-7e47-4eae-ba1b-e9eae58d14ab","Installation of a Large Diameter Cold Water Pipeline for a 3MW Onshore Based OTEC Plant","van Kooten, Rob (TU Delft Mechanical, Maritime and Materials Engineering)","Metrikine, A. (mentor); Hoving, J.S. (mentor); van Dalen, K.N. (graduation committee); Kleute, Berend Jan (mentor); Delft University of Technology (degree granting institution)","2020","Ocean thermal energy conversion (OTEC), is a renewable energy resource that uses the thermal gradient of the ocean to generate electricity. Warm surface water and cold deep sea water, which can be found at depths of approximately 1000 [m], are used to generate electricity in a thermodynamic Rankine cycle. Due to its dimensions, the installation of the cold water pipeline is one of the most challenging aspects of an OTEC plant. Allseas Engineering B.V. is planning to install a 3 [MW] onshore based OTEC plant on Bonaire. For this OTEC plant, a cold water pipeline with an outer diameter of 2.25 [m] is required that pumps up water from 950 [m] water depth. High density polyethylene (HDPE) is used as the material for the pipeline. HDPE is buoyant and therefore requires additional downwards force to be installed below the sea surface. Two installation methods are considered for this cold water pipeline: the ‘hold and sink installation method’ and the ‘pull down installation method’. A numerical non-linear Euler Bernoulli beam model is used to optimize both installation methods. The Von Mises stress criterion is used to assess whether the structural integrity is maintained during the installation.<br/>The hold and sink pipeline is ballasted using concrete ballast weights to provide the necessary downwards force. The seabed stability criterion is used to determine the required amount of ballast. Hold points are attached along the length of the pipeline that provide a vertical upwards force to control the sinking velocity. A pull force is applied at the offshore end to reduce pipeline bending stress and to reduce the lateral deflection that results from the sea current. Using the hold and sink installation method, the pipeline can be successfully installed without exceeding the design stress.<br/><br/>The pull down installation pipeline is divided into two sections: a ballasted section of 450 [m] and the remainder of the pipeline that remains afloat. A concrete ballast weight is installed at the seabed, at the final position of the offshore end of the pipeline. The ballasted section is installed using an installation method that is frequently used for HDPE pipelines called the float and sink method. A chain is connected to the offshore end of the pipeline. The chain is connected to a pull cable that runs through the anchor box at the seabed to a crane vessel at the sea surface. The unballasted section is then pulled down to the anchorbox, where the chain is secured in the anchorbox and the pipeline remains in a reversed catenary shape during its operational life. In the transition zone where the transition between the ballasted section and the floating section of the pipeline occurs, the Von Mises stress exceeds the design stress. The Von Mises stress results primarily from pipeline bending, therefore additional bending stiffness is applied in the transition zone. The maximum pull force is limited to the weight of the anchorbox. The required pull force to install the pipeline exceeds the allowed pull force. Additional ballast weights are attached to the free span of the pipeline to reduce the required pull force. The pipeline can be installed without exceeding the design stress when the bending stiffness in the transition zone is increased and the required pull force is reduced.<br/>A preliminary multi-criteria analysis is conducted as an initial comparison between the two installation methods. From this analysis no obvious preferred installation method can be selected. A recommendation is made to expand this preliminary multi-criteria analysis and include a detailed cost estimation of the installation methods. Furthermore, it is recommended to include a detailed operational lifetime analysis on the structural integrity of the pipeline for both installation methods.","OTEC; Cold Water Pipeline; Installation","en","master thesis","","","","","","","","2022-08-26","","","","","",""
"uuid:07f01e0c-cbcd-42d8-9c4d-75e328dd6d40","http://resolver.tudelft.nl/uuid:07f01e0c-cbcd-42d8-9c4d-75e328dd6d40","The Robotic Programming Lab: Designing an interactive experience at Museon","Padmasola, S. (TU Delft Industrial Design Engineering)","van der Helm, A.J.C. (mentor); Vermeeren, A.P.O.S. (mentor); Visser, Friso (mentor); Delft University of Technology (degree granting institution)","2020","The Netherlands is one of the forerunners in the fields of international scientific research, education and innovation. Currently ,the country faces a dire problem - insufficient technologically skilled people to meet the demands of the fast growing technological development. <br/>To address this problem, the government mandated to actively encourage science among young children. <br/>Science museums play a crucial role in delivering lessons to schools, they are ideal spaces to make the maximum impact on a young mind. Thus, the idea for the Robotic and Programming lab at Museon was born. The lab is established to be at the forefront of this change and to actively introduce programming to primary school children. <br/> <br/>This project conceptualises the interactive experience of the robotic programming lab. It also formulates a framework for the experience which aids in the conceptualisation of interactive activities within the lab. These interactions are designed with an aim to encourage programming while closely considering the learning outcomes and the science concepts that children are already familiar with.","Interaction Design; experience design; museum experience; Museum; programming; Robot; programming for children","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:263a16e0-1480-401c-b072-ad24814b334c","http://resolver.tudelft.nl/uuid:263a16e0-1480-401c-b072-ad24814b334c","Designing Energy Partnership between Users and Intermittently Powered Device","Bao, B. (TU Delft Industrial Design Engineering)","Kortuem, G.W. (mentor); Giaccardi, E. (graduation committee); Delft University of Technology (degree granting institution)","2020","Today's mobile devices powered by batteries have kept feeding users endless entertainment and convenience, whereas always accompanied by some unfavorable experiences that is 'Always have to recharge'. The puzzle of battery life has been an inevitable limitation that could probably degrade user experience, even though smartphones, smart homes, and smart wearables are growing ever more advanced. A new technology named 'Energy Harvesting' emerges. As an enabler of battery-less devices, it has exceptional potential in replacing the battery as the power source for future mobile devices. On the other hand, however, accompanied by enormous potential, energy harvesting will also bring tremendous concerns. Current mobile device users have equipped the knowledge of handling the limited battery life and formulated a cognition towards energy in battery-based devices. In other words, the Current Energy partnership, meaning the interactive and cognitive relations between users and energy in battery-based devices, is built on the battery capacity limitation. However, such a partnership will not be compatible with the non-battery devices in which battery life is no longer a limitation. <br/><br/>The central aim of this research has been to explore the current and future Energy Partnership between users and future intermittently powered devices. The Research-through-Design methodology has been employed, embracing online surveys, user interviews, prototypes design, and user tests to launch a collaborative discussion with interviewees about the possibilities of the future Energy Partnership.<br/><br/>From a set of user studies and a systematic integration of previous research, the current EP Model is proposed to demonstrating the interactive and cognition process between users and the energy in battery-based mobile devices. The research found that the current energy partnership can be conceptualized as a balance between user and appropriate usage time. Building on the current EP Model and insights distilled from expert interviews, a hypothetical EP Model has been developed, articulating the transformation of Energy Partnership brought by energy harvesting technology. The hypothesis was then iterated twice through designing and testing the prototype simulating the energy behavior of intermittently powered devices.","Energy Partnership; Intermittently Powered Device; Human-Energy Interaction","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:45505b0c-77e2-4e45-9871-b163abfa0a78","http://resolver.tudelft.nl/uuid:45505b0c-77e2-4e45-9871-b163abfa0a78","Atmospheric Characterisation of Jupiter using Polarimetric Data","Frericks, H. (TU Delft Aerospace Engineering)","Vermeersen, L.L.A. (mentor); Visser, P.N.A.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","Jupiter is the most visited outer solar system planet, but the exact variation in atmospheric properties along its disk remains largely a mystery. This is where polarimetry fits into the picture. Its added value to spectrometry by additionally measuring the polarisation degree and direction of light makes it a suitable remote sensing tool for the characterisation of planetary atmospheres. It can potentially be used to detect and characterise exoplanets as starlight is originally unpolarised [Kemp et al., 1971] while light reflecting from an object is not. The degree of polarisation is sensitive to the atmospheric properties and its coupling with the wavelength, phase angle and absorption are used to derive the approximate upper atmospheric structure of Jupiter. For this purpose, polarimetric observations of the Torino Polarimeter are compared to the results of a numerical model coded in Fortran. This numerical model uses a doubling-adding radiative transfer algorithm to simulate the polarisation properties of the designated atmospheric profile. The atmospheric profile consists of gas and aerosols, the latter modelled by spherical particles using Mie scattering theory. The numerical model results are processed and compared to the observations using a Matlab script. The particle properties are constrained by the observations using the wavelength filters, the implemented methane absorption and by using a variable cloud pressure and haze optical thickness. The numerical model results best matching the observations show higher altitude clouds in the higher polarisation degree regions known as the zones, and lower altitude clouds in the belts. The optical thickness of the haze layer turns out to be low or zero in the zones and higher in the belts. To better characterise Jupiter's atmospheric structure, several aspects relating to the observations and the numerical model have to be investigated in more detail in order to improve the matching of the two.","Polarisation; Jupiter","en","master thesis","","","","","","","","2020-08-26","","","","Aerospace Engineering","",""
"uuid:f17bd38d-aac7-4b38-a1c9-5bef08005ddd","http://resolver.tudelft.nl/uuid:f17bd38d-aac7-4b38-a1c9-5bef08005ddd","Een ray-tracer voor geodeten van lichtstralen om een zwart gat","Knoppert, Daan (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Applied Sciences)","Visser, P.M. (mentor); Rieger, B. (mentor); van den Dries, B. (graduation committee); Blanter, Y.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","In 2019 werd er voor het eerst een foto van een zwart gat gepubliceerd. Het betreffende super zware zwarte gat ligt in het midden van het sterrenstelsel Messier 87. In dit onderzoek willen we simulaties maken van hoe een foto van een zwart gat eruit ziet. Zowel voor een achtergrond (zoals de sterrenhemel) als de accretieschijf die eromheen zit. De vraag is vervolgens welke informatie uit de foto gehaald kan worden. Om de foto te maken, werd een ray-tracer gemaakt. Hierbij kijk je waar een lichtstraal, die op het scherm komt (een oog of camera), vandaan komt. De bewegingsvergelijkingen zijn vereenvoudigd door constantes van de beweging te zoeken om de geodeetvergelijkingen te versimpelen. Vervolgens zijn de bewegingsvergelijkingen numeriek opgelost. Er is gevonden dat lichtstralen van veraf niet in een zwart gat vallen bij $\frac{\sqrt{27}}{2}R_s$. $R_s$ is de Schwarzschild straal. Dit is de straal waarvandaan licht niet meer kan ontsnappen van een zwart gat. De gesimuleerde plaatjes zijn 128x128 pixels. In de gesimuleerde plaatjes had het zwart gat ongeveer $2.5R_s$. Dit komt nauw overeen maar er wordt een aanzienlijke fout gemaakt door de resolutie van de plaatjes. Verder is kwalitatief de oriëntatie en rotatieparameter $a$ goed uit de plaatjes te halen.","Zwart gat, Ray-tracer, foto","en","bachelor thesis","","","","","","","","","","","","","",""
"uuid:6925ccc5-55b6-4f0f-b1c8-57a227b3e25f","http://resolver.tudelft.nl/uuid:6925ccc5-55b6-4f0f-b1c8-57a227b3e25f","Global Interpretation of Image Classification Models via SEmantic Feature Analysis (SEFA)","Soilis, P. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Bozzon, A. (mentor); Balayn, A.M.A. (mentor); Lofi, C. (graduation committee); van Gemert, J.C. (graduation committee); Delft University of Technology (degree granting institution)","2020","Deep learning models have achieved state-of-the-art performance on several image classification tasks over the past years. Several studies claim to approach or even surpass human-levels of performance when using such models to classify images. However, these architectures are notoriously complex, thus making their interpretation a challenge. This limited interpretability, in turn, leads to several issues, such as restricting their applicability to critical domains like health care and finance.<br/><br/>Several methods in literature attempt to address this issue by providing local explanations which describe individual predictions or global ones that explain the model behaviour for a specific class. When focusing on global methods, we notice that they are limited with respect to the interpretability queries that they answer. For instance, consider we want to query whether the simultaneous presence of two objects is associated with predicting a specific class. To the best of our knowledge, there is no existing method that can tackle such a query type due to their limited expressivity. In this thesis, we address this limitation by answering the following research question: to what extent can image classification models be interpreted by analysing semantic features extracted from groups of salient image pixels?<br/><br/>We begin our study by investigating existing research work to devise the ideal characteristics that an interpretability method should adhere to. Our analysis highlights the aforementioned gap regarding the query complexity that existing methods cover. To address this limitation, we propose a new global interpretability method called SEmantic Feature Analysis (SEFA). To elaborate, it combines explanations of individual image predictions with semantic descriptions provided by human annotators about them, thus extracting the aforementioned semantic features. We argue that by analysing a structured data representation extracted out of semantic features will allow us to answer a wider range of interpretability queries compared to existing methods. The proposed method poses several challenges, such as identifying the number of image annotations required to obtain reliable results at a reasonable annotation cost.<br/><br/>Our results show that SEFA provides its users with the flexibility to answer several types of interpretability queries, including the ones that we found existing methods to be lacking. Further experimentation on its hyperparameters using three separate image classification tasks provides us with a set of suggested settings that one should use on similar datasets. Finally, we showcase the ability of SEFA to output semantic features relevant to the model classification behaviour by fine-tuning existing model architectures on biased datasets and evaluating whether the salient semantic features output describe the previous bias.","Global Interpretability; Deep Learning; Image Classification","en","master thesis","","","","","","","","","","","","Computer Science | Data Science","",""
"uuid:a8d1c209-358e-486e-a6de-8ed52f5cfef2","http://resolver.tudelft.nl/uuid:a8d1c209-358e-486e-a6de-8ed52f5cfef2","Mesoscale Modelling of Waterspouts: An Offshore Wind Energy Perspective","Yu, Q. (TU Delft Civil Engineering and Geosciences)","Basu, S. (mentor); Watson, S.J. (graduation committee); de Roode, S.R. (graduation committee); Delft University of Technology (degree granting institution)","2020","Wind energy is becoming an important renewable energy source. An increased number of offshore wind farms are constructed due to the relatively higher wind speeds. Besides, compared with the land, the ocean areas offer more empty space for the installation of wind turbines. In recent years, several governments in Europe have the plan to expand their countries’ wind farms over the North Sea area. With this surge in the development of offshore wind farms, extreme weather events over the sea pose threats to the installations. A waterspout is one of such phenomenon of concern.<br/><br/>In this study, we simulated and characterized the atmospheric conditions associated with two waterspout events observed recently over the North Sea. These cases were selected from the European Severe Weather Database. Various types of observational data, including radiosondes, radar reflectivities, satellite imageries, lighting maps, and floating liar-based wind profiles, were utilized for detailed characterization. Atmospheric circulation patterns associated with waterspouts were deduced from surface-level and upper-air synoptic charts. A mesoscale model, called the Weather Research and Forecasting model, was used for simulations with a high spatial resolution of 1 km. We used five different parameterizations of varying complexities to quantify the sensitivity of the simulated results with respect to cloud microphysics. A number of meteorological variables and indices (e.g., thermodynamic indices, wind shear, vertical velocity, reflectivity) are extracted from the simulations and compared with the observational data. In general, our results are in agreement with the findings from previous studies. For instance, we have found that a double moment microphysics parameterization produces more realistic results in comparison with a single moment one. However, we have noticed that our simulated results fall outside the range specified by the so-called Szilagyi waterspout nomogram. This nomogram was initially proposed based on observational data from the Great Lakes region and is widely used by the operational meteorologists. Based on the results, updating this nomogram is needed with additional observational and simulated data from the North Sea region.","","en","master thesis","","","","","","","","","","","","","",""
"uuid:fe2bc484-23f3-47ba-90c0-496f6fe08a76","http://resolver.tudelft.nl/uuid:fe2bc484-23f3-47ba-90c0-496f6fe08a76","Decarbonising the Residential Space Heating Sector of the Netherlands in 2050 through Three Decarbonisation Pathways: Hydrogen Boilers, Hybrid Heat Pumps and Electric Heat Pumps","Chowdhury, Kunal (TU Delft Electrical Engineering, Mathematics and Computer Science)","Blok, K. (mentor); Luscuere, P.G. (graduation committee); van Wijk, A.J.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","Residential space heating demand in the Netherlands is met by natural gas boilers in 93% of Dutch households. In order to combat global climate change and limit the increase in global average temperatures to below 1.5°C by the year 2050, the Netherlands will have to cut down its emissions across all sectors of human activity to nearly zero. The residential space heating sector accounts for majority of the emissions of the built environment, decarbonising this sector is key to eliminating greenhouse gas emissions and combating global climate change. Decarbonisation of the residential heating sector can be achieved through multiple pathways. The aim of this thesis is to investigate which pathway would have the least cost to the end user in the year 2050. Three pathways have been selected, the all-electric pathway based on using heat pumps to meet space heating demand, the core hydrogen pathway based on meeting heating demand with end-use hydrogen boilers, and the hybrid pathway based on meeting heat demand with hybrid heat pumps. Electricity supply in all three pathways will come mainly from solar photovoltaic energy and wind turbines and hydrogen will be produced by electrolysis of water, from renewable electricity. Hydrogen is assumed to be transported directly to end-user households using the existing natural gas transport infrastructure of the Netherlands, with adequate safety modifications, after being produced by dedicated offshore wind turbine capacity. Hydrogen is not produced at all in the electric pathway. First, the heat demand per household (space heat + domestic hot water) is determined for each of the five types of dwellings in the Netherlands. Annual energy cost per household is then determined from projected future electricity and hydrogen retail prices. The installation of heat pumps will also involve renovations to the home to improve insulation levels in order to maximise the coefficient of performance, at additional cost to the end-user. The total annual cost per household of each pathway is then determined as the sum of the annual energy cost per household, the investment and installation cost of each device per household, and the annual maintenance cost. Total annual cost per decarbonisation pathway is the sum of the total annual cost per household for all houses in the Netherlands in 2050. The annual cost per household varies widely depending on the values of electricity and hydrogen tariffs in 2050, the capital investment cost of each device, the level of household renovations required to improve household insulation levels, and the cost of investment in devices such as low temperature radiators. Annual costs vary among different types of dwellings, the smaller the dwelling, the smaller the required area to be heated. The annual cost per pathway was found to mainly have uncertainties regarding the device capital investment cost and electricity and hydrogen tariffs in 2050. To reduce uncertainties in results, a scenario study was performed. The scenarios were constructed to account for the variations in device capital investment cost found in literature for electric and hybrid heat pumps, and the variations in energy tariff (electricity and hydrogen tariff) estimates for 2050. In five out of six analysed scenarios, the hydrogen boiler pathway was found to have the least annual costs in 2050, with electric heat pumps being the most expensive pathway in these scenarios.","","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:41ab8a21-a391-490b-ace7-83db7be7cdef","http://resolver.tudelft.nl/uuid:41ab8a21-a391-490b-ace7-83db7be7cdef","Development of a Game to Encourage Data sharing in Supply Chain","Ijaz, M. (TU Delft Technology, Policy and Management)","Tavasszy, L.A. (graduation committee); van Duin, J.H.R. (mentor); Scholten, V.E. (mentor); van Veen, A.J. (mentor); Delft University of Technology (degree granting institution)","2020","In order to tackle the problem of supply chain managers not being ready to share data, the thesis first identifies the root causes of the reluctance of supply chain managers towards sharing data. This reluctance of the supply chain managers is caused by many reasons. Firstly, they fear the misuse of their sensitive information. Information regarding one supply chain firm can be used by other firms in a way that undermines the original firm. The competitors can use this information to win the race over the original firm. There is not enough trust between supply chain firms and hence, they fear giving their information to each other. Lastly, the data sharing techniques would require investment in terms of infrastructure of data sharing technologies. The reluctance, caused by the aforementioned reasons, is a reason for the absence of data sharing in supply chains. By overcoming this reluctance and sharing data in a supply chain, efficiencies can be increased and optimal potentials can be achieved. Therefore, this reluctance is an obstacle that needs to be overcome.","Data; sharing; supply chain; blockchain","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:44d70d99-c4bf-4f33-b52f-0cbd1969597b","http://resolver.tudelft.nl/uuid:44d70d99-c4bf-4f33-b52f-0cbd1969597b","Evaluating Image2Speech: The evaluation of automatically generated phoneme captions for images","van der Hout, J.R.T.E. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Scharenborg, O.E. (mentor); Delft University of Technology (degree granting institution)","2020","Image2Speech is the relatively new task of generating a spoken description of an image. Similar to Automatic Image Captioning, it is a task focused on describing images, however it avoids the usage of textual resources. An Image2Speech system produces a sequences of phonemes instead of (written) words which makes the Image2Speech task applicable to languages which do not have a standardized writing system. This thesis presents an investigation into the evaluation of the Image2Speech task. The Image2Speech output is evaluated with human evaluators as well as multiple objective evaluation metrics. These metrics are often used in the field of Natural Language Processing, such as BLEU, METEOR, PER, etc. and can be used to give an indication of the semantic similarity between two sentences of words. Since humans are the end users of Image2Speech systems, the objective evaluation metrics are correlated with human evaluation in order to determine which metric can best evaluate an Image2Speech system with the end users in mind. For this, first an Image2Speech system was implemented which generates image captions consisting of phoneme sequences. This system outperformed the original Image2Speech system on the Flickr8k corpus, which is a dataset containing 8,000 images which each image also having five written and spoken captions. Subsequently, these phoneme captions were converted into sentences of words in order to be more easily interpretable for human evaluators. The captions were rated by human evaluators for their goodness of describing the image and correlated with the objective evaluation metrics. Although BLEU4 does not perfectly correlate with human ratings, it obtained the highest correlation among the investigated metrics, and is the best currently existing metric for automatically evaluating the Image2Speech task. Current metrics are limited by the fact that they assume their input to be words. A more appropriate metric for the Image2Speech task should assume its input to be parts of words, e.g. phonemes, instead.<br/><br","Image Captioning; Speech; Unwritten Languages; Evaluation","en","master thesis","","","","","","","","","","","","","",""
"uuid:319ae419-a271-4774-a934-9a433035f990","http://resolver.tudelft.nl/uuid:319ae419-a271-4774-a934-9a433035f990","“From Home to Home” : Towards an inclusive, mixed and updatable community","Cheng, Jinfeng (TU Delft Architecture and the Built Environment)","Mooij, H.A.F. (mentor); Schnater, F.R. (mentor); Amorim Mota, N.J. (mentor); Wamelink, J.W.F. (graduation committee); Delft University of Technology (degree granting institution)","2020","Ethiopia is going through rapid urbanization and population growth in the recent two decades with lots of migrants from the rural areas, resulting in a dramatic housing shortage. The same situation happens also in many other developing countries in the Global South, where affordable houses are demanded. By exploring an affordable housing scheme for mixed-income groups, this project is trying to find a way to create an inclusive community where different income groups can cohabit and have equal rights to participation, diversity, and appropriation. At the mean time exploring affordable housing scheme strategy in the context of Addis Ababa with the guideline of the studio. Residents could feel significant connections to their communities, and residents can shape outcomes for the communities and a sense of belonging by participating. The design will research how different income groups define places as home and to what degree private and public realm could be mixed to create coherent living quality for all income groups. World widely, mixed neighborhoods which involve complicated social ties and special combination of different income groups, are damaged by the standard, rigid planning methods, resulting in larger social segregation as well. This project can contribute to rebuilding an inclusive and resilient urban form.","Addis Ababa Living Lab; Affordable Dwelling; Mixed Income Housing; Gerji","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Global Housing","Addis Ababa Living Lab: Creating Resilient Dwelling Clusters for Urban Resettlement","8.997361, 38.807671"
"uuid:de16b13e-bc47-4472-b3b5-14395512f48f","http://resolver.tudelft.nl/uuid:de16b13e-bc47-4472-b3b5-14395512f48f","AI Enabled Dynamic Capabilities: Helping Large Organisations to Overcome Disruptions with a Capability Orchestration Framework","Smith, K.L. (TU Delft Industrial Design Engineering)","Santema, S.C. (mentor); Kim, E.Y. (mentor); Plugge, A.G. (mentor); Delft University of Technology (degree granting institution)","2020","Due to globalisation and technological advancements, the world is becoming increasingly complex. Volatile, uncertain, complex and ambiguous (VUCA) environments have called for organisations to become more agile in order to survive and compete in such changing environments. Large organisations are at particular risk for becoming stagnant due to operational inertia. In order to combat this and achieve agility, dynamic capabilities are developed. These capabilities allow an organisation to more effectively and efficiently change to incoming threats or opportunities. Such changes create uncertainty and insecurity amongst employees which translates into higher employee turnover and decreased performance. Stability therefore needs to be provided for individuals, while achieving dynamacy for organisations. This paradox of dynamic stability drives research into understanding relationships and effects caused by <br/>disruptions. Covid-19 is used as an extreme use case in order to create these understandings. After primary and secondary research conclusions were developed, a conceptual framework was developed in order to orchestrate capabilities. This aims to help speed up the time taken for opportunities/threats to be translated into outcomes. This also aims to help improve the depth, diversity and accuracy of these outcomes.<br","Dynamic Capabilities; Dynamic Stability; Artificial Intelligence and Design; Complexity; Change Management; Organisational Culture; Framework","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:33b7eb23-ca98-4457-9485-66f1d19d2ca4","http://resolver.tudelft.nl/uuid:33b7eb23-ca98-4457-9485-66f1d19d2ca4","Modelling the steady-state motion of a soil column including nonlinear hysteretic damping under periodic excitations","van der Esch, I.A. (TU Delft Civil Engineering and Geosciences)","Faragau, A.B. (mentor); van Dalen, K.N. (graduation committee); Metrikine, A. (mentor); Pisano, F. (mentor); Delft University of Technology (degree granting institution)","2020","Soil exhibits hysteretic damping. A commonly used implementation of this type of damping are the Masing rules. They consist of a loading and an unloading branch, dened as a piecewise function and having a nonsmooth character. This paper presents a framework how steady-state solutions of the motion of a soil column, with nonlinear hysteretic damping, can be obtained by using a variant of the Harmonic Balance Method (HBM), the Alternating Frequency/Time Harmonic Balance Method (AFTHBM), applied on a discretised soil column (a lattice system). The theoretical background of the method is presented, as well as its application to a soil column with both shear strain-dependent stiness and damping. Results show that the AFTHBM is an efficient method for obtaining steady-state results for nonsmooth nonlinear behaviour, which is in this paper presented by simulations for nonlinear media. The results of the AFTHBM are sensitive to time sampling and convergence tolerances; nonetheless, if these parameters are properly chosen, the application of AFTHBM leads to good results.","Harmonic Balance Method; Alternating Frequency/Time Harmonic Balance Method; Soil; Hyperbolic; Nonlinear; Hysteresis","en","master thesis","","","","","","","","2025-08-26","","","","","",""
"uuid:425f4402-fd79-4568-be22-08f850b06b36","http://resolver.tudelft.nl/uuid:425f4402-fd79-4568-be22-08f850b06b36","A dependent sampling approach to Scenario Discovery","van Droffelaar, I.S. (TU Delft Technology, Policy and Management)","Kwakkel, J.H. (mentor); Aydin, N.Y. (mentor); Warnier, M.E. (mentor); Delft University of Technology (degree granting institution)","2020","The use of scenario planning has a long history in decision-making and public policy (Bryant and Lempert, 2010). Traditional scenario planning, as, for example, used by the Shell Scenarios group, provides tools to communicate and characterize uncertainty,allowing decision-makers to anticipate the future and create more robust strategies (Bradfield et al., 2005).<br/><br/>However, the classical qualitative approach, where scenario narratives are developed, has some severe limitations. While this approach provides results which are readily communicated to decision-makers, it often overlooks truly unexpected (but plausible) scenarios (Kwakkel and Cunningham, 2016). Besides, they are not readily implemented for problems where the structure is also disputed (Bryant and Lempert, 2010).<br/><br/>Scenario discovery, a quantitative, brute-force approach to scenario development,developed by Bryant et al. (2010) aims to address these limitations. This approach has been successfully applied to numerous grand challenges, among others climate change (Kwadijk et al., 2010), sustainable water management (Haasnoot et al., 2011), and global natural resource management (Kwakkel et al., 2013). <br/><br/>The original approach to quantitative scenario discovery relies on three consecutive steps: sampling, labeling and searching for subspaces leading to the regions of interest.The sample is typically collected using Latin Hypercube Sampling (Kwakkel, 2017). For uniform, independent sampling, the chance that a random sample falls within the region of interest decreases quadratically with increasing size of the bounds (Vrugt, 2016). Therefore, if the prior distribution cannot be estimated, or the problem at hand demands a wide range of possible values, and the problem has a high number of dimensions, these sampling techniques require an unreasonably high number of samples to adequately delineate the region(s) of interest.<br/><br/>Therefore, this thesis proposes using dependent sampling, which concentrates the sampling on the regions of interest, rather than attempting to represent the entire input space. After convergence, the resulting sample approximates the true posterior distribution. By performing a Kolmogorov-Smirnov test for uniformity, the uncertain factors leading to the behavior of interest can be derived. The relevant ranges of parameter values can be recognized and communicated to decision-makers.","Deep Uncertainty; Scenario Discovery; Approximate Bayesian Computation; Dependent Sampling","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:fbab3fe2-e077-4d41-ace4-e434c25ce27f","http://resolver.tudelft.nl/uuid:fbab3fe2-e077-4d41-ace4-e434c25ce27f","Deepification: Learning Variable Ordering Heuristics in Constraint Optimization Problems","Doolaard, F.P. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Yorke-Smith, N. (mentor); de Weerdt, M.M. (graduation committee); Pouwelse, J.A. (graduation committee); Delft University of Technology (degree granting institution)","2020","Constraint programming is a paradigm for solving combinatorial problems by checking whether constraints are satisfied in a constraint satisfaction problem or by optimizing an objective in a constraint optimization problem. To find solutions, the solver needs to find a variable and value ordering. Numerous heuristics designed by human experts already exist to guide search and recent research uses machine learning to learn new heuristics. In this work the concept of deep heuristics is introduced. First, data is collected during a probing phase after which a deep heuristic function is learned based on the smallest, anti first-fail, and maximum regret heuristics. The learned deep heuristics look arbitrarily many levels in a search tree instead of a single instant lookup for normal heuristics. The results show that deep heuristics solve 20.5% more problem instances than normal heuristics while improving on overall runtime for the Open Stacks and Evilshop problems.","Machine Learning; Constraint Programming; Combinatorial Optimization; Heuristic","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:5b9d542f-7d61-4c11-9646-474be1b85fca","http://resolver.tudelft.nl/uuid:5b9d542f-7d61-4c11-9646-474be1b85fca","Effective Primary Healthcare Differential Diagnosis: A Machine Learning Approach","Agba, Obinna (TU Delft Electrical Engineering, Mathematics and Computer Science)","Al-Ars, Z. (mentor); Jaber, Tareq (mentor); Kitsak, M.A. (graduation committee); Delft University of Technology (degree granting institution)","2020","Primary health care facilities are usually the first point of call for patients seeking medical help. However, mis-diagnosis at this stage of the clinical encounter is still quite prevalent. Mis-diagnosis can be potentially harmful to the patient and even when not the case, there is an increased financial cost of arriving at the correct diagnosis borne by the patient and an increased pressure on the capacity of the medical system. The focus of this thesis is an evaluation of machine learning models which can make a differential diagnosis of possible patient conditions from presented symptoms. In this project, a systematic approach to the acquisition and generation of data relevant to the task is presented. This approach sidesteps one of the major barriers to the application of artificial intelligence methods in the health care domain i.e. access to data. With a generated dataset of approximately 5 million records, containing 801 conditions and 376 symptoms, three machine learning models - Naive Bayes, Random Forest and Multilayer perceptron (MLP) - are evaluated and compared on the generated data using the accuracy, precision and Top-5 accuracy as evaluation metrics. The Naive Bayes model achieves a 58.8% accuracy score, 63.3% precision score and an 85.3% top-5 accuracy score. The Random Forest achieves 57.1% accuracy with a precision score of 61.2% and a top-5 accuracy of 84.5%. The MLP model achieves similar performance with Naive Bayes with an accuracy of 58.8%, a precision of 63.0% and a top-5 accuracy of 85.5%. The number of symptoms expressed per condition was shown to have a strong effect on the achieved metric scores. When evaluated on a generated dataset with at least 5 symptoms per condition, the accuracy score lay between 80.2% and 83.6%, the precision was within the range of 84.2% and 87.6% and the top-5 accuracy was between 95.7% and 96.6% across all evaluated models. For a better understanding of the potential efficacy of these models in a real world setting, a number of possible real world scenarios are proposed and new datasets are generated based on these scenarios. The trained models are then evaluated on these new datasets. It is shown that model performance is closely related to the relevance and number of observed symptoms for each condition - a higher number of symptoms expressed per condition results in higher performance by the models. It is also shown that model performance degrades considerably when the new datasets are very different from the original generated data. The models perform poorly especially in the case when symptoms not usually associated with a condition are presented even when the presentation probability is still low.","machine learning; healthcare","en","master thesis","","","","","","","","","","","","Computer Engineering","",""
"uuid:38d9b35e-2d75-4cab-b6d1-723c2849badb","http://resolver.tudelft.nl/uuid:38d9b35e-2d75-4cab-b6d1-723c2849badb","Dataflow Hardware Design for Big Data Acceleration Using Typed Interfaces","Hadnagy, A. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Al-Ars, Z. (mentor); Delft University of Technology (degree granting institution)","2020","Recent trends in large-scale computing demonstrate continuous growth in the need for raw processing performance. At the same time, the slowdown of vertical scaling pushes the industry towards more energy-efficient heterogeneous architectures. With the appearance of FPGAs in the cloud and data centers, a new architecture is offered for offloading processing tasks and to bundle custom processing hardware with the applications. However, with great adaptability comes the increased complexity of development. The adoption of custom accelerators has been bounded by their limited programming models and the long turnaround time of development.<br/><br/>In this thesis, we look at current trends in the digital hardware design and synthesis to evaluate them in a big data context and identify the bottlenecks that limit productivity in the development and integration of domain-specific accelerators.<br/><br/>Based on the findings, we propose a composition language for components that implement typed interfaces to streamline kernel development. The language allows developers to compose accelerators from individual processing units that implement custom dataflow interfaces in a productive way. The productivity boost and utility of the language were evaluated on a practical use-case, showing almost two orders of magnitude reduction in code size. The performance of the proposed approach was benchmarked on a Power9 system with OpenCAPI, where our proof-of-concept accelerator kernel was able to achieve 4.04GB/s throughput using only 3.75% of the available FPGA resources. The integration of the accelerator led to a 13x speedup compared to a CPU-based Apache Spark implementation of the same algorithm.","FPGA; Hardware acceleration; Big data; Cloud FPGAs; Dataflow design; OpenCAPI; Fletcher; Apache Arrow; Tydi","en","master thesis","","","","","","","","","","","","","",""
"uuid:5ae61380-b49a-42c9-86ff-cf09559ef466","http://resolver.tudelft.nl/uuid:5ae61380-b49a-42c9-86ff-cf09559ef466","Design of an outdoor lighting system for Slamp S.p.A.","Nicer, Mikołaj (TU Delft Industrial Design Engineering)","Pont, S.C. (mentor); van de Geer, S.G. (mentor); Karagkouni, Katerina (mentor); Delft University of Technology (degree granting institution)","2020","Slamp spa is an Italian company, so far known for the design and production of decorative handmade lamps and lighting systems. Most of their current products are intended for indoor use. However, their plan for the coming years is to expand its portfolio with products also intended for external use. Due to the generality of the topic, extensive research was carried out in order to narrow down the issue. The outdoor lamp market, trends, materials, and the production possibilities of Slamp were carefully analyzed. Interviews with users of outdoor lighting were also conducted. The analysis resulted in the selection of private use, portable lamps as a category for the designed product. The first stage of the project was summarized by defining the target group, personas, and scenarios. <br/><br/>The concept development stage was carried out. It was characterized by a large amount of generating ideas through simultaneously trial and error, testing, searching for the form, application, and proper operation of light. It was a process that combines the features of a structured, methodological approach to the work of an IDE and the work of an artist looking for inspiration and a starting point through continuous experimentation. The stage was completed with the evaluation of the best concepts and the selection of one, which was then subjected to further development and embodiment design.<br/><br/>The result was a wireless lamp designed for indoor and outdoor use. The product directly responds to the needs of the interviewed users who emphasized that despite the installed external lighting, they used additional light sources such as candles, LED lamps, lanterns, etc. The lamp’s purpose is not to fully illuminate, but rather to provide additional or intimate illumination of the surroundings and a space in which the users are located. The lamps allow them to tune the mood and atmosphere, especially in a garden, on a terrace or a balcony. Furthermore, there is full freedom of how to use the lamp. It can stand horizontally, vertically, on the side, however users want, depending on their needs. It is recommended to buy not one, but two or three lamps to achieve optimal flexibility and optimal space illumination possibilities.<br","lamp; Lighting design; atmosphere; light; aesthetics; lighting system","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:bbdf4ff9-2cff-4756-a59f-33fa49ed4dc0","http://resolver.tudelft.nl/uuid:bbdf4ff9-2cff-4756-a59f-33fa49ed4dc0","Shape optimisation of residential mid-rise buildings for reduction of energy demand in temperate climate","Dorresteijn, Bo (TU Delft Civil Engineering and Geosciences)","Schipper, H.R. (mentor); Pasterkamp, S. (graduation committee); Turrin, M. (graduation committee); Debets, N.A. (graduation committee); Delft University of Technology (degree granting institution)","2020","class=""MsoNormal"">Shape has long been an important parameter in improving the internal comfort of buildings and reducing energy demand. This can be seen from historical vernacular architectural typologies, like igloos, which have minimal thermal loss surface to provide a comfortable internal climate.  Using a shape factor to reduce the building envelope and to minimise thermal loss is incorporated into the Dutch Building codes for a long time, aimed at a comfortable climate and low energy demand. This research is focussed on optimising building shape to reduce energy demand but combining this with demands for thermal comfort and daylight entrance.  By making use of Grasshopper a parametric design model is created. Using this model, a large variety of building designs was generated which are analysed on their daylight entrance and energy demand using Honeybee and Ladybug. By analysing the outcomes of these performance analyses, the window-to-wall-ratio and shape, quantified by shape factor Lc, of these designs were optimised using the autonomous optimisation algorithm pilOPT in modeFRONTIER. The optimisation objective is to minimise the total energy demand for heating and cooling. This is assessed by calculating the normalised energy demand for heating and cooling for both a summer and winter period. To execute the optimisation, the Erasmus Campus Student Housing project by Mecanoo in Rotterdam was used as a reference project.  The optimisation results show more compact buildings, with low WWRs have lower energy demands. This can also be seen from the Pearson correlation between the Lc [m] and the normalised energy demand [kWh/m2]. Which is found to be -0.624 for the first optimisation and -0.632 for the second optimisation. This confirms current building practice in which the relative building envelope is tried is be reduced.  Low WWRs (&lt; 0.2) can obtain a minimum daylight factor (DF50%) of 2.1%, which is lower than current practice. However, the minimum WWR is largely affected by the presence of neighbouring buildings. For facade orientations with adjacent buildings, minimum WWR is significantly higher (up to 0.8). Since buildings outside the own plot are not considered in the daylight calculation according NEN 2057 and the new NEN-EN 17037 situations may occur where buildings will obtain legal requirements but acquire poor daylight entrance. For future building shape optimisation studies, it is recommended to make use of visible part of the sky analysis (VSF) in the assessment of daylight criteria. Using VSF can save minutes of computation time per building analysis thereby speeding up the optimisation process. Recommendations for further research following this thesis are to: enlarge the number of case studies; focus on more detailed WWRs in a smaller range, by allowing smaller steps for WWR parameters, more detailed optima may be found; include the effect of installation efficiency, as this will affect the primary energy demand; assessing the effect of on-site energy production such as PV-panels on the building shape and WWR, as increasing the building envelope might not increase the net energy demand of buildings if more energy can be produced.    ","optimisation; Building shape; Energy demand; Grasshopper; modeFrontier; Honeybee; daylight entrance","en","master thesis","","","","","","","","","","","","Civil Engineering | Building Engineering - Structural Design","",""
"uuid:4b51562e-6e60-49ff-b769-2dc5115c75d7","http://resolver.tudelft.nl/uuid:4b51562e-6e60-49ff-b769-2dc5115c75d7","Detecting structural heterogeneity in single-molecule localization microscopy data","Huijben, Teun (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Applied Sciences)","Rieger, B. (mentor); Delft University of Technology (degree granting institution)","2020","br/>For decades, the resolution of fluorescent light microscopy has been bounded by Abbe’s diffraction limit to λ/2NA. Super-resolution methods, awarded with the 2014 Nobel Prize in Chemistry, use tricks to overcome this limit. The general idea is to image blinking fluorophores for a multitude of frames, such that each frame only contains a sparse subset of fluorophores. Assuming that single emitters give rise to a sparse subset of diffraction-limited spots, their locations can be determined with nanometer precision. The resolution of the final reconstructed image is limited by the localization precision and incomplete fluorescent labeling. To even further improve the resolution, by increasing the signal-to-noise and overcoming the problem of a low label- ing density, single-particle averaging can be used if multiple copies of the same target particle (e.g. macro- molecular complex) can be imaged. All emerging localization patterns are computationally merged into one super-superresolution image. Despite the increase in resolution, potential structural variation among the particles will blur the particle fusion result and possible (small) subsets of structurally different particles can- not be detected in the reconstruction. We present an a-priori knowledge-free, unsupervised classification method that splits the dataset into conformationally different groups of images prior to the merging process, which can subsequently be fused per class. The implemented algorithms are validated on multiple exper- imental and simulated datasets. We achieved classification performances of 96% on experimental datasets with up to four different DNA origami structures, are able to detect rare classes of mirrored origami’s occur- ring at a rate of 2%, and capture the variation in the ellipticity of nuclear pore complexes. This new classifica- tion tool will allow microscopists to study heterogeneous samples with single-particle averaging techniques and discriminate between different particles, structures or conformations with a high resolution.","Classification; Localization microscopy; structural heterogeneity","en","master thesis","","","","","","","","","","","","","",""
"uuid:23f7df57-303b-475b-be9f-0eae4af5b174","http://resolver.tudelft.nl/uuid:23f7df57-303b-475b-be9f-0eae4af5b174","Kebele 24: An urban redevelopment scheme for multistory dwelling in Addis Ababa, Ethiopia","Pasveer, C. (TU Delft Architecture and the Built Environment)","Amorim Mota, N.J. (mentor); Verkuijlen, S.H. (mentor); Mooij, H.A.F. (mentor); Hobma, F.A.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","It is projected by the United Nations that the population of Addis Ababa will increase to almost double the size as it has by the day today. Due to political, as well as geographical circumstances, there is very little vacant space left to accommodate this growth. To tackle this growth, the Ethiopian government established the Integrated Housing Development Project (IHDP), a large scale and top-down, mass housing project. Inherent to the design of the condominiums of the IHDP are problems, varying from imposing a new lifestyle which does not correspond to the current lifestyle of the new residents, to the allocation of current residents to other parts of the city and thereby breaking up their social and economic network. Alongside the formal developments of housing we see in Addis the rapid formation of informal settlements, commonly referred to as slums. This too causes problems. First of all, the living condition inside these informal settlements can be considered as poor. Second, it is a bad allocation of valuable and scarce resources like land, labour, materials and energy. However, they do offer urban conditions which is one of the primary reasons why people move the cities: the accessibility to high economic activity. The project proposed in this report tries to find a synthesis between these two developments by answering the following question: How can a large scale affordable and progressively built housing scheme, incorporate the needs of different social classes while accommodating and maintaining different kinds of (informal) economic urban activities and being at the same time adaptive to future social changes?<br","Densification; Global housing; Rapid urbanization; Redevelopment; Low-cost housing","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Global Housing","Addis Ababa Living Lab: Creating Resilient Dwelling Clusters for Urban Resettlement","9.008819, 38.797084"
"uuid:d59e3379-7598-4064-8ffb-0db0c1726c35","http://resolver.tudelft.nl/uuid:d59e3379-7598-4064-8ffb-0db0c1726c35","Solar Charging Electric Vehicles: Analysing the charging efficacy of an off-grid, solar powered electric vehicle charging system in long stay carpark applications","Heath, Edward (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Process and Energy)","van Wijk, A.J.M. (mentor); Ghotge, R. (graduation committee); Delft University of Technology (degree granting institution)","2020","The need for sustainable practises in all walks of society are more pressing than ever, with the effects of climate change being felt worldwide. Furthermore, the increasing share of variable and decentralised power generators coupled with the growing electricity demands from electric vehicles (EVs) at irregular times is placing unprecedented stresses on national power grids. To this end, innovative solutions to these complex issues are required. Electric vehicle solar carports (EVSCs) are structures that provide shelter for cars parked under a canopy roof fitted with PV modules. Adjacent to these parking spaces are the EV chargers, powered with the solar generated electricity. The aim of this study was to develop an accurate model and simulate an off-grid EVSC system for long stay parking applications, more specifically for the case of Lelystad Airport. <br/>The base case consisted of ‘dumb charging’ which simply split the generated current evenly amongst the actively charging EVs and curtailed any excess. The results of this found that across the year, 85% of EVs left with and adequate state of charge (SOC), defined as being greater than 75% of nominal battery capacity.<br/>This was then compared to various other scenarios in a rigorous sensitivity analysis to better understand the influential design parameters and attain a better final SOC distribution. Additionally, an economic assessment was performed, in which the base case was compared to a conventional grid-dependent system as well as a grid-inclusive, PV + grid, system.<br/>It was found that the off-grid EVSC system is a profitable investment, and that better system design can result in a better charging performance as well as provide resilience to detrimental scenarios.","Solar PV; Electric Vehicle; PV System; Charging Infrastructure","en","master thesis","","","","","","","","","","","","","","52.456, 5.517"
"uuid:28512648-6ea2-4706-a18f-15cdb0c6a63f","http://resolver.tudelft.nl/uuid:28512648-6ea2-4706-a18f-15cdb0c6a63f","Bridging Nicosia: Finding common ground for building peace in the contested city","Dimitriou, I. (TU Delft Architecture and the Built Environment)","Rocco de Campos Pereira, R.C. (mentor); Newton, C.E.L. (graduation committee); Delft University of Technology (degree granting institution)","2020","Cyprus is an island where two opposite civilizations with great history meet, but unfortunately do not interact. Greek- and Turkish-Cypriots used to coexist in peace on the island, despite their differences. However, their strong ethnic identities and foreign influences developed feelings of mistrust and fear between them. Therefore, this resulted in nationalistic claims of sovereignty which ended in territorial separation.<br/>The capital of Cyprus, Nicosia, is divided for more than 50 years. This division was an attempt to ease the tension between the two rival communities. In 1964, a cease-fire line patrolled by The United Nations Peacekeeping Force in Cyprus (UNFICYP) was established in the most commercial area of the capital. Then, Turkish military forces invaded the island and divided the whole country into two ethnic parts. Within a day the spatial, social, and political background of the island changed completely. Forcible division, violation of human rights, and displacement of people from both communities were some of the consequences of this ethnic conflict.<br/>It is recognised that as the dynamics of the buffer zone change, so also the status of the conflict. The conflict today is completely different from how it was before and right after the division; it is domesticated. Following so many years of failed negotiations in the political context and without conclusions, this protracted conflict transformed from a domesticated conflict into a comfortable one. Even though the consequences of this conflict violated a load of human rights and created feelings of injustice and fear between the two communities, it also created a state of a stable ‘instability’ in the island; both communities either it was by force or not, accommodate themselves in this situation. Thus, it is required a paradigm shift in order to move the focus away from the conflict and emphasise on constructing a shared future for dealing with common issues. Moreover, even though domestic and international negotiators have been working on a settlement for reconciliation, the final decision depends on the society, and unfortunately not so many Cypriots trust current peacebuilding processes.<br/>This research project aims to prepare the ground for conflict resolution by bridging the spatial and socio-cultural gap between the two communities. Therefore, the research proposes the “commoning” process, which is self-govern and self-sustain cooperation for overcoming common issues. Bi-communal cooperation<br/>holds promise for bringing the two communities together, as well as increasing people’s awareness and participation with the wider objective to create a sense of belonging and a sense of community in the contested city.","","en","master thesis","","","","","","","","","","","","","","35.11.8.0376, 33.22.56.1900"
"uuid:3eaddab1-3863-4c18-9ace-e97649230609","http://resolver.tudelft.nl/uuid:3eaddab1-3863-4c18-9ace-e97649230609","Online Learning of Tire Behaviour combined with MPC for Autonomous Racing","Iyer, Kunal (TU Delft Mechanical, Maritime and Materials Engineering)","Shyrokau, B. (mentor); Wisse, M. (graduation committee); Pan, W. (graduation committee); Ivanov, Valentin (graduation committee); Zheng, Y. (graduation committee); Delft University of Technology (degree granting institution)","2020","In this project, a unique method of combining online learning with model predictive control is applied to autonomous racing. A concern in autonomous racing is that accurate models that encapsulate the dynamics of the vehicle are complex, nonlinear, and difficult to identify. In order to make this more practical for control purposes, the controller is initialized with a nominal tire model, which then learns tire properties online using locally weighted projection regression during the course of the race. This makes it more practical for control purposes while maintaining model accuracy. Focus is placed on learning the tire properties which in reality, keep varying due to wear, temperature and pressure fluctuations, etc. The main objective is to minimize lap times by allowing the controller to ""learn"" its varying tire behavior while on the track.","Autonomous racing; Locally weighted projection regression; Model Predictive Control; Online Learning","en","master thesis","","","","","","","","2023-08-04","","","","","",""
"uuid:c2fe085c-429f-48b1-bbab-d6b0ea19cbbf","http://resolver.tudelft.nl/uuid:c2fe085c-429f-48b1-bbab-d6b0ea19cbbf","Effect of sodium chloride on the formation of ice and salt during eutectic freeze crystallization of sodium sulfate with a scenario study of real brine","Wu, HAO (TU Delft Civil Engineering and Geosciences)","Spanjers, H. (mentor); Ebrahimi, S. (mentor); van Loosdrecht, Mark C.M. (mentor); Heijman, Sebastiaan (mentor); Delft University of Technology (degree granting institution)","2020","Brine streams from industry is a burden to the environment if not disposed properly. “Zero liquid discharge” (ZLD) is an ideal way of converting saline streams from waste to resource through multiple membrane-based or thermal-based treatment technologies. The utilization of the recovered resource minimizes both costs and environmental impacts. Among the brine treatment technologies, the Eutectic Freeze Crystallization (EFC) is a promising thermal-based technology to obtain water and salt in high purity. EFC technology has higher energy benefit and simpler equipment than conventional evaporation technology. This technology is feasible for continuously recovering pure salt and ice in different stages, and separating them spontaneously. In this study, batch EFC experiment was conducted to determine the solubility curve of Na2SO4 under the different concentrations of NaCl. The effect of NaCl on the solubility of Na2SO4 at the low-temperature interval was investigated. It was found that with the increasing concentration of NaCl, the common ion effect between Na2SO4 and NaCl reduced the solubility of Na2SO4 and depressed the eutectic point (EP) of Na2SO4-H2O system. The decreasing EP showed a linear trend. A thermodynamic model in OLI Studio was used to evaluate the solubility of Na2SO4 as well. The modelling result was compared with the experimental data. The experimental result about the EP of Na2SO4-H2O system has a better agreement to the theoretical value than the eutectic concentration of Na2SO4. Besides, the effect of NaCl was compared with KCl in the OLI Studio, the salting- in effect of KCl promoted the solubility of Na2SO4. A scenario study was carried out to explore a proper process to treat reverse osmosis (RO) concentrate from a demineralised-water-producing (DWP) plant that was rich in Na+, SO42- and Cl-. The thermodynamic model was used to simulate the continuous EFC process and investigate how the different pre-treatment processes affect the recovery of Na2SO4. Four scenarios with different pre-treatment technologies were put forward based on the existing processing facilities: Scenario 1: RO – NF – EFC, Scenario 2: RO – TOC – NF – EFC, Scenario 3: RO – TOC – EFC, Scenario 4: RO – TOC – NF – RO – EFC. All the scenarios could reach more than 92% recovery of H2O. Among the four scenarios, Scenario 4 accomplished the highest recovery of Na2SO4 (98.4%) by -3℃. But the scaling tendency and poor permeate quality of the second RO unit made spontaneously. The gap between ice yield and Na2SO4·10H2O (Mirabilite) yield was significant in all the scenarios. It was suggested only to recover H2O rather than both H2O and Na2SO4, which can be achieved by means of Scenario 1 or 3. In Scenario 2, the close nucleation temperature of ice and mirabilite brought problem for separation work. To conclude, EFC is a newly emerging technology that can achieve a sequential removal of minerals from brine and is sustainable. There are barriers to overcome in impurity studies and those problems deserve attention. Further developments should be stimulated on recovering H2O and salt with an advance retrieving method, for example the design of multi-stage separation process, and the synergistic effect of different ion species and the combined effect of the organic compounds.","Eutectic Freeze Crystallization (EFC); Brine treatment; crystallisation; Sodium chloride and Sodium Sulphate","en","master thesis","","","","","","","","","","","","Civil Engineering | Environmental Engineering","ZERO BRINE",""
"uuid:df220341-baad-457c-9b7d-895af262e655","http://resolver.tudelft.nl/uuid:df220341-baad-457c-9b7d-895af262e655","Early Warning model for Thunderstorms around Lake Victoria","Magura, bart (TU Delft Civil Engineering and Geosciences)","ten Veldhuis, Marie-claire (mentor); van de Giesen, N.C. (graduation committee); Schleiss, M.A. (graduation committee); Delft University of Technology (degree granting institution)","2020","This report describes the development of an early warning model for thunderstorm occurrence around Lake Victoria. It is the first model to use the TAHMO lightning sensor data to predict thunderstorms. This study hopes to contribute to the TWIGA focus area of increasing disaster resilience through forecasting and early warnings and could be used to reduce the impact of thunderstorms for the communities around Lake Victoria, and to aid the flights of Zipline’s medicine-delivery drones.","Thunderstorms; machine learning; Early Warning Model; Lake Victoria","en","master thesis","","","","","","","","","","","","Civil Engineering | Environmental Engineering","",""
"uuid:f85d3daf-c944-4781-9d4b-495119fd94f0","http://resolver.tudelft.nl/uuid:f85d3daf-c944-4781-9d4b-495119fd94f0","Bridging the Past and the Future: a New Palimpsest Layer for the Heritage Landscape of Hof te Dieren","Yuan, Beiqi (TU Delft Architecture and the Built Environment)","Luiten, E.A.J. (mentor); van Emstede, C.I.C. (graduation committee); Cattoor, B. (mentor); Delft University of Technology (degree granting institution)","2020","Heritage landscape as a dynamic system that bridges the past and the future, on the one hand tells the history of an area and contributes to the identity of local people, and on the other hand need to meet the contemporary demand and deal with future challenges. In that case, apart from traditional strategy of isolating cultural heritages from urbanisation for protection, is there a new perspective to view heritage landscapes and a new approach to tackle them?<br/><br/>Hof te Dieren is an estate located in Gelderland province. With rich cultural-historical value lying in the land not fully recognised by people, it is simultaneously facing a series of challenges that are common in other Gelderland estates. This thesis studies Hof te Dieren as a case and uses palimpsest as an approach to read the historical traces in the site and to design new development.","Heritage landscape; Estate landscape; Palimpsest; Landscape Biographies","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Landscape Architecture","",""
"uuid:a8881fa4-6652-4e1b-a4d2-d35d53785485","http://resolver.tudelft.nl/uuid:a8881fa4-6652-4e1b-a4d2-d35d53785485","Supply and planning in the factory of the future: The implementation framework","Nijland, Davey (TU Delft Technology, Policy and Management)","Ding, Aaron Yi (mentor); Tavasszy, Lorant (graduation committee); Delft University of Technology (degree granting institution)","2020","Recent developments in technology innovations show that huge efficiency improvements can be made in the manufacturing industry. Moreover, companies that adopt the new innovations, associated with Industry 4.0, can create a huge competitive advantage. However, these rather conservative businesses are slow adopters and usually wait for proof-of-concept before actual implementation. Since this industrial revolution, Industry 4.0, is still in its infancy, more research is required to get to full adoption. Although the industry still awaits proof-of-concepts, many different case studies have been performed, and with success! These clearly exhibit the versatility of the Industry 4.0-philosophy, makingwidespread adoption just a matter of time. One of the identified reasons for this lag in adoption is the lack of clear implementation guides despite the thorough research and redundancy of technology. Due to the holistic Industry 4.0-concept, many practitioners lose sight on how and what to implement. Various researches proposed the creation of a widely applicable implementation model, but this is yet to be developed. One of the prominent issues related to creation such model is the all-encompassing nature of Industry 4.0; it includes novel innovation in supply chains, in factories, and even in the products manufactured. Since there are clear differences between these ’applications’, a generic overarching model seems unreasonable considering the immense amount of variables to consider. This thesis depicts the first ever-made implementation model specifically aimed at improving raw material supply &amp; planning in complex manufacturing companies.Supply &amp; planning processes are the closest connections between a manufacturers’ own operations and its closest neighbours in the supply chain; i.e. suppliers and customers. Tapping into this specific field of operations enhances the utilization of Industry 4.0 both on the supply chain and manufacturing aspects. Through answering the main question, and several subquestions, relevant information is gained that enable the construction of an implementation model. The design of such implementation model includes a step-by-step approach for practitioners of manufacturing companies, and a clear description on what to consider at each step. Creation of the artefact (i.e. implementation model) happens by explaining the research question: How can Industry 4.0 be implemented into supply and planning departments of complex manufacturing companies using an implementation framework?By means of a design science research methodology (DSRM) the Industry 4.0 supply &amp; planning implementation framework is designed. Through 6 pre-determined steps; (i) problem identification, (ii) objective definition, (iii) design &amp; development, (iv) demonstration, (v) evaluation, and (vii) communication, it ensured that all relevant stages are included to construct a scientific substantiate artefact. Three of these elements in particular were considered to be main constructs of the thesis report. Through the objective definition stage, qualitative research in the form of interviews and literature review imposed what had to be included in the implementation model. In the design &amp; development stage this information was casted into a mold, thereby being the first result to the thesis’ ultimate goal. The demonstration phase was assigned to check the applicability and effectiveness of the model by putting it into practice. Altogether a significant base of information was collected, obtaining the firstconceptual implementation model for Industry 4.0. In the existing tight markets in which various manufacturers operate, the utilization of improvement technologies is high. Techniques derived from methods like Lean, Agile and Six Sigma are used on a daily basis. Because companies are familiar with the use of these models, the adoption of newer versions becomes straightforward. Consequently, the implementation model is a derivative of such method, namely the DMAIC (Define, Measure, Analyze, Improve, and Control). Since these overarching steps do not provide sufficient information for actual implementation, extra delineation is applied through a combination of the Continuous Quality Improvement model and practitioners’ experiences. Via combination of the two, a first model consisting of 11 steps (i.e. within the 5 DMAIC stages) was constructed.The implementation model starts with goal identification, in which the companies’ digital transformation (i.e. Industry 4.0-adoption) strategies are adapted to local needs. Subsequently, the business processes are investigated thoroughly. By clever modification of an existing model called RAMI (ReferenceArchitecture Model Industrie 4.0), a standardized approach for identifying the key aspects of the business processes was obtained. Using the results of this business process modelling allows to diagnose the so-called key variables that have a considerable effect on the performance of operations. The top five of these key variables provide the focus for the execution of the consecutive steps. Data and information about these 5 variables is gathered through a process of replacing paper forms by digital forms and through connection of existing Operational Technology (OT) systems with Information Technology (IT) systems. Once all the relevant data for the five variables is obtained, a data analysis follows. Examining the inconsistencies in this data pinpoint the location where data enhancement (i.e. Industry 4.0-adoption) will significantly improve the process. Defining the performance indicators then help to know the business’ existing performance and allow comparison with future results, but also help users to monitor real-time process-efficiency by means of a dashboard. According to the Key Performance Indicators (KPI’s) chosen, technology introduction can finally happen. Thirteen different enabling technologies were identified during the literature research, providing practitioners a wide portfolioof options in their Industry 4.0-implementation. Shortly after implementation follows continuous monitoring according to the aforementioned KPI’s. By carefully assessing the business process’ performance, improvement studies can be performed and actual improvement of the system can take place. In the final stage it is evaluated whether the implementation was effective and what lessons-learned should be brought to the next technology-implementation. To test whether the implementation model indeed fulfil its vows, a test run is performed at an agriculture fertilizer manufacturing facility that definitely classifies as a complex factory according to the definition of this thesis (i.e. large portfolio of products and raw materials). The first few stages were quite obvious in their execution, mainly because of the clear instructions given. Especially the modified RAMI model gave useful insights and abandoned the requirement of complete Business Process Mapping which is very time consuming. Various key variables were obtained using a quality team. Since the majority of data -for these key variables- was already available, it was only a minor effort to obtain the rest using either OT-IT merger or digital reporting. In the case study, the data analysis stage was the most demanding task in both time and extra investigation. After describing the KPI’s related to the data analysis and describing the technology introduction stage, the real version of the case studyhad come to an end due to time and resource limitations. Continuous monitoring, improvement, and evaluation were further concluded through the sense of ’modelling’, where providing examples and describing the expected outcomes served as enclosure of the first trial. Although the model was designed with extra care and the input from both the literature review and the interviews were significant, some limitations still apply. It was observed that some of the stages were not definitive enough, making the actual goal of each step rather vague. As a result, some stages could take considerably more time than necessary, diminishing the model’s effectiveness. Moreover, the power of the data analysis, as described before, was truly reliant on my experience in statistical and data analytics. Therefore, the current data analysis-description requires more attention to advance the usefulness of this stage regardless of the users’ experience. Finally, the effectiveness and generalizability of the model were only touched upon briefly and require more in-depth investigation before claiming its novelty.","Industry 4.0; smart factory; Supply Chain; Supply & planning; Operations","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:02cc8ccb-33ae-4b07-a402-ac5baf3ec365","http://resolver.tudelft.nl/uuid:02cc8ccb-33ae-4b07-a402-ac5baf3ec365","Joint angle coupling of a musculoskeletal model and a graphical model of the hand for enhanced display in medical education","Cueto Fernandez, Judith (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Biomechanical Engineering)","Mugge, W. (mentor); Geelen, J.E. (mentor); van der Helm, F.C.T. (graduation committee); Bogomolova, K. (mentor); Hierck, B.P. (mentor); Hovius, S. (graduation committee); Delft University of Technology (degree granting institution)","2020","Advanced anatomical knowledge and understanding of the muscles involved in various movements are crucial for medical practitioners to reach the correct diagnostic and successfully predict surgery outcomes. To acquire this knowledge, 3D graphical anatomical models which are displayed stereoscopically can effectively supplement cadaveric dissections. Nevertheless, the movements implemented in the available graphical models do not accurately reproduce the intricate dynamics of the human body, which is especially relevant in the case of the hand. Biomechanical models, on the other hand, provide accurate movement simulations from experimental data, while lacking a detailed graphical representation. Thus, the current paper focuses on the incorporation of the biomechanical model of the hand developed by Mirakhorlo et al. (2018) into a comprehensive graphical anatomical model (Zygote Media Group Inc), to be used for educational purposes. Motion capture data of a pinch task was acquired to validate the combinational approach, and an inverse kinematics simulation was performed in OpenSim using the musculoskeletal model. A reference value based on the fingertip distance difference at the pinch pose was calculated from the experimental data and the simulated motion by the musculoskeletal model. This value was used for validation of the musculoskeletal model reproducibility by the graphical model. Comparison shows that the graphical model reproduced the simulated motion with satisfactory visual effects and within an acceptable range from the reference metric. The presented approach is considered a successful first step towards a biomechanically and anatomically accurate graphical model of the human hand. This lays the foundation for further work on minimising the effect of the anatomical differences between the two models in order to achieve a better match.","Hand Model; Musculoskeletal Model; Graphical Model; Inverse Kinematics; Motion Capture; Joints; Finger","en","master thesis","","","","","","","","","","","","Mechanical Engineering | BioMechanical Design","",""
"uuid:8d5e0ef2-63d1-42ea-a69e-1f8fc89f4b10","http://resolver.tudelft.nl/uuid:8d5e0ef2-63d1-42ea-a69e-1f8fc89f4b10","Waste Collection in Amsterdam Centrum Using Autonomous Vessels: Optimization of container type selection and location for household waste collection in Amsterdam Centrum with Autonomous Vessels (Roboats)","van Toor, Hank (TU Delft Mechanical, Maritime and Materials Engineering)","Atasoy, B. (mentor); Deinema, Ynse (mentor); Numan, Anita (mentor); Negenborn, R.R. (graduation committee); Jarquin Laguna, A. (graduation committee); Delft University of Technology (degree granting institution)","2020","This research strives to contribute to the solution of the Amsterdam waste problem by improving the location determination of the various container types within the Centrum area. One of the modalities is an autonomous surface vehicle (ASV), and in this case, a Roboat. Since it is not possible to assign all demand to one modality, also trucks and small electric vehicles are taken into account. This waste collection problem is represented through a facility location problem with different facility types in order to maximize the coverage with a minimum number of containers. Case studies are designed in Amsterdam Centrum, and different calculation strategies are executed to compare different methods.","Autonomous Surface Vessels; GIS; facility location; multi-facility; location-allocation; Waste management","en","master thesis","","","","","","","","","","","","Marine Technology | Transport Engineering and Logistics","","52.3737208, 4.9149086"
"uuid:fad805a9-136b-49a7-a2e8-228b37ba597f","http://resolver.tudelft.nl/uuid:fad805a9-136b-49a7-a2e8-228b37ba597f","Improving Search Relevance Feedback through Human Centered Design","GU, Shengfeng (TU Delft Industrial Design Engineering)","Bozzon, A. (mentor); Lomas, J.D. (mentor); Szlávik, Zoltán (mentor); Delft University of Technology (degree granting institution)","2020","br/>Artificial intelligence (AI) is expected to play a transformational role in health and wellbeing. Search (i.e. information retrieval) technologies already play a significant role in healthcare research and practice. Relevance feedback in Search is vital for system evaluation and improvements. However, in small user scale contexts, the exploitation of user behaviors may not infer valid relevance judgments. Therefore, engaging users to provide such feedback explicitly is essential for improving search performance (i.e. effectiveness). However, previous research has found that users are generally reluctant to provide explicit feedback in digital environments, and the willingness decreases overtime in some experiments. In collaboration with myTomorrows, an Amsterdam-based pharma-tech company, this Master thesis aims to find answers to the challenge mentioned above through a specific context of myTomororws AI-powered treatment Search which has the urgent need for engaging healthcare professionals (HCPs) in providing relevance feedback on search results (e.g. Clinical Trials and Expanded Access Programs) for system evaluation and improvements. Through Human Centered Design methods such as interviews, observations, and speed dates, the project yielded a future myTomorrows Search design enhanced with three relevance feedback collection concepts. As research materials, the concepts were tested and evaluated by nine HCPs from three countries (the Netherlands, China, and Brazil). The user study results indicate that embedding utility, as the motivator, in relevance feedback collection appeals to HCPs more than using motivators such as altruism or enjoyment. Moreover, the best point of user engagement is identified as the moment between users finishing the examination of information and starting the next ones. Additionally, this study generalized the project process and user study insights into a four-stage guide for designing explicit feedback collection in text-base Search. Although it remains unvalidated, this guide has the potential to apply to other small user scale contexts, guiding or inspiring user researchers and designers to design explicit user feedback collection in Search.<br","Human Centered Design; Relevance feedback; Search experience; Healthcare","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:3acab98c-9f28-4acf-9c87-c919bf105908","http://resolver.tudelft.nl/uuid:3acab98c-9f28-4acf-9c87-c919bf105908","Researching the willingness of island residents to become self-sufficient: Deploying Discrete Choice Models on Schiermonnikoog","Terhoeve, Tessa (TU Delft Technology, Policy and Management)","Delft University of Technology (degree granting institution)","2020","Schiermonnikoog, just as a lot of other islands worldwide, aims to become energy self-sufficient by 2025. This requires major changes to the current electricity system. As it is desirable to involve the local population to create support for energy self-sufficiency, this paper aims to research the trade-offs that island residents are willing to make to become self-sufficient. This trade-off is formulated as the trade-off between energy self-sufficiency and energy security (consisting of availability, affordability and acceptability). From the results of the deployment of a choice model on Schiermonnikoog it can be concluded that island residents are willing to trade-off (to a certain extent) affordability and availability against self-sufficiency. When it comes to acceptability however, it turns out that island residents very negatively value the deployment of large renewable electricity plants on their island and are therefore not willing to trade-off acceptability against self-sufficiency.","","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:c4bff32e-b89c-4011-8fa7-13c78a85e500","http://resolver.tudelft.nl/uuid:c4bff32e-b89c-4011-8fa7-13c78a85e500","Magnetic Signature Translation for Magnetic Ranging with Drones","Analikwu, B.O. (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Applied Sciences)","Vijn, A.R.P.J. (mentor); van Dijk, N.H. (mentor); Lepelaars, Eugene (mentor); Heemink, A.W. (graduation committee); Bouwman, W.G. (graduation committee); van Gijzen, M.B. (graduation committee); Delft University of Technology (degree granting institution)","2020","In this thesis, an algorithm to model the magnetic perturbation field caused by ships is designed and implemented. A systematic description of methods used for modelling the magnetic signature of ships is given. The algorithm fits coefficients of a prolate spheroidal harmonic expansion of the scalar potential of the magnetic field using a least angle regression method (LARS) modified to implement Lasso regularisation. A Monte Carlo method with model selection based on Akaike's information criterion (AIC) is used to select optimal parameters specifying the prolate spheroidal coordinate system centred on the ship. Furthermore, a method to restrict the degree and order of the harmonic expansion is presented and an extension of the scikit-learn module in Python is given. The predictive power of the model was verified using simulated test data, which showed that the designed model is able to make adequate predictions, but improvements are needed. Different analyses on the inputs of the model showed that the model is succesful for low levels of noise, but is susceptible to overfitting for higher levels of noise. Several recommendations for further research are made.","Magnetic ranging; Magnetic multipole expansion; Least angle regression; Akaike's information criterion; Magnetic signature","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics | Applied Physics","",""
"uuid:65aff56a-a83f-4a3c-9575-fe061761b525","http://resolver.tudelft.nl/uuid:65aff56a-a83f-4a3c-9575-fe061761b525","Downscaling Integrated Assessment Models for Energy Transition Policy Support: Exploring Trade-offs and Limitations","Wang, J.R. (TU Delft Technology, Policy and Management)","Kwakkel, J.H. (mentor); Chappin, E.J.L. (mentor); Delft University of Technology (degree granting institution)","2020","Global Earth Systems Integrated Assessment Models are used by policymakers to understand the complex interactions between anthropogenic activity, including energy use, and its environmental impacts. However, they are computationally expensive, so spatiotemporal resolution is kept low as a trade-off. Generally, the smallest geopolitical component is a large nation. Yet, much of energy transition planning occurs at subnational levels. Downscaling is the process of turning low resolution model outputs into higher resolution ones and has been used extensively in hydrological and weather modelling. Since downscaling in the energy sector is nascent, this presentation reviews the trade-offs between statistical downscaling methods within the energy domain using ten newly developed criteria. Highlighting such trade-offs can better equip policymakers as they craft energy transition policies. These criteria fit within three main categories: replicability, coherence to the parent model (the IAM), and handling of energy-specific insights. The linear downscaling method was highly replicable and, though coupled to the parent model, assumes that all its constituent regions are homogeneous and distributes outputs blindly. It performs well to introduce technologies that do not exist yet, but does not consider geographic to resource use here. The convergence method similarly struggles with geospatial limitations, but obfuscates energy sector nuances described by the original model. It is less replicable than the linear method. Modifying these approaches could resolve some of their issues, but they will likely never be useful for serious policymaking. Two other methods described in the literature are also discussed that could overcome the limitations of these two approaches, though they are not implemented here. Downscaling energy systems still holds some promise, though significant research is required to integrate technological innovation and diffusion considerations to the methods.","integrated assessment modelling; downscaling; energy transition","en","master thesis","","","","","","Code and documentation of implementing and analyzing downscaling methods: https://gitlab.com/jasonrwang/downscaling-electricity","","","","","","Engineering and Policy Analysis","",""
"uuid:8cc69363-d934-4e11-9f52-5b4acb44220b","http://resolver.tudelft.nl/uuid:8cc69363-d934-4e11-9f52-5b4acb44220b","Electric Vehicle Traction Drive Using Si/SiC Hybrid Switches","Tan, C. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Batista Soeiro, T. (mentor); Bauer, P. (graduation committee); Lekic, A. (graduation committee); Delft University of Technology (degree granting institution)","2020","The parallel connection of a Silicon (Si)-based IGBT and a Silicon Carbide (SiC)-based MOSFET forming a so called hybrid switch can be used to capitalize on the advantageous features of both semiconductor and materials technologies. In this thesis, a hybrid switch-based inverter designed for the application of Electric Vehicle (EV) traction drive is compared to the conventional inverter assembled with Si-based IGBTs, and SiC-based MOSFETs. According to different standardized driving cycles, Electric Vehicles operate in low partial load for a considerable amount of the time. Therefore, in this application, semiconductor conduction losses can be considerably reduced when unipolar switches such as MOSFETs are used. Collectively, this work shows that the hybrid switch configuration constitutes a good compromise between efficiency and cost when compared to a solution implementing only Si-based IGBT or solely SiC-based MOSFETs.","Electric Vehicle; SiC; Hybrid Switch; motor drive","en","master thesis","","","","","","","","","","","","","",""
"uuid:21a9f62f-9b8e-4e46-8493-8209df7cac29","http://resolver.tudelft.nl/uuid:21a9f62f-9b8e-4e46-8493-8209df7cac29","Low-field MR Imaging Using a Nonuniform Fast Fourier Transform","Macarulla Rodriguez, M. (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Circuits and Systems)","Remis, R.F. (mentor); de Leeuw den Bouter, M.L. (graduation committee); Delft University of Technology (degree granting institution)","2020","Low-field Magnetic Resonance Imaging (LF MRI) is a cheap and safe technique to visualise the internal structure of the human body. Unlike other imaging techniques, Magnetic Resonance Imaging does not use ionising radiation to generate the images. Instead, it uses magnetic fields and radio waves which are nonthreatening to the health. The LF MRI scanners are constructed out of inexpensive materials and their maintenance is affordable. Therefore, these scanners are a promising alternative for developing countries that present economic limitations. Nonetheless, since Magnetic Resonance scanners use a weak magnetic field, the process of image reconstruction requires complex algorithms that need time. This thesis will examine the way in which the computational time of the image reconstruction from a low-field Magnetic Resonance Imaging can be reduced, using an algorithm based on the fast Fourier transform.","Low-Field Magnetic Resonance Imaging; nonuniform fast Fourier transform; nonlinear gradients; inhomogeneous background field","en","master thesis","","","","","","","","","","","","Electrical Engineering | Signals and Systems","",""
"uuid:336fe05c-4d3a-45a3-9e41-3545e565f10f","http://resolver.tudelft.nl/uuid:336fe05c-4d3a-45a3-9e41-3545e565f10f","Wireless Event-Triggered Control for Water Irrigation Systems","Lont, J.J. (TU Delft Mechanical, Maritime and Materials Engineering)","de Albuquerque Gleizer, G. (mentor); Mazo Espinosa, M. (graduation committee); van Nooijen, R.R.P. (graduation committee); Delft University of Technology (degree granting institution)","2020","The application of optimal control structures for water irrigation systems (WISs) can be enabled by applying wireless event-triggered control (ETC). The term WIS, is used to describe open-water channels, that are mainly used to supply water to farmers all around the world. The water levels in these channels need to be controlled, but because of the large scale of WISs, it is very expensive to create centralized control structures when using wired connections between individual sensors, actuators and a centralized controller. Previously, WISs were typically controlled using individual decentralized (non-communicating) controllers. Applying wireless technologies enables communication between (smart) sensors, actuators and a centralized controller without the expense of installing and maintaining cables over lengths of kilometers. To create such a wireless infrastructure, a network needs to be designed, consisting of multiple nodes that are able to communicate with each other over wireless. Each sensor and actuator will be connected to (or integrated in) a node, just like the centralized controller needs to be connected to a node. To minimize the costs related to creating such an infrastructure, the nodes should have their own power source in order to prevent that a maintenance worker has to change the batteries of the nodes periodically. The nodes could be powered using a solar panel, or by using energy harvesting, which could be done by using a turbine to extract energy from the flow in a water channel. When using such energy sources, it is important to minimize the power consumption of the nodes. Most of the consumed power is used in communication when transmitting information. By applying ETC, the amount of communication between the individual parts of the control system is minimized, while still retaining good closed-loop system control using a centralized controller. In this research, techniques on wireless control, ETC and WIS control are combined and the application of an event-triggered centralized controller is presented using simulations, as well as the achievable reduction in communication compared to regular periodic control. Furthermore, a cyber-physical lab setup is designed and built which makes it possible to test these techniques in the Delft Center for Systems and Control (DCSC) lab.","Event-triggered control; Wireless control; Water irrigation systems; Networked cyber-physical systems","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:fa2d3886-47da-4bff-ad3f-8eabe640ca85","http://resolver.tudelft.nl/uuid:fa2d3886-47da-4bff-ad3f-8eabe640ca85","Identifying Behavioural Changes due to Parkinson’s Disease Progression in Motor Performance Data: Development of a Tool for Monitoring Treatment of Parkinson’s Disease","Lugtenborg, Lieke (TU Delft Aerospace Engineering)","Pool, D.M. (graduation committee); Mulder, Max (mentor); Pel, Johan J.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","Parkinson's disease can severely affect motor performance and impede in executing daily activities. Treatment can greatly improve patients' quality-of-life, however, disease detection and monitoring is still performed subjectively. Quantification of patients' motor performance and its decline due to increasing symptom severity using tracking tasks could provide a solution and even help in early disease assessment. In order to develop a proof-of-concept for a tool that can be used for the detection of behavioural changes in motor performance data, the longitudinal clinical data are approximated by a combined data-set with experimental data of healthy participants and simulated Parkinson's disease control behaviour. 25 healthy participants in the age range of 55-75 participated in a manual pursuit tracking experiment to identify baseline control behaviour. PD data were simulated by bootstrapping the experimental data and scaling this value based on previous research. The resulting experimental and PD data were combined and a general linear regression model was used to see if a change in control behaviour due to upcoming PD symptoms could be detected with trend analysis. It was found that for the parameters related to a decline in motor performance caused by the disease, for at least 50% of the participants a simulated change in motor behaviour was successfully detected. This means that the developed method is able to detect a trend for half of the population and is a major step forward in the development of a tool that can aid monitoring of disease progression and treatment for Parkinson's disease.","Manual tracking; Parkinson's Disease; Cybernetics; System Identification; Trend analysis; Linear Regression; Behavioural change","en","master thesis","","","","","","","","2025-08-26","","","","Aerospace Engineering","",""
"uuid:ec17d83e-ed62-40d9-a56a-b07bff4052fd","http://resolver.tudelft.nl/uuid:ec17d83e-ed62-40d9-a56a-b07bff4052fd","Determination of the Pre-Qualification Rules for the Acceptance Testing of MVDC Cable System","Santosh, Adeep (TU Delft Electrical Engineering, Mathematics and Computer Science)","Ghaffarian Niasar, M. (mentor); Chmura, L.A. (mentor); Ross, Robert (graduation committee); Cvetkovic, M. (graduation committee); Bergsma, Dennis (graduation committee); Delft University of Technology (degree granting institution)","2020","In the transmission and distribution network of the future, there is expected to be a mix of both Alternating Current (AC) and Direct Current (DC). In the high voltage division owing to technical and economic aspects, there is a wider use of High Voltage Direct Current (HVDC) instead of High Voltage Alternating Current (HVAC). However, when observing the medium voltage network, it is noticed that it is completely AC in nature. One major reason for this preference of AC in the medium voltage network is the better know-how of an AC network and the presence of well established and reliable MVAC components and the ability to transform (step up and down) voltage in AC. A switch to Medium Voltage Direct Current (MVDC) is expected as the cost of power electronic components is decreasing with time, and there is an improvement in their performance. Therefore, switching to MVDC would provide advantages in the form of improved transfer capacity and better power control. MVDC grids are debated to be a vital member of the future distribution network. In the present scenario, there is an absence of such an MVDC grid. Thereby, there are also no MVDC accessories available which can be used in such a grid. Therefore, there is also the absence of a testing procedure for the same. CIGRE TB 496 provides the testing strategies for DC cable systems up to 500 kV, but it does not take into consideration the difference between an MVDC system and an HVDC system. The systems may have a striking difference in construction, such as concerning materials. Additionally, there is also a difference concerning max field stresses and thickness of the insulation. The possibility of using the AC accessories for DC application needs to be analysed, and it needs to be verified how such an AC accessory would behave under the influence of prolonged DC stresses. The use of existing MVAC accessories for DC would be beneficial given the high production standards and the voluminous supply chain of MVAC systems. Additionally, this also opens possibilities of reusing existing AC cable system for DC stress. It needs to be noticed that in DC, the field distribution would depend on the conductivity of the material which is different from AC where the field distribution depends on the permittivity of the material. The permittivity of insulation is virtually independent of the temperature. However, conductivity has a strong relation to temperature and electric field, which makes DC field distribution more complex when compared to AC field distribution for any geometry. The test criteria of MVAC and pre-qualification test for HVDC are well known and need to be utilised in proposing and motivating the test sequence and test voltages for the accessories to be used in the future MVDC network. These accessories to be used in this future MVDC cable system needs to be analysed using Finite Element Method (FEM). The field simulations would give identification of locations in the joint which are undergoing maximum stresses during DC application. These maximum values of stresses are used to calculate the voltage life of the system based on electro-thermal life laws. The test results based on the representative testing procedure would help in understanding the performance and lifetime of the cable systems under DC stress. Therefore, to understand all items previously mentioned, a representative testing procedure needs to be proposed and motivated to test the use of existing MVAC accessories in the future MVDC network.","Acceptance testing; MVAC cable system; COMSOL Multiphysics","en","master thesis","","","","","","","","2022-12-31","","","","","",""
"uuid:f5033eb5-148c-4c7f-a95b-8cee6d25c3d3","http://resolver.tudelft.nl/uuid:f5033eb5-148c-4c7f-a95b-8cee6d25c3d3","Exploring the Kuiper Belt: Design of trajectories for long-term Kuiper Belt exploration","van der Heyden, Laurens (TU Delft Aerospace Engineering)","Noomen, R. (mentor); Delft University of Technology (degree granting institution)","2020","Previous trajectory proposals with the purpose of exploring the Kuiper Belt have been limited to identifying trajectories to fly by a single pre-selected Kuiper Belt Object (KBO). Furthermore, these proposals were often limited to high-velocity flybys that pass through the Kuiper Belt in a limited number of years, or are based on the assumption of significant and uncertain technological advances. This thesis investigates the existence of currently feasible trajectories which position a spacecraft inside the Kuiper Belt for a significantly longer period of time. The feasibility of these trajectories is based on the assumption of current technological capabilities and a launch date between the years 2025 and 2040. To model these unique trajectories the conventional MGA-1DSM trajectory model is adapted in order to optimize trajectory problems that aim to reach the Kuiper Belt. The use of powered flybys is excluded in these problems in order to reduce problem and mission complexity. Optimization of the trajectory problems was done by performing an interactive multi-objective optimization approach with four distinct objectives on a set of twenty planetary sequences. The high complexity of these problems in combination with conflicting multiple objectives was found to necessitate an iterative optimization process using the pooled results of several algorithms in order to obtain satisfactory results. The optimization algorithm performance was further enhanced using various encouragement methods. By using the established optimization method multiple routes were identified that all culminate in a long-duration flight through the Kuiper Belt. The best results were found with planetary flyby sequences VVEJS, EVEEJN, and JN. The required launch energy (C3) for these trajectories ranges from 16 km² /s² , for sequences utilizing multiple inner planet flybys, to 75.5 km²/s² , for solutions utilizing adirect Jupiter-Neptune route. The maximum onboard delta V capability required for these solutions is 400 m/s. The flight time to the inner boundary of the Kuiper Belt ranges from 14.6 to 24 years. All thesetrajectories feature a flight time through the Kuiper Belt of well over or close to 100 years. In addition, it was found that trajectories that conclude their planetary flyby sequence with a Jupiter-Neptune leg are found to be especially well suited for long-duration Kuiper Belt flight.","Kuiper Belt; Trajectory Design; Optimization","en","master thesis","","","","","","","","2022-09-01","","","","Aerospace Engineering","",""
"uuid:ab705d29-b73f-4e58-a2b0-9d22ed23b6ce","http://resolver.tudelft.nl/uuid:ab705d29-b73f-4e58-a2b0-9d22ed23b6ce","Learning for Control: An Inverse Optimization Approach","Akhtar, Adnan (TU Delft Mechanical, Maritime and Materials Engineering)","Mohajerin Esfahani, P. (mentor); Delft University of Technology (degree granting institution)","2020","Data driven learning has become a common practice in many decision making applications. Machine learning techniques are the dominant methods employed but have limitations with respect to constraints satisfaction. A learning method is presented to learn the mapping from an input space to an action space, which is particularly suitable when the action is an optimal decision with respect to a certain unknown cost function. An inverse optimization approach is presented to retrieve the cost function, like inverse reinforcement learning, by introducing a<br/>new loss function along with a new hypothesis class of mapping functions. The loss function used is particularly suitable when the action is representative of an ‘expert’ behaviour, that takes actions by cost minimization. A tractable reformulation of the learning problem using the new loss function is also presented. The method is effective for learning input-action<br/>mapping for constrained systems in continuous input-action space, typically present in control systems. The learning approach can be effectively transformed to learn a MPC behaviour and a case study to mimic an MPC is presented, which is a rather computationally heavy control strategy. Simulation results and experiments on a lab helicopter show the effectiveness of the proposed approach.","Learning for Control; Inverse Optimization; Behavior Cloning; Imitation Learning","en","master thesis","","","","","","","","2022-08-31","","","","Mechanical Engineering | Systems and Control","",""
"uuid:872485e8-6434-4212-9be9-e5633f534adf","http://resolver.tudelft.nl/uuid:872485e8-6434-4212-9be9-e5633f534adf","WhirlWind: Wind Energy Harvesting Wireless System for Sensing Angle of Attack and Wind Speed","Sharma, Suryansh (TU Delft Electrical Engineering, Mathematics and Computer Science)","Venkatesha Prasad, R.R. (mentor); Verhoeven, C.J.M. (graduation committee); van Genderen, A.J. (graduation committee); Delft University of Technology (degree granting institution)","2020","","Wind energy harvesting; Angle of attack sensor; Wind speed sensor; Piezoelectric energy harvester (PEH); Batteryless; Aeroelastic flutter","en","master thesis","","","","","","","","2022-08-31","","","","","",""
"uuid:00611754-0599-4b9c-9218-1bd8fd9c2111","http://resolver.tudelft.nl/uuid:00611754-0599-4b9c-9218-1bd8fd9c2111","A Circular Economy in 2050: A Look at the Stocks and Flows of Electricity Cables in the Netherlands","Verschelling, Judith (TU Delft Technology, Policy and Management)","van der Voet, E. (mentor); Korevaar, G. (mentor); Delft University of Technology (degree granting institution); Universiteit Leiden (degree granting institution)","2020","","","en","master thesis","","","","","","","","","","","","Industrial Ecology","",""
"uuid:5e1dec98-ec4f-4079-a945-8cb74c67bf43","http://resolver.tudelft.nl/uuid:5e1dec98-ec4f-4079-a945-8cb74c67bf43","Assessing the changes required in the energy infrastructure with regard to the heating transition: An analysis of the materials and associated emissions of constructing the future energy infrastructure","Altena, Robert (TU Delft Technology, Policy and Management)","Sprecher, Benjamin (mentor); Heintz, John L. (graduation committee); Delft University of Technology (degree granting institution); Universiteit Leiden (degree granting institution)","2020","In the Netherlands, almost half of the energy supplied to households is used for space heating. Since natural gas supplies heating fuel to almost 95% of residential buildings Dutch municipalities have to investigate the possibilities of diversifying their heating infrastructure in order to comply with government environmental goals. Possible heating alternatives included in this study are; biogas, district heating and all-electric. In this thesis, a geospatial model was constructed to analyse the energy demand of the city of Leiden and its energy infrastructure. By combining various governmental datasets in Python and GeoPandas an analysis on the city scale is possible. The main focus of the thesis is material demand for each heating alternative and the associated environmental impact of those materials. The current heating system of natural gas scores lowest on total material demand and embedded carbon. Of the investigated alternatives the district heating scenario has most materials embedded into the infrastructure and also the highest carbon footprint. The all-electric scenario completely replaces heating infrastructure by only utilising electricity for heating. This results in a significant system change with average material consumption. However, the all-electric scenario scores highest for demand in REE’s. A combination of heat pumps and biogas resulted in the lowest material consumption of the researched alternatives. This scenario combines the relatively simple conversion to biogas for older houses with the most efficient heating utilising heat pumps for new houses. The major drawback for this scenario would be the sourcing of biomass required for biogas production.<br/>In terms of embedded CO2 the sustainable heating alternatives proposed in this thesis score higher than the current system. However, the embedded carbon of the building materials would be compensated for in the first year if use-phase emissions are taken into account. The emissions associated with the construction of the supporting energy infrastructure were found to be significantly smaller compared to the use-phase emissions. Together with factors such as heat source availability, investment costs and social acceptance of the heating alternatives municipalities have to decide which heating alternative has its preference.","infrastructure; Heating transition; GIS","en","master thesis","","","","","","","","","","","","Industrial Ecology","",""
"uuid:ccb85a73-f2a7-4674-bb6c-6a6d1f63e9fd","http://resolver.tudelft.nl/uuid:ccb85a73-f2a7-4674-bb6c-6a6d1f63e9fd","The phenomenon of expression in resort modernism of Soviet Lithuania: Western dream then, undesirable shadow now? Collective remembrance | national identity | “young” heritage","Mankutė, Aistė (TU Delft Architecture and the Built Environment)","Tanovic, S. (mentor); Delft University of Technology (degree granting institution)","2020","During thirty years of independent Lithuania, numerous iconic modern and postmodern buildings from the Soviet period had been demolished. Only in recent years architects and preservationists have started to protest and communicate the message of opposition to such activities but in most cases, it is too late to save an artifice.<br/>In the rich field of architectural edifices of social modernism, resort architecture is particularly interesting. It can be stated that it was in the resorts that some of the most original and valuable structures of socialist modernism were erected in Lithuania. In theory it should be regarded as a niche where true Lithuanian architecture could have emerged through the limitations of Soviet apparatus, however it is surprising to see this sort of architecture neglected or demolished.<br/><br/>Knowing that architecture makes up a large part of the regional identity, demolition of unique recreational buildings can lead to irretrievable loss of existing genius loci. Therefore, my main research question is why and how large number of expressive examples of socialist resort modernist architecture in Lithuania are undesirable?<br/>Is it a matter of economics, considering the prestigious location of most of the remaining resort buildings? Is it because of the inseparable link between politics and architecture? Is it the institution of heritage and conservation failing to protect them? Is collective remembrance being altered when difficult heritage buildings are being demolished?<br/>In addition to the existing discussion within the Lithuanian community about Soviet time heritage preservation, I am considering the unique resort buildings being part of the national identity and as an element of a cultural phenomenon.<br/><br/>In the first chapter I explain historical context and the origin of socialist modernism, prevailing ideological apparatus at the time, significance of resorts and their architecture.<br/>The second chapter consists of investigation what is hiding “behind the scenes” of the ignorance of socialist modernist architecture. In different sections I discuss such architecture in terms of memory, collective remembrance, explain the concept of genius loci, talk about psychological confrontations of the country, elaborate on how heritage preservation is not always applicable in Lithuania and look into economic aspect.<br/>The third chapter addresses two case studies - demolition and renovation of resort buildings. Firstly, I discuss the demolition case of cafe “Banga” (1796; demolished in 2015) in Palanga. Secondly, renovation of café “Vasara”(reconstructed in 2005).<br","Collective Memory; Identity; young monument; young heritage; collective remembrance; Lithuania; Resort architecture; recreation architecture; resort modernism; soviet modernism; expressive architecture; socialist modernism; Ideology; genius loci; demolition; Renovation","en","student report","","","","","","","","","","","","Architecture, Urbanism and Building Sciences","","55.916450, 21.065541"
"uuid:b6dcabb0-4d92-4952-b5ea-855cee9f0de5","http://resolver.tudelft.nl/uuid:b6dcabb0-4d92-4952-b5ea-855cee9f0de5","Designing a construction logistics control tower for city development: A case study in Amsterdam Amstel III","Tesselaar, Tom (TU Delft Technology, Policy and Management)","Ludema, M.W. (mentor); Ploos van Amstel, Walther (mentor); Zuiderwijk, AMG (mentor); Delft University of Technology (degree granting institution)","2020","","Coordination; Construction Logistics; 4C; Contol Tower; Cross Chain Control Centre; Supply Chain Management","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:19b8ab1c-82d2-48d0-98de-21cc72dc58d9","http://resolver.tudelft.nl/uuid:19b8ab1c-82d2-48d0-98de-21cc72dc58d9","Performance modeling of PageRank in large-scale systems: A case study","Doekemeijer, Niels (TU Delft Electrical Engineering, Mathematics and Computer Science)","Varbanescu, A. L. (mentor); Sips, H.J. (graduation committee); Pawełczak, Przemysław (graduation committee); Hidders, J. (graduation committee); Delft University of Technology (degree granting institution)","2020","Graphs are a ubiquitous concept used for modeling entities and their relationships. Large graphs, present in a variety of domains, are often fundamentally difficult to process because of sheer size and irregular computation structure. In recent years, both academia and industry have committed to designing scalable solutions to efficiently process these graphs.<br/><br/>Next to processing large datasets in a distributed environment, a relatively new trend is to accelerate single node computation performance using heterogeneous platforms (for example, by leveraging the GPU as well as the CPU). However, the structure of the input graph can markedly influence the processing speed on a certain platform and it is unclear what would be the most efficient platform for execution given an input dataset.<br/><br/>In this thesis, we will analyze the performance of multiple PageRank implementations for diverse platforms. Using implementations for CPU (using OMP), GPU (using OpenCL and CUDA), and heterogeneous environments (using StarPU and MPI), we will characterize platform performance in relation to the structure of the input dataset. Finally, we will propose and evaluate a performance model for PageRank that takes into account traits of the input graph.","Graph Analysis; Performance Analysis; Heterogeneous Computing; Benchmark; Pagerank","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:aa5965b1-9b51-4304-8f48-c96e69e4c6d2","http://resolver.tudelft.nl/uuid:aa5965b1-9b51-4304-8f48-c96e69e4c6d2","Validation &amp; Verification of Hydro-Elastic Analyses for Marine Propellers","van de Sanden, Klaas (TU Delft Mechanical, Maritime and Materials Engineering)","van Terwisga, T.J.C. (mentor); van Wijngaarden, H.C.J. (mentor); Neatby, H.C. (graduation committee); Laskari, A. (graduation committee); Pahlavan, Lotfollah (graduation committee); Delft University of Technology (degree granting institution)","2020","A fairly recent development in the maritime industry is the rising interest in composites, as they have great potential to outperform conventional metallics. They offer good corrosion resistance, fatigue resistance, a low magnetic signature, and a high strength to stiffness ratio. In case of a propeller, the latter may be utilized by adapting the geometry passively to suit the loading condition more optimal. A possible is to mitigate cavitation by utilizing the relatively large deformations when subjected to loads. The hydrodynamic response of a flexible propeller in a flow field can be predicted by the use of Fluid-Structure Interaction (FSI) software, which is currently being developed at MARIN. The project is called ComPropApp, and combines existing fluid and structural solvers. As the ComPropApp is still under development it needed to be verified and validated, which is the main objective of this thesis. As an initial step in the verificatio, a falsification study was applied on the procedures followed in the ComPropApp. This led to the discovery of several errors, to which corrections have been applied to improve the program. With an updated version, computations with a number of different materials were performed to finalize the verification. Then, a model size polyurethane propeller has been manufactured at MARIN to be used in the experimental validation. Experiments were performed in the cavitation tunnel testing facility at MARIN. Here the propeller was tested in several operating conditions, which was then compared with ComPropApp simulations. Lastly, it was investigated whether the application of a composite can reduce cavitation. This was for theoretical research only, since the testing propeller would fail far before reaching cavitating conditions. With the fluid solver, a requirement for twist deformation was set up. Based on these requirements, a range of composite materials was defined, and with it, ComPropApp computations were performed. The resulting displacements and pressure distributions were then compared for rigid and composite propellers. With the presented verification study, it can be concluded that the FSI software is capable of providing realistic computation results. The validation study has led to conclude that the unsteady FSI module is capable of qualitatively predicting the bend deformations in open water conditions. However, due to the large uncertainties arising from the testing material properties and questionable machining quality, the measurements cannot be utilized to define the accuracy of the FSI software. In wakefield conditions the additional uncertainty of the wake velocity distribution meant that these measurements are inconclusive, hence the validation was only performed for open water conditions. The material study with the purpose of mitigating cavitation has shown potential in the application of anisotropic materials. Composites with a specific ply orientation sequence have the possibility of realizing bend twist coupling motions, such that the propeller would unload itself in the vicinity of the ship hull, with reduced cavitation as an expected result.","Ship propulsion; FSI; Composites","en","master thesis","","","","","","","","","","","","Marine Technology","",""
"uuid:97e10fc8-e1a7-414e-a72e-3bfbd4d8791e","http://resolver.tudelft.nl/uuid:97e10fc8-e1a7-414e-a72e-3bfbd4d8791e","Ultra-thin thermal SiOx enabled poly-Si carrier selective passivating contacts for IBC solar cell application","SENTHIL KUMAR, Saravana Kumar (TU Delft Electrical Engineering, Mathematics and Computer Science)","Isabella, O. (mentor); Yang, G. (graduation committee); Delft University of Technology (degree granting institution)","2020","Crystalline silicon solar cells based on poly-Si Tunnelling Oxide Passivating Contacts (TOPCon) is becoming one of the most promising solar cell structures that enable both high efficiency and low cost. The record efficiency for the Front-Back contacted (FBC) cell with TOPCon structure is 25.7 %. By moving both the metal contacts to the back side, the so-called interdigitated back contact (IBC) approach, the solar cell efficiency can be improved significantly due to the absence of optical shading from the front metal contact. Further, by narrowing the width of the metal fingers present on the rear side of an IBC solar cell, light illumination can also be made possible from the rear side. This makes the IBC solar cell a bifacial IBC solar cell. The objective of this thesis work is to optimize the Carrier Selective Passivating Contacts (CSPCs) with an ultra-thin thermal SiOX.","poly-Si; Solar cells; Carrier selective contacts; IBC; Thermal Oxide","en","master thesis","","","","","","","","2022-08-26","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:5f16cecd-a95e-43a8-a049-7becfdbba8ba","http://resolver.tudelft.nl/uuid:5f16cecd-a95e-43a8-a049-7becfdbba8ba","Optimisation of a Photovoltaic-Thermal (PV-T) panel for Desalination","Mhatre, Supriya (TU Delft Electrical Engineering, Mathematics and Computer Science)","Isabella, O. (mentor); Ziar, H. (mentor); Cen, Jiajun (mentor); Delft University of Technology (degree granting institution)","2020","Water stress levels are rising due to industrialisation and the increase in population. With the freshwater supplies depleting at a rate faster than the refreshment rate, there is a need to look into unconventional and sustainable sources of water. Desalination technology is a reliable solution for the future water requirement; however, it is an energy-intensive process. Desalination is mostly powered by fossil fuels and there is a need to move away from these. For this reason, a Photovoltaic Thermal (PV-T) powered desalination plant which uses the Multi-effect Distillation (MED) coupled with Mechanical Vapour Compression (MVC) technology, is investigated. A novel design of the PV-T module is used wherein a water reservoir is attached directly to the back of a PV module.<br/><br/>The PV-T module produces electrical and thermal energy simultaneously, which are the required inputs to a MED-MVC desalination system. To have the desalination system working efficiently, it is important to predict the output from the module with respect to its design and the location weather parameters. To predict the output water temperature with varying weather conditions, a PV-T model was built using COMSOL Multiphysics. The model was validated using experimental data from the location of Dubai. It is found that the water outlet temperature and the total efficiency of the module vary with its inclination angle and flow rate of water through it. With a sensitivity analysis for the outlet water temperature and the total efficiency with respect to tilt angle and flow rate, optimum values for these parameters are obtained for summer and winter days. A maximum water outlet temperature of 91<sup>o</sup> C in summer and 58 <sup>o</sup> C in winter is predicted from the model, for the Dubai location, for these optimum values. Using experimental and simulated results, output parameters such as water outlet temperature at a given flow rate is predicted using dimensionless numbers which characterises the PV-T design and the surrounding environment that the system is placed in. <br/><br/>The hot water from the PV-T array which consists of 400 PV-T panels is used to produce steam using flash evaporation, for thermal input to the MED vessel. Sensitivity analysis for the temperature and quantity of the hot water produced from the array showed that a maximum amount of steam of 1782 kg can be produced on a summer day with a water outlet temperature of 85 <sup>o</sup> C. Due to lower water outlet temperature in winter, heating elements should be used to raise the water temperature to 85 <sup>o</sup> C. The maximum amount of steam produced, as a result of 85 deg C water temperature, will lead to 6058 kg of distilled water per day when used as input to the MED with 4 effects. According to water requirement, additional steam can be produced by the MVC.<br","PV-T","en","master thesis","","","","","","","","2022-08-26","","","","","",""
"uuid:07a1cd44-4105-40f6-8b9c-555535659ae6","http://resolver.tudelft.nl/uuid:07a1cd44-4105-40f6-8b9c-555535659ae6","Imaging Angle-Dependent Reflectivity using the Marchenko Method","Alfaraj, Hassan (TU Delft Civil Engineering and Geosciences; Saudi Aramco)","Brackenhoff, J.A. (mentor); Wapenaar, C.P.A. (graduation committee); Delft University of Technology (degree granting institution)","2020","When reflection images are studied, often only the zero-offset reflectivity is considered, however, taking into account the angle-dependent reflectivity can add additional information about the Earth's subsurface. This additional information can be used to extract the properties of the subsurface using the amplitude variation with offset (AVO) analysis techniques. However, the presence of a complex overburden can significantly deteriorate the AVO response, especially for deep targets. To overcome this problem, the overburden effects can be removed by redatuming the reflection response at a depth level below the overburden. The Marchenko method has the potential to correctly retrieve the angle-dependent reflectivity in acoustic media without distortions due to multiple scattering caused by the overburden. The method estimates the downgoing and upgoing Green's functions of a virtual source located in the subsurface from surface reflection data and an estimate of the direct arrival from the location of the virtual source. The estimated Green's functions represent accurate upgoing and downgoing wavefields as they contain all orders of internal multiple reflections of the subsurface. These internal multiple reflections contribute to retrieving the reflectivity accurately in the redatumed reflection response. By deconvolving the retrieved upgoing Green’s function with the downgoing Green’s function, a new reflection response is obtained, with virtual sources and virtual receivers in the subsurface. The resultant reflection response is free of spurious events related to internal multiples in the overburden and contains the correct amplitudes. The angle-dependent reflectivity of the redatumed response can be obtained by summing the reflection coefficients along lines of constant ray parameter or angle. Potentially, the retrieved angle-dependent reflection coefficients obtained by this method can be used as input in a subsequent inversion process to obtain the velocity and density of the subsurface.","Imaging; AVO; reflectivity; Marchenko; angle of incidence; ray parameter","en","master thesis","","","","","","","","","","","","Applied Geophysics","",""
"uuid:f1a66448-b256-49c0-a11d-171d48677593","http://resolver.tudelft.nl/uuid:f1a66448-b256-49c0-a11d-171d48677593","Methanol from sunlight and air: A guide towards the embodiment design of the micro plant","Boer, G.J. (TU Delft Industrial Design Engineering)","Oberdorf, J.E. (mentor); Diehl, J.C. (graduation committee); Delft University of Technology (degree granting institution)","2020","The carbon emission of fossil fuels contributes to global warming. The start-up ZEF develops a sustainable alternative to create fuel. By capturing CO2 and H2O from the air, the energy from PV solar panels, and the right technology, they create methanol. Methanol can, among other things, be used as a fuel or to create plastics. This product is called a micro plant. With the development of large PV solar farms with 40.000 solar panels and 13.000 micro plants, methanol will be produced on a large scale.<br/>The micro plant is a small chemical factory with about 50 different parts. These parts are individually, or within one of the four subsystems developed at TRL level 4. However, these parts are only developed at a technical level; the integration of these parts into a micro plant suitable for the mass manufacturing of 100,000 pieces has had little thought. Therefore the purpose of this graduation project is to guide ZEF towards an embodiment design for the micro plant. The four main design drivers that influenced the choices are price, functionality, environmental impact, and flexibility.<br/>To get to an embodiment design the influence of maintenance, the architecture design, the insulation and the casing where researched.<br/>Maintenance: The micro plant requires maintenance about every 2 to 5 years. The chosen maintenance strategy is preventive predetermined scheduled maintenance. The two extreme options for maintenance were maintenance at the micro plant’s location or automated maintenance in a garage. Option one was chosen because this allows for the flexibility to make changes in the maintenance schedule. This resulted in the requirement to have access to all maintenance interfaces and six control buttons for the micro plant.<br/>Architecture design: Architecture design is about how the different parts are positioned relative to each other. Size of the parts, their heat and cooling requirements, their maintenance requirements, and their place in the system diagram determined their position.<br/>Insulation: The material used for insulation is stone wool. Stone wool is cheap, durable, and has the proper thermal properties. It can be manufactured in different ways; for this project, the solution of a box made with stone wool plates, placed around the insulation parts and filled with stone wool flakes will be used. The insulation gets a plastic protective layer.<br/>Casing: The core function of a casing is to keep all the parts stiff together and transport the air from the air filter to the air fan. It is unnecessary to have a casing that encloses the whole micro plant because most parts do not require an enclosed to ensure a 20 years lifetime. This design chooses a blow-molded air duct with a steel frame to embody this ‘naked’ casing.<br/>In the end, the total costs of the micro plant were 700 euros, where the target price was 450 euros. The micro plant needs to be suitable for more PV solar panels, cheaper, or it is not feasible.<br/>This project was only a starting point for product design, recommend is to continue the development on the product level, because the product level does influence the technical level. Also, getting from a concept to a product requires time and collaboration with multiple stakeholders.<br","Sustainabilty; Renewable Energy; Methanol","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:6c7b8f18-467e-48f4-840f-a24b1da8c816","http://resolver.tudelft.nl/uuid:6c7b8f18-467e-48f4-840f-a24b1da8c816","From resource draining to maintaining","van Stralen, Stan (TU Delft Architecture and the Built Environment)","Snijders, A. (mentor); de Krieger, J. (mentor); Tomesen, P.L. (mentor); Meijs, M.H. (graduation committee); Delft University of Technology (degree granting institution)","2020","The area of Amstel III will drastically change by 2040 into a lively urban district. This change allows for the rethinking of the urban metabolism of the area, to shorten the material cycles and by better utilization of resources. Through estimation and calculations on potential flows related to energy, water, and organic material the potential impact of urban farming is given with a plausible configuration for the 2040 scenario. Organic waste flows are significant enough to provide the necessary nutrition for about 4250 tonnes of food yearly, which is a large portion of the diet consumed in Amstel III. To enable this food production urban farms of 70 ha of arable land and 80 ha of CEA need to be integrated into the urban plan, and additional engines such as a local biodigester, CHP and simple WWTP are necessary. Furthermore, there is much potential in the harnessing of solar, wind and thermal energy in the district, potentially making the district for nearly 75% independent on energy. The impact of the proposed configuration of the metabolism could save valuable depletable mineralized fertilizers, for example about 12 tonnes of phosphorus and 29 tonnes of nitrogen can be recovered each year in the form of digestate, as well can 15000 tonnes of carbon dioxide be captured from the organic waste to be utilized for food production in CEA.","Urban farming; Urban Metabolism; Food System; Urban Transformation","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences","",""
"uuid:6e27d557-876d-4742-b78d-8324c74d7a83","http://resolver.tudelft.nl/uuid:6e27d557-876d-4742-b78d-8324c74d7a83","Interest rate models for estimating counterparty credit risk: Dynamic Nelson-Siegel and Displaced Diffusion","Rood, N.M. (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Delft Institute of Applied Mathematics)","Oosterlee, C.W. (mentor); Huang, Xinzheng (mentor); Zhang, Bowen (mentor); Anderluh, J.H.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","In this study, two interest rate models are analysed in context of counterparty credit risk. The goal of the study is to find a model that performs well on historical simulation for the PFE and EPE. The two models analysed are the Dynamic Nelson-Siegel model and the Displaced Diffusion model.<br/>In the Dynamic Nelson-Siegel model, a Nelson-Siegel curve is fitted against the historical yield curves. The fit gives an historical series of the parameter values of the Nelson-Siegel curve, which are modelled via a stochastic process to obtain future yield curve predictions. In historical backtesting, the classic model using AR(1) processes for the parameters performs inadequate. Analysis on the underlying assumptions of the model show that the mean-reverting behaviour that is modeled is the cause. In addition the data is likely to feature heteroskedastic behaviour, which is not incorporated by the model. An adjusted model in which one parameter is modeled with a random walk with drift performs well on longer maturity rates, however shorter maturity rates are not modeled satisfactory. <br/>The Displaced Diffusion model uses a lognormal diffusion process that is shifted to model Libor rates. As it is a Libor market model, all libor rates are modelled seperately using correlated Brownian motions. The shift parameter allows negative rates to be modeled, and is initially assumed constant. The backtesting results are mixed; some observed libor rates are modeled inadequately and some cannot be rejected to come from the Displaced Diffusion model and thus are modelled correctly. When backtesting the PFE, the results are good at the short term. At the 2-year window, PFE estimates are not always conservative but the number of excesses are of medium severity when compared to the probabilities used in the green-orange-red system dictated by the Basel committee for VaR backtesting.","Counterparty Credit Risk; Model validation; Dynamic Nelson-Siegel; Displaced Diffusion; Historical Backtesting; Interest Rate models","en","master thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:fe8f7944-682b-418b-be4b-9a0512f805d2","http://resolver.tudelft.nl/uuid:fe8f7944-682b-418b-be4b-9a0512f805d2","Economic Robustness of the OnShore German Wind Energy Industry under Deep Uncertainty","Modrakowski, E.V. (TU Delft Technology, Policy and Management)","Kwakkel, J.H. (mentor); Hakvoort, R.A. (mentor); Delft University of Technology (degree granting institution)","2020","Germany aims to compose 65 % of its electricity mix with renewable energy by<br/>2030. Thus, it relies on onshore wind energy as a source. This industry has experienced a significant turmoil from 2017 to 2019 as the newly installed capacity dropped by 80 % within these two years. The public discussion sees an increase in lawsuits caused by low public acceptance as the reason for this behaviour. Action is demanded in form of a simplification of the permitting process of the wind energy projects and an increase in public support mainly by involvement of the community adjacent to the planned wind park or increased distance between projects and habitants. Even though these are noble requests, calling public acceptance as the only reason for the decrease in installed capacity does not seem plausible. Interestingly, 2017 coincides with the adoption of a new subsidization scheme which includes a bidding process. Since wind energy projects are private investment projects, their finances are key to success. The aim of this study is to gain understanding about the reasons of the slump and develop an alternative hypothesis. A literature review summarizes the legal, political, social, and technological landscape for onshore wind energy. A detailed synthesis of public acceptance literature is performed and understanding of the financial dependencies and influences related to wind energy projects is gained. To support the reasoning, a model is constructed which simulates the income and expenses of wind energy projects. A participation in the bidding process is simulated including a detailed calculation of interest rates, an approximation of the impact of an increasing wind turbine population and an estimation of the development of the turbine maintenance sector. The findings of this study are threefold. First, it summarizes in detail all financial aspects of onshore<br/>wind energy projects. As a result, it is concluded that the maximum bid is set too low and the subsidization scheme is not adapted to the financial needs of a project. As a consequence, not enough sites are built even though they could technically be available, resulting in the slump. Secondly, with the current constrains of the bidding process, the onshore wind energy sector will remain in a slump and the 2030 goal set by the German government cannot be reached as projected technological advancements have a small effect. The slump also forces the wind energy sector into a recession. Since any scenario of technological development cannot be relied on to counteract the slump, an adjustment of the subsidization scheme is needed. The most effective way to reach the objectives<br/>is to increase the maximum bid. Thirdly, it is argued that the public acceptance<br/>would have limited to no effect on the situation. The German government has three options. Either, (I) the maximum bid is raised or (II) reversed to the old subsidization both implying higher costs than desired or (III) other renewable energy sources have to be supported and the onshore wind energy sector will undergo major restructuring including possible job losses.","Wind Energy; Crisis; Germany","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:3ee92a9d-d555-498b-9694-298e07051833","http://resolver.tudelft.nl/uuid:3ee92a9d-d555-498b-9694-298e07051833","Learning State Machines faster using Locality-Sensitive Hashing and an application in network-based threat detection","Skoulos, R. (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Intelligent Systems)","Verwer, S.E. (mentor); Lagendijk, R.L. (graduation committee); Finavaro Aniche, M. (graduation committee); Delft University of Technology (degree granting institution)","2020","The internet traffic is constantly rising nowadays due to the significant increase of the devices connected to the Internet. As a consequence, many cyber risks have arisen. Cybercriminals are trying to exploit the vulnerabilities of these devices to cause damage and gain profit. Monitoring the network traffic and detecting such threats has become essential in order to keep safe systems that are connected to the Internet. The powerful properties of state machines and the sequential nature of the network traffic data, makes them an interesting and promising solution for the implementation of an intrusion detection system.<br/><br/>The goal of this thesis is to implement a new state-merging heuristic which will speedup the state machine building procedure without a significant loss on the quality of the model, and use it to detect malicious host on network traffic data. The new state-merging heuristic is utilizing the Locality-sensitive Hashing concept to store the future traces of each state and simplify the consistency check for the merge of two states. The network traffic data used are in the NetFlow format, and they are encoded and converted into traces in order to build the state machine model and measure its performance. The state machine built is modeling a malicious behavior and used to classify other hosts.<br/><br/>We show that the models built can effectively detect the malicious hosts, with its performance being comparable to the one of a state-of-the-art model. At the same time, the time needed to build the model is much less when compared to the time needed by other state-merging heuristics.","state machines; network threat detection; locality-sensitive hashing; anomaly detection","en","master thesis","","","","","","","","","","","","Computer Science | Cyber Security","",""
"uuid:f8ee5161-93c4-441d-9032-1420fb446408","http://resolver.tudelft.nl/uuid:f8ee5161-93c4-441d-9032-1420fb446408","The role of incubators and regional factors influencing the location decision of academic spin-offs: An exploratory study in Delft and Wageningen","Hulivahana Shivalinga, Bhavana (TU Delft Technology, Policy and Management)","Khodaei, H. (mentor); Verburg, R.M. (graduation committee); Scholten, V.E. (graduation committee); Delft University of Technology (degree granting institution)","2020","The recent years have witnessed university business incubators being major contributors to regional development by supporting and nurturing academic spin-offs, and fostering innovation. However, with the academic spin-offs scaling up, they decide to exit the incubator and sometimes even migrate to another city or region. This study recognizes the migration pattern of academic spin-offs from Delft and Wageningen and identifies not only the regional factors influencing the location choice of academic spin-offs but also incubator related factors. The study is exploratory and follows a mixed approach with both qualitative and quantitative analysis done through the study of secondary data from 2012, desk research, literature review, semi-structured interviews, semi-structured questionnaires and comparative case studies.<br/><br/> To begin with, a desk research was conducted tracing academic spin-offs in the incubators of both the university cities- Yes!Delft from Delft and StartHub from Wageningen. The academic spin-offs were tracked for their current location, technology, industry, ownership type, founding year and age to recognize any pattern. Through the semi-structured interviews with the experts from each of the two incubators, the types of support, activities and policies were investigated. The interviews confirmed the findings from desk research in the areas they prefer or most dominant technology in the incubators. While Yes!Delft is dominated by complex tech and MedTech academic spin-offs, for StartHub (StartLife) is dominated by food and agritech. <br/><br/>Through the literature study, a conceptual framework was devised with the factors recognized from existing literature influencing the stay and exit of startups from the incubator and region. Apart from confirming the factors from the conceptual framework, a new set of factors were added from the interviews, questionnaire and the case studies. The study concludes with individual frameworks for Delft and Wageningen and an overall framework with a combined list of reasons. Quantitative analysis was conducted briefly through mean comparison of support factors and appreciated based on Likert scale for the data from 2012 and 2020 of Delft and Wageningen. The regional support still remains the most appreciated category of support influencing the location choice of academic spin-offs. While most startups that exit Yes!Delft still remain located in either Delft or the neighboring cities the startups that exit from StartHub have moved to bigger cities such as Amsterdam, Utrecht and Rotterdam. <br/><br/>The migration pattern can be explained through the findings of the study. The research shows that as and when startups scale up they seek not just better accommodation and infrastructural facilities but also the need for developing work culture, market agglomeration and closer distance to clients, suppliers and other resources apart from university reputation, easy access and availability, affordability of resources and social ties. In spite of academic spin-offs exiting the incubators, Regional development can be improved by influencing them to stay located in the region. The support can be offered not just by the infrastructural support by incubators but also through the entire entrepreneurial ecosystem as a whole by nurturing them with resources and social ties. <br","Location decision-making; Academic Spin-offs; regional development; Start-up; Incubator; incubator support; migration pattern; resource based view of the firm","en","master thesis","","","","","","","","","","","","","",""
"uuid:3a1459c3-4c36-4d3c-9a28-f1381fca24dd","http://resolver.tudelft.nl/uuid:3a1459c3-4c36-4d3c-9a28-f1381fca24dd","An environmental and economic assessment of solar photovoltaics and nuclear energy in Maharashtra, India","Nama Ashok kumar, N. (TU Delft Technology, Policy and Management)","Korevaar, G. (mentor); Schröder, E. (mentor); Lukszo, Z. (graduation committee); Tsalidis, G.A. (graduation committee); Delft University of Technology (degree granting institution)","2020","Maharashtra, the second largest state in India in terms of population and area, is a fast-developing economy and meeting its electricity demand is crucial for its economic growth. Currently, power production is causing severe environmental and security issues mainly because of the reliance on coal plants in the state. In order to meet SDG 7 “affordable and clean energy” proposed by UN, a government think tank called NITI Aayog helps set polices and targets for sustainable development of electricity production in states of India. However, the stakeholders are hindered to address the problems of sustainability dimensions due to a significant knowledge gap causing discrepancies in power policies. There is a need for a comprehensive approach which involves life cycle thinking and integration of the sustainability dimensions. Hence, this study adopts an integrated approach of environmental and economic dimensions of power sector in Maharashtra for suggesting NITI Aayog on policies and framework which can be used in the expansion of electricity generation capacity. The framework followed in this study consisted of the four steps, indicator selection, environmental performance evaluation, economic performance evaluation, integration and policy implications. For this work, solar PV and nuclear technologies were selected and then the dimensions of technologies were integrated with respect to the predominant technology, coal. Firstly, in order select indicators which relevant to SDG 7 and our case study, a literature study was conducted based on several criteria. After the analysis on the studies selected, GWP and LCOE indicators for environmental and economic dimensions were selected. Furthermore, for evaluating the environmental performance of the technologies, LCA studies were used to quantify GHG emissions and to identify hotspots in life cycle stages. A methodology was followed to harmonise the published results of the selected studies to reflect the current status of Maharashtra conditions. The GHG emissions of solar PV was found to be 39 g CO2 eq/kWh of which 89% was contributed from manufacturing phase of the modules whereas GHG emissions of nuclear energy was estimated to be 12.5 CO2 eq/kWh in which 75% of the emissions is during HW production. Over time, solar PV emissions tend to decrease because of the improvements in the system efficiency while nuclear energy emissions tend to increase because of decreasing uranium ore grades. Thirdly, evaluation of economic performance of both technologies was carried out by using LCOE tool. DCF method was used to bring the future costs to NPV and after calculating LCOE, a sensitivity analysis was performed to know the influential parameters. Under the defined system boundaries, LCOE of solar PV was estimated to be 0.045 USD/kWh in which 85% of the costs are capital costs. whereas LCOE of nuclear energy was calculated to be 0.055 USD/kWh in which capital costs and O&amp;M costs account to 50 and 37% respectively. Over time, the LCOE of solar energy tends to decrease with improvements in technology while LCOE of nuclear tend to increase because of the increasing safety standards and inflation. Lastly, an MCDA method, weighted sum approach was chosen for integration of two aspects as it provides platform for stakeholder participation and provides a transparent, inclusive and organised framework. Three scenarios were considered in which even extreme weights were considered for calculation of sustainability scores and the overall ranking of technologies remained same in the given scenarios. Clearly, solar energy is the winner in the range of the assumed extreme weights and is followed by nuclear and coal energy. Based on the outcomes of LCA and MCDA of this study, policy implications were discussed. On economic front, electricity bundling of solar and nuclear energy is recommended to reduce the overall cost and to solve the issue of intermittency of solar energy. On the environmental front, GHG hotspot phases in both solar PV and nuclear energy were identified and policy recommendations were discussed. Overall, policies should be aimed at lowering or phasing out the fossil fuels and at providing enabling environment for increasing the low carbon technologies into the energy mix. As far as LCA and MCDA framework in this research is concerned, the sustainability scores of the technologies help ranking the technologies. More than ranking the technologies, the deliberative process makes stakeholders come together on a platform to formulate problem, discuss trade-offs and come up with unique solutions to reduce the impacts. NITI Aayog can use the framework not only for the case of Maharashtra, but also for different states. The framework allows to arrive at a customised solution according to the preferences of all stakeholders while still be able to measure and compare the improvements in the sustainability aspect.","Life cycle assessment; Economic analysis; Environmental impact; MCDA; policy-making; decision making; electricity emissions; Solar; nuclear; sustainable development goals; Sustainabilty","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:6b74a0e6-37aa-4ff4-bada-3e414498eafd","http://resolver.tudelft.nl/uuid:6b74a0e6-37aa-4ff4-bada-3e414498eafd","Contrastive Learning of Visual Representations from Unlabeled Videos","Simion-Constantinescu, Andrei (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Pattern Recognition and Bioinformatics)","van Gemert, J.C. (mentor); Kayhan, O.S. (mentor); Loog, M. (graduation committee); Tintarev, N. (graduation committee); Delft University of Technology (degree granting institution)","2020","This thesis presents a novel self-supervised approach of learning visual representations from videos containing human actions. Our approach tackles the complex problem of learning without the need of labeled data by exploring to what extent the ideas successfully used for images can be transferred, adapted and extended to videos for action recognition purposes. We begin by giving a brief introduction to the topic of learning features without having access to a labeled corpora, providing the motivation of our work. We continue with presenting the related research in terms of contrastive learning, action recognition from videos with 3D convolutions and self-supervised techniques for both images and videos. Next, we formalize our approach with regards to the sampling method, the types of spatial and temporal transformations and the contrastive loss used. We evaluate videoSimCLR proposed method in terms of linear evaluation, fully fine-tuning and video retrieval using two popular action recognition datasets, HMDB51 and UCF101. We also explore the extension of another contrastive learning approach to videos, videoMOCO, and compare it with videoSimCLR by means of linear evaluation.","Self-supervision; Deep learning; Computer vision; Action Recognition; Convolutional Neural Networks; Unsupervised learning; Video embedding; Video retrieval; Contrastive learning","en","master thesis","","","","","","","","","","","","Computer Science | Data Science and Technology","",""
"uuid:c93c1e75-89aa-4ef4-b0c6-72c797df5bb6","http://resolver.tudelft.nl/uuid:c93c1e75-89aa-4ef4-b0c6-72c797df5bb6","Opening the bottle: designing openable surfaces in a mono material construction of recycled PET","van den Berg, Noah (TU Delft Architecture and the Built Environment; TU Delft Architectural Engineering +Technology; TU Delft Design Informatics)","de Ruiter, P. (mentor); Veer, F.A. (graduation committee); Delft University of Technology (degree granting institution)","2020","A proposal is made on how to design and create an openable surface in a mono material 3D printed tiny house that consists out of recycled PET.","openable surface; mono material construction; FDM printing","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Building Technology","Living in a bottle",""
"uuid:3fd69592-711d-47ad-93d9-7bda79747e33","http://resolver.tudelft.nl/uuid:3fd69592-711d-47ad-93d9-7bda79747e33","City hall of Brussels","Yang, Lin (TU Delft Architecture and the Built Environment; TU Delft Architecture)","De Vocht, S. (mentor); Parravicini, M. (mentor); Rosbottom, D.J. (mentor); Pimlott, M. (mentor); Delft University of Technology (degree granting institution)","2020","Brussels has a complex political background and social texture. The existing administrative centre does not meet the demands of 1700 employees anymore. The city centre is going to build a new city hall-the Brucity, and move 1700 staffs from the old administrate centre- Muntcentrum. While the Brucity is an enormous volume breaking the urban fabric. The planning of Brussels city centre indicates the government, as well as citizens, wish to have a more pedestrian-friendly urban space. The project will be part of the urban linking system, contributing to the goal of pedestrian-friendly and publicity in the city centre, and provide a better connection for open spaces. In the building scale, the representation of democracy in a political building is quite important. In the new city hall, the communication of politicians and public as well as activism groups will be promoted by a series of atria spaces. And the design is mainly about public engagement in different level, trying to achieve broadly engagement of the public in Brussels new city hall","city hall; Brussels; interior building cities","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences","",""
"uuid:6aacd9f4-1601-41cb-ab51-ea8ebfa966fa","http://resolver.tudelft.nl/uuid:6aacd9f4-1601-41cb-ab51-ea8ebfa966fa","DiaMediPort increasing elderly agency by improving triage at home","Rebel, H.J.M. (TU Delft Industrial Design Engineering)","Sleeswijk Visser, F. (mentor); Brinkman, C. (graduation committee); Beekman, A.Q. (graduation committee); van Glabbeek, G. (graduation committee); Delft University of Technology (degree granting institution)","2020","The rapidly aging Dutch baby boom generation threatens to overwhelm the healthcare system in the Netherlands (Hoedeman &amp; Koki, 2020). The elderly, more than any other age group, are more prone to experiencing a steep decline in physical and cognitive health during hospitalization (Brown, 2020; Mathews, Arnold &amp; Epperson, 2014). 61% of the elderly Dutch are unnecessarily admitted to emergency wards (G. de Kousemaeker of Fluent, personal communication, January 16, 2019). Likewise, the elderly, especially those from rural areas, are fueling more than a 50% increase in the number of persons 65+ who require nursing care at a home (CBS, 2019). A complex network of stakeholders interacts in the healthcare value chain to provide interventions for this vulnerable group. Yet, healthcare providers (HCPs) who collaborate together to diagnose, treat or adjust medications for the elderly are under immense pressure (SCP, 2019a). With its technology-enabled services, DiaMediPort aims to solve the shortages of HCPs by sending triage nurses to the homes of the elderly in distress and by virtually connecting them to general practitioners and medical specialists via information logistics. The research section of this project highlights the advantages of ensuring person-centered triage care in the Dutch elderly person’s home during the period of 2020. I conducted secondary and primary research (e.g. ethnographies, contextual maps, qualitative interviews) with an elderly couple in their extramural home, informal caregivers, district nurses and elderly care specialists from intramural facilities, ambulance and mobile night teams and elderly call centers. Five key conclusions are made based on the insights generated on triage moments, information flow, technology and the healthcare value chain. 1) There is an obvious disconnect between the government’s response to the elderly and what the elderly want. The Dutch Minister of Health, Sports and Wellbeing stated the role of each Dutch person is to care for other persons in the community; while the elderly interviewed state that independence is a core value and it must be accounted for during the development of an elderly triage service. 2) Triage moments are a source of needless and redundant suffering for the elderly person who lives in an extramural home. The informal caregiver must communicate with HCPs during these moments so that the decisions made on behalf of the elderly person are dynamic. Although nurses can handle a litany of triage moments, the healthcare system prohibits them from taking action without the supervision of a medical doctor. 3) The mobile night team becomes a part of the traditional medical system. When an informal caregiver or district nurse is unavailable, triage nurses perform unexpected tasks at night. 4) Information flow and open communication reduce the usage of human and financial resources and improve the elderly person’s medical outcomes. 5) The nurses who work at elderly care centers rely on ICT system information. Often the elderly’s digital records and other necessary information are not yet entered or updated. Hence, triage nurses must act in an information vacuum. The appearance and complaints of the person suffering from old age is the only information at their disposal. It is very difficult to read him. Sometimes, he lacks the words to express what is wrong. As a result, nurses cannot make informed medical decisions. DiaMediPort is ideally poised to tackle these issues and concerns. Besides, its services give reassurance to beneficiaries (e.g. elderly person and informal caregiver) and facilitate their independent living at home. The design section offers 2 tools that I created for DiaMediPort. Their 2 objectives were to 1) visually inform how HCPs and beneficiaries interact within the existing healthcare system and 2) convince HCPs and decision-makers (e.g. insurance providers, hospitals, governmental bodies) to adopt DiaMediPort’s services. The tool Stakeholder Perspectives has two components: 1) “DiaMediPort in Film” presents short films of elderly persons in triage situations; these stories are produced with cartoon cutouts and voice-overs. And 2) “DiaMediPort Platform” will be used in a co-creational workshop. It gives an overview of the DiaMediPort beneficiaries and stakeholders, their social context and how DiaMediPort acts as intermediary. The tool Layered System Overview illustrates the triage phases wherein DiaMediPort is capable of providing services.","aging; triage; elderly; point of care technology; medisign","en","master thesis","","","","","","","","","","","","","",""
"uuid:70e2839e-38c5-4165-b017-cad66997535e","http://resolver.tudelft.nl/uuid:70e2839e-38c5-4165-b017-cad66997535e","Green Flow Converter","Wang, Jieli (TU Delft Architecture and the Built Environment)","van Bennekom, H.A. (mentor); Holst, J.P.G. (graduation committee); Delft University of Technology (degree granting institution)","2020","","","en","master thesis","","","","","","","","","","","","","",""
"uuid:6ab25862-c2da-4a52-a570-7cbe3c774a17","http://resolver.tudelft.nl/uuid:6ab25862-c2da-4a52-a570-7cbe3c774a17","Bed level changes in the shoaling zone and surf zone under the influence of cross-shore effects at a time scale of minutes","Zeeuw van der Laan, C.L.M. (TU Delft Civil Engineering and Geosciences)","Hopkins, J.A. (mentor); de Schipper, M.A. (mentor); Hut, R.W. (mentor); Delft University of Technology (degree granting institution)","2020","","","en","master thesis","","","","","","","","","","","","","",""
"uuid:7e065ec9-ceab-4303-9f21-28c2bd814586","http://resolver.tudelft.nl/uuid:7e065ec9-ceab-4303-9f21-28c2bd814586","A City Hall in Brussels","Huang, Luna (TU Delft Architecture and the Built Environment)","Pimlott, M. (mentor); Parravicini, M. (mentor); Rosbottom, D.J. (mentor); De Vocht, S. (mentor); Delft University of Technology (degree granting institution)","2020","Brussels will build a new administrative building in the city centre, which will provide new residences for approximately 1,700 government employees. With the expansion of Brussels' urbanization, the decrease in air quality has gradually attracted people's attention. The project hopes to form an ecological corridor by planting oak trees in some areas of the city, combining with the existing urban green space, and providing a better living environment for animals and plants in the city. As a longevity tree, oak trees provide living space and food for a large number of animals. This is a future project. The project hopes to carry political space, social space and ecological space through a big tree. This is a story in which buildings and trees grow together in the passage of time. The project aims to not only increase the abundance of urban species, but also to declare that trees should not be an accessory to urban buildings, but should become the main body and be paid attention to and used by people.","City Hall; Brussels; Tree","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences","",""
"uuid:9d415765-50de-4f76-9a71-5d50d073ac34","http://resolver.tudelft.nl/uuid:9d415765-50de-4f76-9a71-5d50d073ac34","Foyer - mediation of particles in Skopje","Kalinauskas, Andrius (TU Delft Architecture and the Built Environment; TU Delft OLD Methods & Analysis)","Mejia Hernandez, J.A. (mentor); Jennen, P.H.M. (graduation committee); Havik, K.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","Skopje – became city of solidarity after 6.1 momentum magnitude earthquake in 1963. Unprecedented situation allowed for tabula rasa of planning a future city to emerge. Metabolist masterplan for city central area proposed by Japanese team leaded by Kenzo Tange, allowed for a brutalist architecture to present itself as part of new city. Controversial plan of rebuilding the city was announced in 2010.This project was highly criticised by the professional community for its “new classicism” style and many monuments scattered around the center area without any logic to its location, creating clash between architectures. The project investigates the potential of how implementation of in between space would allow for existing architectures to coexist without overwhelming it. By using principles of traditional Macedonian housing, metabolism architecture and contemporary building techniques project aims to create a threshold where appropriation and dialog would emerge.","mediation; in-between; Skopje; Architecture; Cultural; Foyer","en","master thesis","","","","","","","","","","","","","","41.997214, 21.436637"
"uuid:13fb65e3-7952-4aa5-bf69-b8a802396a35","http://resolver.tudelft.nl/uuid:13fb65e3-7952-4aa5-bf69-b8a802396a35","Wave reflections in a semi infinite string due to nonlinear energy sinks at the boundary","Missula, Sharanya (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Horssen, W.T. (mentor); Delft University of Technology (degree granting institution)","2020","Vibrations or oscillations can be caused in overhead cable lines or bridge cables due to strong rain and winds, making the structure unstable.These vibrations can be mathematically described as a string like initial boundary value problem with non-classical boundary conditions. In this thesis, we consider a nonlinear attachment at the boundary which consists of a mass, nonlinear spring and a damper attached to a semi infinite string. In particular, we consider a weak nonlinearity and damping. In this study we used the D'Alembert solution and the multiple time scales perturbation method to obtain bounded solutions of the initial boundary value problem. We assumed travelling wave initial conditions, and obtained special cases and conducted detuning around these special cases to further study the reflected waves at the boundary and the stability of our solutions. Our main objective is to study the reflection of the incident wave on the boundary and compute how much energy is dissipated at the boundary due to the weak dissipative forces present at the boundary","Nonlinear dynamics; nonlinear energy sinks; perturbation theory; wave equation; multiple time scales","en","master thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:f89f4c36-aa32-462d-9baa-91efec7dcfc1","http://resolver.tudelft.nl/uuid:f89f4c36-aa32-462d-9baa-91efec7dcfc1","Proxying Bond Credit Spreads with Machine Learning","Bacci di Capaci, G. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Oosterlee, C.W. (mentor); Huang, Xinzheng (mentor); Strizencova, Katarina (graduation committee); Fontanari, Andrea (graduation committee); Delft University of Technology (degree granting institution)","2020","The bond market is affected by the shortage of liquidity problem, which means that many bonds are not frequently traded. This implies that market data for these bonds are missing. This lack of data represent a problem for financial risk measures such as Value at Risk (VaR). This research provides the framework for the construction of a proxy which replaces the missing data with artificial data such that VaR can be calculated. The data used for the VaR calculation are bond z-spreads, which is a credit spread measure. This research represents an improvement of the current proxy methodologies under different aspects. A major improvement is provided by the usage of machine learning algorithms such as Random Forest, Support Vector Regression and CatBoost which significantly increased the predictive accuracy of the proxy. Another main difference from the current proxy methods relies in the<br/>prediction of z-spreads daily changes (shifts), instead of z-spread levels. This modification required a shift types assessment and it has been beneficial both for the proxy performance and for the VaR calculation. The main result of this thesis from a financial and statistical perspective is the theoretical and empirical convergence of the VaR obtained through the proxy with the VaR calculated with real market data.","Machine Learning; Proxies; Bonds; Z-spread; Finance; Random Forest; Support vector regression; gradient boosting","en","master thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:6342ec7c-1dc6-4239-9672-d552b4ef310f","http://resolver.tudelft.nl/uuid:6342ec7c-1dc6-4239-9672-d552b4ef310f","sensuous public space","Shen, Luyuan (TU Delft Architecture and the Built Environment)","de Koning, S. (mentor); Koskamp, G. (graduation committee); Delft University of Technology (degree granting institution)","2020","New York was born in the pursuit of profit. Anglo-Dutch War, Independence War, Civil War, World War I and World War II, New York stands at the forefront of every major political change until it becomes the capital of the post-war world. New York opened its arms and embraced the groups that were excluded and expelled from other continents. It also attracted speculators full of speculation, creating a unique immigration city in the world, where global cultures collided and sparked. Capital and population accumulate here, creating a spectacle of congestion in this metropolitan laboratory. However, what will the New York City change in the future? How the public realm would evolve in the urban context? Although the globalization might lead to a homogeneous future, the sensuous space and emotive architecture are still what we cannot lose. It’s always meaningful to really touch, smell, hear something. So, it’s always worthwhile to discuss the position of public spaces in the future.","public space; new york; SDG; senses; Smart City; modular design; street life","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences","",""
"uuid:a09061e3-3be8-473c-812e-3e2d9ecc764d","http://resolver.tudelft.nl/uuid:a09061e3-3be8-473c-812e-3e2d9ecc764d","Semi Bistatic Radar: Subgroup - Receiver Antenna","Renger, S.G. (TU Delft Electrical Engineering, Mathematics and Computer Science); van der Kleij, J. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Uysal, F. (mentor); Dogan, O. (mentor); Cavallo, D. (graduation committee); Yarovyi, O. (graduation committee); Delft University of Technology (degree granting institution)","2020","In this thesis, a design of a passive radar for use on a drone used in inhospitable areas where air traffic control is not available due to circumstances. The thesis focusses on the receiver chain and angle of arrival algorithm.","Bistatic radar; Receiver; Angle of arrival","en","bachelor thesis","","","","","","","","","","","","","",""
"uuid:dbd83e4c-6277-4403-8e82-f48a5eaf46ed","http://resolver.tudelft.nl/uuid:dbd83e4c-6277-4403-8e82-f48a5eaf46ed","Batteries and energy arbitrage: A techno-economic analysis of electricity arbitrage opportunities for utility-scale battery energy storage in the Netherlands","Hugenholtz, Dorine (TU Delft Electrical Engineering, Mathematics and Computer Science)","Mulder, F.M. (mentor); de Vries, L.J. (graduation committee); Hakvoort, R.A. (graduation committee); Bliek, Frits (graduation committee); Delft University of Technology (degree granting institution)","2020","As the variable renewable energy share keep on increasing throughout the energy transition, power systems require more and different flexibility measures. Battery energy storage can provide these essential services that enable the energy system to carbonise and transform on short time scales. Energy arbitrage, the trading of electricity on the electricity markets, can create economic value for batteries. This research assesses the energy arbitrage opportunities for utility-scale battery energy storage in the Netherlands. It compares five different battery technologies and defines the optimal size and power capacity with a linear mixed-integer Matlab optimization model. Furthermore, the operation of for the most optimal technology is simulated for one year with a Model Predictive Control algorithm to be able to compare the effects of forecasting accuracy of the electricity prices on the estimated profits. The results show that according to optimized planning and dispatch in the operation of a battery system can lead to financial opportunities in the Netherlands regarding energy arbitrage for flow batteries. If not today, then in the future. It has been shown that towards 2030 the business case for battery energy storage will significantly increase due to decreasing capital costs and increasing price volatility with the rise of the VRES and phase-out of fossil energy sources. With this research, a contribution is delivered towards the realisation of commercially operating an independent utility-scale battery energy storage facility. Insights are provided on what battery configuration is best suited for energy arbitrage purposes and the effectiveness of simulating the optimized operation of a battery facility with a model predictive control method has been shown. This has lead to clearer insights into the profitability of operating a BESF in the Netherlands.","Batteries; Arbitrage; Energy Storage","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:003c0d5e-481a-4f52-8c3a-95c8dddcab9d","http://resolver.tudelft.nl/uuid:003c0d5e-481a-4f52-8c3a-95c8dddcab9d","Anomaly Detection in Network Traffic using Multivariate State Machines","Serentellos, V. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Verwer, S.E. (mentor); Lagendijk, R.L. (graduation committee); Panichella, A. (graduation committee); Delft University of Technology (degree granting institution)","2020","Computer networks have nowadays assumed an increasingly important role in the expression of modern human activity through the ongoing rapid development in the field of Information and Communication Technologies (ICT). More and more individual users and businesses around the world are gaining access to networks online, while the range of services offered by these networks span multiple domains of human life, leading them to grow in terms of both size and complexity, and in parallel handle a constantly growing volume of user-generated data. As with every important aspect of human life, computer networks need to be protected from malicious adversaries aiming to degrade the quality of the offered services and acquire unauthorised access to them, so as for their intended functionality to be uneventfully maintained. The broad success of Machine Learning (ML) based techniques in applications originated from a wide range of fields has led to the wide adoption of such techniques in the premises of automated network traffic analysis systems aiming to detect malicious activity within computer networks, with a notable portion of these systems employing solutions inspired from the field of anomaly detection. Such an automated system for anomaly detection in network traffic, attempting to address as many of the major shortcomings of earlier relevant works as possible, constitutes the content of this thesis. In particular, the proposed system is designed to offer fine-grained analysis of the recorded traffic, by leveraging powerful sequential learning models, like multivariate state machines, equipped with well known anomaly detection algorithms in their structure, towards the extraction of benign behavioral profiles from NetFlow traces of aggregated network entities, like hosts or connections, so as to use these profiles towards the identification of any behavior not conforming to them as anomalous. Three publicly available Netflow-based datasets, incorporating a diverse set of cyber attacks, are utilized to evaluate the detection potential of the proposed methodology. First, the effectiveness of multiple different settings of the designed detection system is quantified, so that the configurations with the most promising detection potential can be identified. Subsequently, the proposed system is compared with various easily developed baseline detection methodologies for the extent of the impact of its inherent complexity to be evaluated. Finally, the designed system is examined in comparison to a state-of-the-art detection technique operating on one of the three datasets used in this thesis, achieving higher or similar detection performance on all the scenarios considered.","Anomaly detection; State machines; Cyber Security; Machine Learning; Network traffic analysis","en","master thesis","","","","","","","","","","","","","",""
"uuid:692c4566-12b3-4761-9174-4480af014e0a","http://resolver.tudelft.nl/uuid:692c4566-12b3-4761-9174-4480af014e0a","Low Voltage AC-DC Converter Systems for Fast Charging Stations for Electric Vehicles","XIANG, Jingchun (TU Delft Electrical Engineering, Mathematics and Computer Science)","Bauer, P. (mentor); Soeiro, Thiago B. (mentor); Stefanov, Alexandru (graduation committee); Delft University of Technology (degree granting institution)","2020","Fast charging technology has accelerated the growth of the electric vehicle(EV) market and attracted significant attention from the industry. Two-stage AC/DC converter system is one of the traditional fast-charging architectures consists of the front-end converter and back-end converter. Numerous researches have developed IGBT-based medium-voltage converter or MOSFET-based low-voltage applications. In this work, a two-stage IGBT-based converter system is proposed in consideration of power switch costs and magnetic component loss.","DC/DC Converter; Fast Charging; ZVS","en","master thesis","","","","","","","","","","","","Electrical Engineering | Electrical Power Engineering","",""
"uuid:3b8695fd-8ab8-4ea1-8d4c-1f489ffc85da","http://resolver.tudelft.nl/uuid:3b8695fd-8ab8-4ea1-8d4c-1f489ffc85da","Visually grounded fine-grained speech representations learning","Tian, Tian (TU Delft Electrical Engineering, Mathematics and Computer Science)","Scharenborg, O.E. (mentor); Wang, X. (mentor); Isufi, E. (graduation committee); Tintarev, N. (graduation committee); Delft University of Technology (degree granting institution)","2020","Visually grounded speech representation learning has shown to be useful in the field of speech representation learning. Studies of learning visually grounded speech embedding adopted speech-image cross-modal retrieval task to evaluate the models, since the cross-modal retrieval task allows to jointly learn both modalities and find their relationships. Specifically, the two modalities, i.e., audio and visual, were jointly embedded into a common space where the speech embeddings and the image embeddings were learned in this process. The obtained embeddings were evaluated by cross-modal retrieval task to see the model performance. Currently, the studies worked on visually grounded speech representation learning trained on scene-based datasets, such as Flickr8k, etc., which learn different objects to infer a new scene. The works that investigating the visually grounded speech representation model's ability to combine different attribute information to infer new objects are lacking. Therefore, this thesis presented a visually grounded speech representation model trained on the fine-grained datasets that contain high level details of objects to learn attribute information associated with objects to infer new objects. The proposed model adopted dual-encoder structure and used different DNN models to extract visual and audio features. An adapted batch loss was used to calculate the similarities between two modalities. Experiments were conducted to test the model performance: 1) The parameter adjusting to obtain a better-performed model. 2) Comparing with state-of-the-art models in speech-image cross-modal retrieval field and fine-grained text-image cross-modal retrieval field. 3) Ablation studies to evaluate components in the model. 4) Research on attention module to see its effectiveness. The results indicated that the proposed model was able to learn the relationships between attributes and objects to retrieve new visual objects and outperformed other visually grounded speech learning models.","Multimodal modelling; semantic retrieval; visual grounding; speech representation learning","en","master thesis","","","","","","","","","","","","Computer Science | Multimedia Computing","",""
"uuid:9311bacf-01f9-444d-aa03-3baba8573013","http://resolver.tudelft.nl/uuid:9311bacf-01f9-444d-aa03-3baba8573013","Data fuelling Scania's future business","van Hasselt, Winand (TU Delft Industrial Design Engineering)","Simonse, LWL (mentor); Bluemink, R.G.H. (mentor); Hantosi Albertsson, Sarah (mentor); Delft University of Technology (degree granting institution)","2020","Scania is a Swedish manufacturer of trucks, busses and marine engines. With more than a hundred years of manufacturing experience Scania has built a track record of highly reliable and energy efficient trucks. Over the years Scania has been expanding its offering with maintenance services and later with data driven services to assist their clients in their daily operations. This thesis proposes an innovation strategy and service proposition for building on these data driven services. <br/><br/>The transport system is currently undergoing a transformation, led by trends like electrification, digitalization and connectivity. These trends have effects on how the value network of transport and logistics is organised and offer space for new business models. For Scania this means that there are opportunities to rethink favourable positioning in the value chain and develop business models, related to data driven services. To explore these potential new business models and positioning, this thesis aims to create a strategy, captured in a roadmap, supported by a new service proposition captured in a use case. <br/><br/>To create an according strategy and service proposition the internal environment and customers, value network, consumer context, market trends, technologies were analysed. These aspects formed the foundation for defining a strategic direction and future vision on data driven services. With this project the decision was made to narrow down to one specific application of transport to be able to provide more focus and in depth contextualisation. The chosen application was cooled transport for grocers, due to the perishable nature goods and transformation towards e-commerce. The future vision that was developed based on the insight gathered is: “Providing carefree cooled logistics.” <br/><br/>With this future vision a new service concept was developed that supports grocers in operating their logistics operations carefree by enhancing trust, increasing transparency and operational efficiency. This is accomplished by a combination of load sharing and secured data sharing, in which blockchain technology plays a key role. The concept was captured in a service blueprint and further illustrated in a use case. <br/><br/>Finally the concept has been captured in a roadmap, to build a pathway towards reaching the designated vision of providing carefree cooled logistics. Although the service concept and roadmap are targeted at cooled transport for grocers, some needs and principles are transferable to other applications of transport, creating potential opportunities for service development in other applications of transport. <br/><br","Innovation Strategy; Transport; Logistics; Design Roadmapping; Use Case; Service Blueprint; Scanie","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:3b2ce384-57d6-4484-83a1-97b3a9a1f03e","http://resolver.tudelft.nl/uuid:3b2ce384-57d6-4484-83a1-97b3a9a1f03e","City Hall Brussels","Stańczak, Magdalena (TU Delft Architecture and the Built Environment)","De Vocht, S. (mentor); Parravicini, M. (mentor); Rosbottom, D.J. (mentor); Pimlott, M. (mentor); Ploeger, H.D. (graduation committee); Delft University of Technology (degree granting institution)","2020","According to the World Migration Report 2015, published by the International Organisation for Migration, 62% of the people of Brussels are foreign-born or of foreign descent. That makes Brussels the second most diverse city in the world. The heterogeneity of the city of Brussels can be witnessed on the different levels such as class, culture, income, voluntary and enforced migrations. This diversity defines the nature of the city and it is often a reason for the tensions between authorities and identities. The city of Brussels, one of 19 municipalities that together form the Brussel Hoofdstedelijk Gewest, sponsored a developer-led competition for a city administrative building. The winning proposal was taken by the studio as a provocation, the beginning of the discussion about the place where the citizens can contact administration and governance, a place which represents the citizens and their concerns, a political space. <br/>A starting point of the idea for the graduation project was the complexity and the heterogeneity of the city of Brussels, demonstrated on its streets and the communal life. The main objective of the proposal was to create a building which contributes to the public realm of Brussels, to extend the existing public space instead of creating a new one, to connect the new building with an existing dynamic of the surroundings. <br","City Hall; Brussels","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Interiors Buildings Cities","",""
"uuid:5ea48fce-fa1e-457d-8277-ad19784033bc","http://resolver.tudelft.nl/uuid:5ea48fce-fa1e-457d-8277-ad19784033bc","Sustainable fashion: A statistical analysis of consumers’ behaviors by stated choice experiment","Pham, Dang Khoa (TU Delft Technology, Policy and Management)","Roeser, S. (graduation committee); Gammon, A.R. (mentor); Molin, E.J.E. (mentor); Delft University of Technology (degree granting institution)","2020","The manufacturing process, supply chain and consumption pattern of fashion impose high risks on the environment. Besides, the utilization of cheap labor in developing countries by Western fashion brands entails great concern about labor rights of sweatshop workers. To tackle the daunting sustainable issues in fashion industry, various nascent firms have utilized novel technologies to transform their production, supply chain, planning and marketing activities. However, the market size of sustainable clothes is still relatively small. As a matter of fact, consumers are supportive of sustainable clothes, but their positive attitude does not always turn into actual purchasing behavior. Prior research has shown that there is a discrepancy between people’s value and their action. No studies have used an objective rating system for sustainability attributes and calculated consumers’ willingness to pay for improvement in those ratings. My thesis aims to bridge this gap by studying how consumers trade off price against hypothetically constructed ratings of environmental and labor rights practices. 7 main variables representing information on clothes labels (price, country of origin, fiber content, washing instruction, drying instruction, environment rating, labor rights rating) and 12 background variables (including 6 sociodemographic, 3 spending habit and 3 attitudinal variables) were chosen for this project. A stated choice experiment was constructed to collect data from 123 people, and discrete choice modelling was employed to analyze the data. The results showed that 5 out of 7 main variables (price, fiber content, washing instruction, environment rating and labor rights rating) play a significant role in respondents’ choice. Consumers prefer lower price, pure cotton (vs mixed blend) and the option to use washing machine (vs washing by hand). Regarding the environment and labor rights attributes, higher ratings are preferred, and the preference for higher ratings follows the law of diminishing marginal utility. In the final model, 4 background variables including gender, country of residence, concern about sweatshops and skepticism of eco-labels were shown to moderate the effects of main variables. Women and residents in high-income countries are more sensitive to price. People who are more concerned about sweatshops attach a higher importance to labor rights rating, whereas people who are more skeptical of eco-labels care less about the it. A typical individual in our sample is willing to pay €12 to €36 more for 1-point improvement of either environment rating or labor rights rating. Consequently, sustainable fashion brands can deploy either of the following two strategies to enhance their sales: (1) charge this price premium without losing their market share or (2) keep the same price to gain more customers.","Sustainabilty; Sustainable Consumption; Fashion; Consumer Behaviour; Stated Choice Experiment; discrete choice modelling","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:311e38fd-2a7e-410d-89e3-688a24ee0a69","http://resolver.tudelft.nl/uuid:311e38fd-2a7e-410d-89e3-688a24ee0a69","Antifragility in strategic management; Strengthening companies through embracing uncertainty: An analysis of the application of antifragility in the field of strategic management, focusing on redundancy, optionality, and skin in the game","Disseldorp, Thomas (TU Delft Technology, Policy and Management)","Scholten, V.E. (mentor); van Beers, Cees (mentor); Delft University of Technology (degree granting institution)","2020","The environment that high-tech companies have to navigate is changing rapidly. To deal with these changes, managers have limited tools, of which many are based on predictive properties. However, as Black Swans and X-events illustrate, the future is inherently unpredictable. As the field of strategic management is primarily involved in dealing with the future, a new approach that does not rely on prediction could be of incredible value. Therefore, the concept of antifragility is introduced in this field as a new approach for management to decide on strategies. Antifragility is a concept that moves away from prediction. It does so by focusing on ways to deal with variation instead of merely aiming to prevent or predict it. It looks at what changes will do to an organisation and how to adapt a system so it can absorb or even benefit from this variation. Antifragility is a relatively new concept in the field of strategic management and therefore limited research has been conducted. The aim of this research is to analyse the concept through three aspects of antifragility: optionality, redundancy, and skin in the game. Strategies and practices that are related to these aspects are identified and analysed in order to get higher level insights in the mechanisms that increase antifragility through these concepts. The end results are several propositions capturing these mechanisms, which give insight in how companies and organisations can use antifragility to improve their strategic management. The research is exploratory as the field is relatively unknown and the existing research is not consistent of quality due to the lack of a theoretical framework. The main research question investigated in this thesis is the following: What underlying mechanisms drive antifragility in strategic management through the concepts of redundancy, optionality, and skin in the game? In order to be able to create propositions with validity in such a new field, the research consisted of three separate parts that delivered separate conclusions. This way, insights and higher-level mechanisms could be triangulated from these parts, creating valid and strong propositions. First a desk research was conducted through literature on antifragility from the fields of strategic management, urban planning, systems dynamics &amp; engineering, and ICT. The literature was analysed to create conclusions on the strategies and practices for implementation of antifragility in strategic management. Furthermore, a comprehensive overview and consolidation in vocabulary on the subject of antifragility in strategic management was made. Second two case studies were executed, respectively about Haier and Zappos. Both companies are known for their innovative management structures and are well documented in scientific literature. This literature was analysed to highlight antifragile strategies and practices employed by the companies and general conclusions were created by comparing overlap between them. Finally, nine semi-structured interviews were conducted with interviewees that employ antifragility or related concepts in their professional career. The results were analysed using a general inductive approach. The resulting categories were discussed. The conclusions of these three aspects combined created higher-level insights into the mechanisms behind optionality, redundancy, and skin in the game and how they contributed to an increase of antifragility for organisations. These insights were captured in several propositions. The resulting proposition highlighted that a greater focus on continuous experimentation, building redundancy and optionality through diversifying and a structure of decentralized decision making can increase the antifragility of a company. Furthermore, that implementing skin in the game from employees can be achieved through either conscious choice or an increase in employee engagement. The implications of the propositions cover many areas. For the scientific community an overview, consolidation of terminology, and an expansion towards other fields has been made for antifragility in strategic management. This opens up both many new research possibilities and a common ground to start from. For the TU Delft this new view on strategic management can add a new and contrasting view to the curriculum, highlighting biases and assumptions underlying many strategies and theories. For society, a focus on growing organisations in an antifragile manner can promote more adaptability and thus stable economic prosperity. For management, the implications can be far reaching. This research shows that although the quantitative evidence of the benefits that antifragility can bring are few, the concept holds promise of more control and success in strategic decision making. Using antifragility, they are better able to withstand variations, can benefit from it and it enables them to take an inwards look, focusing their efforts at what companies can influence, instead of trying to influence the un-influenceable. Adjusting to the propositions as stated requires a new view on almost every aspect of the modern company. However, for the concept to become more accepted and applied, future research is necessary, such as quantitative proof of effectivity of antifragility and a better understanding of the limitations of antifragility.","Strategic management; Antifragility; Resilience; Redundancy; Optionality; Skin in the game","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:6146df1f-c4d8-4e51-9ba1-f10c21b61561","http://resolver.tudelft.nl/uuid:6146df1f-c4d8-4e51-9ba1-f10c21b61561","Effect of consolidation parameters on (de)consolidation in ultrasonic welding of thermoplastic composites","Vinod, Rahul (TU Delft Aerospace Engineering)","Villegas, I.F. (mentor); Jongbloed, B.C.P. (mentor); Delft University of Technology (degree granting institution)","2020","Thermoplastic composites are gaining prominence in the aerospace industry owing to their higher damage tolerance, cost-efficient means of manufacturing, and the possibility to be recycled. One of the major benefits of thermoplastics compared to thermosets is their ability to be welded, and one of the most promising welding techniques for thermoplastic composites is ultrasonic welding. Ultrasonic welding is the fastest welding technique currently known, with typical weld times of a few hundred milliseconds.<br/><br/>Studies have been conducted in plenty regarding static ultrasonic welding of thermoplastic composites. But the industrialisation of the process involves the development of a robust continuous ultrasonic welding process which can weld the entire span of the joints, thus enabling higher load transfer and reduced stress concentrations. However, the state-of-the-art continuous ultrasonic welded joints contain voids at various locations within the weld which are assumed to appear due to a lack of consolidation during the welding process. Unlike the static ultrasonic welding, where the sonotrode can both transfer the vibrational energy to the adherends being welded and provide consolidation force, the continuous ultrasonic welding requires a separate consolidation device to provide consolidation pressure application. This makes it necessary to expand the understanding of the consolidation process to improve the weld quality and increase the Technology Readiness Level (TRL) of the ultrasonic welding process before it can be industrially used. While a lot of research to date focused on the vibration phase of the process, not much information is available regarding the consolidation phase. This research project thus explores the effect of consolidation pressure and time on (de)consolidation in ultrasonic welding of thermoplastic composites.<br/><br/>An experimental study was carried out on the consolidation in static welding of CF/PPS test coupons, and the knowledge obtained was extended to the continuous ultrasonic welding process. The consolidation in the continuous ultrasonic welding process was provided by a separate consolidation device or ”consolidator” placed behind the sonotrode. Various characterisation techniques including lap shear strength, void content assessment and fracture surface analysis were used to analyse the results obtained. The experiments revealed that for semi-crystalline polymer PPS, consolidation should start when the polymer is in its melt state and extend until the interface temperature of the weld drops below the crystallisation temperature of the polymer. The results obtained indicated that the voids in ultrasonic welding were formed due to a combination of shrinkage due to crystallisation, fibre decompaction, the choice of the clamps used and excessive squeeze out of the resin. In continuous ultrasonic welding, the location of the consolidator behind the sonotrode and the consolidation pressure was found to influence the weld quality. The research conclusions serve as a first step towards developing a robust consolidation process in continuous ultrasonic welding of thermoplastic composites.","Thermoplastic Composite; Ultrasonic welding; Continuous ultrasonic welding; Consolidation parameters; Deconsolidation; Voids; Composite welding","en","master thesis","","","","","","","","2021-07-31","","","","Aerospace Engineering","",""
"uuid:a2262e3f-36ed-4c8b-aefa-061a4cc8127a","http://resolver.tudelft.nl/uuid:a2262e3f-36ed-4c8b-aefa-061a4cc8127a","A Multi-modal Feedback System for Ergonomic Pose Estimation","Thirani, Kushal (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Cognitive Robotics)","Abbink, D.A. (mentor); Peternel, L. (graduation committee); Vallery, H. (graduation committee); Delft University of Technology (degree granting institution)","2020","This study proposes the creation of a multi-modal feedback system to guide humans towards ergonomic poses. A number of studies have tried to come up with methods where subjects are alerted upon crossing biomechanical or ergonomic thresholds while doing a task but not many have tried to successfully and efficiently guide users to ergonomic positions after having alerted them. Through this study we propose the creation of a multi-modal feedback system comprising of a visual and a speech based audio feedback and hypothesize that the proposed system will lead to a better performance as compared to the other feedback modalities when trying to guide users from one pose to another. During our study we have conducted two sets of experiments to carry out a comparative study between only audio, only visual and the proposed multi-modal feedback system to try and find the modality most effective and successful in guiding humans for pose corrections and a comparative study between two types of speech based audio feedbacks in joint space and end point space to motivate our choice for using the more desired one between the two for our proposed system.<br/>Speech based feedback in joint space came out as the preferred audio feedback due to its ability to allow users to carry out efficient and coordinated inter-joint movements especially in cases of high redundancy whereas the proposed multi-modal feedback system successfully shows its superiority over the other feedback<br/>modalities by showing equivalent results against the benchmark visual feedback when measured objectively and better results when measured subjectively due to its ability to successfully combine the advantages of audio and visual feedback and at the same time, avoid their limitations.","Ergonomics; Human Machine Interaction; Pose estimation; Multimodal feedback","en","master thesis","","","","","","","","2021-08-31","","","","Mechanical Engineering","",""
"uuid:0de2b13d-ab80-4ac7-afca-8ea27934f3b5","http://resolver.tudelft.nl/uuid:0de2b13d-ab80-4ac7-afca-8ea27934f3b5","Green Hydrogen for Residential Heating and Agricultural Mobility in Rural Areas: Socio-technical analysis of a hydrogen based energy system in Oudeschip","van der Weijden, Joep (TU Delft Technology, Policy and Management)","Lukszo, Z. (mentor); Warnier, Martijn (mentor); van Wijk, A.J.M. (mentor); Fens, T.W. (mentor); Delft University of Technology (degree granting institution)","2020","The Dutch Government is picking up the pace in the energy transition. However, the expansion of wind generation is facing congestion challenges, and the decarbonization of household heating and agricultural mobility proves that electrification is not always an option. These challenges occur together in rural areas like Oudeschip. <br/>Hydrogen has emerged as a possible solution to the encountered problems. By producing hydrogen from the wind power and transporting the hydrogen through the natural gas infrastructure, household heating can be decarbonized without electrification. Furthermore, by converting the tractors of the local farmers to diesel-hydrogen hybrids, they can reduce their emissions. This research approaches the energy system of Oudeschip as a socio-technical system, and tackles the challenges in different sectors in an integrated manner.","Hydrogen; heating; mobility; rural areas","en","master thesis","","","","","","","","","","","","Systems Engineering, Policy Analysis and Management (SEPAM)","",""
"uuid:28449637-066a-46b2-9bdc-6d6e249e0f47","http://resolver.tudelft.nl/uuid:28449637-066a-46b2-9bdc-6d6e249e0f47","Syntonize: A collaborative music making platform for bandmates","Langrand, Marianne (TU Delft Industrial Design Engineering)","Pasman, G.J. (mentor); Stappers, P.J. (mentor); Delft University of Technology (degree granting institution)","2020","This research explores the music making practices of musicians in a band, uncovering their needs to carry out successful collaborations. This work focuses on three key areas: the creative activities of music making, the dynamics of collaboration, and the tools used to support these. <br/><br/>This research unravels the complexity of the workflows of musicians, which lie amidst their individual musical expression, the constant exchange of their ideas, and the evolution of their personal relationships, with the goal of contributing to a shared musical piece. Additionally, currently used music making apps do not facilitate collaborative activities, making musicians seek alternative file sharing and communication tools to fulfill their needs online. This blocks their creative flow and slows down the band’s progress, particularly in the context of remote collaborations. <br/><br/>In a bid to address these issues and improve their collaboration, a solution was designed: Syntonize is a simple music making app concept that enables musicians in a band to easily collaborate on their early music making activities. They can create music teams with their bandmates, as well as shared music projects where they can easily record and combine their ideas. They can also communicate about their music, whether it is for precise feedback on their work, or general project management.<br","music making; music; user research; digital design; app design; creativity; technology; remote research","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:4ef079cf-78ca-4deb-a942-7de50fea8627","http://resolver.tudelft.nl/uuid:4ef079cf-78ca-4deb-a942-7de50fea8627","Scrum for Hardware development projects: A study to fit the scrum method in Hardware development projects","Satish Jyotsni, S.J. (TU Delft Civil Engineering and Geosciences)","Bosch-Rekveldt, M.G.C. (mentor); Bluemink, R.G.H. (mentor); Rosch, Karin (mentor); Bakker, H.L.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","The trends in the high tech sector push towards creating and delivering better products to cope with the increasing demands of the customers. The projects of the high tech sector are referred to as Hardware (HW) development projects, which consist of both hardware and software (SW) development. Many organisations have been using traditional project management approaches for years for such projects. In the past few years, the organisations are considering or in the progress of shifting towards the agile project management approach as it has potential benefits which include high involvement and satisfaction of customers, a better quality of deliverables, and adapt to changing requirements in a project. However, mixing both the traditional and agile approaches can have a significant effect on the performance of the project. As it is possible to integrate practices of the agile method into the traditional project management approach, and when combined, this would improve the functionality of the product less influencing the cost and time. A common framework of the agile project management approach is the Scrum method, commonly used for software development. However, to get full advantage of the scrum method for hardware development, it needs to be tailored to the needs and type of the project. The aim of the research is to explore the application of Scrum for hardware development projects with the objective is to formulate suggestions on elements of Scrum that can be applied in the management of hardware development for the benefit of the projects. A theoretical framework was developed, describing scrum practices and their benefits. The benefits known from the theoretical framework will be used as background knowledge to investigate the fit of Scrum elements in the current management approach. Further, the applicability of scrum practices for HW development is decided based on the agile value and principle; each Scrum practice is related. This research determines the characteristics of the HW development project and the difference between the traditional project management approach and agile project management approach. Also presents the suggestion of scrum practice after considering the inputs from the expert's meetings that can be applied in managing specific complexity/problem.<br","hardware development; agile management; scrum method; traditional management; complexities; problems","en","master thesis","","","","","","","","","","","","","",""
"uuid:e3c856fb-3525-4cb0-bd51-b7b25191a1b6","http://resolver.tudelft.nl/uuid:e3c856fb-3525-4cb0-bd51-b7b25191a1b6","Digital Playground: Pneumatic interactive architecture in abandoned post-industrial structures","Romaniuk, Filip (TU Delft Architecture and the Built Environment)","Bier, H.H. (mentor); Adema, F. (graduation committee); Hidding, A.J. (graduation committee); Rooij, R.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","The master's thesis explores the possibilities of reusing abandoned post-industrial structures and objects of architectural heritage. Objects, which are usually difficult to renovate due to high costs and their poor physical condition, could be filled with new inflatable volumes and thus be filled with new space, function, and life. The work is inspired by designs from the 1960s and 70s of temporary and easily deployable inflatable installations, as well as the latest developments in soft robotics. Pneumatic structures equipped with sensors and activators would allow the creation of a responsive and interactive architecture evolving in time.","pneumatic; Inflatable; Pneumatics; Interactive; Responsive Space; Responsive surface; Digital architecture; air; Plastic; Soft Robotics; Abandoned structures; Senses; touch; temporary architecture","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Robotic Building","",""
"uuid:e572b02c-6e94-49a2-9347-07c62d94d7cd","http://resolver.tudelft.nl/uuid:e572b02c-6e94-49a2-9347-07c62d94d7cd","Faster Low-Thrust Trajectory Design Through Finite Fourier Series: The effects of a new initialisation strategy","van Lith, Thijs (TU Delft Aerospace Engineering)","Noomen, R. (mentor); Delft University of Technology (degree granting institution)","2020","Low-thrust propulsion has gained more popularity over the past few decades because of its high efficiency. Interplanetary transfer trajectories in particular benefit from low-thrust propulsion, considering the typically high Delta V to be achieved. In order to allow a fast design of such missions, first-order, efficient representations of transfer orbits are usually used before a more detailed and exact numerical model is applied. The finite Fourier series method is one of these so-called shape-based methods that are suited for this. In this thesis, the focus is twofold: it lies on the implementation and validation of the method in TUDAT, and on improving this first-order method through a different initialisation strategy with the goal of improving its convergence speed and its three-dimensional stability.<br/><br/>During implementation, some inconsistencies have been encountered that were not clearly, or even incorrectly addressed or documented by the inventors of this method. These include the calculation of the initial guess, the definition of the decision vector, the performance of the two-dimensional unconstrained finite Fourier series, the two-dimensional reference results and the interpretation of the reference frame. After these problems have been overcome, the method has been validated successfully against three case studies.<br/><br/>The original strategy is based on the approximation of the trajectory by means of a third-order power function. In the search of a better strategy, four different function types have been analysed: (the original) power function, an exponential function, a trigonometric function and a logarithmic function. The functions were tested on two transfer trajectories, both in two and three dimensions: from the Earth to Jupiter and from the Earth to Dionysus.<br/><br/>It has been concluded that the use of the proper initialisation strategy can considerably boost the effectiveness of the finite Fourier series method. However, a clear contrast between the two-dimensional and three-dimensional version was observed: the two-dimensional version of the algorithm greatly benefits from an exponential function to generate a priori values and shows an increase in convergence speed of up to 42.6%. On the other hand, there has not been a single approach that decreases the convergence time of the solver nor improves the stability for the three-dimensional version. This also led to the conclusion that the finite Fourier series method is rather sensitive regarding a priori values for the axial candidate.","Low-thrust propulsion; Shape-based methods; tudat; Implementation; application; Initialisation","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:31f952ac-b412-43bb-909a-c34ad8e9f390","http://resolver.tudelft.nl/uuid:31f952ac-b412-43bb-909a-c34ad8e9f390","The Influence of Public Participation and Energy Justice on the Heating Transition in Mariahoeve, The Hague: An explorative case study on the heating transition","Broer, Rutger (TU Delft Technology, Policy and Management)","Hoppe, T. (mentor); Pesch, U. (graduation committee); Delft University of Technology (degree granting institution); Universiteit Leiden (degree granting institution)","2020","The thesis analyses the role of public participation and energy justice perceptions of local stakeholders on policy-making in the heating transition in the district Mariahoeve in The Hague. The thesis shows that the municipality of The Hague approaches public participation both top-down and bottom-up. Participants mainly expressed justice concerns in relation to communication, outcome fairness, outcome favourability, and distribution of responsibilities. In reaction to the preferred scenario of the municipality, participants proposed to include a low temperature district heating system in the assessment for the most suitable heating solution. Analysis of the interactions between policymakers and stakeholders indicates a willingness of policymakers to hear the concerns of participants. However, the municipality can be more clear in its communication about how the heating transition will be organized in Mariahoeve.","Public Participation; Energy Justice; Heating transition; Governance; District heating systems","en","master thesis","","","","","","","","","","","","Industrial Ecology","",""
"uuid:2dccaa3b-dbff-428e-a5d3-d46ada57504d","http://resolver.tudelft.nl/uuid:2dccaa3b-dbff-428e-a5d3-d46ada57504d","Scheduling Strategies for Event-Triggered Control Using Timed Game Automata Over CAN Networks","Samant, Aniket Ashwin (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Delft Center for Systems and Control)","Mazo, M. (mentor); Nasri, Mitra (graduation committee); Mohajerin Esfahani, P. (graduation committee); Delft University of Technology (degree granting institution)","2020","Modern times have seen an increasing use of networked control systems, in which plants and controllers may not necessarily have a direct link but instead be connected through a network, thereby closing control loops over multiple nodes.<br/><br/>The system may also be spread out spatially over a large area, and thus the associated network delays could greatly hamper control performance, potentially affecting the closed-loop stability of the system. In such scenarios, event-triggered control approaches could greatly reduce network congestion<br/>by allowing a means for the controllers to send control loop computation packets over the network only when required, in an event-driven manner, rather than through periodic transmissions. However, in practice, the number of parallel channels is limited compared to the number of controllers and hence the transmission of packets needs to be scheduled carefully to avoid network conflicts. <br/><br/>This thesis explores using a network of timed (game) automata composed of models representing a networked control system’s control loops and its communication network. This reduces the scheduling problem of transmission of control loop computations to one of creating strategies using known algorithms, with the objective being to avoid network conflicts brought about by simultaneous transmissions. Furthermore, the proposed automata models also aim to reduce the conservatism of generated scheduling strategies by allowing the control loops a bounded number of retransmission attempts to send packets over the network in case it is already occupied. The concept is finally demonstrated in practice using simulated plants and controllers distributed over multiple machines connected via a physical CAN network.","event-triggered control; timed automata; cyber-physical systems; CAN networks","en","master thesis","","","","","","","","","","","","Electrical Engineering | Embedded Systems","",""
"uuid:5962bba9-8271-44f2-bf7c-1c92a0c8e1e5","http://resolver.tudelft.nl/uuid:5962bba9-8271-44f2-bf7c-1c92a0c8e1e5","Response-Time Analysis for Non-Preemptive Global Scheduling with Spin Locks","Nogd, Suhail (TU Delft Electrical Engineering, Mathematics and Computer Science)","Langendoen, K.G. (graduation committee); Nasri, Mitra (mentor); Nelissen, Geoffrey (mentor); Delft University of Technology (degree granting institution)","2020","With the proliferation of multicore platforms, the embedded systems world has shifted more and more towards multiprocessing to make use of high computing power and increased cyber functionalities. Although today multiprocessor platforms have been extensively adopted by real-time embedded systems, there exists a need for tools and techniques that can accurately assess the temporal correctness of a system. In terms of multiprocessor systems, this is coupled with fundamental challenges, since these systems, as we find them today, make use of complex hardware components, resource sharing and memory architectures, which negatively affect the timing predictability of such systems. Spin-based locking protocols, which are used to ensure mutual exclusion when sharing resources in a system, and a non-preemptive execution model have been found to help mitigate the adverse effect on the timing predictability, since they allow for less interruptions, which results in reduced cache evictions and a better estimate of worst-case execution times. While this improves the overall timing predictability of such systems, to date, there exists no response-time analysis that can analyze multiprocessor systems that globally execute non-preemptive tasks sharing resources protected by spin locks. Motivated by the lack of analysis tools for systems that consider non-preemptive global scheduling and the access to shared resources, this work provides the first analysis for global job-level fixed-priority (JLFP) scheduling policies and FIFO- or priority-ordered spin locks. To do so, it extends the family of schedule-abstraction-based analysis to model the access to shared resources in a highly accurate manner. The proposed analysis computes response-time bounds for a set of resource-sharing jobs subject to release jitter and execution-time uncertainties by implicitly exploring all possible execution scenarios using state-abstraction and state-pruning techniques. A large-scale empirical evaluation of the proposed analysis shows it to be substantially less pessimistic than simple execution-time inflation methods (i.e., a straightforward extension of existing response-time analysis tools for non-preemptive tasks that do not share resources), thanks to the explicit modeling of contention for shared resources and a scenario-aware blocking analysis.","real-time systems; response-time analysis; multiprocessor platforms; shared resources; embedded systems","en","master thesis","","","","","","","","","","","","Electrical Engineering | Embedded Systems","",""
"uuid:c7dc661e-c3f9-4986-bc54-c903aaddbc68","http://resolver.tudelft.nl/uuid:c7dc661e-c3f9-4986-bc54-c903aaddbc68","Towards Engineering AI Software for Fairness: A framework to help design fair, accountable and transparent algorithmic decision-making systems","Lazo, Claudio (TU Delft Electrical Engineering, Mathematics and Computer Science)","Houben, G.J.P.M. (graduation committee); Lofi, C. (mentor); Venkatesha Prasad, R.R. (graduation committee); Delft University of Technology (degree granting institution)","2020","Algorithmic decision-making (ADM) is becoming increasingly prevalent in society, due to the rapid technological developments in Artificial Intelligence. ADM make substantially impactful decisions about people: diagnosing whether we have a disease, what news and which ads we get to see, whether we<br/>are eligible for a job, benefits, a college or a loan, they show us personalized media and news, and steer the car that drives us home. However, ADM brings about ethical, legal and social issues by inheriting and perpetuating human biases, learning to discriminate—even learning gender or racial stereotypes, and lacking transparency and accountability. This unexpected and biased behaviour arises because these software systems are usually built without the specification of fairness requirements (i.e. what fair behaviour is expected of the system). We envision a Software Engineering for Values (SEfV) method that solves this problem. <br/>This study addresses that specification problem, aiming to help practitioners design ADM software for fairness. Using literature in social sciences—specifically organizational justice—the human value of fairness has been conceptualized in regard to ADM. This resulted in a fairness tree with four dimensions (procedural, distributive, informational and interpersonal fairness), which is further specified into 31 fairness norms. Subsequently, the fairness tree is related to current measures of fairness and techniques. Finally, we put forward the Software Engineering for Values (SEfV) framework, based on the principles of Software Engineering and Design for Values, and show how it can be applied to design ADM for fairness.<br/>Experiments were conducted where participants (N = 12) performed a design task (M = 3, 75 requirements specified) and an audit task for a hypothetical loan decision system—using a prototype of the SEfV framework. Participants found the prototype useful for both design as auditing, especially<br/>as a tool for reflecting on fairness considerations. This suggests that a high fidelity version would be useful for practitioners.","fairness; discrimination; bias; algorithmic decision-making; machine learning; software engineering; requirements engineering; Design for values; AI ethics","en","master thesis","","","","","","","","","","","","Computer Science | Web Information Systems","",""
"uuid:a3cf2384-4913-495f-8542-37fbbfbb3197","http://resolver.tudelft.nl/uuid:a3cf2384-4913-495f-8542-37fbbfbb3197","Analyzing single molecule emission patterns using Deep Learning","Mukherjee, Anish (TU Delft Mechanical, Maritime and Materials Engineering)","Stallinga, S. (mentor); Delft University of Technology (degree granting institution)","2020","The time taken to generate a super-resolution image and the quality of the final synthetic image depends on the performance of the localization algorithm which is used in the localization microscopy pipeline. The most precise and accurate algorithms are mostly iterative and they take a long time to generate the localization list while the faster ‘one-shot algorithms’ are not very accurate and precise. A deep learning method smNet (single-molecule Net) was developed by Zhang et al which was claimed to perform one-shot localization with precision close to the theoretical limit and very accurately, along with performing aberration estimation and dipole-emitter orientation angle estimation. The deep<br/>learning model smNet was trained either by augmenting experimental data or using simulated data generated with an erroneously simplified simulation model and a phase retrieval method. The purpose of this work was to characterize the performance of smNet when it was trained with simulated images generated using an accurate vector model for a range of physical conditions. Along with the characterization of smNet’s performance in doing 3D localization and aberration estimation with the accurate vector model, a pipeline was also designed which made the training process of smNet more efficient and computationally cheaper while performing accurate and precise 3D localization and aberration estimation.<br/>The pipeline was designed to implement the concept of simulator learning where a smNet model could be trained on simulated data and used to perform 3D localization and aberration estimation directly on experimental data without any retraining or domain adaptation techniques.","Localization Microscopy; Deep Learning; 3D Localization; Aberration Estimation","en","master thesis","","","","","","","","","","","","Biomedical Engineering | Medical Physics","",""
"uuid:b9e02a1d-4c02-4261-9d66-1b282e8d690f","http://resolver.tudelft.nl/uuid:b9e02a1d-4c02-4261-9d66-1b282e8d690f","Active cooling in additively manufactured liquid rocket engines: Comparing regenerative, film and transpiration cooling","Koehler, Stijn (TU Delft Aerospace Engineering)","Zandbergen, B.T.C. (mentor); Gill, E.K.A. (graduation committee); Melkert, J.A. (graduation committee); Delft University of Technology (degree granting institution)","2020","The heat fluxes in (liquid) rocket engines can go up to high values and they need active cooling to prevent the chamber wall from failing. Transpiration cooling is identified as a way to achieve lower wall temperatures than commonly used regenerative cooling and regenerative cooling with additional film cooling (referred to as film cooling from now on). This can lead to higher performance of the engine. However, transpiration cooled engines are not in use today and this is mainly attributed to problems with the required porous wall materials. Additive manufacturing (AM) is a promising solution for these material problems. Better cooling is especially useful for Inconel additively manufactured rocket engines as such engines experience higher wall temperatures due to the low thermal conductivity of the material. <br/>This thesis has two purposes. Firstly, an analysis was performed to see if transpiration cooling actually performs better than regenerative and film cooling in total engine performance. Secondly, it was investigated if AM can be used to create the porous walls required for transpiration cooling. <br/>To compare the cooling techniques, a simplified model for each cooling technique was developed. These models were verified and validated using data from literature. A new (transcritical) film cooling model was created by combining three existing film cooling models. The wall temperatures obtained from the three cooling methods were compared by applying them to a reference liquid rocket engine with either Inconel or copper as wall material. Subsequently, the losses in specific impulse and dry mass were determined. Then, a delta-v calculation for each cooling method was made to objectively compare them. <br/>The conclusions on the comparison of the cooling techniques are that the regenerative cooled engine reaches wall temperatures above the material limits. Therefore, it is not a feasible to use this cooling method for the reference engine. Film and transpiration cooling can both achieve temperatures below the limit. Transpiration cooling requires less coolant than film cooling to achieve the same temperature. This will result in lower losses in specific impulse compared to film cooling. However, to achieve these low coolant mass flows, thick chamber walls are required to achieve the specified pressure drop over the wall. When comparing transpiration cooling to film cooling on the total delta-v achieved, it is found that the Inconel chambers perform better than the copper ones. However, it depends on the pore size if transpiration cooled engines outperform film cooled ones. A smaller pore size is better.<br/>Additionally, it was found that the pore sizes producible with AM are an order of magnitude larger than required. Therefore, experiments were performed on the pressure drop over AM porous walls with different geometries. With these experiments, it was found that a new porous wall geometry made using AM techniques has a lower pressure drop than the geometry used in the calculations, being 1.32 lower. A geometry designed to achieve an as large as possible pressure drop increased the pressure drop 24.9 times. However, this geometry does not achieve a uniform coolant injection required for transpiration cooling, so further research is required.<br/><br","Film cooling; Transpiration cooling; Rocket propulsion; Heat transfer; Additive Manufacturing; Regenerative cooling","en","master thesis","","","","","","","","2022-08-25","","","","Aerospace Engineering","",""
"uuid:c20e0a4f-1237-4ab7-8851-691db891caad","http://resolver.tudelft.nl/uuid:c20e0a4f-1237-4ab7-8851-691db891caad","Predictive maintenance for utility scale solar parks: A machine learning approach towards early fault detection for PV inverters","Manmohan Sane, Omkar (TU Delft Electrical Engineering, Mathematics and Computer Science)","Isabella, O. (mentor); Ziar, H. (graduation committee); Kozlova, Tatiana (mentor); Giagkoulas, Vasilieos (graduation committee); Delft University of Technology (degree granting institution)","2020","The growing demand and improvements in manufacturing capabilities, supported by government subsidies, has allowed the increase in the installed capacity of utility scale solar parks. Due to the remoteness in their location, the costs associated with dispatching personnel for maintenance is extremely high. A major contribution towards unscheduled downtime of these plants is due to the inverter faults. Currently, reactive and preventive maintenance are the most prevailing methods to identify and fix inverter faults. The presumption that the components will not under-performor fail until the scheduled visit, leads to a significant loss of production and revenue. To deal with the disadvantages of current maintenance methods, the solar industry is very keen on understanding the possibility of early detection of inverter faults by implementation of predictive maintenance. This research assessed the applicability of Machine Learning (ML) towards early signal detection of inverter faults in order to generate predictive maintenance alerts. The data for building the ML algorithms was acquired from a Shell owned 26.6 MWp utility scale solar park located in Moerdijk, The Netherlands. The early signal detection algorithmdeveloped, was based on the comparison between the actual and the predicted active power. The model built to predict the active power was based on two supervised learning methods;Elastic Net and Gradient BoostingMachine (GBM) with quantile regression. These models were capable of predicting the active power with a Mean Absolute Error (MAE) of 0.98kW &amp; Root Mean Square Error (RMSE) of 1.8kW using Global Plane of Array irradiance (GPOA) and module temperaturemeasurements available from theMoerdijk data. The early signal detection relied on differentiating between prediction error and actual error. A window was created to encompass the maximum extent of prediction errors to avoid any false positive signals. This window for elastic net was found to be ¡¾ on the lower side and 2¾ on the upper side. Although when elastic net method was tested on 337 inverters- by looking at their residual variation 1-week prior to registered fault- it was found that the predictions suffered a periodic structural error. This was due to the erroneous predictions at times with extreme irradiance values. To mitigate, this the GBM with quantiles of 0.01 and 0.99 of GPOA was built to create a range of predictions giving rise to a wider range for normal operation. The results from both the algorithms indicated no early signals for inverter fault detection. This was partly due to data quality issues with fault tags in the Supervisory Control and Data Acquisition (SCADA) monitoring system; only 7 actual fault cases were identified. Additionally, the economic feasibility of implementing predictive maintenance was found to potentially reduce the current Operational Expenses (OPeX) by up to 10%. Despite the issues with data quality, an approach of using ML towards early fault detection for inverters in utility scale solar parks has been realised through this research.","Machine Learning; predictive maintenance; Artificial intelligence; SCADA; analytics; GBM; Gradient Boosting Machines; Elastic net; quantile regression","en","master thesis","","","","","","","","2022-08-25","","","","","",""
"uuid:009a6801-cf71-4490-9046-326113bce762","http://resolver.tudelft.nl/uuid:009a6801-cf71-4490-9046-326113bce762","Modelling of Electric Powertrain for Heavy-Duty BEV","Abhay, Nived (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft DC systems, Energy conversion & Storage; TU Delft Electrical Sustainable Energy)","Dong, J. (mentor); Nouws, Simon (mentor); Bauer, P. (mentor); Rueda, José L. (graduation committee); Delft University of Technology (degree granting institution)","2020","The automotive industry plays a crucial role in battling the climate crisis and reducing emissions. Medium-duty and heavy-duty vehicles alone contribute to one-fourth of global emissions in the transport sector and there is a positive trend in the demand for these vehicles. Battery Electric Trucks have the potential to transform the growing logistics industry.<br/><br/>DAF Trucks N.V., one of the largest truck manufacturers in Europe, aims to transition to zero-emission vehicles and advance in this future of electric mobility. This project aims to model the powertrain of their CF Electric model and explore viable options for future designs. The thesis work can be defined in three parts.<br/><br/>The first part of the research focuses on modelling the electric powertrain in MATLAB/Simulink. Here, more focus is given in the calculation of individual motor and inverter losses. These losses are reverse engineered and extracted from the motor drive efficiency map using Particle Swarm Optimisation (PSO) algorithm.<br/><br/>The second part of the project focuses on performing sensitivity analysis to identify the key parameters that have the most influence on the energy efficiency of the Battery Electric Vehicle (BEV). This helps to prioritise and focus on optimisation of these parameters for future models. A comparison is drawn between the percentage change in the range each parameter has with small changes.<br/><br/>Lastly, in the third part of the thesis, different powertrain architectures are studied and modelled to under- stand their influence on the range of the BEV and the challenges involved in implementing such layouts.","Battery Electric Vehicles; Modelling; Powertrain; Particle Swarm Optimization; Heavy duty vehicles; Sensitivity Analysis","en","master thesis","","","","","","","","2022-08-25","","","","","",""
"uuid:9370704d-a455-4a64-924e-ab428450327c","http://resolver.tudelft.nl/uuid:9370704d-a455-4a64-924e-ab428450327c","Linear and Efficient Power Amplifier for WiFi","Kumaran, Anil Kumar (TU Delft Electrical Engineering, Mathematics and Computer Science)","de Vreede, L.C.N. (mentor); Alavi, S.M. (mentor); Fan, Q. (graduation committee); D'Avino, M. (mentor); Delft University of Technology (degree granting institution)","2020","CMOS technology is one of the feasible solutions to meet the world’s growing demand for high data rates because it offers the prospect of SoC at a low cost. But, the PA forms the major bottleneck in making SoC because the PAs in high data rate wireless communication systems have the requirement of high-efficiency and good linearity even at backed-off power levels. Currently, PAs are mostly of classes A and B. Both of these are linear, but peak efficiencies are only 50% and 78% respectively. This thesis focuses on implementing Continuous Class F (CCF) PA for WiFi 802.11n over the bandwidth 2.1 - 2.7 GHz, which meets the requirement of high efficiency and good linearity even at backed-off power levels. The CCF PA overcomes Class F’s disadvantage of limited bandwidth as well as maintains peak efficiency of 90.7% over the entire bandwidth. The designed PA has four main blocks: the driver, inter-stage matching, output network, and output stage. The procedure to implement each of these blocks is explained extensively in chapters 3, 4, 5, and 6. The layout of the chip is carried out in TSMC 40 nm, and the chip size is 1.4 mm2. From simulations, the CCF PA has a maximum efficiency of 30 % and EVM of -25 dB at 3 dB back-off across the bandwidth 2.1 -2.7 GHz. The tapeout of the chip is planned in March 2021. Later, the chip can be tested and simulation results will be validated. To the best knowledge of the author, this is the first CCF chip at 2.4 GHz band.","CMOS PA; CCF; Linear; Efficient; Class F; WiFi; Wideband; harmonic analysis; Continuous Class F; 40 nm; 2.4 GHz; Double tuned transformer","en","master thesis","","","","","","","","2022-08-25","","","","Electrical Engineering | Microelectronics","",""
"uuid:06c865ae-78ad-4aa9-acd6-723dd7477cd3","http://resolver.tudelft.nl/uuid:06c865ae-78ad-4aa9-acd6-723dd7477cd3","Dynamic response of a deep-water SRI concept based on experimental data","Tikai, Karan (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Civil Engineering and Geosciences)","Metrikine, A. (mentor); Tsouvalas, A. (mentor); van Dalen, K.N. (graduation committee); Delft University of Technology (degree granting institution)","2020","As the exploration for oil and gas is shifting towards greater water depths, there is a market for subsea rock installation (SRI) at these large water depths as well. Boskalis is a key player in the rock installation market and installing rock material at water depths of approximately 3000 meters is still far from routine work. Therefore, Boskalis is researching accurate and cost-eﬃcient systems for installing rocks in these ultra-deep waters.<br/>Since this is a concept with operations that are not applied before by Boskalis, there are no structural test data available that could be used for research purposes. Therefore, it is decided to perform scaled model tests to obtain reliable production rates of the rock installation process. The basket and its corresponding release mechanisms is built on scale and forces are measured during the release process for diﬀerent conﬁgurations, where the type of release mechanisms and the area of opening were varied. The production rates that followed from these force measurements are used as input parameter in the model that simulates the dynamic response of the envisaged concept.<br/>In order to better understand the force and motion behaviour of this envisaged concept, a simplified one-dimensional cable model has been constructed in Matlab to simulate the dynamic response of the lifting wire and basket, and the force distribution in the lifting wire.","Dynamics; Subsea rock installation; pipeline integrity","en","master thesis","","","","","","","","","","","","","",""
"uuid:721510e7-6393-4b5e-af07-75063ced210c","http://resolver.tudelft.nl/uuid:721510e7-6393-4b5e-af07-75063ced210c","European option pricing under the rough Heston model using the COS method","Erkan, K.E. (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Delft Institute of Applied Mathematics)","Oosterlee, C.W. (mentor); Liu, S. (mentor); Grzelak, L.A. (graduation committee); Fokkink, R.J. (graduation committee); Delft University of Technology (degree granting institution)","2020","This thesis is about pricing European options using a Fourier-based numerical method called the COS method under the rough Heston model. Besides examining the efficiency and accuracy of the COS method for pricing options under the rough Heston model, it is also investigated if the rough Heston model produces the advantages of the so-called rough volatility models. To do so, the characteristic function of the rough Heston model is derived, and the COS method for the rough Heston model and also a Monte Carlo simulation scheme is introduced. Throughout the thesis, the theoretical background of the rough Heston model, the numerical techniques and some numerical experiments on European option prices and implied volatility behaviors are presented. Also, a calibration of the rough Heston model is performed using Artificial Neural Networks. As a result of this thesis, pricing of European options using COS method is succeeded. Moreover, it is shown that the rough Heston model produces the rough volatility behaviors as expected.","Option Pricing; European Options; Rough Heston Model; Rough Volatility; COS method; Artificial Neural Networks; Monte Carlo Simulation; Fractional Brownian Motion","en","master thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:d505d455-0a1f-4e53-b129-8022f00126f9","http://resolver.tudelft.nl/uuid:d505d455-0a1f-4e53-b129-8022f00126f9","Analytical model to assess bending moments in wind turbine support structures subjected to ship collisions","Broersen, A.M. (TU Delft Mechanical, Maritime and Materials Engineering)","Walters, C.L. (mentor); Amdahl, Jørgen (graduation committee); Tidemann, Lasse (graduation committee); Delft University of Technology (degree granting institution); Norwegian University of Science and Technology (NTNU) (degree granting institution)","2020","The number of offshore wind farms is growing rapidly, which increases the likelihood of ship collisions with offshore wind turbines. Additionally, the cost of energy reduction for wind turbines is achieved due to radical design optimizations. Therefore, simple methods should be obtained to determine the offshore wind turbine response during ship impacts in an early stage of wind farm development.<br/><br/>In this research, the response of monopile-supported wind turbines to the impact of a supply vessel is investigated with respect to overturning moments at critical locations; at seabed and tower bottom. The response of the offshore wind turbine is analyzed by modeling a 10 MW wind turbine using the FEM software USFOS. The impact of a 7500-ton supply vessel is represented by a single degree of freedom non-linear spring, of which the force-deformation curve is obtained by using numerical simulations in LS-DYNA. Multiple impact scenarios and two different wall thicknesses at the monopile impact location are considered. Observations from the numerical model are used to develop a method based on analytical equations which can approximate the same maximum overturning moments at seabed and tower bottom during a ship collision. The numerical model is used to verify the analytical model.<br/><br/>Although large bending moments are observed at the tower bottom in the second bend- ing mode directly after impact, the maximum bending moments for both at tower bottom and seabed were found predominantly in the first bending mode. Soil deformation has a significant influence on the permanent displacement of the wind turbine structure. The impact direction relative to the wind direction and the impact speed have significant influ- ence on the maximum overturning moments. The impact force curve is strongly influenced by the second eigenmode with respect to the shape and period. For the analytical model, the force-time curve of the impacting ship is taken as input and has a large influence on the overturning moments. The resulting moments were found to be within a range of 10-40 % of the numerical results, depending on the impact force curve, location, and impact speed.","collision; offshore; wind turbine; Ship collision; monopile; supply vessel; analytical model; numerical model; USFOS; LS-DYNA; bending moments; Support structure","en","master thesis","","","","","","","","","","","","European Wind Energy Masters (EWEM) | Offshore and dredging engineering | Bottom Founded Structures, Arctic and Wind","",""
"uuid:48af5ae0-db00-4ad6-adfc-14f25a8651f3","http://resolver.tudelft.nl/uuid:48af5ae0-db00-4ad6-adfc-14f25a8651f3","The Metropolis-Hastings Method","Gangapersad, Ravish (TU Delft Electrical Engineering, Mathematics and Computer Science)","Kekkonen, H.N. (mentor); Meester, L.E. (mentor); Delft University of Technology (degree granting institution)","2020","In this report, our goal is to find a way to get some information such as the mean out of high dimensional densities. If we want to calculate the mean we need to calculate integrals, which are difficult to do for high dimensional densities. We cannot use the analytical or classical (deterministic) numerical rules for high dimensional problems for which we want to calculate the mean. These methods take a lot of computational time. To solve this problem we introduced the Markov Chain Monte Carlo (MCMC) method, the method samples from the distribution, and with these samples, we can approximate the mean. Then we explain the theory behind these methods and how we can use it. Then we introduced one MCMC method, in particular, the Metropolis-Hastings Algorithm. We explain how this method works and the theory behind it. From this, we see that the method is very easy to implement and can be used to approximate the mean. Then we approximate the mean for some examples using this method.","Metropolis-Hasings algorithm; Markov chains; Markov Chain Monte Carlo","en","bachelor thesis","","","","","","","","","","","","","",""
"uuid:df686357-f5e1-4700-91c5-44560ed8f1ae","http://resolver.tudelft.nl/uuid:df686357-f5e1-4700-91c5-44560ed8f1ae","Aerodynamic analysis of the closure flap mechanism inside the NACA ram-air intake","Leung, K.C. (TU Delft Aerospace Engineering)","Vos, R. (mentor); Delft University of Technology (degree granting institution)","2020","A low-speed aerodynamic analysis on the conventional NACA ram-air inlet of the Airbus A320 with a new closure flap was conducted. The conventional closure flap mechanism inside the NACA ram-air inlet is replaced by a morphing plate design. Steady-state Reynolds-Averaged Navier-Stokes (RANS) based Computational Fluid Dynamics (CFD) simulations were conducted in order to analyse the aerodynamic performance of the baseline model and the new design with morphing flap for a range of operating settings. For validation, the Least Squares version of the Grid Convergence Index was carried out to show the grid independence. The results show an improvement in pressure recovery with a maximum of 13.5% for the NACA ram-air inlet with a morphing flap installed compared to the baseline model with a hinged flap. The maximum drag reduction by replacing the hinged flap with a morphing flap was found to be 33.8%.","NACA ram-air intake; NACA ram-air inlet; submerged inlet; aerodynamic performance; CFD; closure flap; morphing","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:946dbdf6-ea99-4f57-8441-5a012e704d37","http://resolver.tudelft.nl/uuid:946dbdf6-ea99-4f57-8441-5a012e704d37","Experimental and simulation-based investigation of the performance of a 100 % methanol port-injected spark-ignited engine","Bosklopper, J.J. (TU Delft Mechanical, Maritime and Materials Engineering)","Visser, K. (mentor); Roekaerts, D.J.E.M. (mentor); van de Ketterij, RG (graduation committee); Sapra, H.D. (graduation committee); Delft University of Technology (degree granting institution)","2020","The maritime sector faces major challenges with increasing regulations from the International Maritime Organization (IMO) and national regulations for CO2, SOx and NOx. Innovative fuel types for maritime use are now under development by various stakeholders. Methanol shows considerable potential as one of the most promising for implementation in the short to medium term, based on the potential availability, emission reduction, and energy density. The Green maritime methanol (GMM) project is Netherlands based collaboration of important stakeholders such as shipbuilders, engine manufacturers and universities. Within this project, methanol is researched as a potential alternative combustion fuel for maritime vessels. For this purpose, the ”Dutch Caterpillar engine dealer” PON Power provided a G3508A engine available as a retrofit option. The engine is a turbocharged spark-ignited natural gas (NG) engine with 8 cylinders and a rated power of 500 kWe at 1500 rpm. After six months of rebuilding the engine, the spark-ignited (SI), port fuel injected (PFI) engine runs on 100% methanol. Tests with stable engine operation were achieved with 100% methanol at 25%, 50%, and 75% engine loading and a constant engine speed of 1500 rpm.<br/>In this research, experiments and modelling have been performed to study combustion using 100% PFI methanol. Measurements are realized with varying: ignition timings, NOx emission settings, and manifold temperatures. Data collected during these measurements such as in-cylinder pressures, emissions, and temperatures, provided a comparison between running the engine on methanol or natural gas. In this comparison combustion stability is determined with the coefficient of variation (COV) of Pmax and of imep, optimum ignition timing is determined and engine efficiency is calculated and compared to NG. Modelling is accomplished with a TU Delft model of the G3508A SI engine adjusted for the use of 100% methanol as a fuel. A modified sub-model for the PFI and vaporization of methanol has been developed. These engine data will be used to validate the methanol engine model and to optimise the engine performance for further experimental runs and better understanding the use of methanol as a fuel.<br/>The effect on the performance and the combustion when 100% methanol is used as fuel for a SI PFI engine compared to premixed injection of natural gas is shown in this work. The engine operates stably on methanol at 50% and 75% load within ignition timings of 16-24 °CA BTDC, but less stable than with NG. Heat release indicates an almost similar combustion duration, but shorter combustion duration is shown for methanol. Also with methanol, the crank angle where 50% of fuel is burnt (CA50) is shown earlier compared to NG. The faster premixed combustion, combined with a better found fuel consumption operating point, resulted in higher efficiencies for methanol compared to NG for the tested 50% and 75% load at comparable operating conditions.<br","Methanol; Port fuel injected; spark-ignited; Internal combustion engine; experiments; simulation; Natural gas engine","en","master thesis","","","","","","","","","","","","","Green Maritime Methanol Project",""
"uuid:77fa4a98-f647-4840-a5b4-d5ed151ea760","http://resolver.tudelft.nl/uuid:77fa4a98-f647-4840-a5b4-d5ed151ea760","Social contagion as a means to transitions","Shah, J.S. (TU Delft Industrial Design Engineering)","Price, R.A. (mentor); de Koning, J.I.J.C. (graduation committee); Kwakman, Jacco (graduation committee); Delft University of Technology (degree granting institution)","2020","Faced with increased pressure due to the earthquakes in Groningen and global warming, the Netherlands government has decided to discontinue the production of and completely transition away from natural gas by 2050. This requires the transformation of the 95% of houses that are currently heated using natural gas into ones that are heated using greener energy alternatives. To affect the requisite change, the government’s top-down, policy-driven efforts need to be complemented with bottom-up, socially-driven interventions that lead to the institutionalisation and large-scale adoption of the greener energy alternatives. This project aims to stimulate this bottom-up institutionalisation and activate residents towards the energy transition using the phenomena of social influence and social contagion. The focus on social influence and social contagion follows from the extensive literature that highlights the significant role of social norms, social proof, social context and social networks on an individual’s decision-making and attitude formation; as well as in changing behaviours. The project draws on complex contagion theory to activate residents. Reyeroord (a pilot neighbourhood in Rotterdam) is used as a case study to understand the municipality’s efforts and residents’ motivations &amp; apprehensions towards the energy transition; as well as to understand people’s social identities and networks – the building blocks of social influence. Analysis reveals the prevalence of different barriers under the key themes of trust, loss/ risk perceptions, understanding &amp; awareness which lead to procrastination of decision-making amongst residents. Thus, overcoming procrastination by mitigating the underlying apprehensions and barriers forms the key goal for Reyeroord. In order to help the Municipality(s) to overcome these apprehensions using social contagion, the ‘Design for social contagion’ framework and toolkit are developed. The framework provides actionable steps that help in visualising and shaping the contagion of the target behaviour. The toolkit helps in designing interventions within the process outlined in the framework. It consists of a deck of inspiration cards, a set of canvases and a design handbook; to be used during a creative session. The inspiration cards capture the design criteria, design principles and design components that each intervention must fulfill, follow and consist of, respectively. Additionally, the cards include examples of persuasive strategies that can be used to design the interventions. The canvases guide the design process from problem definition, brainstorming, concept generation to detailing. The handbook outlines how to use the toolkit. From the perspective of transitions (transition design), the project, its outcomes and the underlying principle of social contagion provide a new perspective and leverage point to untangle (loosen) the complex knot between the interconnected social, technical, financial and political lock-ins and steer systemic change. On the other hand, it bridges the gap between academia and practice by providing actionable steps to shape contagions, qualitatively.","Energy transition; Transition Design; Systemic design; Toolkit; Framework; Social contagion; Social influence; Built Environment; Behaviour change; Strategic Design; Persuasive Design","en","master thesis","","","","","","","","","","","","","",""
"uuid:36653928-24cd-49b6-a7cf-e2aa1b133115","http://resolver.tudelft.nl/uuid:36653928-24cd-49b6-a7cf-e2aa1b133115","Towards Carfree Cities: Looking for effective and feasible policies for municipalities to convert towards a carfree or low-car city","Floor, Matthias (TU Delft Technology, Policy and Management)","Annema, J.A. (mentor); Veeneman, W.W. (graduation committee); Wegewijs, F.A. (graduation committee); Delft University of Technology (degree granting institution)","2020","Cities are on the rise: Recent years, cities have faced an increase in economic growth, employment rates and population numbers. As a result, the accessibility and liveability of cities is under pressure, mainly due to an increase in the number of cars. One of the possibilities to cope with this problem is to free existing cities from cars, resulting in ‘carfree cities’. However, the effectiveness and feasibility of measures that aim to achieve this, is not always clear. This paper aims to describe the characteristics and desired results of carfree cities and aims to identify effective and feasible policies for municipalities to convert their city into a low-car or carfree city, by answering the question: ""Which government policies have shown or are regarded by experts to be effective and feasible in contributing to the realisation of low-car or carfree cities and what are thereof the implications in achieving carfree cities?"". With use of a literature review, desk research and interviews we found that there is a wide variety of possible policy measures to achieve a low-car of carfree city, however, often without a clear evaluation of their effectiveness and feasibility. Generally spoken, measures concerning ’Price measures and restraining cars’ have a potentially high effectiveness, but low feasibility. There is a lack of clear data about the effectiveness of measures in the group ’Improvement and innovation of collective transport services’, but feasibility is regarded as high. Regarding the group ’Making slow traffic more attractive’, in general, the feasibility of this group is regarded as (very) high, but convincing evidence of the effectiveness is lacking, or shows only a limited effectiveness. Above all, it is advisable to implement measures as a package, in which push and pull measures are combined, good alternatives are offered and the liveability benefits are emphasised.","Carfree; Low-car; Cities; Sustainable mobility; Decision-making","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:ca72bf09-673c-476c-b092-e5745641a98e","http://resolver.tudelft.nl/uuid:ca72bf09-673c-476c-b092-e5745641a98e","The role of power-to-methanol technologies in the energy mix: Investigation of the impact of stimulating power-to-methanol technologies on reliability of the Dutch power grid and CO2 reduction","Afzali, K. (TU Delft Technology, Policy and Management; TU Delft Energy & Industry)","Stougie, L. (mentor); Correlje, A.F. (graduation committee); Dahm, Gertjan (graduation committee); Katakwar, Piyush (graduation committee); Delft University of Technology (degree granting institution)","2020","Power-to-methanol (PtM) technologies have a potential to store excess renewable energy in methanol molecules. However, there is a lack of understanding about the role of these technologies in the course of energy transition. In this research, the influence of PtM technologies on power grid’s reliability and CO2 reduction are studied. An agent-based model is developed in order to explore possible future scenarios created by deployment of PtM technologies, in case green methanol is primarily supplied to the shipping sector as an alternative low-carbon fuel. The model outcomes are explored using two sets of experiments representing two hypothetical cases: ""flexible grid"" experiments in which the power grid is assumed to have several flexibility options, and ""low flexibility"" grid that the grid cannot easily adapt to high levels of renewable power production. The results show that deployment of PtM technologies can help with absorbing excess renewable energy and improving the reliability of the power grid. However, PtM alone is not sufficient to keep the grid reliable. PtM is shown to be successful in enabling high levels of CO2 reduction. The results obtained in this research can be used as the starting point to open up a discussion between system operator and policy makers in order to define a proper support plan for PtM or other Power-to-X (PtX) options.","Power-to-X (PtX); Grid reliability; Electrofuel (E-fuel); Green hydrogen; Renewable power scenario; Green Methanol","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:8a26e95d-bd87-49a1-bb69-ce042869f5d7","http://resolver.tudelft.nl/uuid:8a26e95d-bd87-49a1-bb69-ce042869f5d7","Adapt me for tomorrow: Towards urban resilience and rainwater adaptationin The Hague by 2050 through public space design","He, Binghui (TU Delft Architecture and the Built Environment)","Calabrese, L.M. (mentor); van der Meulen, G.J.M. (mentor); Rizzetto, F. (mentor); Milani, S. (graduation committee); Delft University of Technology (degree granting institution)","2020","The phenomena of climate change interacts with the complexity of urban system, which reflect sptially on the process of urbanization. One of the effects of climate change is an increased flooding hazards, and when floods occur this has a severe impact on human lives and comes with vast economic losses. The city of The Hague aims to achieve the goal of becoming a resilient city in 2050. However, the city is under the threat of extreme precipitation and the challenge of urbanization, which affect the liveability in the city. As an important component of achieving resilience, rainproof adaptation can be transformed as an opportunity. By taking the complexity of the social and enviromental vulnerabilities into the consideration, the project discusses the possibility of linking the water management process with the public space design to develop a conversation of the techinical, spatial and social process. The focus of the graduation project is how precipitation flood management can collaborate with public space design to become an opportunity for achieving urban resilience. Taking the case of The Hague, the Netherlands, the project proposes a re-defination of urban development process through public space design with techinical water management approach.","Urban Resilience; Rainwater flood management; Public space design","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Urbanism","Transitional Territories","52.07667, 4.29861"
"uuid:1f750d55-1471-4d75-a598-d1a2e1ea5f2c","http://resolver.tudelft.nl/uuid:1f750d55-1471-4d75-a598-d1a2e1ea5f2c","Experimental Study on Electromigration by Using Blech Structure","Zhang, Y. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Zhang, G.Q. (mentor); Vollebregt, S. (graduation committee); Cui, Z. (graduation committee); Delft University of Technology (degree granting institution)","2020","In the advanced semiconductor industry, modern electronic devices are expected to realize complex functions with minimized size, which requires an increase in the density of on-chip interconnects. To meet this demand, the dimension of interconnects is reduced and it requires the narrowing of metal interconnects to carry the increasing current density. With such a developing trend, electromigration is one of the significant reliability challenges for electronic devices. Although lots of works focus on the formulation and simulation for electromigration, they are not complete and consistent with experimental results. Recently, A fully-coupled and self-consistent electromigration theory was developed by Cui et al, but new and extensive experimental data and analysis are needed to further validate their theoretical results.<br/>This research work focuses on the experimental study on electromigration (EM), and the aim is to investigate the different effects on EM. The Blech structure was proposed as our experimental structure. The fabrication of Blech structure is conducted at the EKL cleanroom, and main structures with various dimensions are fabricated by employing sputtering technique for deposition and lithography for defining patterns. The measurement is carried out by accelerated tests with high current stress and at elevated temperature. Experimental results are characterized and analyzed by different tools, such as Keyence 3D laser profilometer and scanning electron microscope<br/>With the current density of 1×1010퐴/푚2 and temperature of 250 ℃, the result shows that the critical length under certain conditions is 10 μm, and longer stripes have larger drift lengths and a shorter time to form voids in electromigration. Furthermore, it is found that with elevated temperature, the drift length increases and the electromigration lifetime decreases. In addition, the covered SiN passivation layer only for the annealed Al stripes suppresses electromigration and this is because the annealing process improves the coalescence of grain in Al film, reducing the defects at the grain boundary and finally forming a denser microstructure. The influence of the atmosphere on electromigration indicates that the additional oxide on Al interconnects increases that actual current stress and results in a short electromigration lifetime. In general, present experimental results were consistent with existing results in the literature, but several problems are still unsolved, which will be part of our future work.","electromigration; aluminum; reliability","en","master thesis","","","","","","","","","","","","","",""
"uuid:b1927e92-e9b1-4462-ae2c-865049d5afaf","http://resolver.tudelft.nl/uuid:b1927e92-e9b1-4462-ae2c-865049d5afaf","Palliative terminal care virtual training for inexperienced nurses on emotional and spiritual capability","Ye, Xiaochen (TU Delft Industrial Design Engineering)","Sonneveld, M.H. (mentor); Kroon, C.P.J.M. (graduation committee); Kotey, Harry (graduation committee); Delft University of Technology (degree granting institution)","2020","Over recent decades, the quality of death and dying has received much attention in society. Many patients with terminal cancers or admitted to intensive care/acute units are in need of care for the end of their life (Susan, 2015). With this need rising up, palliative care service is gradually developed mainly as the setting of hospice or home care. However, some patients who are terminally ill are in a situation in need of hospital medical settings to manage their symptoms (Cotogni, 2018). Therefore, in-hospital palliative terminal care becomes important for those patients/families in terms of guaranteeing the quality of life in their last days or hours. Currently, most western hospitals, including Maasstad Hospital, implement palliative terminal care with the integrative model (Metaxa, 2019) which needs general medical professionals, especially nurses, to provide palliative care as a part of routine practice combined with a consultative palliative care team, which is a reported as a challenging work for nurses (Bratianu, 2015) (Johansson, 2011). The project aims to investigate how to support nurses in the Oncology Department of Maasstad Hospital to be able to provide palliative care to patients. Through a series of literature research and interviews from historical (trend), cultural, user and context, and technology aspects to understand and explore the context, the design opportunity, supporting junior nurses with palliative care on-site learning, is unearthed. Insights gained from supplementary research helps the project further define the design goal: to create virtual training of palliative care for inexperienced nurses on emotional and spiritual capabilities, where nurses gradually become mentally prepared to provide palliative terminal care for dying patients and families, to ensure nurses’ mental well-being while being able to provide emotional and spiritual care to patients and families with quality. A VR demo is built for nurses to evaluate the concept. Due to the Covid-19 situation with limited access to nurses, the evaluation result is not quantitative which means further user tests and evaluation need to be considered. The final design is perceived by the nurse as to be promising to provide the inexperienced nurses or even other medical professionals with a safe environment to learn to cope with their own feelings, explore and make mistakes, and be eventually more comfortable and confident to look after dying patients and their family members. However, since the design mainly focuses on the training program structure and the experience journey, more opportunities and details of the interaction design still need to be developed and tested if the application is expected to be launched. The recommendations regarding these details and opportunities are provided as the end of this project.","Palliative terminal care; Virtual Reality; Nurse training; Emotional and spiritual capability","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:bd5b6bbe-d225-487b-8885-139584d731f7","http://resolver.tudelft.nl/uuid:bd5b6bbe-d225-487b-8885-139584d731f7","Mobility as a Service applied in residential areas: Stated Choice experiment in the context of Dutch cities","Damen, Wouter (TU Delft Technology, Policy and Management)","Molin, E.J.E. (mentor); de Vries, G. (mentor); Delft University of Technology (degree granting institution)","2020","This research has the goal to analyse the influence of neighbourhood characteristics on people’s willingness to adopt Mobility as a Service (MaaS) instead of the car for new residential areas. It estimated the influence of a reduced parking comfort, MaaS-hub availability and aditional quality of the overall neighbourhood on the willingness to adopt MaaS instead of the car and the total attractiveness of new residential areas. It used a Stated Choice experiment and survey to estimate a MNL- and ML-model for both one and multiple car households. The results indicate that MaaS adoption rates are limited. MaaS only seems a niche market for people with multiple cars and as neighbourhoods with a larger hub at the border near public transport facilities combined with multiple small scale neighbourhood hubs with only shared cars and bikes.","Mobility as a Service; Parking comfort; Stated Choice","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:5d8d46ea-6353-476b-9260-72bd07d455eb","http://resolver.tudelft.nl/uuid:5d8d46ea-6353-476b-9260-72bd07d455eb","Applying Human-Centered Design in the development of digital products for disaster response","Jager, R.J. (TU Delft Industrial Design Engineering)","Diehl, J.C. (mentor); Comes, M. (mentor); Canavan, Orla (mentor); Delft University of Technology (degree granting institution)","2020","The context of disaster response is incredibly complex due to its chaotic nature and the large number of variabilities per disaster. This complexity makes it difficult for developers of digital tools for disaster response to understand the context of the products they develop. However, a lack of understanding of the use context can result in the development of ill-suited products that do not fulfill the user needs. Human-Centered Design (HCD) is a method to generate a better understanding of the user and the use context through the perspective of the user. It is an approach that is rooted in the belief that the people who face the problems are the starting point when developing a solution.<br/><br/>510 is a Netherlands Red Cross initiative that develops accessible digital tools for humanitarian response across the world. 510 products, which can be databases, models or software tools, are developed for different types of disasters in different countries across the world. In order to ensure that the products are solving user needs and in order to ensure that the products are suited for the context in which they will be employed, 510 aims to incorporate a Human-Centered Design (HCD) approach to their product development. However, the HCD methods are not yet structurally employed across all projects.<br/><br/>The aim of this thesis is to understand how Human-Centered Design can be applied in the development of data and digital tools for humanitarian response. In order to achieve this, the reseach aims to (1) understand the factors that enable and hinder the implementation of HCD, to (2) translate these into required elements for HCD implementation, to (3) understand the needs for HCD in the development of response technology and to (4) make a proposal for the implementation of a human-centered product development process for 510.<br/><br/>The case study presents several insights in the implementation of HCD for digital tools for disaster response within humanitarian organizations like the Netherlands Red Cross. Three lessons about implementing HCD are: HCD is already done in many ways, HCD covers all aspects of the organization and should be implemented by everyone in the organization. Three elements for successful implementation of HCD are found to include: a clearly defined role and scope for HCD activities, an embedded workflow that complements existing product development and a communication plan that guides HCD throughout the organization and promotes participation and transparency. Identified suitable roles for HCD in the development of response technology are: supporting the formulation of human-centered project goals, generating an understanding of the user and their direct context and the design of usable and suitable products.<br","Human-Centered Design; Digital Tools; Humantarian Response","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:d9ecc6f2-19ab-4dc4-b3b4-513c7285677d","http://resolver.tudelft.nl/uuid:d9ecc6f2-19ab-4dc4-b3b4-513c7285677d","The Effect of Temporal Supervision on the Prediction of Self-reported Emotion from Behavioural Features","Rietveld, T.M. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Hung, H.S. (mentor); Oertel Genannt Bierbach, C.R.M.M. (graduation committee); Hildebrandt, K.A. (graduation committee); Dudzik, B.J.W. (graduation committee); Gudi, A.A. (graduation committee); Delft University of Technology (degree granting institution)","2020","Continuous affective self-reports are intrusive and expensive to acquire, forcing researchers to use alternative labels for the construction of their predictive models. The most predominantly used labels in literature are continuous perceived affective labels obtained using external annotators. However an increasing body of research indicates that the relation between expressed emotion and experienced emotion might not be as apparent as previously assumed. Retrospective self-reports provided by participants do capture experienced emotion, but models applied on these labels suffer from the lack of continuous annotations during training. In this work, we aim to answer whether this lack of temporal information can be remedied by using continuous external annotations as proxies for experienced emotion over time. Furthermore, we investigate whether weakly-supervised models can generate accurate continuous annotations to reduce the annotation burden for large datasets. Our results indicate that external annotation sequences bear little significant information for the prediction of self-reports. However, forcing models to reflect changes in external annotations by training models in a multitask fashion improves model performance, suggesting that such temporal supervision helps models to distinguish relevant segments in input data. Besides this, we find that weakly-supervised models can to a certain extent capture changes over time, but in general yield poor results compared to fully-supervised models.","Affective Computing; Emotion Classification; Self-reports; Machine Learning; Weakly Supervised Learning","en","master thesis","","","","","","","","","","","","","",""
"uuid:948769c8-49e5-4175-9990-76b3235f7a25","http://resolver.tudelft.nl/uuid:948769c8-49e5-4175-9990-76b3235f7a25","The Lamperti Transform: Applications to Stochastic Local Volatility Models","de Boer, S.G. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Oosterlee, C.W. (mentor); Kurowicka, D. (mentor); Grzelak, L.A. (mentor); Chebolu, P. (mentor); Delft University of Technology (degree granting institution)","2020","This thesis showcases a rather contemporary method of solving a generalized system of stochastic differential equations (SDE's) comparable to the SABR model. The solution is derived from a stochastic-local volatility (SLV) model in which the local volatility (LV) component is kept general. This generality is maintained throughout all derivations, eventually yielding a model containing an undefined LV function. This function can then be specified however the user of the model deems suitable, as long as minor constraints are satisfied. Obviously, this is a very valuable quality of the model as it is highly customizable. The solution consists of a set of pricing functions that seemingly possess all the aforementioned desirable properties, i.e. fast in evaluation, computational tractability, flexibility etc., with little disadvantages. The generalized SLV model that is used is typically denoted in the form of two SDE's, though in the majority of this thesis an atypical three SDE form is used. This extended system is used to isolate the LV component, in turn enabling for appropriate application of an SDE transformation called the Lamperti transform, which will provide the key to solving the entire system. The Lamperti transform is a highly versatile method for transforming SDE's into new equations typically more suitable for simulation and parameter estimation procedures, and its inner-workings and various applications will be the main focus of this thesis.","Stochastic Differential Equations; Volatility; SABR model; Financial model; Option Pricing","en","master thesis","","","","","","","","2021-02-24","","","","Applied Mathematics | Financial Engineering","",""
"uuid:4e40d8a2-c0cc-44ce-940d-f11d724155dc","http://resolver.tudelft.nl/uuid:4e40d8a2-c0cc-44ce-940d-f11d724155dc","Synthesis of Inherently Moment Balanced Robotic Manipulators","Becht, Gijs (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Precision and Microsystems Engineering)","van der Wijk, V. (mentor); Herder, J.L. (graduation committee); Schwab, A.L. (graduation committee); Delft University of Technology (degree granting institution)","2020","In robotics, machine elements are accelerated in order for the machine to perform certain tasks, such as picking and placing objects. These accelerations result in inertia forces and inertia torques on the machine elements and on the base of the machine. These reaction forces and reaction torques on the base are called shaking forces and shaking moments. Shaking forces and shaking moments result in noise, vibration, wear and fatigue problems. Dynamic balancing eliminates shaking forces and shaking moments on the base, which results in low cycle times and high accuracy. However, the process of balancing a mechanism generally increases the masses, the moments of inertia, and the complexity of the mechanism.<br/><br/>The method of inherent dynamic balance aims at minimizing these drawbacks by considering the balancing prior to the kinematic synthesis. With the method of principal vectors, a large number of inherently shaking force balanced mechanisms has been found. However, the options for shaking moment balanced mechanisms are still limited. <br/><br/>In this thesis, an overview of current dynamic balancing methods is presented, along with a new method for the synthesis of inherently moment balanced mechanisms. This new method is used for the synthesis of inherently dynamically balanced 1-DoF pantographic linkages, where the desired motion of the end-effector is selected by the designer. This motion is defined as a set of precision positions. For this new method, the known method for RR chain synthesis from Burmester’s theory is combined with the shaking moment balancing condition. For the special case where the relationship between link angular velocities is linear, the shaking moment balancing condition is substituted into the RR chain design equation. For the general case where the relation between link angular velocities is non-linear, the equation of motion is numerically solved for a range of possible solutions in order to find the solution which reproduces the desired motion.<br","dynamic balance; shaking force balancing; shaking moment balancing; Kinematic Synthesis; Pantograph; motion generator","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Mechatronic System Design (MSD)","",""
"uuid:88eb3516-79c4-42b3-87aa-beb3436b9277","http://resolver.tudelft.nl/uuid:88eb3516-79c4-42b3-87aa-beb3436b9277","Advances in Graph Signal Processing: Fast graph construction &amp; Node-adaptive graph signal reconstruction","Yang, Maosheng (TU Delft Electrical Engineering, Mathematics and Computer Science)","Leus, G.J.T. (mentor); Isufi, E. (mentor); Delft University of Technology (degree granting institution)","2020","This thesis consists of two parts in both data science and signal processing over graphs. In the first part of this thesis, we aim to solve the problem of graph construction in big data scenario, which is critical for practical tasks, like collaborative filtering in recommender systems, spectral embedding or clustering in learning algorithms. We achieve to accelerate the data-driven graph construction algorithms by relying on an approximation technique for large matrix multiplication, diamond sampling. We show its potential in real problems by extensive experiments. In the second part, we improve the performance of the graph signal reconstructions by exploiting the local properties of graph signals. We propose a node-adaptive regularization with an improved degree of freedom, so a more general signal smoothness assumption is allowed. Different regularization weights design methods are proposed to achieve its best performance. By comparing it with Tikhonov regularization, we observe its superiority in graph signal reconstruction and interpolation, also in graph signal sampling.","Graph construction; Diamond sampling; Graph signal processing; Graph signal reconstruction","en","master thesis","","","","","","","","","","","","Electrical Engineering | Telecommunications and Sensing Systems","",""
"uuid:24f0c6d9-c798-40d2-9db8-f35c90e9824b","http://resolver.tudelft.nl/uuid:24f0c6d9-c798-40d2-9db8-f35c90e9824b","Citizen preferences regarding municipal solid waste re-use measures: A stated choice experiment to analyze the preferences of the citizens living in the municipalities served by Meerlanden regarding the re-use of municipal solid waste","Rusman, Esmee (TU Delft Technology, Policy and Management; TU Delft Engineering, Systems and Services)","Molin, E.J.E. (mentor); Krabbenborg, L.D.M. (mentor); Pesch, U. (mentor); Annema, J.A. (mentor); Notenboom, Diederik (mentor); Delft University of Technology (degree granting institution)","2020","Worldwide, material consumption has expanded rapidly. The Netherlands has become wealthier, citizens can afford more products and therefore the amount of municipal solid waste (MSW) increased enormously. The distribution of MSW is associated with environmental problems and health risks. MSW consists of everyday items disposed by households, such as furniture, clothing, electronics, food and product packaging. A large share of these products are not only suited for recycling but could also be re-used. The step from recycling towards re-use is desired as re-use is more sustainable and effective in reducing the associated (environmental) problems and risks than recycling. However, current local waste management systems are not equipped for re-use. Facilities to handle re-use already exist. The main problem is, that the MSW products are in most cases not ending up at these facilities because the current local waste management systems are designed to stimulate recycling instead of re-use. Re-use is solely in the hands of the citizens themselves. There is insufficient knowledge of what kind of re-use policies are preferred by different citizens. The policy-makers do not know about the trade-offs citizens make regarding re-use. Therefore, this research aims to find what the preferences of the citizens are regarding re-use measures of MSW, and if these preferences are heterogeneous among the citizens or not. <br/>The results of the research showed that citizens were willing to change from the current system towards re-use of MSW. In 80% of the choice situations, a re-use measure was chosen over the base alternative (current situation). This is a positive result as re-use can diminish waste levels and indirectly the negative effects associated with waste. Citizens preferred the “Platform” and “Bringing to the waste disposal centre” alternative the most and preferred these two measures more than the base alternative (current situation). The preferences were related to multiple citizen characteristics such as age, ability to bring (small and big) products to the waste disposal centre, and having a divers’ license <br","Re-use; stated choice experiment; Stated Preference; municipal solid waste","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:a73d49b0-eba4-4377-afae-41a579368486","http://resolver.tudelft.nl/uuid:a73d49b0-eba4-4377-afae-41a579368486","Factors influencing the success within multi-mode standardization for selecting the Vehicle-to-Grid (V2G) charging standards","Fulari, Sameer (TU Delft Technology, Policy and Management)","van de Kaa, G. (mentor); Stikkelman, R.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","The transportation sector is considered to be one of the significant contributors of carbon emissions around the world. With the rise in carbon emissions, electric vehicles are increasingly becoming popular globally. Most of the developed countries are moving towards the electrification of the transportation sector at a faster pace. Although the concept of electrification is novel and environmentally friendly, the electricity demand is predicted to rise exponentially in the next decade. Concerning this demand, Vehicle-to-grid (V2G) technology is considered to be one of the best solutions by experts to incorporate future electricity demand. Even though the technology was introduced in the late 20th century, it is yet to be commercialized for public use on a large scale. There are various pilot projects under development around the world, especially in the European continent. A few private clients in Denmark have already commercialized the technology for private usage, but certainly, it is not available for the general public. Hence, Europe was considered to be an ideal choice for geographical focus. The most important barrier to the adoption of V2G technology is related to the adoption of electric vehicles (EVs) in the market. While the demand for EVs is gradually increasing, the large scale adoption of V2G technology will eventually grow. The charging equipment that is used to charge the electric cars at the charging stations is another critical barrier. Three different standards are competing against each other to dominate the market (i.e., CHAdeMO, CCS Combo, and Tesla). Most of the charging stations in Europe consists of either or all the three types of charging equipment. A few private charging infrastructure companies have also established charging stations locally or nationally in Europe. As there is an equal distribution of CHAdeMO and CCS Combo charging stations around Europe, standardization of the charging equipment could become a necessity for the implementation of V2G technology in the future.<br/><br/>According to the literature, there are three different modes of standardization processes, namely: committee-based, market-based, and government-based standardization. Based on the involvement of various actors in the standardization processes, the concept of multi-mode standardization was introduced in the literature. The case of charging standards related to V2G technology involves actors from various domains indicating the potential case of multi-mode standardization. While the three charging standards are still in the early phases of the battle, it is imperative to analyze the factors that could influence the standardization of charging standards. Hence, the main research question for this research was framed: ""What are the factors that influence the success of charging standards in the context of multi-mode standardization in the European market for the implementation of V2G technology?"". The factors influencing success within the case of multi-mode standardization were recently introduced into the literature. A thorough literature review was carried out to identify a total of 39 influential factors within various case studies of multi-mode standardization. And it resulted in the proposition of a new framework for further analysis in this research. With the combination of a literature review and interview with the experts, 35 factors were found to be relevant. Further, a Multi-criteria Decision Making (MCDM) tool known as the ‘Best Worst Method (BWM)’ approach was used to rank the factors based on expert’s preferences. A total of seven interviews were conducted to allocate weights for each factor using the BWM approach to rank the factors. The experts belonged to academic as well as industrial backgrounds. The results of the analysis showed that the factors ‘brand reputation and credibility’, ‘compatibility’, ‘financial strength’, ‘bandwagon effect’, and ‘lobbying’ ended up being the top five influential factors in this research. While there were two groups of interviewees, a set of two different statistical tests were performed to analyze the significant differences between the results obtained from the two groups of experts. The weight of the factor ‘delay in the standardization process’ was found to be significantly different among the two groups. Hence, this factor was not considered for listing the influential factors.<br/><br/>Compared to the previous framework in the literature, a set of ten factors were added to the framework constructed during this research. The new factors were found to be indeed relevant in the standardization of charging standards. It was also observed for the first time in the BWM literature that a total of 35 factors were found to be relevant. Researchers can use the new framework for analyzing the factors influencing standards battle in different domains. Also, the BWM approach was used for the first time to identify success factors in the selection of charging standards for the implementation of V2G technology. Additionally, the articles that discussed success factors previously in literature from the market perspective were re-analyzed to explore the concept of multi-mode standardization for the first time. Out of ten reviewed articles, eight articles were recategorized to a relevant combination of multi-mode standardization. Moreover, empirical evidence was found for the factors that were considered to be relevant in the third phase of technology dominance. Additionally, it was also found for the first time that a few factors believed to be crucial in the fourth phase of technology dominance were found to be essential already in the third phase of standards battle between charging standards. The statistical analysis tests used in this research can also be used where there are more than two experts involved in the application of the BWM. Finally, the results obtained in this research provide empirical evidence to assign weights to the relevant factors and analyze the importance of those weights to explain their influence in the standardization using the BWM approach.<br/><br/>From a managerial point of view, a few practical contributions were also made during this research. The technology managers can use the proposed framework for the selection of charging standards globally in the future. The combination of the proposed framework and the BWM approach can be used to analyze technologies within similar domains in a situation of multi-mode standardization. The identified factors in the framework can be used to define strategies by the technological managers in the market to gain an edge over competitors in the market. Furthermore, the newly introduced factors in the proposed framework influence the members of the committees and help them to arrive at a consensus in standard development organizations. These factors can not only be validated by the technology managers but also by the committee members representing other aspects in the process of technology standardization. The proposed framework can be modified by the addition of new factors based on the relevance in the technology battle. With the increasing number of startups in the market, the framework can act as a guidance tool for entrepreneurs to analyze, validate and evaluate various factors that could influence the standardization of their product in the market.","Standards battles; Vehicle-to-Grid; Multi-mode standardization; Best Worst Method; Success factors; EV Charging standards; CHAdeMO; CCS Combo; Tesla Supercharger; Phases of technology dominance; V2G; Mann-Whitney U test; Independent sample T test","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:5119b0dc-7d0b-433d-b43d-7007b12609c3","http://resolver.tudelft.nl/uuid:5119b0dc-7d0b-433d-b43d-7007b12609c3","A Vision-based Semi-autonomous Impedance Control Method in Teleoperation","Huang, Yu-Chih (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Cognitive Robotics)","Peternel, L. (mentor); Abbink, D.A. (mentor); Kober, J. (graduation committee); Roozing, Wesley (graduation committee); Delft University of Technology (degree granting institution)","2020","Teleoperation of a robot is often necessary when the remote site is not safe for humans. Moreover, to interact with dynamic environments safely, a teleoperation method called teleimpedance, which allows the human operator to control the impedance of the robot, is used. The main drawback of this method is that the human workload may increase. This could be tackled by using autonomous impedance controllers to relieve the human operator from this added workload. However, most of the existing autonomous impedance controllers require physical contact before adjusting to unexpected environmental changes. This study presents a novel semi-autonomous impedance control method that includes a vision-based autonomous impedance controller and a voice-based impedance control interface. The first element allows the robot to adjust to the environment before contact, whereas the second element allows the human operator to interact with the impedance controller when the vision-based autonomy is performing poorly or not sufficient under the environment. The method has four modalities: (i) Perturbation rejection mode, (ii) Object property detection mode, (iii) Verbal confirmation mode, (iv) Voice control mode. To provide a proof-of-concept of the proposed method, experiments were performed on a teleoperation setup that uses a Force Dimension Sigma.7 as the slave robot, a computer mouse as the master device, and a camera device. The proposed method was analyzed with a position tracking task and contact establishing task, where changing impedance can be crucial and beneficial.","Impedance control; Teleoperation; Vision-based Control; semi-autonomous","en","master thesis","","","","","","","","2021-08-24","","","","Mechanical Engineering | BioMechanical Design","",""
"uuid:9e807a27-1f61-4337-96e9-c5eb62baeabd","http://resolver.tudelft.nl/uuid:9e807a27-1f61-4337-96e9-c5eb62baeabd","Where do all the idIoTs come from?: Identification of Insecurely Developed IoT devices and a corresponding analysis of Dutch digital markets that sell them","Vetrivel, Swaathi (TU Delft Technology, Policy and Management)","van Eeten, M.J.G. (mentor); Hernandez Ganan, C. (mentor); Storm, S.T.H. (mentor); Turcios Rodriguez, E.R. (graduation committee); Delft University of Technology (degree granting institution)","2020","","","en","master thesis","","","","","","","","2021-09-01","","","","Management of Technology (MoT)","",""
"uuid:4f939347-5374-4cbf-a32b-b122139bd3ec","http://resolver.tudelft.nl/uuid:4f939347-5374-4cbf-a32b-b122139bd3ec","Acceleration Magnification for Visualising Blood Flow Pulsation in the Skin","Verzijl, Matthijs (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Intelligent Systems)","Lelieveldt, B.P.F. (mentor); Dijkstra, J. (graduation committee); van der Vorst, J.R. (graduation committee); Vos, F.M. (graduation committee); Pintea, S. (graduation committee); Delft University of Technology (degree granting institution)","2020","While millions of people world wide suffer from arterial diseases, such as peripheral arterial disease, there are a limited number of methods that can be used to diagnose and track these diseases which are also easy, quick and non-invasive. <br/><br/>This work focuses on what is needed to improve diagnosing and tracking of peripheral arterial disease (PAD) using visualisation techniques. Visualising the blood flow pulsation in the skin can be useful in cases of arterial diseases, as the diseases can influence the blood flow by obstructions and arterial stiffness. The main objective in the visualisation is to show the acceleration of the blood flow, as this is linked to the arterial stiffness.<br/><br/>The proposed algorithm for visualising the acceleration of the blood flow is comprised of multiple steps, including techniques such as motion reduction, Eulerian video magnification, remote photoplethysmography signal extraction and using the second derivative. The input of this algorithm are videos of the skin of patients, this makes this method easy and non-invasive. <br/><br/>Photoplethysmography (PPG) signals are present in videos of skin, but can not be seen with the naked eye. Using Eulerian video magnification the PPG signals are amplified for better processing and visibility. By combining groups of pixels into small patches, a decrease in processing time is achieved and it adds a filtering effect. The size of the patches controls the resolution of the visualisation. Movement from the camera or patient is detrimental when extracting the PPG signal from the video. To counteract the motion in the videos a motion reduction step, using optical flow, is applied. Using the Plane-orthogonal-to-skin (POS) algorithm, the signal extracted from videos is converted to a PPG signal. Calculating the second derivative of the PPG signal gives the acceleration of the signal. By splitting the acceleration signal into positive and negative numbers, the acceleration and deceleration of the blood flow is visualised.<br/><br/>Synthetic videos simulating the skin were generated in various levels of accuracy to aid the development of the algorithm and to conduct experiments. The levels range from a simple pulsating square to a moving PPG signal over a blood vessel like structure. In addition, real videos of patients were used.<br/><br/>The experiments show the feasibility of visualising the acceleration of the blood flow pulsation in the skin, but also highlights areas of improvements and future research. More fine-tuning of the algorithm is needed, in addition to acquiring more videos of patients with PAD before and after surgery in a controlled environment.<br/><br/>A working proof of concept of the algorithm is shown. It has the potential of being a novel method of diagnosing and tracking arterial diseases.","acceleration; video; magnification; blood flow; skin; second derivate; peripheral arterial disease; visualisation; pulsation","en","master thesis","","","","","","","","2021-09-24","","","","","",""
"uuid:d01d9654-6279-4951-b87c-7ced21f44373","http://resolver.tudelft.nl/uuid:d01d9654-6279-4951-b87c-7ced21f44373","Design of a blockchain-based platform to support the availability of Entry Summary Declarations to European Customs","di Benedetto, Matteo (TU Delft Technology, Policy and Management)","Ubacht, J. (mentor); Tan, Y. (graduation committee); Maknoon, M.Y. (graduation committee); Rukanova, B.D. (graduation committee); Hofman, Wout (graduation committee); Delft University of Technology (degree granting institution)","2020","To ensure safety and security of imported goods, customs authorities perform risk assessment on incoming goods. European customs use declaration data provided by traders to execute risk analysis. Lacking availability of this data to customs authorities currently hinders proper risk management and poses threats for the European socio-economy. To solve this issue, this research analysed how Blockchain, an emerging and promising technology, could solve the issue at hand. Using a design-oriented approach, the process to be supported was analysed, the requirements were elicited, and the core blockchain components were identified. This was instrumental to develop a blockchain-based platform to support the availability of declarations data to customs authorities. The feasibility of the designed platform was evaluated through a comparison with TradeLens, an existing supply chain platform underpinned by blockchain technology, and possible implementation issues were identified by using a blockchain governance framework. The platform design contributes to the import control system implementation and research on blockchain technology. The next step is the development of a Proof-of-concept to analyse whether the designed platform supports the process at stake.","Blockchain; Governance; Design-Oriented Research; Import Control System; Customs Risk Assessment; Customs Autorithy; Global Trade; Entry Summary Declaration","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:3dc6b272-f319-4511-9a68-673a3543c0ce","http://resolver.tudelft.nl/uuid:3dc6b272-f319-4511-9a68-673a3543c0ce","Design for an automated system for research on genetic diseases: System Concept development for the automation of iPSC culture","Rikalo, N. (TU Delft Industrial Design Engineering)","Goossens, R.H.M. (mentor); Bozzon, A. (mentor); Delft University of Technology (degree granting institution)","2020","Human induced pluripotent stem cells (hiPSCs) offer the possibility to model human disease and study their behavior. They help scientists discover early disease-causing events in cells and are therefore used in discoveries about premature aging, congenital heart disease, cancer, and disorders connected to fetal development. Because of their characteristics, pluripotent cells can be employed to create any cell of the body and since they are derived by patient cells, potentially they can be manipulated to manufacture healthy cells for transplants. At present, the generation of iPSCs is very labor-intensive, requiring daily monitoring and handling of iPSCs. Researches have to be trained in every detail of the process, constantly monitor and bring further the development of the cells. This is a limiting factor for the generation of a high number of iPS lines and human handling can also include variables of imprecision that can make the process last longer. Automation is the solution adopted to overcome these struggles and increase production throughput. Existing automated models are expensive and rigid systems that require additional expenses in order to satisfy the change of needs of an IPSC producing facility. At the moment there are a limited number of systems for the automated production of IPSC cell lines. However, these robots are not able to readapt to changes of the process, or of the spaces where they are installed and do not follow exactly the process needs of every facility. In order to satisfy these needs, starting from the analysis of the processes used at the IPS Core Facility at Erasmus MC, the RXF system was developed. The system design objective has been reached by combining several fronts of investigation. On one side, the process of production has been initially investigated in order to identify functional needs. The results of this analysis have been merged with observations of the daily activities and work organization of the laboratory, which contributed to the understanding of the human factors necessary within biological production. An extensive comparative analysis of other automated systems has been conducted in order to identify the system structure that comes closest to the needs of the IPS Core Facility production necessities. Further analysis and realignment have been conducted on the final components to be embedded. On the other side, ideation sessions, and considerations on modularity, management of throughput and composition lead to the development of system architecture concepts. The combination of these two research sides and synthesis of the strengths of four initial concepts lead to one final proposition for the architecture layout of the automated system for IPSC production: the RXF. This is a system composed of three modules, each of which is used during one section of the overall IPSC production process, giving possibilities of repurposing the remaining modules for other processes.","System Design; Automation; IPSC culture; ipsc","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:aa4c6431-6880-406c-8429-af5b04bc3b05","http://resolver.tudelft.nl/uuid:aa4c6431-6880-406c-8429-af5b04bc3b05","Deepfake Image detection using Anchored Pairwise Learning Approach","Sudharsan, S. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Tax, D.M.J. (mentor); Hung, H.S. (graduation committee); Gadiraju, U.K. (graduation committee); Delft University of Technology (degree granting institution)","2020","Deep learning has enabled technologies that have been perceived complex or impossible a few years ago. Deep learning models can be used to solve several complex problem statements thereby making it a prominent field of research. With the advancements of Deep learning models, their application in domains have diversified. One prominent use-case is the generation of synthetic images or videos targeting unethical media manipulation. This raises concerns on implications caused in the society where there is loss of trust in digital media. The synthetic media generated using Deep learning models are called Deepfakes (portmanteau of ""Deep learning"" and ""fake""). Deepfake generation leverages powerful techniques using Deep learning and Artificial Intelligence (AI) to manipulate or generate visual content with a high potential prospect of deception to human perception. The application of deepfakes is primarily in face images or videos. The use-case of synthetically generated media is a powerful tool to communicate information with false motives to public. However, synthetic media generation of faces is not new with Deep learning. Prior to deepfakes, synthetic face images and videos were generated using photo-editing softwares, primarily in the computer graphics domain. The inclusion of Deep learning methods has only facilitated higher realism of synthetic media with lesser time computation required. <br/><br/>With synthetic media being made easier to generate using Deep learning models, appropriate detection methods should also be deployed. This thesis focuses on detecting deepfakes using Face Recognition Systems. Deepfake detection methods have been proposed and implemented since 2018. However, the fundamental challenge in deepfake detection is the capability of the model to learn discriminatory features between real and deepfake media (owing to high similarity and realism). Furthermore, the availability of real images or videos of target individuals is lesser in comparison with the number of deepfakes available thereby posing a challenge for the detection models to further learn the real vs. deepfake features.<br/><br/>In this thesis, a modification to traditional Siamese Network using Pairwise Learning approach is made called Anchored Pairwise Learning, to learn the similarity between a pair of input faces to address the challenges in deepfake detection with regard to availability of real faces per individuals class. Anchored Pairwise Learning combines two proposed methods called Anchor Siamese Network (ASN) and Anchor Face Detector Network (AFDN) to perform a binary classification of images belonging to real or deepfake class by anchoring one of the test input pairs. The reported best AUC performance of the method on a test set of real and deepfake images is 91.9% and 81% on an independent hold-out set. Additionally, a comparative study between the proposed method and a baseline traditional learning face recognition method is made and their results based on model performances are discussed. Furthermore, the proposed method is evaluated with other state-of-the-art deepfake detection methods from a generalization performance on the reserved independent hold-out set. The results conclude that the Pairwise learning techniques outperform traditional learning techniques in scenarios where the number of real images are lesser compared to the deepfake images.","Deep Learning; Face Recognition; Media Forensics; Deepfake","en","master thesis","","","","","","","","","","","","Computer Science | Data Science and Technology","",""
"uuid:1db63388-3c42-4003-af7b-fe09085e25c3","http://resolver.tudelft.nl/uuid:1db63388-3c42-4003-af7b-fe09085e25c3","Adoption of AI Based Predictive Maintenance Technologies in the Manufacturing Industry: Research to determine and develop the suitable best practices reference checklist to facilitate the adoption of artificial intelligence predictive maintenance technologies","Loorpuu, A. (TU Delft Technology, Policy and Management)","Chappin, E.J.L. (graduation committee); Ding, Aaron (mentor); Oudmans, Jules (mentor); Delft University of Technology (degree granting institution)","2020","Predictive maintenance (PdM) is one of the promising technologies coming along with the fourth industrial revolution being pushed by disruptive technologies like Internet of Things (IoT), Artificial Intelligence (AI), robotics and Augmented and Virtual Reality (AR/VR). Adopting PdM potentially allows companies to reduce equipment downtime, increase the safety of their processes, increase revenue and develop additional business models. Although the promises of the technology are extensive, the successful adoption rate of this technology is still relatively slow. This is stemming from PdM’s multi-disciplinary nature and “hype” that over-promised its ease of implementation. Organizations are now starting to understand what is needed for efficient implementation, and this helps to manage the expectations about this technology. The fundamental problems highlighted in this research are the complexity, unclear vision, lack of knowledge and know-how in adopting AI predictive maintenance technologies inside an organization. According to Bain &amp; Company’s survey companies in the industrial sector indicated that implementing IoT inside their organization proved to be more complicated than anticipated (Schallehn, Schorling, Bowen, &amp; Straehle, 2019). There is a knowledge gap in the scientific literature, where a lack of best practice methods in terms of predictive maintenance implementation can be identified. Based on the problem highlighted and knowledge gap, the main research question was formulated: “How to facilitate the adoption of Artificial Intelligence-based predictive maintenance technology in the manufacturing industry?“. This study follows a phase-wise approach to obtain the research results. In the first phase, a literature study is conducted to identify the current situation about PdM, what information is available about the factors affecting this technology’s adoption and where is the knowledge gap to be filled. Selected factors to focus on with this research are discussed and agreed upon with the researcher and supervisors. In the second phase, the development of the best practices checklist is commenced. The centrepiece of this phase and the research project overall is the set of semi-structured interviews with 11 industry experts with extensive domain knowledge about predictive maintenance to collect best practices in PdM implementation. The insights gathered from the interviews are analysed in-detail in multiple iterations and then that filtered, aggregated information is used to develop the predictive maintenance project reference checklist. In the third phase, expert panel evaluates the practical applicability, generalizability and the validity of the constructed PdM checklist. Efficient implementation of PdM inside the organization could face numerous barriers and difficulties. Most of these barriers related to technologies using big data could be divided into three categories: technical, organizational and people related (S. Li, Peng, &amp; Xing, 2019). Addressing all of these barriers in those 3 major categories would be unwise since that would not provide sufficient depth of analysis for each one of them. Selection of barriers is based on 3 criteria: the barriers must be relevant and applicable to the adoption of the PdM technologies; there should be a noticeable knowledge gap about how to overcome the barriers; the barriers must be complex enough (affecting multiple layers and stakeholders of the organizations) to fit with the Management of Technology multidisciplinary problem-solving perspective. Based on the information from scientific literature and consultancy reports on PdM, 3 relevant barriers to be focused on are chosen: business case building for PdM; trust in AI-based PdM (lack of trust in big data analytical results) and data management for PdM (the challenge of collecting the data, utilizing it and making sense of it). The interviews with the industry experts revealed valuable insights about predictive maintenance adoption, factors affecting the implementation and best practices that other companies have followed during the process of PdM realization. The most notable best practice that all the interviewees mentioned was involving all the relevant stakeholders early on. In addition, taking small steps, maintaining PdM platforms, celebrating small successes, showing a broad picture and providing a range for PdM business case were outlined. Furthermore, key factors that emerged from the conducted interviews influencing PdM adoption are delineated and summarized in this research project. These are useful for both practitioners and academic personnel who have an interest in this domain and want to gain further understanding of the dynamics surrounding predictive maintenance projects. This research project developed best practices reference checklist for predictive maintenance project implementation that supports organizations on high-level in adopting this novel technology by illustrating and bringing awareness to best practices that other organizations have been following during PdM implementation. This reference checklist is constructed to be a holistic, high-level PdM project support tool for the stakeholders proceeding with predictive maintenance implementation for the first time. This means that a detailed analysis of separate nuances is not sought after since that would misalign with the goal of being a wholesome, comprehendible overview of PdM project implementation checklist. Having a clear, structured and holistic perspective allows stakeholders to conveniently follow this checklist commencing and during predictive maintenance projects without being overwhelmed by excessively detailed information. This best practice checklist based on empirical study comprises a five-phase approach where the enablers and barriers in each phase are mentioned and suggestions on how to deal with them are outlined. These 5 phases are as follows: concept, feasibility, data, PdM algorithm development and operation phase. Furthermore, high-level, structured steps in each phase are laid out to support and offer recommendations to organizations with their PdM activities. In the end of each phase, an overview of best practices and barriers is delineated to recapitulate. In the concluding section of this best practices checklist, a compact, five-page adaptation of this reference checklist is devised for a quick overview of this constructed PdM project support medium and it is advisable to resort back to phases in the checklist itself if the more detailed explanation is needed. This compact version is meant for practitioners in the industry who have strict time limitations and wish to receive information quickly in a condensed format. To the best of our knowledge, such kind of high-level compact overview to assess PdM projects was not existing in the scientific literature. This research project directly investigates and provides a best practices checklist to fill this gap. In addition, this research provided design improvement ideas for different stakeholders to incorporate in their processes/products to facilitate better adoption of PdM. Trust factors affecting the implementation process of predictive maintenance are also outlined, helping companies to better communicate with their clients and internal organization about the benefits and usefulness of PdM. The developed research output has been preliminarily validated and evaluated by the expert panel that concluded that this best practice checklist indeed supports organizations in adopting predictive maintenance technologies. Furthermore, it was agreed that the output is clear and understandable with a well-structured approach. Coming from the high-level nature of this research, experts agreed that this research is generalizable to other industries. Main recommendations (for future research) include validating the best practice checklist in practice with multiple organizations inside the industry to correlate usage of this approach and success factor of implementing PdM. Furthermore, the development of additional support tools and frameworks to facilitate efficient implementation of predictive maintenance technologies would yield increased adoption rates of the technology. This research highlighted important factors contributing to the adoption of predictive maintenance technologies from organizational, people and technology perspectives. This helps to create more awareness about what is needed to consider for better adoption of this technology. Furthermore, a high-level structured overview of best practices checklist supporting PdM implementation is contributed to the scientific and practical domain, filling the previously outlined gap in the literature. In addition, coming from the analysed literature, this research complements the scientific literature on the topic of predictive maintenance by providing original content and additional awareness to the overall academic context regarding the dynamics of this technology’s adoption.","Predictive Maintenance; Maintenance; Internet of Things; Technology adoption; Industry 4.0","en","master thesis","","","","","","","","","","","","Management of Technology","",""
"uuid:933acd50-2e12-4ace-84d5-d6e5a1cde2ec","http://resolver.tudelft.nl/uuid:933acd50-2e12-4ace-84d5-d6e5a1cde2ec","Geometry and Reconstruction of Bipartite Quantum Correlations","Bosma, Jan (TU Delft Applied Sciences; TU Delft Electrical Engineering, Mathematics and Computer Science)","de Laat, D. (mentor); Groeblacher, S. (mentor); Heemink, A.W. (graduation committee); Elkouss Coronas, D. (graduation committee); Delft University of Technology (degree granting institution)","2020","The first part of this thesis provides a mathematical description for bipartite quantum correlations, aiming to analyze the geometry of several sets of correlations. We explain why quantum entanglement can be used to simulate shared randomness: C<sub>loc</sub>(Γ) ⊆ C<sub>q</sub><sup>d</sup>(Γ) for a sufficiently large d. The known bound for this dimension d in the literature is d ≥ dim(C<sub>loc</sub>(Γ))+1, but we improve this by showing that the inclusion is always true for d ≥ dim(C<sub>loc</sub>(Γ)). For the proof of this bound, we show that the set C<sub>private</sub>(Γ) of correlations using private randomness is connected, which allows the use of an improved version of Carathéodory’s Theorem. In the second part of this thesis, we define and analyze a see-saw method to determine the state and measurement operators that reconstruct both the correlation itself as its entanglement dimension, by solving consecutive semidefinite programs. One of the strengths of the algorithm is its generality: it applies to different dimensions, question sets, and answer sets. Some numerical experiments demonstrated that the method can indeed reconstruct quantum correlations, although some highly entangled correlations failed to be reconstructed due to the computationallimitations. The numerical experiments motivated several new theorems, for example the fact that every correlation with |A|= 1 or |B|= 1 has entanglement dimension 1, which means that it can be written as a private randomness correlation. The proof of this result is based on the earlier described improvement for the dimension d.","Bipartite Correlations; Quantum Mechanics; Entanglement; Optimization; Semidefinite Optimization; See-saw Algorithm","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics | Applied Physics","",""
"uuid:2a394e73-fa86-4550-8860-c507dbc861c6","http://resolver.tudelft.nl/uuid:2a394e73-fa86-4550-8860-c507dbc861c6","Risks of structural failure of navigation locks due to drought: A probabilistic analysis","van Poelgeest, Remco (TU Delft Civil Engineering and Geosciences)","Jonkman, S.N. (mentor); Voorendt, M.Z. (graduation committee); Korff, M. (graduation committee); Roggeveld, R. (mentor); Delft University of Technology (degree granting institution)","2020","The summer of 2018 was one of the hottest and driest summers since the start of measurements by the Dutch weather service in 1900. This lead to forest fires, problems for farmers and extreme low water levels. The Rhine at Lobith recorded an all-time low water level and also the Ijssel an Meuse rivers recorded extreme low water levels. This caused many problems for everyone using the river water. <br/><br/>In this thesis, it has been investigated what in influence is of extreme low water levels on the strength and stability of navigation locks. This has been done in two phases. First, based on theory and small deterministic calculations, the most relevant failure mechanisms that can occur during drought have been selected. These are: Failure of the doors, piping and degradation of timber elements. Next, a probabilistic approach has been taken to see what the failure probability of a navigation lock is during extreme low water levels. These failure probabilities have been used in a risk analysis to estimate the probability of failure. It has been concluded that the risk of failure due to extreme low water levels is rather low.","Navigation locks; Markov Chains; Fragility curves; Risk Analysis; Drought; Low Water; Structural Failure","en","master thesis","","","","","","","","","","","","Civil Engineering | Hydraulic Engineering","",""
"uuid:885ee74c-4ae1-4a5e-a58f-4e2801a69844","http://resolver.tudelft.nl/uuid:885ee74c-4ae1-4a5e-a58f-4e2801a69844","Uncertainty-based Interactive Machine Learning","Valletta, P. (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Cognitive Robotics; TU Delft Delft Center for Systems and Control)","Kober, J. (mentor); Perez Dattari, R.J. (mentor); Mohajerin Esfahani, P. (graduation committee); Pan, W. (graduation committee); Delft University of Technology (degree granting institution)","2020","Interactive machine learning describes a collection of methodologies in which a human user actively participates in a novice agent’s learning process, through providing corrective or evaluate feedback or demonstrative actions. A primary assumption in these methods is that user input is at worst nearoptimal, however a realistic set of demonstrations will often contain conflicting or poor examples, which degrade the quality of the learnt policies. This project explores methods for the detection of such undesirable features in data and develops an algorithm for policy training with suboptimal demonstrations, while leveraging the generalisation and scalability qualities of artificial neural networks. Uncertainty estimation, which presents a structured approach for the quantification of a network’s confidence in the accuracy of its output, based on the observed training data, is applied for the detection of unwanted features in a demonstration dataset. The particular focus of this project is conflicting data resulting from scenarios with equivalent action choices, such as the obstacle avoidance setting. Following thorough testing on various environments, it is shown that novice policies may be trained to achieve a desired goal in multi-dimensional spaces with either discrete or continuous data, despite the presence of conflicts in this training data.","interactive machine learning; Learning from Demonstrations; Uncertainty Estimation","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:6beec677-42fd-4716-b040-e3be64a1ab49","http://resolver.tudelft.nl/uuid:6beec677-42fd-4716-b040-e3be64a1ab49","Future Hydrogen Town: Designing a PV-Hydrogen-Battery-FC system for atypical neighbourhood in the Netherlands","Atkins, Megan (TU Delft Electrical Engineering, Mathematics and Computer Science)","Smets, A.H.M. (mentor); de Vrijer, T. (graduation committee); Delft University of Technology (degree granting institution)","2020","One of the goals outlined during the Paris Agreement in 2015 aimed at 'holding the increase in global average temperature to well below 2C above pre-industrial levels and pursuing efforts to limit the temperature increase to 1.5C'. In conjunction with this, the Klimaatakkord of the Netherlands aims to 'reduce greenhouse gas emissions in the Netherlands by 49% compared to 1990 levels' To achieve this goal, a rapid decarbonisation of our economy and energy system is needed. Currently, residential usage accounts 20.4% of Dutch energy consumption.. To reach these targets, the integration of renewable energy sources in Dutch households will be a needed.<br/><br/>Solar energy is already one of the most affordable renewable energy sources available and is currently being integrated into newly built households across the Netherlands. However, as the renewable capacity of the Netherlands expands, so will the need for energy storage to meet the mismatch between renewable generation and demand. A battery bank is usually adopted to supply this mismatch on a daily basis and the production and consumption of hydrogen the chosen technology for a seasonal one. Thus, future households and neighbourhoods in the Netherlands must incorporate both in order to maximise self sufficiency from the grid. The high costs of these components make it unsuitable for implementation in a single household, but scaling up to provide for an entire neighbourhood is a more feasible approach. This results in a so called grid-connected hybrid PV-Battery-Electrolyser-FC energy system.<br/><br/>This final thesis project models and optimises a grid-connected hybrid PV-Battery-Electrolyser-FC energy system to asses its feasibility, both economically and technologically, for utilisation on a neighbourhood in the Netherlands. The simulation model of the hybrid energy system is designed TRNSYS. The model is optimised to minimise the levelised cost of eletricity (LCOE) and to maintain a self-sufficiency ratio of 1\% for the hybrid energy system in TRNOPT. Several scenarios are optimised based on the overall system layout and cases dependant on the electrical, heat and mobility demand. The particle swarm optimisation (PSO) and Hooke-Jeeves optimisation algorithms are used for the optimisation process in GenOpt. In addition, a literature study on the learning curves of different components in the hybrid energy system was performed to predict their costs in 2030. The results of this were used to optimise the system as if it were built in 2030.<br/><br/>The simulated hybrid PV-Battery-Electrolyser-FC energy systems are technically feasible for most scenarios and load profiles for a Dutch neighbourhood. The one exception to this is heat load demand with de-centralised PV generation, which saw an energy deficit at the end of the year. The lowest LCOE of 0.749 €/kWh was found for the centralised scenario implementing smart load management in the load demand. It is found that de-centralising the PV-system to the roofs of houses and the battery storage system each increases of the LCOE of the system due to larger installations costs and a different battery technology. The preliminary results of the future scenarios suggest the results will follow the same trends as was seen in 2020. The LCOE reduces by 21% - 28% compared to the LCOE of 2020. However, more research is needed on this topic to draw conclusive results.","Solar; Hydrogen; Battery; Energy transition; Optimisation; Residential; Particle Swarm Optimization; Hooke-Jeeves; Hybrid; Alkaline Electrolyzer; PEM fuel cell","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:481e1d9c-a9b6-4962-bf1e-242731addc1b","http://resolver.tudelft.nl/uuid:481e1d9c-a9b6-4962-bf1e-242731addc1b","On the Use of Low Earth Orbit Satellite Constellations for Offshore Communication","Born, Joppe (TU Delft Aerospace Engineering)","Guo, J. (mentor); Delft University of Technology (degree granting institution)","2020","The marine industry pushes developments that involve down-manning of vessels and the use of autonomous and remote technologies. A fast (real-time) and high capacity data transfer is required, which is currently not feasible using geostationary (GEO) satellites. For this article the performances of four Low Earth Orbit (LEO) satellite constellations (Starlink, Kuiper, Telesat and OneWeb) have been simulated in terms of coverage, round trip time and capacity and are subsequently compared to current and future GEO solutions for marine offshore communication. It turns out that LEO satellite constellations surpass GEO satellites from their second to third deployment phase and provide continuous global coverage, in real time, provided that two remote operation centers are located at opposite sides of the Earth.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:463e85f4-c8fe-4a78-8107-a7d42dad85f5","http://resolver.tudelft.nl/uuid:463e85f4-c8fe-4a78-8107-a7d42dad85f5","Sustainable Personal Mobility: How active modalities and the reduction of mobility can contribute to pro-environmental pratice among commuters","Kuiper, Jelle-Jacob (TU Delft Industrial Design Engineering)","Hiemstra-van Mastrigt, S. (mentor); Jaśkiewicz, T.J. (graduation committee); Spaargaren, C.H. (graduation committee); Delft University of Technology (degree granting institution)","2020","","","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:61d6fefb-d99f-4f9d-aa82-db5b4a6b483d","http://resolver.tudelft.nl/uuid:61d6fefb-d99f-4f9d-aa82-db5b4a6b483d","Quantifying the dispersion of turbidity currents generated by seafloor mining operations","Bedón Vásquez, Andrea (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Offshore and Dredging Engineering)","van Rhee, C. (mentor); Helmons, R.L.J. (mentor); Elerian, M.F.A.I. (mentor); Delft University of Technology (degree granting institution)","2020","Turbidity currents are common in the waters around the world. They can be caused by earthquakes, collapsing slopes or other geological disturbances. However, turbidity currents can also be caused by deep sea mining activities. Deep sea mining is done with special mining vehicles. There are three main operations within this mining vehicle: collecting nodules, separating the nodules from the mixture and discharging the mixture of sediment and water towards the environment. After impingement of the discharged flow with the seabed, it is expected that the flow will take the form of a turbidity current. Turbidity currents belong to a larger class of flows called gravity currents. Furthermore, turbidity currents are typically defined as dilute flows in which particles are dominantly supported by fluid turbulence. These currents have an interstitial fluid that is a liquid, generally water. The objective of this research is to increase knowledge of the behavior of these currents and to obtain experimental results that can be used for validation of CFD models. In this research the influence of the initial concentration on the dispersion, deposition and entrainment of the current is investigated. In addition, the spread of particles within the current is researched. Furthermore, different types of sediment are used with various particle size ranges and particle properties. The experimental methodology can be divided in two parts. The first part are experiments that involve a full-depth lock release of a fixed volume suspension of a sediment with different particle size ranges and particle properties into water. The initial concentration is varied and the obtained current is recorded with a high-speed camera. The second part consists of multiple calibration procedures. During these procedures, different concentrations of sediment are mixed with water and the resulting solution is recorded. This data is used to create a calibration function that in turn can be used to quantify the concentrations of sediment in the previous recorded currents. The experimental methodology differs from previous work due to this calibration procedure. Afterwards, video processing is used to perform an analysis of the current. The resulting turbidity currents go through three phases as observed in the experiments and previous work. At the start, there is an initial phase where the front is formed and the current accelerates. During this phase a limited amount of particles settle out of the current. Afterwards, the current transitions into a second phase when the velocity of the front starts to decrease due to inertial forces and due to the start of particle settling at the rear of the current. The last phase is when the backflowing bore created by the ambient fluid at the release of the gate reaches the front and decelerates the current until viscous forces start to dominate until the current vanishes. The experiments shows that currents transporting fine particles reach higher velocities and may travel for longer distances in comparison to currents composed of larger particles. Furthermore, the combination of fine and large particles has a substantial effect on the currents dynamics. The currents composed of a mixture of these two sediment types travel longer distances than currents with only large particles. The performed experiments also focus on varying the initial concentration and sediment type. These show that larger particles tent to entrain more with the ambient fluid in comparison to smaller particles and thus they have a larger vertical dispersion. Furthermore, currents composed of sediment with only fine particles will have a more rapid transition into a dense front and a less dense middle and rear pat of the current. Currents composed of fine sediment and a combined sediment with small and large particles have a clear division between a dense basal layer and a less dense top layer within the current. At last, deposition patterns are different per sediment type. Sediment composed of larger particles will have a larger deposition rate than sediment composed of smaller particles. Furthermore combining both sediment types will increase the deposition rate at the beginning of the current.","Turbidity currents; Deep sea mining; Particle-laden flow; gravity current; Offshore mining; Sediment; Entrainment","en","master thesis","","","","","","","","2022-08-31","","","","Offshore and Dredging Engineering","",""
"uuid:3d9bcbf8-98be-40c4-947a-4f15e492cb8b","http://resolver.tudelft.nl/uuid:3d9bcbf8-98be-40c4-947a-4f15e492cb8b","Eco-design tools within product development processes of automotive companies and lessons learned from their experience: BMW, Volkswagen and Volvo: a comparative study","Aguirre Pereira, Joseba (TU Delft Technology, Policy and Management)","Korevaar, G. (mentor); Steubing, B.R.P. (mentor); Moncada Botero, J. (mentor); Delft University of Technology (degree granting institution); Universiteit Leiden (degree granting institution)","2020","Over the past years, the scientific community has payed increasing attention to the integration of Eco-design in product development processes. In spite of this, Eco-design practices within mainstream manufacturing companies has proven to be scarce. A great share of the literature has focused on the development and improvement of Eco-design tools from a theoretical perspective. A more practical perspective, including companies’ point of view, allow us to identify bottlenecks or improvement potential only visible for practitioners, such as the compatibility of tools with companies’ current procedures, time and data constraints, or guidance provided by output mechanisms. This thesis reviews a set of Eco-design tools adopted or developed by three automotive companies (BMW AG, VW AG and AB Volvo) with decades of experience in Eco-design. The extensive literature review aims at combining and integrating the observed best practices into a model that offers guidance on how to incorporate Eco-design into product development processes of less experienced companies. The model presents an iterative process comprised of three phases: impact assessment, definition of action, and management and control. The impact assessment phase consists of the analysis of hotspots and the comparison of design alternatives. The results from the impact assessment then lead to the definition of improvement actions. Actions that are agreed through team dialogues among different departments of the company which are selected according to a prioritization process to find the right balance between aspects, such as costs, product functionality, customer preference, current and future policy compliance or corporative image. Once impact results are translated into technical targets, the management and control phase ensures that employees are designated to supervise the implementation of actions, report possible rebound effects and inform about the findings that become the knowledge foundation of future projects. The automotive experience also reveals that LCA represents the cornerstone of the three companies in the integration of Eco-design practices, but it is noteworthy that LCA approaches are recognized to be dependent on other indispensable tools. From the observed experience, the LCA studies are conducted in a form that are too dependent on the product system of preceding versions of the product, which often limits radical innovation and rather results in small incremental improvement. In combination with LCA, systematic team dialogues between different knowledge fields shall contribute to the creation of collective knowledge. An appropriate arena that allows experts to reflect on impact results and explore innovative improvement opportunities, out of the scope of LCA practitioners.","","en","master thesis","","","","","","","","","","","","Industrial Ecology","",""
"uuid:ce520b97-a28b-40be-b831-3a792b9a8173","http://resolver.tudelft.nl/uuid:ce520b97-a28b-40be-b831-3a792b9a8173","Including the Effects of Artificial Light at Night on Moths in Life Cycle Impact Assessment","Slootweg, Mike (TU Delft Technology, Policy and Management)","Cucurachi, S. (mentor); Cieraad, E. (mentor); Delft University of Technology (degree granting institution); Universiteit Leiden (degree granting institution)","2020","The aim of this research is to implement the effects of artificial light at night on moths in a model that functions as an impact category in the life cycle assessment methodology. The model defines the attraction of moths in a specific region of influence. This attraction might result in multiple direct and indirect effects that could lead to the reduction of moth population, due to an increase in mortality. The region of influence is expressed in square meters and is the area where the intensity of streetlight is higher than the intensity of the background light, which includes the moon- and starlight combined with skyglow of a certain region. The first prototype is tested in two districts of Berlin to demonstrate how the method is used in a region and to show the limitations and the different scenarios per intensity class and mounting height of the streetlight. Practitioners should be able to use this model to implement this in life cycle impact assessment. Weather conditions, moon phase, and skyglow are spatially dependent and should therefore be assessed per region. Including the wavelength of the lamp type of the streetlight and including other objects such as vegetation are seen as limitations in this research and could extent this model by doing further research.","Artificial Light; Moths; Life Cycle Impact Assessment; Life Cycle Assessment","en","master thesis","","","","","","","","","","","","Industrial Ecology","",""
"uuid:9d1fb18d-49c3-444a-9839-55b9e95e4c13","http://resolver.tudelft.nl/uuid:9d1fb18d-49c3-444a-9839-55b9e95e4c13","Link Weight Tolerance: A study of betweenness centrality and data transmission in complex networks","Pothirajan, Deeksha (TU Delft Electrical Engineering, Mathematics and Computer Science)","Noldus, R.A.C.J. (mentor); Delft University of Technology (degree granting institution)","2020","Links play a significant role in the functioning of a complex network. The aim of this thesis is to study the links in a weighted network by introducing two new concepts. The link betweenness centrality of a link is defined as the fraction of shortest paths between all pairs of nodes in a graph that traverses that link. Although link betweenness is a widely known measure that characterizes the link, we introduce the concept, link weight tolerance, to understand the extent to which the weight of the link can be increased or decreased such that the shortest paths in the graph are unaffected, therefore the link betweenness of the links remain the same. We develop a method to generate the positive and negative tolerance of a link. We use examples to illustrate the algorithm and discuss the results. Prior to introducing this concept, in addition to surveying existing network theory measures, we also analyse the metric, betweenness centrality and describe the methods used to generate weighted and unweighted random graphs. To extend the concept of link betweenness, we introduce the second concept, link tension. Link tension provides the information related to the ability of the link to handle transmission of data and shows us the links that are important in a network.","weighted networks; Link tolerance; Link tension","en","master thesis","","","","","","","","","","","","Electrical Engineering | Embedded Systems","",""
"uuid:d556d05a-766e-4e3f-847a-44160bd7a3d1","http://resolver.tudelft.nl/uuid:d556d05a-766e-4e3f-847a-44160bd7a3d1","In search of Comammox in oxygen limiting conditions","LU, Mu-En (TU Delft Applied Sciences; TU Delft BT/Environmental Biotechnology)","Kleerebezem, R. (mentor); Stouten, G.R. (mentor); Weissbrodt, D.G. (graduation committee); van Lier, J.B. (graduation committee); Delft University of Technology (degree granting institution)","2020","Comammox bacteria are capable of catalysing the full nitrification pathway – oxidation of ammonium to nitrate – and have been encountered in many ecosystems recently (Lawson &amp; Lücker, 2018). What the ecological role of comammox bacteria is in hypoxic enrichment cultures remains unclear. Based on the thermodynamics and biochemistry of known nitrogen cycle conversion, we propose that comammox is oxidizing ammonium to nitrite with both oxygen and nitrate as electron acceptor in hypoxic condition. Our hypothesis suggests that when comammox cooperates with anammox, they can harvest most energy per unit of oxygen supplied. We tried to cultivate bacteria toward a community of anammox and comammox consortium by limiting the oxygen and supplying ammonium and nitrate. Although the predicted optimal state has not been achieved during this work, we did observe that the community indeed developed towards higher consumption of ammonium under limited oxygen supply.","comammox; anammox; nitrification; denitrification; stoichiometry; thermodynamics","en","master thesis","","","","","","","","","","","","Life Science and Technology (LST)","",""
"uuid:2cf31331-4708-4e8c-831b-105559116e7d","http://resolver.tudelft.nl/uuid:2cf31331-4708-4e8c-831b-105559116e7d","Design of slender steel pedestrian bridges: Applying a moving jogger load model including Human-­Structure Interaction","van de Velde, Tibo (TU Delft Civil Engineering and Geosciences)","van der Meer, F.P. (mentor); Veljkovic, M. (graduation committee); Tsouvalas, A. (graduation committee); Bosman, E. (graduation committee); Delft University of Technology (degree granting institution)","2020","Developments in structural engineering give rise to the ability of increasing the slenderness within the design of footbridges. However, this often results in a fundamental eigenfrequency which coincides with the step frequency range of humans on the bridge. This can lead to uncomfortable vibrations of the structure. In order to maintain the comfortability, the Dutch national annex of the Eurocode prescribes to consider a dynamic jogger load case, which is often governing for the slenderness of a design. In this thesis, a moving model for the dynamic jogger load case with the addition of human­-structure interaction (HSI) in vertical direction is considered in order to reduce conservatism. Using a simplified 1-dimensional Finite Element representation of a footbridge consisting of 4 HEA320 pro­files, a comparison is made between a moving force (MF) and a moving mass­-spring-­dashpot (MSD) model representing the jogger. Different analyses of a single jogger case are made to investigate the influence of the following simplifications: 1) applying a stationary instead of a moving dynamic load, 2) applying a load model neglecting the separation between jogger and bridge and 3) neglecting the subject variability. The Dutch national annex prescribes the use of multiple joggers during the load case. Therefore, an initial research is done on the effect of HSI on a multiple jogger case. It is found that the HSI results in a decrease of the maximum accelerations for all load cases. The effect increases when the joggers-­to-­bridge mass ratio increases. The same holds for the influence of separation. The results show that reduction of the maximum acceleration due to the addition of the HSI is generally not large enough to result in an increase of the maximum slenderness.","Footbridges; Human-Structure Interaction; Dynamics; Vibrations","en","master thesis","","","","","","","","","","","","Civil Engineering | Structural Engineering","",""
"uuid:21cf41be-4749-4d54-bae8-6eda33392270","http://resolver.tudelft.nl/uuid:21cf41be-4749-4d54-bae8-6eda33392270","Integrating data center waste heat into the district heating network in Amsterdam","Hattink, Laura (TU Delft Technology, Policy and Management)","Korevaar, G. (mentor); Correljé, A. (mentor); Chappin, E.J.L. (graduation committee); Delft University of Technology (degree granting institution)","2020","District heating is gaining popularity and can serve as an alternative for the use of natural gas to provide heat to residential areas. District heating systems can make use of heat sources that are often locally distracted and would have otherwise been wasted. Data centers could act as low temperature heat sources by recovering residual heat for district heating purposes. However, integration issues arise on various levels. This research aimed to provide insights into how data center waste heat in Amsterdam can be integrated into the district heating network.<br/><br/>The district heating concept are explained by investigating the technical, economic, environmental, and institutional concepts. District heating markets of the Netherlands, Sweden, and Denmark were compared, based on the type of markets (regulated or deregulated), the pricing structures, the degree of market opening, and the ownership structure. Next, a system engineering approach was developed to find and test opportunities to integrate data center waste heat into the district heating network of Amsterdam. The approach could offer support in the feasibility phase before making development decisions for a district heating network case. The network layered approach that was applied for the case of Amsterdam was used as the starting point for a pilot project in Amsterdam, modeled in the simulation tool EnergyPRO<br/><br/>The investigation into possible integration opportunities has resulted in a two-step approach: Creating a theoretical understanding of the district heating system for a specific case, and also looking into a practical case study by using a simulation tool. The decision-making and waste heat integration will simply not be ready in a day. Still, a clear vision of the functionality and interdependencies of all system components support steps towards successful integration.<br","District heating; Data center waste heat; System engineering; Modeling; Amsterdam; Vattenfall","en","master thesis","","","","","","","","2022-08-10","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:c9f021d4-4ca1-4a52-b5f2-bd72c2fc4b6d","http://resolver.tudelft.nl/uuid:c9f021d4-4ca1-4a52-b5f2-bd72c2fc4b6d","Rotating heat pipe with Dowtherm A for intermediate temperature applications in a heat pipe assisted annealing process: An experimental study on internal heat transfer with attention for the effects of non-condensable gas described by a computational model","Verbeek, Frederik (TU Delft Mechanical, Maritime and Materials Engineering)","de Jong, W. (mentor); Çelik, M. (mentor); Delft University of Technology (degree granting institution)","2020","The production of steel is an energy intensive process, using 20GJ/tonne of steel. The energy use needs to be declined by 10% in 2030 in order to be on track of the Sustainable Development Scenario(SDS). About 1GJ/tonne is required today by the annealing process, a heat treatment in which the steel strip is heated to a temperature of about 600-700<sup>o</sup>C and cooled afterwards. Tata Steel came up with a way of connecting the cooling and heating section in an innovative way, which can potentially reduce the energy requirements of an annealing line by up to 70%. Horizontal rotating heat pipes are proposed to transfer heat efficiently over its axial length from the strip in the cooling section to the strip in the heating section. Dowtherm A has been selected as the working fluid between 150 and 350<sup>o</sup>C. No research is available on rotating heat pipes with Dowtherm A. The aim of this study is to research the relevant internal heat transfer characteristics of a<br/>rotating heat pipe and gain insight into the performance of Dowtherm A as the working fluid in terms of heat transfer efficiency. Furthermore, the aim is to gain knowledge on the effect of non-condensable gas inside a heat pipe and on the way the effects can be modelled in a computationally efficient way. Non-condensable gas is likely to be of influence on heat transfer homogeneity outwards to the relatively cool steel strip. Understanding this influence is another goal of this study. To fulfil the aims of this study, experiments are conducted and a computational model is devised. An experimental setup with working fluid Dowtherm A is used to acquire data at different rotational speeds, operating temperatures and at different thermal inputs and outputs. The rotating heat pipe used is of smaller scale than one in a heat pipe assisted annealing line, but with comparable heat fluxes. Secondly, the devised model is used to both qualitatively and quantitatively study the effect of non-condensable gas for different operating<br/>parameters and non-condensable gas amounts, which is done for conditions as in the experimental setup and as in a heat pipe assisted annealing line. The rotating heat pipe worked successfully during conducted experiments and Dowtherm A has shown to be able to transport at least 280W axially through the inner geometry in the non-annular flow regime, which is 192,000W/m<sup>2</sup> and corresponds to a vapor flow of 0.001kg/s, at an axial temperature difference of only a few degrees Celsius. Nucleate boiling was considered the dominant heat transfer mechanism through the film in the evaporator, with a typical heat transfer coefficient observed of 4200W/m<sup>2</sup>K. The condenser has shown a lower film heat transfer coefficient; 1750W/m<sup>2</sup>K. The effect of rotational speed, power and temperature is minor in the evaporator at conditions tested. The 1D model for determining non-condensable gas distribution showed good agreement with reported experimental data, which show a major axial temperature drop at the condenser end. It was shown that wall conduction influences non-condensable gas distribution for heat pipes with a relatively thick wall, which is modelled by the addition of wall temperature calculations to the 1D model. The effect of non-condensable gas on heat pipe performance showed to be strongly dependent on<br/>operating temperature. Axial convective transport showed to be between two and three orders of magnitude more efficient than pure conduction. Homogeneous heat outflow is achieved when non-condensable gas is not present in the condenser, which can be achieved by extending the heat pipe at the condenser end. The devised model is suitable to predict the effect of operating conditions and design adjustments in an efficient way. Results have shown that Dowtherm A is a suitable working fluid for a heat pipe assisted annealing line, due to the low internal resistances to heat and mass transfer.","Rotating heat pipe; Dowtherm A; Heat transfer; Non-condensable gas","en","master thesis","","","","","","","","2022-08-24","","","","Mechanical Engineering | Sustainable Process & Energy Technology","",""
"uuid:8a04400d-8e96-46f4-a048-769d954674d4","http://resolver.tudelft.nl/uuid:8a04400d-8e96-46f4-a048-769d954674d4","Modeling and Monitoring of a Floating Photovoltaic Pilot System","Stark, Tim (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Photovoltaic Materials and Devices)","Ziar, H. (mentor); Isabella, O. (mentor); Delft University of Technology (degree granting institution)","2020","","Floating Photovoltaics; Floating PV; PV Monitoring; Energy Yield Simulations; PV Inspection","en","master thesis","","","","","","","","2022-08-24","","","","","INNOZOWA",""
"uuid:dd1d11af-1879-462a-a64a-cf61949ca0a2","http://resolver.tudelft.nl/uuid:dd1d11af-1879-462a-a64a-cf61949ca0a2","Extended semi-analytical model of bipolar hybrid stepper motor","Wu, Newman (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft DC systems, Energy conversion & Storage; TU Delft Electrical Sustainable Energy)","Dong, J. (mentor); van Beek, T. (mentor); Lahaye, D.J.P. (graduation committee); Bauer, P. (graduation committee); Delft University of Technology (degree granting institution)","2020","The aim of this graduation thesis is to present a bipolar stepper motor semi-analytical model and compare its simulated motor dynamics. Stepper motor modeling has been successfully used to simulate motor performance and dynamics, yet, each modeling method holds advantages and disadvantages toward one another. In this thesis, the analytical modeling method is implemented for its faster simulation time. A semi-analytical model is constructed with motor non-linear entities on top of the motor analytical equations. <br/><br/>This thesis first examines and validates a finite element analysis model to extract such non-linear entities into lookup tables. A generalized electrical model and a flux-based model are constructed separately based on the analytical equation and lookup table. In a second stage, the motor dynamics from these models are compared and adapted to the semi-analytical model motor dynamics through non-linear parameters. Two methods to obtain the non-linear parameters, with and without motor measurements, are applied. Finally, Various motors with different parameters are simulated with the semi-analytical model. Comparison, accuracy, and limitations of the semi-analytical model is discussed. At the end of the thesis, conclusions are drawn from the simulated dynamics that a semi-analytical model can indeed be implemented to better simulate the motor dynamics; however, because of the estimation and measurements needed for the non-linear parameters, the semi-analytical model holds several limitations that made it less robust than the model with pure analytical equations.","Hybrid stepper motor; semi-analytical model; FEA; Matlab Simulink","en","master thesis","","","","","","","","2022-08-24","","","","Electrical Engineering | Electrical Power Engineering","",""
"uuid:acae9eb8-ff70-4a1c-bbda-685b3f6e4391","http://resolver.tudelft.nl/uuid:acae9eb8-ff70-4a1c-bbda-685b3f6e4391","Integration of manufacturing and structural design of 3D concrete printed bridges","Hoogeveen, Maartje (TU Delft Applied Sciences; TU Delft Civil Engineering and Geosciences)","Hendriks, M.A.N. (mentor); Schipper, H.R. (mentor); van der Ham, H.W.M. (mentor); Bruurs, Marijn (mentor); Delft University of Technology (degree granting institution)","2020","3D concrete printing (3DCP) is a new, innovative construction method in which concrete structures are produced layer-by-layer using a 3D printer. A printed concrete structure, can be self-supporting, which means no formwork is required anymore, increasing the freedom of form, while decreasing construction cost and material use. However, the engineer designing 3DCP structures is challenged, because the construction process is completely different than from designing conventional concrete structures. The fresh concrete structure must be stiff and stable enough to resist the increasing self-weight of the subsequent layers and the material properties can become anisotropic due to a limited bond-strength between two layers. The objective of this research is to integrate the manufacturing process into the structural design of a simply supported 3DCP cyclist bridge, to provide guidelines for designers and for future research. Using a parametric research model, the performance and feasibility of the design can be assessed as a function of 22 parameters describing the bridge geometry, material properties (fresh and hardened) and printing process parameters. The model is built in Grasshopper and Python by using analytical formulations only. The use of FE software is omitted to make the model as fast as possible. Like this, a global sensitivity analysis based on thousands of parameter combinations could be conducted, revealing the most important parameters for determining the design's performance and feasibility, as well as the absolute effect of specific parameters. These results were used in an optimisation run, seeking the most cost-efficient and sustainable design. The research shows that integrating the manufacturing process into the structural design of 3DCP objects yields more optimal designs and the analytical model that has been developed has proven to be a useful tool for research and design.","3D Concrete Printing; Analytical Parametric Model; Global Sensitivity Analysis","en","master thesis","","","","","","","","2022-08-24","","","","Civil Engineering | Structural Engineering","",""
"uuid:00348017-cb95-44ff-9b7b-9bd26f3b424f","http://resolver.tudelft.nl/uuid:00348017-cb95-44ff-9b7b-9bd26f3b424f","Sowing and Harvesting Circular Ideas: An explorative action-oriented study on how to generate and pursue circular ideas for their potential as business models within the civil engineering sector","Lu, Cindy (TU Delft Civil Engineering & Geosciences)","Bakker, H.L.M. (graduation committee); Schraven, D.F.J. (mentor); Konietzko, J.C. (graduation committee); Willems, A. (mentor); Delft University of Technology (degree granting institution)","2020","The civil engineering sector has been said to have potential for profound change when it comes to circularity, as its projects involve very large material flows and have significant impacts on the environment. Nevertheless, its state of the transition is limited which is partially due to the gap between the business model innovation phases ideation and integration. The objective of this research is to provide an approach for organisations in the civil engineering sector to generate circular ideas and test them on the criteria desirability, viability, and feasibility to further develop them into business models. The following research question is defined as a solution for the research gap: How to generate and test circular ideas for their desirability, viability, and feasibility as circular business models for civil engineering services? The methodology designed to answer the research question consists of a literature study to establish the basis for the rest of the research, an ideation workshop to generate and select promising circular ideas, semi-structured interviews to pursue these ideas, an analysis of the results, and finally a design of a framework. The analysis showed that there are organisational and sector-wide motives and deterrents for organisations deciding on whether to further develop a circular idea. The developed framework provides a process with a tool for organisations to further develop a circular idea and test them for their desirability, viability, and feasibility. Eventually establishing a solid thought out idea to be evolved into a business model. The framework is accompanied with a set of recommendations for civil engineering organisations to implement, boosting the pursuit of circular ideas while creating a suitable environment for the transition. The process and framework developed can also be used for innovation in general as they provide tangible and practical steps for them to take their innovative ideas further and to continue developing them into usable business models, without the circular aspect.","","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:90105518-e3f8-4355-b9d3-bf541215e83c","http://resolver.tudelft.nl/uuid:90105518-e3f8-4355-b9d3-bf541215e83c","Predicting helicopter damage caused by a collision with an Unmanned Aerial System using explicit Finite Element Analysis","Jonkheijm, Laurens (TU Delft Aerospace Engineering; TU Delft Aerospace Structures & Computational Mechanics)","Chen, B. (mentor); Schuurman, M.J. (mentor); Kassapoglou, C. (graduation committee); Voskuijl, M. (graduation committee); Delft University of Technology (degree granting institution)","2020","Due to an exponential growth in the number of shipments of Unmanned Aerial Systems (UAS), the amount of these devices operating in the sky has increased remarkably over the last few years. This led to an increasing number of proximity incidents with manned aircraft. Since these devices share certain airspace with rotorcraft, the question arises how much damage a helicopter could sustain after an impact with a UAS. Within this thesis, a risk assessment was completed initially to determine which collision in terms of type of UAS and helicopter impact location poses the highest risk to the operator of the helicopter. Subsequently a validated model of a DJI Phantom III was developed and impacted onto a rotorcraft windshield in explicit Finite Element software. The sustained damage was compared with a simulated bird strike event to determine whether the prevailing certification requirements would suffice to guarantee safety of the crew.","UAS; impact; helicopter; damage","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:68835460-920e-4799-8f44-39d6dbf74d36","http://resolver.tudelft.nl/uuid:68835460-920e-4799-8f44-39d6dbf74d36","Monitoring Groundwater flow with ERT","Van Ballaer, A. (TU Delft Civil Engineering and Geosciences)","Slob, E.C. (mentor); Karaoulis, Marios (mentor); Draganov, D.S. (graduation committee); Wagner, Florian (graduation committee); Delft University of Technology (degree granting institution)","2020","Geophysical monitoring is a popular tool in aquifer characterization and groundwater flow. To address this objective at groundwater extraction site ‘t Klooster, an ERT dataset was analyzed to identify groundwater flow patterns resulting from the injection of warm oxygenated water. Using a petrophysical model, changes in resistivity were converted to estimated temperature changes to visualize the spread of warm oxygenated water. Multi-dimensional analysis of the resistivity response of the subsurface was carried out. This allowed for the division of the subsurface into 4 depth regimes according to their response to well activity. It is shown that wells up to 100m removed from the ERT set-up influenced the temperature distribution. Furthermore, injected oxygenated water highlighted a preferential flow path between the depths of 20 and 35m in a north-west direction. This is in line with global groundwater flow in the area. Groundwater flow effects could not be reliably separated from the effect of well activity, however its effect is recognized both during extraction of groundwater and injection of warm water.","Electrical resistivity tomography; Groundwater abstraction; Groundwater flow","en","master thesis","","","","","","","","","","","","","",""
"uuid:171a04f3-5745-4eff-8a06-c10e4aafce45","http://resolver.tudelft.nl/uuid:171a04f3-5745-4eff-8a06-c10e4aafce45","Vital Signs Monitoring Using Doppler Signal Decomposition","Li, Y. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Yarovyi, O. (mentor); Petrov, N. (mentor); Delft University of Technology (degree granting institution)","2020","There is an ever-growing demand for vital signs monitoring for a variety of occasions. Non-contact vital signs monitoring can be achieved by detecting the displacement of the human chest using Doppler radar. This method is non-invasive, environment-independent and suitable for long-term monitoring. However, the real-time detection of cardiopulmonary parameters extraction with radar needs to address the challenges of the limited time duration of the signal for the extraction of cardiopulmonary signals, accuracy of vital signs parameters estimation and signal processing algorithm complexity. Here we show that empirical and variational signal decomposition methods can be performed to extract respiration and heartbeat signals in radar system. Hilbert-Huang transform is applied in conjunction with the signal decomposition methods to display the time-frequency-energy distribution of decomposed signals, thus the instantaneous frequencies and amplitudes of vital signs can be obtained. Besides, online signal decomposition approaches are illustrated to achieve the dynamic estimation of vital signs from radar data stream. The results of our experimental verification demonstrate that Online-VMD has an accuracy of 99.56% and a variance of estimated frequencies of 1.81×10−3 when it is applied in FMCW radar system, providing a reliable, accurate and real-time parameter estimation result in vital signs monitoring.","vital signs; empirical mode decomposition (EMD); Hilbert-Huang transform; variational mode decomposition (VMD); dynamic estimation","en","master thesis","","","","","","","","","","","","Electrical Engineering","",""
"uuid:c9139cd9-522f-47bf-b3bb-daad05d1362b","http://resolver.tudelft.nl/uuid:c9139cd9-522f-47bf-b3bb-daad05d1362b","Stopproblemen en Speltheorie: De wiskunde achter de optimale inbraak","Heijnders, Tom (TU Delft Electrical Engineering, Mathematics and Computer Science)","Fokkink, R.J. (mentor); van Elderen, E.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","In dit verslag wordt het gedrag van een dief die huizen besteelt wiskundig bekeken. Het dievenspel is de aanleiding van dit verslag. In dit spel bepaalt een dief zijn optimale strategie voor het bestelen van één huis uit verschillende huizen met verschillende waarden. Daarnaast is er een agent die op zoek is naar zijn optimale strategie om de huizen te bewaken. Dit verslag duikt in de speltheorie om het dievenspel te ontleden. Het dievenspel wordt opgelost en vervolgens uitgebreid naar het geval dat de dief meerdere huizen kan bestelen en er meerdere agenten zijn. Er worden twee gevallen onderscheiden, waar huizen dezelfde waarde hebben en waar huizen verschillende waarde hebben. Voor de situatie met huizen van dezelfde waarde wordt er gebruik gemaakt van de theorie over stopproblemen om een optimale strategie voor de dief te bepalen. Eerder wordt de theorie van stopproblemen uitgelicht. Hier worden interessante voorbeelden en optimale stopregels besproken. Voor de situatie met huizen van verschillende waarde zal de strategie van de dief en de agent numeriek worden geoptimaliseerd. Er zal blijken dat het voordeliger is voor de dief om meer huizen van lagere waarde te bestelen en voor de agenten om meer huizen van hogere waarden te bewaken.","Game Theory; Optimal Stopping; Stopping Problem; Thievery","nl","bachelor thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:fe02007d-9afa-42a3-9ec7-9afe8093cc7d","http://resolver.tudelft.nl/uuid:fe02007d-9afa-42a3-9ec7-9afe8093cc7d","Edutainment for toddlers: designing an episode builder for triggering response moments when watching TV","Franx, Tjitske (TU Delft Industrial Design Engineering)","Gielen, M.A. (mentor); Beets, M.F. (mentor); Delft University of Technology (degree granting institution)","2020","The aim of this thesis was to design an ‘Episode Builder’ toolkit which facilitates filmmakers to easily create a wide variety of episodes that all contain at least one educational response moment for 1.5-3-years-olds while meeting parents’ concerns. Additionally, four different response moments were designed which trigger the child to actively engage with the content. These response moments were integrated within the toolkit’s concept. <br/><br/>During the analysis phase, extensive literature studies and an interview with a pedagogue resulted in an overview of context-dependent design opportunities and threats that would affect the educational value of watching television, spread over the six core elements of the framework. Context mapping research with Dutch families found that it was most common that parents let their toddler watch TV when the parent requires his full attention on another activity during the day. However, parents are bothered that their child wasn’t actively thinking about the presented content on television. Therefore, a design goal, an interaction vision and 18 design guidelines were formulated for creating educational and actively engaging episodes, which resulted in the design of four different response moments which a toddler can safely perform without the parent’s supervision. <br/><br/>When evaluating Pixifox Animation’s first storyboards, it was found that filmmakers integrated too many features within their storyboards which are too complicated for the viewer. Two design principles were formulated in which the toolkit should 1) facilitate filmmakers to explore essential features around a central theme, and integrate these features within their storyboard, and 2) fit the filmmaker’s creative process. These design guidelines, and the integration of the response moments, resulted in the toolkit’s final concept, consisting of five templates.<br/><br/>A validation study with 6 participants was set up to clarify whether the toolkit is able to facilitate filmmakers to create a great variety of educational storyboards around different central themes. In pairs of two, participants worked with five laminated paper templates to create an educational storyboard containing one response moment around a chosen theme.<br/><br/>The Episode Builder found to be able to facilitate filmmakers to create various educational storyboards which all include one response moment around different central themes. Participants had a clear idea about what the story’s essence and learning goal should be, which a toddler can comprehend. However, some educational value was lost, since the toolkit failed to facilitate the participants to translate these features into visual shots which aren’t overwhelming for the viewer. The activity was reviewed as insightful, probably easy to use after the first use, and somewhat repetitive. <br/>Future tests should involve participants who are willing to the toolkit several times for four hours to validate if a 3-5 minute storyboard can be created within this timeframe and gain insight which types of themes can be explored with the toolkit. <br/><br/>Design explorations are recommended about how the toolkit can be introduced more efficiently, be more efficient in use when creativity isn’t required, and how parent and child could reflect on the episode’s content in other activities to elevate the educational value.","","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:89fc770b-0ae9-425f-83ff-d0aaa4e0822d","http://resolver.tudelft.nl/uuid:89fc770b-0ae9-425f-83ff-d0aaa4e0822d","Binaural beam-forming with dominant cue preservation for hearing aids","Sathyapriyan, V. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Hendriks, R.C. (mentor); Çalış, M. (mentor); Varon Perez, J.C. (graduation committee); Izadkhast, S. (graduation committee); Delft University of Technology (degree granting institution)","2020","For people with hearing impairment, it is important to have good speech intelligibility, while also being able to localise the sound sources. Many beam-forming algorithms for hearing aids have been proposed, that minimise the noise, in combination with spatial scene preservation of the target and the interferers. By constraining the spatial cues, the limited degrees of freedom available for the design of the filter are expended, and this, to some extent degrades the noise reduction performance. Most of these methods try to preserve both the interaural time difference (ITD) and the interaural level difference (ILD) cues of the noise components over the entire frequency spectrum. However not all frequencies rely on both the ITDs and the ILDs for the localisation of sound. More specifically, the ITDs are dominant cues in the frequencies below 1.5 kHz and the ILDs are dominant cues in the frequencies above 1.5 kHz. Based on these facts, in this thesis we try to preserve only the ILD cues of the noise components at frequencies above 1.5 kHz, while keeping the target signal undistorted. We investigate whether doing so saves the degrees of freedom that can be used to improve the noise reduction performance, in contrast to preserving both the cues. The thesis proposes two methods to preserve only the ILD cues of the interferers. The first method preserves the ILD cues perfectly, while the second method achieves a relaxed preservation of the ILD cues. Both methods show similar performance in anechoic and reverberant environments, and show that the noise reduction performance improves only mildly, when only the ILD cues of the noise components in the higher frequencies are preserved.","binaural beamforming; binaural cue preservation; noise reduction; Source Localization; speech enhancement","en","master thesis","","","","","","","","","","","","Electrical Engineering | Circuits and Systems","",""
"uuid:259debb3-4583-4bb1-9cd9-a8d5b88186e4","http://resolver.tudelft.nl/uuid:259debb3-4583-4bb1-9cd9-a8d5b88186e4","Intelligent signalized intersection management for mixed traffic using Deep Q-Learning","Schneider, C.C.N. (TU Delft Technology, Policy and Management)","Warnier, M.E. (mentor); Annema, J.A. (mentor); Delft University of Technology (degree granting institution)","2020","Signalized urban intersections are bottlenecks for traffic and cause congestion. To improve traffic signal plans, research efforts have been made to create self-adaptive traffic controllers, i.e. controllers which adapt in real-time to the current traffic demand based on connected vehicle data. Past research on self-adaptive controllers has mostly assumed that all of the vehicles are connected. Yet, at least for the close future, traffic will consist of a mixture of regular vehicles (RVs) and connected vehicles (CVs). Up to date, few studies investigated whether self-adaptive controllers are able to control traffic signals efficiently under CV-penetration rates of less than 100%. Within literature, different types of methods to create self-adaptive traffic signal controllers were found. In this thesis, it was chosen to focus on deep Q-learning models (DQN), which are a type of reinforcement learning model. This thesis aimed to alleviate the research gap by investigating whether deep Q-learning-based traffic signal controllers are able to reduce traffic congestion for mixed traffic scenarios, and what design choices have to be made to build such a controller. To answer this, this thesis conducted a systematic literature review, designed and systematically fine-tuned two DQN agents and evaluated these DQN agents on different traffic situations. The literature review discussed the most important design choices regarding agent design, traffic environments and model evaluation. These results were used to design a vanilla DQN agent and a recurrent DQN agent. Since not all design choices were clear a priori, the impacts of several alternative choices and parameters on agent stability and performance were systematically investigated in experiments in order to fine-tune the agents. After the two agents were fine-tuned, they were evaluated using a microscopic traffic simulator. It was investigated how stable the agents’ performance is, how well the agents can efficiently control traffic signals under different traffic scenarios (low constant, medium constant, high constant and dynamic traffic) and CV-penetration rates (between 10% and 100%), how robust agents are to changes in penetration rates, and how the vanilla and recurrent agents differ. To be able to benchmark the two agents’ performances, they were compared to a traditional fixed-time controller. It was concluded that the designed vanilla DQN agent is unsuitable for mixed traffic control. The recurrent DQN agent on the other hand, performed better than the vanilla agent in terms of stability, performance and robustness, and only the recurrent agent was able to outperform the fixed-time controller for all but the lowest penetration rates. This makes recurrent DQN a promising method for future research on reinforcement learning-based traffic signal control. In brief, this thesis found that reinforcement learning algorithms could potentially be used to control signalized intersections in mixed traffic scenarios such that traffic congestion is reduced. Yet, DQN controllers are not yet mature to be implemented in real-life and future research to improve them is needed.","Intelligent intersection management; traffic signal control; mixed traffic; Connected Vehicles; CV; Reinforcement Learning; Deep Q-Network; Deep Q-Learning; Traffic Simulation","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:746ad403-689e-4a07-9da4-5523ddc93e09","http://resolver.tudelft.nl/uuid:746ad403-689e-4a07-9da4-5523ddc93e09","Passive Deep Ocean Thermometry using Hydroacoustic Signals from Submarine Earthquakes","Morandini, Ludovic (TU Delft Civil Engineering and Geosciences; TU Delft Applied Geophysics and Petrophysics)","Shani Kadmiel, S. (mentor); Evers, L.G. (graduation committee); Ghose, R. (graduation committee); Wagner, Florian (graduation committee); Delft University of Technology (degree granting institution)","2020","Measuring temperature variations of the deep ocean is necessary to evaluate the heat flux between the atmosphere and the hydrosphere and thus calibrate climate change models. In the last two decades a passive alternative to profiling oceanographic floats has emerged: hydroacoustic thermometry. This method consists of using the oceanic ambient noise field as a source of acoustic waves and hydrophone arrays as receivers. These sensors are part of the International Monitoring System which is in place for the verification of the Comprehensive Nuclear-Test-Ban Treaty. They are positioned at a water depth of approximately 1 km, in the Sound Fixing and Ranging channel. This channel is a low-velocity layer that functions as an acoustic wave guide, thus facilitating very long range propagation with little attenuation. This study analyses transient signals between 2005 and 2018 triggered by submarine earthquakes and detected at station H10, situated near Ascension Island in the South Atlantic Ocean. This station consists of two three-element (triplet) arrays with an aperture of approximately 2 km each. The triplets are 126 km apart. Array processing techniques applied to individual triplets are prone to be biased by local conditions of the array surroundings. We demonstrate that this bias is largely suppressed when jointly processing both triplets as one six-elements array. Due to the malfunction of element S1, data quality decreased after October 2013 and our results are less robust. For the 2005-2013 period, we retrieve a temperature of 4.3 to 4.8 °C.","Geophysics; Thermometry; Beamforming; Hydroacoustic; Signals; Ocean; Earthquakes","en","master thesis","","","","","","","","","","","","","",""
"uuid:6c3ebc2c-b610-4a4d-950c-00058e27c1f6","http://resolver.tudelft.nl/uuid:6c3ebc2c-b610-4a4d-950c-00058e27c1f6","High precision positioning system for Ghana","Verweij, Peter (TU Delft Industrial Design Engineering)","Diehl, J.C. (mentor); Persaud, S.M. (mentor); van de Giesen, N.C. (graduation committee); Krietemeyer, A. (graduation committee); Delft University of Technology (degree granting institution)","2020","In this report, the design process of a high precision positioning system for Ghana is described. The system consists of two devices, a base station and a user operated rover. These devices provide precision positioning, using dual frequency receivers and the principle of differential positioning. The high precision positioning system can be utilized for multiple purposes. The system can open up business opportunities in surveying, can be used to make height maps for flood prediction and to gather meteorological data. The gathering of weather data is the main purpose of TWIGA, under which flag this project runs. <br/>During this project, the main focus is to create a working product, which can be tested in Ghana as soon a possible. Therefore, the highest priority is to make a functional device in terms of accurate positioning, data connection and power supply. This device should be suitable for the local environmental conditions, such as tropical rain and a high humidity.","Ghana; GNSS; Positioning; Rover; Base station","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:e17e92e0-9b3e-4e70-8b93-5f77ccbe1154","http://resolver.tudelft.nl/uuid:e17e92e0-9b3e-4e70-8b93-5f77ccbe1154","Economic Feasibility of Reusing Structural Components: “How to quantitatively assess the economic feasibility of reusing structural components from existing buildings into new construction?”","Jabeen, Ilma (TU Delft Civil Engineering and Geosciences)","Jonkers, H.M. (graduation committee); Schraven, D.F.J. (mentor); Pasterkamp, S. (mentor); Delft University of Technology (degree granting institution)","2020","The Netherlands has the vision to be completely circular by 2050 cutting its raw material consumption to half by 2030. To reduce the raw material consumption, materials in use must be reused and nothing should be wasted. However, the construction industry is far from reaching this goal. It is traditional in the EOL treatment of the building. The structure is crushed down into mixed debris and recycling is the highest level of waste management adopted in the sector. 85% of the CDW in The Netherlands is mineral waste which is crushed and typically applied as the foundation in road construction. Reuse, a higher level treatment method, is rarely adopted. Only 3%-4% of the total material demand in the industry is met with secondary materials. It is limited to the reuse of products such as doors, windows and interior installations.<br/>Existing demolition methods do not allow for product recovery as it a costlier and time- consuming process. It requires skilled labour, knowledge and collaboration amongst the stakeholders to deconstruct for reuse. The limited knowledge of the know-how of recovering structural components is found to be prevalent. Furthermore, there is no tool or framework to quantitatively assess the economic feasibility of reusing components well before demolition.<br/>The available methods for assessing reuse feasibility are found to have a futuristic approach and cannot assess the economic feasibility quantitatively. Therefore, the Feasibility Calculation Tool is developed in this research which is a practical framework capable of quantitatively assessing the reuse potential of the components. It provides clear guidance to stakeholders on how to assess if the components from existing buildings can be profitably extracted for reuse. The FCT can be successfully used to determine the economic costs and feasibility conditions quantitatively allowing for a circular EOL treatment. The reuse scenario and the tipping points for the structural floor elements can be evaluated well in advance of demolition guiding the decision of the owners to demolish or deconstruct for reuse. A well-planned deconstruction can further help find buyers in time and deconstruct with higher precision as per the requirements of the buyers increasing the salvage cost and the need to modify components after deconstruction.<br/><br/>The results of FCT show that it is most feasible and economic to reuse components directly on the same site (Reuse Scenario 1) then to transport them to another site for reuse(Reuse Senario 2). However, for the existing building stock, it is more probable to reuse under Reuse Scenario 3 than 2 and 1 as the<br/>existing stock is not designed to be reused. Instead, a buyer should be found who has no or minimum modification requirements. Furthermore, taking the environmental impact of reusing secondary components into account improves the reuse feasibility. The reuse cases which are otherwise not economically feasible turn feasible once the environmental impact costs are considered, in other words, once the polluter is made to pay the price. Furthermore, planning for the EOL of the building should be done well in advance<br/>to allow for sufficient time and efficient recovery. The owner should be motivated for deconstructing circularly, allow sufficient time and if he fails to reuse materials himself, he should allow for collection and sale of secondary products by the demolition companies to a third party. The demolition contractors, on the other hand, are found to depend on the question from the owner to reuse. However, they must make voluntary calls for deconstruction.","Reuse; Structural Components; Circular Economy; Economic Feasibility; Feasibility Calculation Tool","en","master thesis","","","","","","","","","","","","Civil Engineering | Building Engineering","",""
"uuid:3dc153a2-01bf-471f-91bd-3d8a5c433b42","http://resolver.tudelft.nl/uuid:3dc153a2-01bf-471f-91bd-3d8a5c433b42","Marine Unexploded Ordnance Detection with the Transient Electromagnetic Method: A Numerical Feasibility Study","Buist, Jan Willem (TU Delft Civil Engineering and Geosciences)","Slob, E.C. (mentor); Werthmüller, D. (graduation committee); Kovalenko, Vsevolod (graduation committee); Singer, Johannes (graduation committee); Delft University of Technology (degree granting institution); ETH Zürich (degree granting institution); RWTH Aachen University (degree granting institution)","2020","The hazards of unexploded ordnance threaten the increasing marine construction activities nowadays, which increases the importance of unexploded ordnance detection. Research has shown that transient electromagnetic methods can successfully be used to detect unexploded ordnance on land. New equipment is being developed to make marine unexploded ordnance detection also possible. This study aims to determine which targets can be detected and which not in a marine environment through a numerical feasibility study. Building on an existing geophysical simulation framework, it asks: Under which conditions can we detect a conductor on or below the seafloor using a time domain loop source? Through the three-dimensional modelling of Maxwell’s equations, responses were computed for hollow rectangular targets of different burial depths, sizes, wall thicknesses, andwall conductivities. For the analysis of these responses two quantities were introduced, a net effect and a measurability. Evaluation of these quantities demonstrated the individual impact of the tested parameters on these quantities as well as the relative significance of the influence of these parameters. The results included derived relations for the influence of individual parameters on the net effect, as well as limits on the measurability of targets. Arectangular conductor of 0.1 by 0.1 by 0.4 metres or smaller with a wall thickness of 10 millimetre, buried more than 2 metres under the seafloor is not measurable under the noise assumptions made. The relative significance of the parameters was found to be from most to least significant: burial depth, size, wall conductivity, and wall thickness.","unexploded ordnance; transient; electromagnetics; detection; numerical; marine; uxo; tdem; geophysics","en","master thesis","","","","","","","","","","","","Applied Geophysics","",""
"uuid:fb9bae2c-e852-4d37-91a6-c1621646fbf5","http://resolver.tudelft.nl/uuid:fb9bae2c-e852-4d37-91a6-c1621646fbf5","A very first real data application of stochastic wave-equation based AVO inversion of seismic pre-stack data","Rivera Herrera, Omar (TU Delft Civil Engineering and Geosciences)","Wapenaar, C.P.A. (mentor); Gisolf, Dries (mentor); Haffinger, Peter (graduation committee); Delft University of Technology (degree granting institution); ETH Zürich (degree granting institution); RWTH Aachen University (degree granting institution)","2020","Wave-Equation-Based Amplitude Vs Offset (WEB-AVO ) inversion solves the full elastic wave equation both for properties and for the total wavefield. It is a non-linear inversion technique that accounts for multiple scattering and mode conversions inside the target interval. When prior geological information interpreted from well logs is incorporated, stochastic inversion can be performed by honouring Bayes' theorem for probability density functions. The posterior function is proportional to the product of the likelihood function and the prior probability density function.<br/><br/>The prior probability function is built from well logs and is a complex mixture of Gaussians that account for thicknesses, property values and their corresponding standard deviations.<br/><br/>The likelihood function is built from the maximum likelihood estimator, the result of the deterministic inversion, and from the Hessian derived from the inversion kernel, scaled by the variance of the noise in the data. <br/><br/>The present work proposes that the best estimate of the noise in the data can be extracted from the residual of the seismic-to-well match.<br/>The inaccuracy of the method can be quantified by taking the second derivative of the posterior function at the Maximum a Posteriori estimate. The present work also proposes that an additional source of inaccuracy is the intrinsic uncertainty, or non-uniqueness, of the method. It can be estimated with the help of random starting models on a perfect data set (synthetic data).<br/><br/>The stochastic WEB-AVO inversion is a natural extension of the already existing deterministic WEB-AVO inversion workflow. The inversion result is constrained by the prior to honour the true geology observed in the wells.","WEB-AVO Inversion; Stochastic Inversion; Seismic Inversion","en","master thesis","","","","","","","","","","","","Applied Geophysics | IDEA League","",""
"uuid:08e2936a-fa22-44bc-a83b-5315a5642449","http://resolver.tudelft.nl/uuid:08e2936a-fa22-44bc-a83b-5315a5642449","Cloud Computing Solutions and Business Model Innovation: A case study in the financial services industry","Frisardi, Davide (TU Delft Technology, Policy and Management)","Roosenboom-Kwee, Z. (mentor); Hakvoort, R.A. (graduation committee); Delft University of Technology (degree granting institution)","2020","The rise of the so called Insurtechs, leveraging digital technologies to offer superior and personalized offerings, has shaken the insurance industry leading to a new age of innovation and business models. In addition, the importance of a digital customer experience is increasing as the number of sales completed online are rising. Customers expect wide availability of personalized options and offerings tailored to their specific risk scenarios. Traditional insurers should react fast to face the threat of new players and remain competitive in this fast-paced market environment. A customer-centric approach to digitalization is required to meet demanding requests from customers while targeting benefits including financial flexibility, lower Total Cost of Ownership (TCO), speed to market, and availability of information anywhere and at any time. Concurrently, the rise of cloud computing technologies spark interests in traditional players that have an opportunity to tackle these challenges by transforming their IT infrastructure to generate value for clients while substantially improving the enterprise’s operations. The aim of this document is to inspire the management to perceive the need for innovation and structural change and provide them with the tools and key recommendations to tackle the challenge. Besides, the literature is lacking contents weighting the cloud computing advantages in the insurance industry and exploring the business model’s innovations necessary to welcome the use of the cloud. Hence, the additional goal of this research, is to address this gap and explore the barriers hindering cloud adoption in the financial services industry together with the mitigation strategies expected to reduce such risk factors.","Cloud Computing; business model innovation; Insurance","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:f74f3dfc-8b96-4b2a-b295-9441c881923b","http://resolver.tudelft.nl/uuid:f74f3dfc-8b96-4b2a-b295-9441c881923b","Modelling of potential energy savings of solar powered smart windows","Kwee, Patrick (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Photovoltaic Materials and Devices)","Isabella, O. (mentor); Ortiz Lizcano, J.C. (mentor); van den Dobbelsteen, A.A.J.F. (graduation committee); Tenpierik, M.J. (graduation committee); Delft University of Technology (degree granting institution)","2020","The built environment is among the highest energy consuming sectors worldwide. However, buildings have large surface areas that can be used to improve the building energy performance. One example is by integration of photovoltaic systems in roofs and facades, which can reduce the carbon footprint of the built environment. An emerging field that could lead to energy savings involves the glazing. Switchable or smart windows allow for a variable transparency which affects the amount of incoming daylight and solar heat. Manually controlled smart windows however, require electricity to function and could thus be powered by solar energy to function autonomously. Smart windows have been shown to improve the building energy performance by reducing heating, cooling and lighting loads and can also be used to optimize the visual and thermal comfort conditions of occupants. In this thesis project the energy performance of three types of switchable glazing has been compared to different window technologies including electricity generating photovoltaic windows. Additionally, the hourly and yearly electricity requirements of each smart window and the corresponding minimal photovoltaic system requirements have been determined.","smart windows; Building integrated Photovoltaic; PV windows; Sustainability; Building Energy Modelling; Energy performance of buildings; Switchable glazing; building facade","en","master thesis","","","","","","","","2021-08-21","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:235d89ab-eaff-4068-8ab9-44e1282f50e3","http://resolver.tudelft.nl/uuid:235d89ab-eaff-4068-8ab9-44e1282f50e3","Modelling Air Flow and Temperature in Urban Area: The influence of vegetation in a street canyon and the implemention of the Van Leer limiter","Nijensteen, Ilse (TU Delft Applied Sciences; TU Delft Electrical Engineering, Mathematics and Computer Science)","Vuik, Cornelis (mentor); Kenjeres, S. (mentor); Delft University of Technology (degree granting institution)","2020","In this thesis, a model for air flow and temperature in urban areas is studied. In particular, the influence of vegetation in a street canyon is investigated. This includes the effect of vegetation on air flow and the cooling property of vegetation to lower temperature in street canyons. Computational Fluid Dynamics simulations with vegetation in a street canyon (green facades and trees) are performed. To model this, the Reynolds Averaged Navier Stokes equations in 3D are closed using the k-e turbulence model with source and sink terms to account for the effects of vegetation on air flow. In the thermal equation, the Simple Gradient Diffusion Hypothesis is used to close the equations and a cooling power term is introduced to account for the transpirational cooling property of vegetation. The results regarding the vertical velocities in the street canyon are compared with earlier simulations by Gromke et al. The simulations involving temperature showed significant effects of the vegetation in the street canyon. At street level, the green facades yielded a stronger cooling effect than trees. However, the cooling effect of trees is stronger halfway the canyon and just above the canyon in comparison with green facades. An important note is that the temperature drop inside the tree canopy strongly suggests that the cooling power in the simulation is modelled stronger than one would expect in reality. Another part of this research is the implementation of a Higher Order Scheme. This is done with the Van Leer limiter. The simulations with this new numerical method yielded very similar results compared with the UDS simulations. One outlier is noticed in the velocity in the 푦-direction for the empty street canyon. A possible explanation could be the sensitivity of the method near the ground. The study of the effect of vegetation in a street canyon could be extended in the future by comparing combinations of vegetation and adjusting the parameters of the green facades. Furthermore, the Van Leer limiter could be extended to the temperature part of the simulations in the future, since sharper gradients are expected here, so the improvement with respect to UDS and QUDS could be more significant. Finally, also other flux limiters, such as the Koren scheme, could be tested.","air flow; urban heat island; urban area; van leer limiter; temperature","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics | Applied Physics","",""
"uuid:35c0b3e9-a52e-4b49-8de9-f07ed7706f6b","http://resolver.tudelft.nl/uuid:35c0b3e9-a52e-4b49-8de9-f07ed7706f6b","Exploring the Value of the Analogy between the Physical Internet and the Digital Internet","van Luik, Sharon (TU Delft Technology, Policy and Management)","Tavasszy, Lorant (graduation committee); Fiebig, T. (graduation committee); Rezaei, J. (graduation committee); Fahim, P.B.M. (graduation committee); de Waard, P (graduation committee); Delft University of Technology (degree granting institution)","2020","","","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:930ef04e-c5a6-4d7b-959d-3d385b487005","http://resolver.tudelft.nl/uuid:930ef04e-c5a6-4d7b-959d-3d385b487005","Improving cost estimating and cost monitoring by the contractor during the design stage in Design &amp; Build contracts: A case study research","van der Donk, M.W.R. (TU Delft Civil Engineering and Geosciences)","Bakker, H.L.M. (mentor); Lousberg, L.H.M.J. (mentor); Keusters, Guus (mentor); Bleijenberg, Paul (mentor); van Veen, Pim (mentor); Delft University of Technology (degree granting institution)","2020","Many construction projects experience cost overruns (Flyvbjerg &amp; Holm, 2002), which is the difference between the estimated cost and the final costs of a project. In Design &amp; Build procured projects, the contractor is responsible for both designing and constructing the project (De Ridder, 2009). During the tender phase, the contractor creates a schematic design and a corresponding cost estimate (De Ridder, 2009), based on client’s functional requirements. After contract award, the contractor elaborates the schematic design into a detail design. Even though this detail design yet has to be created, the budget for the project is already fixed. It is often difficult for the contractor to keep track of the current cost position relative to the cost baseline (budget) during the design stage because of inadequate interaction between designers and actors with practical on-site expertise, often leading to exceedances of the budget, detected at a later point in the design stage (Kim &amp; Park, 2016) The goal of this research was to improve cost estimation and cost monitoring of the contractor during the design stage in Design &amp; Build procured projects to enable the contractor to keep track of the current cost position of the design, relative to the cost baseline (budget). This research’s literature study provided the following insight into the into the structure of both the design and cost management processes (cost management covers cost estimation and cost monitoring) of the contractor and their dependencies in Design &amp; Build procured projects. In the tender, both the design and the cost estimation processes dynamically converge into a tender design with a corresponding price estimate. After contract award, the design is further elaborated upon through a dynamic and iterative process while the budget to build the design ‘outside’ is fixed. Potential differences between the fixed budget and the cost estimate of the developing design occur at different timepoints in the design stage. Only after the detail design is created the working budget is revised, based on a far more accurate estimate of the cost of the detail design. In this research’s case study, four main team members of three ongoing construction projects of Dura Vermeer infra landelijke projecten were interviewed, resulting in the following general findings in practice: 1) The difference between the costs of the design and the budget, is often inaccurate and incomplete as the responsible actors are not perfectly capable to make accurate estimates of the ever-changing costs for the design, neither to they make them for all design changes. 2) The responsibility for communicating the difference between the costs of the design and the budget is unclear within the project team in terms of initiative and frequency. 3) Designers lack background information of the material quantity’s that support the tender design even though monitoring material quantities is key for designers to keep their design within budget. This research delivered a framework that aims at improving alignment between the design, and cost estimation and cost monitoring processes by structuring actor responsibility and information sharing.","Design management; Cost management; Design & Build procured projects; Cost estimation; Cost monitoring","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:efbe886c-1b39-4696-9032-3fc1bbe7e445","http://resolver.tudelft.nl/uuid:efbe886c-1b39-4696-9032-3fc1bbe7e445","Safe Optimization of Steel Manufacturing with Reinforcement Learning","Kosiorek, A. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Spaan, M.T.J. (mentor); Merkestein, Daan (graduation committee); Oliehoek, F.A. (graduation committee); Delft University of Technology (degree granting institution)","2020","Steel production is a complex problem, and little has been done to improve it with the usage of Reinforcement Learning techniques. Most studies focus on decomposing it into sub-problems, instead of tacking it as a whole. Research has shown promising results in the area of safe policy improvement on toy problems. These algorithms are not only computationally tractable but also do not compromise the agent's safety concerns during learning. This thesis investigates how they perform on the real-world problem of improving steel production logistics. We take a simulation of a steel plant that uses hand-crafted heuristics for scheduling tasks and model it as a Markov Decision Process. We experiment with safe policy improvement algorithms by using different baseline policies. Given problem suffers from the known ''Curse of dimensionality''. Hence, the algorithms are adjusted to cope with the fast-expanding complexity. The methods prove to learn with fewer amount of samples than exploration methods. The results are especially promising with a highly stochastic baseline policy, as then the agent has a better understanding of the large environment. The next focus is on the factored representation, which has the advantage of better utilizing the problem. However, in our setting, the algorithms become too computationally expensive.","Reinforcement Learning; Safety; Steel manufacturing; production optimisation; safe reinforcement learning","en","master thesis","","","","","","","","","","","","Computer Science | Data Science and Technology","",""
"uuid:83a78fd0-05c3-4d85-abd2-5cf112be31eb","http://resolver.tudelft.nl/uuid:83a78fd0-05c3-4d85-abd2-5cf112be31eb","District Heating Systems for Sustainable Heating in Metropolitan Areas: How the planning &amp; design of district heating systems in metropolitan areas can support stakeholders in their transition towards sustainable heating","Wiegerinck, S.V.H.J. (TU Delft Civil Engineering and Geosciences)","van den Dobbelsteen, A.A.J.F. (graduation committee); Pothof, I.W.M. (mentor); Hoppe, T. (mentor); Büskens, Nico (mentor); Delft University of Technology (degree granting institution)","2020","District heating systems offer great potential for facilitating the transition towards sustainable heating for metropolitan areas. This research provides an overview of roles and factors relevant to DH systems, identifies stakeholder types, their interests and influence, shows the relationship to system requirements and the lack of stakeholder involvement in the heat planning process. A three-step descriptive system design framework is presented, followed by the identification of improvements for the planning process.","District heating systems; Heat planning; System requirements; Stakeholder interests; Factors; Roles; Metropolitan areas; Urban areas; Sustainable heating; Energy transition; Heating transition","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:0d49d337-0772-4a1b-9c8d-b0ef77ab8e58","http://resolver.tudelft.nl/uuid:0d49d337-0772-4a1b-9c8d-b0ef77ab8e58","Finite element analysis of the closed stiffener to crossbeam connection in OSDs using the hot spot stress approach","van der Ende, D.J. (TU Delft Civil Engineering and Geosciences)","Veljkovic, M. (mentor); Hendriks, M.A.N. (graduation committee); Wu, W. (graduation committee); Maljaars, J. (graduation committee); Delft University of Technology (degree granting institution)","2020","An Orthotropic Steel Deck (OSD) is suspectable to fatigue and this forms an important design criterium. In this research the rib-to-crossbeam connection with a cope hole is studied using Finite Element Methods (FEM). The fatigue assessment is performed with the hot spot stress method making use of surface stress extrapolation. Two fatigue cracks are investigated: the crack initiating from lower weld end in the rib, and the crack which appears at the weld toe of the rib-to-crossbeam connection and propagating in the crossbeam at some distance from the soft toe of the cut-out. <br/><br/>Engineering firms widely use shell elements to model the structure, instead of solid elements. The modelling and computational time is limited when compared to the solid element. When a comparison is made between the results from the solid and shell FE models, a scatter in results is often seen. This thesis studies the difference of shell and solid element modelling in the hot spot stress calculation of OSDs. Improvement of the shell element modelling is given based on the FE analysis using various shell element modelling techniques and compared with solid element models which represent as a reference.<br/>Three different weld modelling techniques are applied to shell FE model: IIW, Eriksson and a combination of the first two approaches. The weld modelling techniques for the shell FE model are first applied on a simple single sided fillet welded transverse stiffener connection. In this study both the deformations and hot spot stress are compared. <br/><br/>A small parametric analysis is performed to investigate the difference in hot spot stress for pure in-plane and out-of-plane rotation of the crossbeam. In this study the different weld modelling techniques for the shell FE models are included. In the extensive parametric analysis two different studies are performed: one based on the influence of the loading positions, the second study is based on different thicknesses of the parts of the OSD. Based on the loading positions study the critical loading positions are further investigated. <br/><br/>From both the fillet welded transverse stiffener specimen and the full OSD specimen it is concluded that the shell FE model in which use is made of the combined weld modelling technique, gives the largest improvement. The ratio between shell and solid FE models of the obtained hot spot stress is reduced from a factor 1.25 to a factor 1.05 for the lower weld toe crack in the rib. <br/><br/>For the crack in the trough, the mean value of the hot spot stress ratios is equal to 1.04 for both the old and new OSD variant and the coefficient of variation (CV) is equal to 0.8% and 2.2% respectively. For the crack in the crossbeam, the mean values are equal to 0.80 and 0.76 for the old and new OSD variant respectively. The CV is equal to 1.9% and 2.0% for the old and new OSD variant respectively. Furthermore, the stress gradient and the stress at 40mm from the weld toe show similar results when compared with the solid FE models. The coefficient of variation for both investigated cracks is low, i.e. below 5%, thus the ratio between obtained hot spot stress of the shell with combined weld and solid FE models is consistent. <br","Fatigue; Orthotropic Steel Deck; Finite Element Analysis; Hot spot stress","en","master thesis","","","","","","","","","","","","Civil Engineering | Structural Engineering","",""
"uuid:588a173d-e3a9-42ac-8d42-aefaa7236498","http://resolver.tudelft.nl/uuid:588a173d-e3a9-42ac-8d42-aefaa7236498","Modelling of PV-Electrolyzer system for optimum operation: Analyzing the effect of varying irradiance and comparison of various configurations for best efficiency","Shriyan, Nikhil (TU Delft Electrical Engineering, Mathematics and Computer Science)","Isabella, O. (mentor); Ziar, H. (graduation committee); Ahmad, Z. (graduation committee); van Kruijsdijk, Cor (mentor); Delft University of Technology (degree granting institution)","2020","With emphasis on finding storage solutions for renewable based power plants, hydrogen has emerged as one of the prominent options. Hydrogen required in fertilizer, oil and gas industries etc., is produced using fossil fuels which emits carbon dioxide 10 times the produced hydrogen. It is important to produce the hydrogen from green energy sources for this industrial use or for the energy storage use. Solar energy harvested from Photo-Voltaic (PV) technology can be used to produce hydrogen in an alkaline electrolyzer. Directly coupling the PV and electrolyzer systems will have least components contributing to inefficiencies, complexities etc. In this study, a tool was made using MATLAB-Simulink, to optimize the PV-Electrolyzer directly coupled system. In literature many authors have done the same but none of them have included variation in space irradiance over PV farm, variation in PV module parameters due to manufacturing defects or defects arising over the period of use. These variations affect the IV curve of PV modules and in turn affect the performance of the whole system. It was observed that after optimizing, the coupling efficiency in the range of 90-95% could be achieved in directly coupled systems with shorter string lengths of PV. This was even after including the variation up to 20% in parameters like irradiance and PV module parameters. If the best configuration is not available in the market, then the set of next best configurations is available as output of simulation. Even with variation of 10% in input parameters, the maximum difference between the global maximum and other local maximums in the results is 3%. This 3% compromise results in energy loss of 870 kWh and 148 euros loss per year for a 50 kWp system. Which is 2.96 Euros/kWp loss, at 1 GW scale it may result into a loss of 2.96 million Euros, if we ignore the variations. In comparison to the DC-AC-DC configuration that comprises of inverter, rectifier and transformer, the directly coupled system performed better. The efficiency was almost 5-10% more for directly coupled system in comparison to DC-AC-DC system. The weighted efficiency for both the configurations were calculated, where the weights were based on the occurrences and the energy contribution of an irradiance bracket. The weighted efficiency for directly coupled system was 95.7% and for DC-AC-DC was 90.63% for Amsterdam. Even after considering all the seasonal, weather parameter and module parameter variations, directly coupled PV-Electrolyzer systems with shorter string length and bigger electrolyzer cells gave the best efficiency amongst all, which was above 90%.","Photovoltaic Systems; electrolyzer; direct coupling; Coupling efficiency; Comparison; irradiance; module parameters","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:d865162e-8ae8-4ce5-b034-fcaf0b958387","http://resolver.tudelft.nl/uuid:d865162e-8ae8-4ce5-b034-fcaf0b958387","Design and Prototyping of Auxiliary Power Supply for MMC based High Voltage Generator","YU, GUANGYAO (TU Delft Electrical Engineering, Mathematics and Computer Science)","Ghaffarian Niasar, M. (mentor); Vaessen, P.T.M. (mentor); Lekic, A. (graduation committee); Delft University of Technology (degree granting institution)","2020","Power electronics technology has been widely used in industry. High-frequency harmonics caused by power electronics related products will have a huge influence on the insulation characteristics of the electrical devices. In order to study these influences, an arbitrary waveform high voltage generator is needed. The multilevel modular converter is a promising topology to build such a generator. The thesis goal is to design and build a prototype DC-DC converter which can step down the MMC submodule capacitor voltage to a reasonable low value for driving the submodule IGBTs. In chapter 1, an introduction is given which shows the background and research questions of this thesis. Chapter 2 is literature review studies. In this chapter, different possible converter topologies are analysed. Finally, the flyback topology with series-connected MOSFETs is selected. High voltage switch constructions and voltage balancing methods are also discussed and some of these methods are simulated in chapter 3. In chapter 4, an open-loop prototype was built. In this chapter, flyback transformer and driving transformer design methods are presented. After selecting proper values for the RC snubber, satisfactory voltage balancing effects can be achieved. Finally, in chapter 5, a DC-DC converter with 500V-1500V input voltage was built and it is designed at 30W. Recommendations and future work are given in chapter 6. They include necessity of temperature rise measurement, PCB design and so on.<br/><br/><br/><br/><br","Power electronics; High voltage; DC-DC converters","en","master thesis","","","","","","","","2022-12-31","","","","","Power Electronics Based Programmable High Voltage Test Source",""
"uuid:a9be0e3f-b8bc-4c58-8326-6e6a551c6dd3","http://resolver.tudelft.nl/uuid:a9be0e3f-b8bc-4c58-8326-6e6a551c6dd3","Project Retina: A new scalable driving and counting system for SNSPDs","van Eijk, Tijmen (TU Delft Electrical Engineering, Mathematics and Computer Science)","Sebastiano, F. (mentor); Fognini, A.W. (mentor); Delft University of Technology (degree granting institution)","2020","The driving and counting electronics for the Superconducting Nanowire Single Photon Detectors (SNSPDs) fabricated and commercialized by Single Quantum (SQ) is currently designed to interface with at most 8 SNSPD channels. Single Quantum is already selling 24 channel systems and the trend is generally towards more channels. In those systems, multiple 8 channel drivers have been used in parallel. However, a redesign of the electronics is needed to allow such system to interface with an arbitrary number of channels, hence enabling new application areas, such as biomedical imaging.<br/>Currently, each channel uses up to 5W of power, which hinders a larger densely packed system. In addition, the current implementation has a counting dead-time of about 20 ms, which gives a significant slowdown in characterizing the SNSPD. And last, the SNSPD might occasionally latch into resistive state and needs to be actively quenched back into superconducting state but the current system is not always able to perform such operation.<br/>This project addresses those issues by making the system scalable in n x 12 channels, reducing the high power consumption on each channel to 2.9 W, proposing a new counting mechanism such that the characterization of an SNSPD is sped up and all photon detections are counted, and proposing a new way to actively quench all types of SNSPD implementations.<br/>The functionality for a 12 channel system is split in Channel Units and a Main Control Unit. The channel units count, bias and control a single SNSPD and communicate with the main control unit through a CAN-FD bus. The main control unit communicates all data from the channel units to the Graphical User Interface (GUI) through ethernet and vice versa translate<br/>the control commands from the Graphical User Interface to the channel units. All units are based on the LPC54618 microcontroller by NXP.<br/>The newly designed system has been tested to work for up to 12 channels, and can be housed in a 19 inch rack mountable enclosure. Using an ethernet switch allows for interfacing with n x 12 channel systems.<br/>This system design paves the way towards the bias and readout of, for instance, a 10x10 SNSPD array such that detailed spatial information may be added at the single photon level.","SNSPD; Computer engineering; Microcontrollers","en","master thesis","","","","","","","","2022-08-20","","","","Computer Engineering","",""
"uuid:f121cb32-1b27-4b1d-bfd0-89410d70ccd1","http://resolver.tudelft.nl/uuid:f121cb32-1b27-4b1d-bfd0-89410d70ccd1","A 10 Gbps Wireline Transceiver Link: To Interface Future RF-DACs","Feng, Jun (TU Delft Electrical Engineering, Mathematics and Computer Science)","de Vreede, L.C.N. (mentor); Alavi, S.M. (mentor); Cavallo, D. (graduation committee); Delft University of Technology (degree granting institution)","2020","This thesis presents the development of circuits and systems for fast wireline transceiver links that will enable a move towards highly integrable RF digital-to-analog converters. A new perspective on the analysis of bit error rates in wireline links leads to the PAM spectral design space chart: a novel, visual system design analysis tool for PAM wireline circuit designers. Moreover, a &lt;2 mW/Gbps/lane, 10 Gbps wireline transmitter has been designed and taped-out in 40 nm CMOS. The proposed inherently pipelined 16:1 multiplexer and current mode logic driver design procedure are the key enablers for this performance. Finally, for development of a 10 Gbps wireline receiver, a novel self-synchronized receiver design is proposed that removes the need of a classical clock and data recovery loop. At its core, this receiver comprises the design of a high-speed two-tail comparator and an asynchronous metastability detection loop.","Wireline; Transmitter; Receiver; PAM; Transceiver; SerDes","en","master thesis","","","","","","","","2022-08-31","","","","","",""
"uuid:272b700c-50b8-4767-b4f7-8694ea3c223b","http://resolver.tudelft.nl/uuid:272b700c-50b8-4767-b4f7-8694ea3c223b","Concentrated Solar Power generation: Triple bottom line assessment in Europe and China 2020-2050","Hahn Menacho, Álvaro (TU Delft Technology, Policy and Management)","Dias Rodrigues, J.F. (mentor); Behrens, Paul (graduation committee); Delft University of Technology (degree granting institution)","2020","Concentrated Solar Power is one of the renewable energy technologies with the potential for satisfying the future energy demand in a sustainable way, mitigating climate change and reducing the current dependence on fossil fuels. Regarding the deployment of this technology, China and Europe are two regions playing a forefront role in the present and in the predicted future. In this study we assess the environmental and socio-economic impacts of the predicted expansion of Concentrated Solar Power generation. Using an Input-Output model, both the direct effects of these installations and their influence in other industries upstream are considered. In addition, this work studies the experience curve of this technology. It suggests a learning rate equal to 16%. This information is combined with the predicted cumulative installed capacity of concentrated solar power and other energy technologies from scenarios developed by the International Energy Agency and the National Development and Reform Commission. The results show how the development of this technology under different scenarios affects its performance assessing its potential as an alternative to produce electricity in the future. It is found that CSP employment intensity amounts to 2.28 jobs/GWh in Europe and 4.23 jobs/GWh in China. These CSP employment intensities are higher than other low carbon technologies intensities. In addition, this technology already presents lower carbon emissions than fossil fuels and it has the potential of reducing the gap with other low carbon technologies. It presents a carbon intensity of 99.76 gCO2eq/kWh in Europe and 129.65 gCO2eq/kWh in China. These values could further be reduced to 31.10 gCO2eq/kWh in Europe and 40.42 gCO2eq/kWh in China by 2050. This work stresses the importance of an integrated approach that considers environmental and socio-economic aspects when evaluating an energy technology and may provide important information about the potential role of CSP in the energy transition. In addition, these results can be used to emphasize the importance of investing on renewable energy technologies to gain experience, since the knowledge obtained during their deployment can be expected to improve their performance.","Solar energy; input-output analysis; socio-economic impact; Environmental impact; learning curve; Concentrated solar power; Renewable Energy","en","master thesis","","","","","","The Master's programme Industrial Ecology is jointly organised by Leiden University and Delft University of Technology.","","","","","","Industrial Ecology","",""
"uuid:8328cab8-c419-4103-80fc-ee5e3f35335c","http://resolver.tudelft.nl/uuid:8328cab8-c419-4103-80fc-ee5e3f35335c","Mainstreaming private climate adaptation: an exploration of business perspectives","Castanos, Emma (TU Delft Technology, Policy and Management)","van der Voort, H.G. (mentor); Enserink, B. (graduation committee); Nieuwenhuis, E.M. (graduation committee); Helmyr, Sabrina (mentor); Delft University of Technology (degree granting institution)","2020","Climate change adaptation is needed in response to the extreme weather events such as heat waves and rainfall-induced flooding in the Netherlands. There is a mandate from the national government to become climate- and water-proof by 2050, and the onus is on local governments to fulfill these goals. Local governments, in turn, need to activate stakeholders in their networks to become more climate adaptive. This research focuses on one group in particular, businesses located on business parks. Via the Q-methodology, fourteen businesses are interviewed and their perspectives with respect to the need and urgency for, as well as, the costs and benefits of climate adaptation are documented, analyzed, and interpreted, resulting in a typology of business perspectives on climate change adaptation. Specific recommendations for government are presented based on this more nuanced understanding of the motivations and barriers businesses face. Specifically, subsidy is largely rejected, the role of regulation remains important for some, and for all, the real risks and practical solutions are needed, which is viewed as the role of government to communicate.","climate change adaptation; governance; private sector","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:48631eb7-8872-4f2c-bb26-de083c8a3949","http://resolver.tudelft.nl/uuid:48631eb7-8872-4f2c-bb26-de083c8a3949","Computational Modeling of A 50 kWth Indirectly Heated Bubbling Fluidized Bed Steam Reformer","Fidllan Nurkhoir, Fidllan Nurkhoir (TU Delft Electrical Engineering, Mathematics and Computer Science)","Padding, J.T. (mentor); Roekaerts, D.J.E.M. (mentor); Mohammadzadeh Moghaddam, E. (mentor); Tsekos, C. (mentor); Peeters, J.W.R. (graduation committee); Delft University of Technology (degree granting institution)","2020","The CFD modeling based on the two-fluid model (TFM) was used on studying the novel indirectly heated bubbling fluidized bed steam reformer (IHBFB-SR). This is a collaborative project between Petrogas and TU Delft for testing the advance’s reactor configuration, which indirectly supplies the heat via radiant burner on the center toward the surrounding bed, thereby improving heat transfer efficiency and reduced the losses. The present work aimed to observe the hydrodynamic and heat transfer of the reactor by first employing air as the fluidizing gas and corundum (Geldart B size) as the bed material. The minimum fluidization condition, bubbles development, and voidage profile are the main objectives for the hydrodynamic simulation. In the heat transfer study, the effect of radiative heat transfer, bubbles and voidage profiles, and different radiative models (P1 and DO) on the heat transfer mechanism were examined. The 2D and 3D models were built, and three drag models: Gidaspow, adjusted Syamlal, and EMMS/Bubbling was employed. The simulation results were then compared to the experimental data obtained, such as minimum fluidization flowrate, pressure drop, bed expansion, and temperature profile on a specific flow rate.<br/><br/>Initially, a grid independency test was conducted using five different grid sizes. It is concluded that the appropriate grid size for simulating the IHBFB-SR with a bed material particle size of 0.496 mm should be at least 7.5 mm or 15 times the corundum particle size. The present research used 2.5 mm or five times dp. The minimum fluidization obtained was in the range of 14-16 kg/h based on both 2D and 3D simulation. Nonetheless, if primarily refers to the 3D model results, the minimum fluidization condition should lie around 14 kg/h. Three drag models have also been compared. It was found that the adjusted Syamlal gives the closest result compared to the experimental data. Nevertheless, the drag modification, based only on minimum fluidization conditions like modified Syamlal, tends to overpredict the drag coefficient on the entire range of solid volume fraction. There are also no significant differences in the bubbles or voidage profiles among those three drag models. Adjusted Syamlal has a slightly larger bubble while Gidaspow and EMMS bubbling has a bit smaller one. The expected better result of using the EMMS bubbling drag model does not appear to have a considerable impact on the case of Geldart B or larger particles. There was also an underprediction of pressure drop and bed expansion on the simulation. Two major factors were the absence of proper particle shape representation through a sphericity factor and the lack of precise simulation of particle size distribution. Only a perfect rounded sphere of corundum with a sphericity factor of one and one uniform size of the particle was assumed.<br/><br/>In the case of heat transfer simulation, bubbles and voidage effect firstly studied. It was found that the increase of the bubbles frequency and size, as represented on the voidage profile, would improve the heat transfer process indicated by the increase of the heat flux. The bubbles’ occurrence on the bed plays a critical role in the mass transfer’s improvement from and to the vicinity of the radiant burner wall, thus increasing heat transfer. In contrast with the voidage, the increase of superficial gas velocity does not directly influence the heat flux. It was also proved that the radiative heat transfer improved the overall heat flux in this bubbling fluidized bed reactor by about 16.11 %. Though it appears small, this contribution fits the range of other proven works, with a similar operating environment and particle size used. There are two different radiative models performed in the simulation: first-order spherical harmonics method (P1) and discrete ordinate method (DO). Both models presented a similar trend, with P1, has a slightly higher magnitude. However, the P1 model shows a peculiar result of having a strange lower temperature lower on the bottom part of the bed. On the contrary, that is not the case for the DO, which is well known for its accuracy but a higher computational cost demand. It is then concluded that for the present setup, the DO model could perform better. Lastly, the overall heat transfer process was investigated. Since no specific experimental data available for validating the heat transfer properties, only the final steady temperature values of five different thermocouples were used. Comparing these two, it was found that the present model did not give satisfactory results due to overprediction of air temperature above the bed and underprediction of bed temperature at the same time. Some improvements are required, as will be presented in the recommendations section.","Biomass gasification; Allothermal; CFD modelling","en","master thesis","","","","","","","","2022-08-21","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:ad3fe978-060a-4e55-b45a-3f7753663b3f","http://resolver.tudelft.nl/uuid:ad3fe978-060a-4e55-b45a-3f7753663b3f","Simulation of a Wind Powered Freshwater and Electricity Production System: Numerical Modeling and Optimization","Goveas, Akhilesh (TU Delft Electrical Engineering, Mathematics and Computer Science)","Greco, F. (mentor); Zaaijer, M B (mentor); von Terzi, D.A. (graduation committee); Diepeveen, Niels (graduation committee); Delft University of Technology (degree granting institution)","2020","The rapid growth in world population and increasing demands have led to the lack of fresh water, taking a toll on several of earths reserves, mainly the fresh water supply reserves. Water stress deters economic growth, leads to conflicts and has a direct impact on the health of humans. Studies show the trends in the<br/>increase of water consumption per capita due to increase in higher standards of living over the last years, resulting in the decrease of usable high purity water. 97% of the world’s water supply is locked in the salted, often unusable oceans. In recent times, water stressed countries are using the saline water from the oceans and desalinating it to produce fresh water for domestic, industrial or agricultural use. The state-of-the art method for desalinating saltwater is by Reverse Osmosis (RO). The biggest drawback of this technology is its high energy consumption mostly provided by conventional sources like fossil fuels. Therefore, for a sustainable future, a renewable energy source must be integrated to power the RO system.<br/>Delft Offshore Turbine (DOT) is currently developing and testing a new hydraulic drive train solution for fluid power transmission in offshore wind turbines using seawater as the medium. A hydraulic positive displacement pump is driven by the DOT wind turbine creating a flow of sea water under high pressure. This high-pressure flow can be either directed to a RO unit to desalinate seawater or converted into electricity using a spear valve and pelton turbine generator. A major challenge while using wind as an energy source is its intermittency. Reverse osmosis plants are designed to operate at a fixed flow and pressure while due to the uncontrolled, varying nature of the wind, the pump output experiences fluctuations in both pressures and flows.<br/>The aim of this thesis is to analyze the steady-state behavior of the integrated system for wind speeds up to the turbine rated wind speed under different operating conditions. This is achieved by simulating the behavior of the DOT500 hydraulic drive train wind turbine coupled to a RO system with pressure exchanger energy recovery device and a nozzle with a pelton turbine generator. The main objective of this research is to build a numerical model in Python using algorithms to solve the system of steady-state equations and optimize the integrated system for maximum water and maximum electricity production at specified locations.<br/>The numerical model is simulated for all combinations of wind speeds and nozzle positions and the behavior of the high-pressure pump, RO system, pelton turbine and various system parameters are shown. A sensitivity study is performed for important desalination parameters and their effect on system performance is analyzed.<br/>This research has yielded three main conclusions / deliverables:<br/>1. Behavior of the wind powered integrated system to produce freshwater and electricity at different operating conditions.<br/>2. Steady state control of DOT500 turbine and behavior of the pelton turbine to produce either maximum electricity or maximum water.<br/>3. Sensitivity of important desalination system parameters on overall system behavior for future optimization of RO membranes.","fresh water production; electricity production; wind energy integration; hydraulic drive train; Numerical modeling; Optimization; wind powered; Sensitivity Analysis; Water Security; Water scarcity","en","master thesis","","","","","","","","2022-08-21","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:83556b37-1484-41f4-b168-3bd316def4a0","http://resolver.tudelft.nl/uuid:83556b37-1484-41f4-b168-3bd316def4a0","Safe reinforcement learning in long-horizon partially observable environments","Kovács, B. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Spaan, M.T.J. (mentor); Yang, Q. (graduation committee); van Gemert, J.C. (graduation committee); Kober, J. (graduation committee); Delft University of Technology (degree granting institution)","2020","Deep reinforcement learning went through an unprecedented development in the last decade, resulting in agents defeating world champion human players in complex board games like go and chess. With few exceptions, deep reinforcement learning research focuses on fully observable environments, while there is slightly less research in the direction of partially observable environments. Though, they are relevant in real-world applications where the physical systems' sensors can read only a limited subset of features required for decision making. In many problems, long-term memory is required for the agent to make optimal decisions, possibly through tens or hundreds of timesteps. In supervised deep learning, in the NLP domain, sequential input processing is done with specialized network architectures like variants of RNNs and attention-based networks.<br/><br/>In this work, we investigate the potential of these advanced sequence-processing architectures in the context of deep reinforcement learning for partially observable environments. Additionally, since partial observability widely appears in the physical world, we take a safe approach by trying to limit high exploration costs and damage to the agent and its environment. First, we augment the soft actor-critic method with constraints on the episodic cost, resulting in an objective function with two Lagrangian multiplier: an entropy temperature and a safety temperature.<br/>Then, to support long-horizon, partially observable environments, we use gated recurrent (LSTM, GRU) and self-attention based neural networks for the policy and the estimation of Q-functions. We also study how the design choices and hyperparameters of the self-attention based method affect the performance.<br/><br/>To evaluate the problem in safety-constrained environments with long-term temporal dependencies, we develop a new set of benchmarks with four parameterizable, partially observable simulations. The environments are also parameterizable with the length of the history containing relevant features. Hence, we can observe how different network architectures handle the same problems with varying time horizons. Additionally, we introduce a practical framework for the reproducible evaluation of the methods.<br/><br/>We conclude that both the recurrent and the self-attention based architectures have high application potential in the introduced domains. We confirm that the feedforward network based baseline agent, shows high performance on problems where only a few, or tens of timesteps have to be processed sequentially. The recurrent and self-attention based architectures show their advantage in environments with longer horizons, where the sequence of events play an important role and looking back to a fixed position is not sufficient.<br/><br/>Maintaining safety proves to be problematic when the reward and cost functions show correlation. Additionally, strict cost limits usually lead to a poor policy and no exploration, contributing to higher costs on the long term, for some environments.<br/><br/>We propose further research for architectural changes to scale up the method for more complex environments, and to analyze the method on discrete-action and environments.<br","reinforcement learning; self-attention; partially observable; deep reinforcement learning; safe reinforcement learning","en","master thesis","","","","","","","","","","","","","",""
"uuid:f3277b52-9a97-48ba-932f-667b30847c51","http://resolver.tudelft.nl/uuid:f3277b52-9a97-48ba-932f-667b30847c51","Surrogate-based optimization under uncertainty of wind farm control using combined control strategies","Debusscher, C.M.J. (TU Delft Aerospace Engineering)","Simao Ferreira, C.J. (mentor); Juhl Andersen, Søren (mentor); Gocmen, Tuhfe (mentor); van Wingerden, J.W. (mentor); van Zuijlen, A.H. (graduation committee); Groves, R.M. (graduation committee); Delft University of Technology (degree granting institution); Technical University of Denmark (degree granting institution)","2020","Due to the limited availability of sites on both land and sea, there is a need to maximize the power density of wind farms whilst limiting the adverse wake effect between the wind turbines that cause power losses and/or increased load cases. The study focuses on analyzing the potential of combining yaw-based wake-steering and constant blade pitch control down-regulation to mitigate the detrimental wind turbine wake interactions. Data-driven surrogate models based upon polynomial chaos theory have been used to model the statistical distributions of the wind farm power production and short-term Damage Equivalent Loads (DEL) in function of the control inputs. The model calibration data has been generated for a range of control settings for two V27 wind turbines aligned with the wind direction through large eddy simulations using the flowsolver EllipSys3D and the aeroelastic code Flex5. A power-based optimization with DEL constraints has been performed and median power gains ranging from +1% to +3% have been observed at close spacings depending on the severity of the imposed constraints. It was identified that larger power gains corresponded to an increase in DEL. At larger spacings, the wind farm control strategies shows limited performance increases and revert to baseline operations.","","en","master thesis","","","","","","","","","","","","European Wind Energy Masters (EWEM) | Rotor Design Track","",""
"uuid:20206cbd-8d50-464b-94c1-37ad5f0c0d8a","http://resolver.tudelft.nl/uuid:20206cbd-8d50-464b-94c1-37ad5f0c0d8a","More than a feeling?: Reliability and robustness of high-level music classifiers","Mostert, C. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Liem, C.C.S. (mentor); Hanjalic, A. (graduation committee); Panichella, A. (graduation committee); Delft University of Technology (degree granting institution)","2020","High-level music classification tasks such as automatic music mood annotation impose several challenges, both from a psychological and a machine learning point of view. Ground truth labels for these tasks at hand are hard to define due to the abstract and aesthetic nature of the data, being largely dependent on human psychology and perception. Such labels, however, are required in training and validation sets when traditional machine learning methods are used. Furthermore, due to copyright restrictions which prevent the sharing of commercial music audio, such classifiers have to work with pre-computed music audio features which are known to be somewhat unstable. Due to the challenges inherent to high-level music classification, the following questions arise: do high-level music classifiers actually perform as well as we believe? And can we trust their output to be a solid foundation for future research? This work analyzes the performance of high-level music classifiers using metrics based on label stability, label agreement and distributional differences, all of which do not depend on any problematic ground truth labels, on a dataset which combines data from AcousticBrainz and Spotify. Unexpected patterns in classifier outputs are uncovered, indicating that these outputs should not be taken as absolute truth and do not form a solid foundation for further research. The improvement of these high-level music classifiers is a multidisciplinary effort for which better evaluation methods are required. To this end, several approaches for more comprehensive classifier testing are presented, based on best practices in psychology and software testing. These approaches are not constrained to the field of Music Information Retrieval and can be applied to evaluate classifiers in other domains as well.","Music Information Retrieval; Data Science; Robustness; Reliability; Machine Learning","en","master thesis","","","","","","","","","","","","Computer Science | Data Science and Technology","",""
"uuid:5f62c19f-7cf0-4c0b-9cc0-561348e59417","http://resolver.tudelft.nl/uuid:5f62c19f-7cf0-4c0b-9cc0-561348e59417","Enhancement of data-driven turbulence models for wind turbine wake applications","Goderie, M.W. (TU Delft Aerospace Engineering)","Dwight, R.P. (mentor); Viré, A.C. (mentor); Steiner, J. (mentor); van der Laan, Paul (mentor); Delft University of Technology (degree granting institution); Technical University of Denmark (degree granting institution)","2020","Wind turbine wakes cause significant reductions in power production and increased fatigue damage for downwind turbines. Thus, they affect the wind levelized cost of energy. Computational Fluid Dynamics (CFD) can be used to quantify the wake characteristics, whereby Reynolds-averaged Navier-Stokes (RANS) has the most potential for industrial applications due to the relatively low computational costs. However, RANS models all turbulence scales, usually done by the linear κ-ε turbulence model, which has significant shortcomings in accurately representing the turbulence characteristics in wind turbine wake applications. This results in an underprediction of the wake deficit. Key reasons for these shortcomings are that the eddy viscosity assumption is not valid in the near wake and that the anisotropic Reynolds stresses are not properly modeled. Also, the direct effects of the turbine forcing is not incorporated in the transport equations.<br/><br/>To address for these shortcomings, machine learning can be used to enhance the turbulence model with data-driven corrections. Recent developments showed for fundamental 2D flow cases that a novel algorithm referred to as SpaRTA (Sparse Regression of Turbulent Stress Anisotropy) can be used to discover sparse algebraic turbulence model corrections. These corrections could lead to improved mean-flow fields when trained on high-fidelity data. Disadvantages of SpaRTA are however that it can only cope with a limited input feature set and that the models have difficulty generalizing towards multiple flow regions simultaneously (e.g. free-stream and wake region).<br/><br/>To help resolve these disadvantages, mutual information, which is a measure from information theory that quantifies the general dependency between variables, is used to a priori measure the importance of a large number of features to the turbulence model corrections. As a result, the most important features can be used for correction model construction. In addition to this, to improve the model predictions in the turbine's wake, only the data samples located in the wake regions are used for training, discarding the free-stream data. Given that these data are discarded, it cannot be guaranteed that the correction models fit the trends in the free-stream. The correction models must therefore be neutralized by a newly constructed sparse algebraic logistic regression model, which distinguishes the wake from the free-stream region. The data used in this research consists of three time-averaged LES (Large Eddy Simulation) cases with multiple turbines on wind tunnel scale, under neutral conditions. <br/><br/>This thesis shows that mutual information can detect most of the essential features, which leads to a good match between the model predictions and the corrections derived from high-fidelity data. Discarding the free-stream samples during model training leads to a further reduction in error in the wake region, both in mean-squared as maximum-squared error of the correction terms. By implementing the constructed algebraic models into CFD, significant improvements in mean-flow fields are obtained compared to the linear κ-ε turbulence model. Nevertheless, there remains room for improvement as well as further research. Although the mean-flow fields match the high-fidelity data in the near wake closely, a discrepancy remains in the far wake.","RANS; CFD; machine learning; data-driven; sparse symbolic regression; classification; Regression; Wind Energy","en","master thesis","","","","","","","","","","","","European Wind Energy Masters (EWEM) | Rotor Design Track","",""
"uuid:eda9ff62-432c-45c5-9c49-f846b79789f0","http://resolver.tudelft.nl/uuid:eda9ff62-432c-45c5-9c49-f846b79789f0","Tool development &amp; validation for brand manifestation design","Yang, R. (TU Delft Industrial Design Engineering)","Hultink, H.J. (mentor); Bakker-Wu, S. (graduation committee); Delft University of Technology (degree granting institution)","2020","Nowadays, social media plays an increasingly important role in people’s daily lives. Many brands make use of it and send out different information, for instance, sales, event notifications and sometimes even their position on social issues through platforms like Facebook and Instagram. However, the process of developing these manifestations have many small problems and interaction among stakeholders are not quite efficient. For example, brand designers often come up against difficulties, like lacking references and “endless” adjustment with brand managers. For brand managers, they wish designers to explain the story/strategy behind manifestations and there are no clear criteria to evaluate if a brand manifestation is qualified. This master thesis explores the possibilities for improving the current process of brand manifestations design in the context of digital platform marketing, specifically for brand designers and managers in the internal branding department, and introduces a series of methods and recommendations for both brand managers and designers. Process of this graduation project is illustrated in the picture on the right. A literature review was conducted at the beginning of the project and from there I decided to focus on brand manifestation design for digital platform marketing. Then I choose the simplified grounded theory method, supplemented by session, as my research methods to explore the context and decide design direction. After research, with common problems and root causes being identified and three ingredients of a good manifestation being decided (balance between “brand fit” &amp; “innovative”, rationales behind visuals, and conveying right massages), I started the ideation phase to develop a series of methods which enable to enhance the experience of brand manifestation design in internal branding department. After idea iteration, conceptualization and two round of validation, three final concepts were developed and a new workflow was created. Future recommendation, as well as discussion, were proposed in the last chapter.","brand manifestation design; digital marketing; social media; new workflow; tool development; standards","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:35db50c3-bd72-4471-ba57-308deb36f8e7","http://resolver.tudelft.nl/uuid:35db50c3-bd72-4471-ba57-308deb36f8e7","Robust energy production optimization of a wind farm using wake steering by calibrating the FLORIS model on SCADA data","van Beek, M.T. (TU Delft Aerospace Engineering)","Viré, A.C. (mentor); von Terzi, D.A. (graduation committee); Simao Ferreira, C.J. (graduation committee); Andersen, Søren (mentor); Delft University of Technology (degree granting institution)","2020","Wind farms experience significant efficiency losses due to the aerodynamic interaction between turbines. A possible control technique to reduce these losses to a minimum is yaw-based wake steering. This thesis investigates the feasibility of this technique by calibrating a surrogate model called the FLOw Redirection and Induction in Steady-state (FLORIS) model on a data set from the Lillgrund wind farm and using it to estimate the potential energy gain. The data set available is processed methodically to remove outliers and erroneous data points, resulting in a reliable and useful data set. It is used to obtain free stream wind conditions per time step and relate those to power measurements. The data set is consequently used to calibrate the tuning parameters of the FLORIS model. The calibration is done using a newly proposed method that determines the tuning parameters per combination of wind speed and turbine spacing. A difference with commonly applied calibration methods is that power measurements are used instead of predicted powers or flow field data from high-fidelity models. The performance of the calibrated model is tested through multiple uncertainty analyses. It is found that the model has a significant bias but low uncertainty by comparing the predicted wake losses with measured wake losses. This bias can potentially be reduced if atmospheric stability is taken into account. With the bias and uncertainty quantified, the FLORIS model is used to optimize the annual energy production of the Lillgrund wind farm by finding the ideal yaw angles for specific inflow conditions. A significant energy gain can be achieved when the optimal yaw angles are determined deterministically. However, the energy gain decreases drastically when uncertainty in input conditions is considered, showing that these yaw angles are not robust in terms of performance under uncertainty. More robust yaw angles can be obtained when the input uncertainty is taken into account during the yaw optimization. The energy gain achievable with these more robust yaw angles is approximately 3.4%. Therefore, it can be concluded that achieving an energy gain using yaw-based wake steering is feasible for the Lillgrund wind farm.","Wind; Uncertainty Analysis; wake steering control; FLORIS; Lillgrund; Robust Optimization; Wake; Control; Energy; Power; Wind turbine","en","master thesis","","","","","","","","","","","","European Wind Energy Masters (EWEM)","",""
"uuid:80c1b078-b8ca-4c29-b0ba-866fdc5f656b","http://resolver.tudelft.nl/uuid:80c1b078-b8ca-4c29-b0ba-866fdc5f656b","Predicting software vulnerabilities with unsupervised learning techniques","Man, K.W. (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Cyber Security)","Verwer, S.E. (mentor); Panichella, A. (mentor); Lagendijk, R.L. (graduation committee); Delft University of Technology (degree granting institution)","2020","As software is produced more and more every year, software also gets exploited more. This exploitation can lead to huge monetary losses and other damages to companies and users. The exploitation can be reduced by automatically detecting the software vulnerabilities that leads to exploitation. Unfortunately, the state-of-the-art methods for this automated process are not perfect and thus more research is needed to address this issue.<br/><br/>This research was partly done at ING, one of the banks of The Netherlands, in order to find a software vulnerabilities prediction method that is more efficient than their already deployed static code analysis tool Fortify Static Code Analyzer. This report proposes a method to predict software vulnerabilities in code using unsupervised learning methods. The data set is comprised of software metrics of code written by developers of ING, in conjunction with its corresponding label whether the code was vulnerable or non-vulnerable, confirmed by a security expert. Principal component analysis reduced the dimensions of the data set. From here on, the unsupervised learning technique k-means was used to build our prediction model and a distance-based anomaly detection technique was applied to find the software vulnerabilities. This produced poor results. In a final attempt to find better results, k-nearest neighbor was used to build a new prediction model and another distance-based anomaly detection technique was applied. The outcome of this latter method was surprisingly good.","k-means; unsupervised learning; software fault prediction; software vulnerability detection; k-nearest neighbors; Fortify; anomaly detection; clustering","en","master thesis","","","","","","","","","","","","","",""
"uuid:494fa652-2125-4352-aeba-041eebcefde9","http://resolver.tudelft.nl/uuid:494fa652-2125-4352-aeba-041eebcefde9","Improving the breakwater design process by using a design automation tool","Winkel, S. (TU Delft Civil Engineering and Geosciences)","Hofland, B. (mentor); Voorendt, M.Z. (mentor); van Nederveen, G.A. (mentor); Kelkitli, M.I. (mentor); Delft University of Technology (degree granting institution)","2020","In the current breakwater design process, not all feasible concepts can be explored due to time constraints. However, designers are also influenced by breakwaters constructed near, or at the same location as their breakwater project. But also conservative assumptions influence the breakwater design process, for instance, regarding the wave height and water depth for which caisson and rubble mound breakwaters are both economical feasible. This results in a suboptimal design, which can result in losing a tender.<br/><br/>By developing a design automation tool more concepts can be generated in the same period, allowing designers to explore more concepts during tenders. However, before developing a design automation tool one must first understand the process to be automated. Therefore, interviews with experienced designers have been conducted to investigate how they design, i.e. what is their design approach and how do they generate and select concepts. <br/><br/>It appeared that the practical breakwater design approach relies on the experience of designers since engineering judgement and experience were mentioned as the preferred methods for the selection of the most promising concept. Furthermore, the designers described an iterative approach for generating concepts during the conceptual design phase, but they did not explicitly stated that these iterations were part of their design approach, indicating that experienced designers automatically perform the required steps. <br/><br/>During the interviews, it also became apparent that implementing a probabilistic design approach is unwanted by designers. According to the interviewees, this results in a too conservative and too expensive design, which can result in losing the tender. They also reported that there is a lack of data, which likely results in the designers making conservative estimates to compensate for the missing data. However, this research did not investigate if conservative estimates are made when data is missing, and therefore requires further research.<br/><br/>Based on the interviews a design automation tool was developed which can design rubble mound, caisson, and vertically composite breakwaters. Because of the importance of experience the decision was made to automatically selects concepts. This to give the largest freedom to the designer so that his experience is incorporated in the process, while using the benefits of automation for the quick generation and verification of concepts, resulting in a semi-automatic design process. <br/><br/>The developed tool was verified and validated by interviewing experienced breakwater designers. From a document and code inspection, it was concluded that the new tool fulfilled all requirements. During these interviews, the designers stated that they would be able to use the developed tool in their design approach. One of the main advantages of the tool is that it was able to quickly design concepts, 0.14s per concept, and made it possible to explore the influence of parameters on the design and cost. This enabled designers to explore more concepts and assess the feasibility of different breakwater types, and thus enabled them to generate a better design. Therefore, it can be concluded that the developed design automation tool can indeed improve the breakwater design process.<br","breakwater; design automation; parametric design; interviews; design; python; hydraulic engineering; design method; concept design; concept exploration; design process; rubble mound breakwater; caisson breakwater","en","master thesis","","","","","","The developed tool in this research is called breakwater and is available under the CC-BY-NC-SA 4.0 license on PyPI and GitHub. Documentation of the Python tool developed in this research: https://breakwater.readthedocs.io. Source code of the Python package developed in this research: https://github.com/Sander-w/breakwater/. PyPI link to the Python package developed in this research: https://pypi.org/project/breakwater/","","","","","","","",""
"uuid:08fa3e3c-2726-4537-884a-9079cf508367","http://resolver.tudelft.nl/uuid:08fa3e3c-2726-4537-884a-9079cf508367","Empowering young change-makers: A tool that enables children activation in their community through a child-led approach","Miccolis, S. (TU Delft Industrial Design Engineering)","Gielen, M.A. (mentor); Calderon Gonzalez, A. (graduation committee); Delft University of Technology (degree granting institution)","2020","Children's participation in society is still limited without the establishment of appropriate areas, and the possibility to access the spheres of urban activism, children risks to remain invisible citizens. While children don't get the chance to unleash their creative talents in the innovation playground society is turning into, society lacks their contribution as playful and constructive disorganizers of the world. Based on those background premises, the current project focuses on exploring how children can participate in society without a top-down involvement and how they can be supported in the process of empowerment as active agents in their social and urban context. The opportunity for the project inquiry was found in collaboration with a children center in the outskirt of Bari (Italy), a frontrunner of the Urban civic networks project aimed at promoting urban and human regeneration in a neglected context, where the sense of powerlessness over positive transformations is handed down to children. A research through design approach was utilized to achieve the project goal: design a tool that enables 6 to 12 years old children to undertake an activation journey to take action towards prosocial challenges meaningful for themselves and their community. In the initial research cycle, desk research and comparative analysis of 6 different case studies of toolkit and programs were performed to unveil how children's empowerment could be supported by design. The resulting map of ideal empowering strategies allowed to identify some pillars of children activation process to inform the following cycles. Among those, the community perception, the unlocking of I can mindset and opportunities for action were the object of the research through design interventions, together with the open endedness of the activation process disclosed along with the two iterations. The insights collected converged into children's intuitive, creative activation journey, including gaps, enablers, and needs they experienced along it. They also contributed to enriching the requirements list for the tool's design. During the ideation the leading research outcomes were embodied in the final tool proposal ""Il Priscio"", activities set for young positive change-makers, that propose them a child-led activation through 5 main steps: raising I can, finding relevance in opportunities for change, becoming protagonists, powers-driven ideation and practicing courage. The tool suitcase board contains 14 activity cards with open-ended steps to perform and additional materials to support the experience, such as a platform to practice courage by sharing the results of the powers-driven ideation. The partial test of the tool in the context of the Urban civic network, set up as a third design intervention, acted as a launchpad for children self-activation. Although the implementation in the context of civic associations is envisioned, the tool opened up further research direction about children's self-esteem, the communicative potential of their imaginative interventions, constructive communication with policymakers, and the addition of levels of ambiguity to the tool journey.","Play Well Lab; Participatory City Making; Delft Design Labs; Children empowerment; Urban civic networks; Child-led approach; Tool kit; change-makers","en","master thesis","","","","","","","","","","","","","",""
"uuid:7e049139-bfb9-4d08-bb0c-024e13caec09","http://resolver.tudelft.nl/uuid:7e049139-bfb9-4d08-bb0c-024e13caec09","Booking and Payment Integration of Air- and Public Transport for First/Last Mile Airport Trips: A Conceptual Framework and Business Model Canvas","Schuiling, J.H.N. (TU Delft Civil Engineering and Geosciences)","van Arem, B. (graduation committee); van Oort, N. (graduation committee); Veeneman, W.W. (graduation committee); Honingh, Arjan (graduation committee); Delft University of Technology (degree granting institution)","2020","In this research, the link between air travel and the first/last mile trip with public transportation will be researched, as in practice, ticket platforms (such as Booking.com or Expedia) do not yet provide this integrated air- and public transport service. Eventually, the idea would be to create an integration platform that serves as a mediator to integrate booking and payment of air- and public transport tickets. As a result, travellers normally booking an airline ticket for airport-to-airport travel, would then be able to buy an integrated ticket involving air- and public transport for travelling from origin to end destination. This research therefore has used methods to judge the feasibility and desirability for this idea, namely a literature review regarding this topic, desk researches, a survey for travel preferences regarding this integration, a stakeholder analysis, and interviews with potential linked parties and governance experts. Eventually the end goal is coming up with a conceptual framework that shows the most important factors regarding the feasibility and desirability of this integration platform, and a business model canvas. It can be said that integrating booking and payment of air- and public transport tickets can be feasible and that certain (shares of) parties think it is or find it desirable. However, the conceptual framework and business model canvas displayed a high amount of important factors, which mostly need to fall into place at the same time. Results of the survey indicated positive reactions, but the question will still be if in reality this interest from potential users will play out. Also, technological developments regarding payment in public transportation can jeopardise this initiative. All in all, risks of this integration platform for potential initiators are not excluded.","Aviation; Public Transport; Multimodality; Ticket Integration; First/Last Mile Airport Trips","en","master thesis","","","","","","","","","","","","Transport, Infrastructure and Logistics","",""
"uuid:17e0d3ec-c6ab-456d-b241-87148e77379a","http://resolver.tudelft.nl/uuid:17e0d3ec-c6ab-456d-b241-87148e77379a","Stimulating Flexibility in Construction Project Management in terms of planning and decision-making","Surve, Madhura (TU Delft Civil Engineering and Geosciences)","Bakker, H.L.M. (Hans) (graduation committee); Heintz, J.L. (John) (graduation committee); Jalali Sohi, A. (mentor); Dijkman, Erik (graduation committee); Delft University of Technology (degree granting institution)","2020","Even after many developments in project management tools and techniques, there is still a loophole in the traditional approaches, due to which it is no longer effective for managing projects in a dynamic environment. As a result, there is a rising urge amongst the practitioners to implement flexible approaches in large complex projects for its successful completion. However, there is a lack of practical recommendations on how to add flexibility into practice in the construction industry. Thus, the objective of this research is to contribute to the knowledge of flexible project management in the construction industry by identifying the flexibility enablers that can be incorporated in practice, investigating the barriers in its incorporation and providing practical recommendations to overcome them.In this research, five flexibility enablers- iterative planning, iterative delivery, short feedback loops, late locking and continuous locking, have been analyzed and investigated for its application in the infrastructure and healthcare real-estate projects. A case study methodology was adopted to conduct this research. Further, this research has identified 30 barriers that occur in the identification and implementation of flexibility enablers. These barriers were mainly classified into five clusters- Lack of awareness/methodologies, Change resistance, Organizational behaviour, Management processes and Miscellaneous. The research findings suggest the five enablers are not well-established in the construction industry, and there are not many methods available to incorporate these enablers. As a result, it lacks recognition and incorporation in practice. One of the main findings of the research is: planning-based enablers (iterative planning &amp; iterative delivery) are more preferred in the infrastructure sector, while decision-based enablers (late locking &amp; continuous locking) are more preferred in healthcare real-estate sector. Most of the barriers in implementing the enablers occurred as a result of lack of awareness and methods to implement them as well as resistance to change to a new and flexible way of working from the traditional approaches.In order to stimulate the incorporation of flexibility enablers and make them explicit, it is necessary to overcome the barriers that occur in its implementation. This research has proposed a conceptual framework following a linear step-by-step approach of creating awareness, providing insights, encouraging teams and implement these enablers, and further proposed suggestions to overcome the most commonly identified barriers. As the main idea behind stimulating flexibility by incorporating flexibility enablers was to identify and overcome the barriers that occur in its incorporation, hence adopting the proposed framework helps in achieving flexibility in construction project management.","Flexibility; Project Management; Planning; Decision-making; Agile; Late-locking; Infrastructure; Healthcare real estate; Iterative; Construction; Framework","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:a1e354f4-dfb3-4990-8a0a-4e15b3b72ba9","http://resolver.tudelft.nl/uuid:a1e354f4-dfb3-4990-8a0a-4e15b3b72ba9","A Machine Learning Model for Normal and Extended Taxi-Out Time Prediction: Vienna Airport Case Study","Probyn, Michael (TU Delft Aerospace Engineering)","Roling, P.C. (mentor); Herrema, Floris (graduation committee); Delft University of Technology (degree granting institution)","2020","All major airport operators face a similar challenge, namely ensuring maximum throughput and maintaining high runway utilisation. A key part of this is accurately planning aircraft movements on the ground to avoid queueing and associated delays. A primary indicator of the operator performance in this area is the Taxi-Out Time. The research objective of this article is to review whether the application of machine learning can be used to model the departure process in such a way as to provide accurate prediction of TXOT taking into account a wide range of variables. A regression tree type machine learning model is developed using actual data from Vienna Airport and a selected set of significant predictor variables. The taxi-out times of the test set of flights are closely predicted with an RMSE of 2.03 minutes for normal taxi-out and 3.75 minutes for extended taxi-out.","Machine Learning; Taxi-Out Time; Airport Operations","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:5833d367-3481-4e31-9249-4efa3068ba08","http://resolver.tudelft.nl/uuid:5833d367-3481-4e31-9249-4efa3068ba08","Redesigning Client Acquisition through Experience","Schouten, J.E. (TU Delft Industrial Design Engineering)","Hultink, H.J. (mentor); Baha, S.E. (mentor); Meijer Zu Schlochtern, A.N.H. (mentor); Delft University of Technology (degree granting institution)","2020","This report describes the process and outcomes of a graduation project for the MSc program Strategic Product Design. The client organization in this project is Innovation Booster (IB). IB, founded in 2012 and located in Amsterdam, is specialized in innovation services. IB is active in segments characterized by traditional and complex organisations. IB offers Entrepreneurial Innovation which consists of three types of expertise services: Innovation Strategies, Business Innovation and Behavioural Innovation.<br/><br/>At the beginning of this project, IB was struggling with their client acquisition. Their sales calls were prepared ad-hoc and IB’s salespeople did not have the required knowledge about potential clients and their context. This resulted in insufficient acquisition, a too low success rate from sales calls and a too expensive and time consuming overall client acquisition process. Subsequently, growth, scalability and continuity could not be ensured. What IB needed was a tool for successful proactive acquisition that leads to high success rates. With high success rates IB could achieve a continuous flow of challenging projects required for growth, scalability and continuity. The tool should provide them the required knowledge, structure and focus for preparing sales calls. Therefore, the initial design challenge was stated as follows: <br/>“Develop a tool for proactive client acquisition that provides the required knowledge, structure and focus for high success rates from sales calls.”<br/><br/>An experience workshop is designed that lets potential clients experience IB’s way of working. The process of the experience workshop is based on literature on reflection, the iterative cycle of Design Thinking and the 1-10-100 method. The experience workshop is preceded by six preparation steps and is succeeded by a follow-up step. Together, the experience workshop, its preparation and follow-up steps form a proactive approach to client acquisition. The process of this proactive client acquisition approach is based on needs of the salespeople of IB and literature on client acquisition, sales and marketing models. The proactive client acquisition approach maps out each step of client acquisition, accompanied by the goal and desired output of each step, and how to realize this output. The approach provides structure and focus in IB’s acquisition process, accompanied by pragmatic tools that support IB in realizing their acquisition goals. With the new approach, IB’s salespeople have the required knowledge about the potential client’s organisation and industry before approaching the potential clients. <br/><br/>The experience workshop is tested and validated with three potential clients from three different organizations through non-participant observation and semi-structured interviewing. Furthermore, the proactive client acquisition approach, including the experience workshop, is validated through a co-reflection session with four people from both the Project Management and New Business Development departments of IB. The validation study concluded that clients become impressed and enthusiastic about cooperating with IB after participating in an experience workshop. In addition, the first pilot have shown that the experience workshop leads to a less expensive and time consuming overall client acquisition process.<br/><br/>For a successful implementation of the proactive client acquisition approach, an internal communication and organisation plan is proposed. In this plan, the different roles and responsibilities are described that are required for a successful implementation and maintenance of the proactive client acquisition approach in the future. <br","acquisition; client acquisition; experience design; process design; strategic design; customer experience; reflection","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:4db140e9-253e-4a86-b0b1-3579a16da69d","http://resolver.tudelft.nl/uuid:4db140e9-253e-4a86-b0b1-3579a16da69d","Innovating Airport Passenger Terminals: Determining the feasibility of new terminal concepts based on seamless flow technology","de Graeff, J.C. (TU Delft Civil Engineering and Geosciences)","van Wee, G.P. (graduation committee); Vleugel, J.M. (mentor); Baggen, J.H. (mentor); Delft University of Technology (degree granting institution)","2020","The continuing growth in air travel passengers, in combination with enhanced security regulations, has led to unsustainable situations at airports. In order to handle the future amount of air travel passengers while complying to security regulations and enhancing the passenger experience, the terminal system must be innovated. Seamless flow is a future end-to-end continuous, efficient and secure innovation which uses passenger biometrics for identification throughout the airport processes. Previous research is focused on fitting the new seamless flow technology in with the conventional airport processes. This research explores whether the biometric technology could lead to new, and feasible, passenger terminal concepts. Two new seamless flow concepts are constructed and assessed on their feasibility by conducting interviews with stakeholders, performing desk-research and executing a financial Cost-Benefit Analysis. The research findings indicate that the new technology could lead to feasible, efficient and experience enhancing passenger terminal concepts in comparison to the conventional terminal concept equipped with seamless flow technology. Thereby, the support of - and collaboration between - stakeholders, especially the border guard agency, is shown to be essential for the implementation of seamless flow technology on civil airports. Besides that, it is shown that more efficient terminal concepts could significantly benefit airports through increased commercial opportunities.","Airport Design; Passenger experience; Seamless flow; Biometric technology; Terminal concept","en","master thesis","","","","","","","","","","","","","",""
"uuid:b1438a6d-6814-49a1-8798-4082ac01da16","http://resolver.tudelft.nl/uuid:b1438a6d-6814-49a1-8798-4082ac01da16","Stability of rock on mild slopes","van Wijland, Bas (TU Delft Civil Engineering and Geosciences)","Hofland, B. (mentor); Kuiper, C. (graduation committee); Lindenbergh, R.C. (graduation committee); van Gent, Marcel R.A. (mentor); Jumelet, H.D. (mentor); Wendt, E.A.F (mentor); Delft University of Technology (degree granting institution)","2020","Until now, an extensive design method for mild slopes has not been available. The aim of this thesis is to understand the stability of rock on mild slopes under wave attack for impermeable cores in order to optimize designs. Physical model tests have been executed to study this stability for a 1:8 slope. Mossinkoff (2019) executed physical model tests for a 1:10 slope and a re-analysis of these tests is included in this thesis as well. Damage caused by entrained rocks is quantified by damage parameters using stereophotogrammetry and coloured rocks in strips. In this study, the influence of several hydraulic and structural parameters on damage parameters has been investigated for mild slopes. A positive correlation has been found between the significant wave height and the damage parameters. Besides this, based on the analysis it can be concluded that the wave steepness and damage parameters are negatively correlated. An increase in layer thickness of the rocks does not seem to increase the stability of rock on mild slopes. However, the slope angle does have an effect on the stability as a milder slope is associated with less damage. Another conclusion is that more damage continues to be observed even after 15 000 waves. Based on the results of the physical model tests, a design formula is developed for mild slopes to be able to increase efficiency in designs of coastal structures for these mild slopes. This study also provides evidence that rocks on mild slopes have different characteristics of damage and damage development compared to steep slopes. The largest share of entrained rocks transport in upward direction and rocks on mild slopes seem to be more mobile compared to steep slopes. This suggested that it might be more efficient to study the moment when the filter layer or the core becomes visible instead of the static stability of rock within the armour layer itself.","rock protection; plunging waves; spilling waves; mild slopes; damage parameter","en","master thesis","","","","","","","","2021-08-20","","","","Civil Engineering | Hydraulic Engineering","",""
"uuid:1cbdfe69-d654-4cde-820b-6ed6641adf92","http://resolver.tudelft.nl/uuid:1cbdfe69-d654-4cde-820b-6ed6641adf92","Optimising Grid Topology Reconfiguration using Reinforcement Learning","Subramanian, Sai Medha (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Electrical Sustainable Energy; TU Delft Intelligent Electrical Power Grids)","Tindemans, S.H. (mentor); Viebahn, Jan (mentor); Rueda, José L. (graduation committee); Spaan, M.T.J. (graduation committee); Delft University of Technology (degree granting institution)","2020","The de-carbonisation of the energy system, more commonly known as the 'Energy Transition' has a vital role to play in the pursuit of mitigating the climate emergency’s impact. There is a global trend of moving toward making power systems more future-proof and this largely affects the roles and activities of a Transmission System Operator (TSO) such as TenneT.<br/><br/>The particular branch of power grid control and operation is one that is undergoing a massive overhaul. Control room operators are highly-skilled and need to be aware of all the physical processes involved in the power system in order to manually intervene when necessary. They are constantly monitoring the grid and are tasked with making quick decisions with a high frequency which rely on many factors such as the expected active power of conventional generator units, the expected demand and also the renewable energy forecasts for a given time instant. One important action that is often considered by the control room operators is reconfiguring the network topology. Making topological changes to the network offers a flexibility that is an under-exploited and low-cost alternative to maintain network security. These operational tasks are getting more complex and nuanced with the addition of newer technologies. <br/><br/>There is specifically an increasing reliance on Information, Communication and Technology (ICT) and newer smart grid technology which can assist in many ways such as higher levels of automation, increase in computation speed and so on. One particular field of study under the umbrella of ICT is the application of Artificial Intelligence (AI) solutions. These solutions have the potential to pave the path to better cyber-physical systems with which large strides can be made to cope with many challenges introduced by the 'Energy Transition'. <br/><br/>Various initiatives are being undertaken in this realm. One such initiative being Réseau de Transport d’Électricité (RTE)’s initiative of  ""Learning To Run a Power Network (L2PRN)"" competition. This competition was conducted with the primary goal of introducing and recognising the potential of AI and machine learning-based tools in order to support control rooms and assist in making optimal decisions. One particular branch of AI that has shown great promise in the field of decision support is Reinforcement Learning.<br/><br/>This competition acts as a great starting point to bring together these two almost exclusive research communities. The research conducted in this thesis uses this competition as a stepping stone along with the tool chain developed for it, to investigate the use of an AI-based solution and test the behaviour of the agent, not just from a machine learning point of view, but also from a power system perspective. This thesis addresses the potential of machine learning as a decision support tool for power system control rooms by implementing a reinforcement learning algorithm to represent an artificial control room operator and assessing its performance on a particular IEEE test network. This thesis also hopes to provide some groundwork for TenneT and to contribute toward a ‘Control Room of the Future’ initiative which can incorporate such an AI-based decision support tool to assist grid operators in taking well-informed actions during the operation of the power systems.<br","Network topology; Power grid operation; Reinforcement learning; Decision support tool","en","master thesis","","","","","","","","2021-08-20","","","","","",""
"uuid:08d14381-dd79-461c-91bc-a537555e4d2c","http://resolver.tudelft.nl/uuid:08d14381-dd79-461c-91bc-a537555e4d2c","Planning for the Transition to Clean Shared Mobility: Leveraging System Dynamics as a Tool for Urban Policy Development","Bearden, Matthew (TU Delft Architecture and the Built Environment)","van Arem, B. (mentor); Stead, D. (mentor); Meijers, E.J. (mentor); Delft University of Technology (degree granting institution); Wageningen University & Research (degree granting institution)","2020","This research aims to evaluate the policies and strategies that cities can deploy to facilitate the transition to clean shared mobility. The literature review supports the research through providing insights into the direction of the shared mobility market, charging infrastructure, electric vehicle development, charging behavior, as well as existing government and policy instruments and spatial considerations for charging infrastructure. Using metrics, such as uptake in electric vehicles and deployment rate of shared mobility services, a baseline analysis is conducted to establish recent trends in this field for the case study of Amsterdam. Next, the development of the system dynamics model provides insights into the interactions between the various aspects of the personal and shared mobility system that can be used to evaluate potential policy scenarios. Amsterdam’s (2019a) Clean Air Action Plan and similar goalsetting plans provide targets to which policies must be steered; therefore, the policies or policy packages to achieve the goals set can be developed via backcasting. Leveraging the four scenarios from the Netherlands Environmental Assessment Agency (PBL), four potential policy packages are developed in accordance with the governance, sustainability, and technological directions prescribed (PBL, 2019). These policy packages are then used in the system dynamics model, which accounts for stakeholder behavior, to evaluate the packages’ effects on the carsharing market, electric vehicle market share, parking and spatial considerations, and charging infrastructure demands. Based on the case study considered for the City of Amsterdam, the resulting trends show that the policy packages evaluated facilitate carsharing as a conduit to drastically reduce the market share of personal vehicles and are critical to the shift towards electric vehicle market dominance. The results can then be compared to inform the relative effectiveness of the policy packages considered. While there are limitations to the study, the model provides a beneficial tool for governments to evaluate effectiveness, side-effects, and constraints of transitioning the personal vehicle market towards a more sustainable future.","","en","master thesis","","","","","","Joint Master of Science in Metropolitan Analysis, Design and Engineering at Delft University of Technology and Wageningen University & Research.","","","","","","Metropolitan Analysis, Design and Engineering (MADE)","",""
"uuid:b889d3d0-a338-4cbc-9d6b-82ebbd060a6b","http://resolver.tudelft.nl/uuid:b889d3d0-a338-4cbc-9d6b-82ebbd060a6b","Exploring self-organisation for car-sharing systems: An agent-based approach","Stork, Casper (TU Delft Technology, Policy and Management)","Warnier, Martijn (graduation committee); Ghorbani, A. (mentor); Delft University of Technology (degree granting institution)","2020","Cities are getting more congested and polluted as they grow; transportation is one of the contributors to this. Mobility-as-a-Service (MaaS) could revolutionise the transportation sector for people. In MaaS, the car-sharing schemes will play a vital role and can help in reducing greenhouse gas emissions. Moreover, in the long-term, these services will decrease congestion in the cities. Nevertheless, business models that have evolved around car-sharing have not always proven to be economically sustainable. In this research, the current institutional settings and characteristics of the car-sharing system are reviewed. After that, car-sharing is examined as a Common-Pool Resource so that they can be managed as such resources. Ostrom has proved that there are many cases where the common pool resources are sustained through the self-organisation of the management of these resources. This self-organisation will be explored for the car-sharing system by testing the influence of the presence of the design principle. The design principles are similarities that are found in self-organising systems and can serve as guidance for the robust management of common-pool resources. To explore the effects of the design principles, an Agent-Based Model is constructed of a car-sharing service. The model was built based on literature, and the design principles on boundaries, equivalence between benefits and costs, collective choice arrangements, monitoring, and graduated sanctions are implemented in the model. The results were analysed with correlation tables and show that the design principle of having collective choice arrangements have a positive effect on the profit of the companies. However, the satisfaction of the users has not been improved by the presence of this design principle. The design principle on graduated sanctioning was implemented and decreased the profit but did not affect the satisfaction rate of users. With these results, it was concluded that there is reason to believe that the car-sharing system can benefit, depending on the rules that are created, from the implementation of the design principles. Furthermore, therefore, further research on the systems institutional settings centred around on self-organisation can be done with the application of the design principles as guidance. The scientific contribution of this thesis is studying of car-sharing as a common-pool resource. This fulfils the knowledge gap that existed in the current research on common-pool resources. Next to that the exploration of the possibilities for self-organisation of car-sharing by implementing the design principles in an agent-based model of a car-sharing system is done. From a social perspective, the study explores the car-sharing system, which has the potential to solve problems with congestion and emissions in cities. In future research, the model could be extended and based on actual data to reveal more in-depth knowledge on the influence of the design principles of a real-world car-sharing system. This could encourage car-sharing companies to investigate the possibilities for self-organisation. Moreover, the Smart-CPR concept could be further implemented in the model of car-sharing and explore the effects of sharing resources for car-sharing.","Common-pool resources; Governance; Car-Sharing; Agent-based modelling","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:38eb2da8-c1cf-414f-a57c-753af89074f6","http://resolver.tudelft.nl/uuid:38eb2da8-c1cf-414f-a57c-753af89074f6","Institutional interactions in climate adaptation of interdependent transport infrastructures: The case surrounding the Port of Rotterdam","Mesdaghi, Batoul (TU Delft Technology, Policy and Management)","Ghorbani, A. (mentor); Bots, P.W.G. (graduation committee); de Bruijne, M.L.C. (graduation committee); Delft University of Technology (degree granting institution)","2020","Transport infrastructures that connect ports to the hinterland are important enablers of economic growth and development in the region. Therefore, infrastructure owners and governments on different levels are engaging in climate adaptation to adapt transport infrastructures to actual or expected climatic hazards. Existing research on the institutional dimension of climate adaptation had exclusively focussed on trying to understand whether existing institutions allowed and encouraged actors to develop and realize adaptation strategies, and as a result, enhance the adaptive capacity of society. However, the connectivity and interdependencies between institutions that guide actors in their decision-making had not been studied. This research therefore improved and applied the Institutional Network Analysis (INA) method to understand how the various public and private parties interact with each other for climate adaptation of transport infrastructures connected to the Port of Rotterdam.","Climate Adaptation; Institutional Networks; IAD framework; Institutional Analysis","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:78a1147b-e97b-418f-a5e6-3ce944df4f49","http://resolver.tudelft.nl/uuid:78a1147b-e97b-418f-a5e6-3ce944df4f49","Design a socialVR tool for the remote co-design of customized cakes","Mei, Y. (TU Delft Industrial Design Engineering)","de Ridder, H. (mentor); Cesar Garcia, P.S. (mentor); Li, J. (mentor); Delft University of Technology (degree granting institution)","2020","Nowadays, co-design is progressively popular in the area of customized retail services. Co-design involves users and potential customers into the whole process of product design, from ideation to final design, and thus, has a great potential in offering a personalized customer experience based on the individual needs and behaviors. However, usually co-design requires face-to-face communication, which might be difficult especially in the current corona time. Additionally, it is a challenge for the customer, the non-expert designer to equally collaborate with professional designers. Therefore, a tool is needed to support remote co-design actions and expower the non-expert users for an equal cooperation with designers. <br/><br/>We propose that socialVR, an emerging mediated social interaction technology in the medium of Virtual Reality, has a potential in supporting remote and interactive co-design activities. Social VR technology enables users in different locations to interact with virtual avatars of other users in a collaborative Virtual Environment. Additionally, socialVR allows users to communicate with each other through diverse communication cues (i.e., 3d visual, audio, haptic), and hence, supports intricate social and physical interactions in co-design. <br/><br/>In this project, we aim to explore how socialVR can facilitate co-design, and understand how socialVR influences people’s experience and behavior in remote collaborative design tasks To find out the answers, we follow a research-through-design methodology. Firstly, we choose a specific use case of collaborative cake-making between cake-makers and clients for the purpose of customized retail. Then, based on the current interaction between baker and clients, we designed and developed a medium-fidelity VR prototype, which allows two users collaboratively design cakes in VE wearing head-mounted displays (HMDs). After that, we performed a VR test for user evaluation, so as to investigate the impacts of socialVR on social and collaborative behavior, as well as validate the functionality and interaction techniques of this prototype. The results offer abundant insights for us to understand the how design non-experts experience interacting with professional designers and design systems in socialVR, and how their experience influences their behavior.<br","socialVR; co-design; Mass customisation","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:7438705a-da39-4f21-b8c0-8ee57faa47c1","http://resolver.tudelft.nl/uuid:7438705a-da39-4f21-b8c0-8ee57faa47c1","Surrogate Constitutive Models with Multi-fidelity Gaussian Processes for Composite Micromodels","Turan, O.T. (TU Delft Civil Engineering and Geosciences)","van der Meer, F.P. (mentor); Barcelos Carneiro M Da R, I. (mentor); Bessa, M.A. (mentor); Delft University of Technology (degree granting institution)","2020","Various engineering applications rely on efficient, high performance materials to overcome design challenges. This high performance can be achieved by engineering micro-heterogenous materials also known as composites. Since the behavior of composites relies heavily on micro-scale interactions between different components, modeling macrostructures with fully-represented microscopic geometry is needed. Thus, the standard finite element modeling approach becomes impractical. Computational homogenization, also known as concurrent finite element analysis (FE$^2$), is a method that is employed to model materials with distinct multi-scaled structure. FE$^2$ employs the concept of embedding a representative volume element (RVE), at each integration point of the macro-scale problem and obtaining the macroscopic constitutive behavior through homogenization, thus bypassing the need to develop a macro-scale constitutive model. Although it succeeds in upscaling the microscopic material behavior accurately, this method comes with the major drawback of being computationally expensive due to its nested structure. Developing methods to bypass the aforementioned computational bottleneck of FE$^2$ is an ongoing research endeavor. Employing machine learning algorithms to create surrogate constitutive models for microscopic behavior is one possible approach. However, creating surrogate models is not an easy task. A thoroughly collected training set is needed for the surrogate model to be representative. Thus, investigation of surrogate model creation strategies with machine learning while trying to reduce the computational burden of this \textit{offline} training process is a compelling area of study. Gaussian Process Regression (GPR) is a probabilistic machine learning model. It can be utilized to create surrogate constitutive models effectively in the aforementioned context. Moreover, the computational burden of the training procedure can be decreased by extending the conventional GPR technique into a co-kriging regression with multi-fidelity information (multiGPR). This surrogate modeling strategy reduces the need to collect high-fidelity information by collecting information from a low-fidelity model thoroughly. Thus, enabling accurate training datasets to be created from a less representative, but computationally less taxing models. In this work, the multiGPR approach is used to construct accurate and efficient surrogates for the behavior of fiber-reinforced composite materials. Training data is obtained from selected RVE configurations that consist of linear-elastic fibers randomly embedded in a matrix that has pressure-dependent plasticity and used to train single and multi-fidelity GPR constitutive models. Both approaches are trained with various combinations of loading scenarios and their prediction capabilities are investigated to represent the training cases in addition to their prediction capabilities under unseen load cases.","FE2; Surrogate Modelling; Machine Learning; Gaussian Process; Composite Material; Constitutive Model; Multi-fidelity; Co-Kriging; Neural Network","en","master thesis","","","","","","","","","","","","","",""
"uuid:dcb92174-78ab-4da9-b47d-c69cc834d397","http://resolver.tudelft.nl/uuid:dcb92174-78ab-4da9-b47d-c69cc834d397","Turbulent drag reduction through spanwise wall oscillation: An experimental investigation by Tomographic PIV","Bermel, Leon (TU Delft Aerospace Engineering)","Scarano, F. (mentor); Ujjaini Kempaiah, K. (graduation committee); Delft University of Technology (degree granting institution)","2020","Turbulent boundary layers are responsible for up to 89 % of the skin friction drag of civil aircraft. This shows that in regard to the current social sensitivity towards climate friendly aviation a reduction of tur- bulent skin friction could have a large impact. On the one side greenhouse gas emissions by aviation could be reduced and on the other hand fuel costs could be saved, an important consideration for air- lines. The research on turbulent drag reduction distinguishes between passive and active techniques. Passive techniques have the advantage that no energy input is necessary. Prominent examples are riblets and dimples which have shown turbulent drag reductions up to 10 %. Active techniques reach turbulent drag reduction percentages of up to 45 %, however it is in doubt if the energy savings are larger than the energy required to operate the control technique. One promising active technique which has proven to partially generate a positive energy effect is spanwise wall oscillation. However, researchers have opposing opinions of the mechanism which leads to the drag reduction. As turbulent boundary layers are strongly three-dimensional, the work of this thesis investigates three-dimensional flow fields of turbulent boundary layers subjected to spanwise wall oscillation by means of tomographic PIV. These are used to study the changes in pointwise statistics and coherent structures in order to derive a descriptive model of the drag reducing mechanism.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:3fa3d71c-afa2-450d-894a-227abd79acfb","http://resolver.tudelft.nl/uuid:3fa3d71c-afa2-450d-894a-227abd79acfb","Topologische Tegenvoorbeelden","van den Berg, M.R. (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Delft Institute of Applied Mathematics)","Hart, K.P. (mentor); de Groot, J.A.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","In dit verslag bekijken we zes topologische tegenvoorbeelden. Eerst bestuderen we de topologie van Appert. Deze topologie is gedefinieerd op een aftelbare verzameling, maar heeft overaftelbaar veel open verzamelingen. In de ruimte van Appert zijn de triviale rijtjes de enige rijtjes die convergeren. De ruimte is separabel, maar voldoet niet aan het tweede aftelbaarheidsaxioma.<br/>Het is bekend dat elke aftelbare reguliere ruimte normaal is en dus `veel' continue functies naar het eenheidsinterval heeft. Daarom is een aftelbare reguliere ruimte niet samenhangend. Dit geldt echter niet voor aftelbare Hausdorff ruimten. We bestuderen een ruimte die aftelbaar Hausdorff is én samenhangend. Deze ruimte heet Gustin's rijruimte.<br/>Daarna bekijken we een andere samenhangende ruimte: de topologische sinus-kromme. Deze is niet compact, maar we kunnen de ruimte uitbreiden en er een compacte ruimte van maken. We zien in dit hoofdstuk dat niet elke kromme padsamenhangend is. Dus samenhang impliceert niet altijd padsamenhang.<br/>De vierde ruimte die we bestuderen is Van Douwen's ruimte. Deze is regulier en $T_1$. Elke continue reëelwaardige functie in deze ruimte is constant.<br/>Verder bekijken we een overaftelbaar product van normale ruimten, waarvan de productruimte zelf niet normaal is. Of het product separabel is of niet, hangt af van de `grootte' van het product.<br/>Tot slot nog een productruimte: de ruimte van Helly. Dit product is wel normaal, maar bevat een niet-normale deelruimte. We zullen namelijk zien dat de ruimte compact Hausdorff is en een deelruimte heeft die homeomorf is met de Sorgenfreylijn. De ruimte voldoet aan het eerste maar niet aan tweede aftelbaarheidsaxioma. De ruimte is wel separabel.<br","Topologie; Tegenvoorbeeld; Productruimte; Rijruimte","nl","bachelor thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:43210f38-23c1-4e92-a471-6c68c03fdcee","http://resolver.tudelft.nl/uuid:43210f38-23c1-4e92-a471-6c68c03fdcee","CareTunes for Families: Connecting ICU Patients and Their Families through Music","Chou, Chen (TU Delft Industrial Design Engineering)","Ozcan Vieira, E. (mentor); van der Helm, A.J.C. (graduation committee); Delft University of Technology (degree granting institution)","2020","CareTunes for Families is a product-service system that connects Intensive Care Unit (ICU) patients and their families through music. Families of ICU patients often experience distress and anxiety. They have the need for information, closeness, assurance, hope, control, and the need to support the patient. These emotional and social needs point to a need for stronger connection/connectedness, especially when the family is outside the hospital. In addition, the families experience many negative emotions such as uncertainty, worry, guilt, fear of loss, etc. Meanwhile, music is a powerful way to communicate emotions and meanings; it has the quality to fulfill the family’s social needs, emotional needs, and need for information at the same time. Therefore, the project aims to increase the connectedness for the families through music, and to bring them more positivity. A series of literature research and qualitative user research was carried out. The design also went through several iterations, inspired by insights gathered from user tests and interviews with experts. The final design of CareTunes for Families includes service design, user experience design, and music design. The design facilitates a meaningful connection between patients and families by transferring the patient’s mental activities and emotions through music streaming or music messages to the family. The music streaming enhances the sense of close presence of the patient, and the music messages enhance the feeling of intimacy and assurance, and reduces the sense of guilt. The product also enables the family to support the patient by sending back voice messages. The music in the design is automatically generated by the system. It comprises a theme melody of the patient, increasing intimacy and connectedness, and multiple other tracks which are connected to different data sources such as heart rate, brain waves and movements, creating variations in the music and a sense of realism. Moreover, the product gives the family the control in ending the music as an act of closure at the end of the service. The user evaluation of the design validates that the experience and the music together can indeed create connectedness and enhance positive emotions such as calmness, hope, and acceptance. The project leads to the following conclusions: (1) Music presents an advantage in building connectedness through an emotional experience and is unfitted to present technical information. (2) The experience is very personal. (3) Streaming and messaging can both cater to the families’ needs respectively. (4) A two-way connection that also supports the patient may be needed. (5) Positivity in music is important. (6) Multi-dimensional composition can bring more life to the music. (7) The music should be predictable. (8) The selected data source for the music should have (humanized) meanings.","Intensive Care Unit; Families; User experience design; Music; Critical Alarms Lab; Connectedness","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:5436b301-e1bb-4f42-922c-3ef033ac891f","http://resolver.tudelft.nl/uuid:5436b301-e1bb-4f42-922c-3ef033ac891f","Commons of Care","Deng, Y.C. (TU Delft Architecture and the Built Environment)","Kuitenbrouwer, P.A.M. (mentor); Koskamp, G. (graduation committee); de Vries, N.A. (mentor); Delft University of Technology (degree granting institution)","2020","Commons of Care is situated in Skydebanehaven Park within the post-renewal district of Vesterbro in Copenhagen, Denmark. As part of the chair of Public Building, the project plays on the two aspects of everyday life that concern the public as participants: commons and care, material and immaterial, goods and services. Implicit in the title is an acceptance that forms of care (daycares and elderly-care centres) are common goods. Care as a resilient urban marker provides a framework that concerns the marginalised multitude of the city, namely the immigrant (“newcomers”) and elderly (“late-agers”) populations in the city. The design is guided by four principles (cure, curation, collectivity, connectivity) that suggest multiple interventions for realising the aspiration for a public condenser. The concept of care legitimises coexistence between multiple communities where accessibility and inclusivity become benchmarks for a renewed definition of liveability in Europe. <br/>CARE: Guided by the principle that welfare ties to wellbeing and excludes no one.<br/>CURE: Providing relief for the those in need, cure offers a support network.<br/>CURATION: The verb “to care” derives from the Latin ‘curare’ which is inscribed etymologically in the word “to curate”.<br/>COLLECTIVITY: Cure and curation come within a collaborative framework of shared identity: assemblage, togetherness, solidarity, belonging.<br/>CONNECTIVITY: Offer new opportunities in the city that connect to people who might otherwise be excluded or marginalised. <br","","en","master thesis","","","","","","","","","","","","","",""
"uuid:37cb8bc9-71fd-4fcd-9558-9b3e6dd0719e","http://resolver.tudelft.nl/uuid:37cb8bc9-71fd-4fcd-9558-9b3e6dd0719e","Tailoring personalized breathing rhythms of a Sleep Robot: An interactive data loop design","Chang, W. (TU Delft Industrial Design Engineering)","Romero Herrera, N.A. (mentor); Bourgeois, J. (mentor); Delft University of Technology (degree granting institution)","2020","The thesis aims to investigate how the Sleep Robot system (a Sleep Robot, its application, and servers) can adopt a data-enabled loop to make optimal use. The research has three main objectives: (1)understanding the needs and concerns of using the Sleep Robot system in different user profiles, (2)building a data loop of the Sleep Robot system with subjective and objective data, and (3) identifying the design principles of long-term engagement in a data loop.<br/><br/>To answer the research question and fulfil the objectives, the thesis adopted a four-diamond design process. In the discovery phase, the research reviewed the literature on personal informatics and sleep solutions, then plotted the Somnox data ecosystem. In the refining phase, the user research was performed to obtain profound insights, create a journey map, and user profiles by using a sensitizing diary, fetching data from servers, creating data visualization, and conducting interviews. The user research found that users stick to standardized breathing settings without engaging themselves in self-experimenting with breathing settings due to the lack of guidance and support. Thus, the project’s design goal is to let users feel guided and at ease during self-experimenting different breathing settings.<br/><br/>By going through creative sessions and user testing in the developing phase, the research found out four essential design elements to achieve design goal: (1) step by step learning experience, (2) dynamics of breathing rate, (3) growing together through empowering the breathing recommendation system, and (4) breathing with a specific goal which reflects causes of poor sleep. Eventually, the proposed design integrated these four elements into three levels of personalized breathing rhythms, including customized breathing, optimized breathing, and contextualized breathing.<br/><br/>In the evaluation phase, the proposed design was evaluated through user scenarios and high-fidelity prototypes. The results showed that users highly appreciated the guidance and ease through measuring personal conditions to tailor three-level breathing rhythms. This study emphasizes the transition role of the proposed concept from three-level of personalized breathing with a data loop and, ultimately, toward the adaptively synthesized breathing.<br","Insomnia; Self-experiment; Breathing rhythms; Data; Personalization","en","master thesis","","","","","","","","","","","","Design for Interaction | Medisign","",""
"uuid:c1553e4e-1833-448f-808f-cf1093808094","http://resolver.tudelft.nl/uuid:c1553e4e-1833-448f-808f-cf1093808094","Augmented Fractional-order Reset Control: Application in Precision Mechatronics","Aldo Yonathan Sebastian, A.Y. (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Precision and Microsystems Engineering)","Karbasizadeh Esfahani, N. (mentor); Saikumar, N. (mentor); Hossein Nia Kani, S.H. (mentor); Delft University of Technology (degree granting institution)","2020","","control system; precision control; mechanical engineering","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Mechatronic System Design (MSD)","",""
"uuid:63511523-64d1-4b5e-ab66-26a5d0d61bd4","http://resolver.tudelft.nl/uuid:63511523-64d1-4b5e-ab66-26a5d0d61bd4","Weight Swapping: A new method for Supervised Domain Adaptation in Computer Vision using Discrete Optimization","Datta, Leonid (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Gemert, J.C. (mentor); Bruintjes, R. (graduation committee); Delft University of Technology (degree granting institution)","2020","Training Convolutional Neural Network (CNN) models is difficult when there is a lack of labeled training data and no unlabeled data is available. A popular method for this is domain adaptation where the weights of a pre-trained CNN model are transferred to the problem setup. The model is pre-trained on the same task but in a different domain that has plenty of labeled data samples available. In a CNN model, we can rearrange the weights of a convolutional layer by permuting them along the input channel dimension. This work shows that certain weights that are learned in the pre-trained model work well in the problem setup when the weights are rearranged in this manner. Computing the set of all possible rearrangements of the weights is computationally intractable. This work proposes two algorithms to find a good rearrangement of the weights in reasonable computation time. The solutions from the algorithms perform equally well or better than fine-tuning in the domain adaptation between SVHN and MNIST data.","deep learning; computer vision; domain adaptation; Convolutional Neural Networks (CNNs); transfer learning","en","master thesis","","","","","","","","","","","","","",""
"uuid:5adc7ba5-c068-493c-b1de-c4ef8f74c0a1","http://resolver.tudelft.nl/uuid:5adc7ba5-c068-493c-b1de-c4ef8f74c0a1","Tail move rearrangement algorithm for rooted binary phylogenetic networks","Husanović, Selma (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Iersel, L.J.J. (mentor); Janssen, R. (graduation committee); van Gijzen, M.B. (graduation committee); Delft University of Technology (degree granting institution)","2020","A common tool for exploring the space of phylogenetic networks is applying rearrangement moves, such as <i>tail moves</i>. Recently, it has been shown by Janssen et al that, given a rooted binary phylogenetic network, it is possible to generate any other alternative network, using only tail moves. The aim of this report is to translate this theory into a tail move rearrangement algorithm, that calculates a sequence of tail moves necessary to transform one network into another, and thus determines an upper bound on the tail distance between the two networks. Furthermore, the goal is to assess the quality of the upper bound as determined by the algorithm, and to try to improve it. To this end, four improvement proposals were made and tested. A comparison was made with the true tail distance for a range of 385 combinations of small networks. It was shown that the original algorithm gives adequate results. However, it was concluded that it generally cannot be predicted which version of the algorithm will perform best. In the case of small and relatively simple networks, the fourth improvement provides the best results.","Phylogenetic networks; Tail move; Algorithm","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:a0336a50-d169-45cb-abe7-097ba8d15084","http://resolver.tudelft.nl/uuid:a0336a50-d169-45cb-abe7-097ba8d15084","Assessment of Parkinson's Disease Severity from Videos using Deep Architectures","Yin, Z. (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Gemert, J.C. (mentor); Dibeklioglu, Hamdi (mentor); Wang, Huijuan (graduation committee); Wang, Ziqi (mentor); Geraedts, Victor (graduation committee); Delft University of Technology (degree granting institution)","2020","Parkinson's disease (PD) diagnosis is based on clinical criteria, i.e. bradykinesia, rest tremor, rigidity, etc. Assessment of the severity of PD symptoms, however, is subject to inter-rater variability. In this paper, we propose a deep learning based automatic PD diagnosis method using videos recorded during the assessment with the Movement Disorders Society - Unified PD rating scale (MDS-UPDRS) part III. Seven tasks from the MDS-UPDRS III are investigated, which show the symptoms of bradykinesia and postural tremors. We demonstrate the effectiveness of automatic classification of PD severity using 3D Convolutional Neural Network (CNN) and the PD severity classification can benefit from non-medical datasets for transfer learning. We further design a temporal self-attention (TSA) model to focus on the subtle temporal vision changes in our PD video dataset. The temporal relative self-attention-based 3D CNN classifier gives promising classification results on task-level videos. We also propose a task-assembling method to predict the patient-level severity through stacking classifiers. We show the effectiveness of TSA and task-assembling method on our PD video dataset empirically.","Parkinson's Disease; Deep learning; Transfer learning; Self-attention; Multi-domain learning","en","master thesis","","","","","","","","","","","","","",""
"uuid:51d875d8-19cf-4397-8755-680de1cbc080","http://resolver.tudelft.nl/uuid:51d875d8-19cf-4397-8755-680de1cbc080","Combustion of diesel/methanol blends in a compression ignited engine: Research into the effects of methanol/diesel blends on the performance and emissions of a diesel engine based on experiments and simulations","Tol, Ruben (TU Delft Mechanical, Maritime and Materials Engineering)","Roekaerts, D.J.E.M. (mentor); Visser, K. (mentor); van de Ketterij, RG (graduation committee); Sapra, H.D. (graduation committee); Delft University of Technology (degree granting institution)","2020","In the context of this thesis, the effect of various diesel-methanol blends in a diesel engine compared to conventional marine diesel oil is investigated by experiments and in-cylinder simulations. The main differences obtained between diesel and methanol are the lower heating value, heat of vaporization and cetane number. During the experiments, the engine was not able to run on M20 at loads lower than 153 [kW]. Pressure signal comparison between the cylinders showed that cylinder one shows better ignition properties for methanol operation compared to cylinder two, three and four. Higher COV's for IMEP and maximum pressure were obtained by methanol blends. Experiments with F76, M10 and M20 fuel have shown that methanol blends increase the specific fuel consumption and slightly decrease the engine efficiency. Specific NOx emissions decreased with 2.9 up to 14.2 [%] by methanol blends compared to F76. Due to the increased fuel consumption, the CO<sub>2</sub> emissions hardly reduced. Exhaust gas temperatures and CO emissions seems to decrease. The ignition delay of methanol blends increased up to 8 [degrees CA] for M20 while remaining the brake power constant. Moreover, the combustion duration and air excess ratio decreased by using methanol blends. A single droplet evaporation model is built to simulate the evaporation heat losses for methanol fuel during the in-cylinder process. Methanol has a longer evaporation time which is a disadvantage for diesel engine applications. By using the single droplet evaporation model combined with an injection model calibrated for dual fuel direct injection, the fuel spray evaporation heat is calculated for implementation in the single zone model. The results are calibrated by using the droplet diameter as a variable. In this way, the evaporation heat required for evaporation of methanol is simulated in the dual fuel single zone model. Heat release analysis shows that the premixed combustion phase of methanol blends is dominant compared to F76, while the diffusive combustion phase significantly reduces. For methanol blends, the residence time at high temperatures is lower due to the decreased combustion duration and elongated ignition delay. Unfortunately, the results from the dual fuel single zone model are strongly dependent on the position of the pressure signal. Results for the temperature of the mean cylinder two, three and four were not in line with the expectations. Cylinder one showed smoother heat release curves and its temperature result was in line with the expectations based on the exhaust gas temperature. More research to the effects of the fuel injectors on the heat release of methanol/diesel blends is recommended.","Methanol; Diesel Engine; Emissions; Dual fuel; Experiments; Simulations","en","master thesis","","","","","","","","","","","","","Green Maritime Methanol Project",""
"uuid:8820b395-c64b-4a5d-87a4-fbf7d1b17a6c","http://resolver.tudelft.nl/uuid:8820b395-c64b-4a5d-87a4-fbf7d1b17a6c","A cup deposit system: An implementation strategy for NS stations to engage customers to use reusable cups and lower their environmental impact","Visser, J.S. (TU Delft Industrial Design Engineering)","Schuffelers, R.J.G. (mentor); Balkenende, A.R. (mentor); van den Berg, E.K. (mentor); Delft University of Technology (degree granting institution)","2020","This graduation project focused on lowering the environmental impact in which warm beverages were drunk at NS stations by motivating user to use reusable cups. It was explored why customers currently do not use reusable cups at NS stations, which solution space can be used to motivate customers to use a reusable cup and how NS can implement this solution space in the NS context.<br/><br/>Different research activities were conducted to under why customers are not using reusable cups now and how NS can motivate thee users. By analysing the results from observations, user interviews and context mapping. Based on the findings 5 barriers were found why customers are not using reusable cups.<br/>Next to these insights 4 personas were created and it was also found how NS can improve the customer experience of drinking a warm beverage at their stations.<br/><br/>Based on these insights two solutions spaces where formulated which were compared to the paper cup. It was concluded that the deposit cup system would be the best reusable cup system for under the right circumstances, but that a user owned cup and a paper cup still have their place.<br/><br/>Because there is no cup deposit system that fits the needs of NS stations the following design goal was formulated:<br/><br/>Design a cup deposit system that has a return rate of at least 98.5% and motivates customers that buy a warm beverage at NS stations to use a reusable cup instead of a single use paper cup, by taking their drivers into account, while at the same time fitting inside the constraints of the NS retail system. This will lower the environmental impact of cups for warm beverages sold at NS stations.<br/><br/>Next to the design goal a design vision was formulated to illustrate how customers should feel when these the system taking each persona into account.<br/><br/>Based on the design goal and the design vision multiple concepts were created from which one was chosen and further detailed into a final concept. This final concept was evaluated with experts within NS, see figure FIX ME. To implement the final concept a road map was made.","Sustainabilty; Contextmapping; Cup deposit system; Nederlandse Spoorwegen","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:7b960d1e-6549-4b4c-b3ed-2ff41f3ff6f6","http://resolver.tudelft.nl/uuid:7b960d1e-6549-4b4c-b3ed-2ff41f3ff6f6","Design for future DDL workplace","Huang, X. (TU Delft Industrial Design Engineering)","Desmet, P.M.A. (mentor); Jaskiewicz, T.J. (mentor); Delft University of Technology (degree granting institution)","2020","A physical work environment is essential for creating and supporting different activities in the workplace, not only for work performance but also for physical and mental wellbeing. Studies have been conducted on the influence of the working environment on work performance and people’s wellbeing since the 1950s. Most of these studies have been published in the domains of ergonomics and human factors or in historical papers on the office environment (Katja, 2019). In recent years, motivated by increasing demand for wellness-focused design, companies and organizations are putting more effort into investing in properties that improve employee’s performance while enhancing their wellbeing in the workplace (Zack, 2019), exploring opportunities of new emerging technologies. The same applies to universities where they always seek for new approaches. Students are more willing to adapt to changes and to participate in experimental setups. Delft Design Labs offers multiple opportunities for student participation and master thesis project is one of them. Working on a graduation project is a challenging time and a graduation lab workplace should be an environment that can help. This project is focused on designing for the future Delft Design Labs workplace, which is being used by students who are working on their graduation projects for Delft Design Labs. The final design is a product system called ""Hexabond"" which encourages meaningful interactions between students, without disturbing everyone. It gives the user an opportunity to connect and interact with others, which can be a start point for students to get to know each other. The Hexabond is simple to set up and does not require a precious time investment. The aesthetic of the products is simple and minimalistic and makes it fit into any workplace. For validation of the Hexabond, some prototypes were created for user tests. The results of the test showed that the final design met the design goals well. The resulting product fulfills the need for encouraging students to offer and ask for help in the workplace, creating connections between students and making students feel a sense of belonging. However, there is still room for improvement for maintaining the connections between students. The biggest limitation during the project is the unfortunate pandemic. Making it impossible to do user tests in the DDL workplace or in general. The current design is still rather hypothetical and is not fully validated with the right usage. The product is rather a user-centered design that needs input and feedback from the user group. If it was possible to actually test the product in a shared workplace with the students, it would have yielded insightful feedback for iterations. <br","workplace","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:48622d76-d9df-4996-9c9b-c680a3def97f","http://resolver.tudelft.nl/uuid:48622d76-d9df-4996-9c9b-c680a3def97f","Time Integration Parallel in Time","Budko, Ariena (TU Delft Electrical Engineering, Mathematics and Computer Science)","Möller, M. (mentor); Lemmens, C.W.J. (mentor); Delft University of Technology (degree granting institution)","2020","In this paper the research behind the parallelization on the GPU of the time parallel time integration method Parareal. Firstly, the theory behind Parareal and its convergence theorems will be detailed. Then, two test models, the Lorenz system and Heat diffusion equation, will be introduced. Additionally, the derivation of the Forward Euler and Backward Euler methods for these problems will be discussed. Secondly, an overview of development in parallel programming will be given, with a focus on architecture, memory organization and GPU properties. Thirdly, the implementation of Parareal in Python using the CuPy library will be shown, including the Parareal convergence plots and the code profiling results. In the second half of the paper, there will be an outline of the improvements that were made for a better speedup of the Parareal implementation. A discussion on linear solvers and their efficiency in<br/>regard to matrix properties will be presented. Moreover, the reason why a different linear solver for the Heat diffusion equation was needed, than the one built into CuPy, will be explained. Furthermore, the creation of a separate linear solver based on the Thomas algoithm as a CUDA-kernel in Python will be shared. The construction of CuPy elementwise kernels for the Lorenz system will be described as well. Lastly, the speedup results for the CuPy built-in functions will be compared to the self-made<br/>kernels utilizing a self-derived speedup formula. A reflection on the implementation of Parareal in practice will conclude this paper.","Parareal; Time integration; Thomas algorithm; GPU computing; Sparse matrix; Dense matrix; convergence analysis; speedup; parallelism; Banded matrix; heat diffusion; lorenz system; Parallel programming; Python","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:14b46f31-7312-4af6-825f-c148d262f5d3","http://resolver.tudelft.nl/uuid:14b46f31-7312-4af6-825f-c148d262f5d3","IMS in 5G: Analysis of IMS based communication services in the 5G network","Dattatreya, Manasa (TU Delft Electrical Engineering, Mathematics and Computer Science)","Noldus, R.A.C.J. (mentor); Smeitink, E. (graduation committee); Wang, Q. (graduation committee); Delft University of Technology (degree granting institution)","2020","The thesis focuses on investigating the role of IP Multimedia Subsystem (IMS) in 5G networks. IMS already plays a very important role in enabling a wide range of real-time multimedia communication services such as basic phone calls and messaging in the LTE network. Addition of application servers on top of the IMS core can provide enhanced functionalities like presence, advanced messaging and SIP trunking. IMS guarantees quality, security and reliability of multimedia services when serving users without the installation of any application as well as flexibility over access. This sets IMS apart from other third party applications found on the internet. IMS was created with the idea of being adaptable to the evolving technology. With the implementation of the 5G network underway, a study of the impact of this new architecture on the IMS services is imminent. The thesis focuses on the study of different network elements participating in an IMS service as well as investigating IMS voice and video calls over the 5G network.<br/>The thesis consists of two parts: The first part involves exploring the role of IMS in 5G networks. A brief overview of the evolution of mobile networks will help understand the differences between 1G/2G/3G/4G. Following this, IMS and its role in enabling multimedia services in the LTE network is explored. Next, the 5G System Architecture is explained along with components and their functions.<br/>Next, a comparison between the elements in 4G and 5G provides a clear understanding of the technological evolution and the procedure involved. The next steps would include understanding the IMS call flow in LTE networks. This would provide a good foundation to understand how the IMS services will be provided over the 5G network. The second part of the thesis includes testing the voice and video services over Ericsson’s 5G network at their Rijen office. As a starting step, the voice and video services are tested using WebRTC. Upon succeeding in the peer-to-peer test, the next step is establishing connectivity to Ericsson’s IMS network at Kista, Sweden. This will allow the testing of IMS voice and video services over the 5G network. The results are recorded and analysed. These are in agreement with the theoretical expectations.","IMS; 5G","en","master thesis","","","","","","","","","","","","Electrical Engineering | Telecommunications and Sensing Systems","",""
"uuid:7c9fcd3a-49de-4cbb-832f-75ac72de6ed2","http://resolver.tudelft.nl/uuid:7c9fcd3a-49de-4cbb-832f-75ac72de6ed2","Development of an optimizing tool for design of tailored PV modules through Cell To Module (CTM) factor modelling","Sinha, Nitish (TU Delft Electrical Engineering, Mathematics and Computer Science)","Isabella, O. (mentor); Ortiz Lizcano, J.C. (mentor); Delft University of Technology (degree granting institution)","2020","The advancement of innovative PV technologies has led to an all-time high integration of the same in the urban environment. Furthermore, development of decentralized power systems complements this rise as it supports in-situ power consumption. Due to space availability constraints in urban environments and a need for appealing aesthetics, tailored PV modules is gaining importance. However, it is desirable to achieve maximum power out of these tailored PV modules to ensure efficiency in space usage.<br/>Literature suggests that one of the most apt performance metric for estimating the goodness of design for PV modules is the CTM ratio. However, various challenges incurred upon implementing the present CTM analysis algorithms on tailored PV modules suggests the need for development of a different approach to estimate the same. The presented work strives towards the development of a tool for the prediction of various performance metrics, including the CTM ratio, of both standard and tailored PV modules to aid its user to make educated design choices to develop optimum modules.<br/>The methodology used for development of the tool encompasses various steps which occur in a pre-programmed flow. Firstly, a developed script automatically creates the module structure based on user inputs. Hereafter, ray tracing is implemented and its results furnishes optical performance of the module. Furthermore, an electrical loss calculation model is developed, using differential element method, which when coupled with the optical performance data enables the estimation of the CTM ratio and other performance metrics. The tool is programmed in Matlab to ensure easy integration of the same with the PVMD toolbox for future research on module designs.<br/>Firstly, an attempt is made to optimize the parameters of the mini-module for maximizing its performance. For a white backsheet test mini-module, optimization through the usage of the tool, leads to a 5.52 % gain from the worst case design. This gain is realized by achieving an optimal tuning between the cell-cell and cell-edge spacing. Moreover, when compared, the white backsheet module’s power production capacity outperforms the black backsheet module by around 13.93 %. Additionally, effect of busbars on the performance of the module is investigated.<br/>Furthermore, the tool is able to derive novel empirical formulas which, for different module architectures, predict the effect of cell top metallization on the cell photocurrent density in an encapsulated environment.<br/>Secondly, efficacy of the tool is demonstrated for a comparative study between a 60 cell module and its corresponding 120 half-cut cell module. The tool suggests the half-cut cell module to have a 2.91 % gain in CTM ratio as compared to its full cell counterpart.<br/>Thirdly, the tool demonstrates modelling and simulation of glass-glass modules and achieve optimization. The tool also recommends an increase of the dimension size for the test module to 20×20 cm2 to achieve the exemplary target transmission of 14 %.<br/>Lastly, the tool efficacy is demonstrated for a triangular PV module. This module with a white backsheet is found to outperform its black backsheet counterpart by 9 % in CTM ratio.","Cell to module; Tailored modules; Mini modules; Tool; Optimization; Matlab; solar modules","en","master thesis","","","","","","","","2021-06-30","","","","Electrical Engineering | Electrical Power Engineering","",""
"uuid:58e681ae-9a2d-4046-b13f-6d33e991af6e","http://resolver.tudelft.nl/uuid:58e681ae-9a2d-4046-b13f-6d33e991af6e","Brain-computer interface-based feedback to enhance motor rehabilitation","Devetzoglou Toliou, STAVRINA (TU Delft Mechanical, Maritime and Materials Engineering)","Schouten, A.C. (mentor); Norton, J. J. S. (mentor); Pool, D.M. (graduation committee); Geelen, J.E. (graduation committee); Wolpaw, Jonathan R. (graduation committee); Delft University of Technology (degree granting institution)","2020","The central nervous system (CNS) exhibits remarkable plasticity throughout life. The physiological changes in the CNS that occur due to plasticity allow us to perform new skills and old ones more effectively and efficiently over time.<br/><br/>Recently, it has been demonstrated that plasticity can be used to help people recover motor function after spinal cord injury (SCI), stroke, or other neurodegenerative diseases. Following injury or illness, neuronal pathways are disrupted, leading to exaggerated reflexes and motor impairments. Rehabilitation methods can help restore motor function by triggering beneficial plasticity (i.e., neuronal and/or synaptic changes that improve motor functions).<br/><br/>H-reflex operant conditioning that triggers beneficial plasticity is one promising new therapeutic approach to motor rehabilitation. In this paradigm, participants are operantly conditioned to change the size of abnormal reflexes associated with motor deficiencies (either increased or decreased as needed), which consequently improves movement. H-reflex operant conditioning has no known adverse side effects and it can complement other therapies. Two present limitations of H-reflex operant conditioning are its success rate and the length of time required to complete the conditioning.<br/><br/>Given that the beneficial plasticity induced by this paradigm is modeled to start in the sensorimotor cortex, we designed an enhanced H-reflex operant conditioning system that provides people with brain-computer interface (BCI)-based feedback on activity from this region of the brain. We hypothesize that<br/>by guiding this critical first stage of plasticity, it should be possible to enhance the efficacy and efficiency of this paradigm.<br/><br/>This thesis is organized as follows. Chapter 1 introduces the H-reflex operant conditioning and the logic for our enhanced H-reflex operant conditioning system. Chapters 2 and 3 describe experiments conducted to identify and train participants to use our BCI-based feedback system. Five participants<br/>completed the training; four of these participants learned to use the BCI with better than 70% accuracy and three of these four participants significantly improved their accuracy with training. Chapter 4 lays out the design of the enhanced H-reflex conditioning system. Finally, Chapter 5 presents plans for<br/>experiments to test the system when human-based research is able to safely resume following the global COVID-19 pandemic and potential directions of future work.","plasticity; H-reflex; neurotechnology; sensorimotor rhythms; EEG; EMG; BCI; brain-computer interface; Reflex; feedback; BCI2000; EPOCS; sensorimotor cortex","en","master thesis","","","","","","","","2021-08-31","","","","Biomedical Engineering","",""
"uuid:aa8a3893-7901-496b-b33c-9c88995e8e7d","http://resolver.tudelft.nl/uuid:aa8a3893-7901-496b-b33c-9c88995e8e7d","Key Components for Potential Sustainable Vehicle-to-Grid Business Models within the Netherlands: A qualitative research to explore the components for sustainable Vehicle-to-Grid business models by conducting semi-structured expert-interviews","Başer, Enes (TU Delft Technology, Policy and Management)","van Wee, G.P. (graduation committee); Annema, J.A. (mentor); Bouwmans, I. (mentor); Ghotge, R. (mentor); van Bergen, Esther (mentor); Delft University of Technology (degree granting institution)","2020","The shifts towards more use of electric vehicles and more use of renewable energy sources create the need for Vehicle-to-Grid (V2G) technology. To penetrate the market, the development of V2G business models is critical. However, there are no sustainable V2G business models determined yet. Therefore, this research focused on what the key components are for such business models focusing on the Netherlands. By applying a qualitative approach, this study analyzed the actor's environment, technological developments, and three cases. After that, semi-structured interviews were conducted interviewing eleven experts with regards to the development of sustainable V2G business models. The results showed that there are three themes (business environment, business model, sustainability), twenty-six categories, and 229 components. This research provided an overview of the key components in a business model framework categorized into three use cases: Public V2G charging, V2G for homeowners (Vehicle-to-Home), and V2G for office/building owners (Vehicle-to-Building). The results showed that the business environment is vital and that the Dutch market is at the moment not ready for V2G to be commercial because of institutional, technical, and standardization issues. However, there is also potential due to the increasing trend of EVs, increasing grid congestion, decreasing costs of V2G charging infrastructure, and other trends.","Vehicle-to-Grid; Business models; Sustainability; Business environment; V2G service provider","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:10ffea49-9585-48ac-8ff4-647741871710","http://resolver.tudelft.nl/uuid:10ffea49-9585-48ac-8ff4-647741871710","Design of an Augmented Reality System for the Live Visualization of Ship Identification Data","Witte, Tieme (TU Delft Mechanical, Maritime and Materials Engineering)","de Winter, J.C.F. (mentor); Delft University of Technology (degree granting institution)","2020","Newly educated sailors have a tendency to neglect the outside view when sailing [1], instead relying on systems like the Electronic Chart Display and Information System (ECDIS) [2] for information on ships in the area.Augmented Reality (AR) has been proposed as a solution to this problem, by visualising ships in the area in 3D at their physical location using a Head-Mounted Display (HMD), including a data table shown above the ship containing information useful for navigation. This thesis describes the design of an AR application to achieve this goal. The designed application is shown to work anywhere where Automatic Identification System (AIS)data is available, and can show ship information close to the sending ship’s actual location. The app is then evaluated, and its problems are identified. Subsequently, two of these problems, namely occlusion and limited Field of View (FoV), are further evaluated. Four possible solutions for the occlusion problem are presented,which work by moving the data table that is shown above the occluded ship hologram so that the user will still be able to access the data when a ship is occluded. Two solutions move the data of the occluded ship vertically up and down respectively, so that the user can access the data of the farther ship by looking up or down. The other two solutions move the data horizontally, showing the data of the farther ship to the left or right of the closer ship, depending on which side the farther ship is located. In the last solution, the data table of the closer ship is also moved, in the opposite direction of the data of the farther ship. These solutions are tested on four participants: two students and two experts. The main results of the thesis are a working application that visualises ships in the area in AR using live AIS data, an overview of identified problems with the app and an analysis of four possible solutions for the occlusion problem. Although no definite best solution for the occlusion problem was found, the results indicate that the solution where the data of both the near and far ship is moved horizontally shows the most potential out of the four tested to be used for marine navigation.","Augmented Reality; Navigation; Royal IHC; Head mounted display; HoloLens; Situational awareness; Occlusion; Field of View","en","master thesis","","","","","","","","","","","","Offshore and Dredging Engineering","",""
"uuid:18fad0ed-5152-45f7-a091-5a1b198aff7e","http://resolver.tudelft.nl/uuid:18fad0ed-5152-45f7-a091-5a1b198aff7e","Influence of the partial closure of estuaries on the residual sediment transport and trapping","Sindy, F. (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Applied Sciences)","Schuttelaars, H.M. (mentor); de Roode, S.R. (graduation committee); Delft University of Technology (degree granting institution)","2020","In this thesis the water motion and sediment dynamics are investigated in a periodically closed and opened estuary. The water motion in an estuary is mainly driven by the semi-diurnal tide with an period of 12h25m and river discharge. An example of such an estuary is the Ems-Dollard estuary. Recent observations show an increase in tidal range (height difference between high and low tide), suspended sediment concentration and the depletion of oxygen levels (consequently harming the ecosystem). A possible solution, periodically closing and opening the estuary, is investigated. The water motion in a periodically opened and closed estuary is described by the linearised cross-sectionally averaged equations which give the sea-surface elevations and tidal velocity when solved with the eigenfunction expansion method. It was found that the sea-surface elevations and tidal velocity for a periodically opened and closed estuary are again 12h25m periodic. For the sediment transport, when no overtide is considered the residual sediment transport is seaward directed if the estuary is closed at low water and landward directed if the estuary is closed at high water. The barrier location determines the magnitude of the residual sediment. When overtide is included in the forcing of the system no relation is found<br/>between the direction of the residual sediment transport and the closing height and closing position. The location of the barrier and closing height both determine the magnitude of the residual sediment transport and direction. By introducing a barrier that periodically closes and opens we intended to achieve a seaward directed residual sediment transport in the Ems-Dollard estuary. The results suggest that this is not possible. Further research is needed with more<br/>extensive models to confirm this. For future Research I recommend to extend the model to a two-dimensional model with the eigenfunction expansion method. Other possibilities may be to consider a spatial dependent erodible bed.","Ems Estuary; Linearised Cross-sectionally averaged equations; Overtide; Eigenfunction expansion method","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics | Applied Physics","",""
"uuid:fb198be3-48d5-4ae0-96ef-bf478167bb0a","http://resolver.tudelft.nl/uuid:fb198be3-48d5-4ae0-96ef-bf478167bb0a","Enhancing Curiosity to Create a Child-Centered EEG Experience","Ekhtiar, T. (TU Delft Industrial Design Engineering)","Gielen, M.A. (mentor); Goto, L. (mentor); de Wit, Marie-Claire (mentor); Delft University of Technology (degree granting institution)","2020","This project focuses on designing a new EEG experience for children visiting the Child Brain Lab at the Sophia Children’s Hospital. The Child Brain Lab will be a new space to do pediatric research for different neurological and psychological disorders. In this space there will be stations where children will do different brain tests, and one which is the EEG station. The initial goal of this project was to improve experience for children 6-12 years old by enhancing curiosity when going to the EEG station, to allow them to learn more about the EEG on their own terms. Literature and observational research was done to learn more about the different stakeholders and the context of the EEG, focusing on identifying moments of boredom, anxiety, and curiosity for the children visiting the EEG space. In addition, the moments of interaction between the child-patient and the parent and lab technician were looked at in relation to these emotions. The observational research led to detailed patient journey maps to be created for four patients who were doing an EEG test regarding the three emotions identified and the interactions between the users. The main insights found were that patients are usually prepared for the procedural side of the appointment but not really about what the EEG test does. This is due to the EEG test being difficult to understand, even for parents, and it becomes assumed that it is too abstract for children to grasp. Factors for how to spark curiosity were also identified through literature research: creating a safe space, building up anticipation, allowing children to predict what will happen, and integrating novel colors, sounds, or other effects. The insights from the research lead to many ideas through sketches and low fidelity prototypes to be developed during and after the research process. Different feedback sessions with patients, parents, and healthcare providers help define the concept direction: an interactive experience that children can play during the EEG to help them learn about what the EEG does on their own terms. The final design is Wavy, an interactive experience that utilizes projected images that interact with physical pieces to create a virtual and physical environment for children to explore ‘What an EEG does’ and to introduce parts of the procedure for children. Wavy shows how doing different activities affects the EEG reading. By placing electrodes pieces, children find brain waves and an activity knob allows children to change the activity, changing the brain waves patterns. The design has been evaluated through interviews with child-patients, their parents, lab technicians, and neurologists (n=14). A virtual interactive prototype was created to test with the child-patients and parents. Lab technicians and neurologists appreciate that the game helps engage children to be more actively a part of the EEG appointment. During the prototype evaluation, children were able to relate the Wavy experience to their own EEG experience and asked exploratory questions to their parents about the game and EEG.","EEG; Children; Play; interactive; Child Brain Lab; Value-based healthcare; Play Well Labs; Design","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:f588ca1d-e4ae-4bf4-96ed-221d483b559d","http://resolver.tudelft.nl/uuid:f588ca1d-e4ae-4bf4-96ed-221d483b559d","Transparently Accelerating Spark SQL Code on Computing Hardware","Nonnenmacher, F.M. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Al-Ars, Z. (mentor); Hofstee, H.P. (graduation committee); Hauff, C. (graduation committee); Hoozemans, J.J. (graduation committee); Delft University of Technology (degree granting institution)","2020","Through new digital business models, the importance of big data analytics continuously grows. Initially, data analytics clusters were mainly bounded by the throughput of network links and the performance of I/O operations. With current hardware development, this has changed, and often the performance of CPUs and memory access became the new limiting factor. Heterogeneous computing systems, consisting of CPUs and other computing hardware, such as GPUs and FPGAs, try to overcome this by offloading the computational work to the best suitable hardware.<br/><br/>Accelerating the computation by offloading work to special computing hardware often requires specialized knowledge and extensive effort. In contrast, Apache Spark became one of the most used data analytics tools, among other reasons, because of its user-friendly API. Notably, the component Spark SQL allows defining declarative queries without having to write any code. The present work investigates to reduce this gap and elaborates on how Spark SQL's internal information can be used to offload computations without the user having to configure Spark further.<br/><br/>Thereby, the present work uses the Apache Arrow in-memory format to exchange data efficiently between different accelerators. It evaluates Spark SQL's extensibility for providing custom acceleration and its new columnar processing function, including the compatibility with the Apache Arrow format. Furthermore, the present work demonstrates the technical feasibility of such an acceleration by providing a Proof-of-Concept implementation, which integrates Spark with tools from the Arrow ecosystem, such as Gandiva and Fletcher. Gandiva uses modern CPUs' SIMD capabilities to accelerate computations, and Fletcher allows the execution of FPGA-accelerated computations. Finally, the present work demonstrates that already for simple computations integrating these accelerators led to significant performance improvements. With Gandiva the computation became 1.27 times faster and with Fletcher even up-to 13 times.","FPGA; Apache Arrow; Apache Spark; heterogeneous computing; Fletcher; Spark SQL","en","master thesis","","","","","","","","","","","","","",""
"uuid:5d77cc6e-a4c5-433e-b898-d5e8b9f4d58d","http://resolver.tudelft.nl/uuid:5d77cc6e-a4c5-433e-b898-d5e8b9f4d58d","An anisotropic fexural isostasy method for investigating the Martian lithosphere","Mussini, Juan (TU Delft Aerospace Engineering)","Root, B.C. (mentor); Riva, R.E.M. (mentor); van der Wal, W. (mentor); Delft University of Technology (degree granting institution)","2020","The subsurface of Mars is impossible to measure directly, yet it has been the subject of many studies. An understanding of the subsurface of Mars would yield large amounts of information on the history of the planet. Two of the tools available to indirectly interact with the Martian subsurface, in particular the lithosphere, are the gravity and topography signals of the planet. These two datasets can be combined using a variety of geological theories in order to investigate the subsurface. In this study, an isostatic model (Airy-type) and two flexural isostatic models (an infinite plate model and a thin shell model) will be the methods of choice. A distinction is made between isotropic or global models, which use one set of physical parameters for the entire planet, and anisotropic or multi-region models which allow for regional variation in physical parameters. The goal of this study is to investigate the performance of the novel thin shell model as compared to the older infinite plate model. <br/><br/>To investigate this, the theory behind each model is explained, after which the models are validated using results from literature. Several regions of interest are defined, mostly among large geological formations or gravity anomalies. Two parameters are chiefly investigated: the average thickness of the lithosphere and the lithospheric elastic thickness, which is a measure of the strength of the lithosphere. Each model is run globally for a variety of these two parameters, and the best fitting parameters are identified. After this, the planet is split into different regions with their own physical parameters. The first study is a dichotomy study which splits the planet into a northern and southern hemisphere, aimed at characterizing the disparity between the Martian north and south. After this, each region is assigned its best fitting physical parameters and the regions are combined into a 'global' regional model. A best fitting multi-region model is obtained via manual observation of the results and adjustment of the inputs until a visual best fit is achieved. <br/><br/>The results are then discussed. A key takeaway is that better methods of judging the performance of models without human visual inspection of their results is necessary in order to realize the full potential of the flexural isostasy models presented in this study. The lack of suitable methods leads to a manifold of best fitting solutions for many of the problems modelled in this study, hindering firm conclusions about the subsurface of Mars. Having said this, global average lithospheric values of about 200 km combined with very low effective lithospheric elastic thickness values of 0 to 40 km are the best fits found in this study. Literature values are typically lower, but this can partially be explained by differences between the flexural isostasy models in this study and the models from literature. Regionally there are large variations, with some features (Hellas basin, Alba mons) being isostatically compensated, others being supported by locally strong lithospheres (much of the Tharsis region), and others resting on buried mass anomalies that cannot be explained with the models in this study (Isidis planitia, Argyre basin). In a dichotomy study, the best fitting values were found for a northern lithosphere zero to ten kilometers thinner than the southern lithosphere. In general, the thin shell model is more sensitive to nonzero lithospheric elastic thickness values, providing very strong lithospheres at low elastic thicknesses. This is due to its aggressive flexural response function's filtering of higher spherical harmonic degree signals. The thin shell models yields higher residuals in the global analyses, but lower residuals in the multi-region studies. At the same time, 80% of the error in all models can be attributed to spherical harmonic degrees between 1 and 10. These signals are likely not caused by flexural isostasy, and require models incorporating more physics (mantle plumes, mass anomalies, etc) to be explained.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:55e92e3c-0b43-4064-8cbb-2ea1d1e1e068","http://resolver.tudelft.nl/uuid:55e92e3c-0b43-4064-8cbb-2ea1d1e1e068","Green roofs and climate resilience in The Hague: Spatial, financial &amp; stakeholder analyses","van Gameren, Lennart (TU Delft Technology, Policy and Management)","van Oudenhoven, Alexander (mentor); Zetland, D.J. (mentor); Delft University of Technology (degree granting institution); Universiteit Leiden (degree granting institution)","2020","Due to climate change, cities are expected to become subject to increasingly intense heat waves and precipitation. This calls for them to become more resilient towards such fluctuations. Green infrastructure is increasingly acknowledged as a means to enhance climate resilience, but cities – especially city centres – often lack the necessary space for realising such infrastructure. That is why green, vegetated roofs are frequently promoted as a potential solution for this spatial problem. This is also the case in the city of The Hague. In this municipality, green roof development has been stimulated for years with subsidies to increase the resilience towards the urban heat island effect (UHI) and stormwater flooding (SWF).<br/><br/>But while there is consensus within the municipality that more green roofs should be realised, no clear, quantifiable targets are set to achieve specific resilience goals. In part, this is because the potential benefits of green roofs have not been quantified at the city scale. And while most local benefits of green roofs are well known, downsides, costs and the barriers to implementation are not well understood.<br/><br/>The goal of this study is to examine the extent to which green roofs can increase climate change resilience in The Hague. In order to view this matter from complementing perspectives, three methods are used to answer five sub-questions. These methods are spatial analysis, financial cost-benefit analysis and stakeholder interviews.<br/><br/>In conclusion, large scale realisation of extensive green roofs is likely to have a positive effect on climate resilience in The Hague. These effects are significant at the city scale if green roofs are realised in large quantities, but they will likely not lead to easily noticeable results for the average citizen on the street. Substantial economic, political, legal and social barriers need to be overcome to implement green roofs at city scale for public environmental benefits. Several areas in the city do however hold notable potential to use its roof space for increased climate resilience.","green roofs; green infrastructure; resilience; climate resilience; climate adaptation; industrial ecology; urban heat island effect; stormwater management","en","master thesis","","","","","","","","","","","","Industrial Ecology","",""
"uuid:644a8239-b577-41c5-b172-b4f80041da32","http://resolver.tudelft.nl/uuid:644a8239-b577-41c5-b172-b4f80041da32","PVT Tolerant Transconductor for Low-Voltage Highly-Selective High-Frequency Filter of MRI Front-end Receiver","Agarwal, Gayatri (TU Delft Electrical Engineering, Mathematics and Computer Science)","Valente, V. (mentor); Totev, Emil (mentor); Serdijn, W.A. (mentor); Sebastiano, F. (mentor); Delft University of Technology (degree granting institution)","2020","MRI machine has evolved tremendously over the years from its inception in order to render high-quality 3D images, best among its companion imaging systems. Of the whole system, RF receiver is the most crucial for its noise performance, which is expected to provide high SNR at all operating conditions. At Philips, MRI’s RF receiver is based on direct-digitization architecture which has replaced the bulky data-acquisition system with an integrated on-coil receiver. It allows a lot of signal processing to be done digitally which was earlier done in analog-domain, thus improving the SNR and dynamic range to more than 100 dB. However, this has increased the design restrictions of the remaining analog front-end. The high-frequency bandpass filter employed to select the signal band around the receiver’s resonance frequency has not only become highly selective (Q 400, 6th order) to narrow down the signal bandwidth and reject the rest with a high stopband attenuation but also incorporates a high passband gain (60 dB), unlikely to see otherwise. Operating at a high frequency of 100’s of MHz, with such a response, the filter can become drastically sensitive to the shift in its components with varying operating conditions. At Philips, the filter uses transconductor as one of its building blocks and filter frequency response is heavily dependent on the transconductance of the unit cell as they are employed in large number in the circuit. The transconductor cell, at Philips, shows 15% deviation with the process, supply and temperature variations. This leads to more than 10% variation in the passband gain of the filter. Operating at low supply voltage, such a deviation in MRI filter can deteriorate its output SNR and dynamic range by 10dB. <br/><br/>In this thesis, a new inverter-based self-biased transconductance circuit has been proposed, which shows a deviation of ±2.5% in transconductance under the process, temperature and supply variations. It limits the passband gain of the filter to 60 dB±2% and bandwidth shows a deviation of less than 0.1%. However, the center frequency is matched precisely with the resonance frequency of the receiver by the external components of the filter. Given, this matching is the basis for the working principle of MRI receiver. With the proposed transconductance circuit, the filter shows an SNR of 112 dB, THD of -63 dB and consumes a power of 0.8 mW. The circuit has been implemented in 40 nm TSMC process and simulated for a temperature range of 0°C -85°C at the power supply of 1.1 V±10%, post-extraction.","PVT tolerance; self-bias; inverter-based; Transconductor; Analog filter; MRI RF receiver","en","master thesis","","","","","","","","2022-08-19","","","","Electrical Engineering","",""
"uuid:8811f9f0-669e-433b-b980-4b3748184dcc","http://resolver.tudelft.nl/uuid:8811f9f0-669e-433b-b980-4b3748184dcc","Hidden in plain sight: encouraging asthma inhaler usage in public","Motie, Rawien (TU Delft Industrial Design Engineering)","Ruiter, I.A. (mentor); van Heur, R.J.H.G. (graduation committee); Delft University of Technology (degree granting institution)","2020","In the Netherlands an estimated amount of 1.75 million people are suffering from asthma, from which an estimated amount of 300,000 are children. Even though the treatment of asthma has come a long way, nonadherence in asthma patients regarding their treatment remains high. This nonadherence is in part linked to the visual appearance of asthma inhaler devices and the ease of incorrectly interacting with these devices. The combination of using a metered dose inhaler (MDI) with a (valved) spacer chamber significantly decreases the likelihood of device interaction issues, but it worsens the visual appearance of the device, making it the least popular asthma inhaler device and also the least likely to be used in public. A concept has been developed in order to make the combination of an MDI + spacer chamber more appealing to use amongst younger asthma patients (children), especially in public. This concept consists of a housing which can hold and disguise an MDI + spacer chamber whilst providing an outwardly appearance of a sports water bottle. Interaction with this concept also provides an outwardly appearance as a person who is drinking from a sports water bottle, as opposed to that of a patient who is inhaling from a medical device. This concept aims to provide the advantages of an MDI + spacer chamber whilst simultaneously decreasing factors of embarrassment and/or reluctance to use such a device in public. Finally a usability study and a user experience (UX) have been conducted in order to evaluate whether the developed concept performs as intended.","asthma; inhaler; MDI; spacer chamber","en","master thesis","","","","","","","","","","","","Design for Interaction | Medisign","",""
"uuid:e3bf7181-380a-4a1c-8808-d967e8c97730","http://resolver.tudelft.nl/uuid:e3bf7181-380a-4a1c-8808-d967e8c97730","Low polders and high waters: Dealing with uncertainties of climate change in future polder management","Frölke, R. (TU Delft Civil Engineering and Geosciences; TU Delft Water Management)","Mostert, E. (mentor); Hoes, O.A.C. (graduation committee); Timmermans, J.S. (graduation committee); Booister, N, (graduation committee); Delft University of Technology (degree granting institution)","2020","It is no secret that the climate is changing, however, the severity and speed of this process is under debate. This leads to the question if and when we need to take action to protect the Netherlands against the effects of climate change. In order to deal with the uncertainties in policy- and decision-making, an adaptive approach is desirable. An option is to apply the Dynamic Adaptive Policy Pathways (DAPP) approach. <br/><br/>The DAPP approach has been applied successfully in several large scale projects. However, less attention is given to the application on small scale areas, and no applications on (small-scaled) polder areas are present. The aim of this report is to answer the following research question: ""Is the Dynamic Adaptive Policy Pathways approach suited for improving the adaptivity of polder management, given the uncertainty in climate change effects?"" The Zuidplaspolder is used as a case area for application of the DAPP approach. This deep-lying polder is interesting due to its diverse land use, the low elevation levels and already present issues in water management. <br/><br/>Through assessing the potential effects of climate change, conducting interviews, creating a hydrological model and following the steps of the DAPP procedure, a pathway map for the Zuidplaspolder is created. This pathway map is evaluated during focus groups with stakeholders from the Zuidplaspolder case area, as well as actors from a different polder area, being the Schermerpolder. Besides evaluating the applicability of the pathway map, the DAPP approach itself was assessed as well.<br/><br/>The pathway map provided several insights, one being the requirement to start considering actions at present in order to timely cope with issues in the future.<br/>Moreover, it was found that the DAPP approach is suited for improving the adaptivity in polder management, given the uncertainty in climate change effects. The pathway map is a helpful tool for authorities and affected stakeholders within polder areas to explicate upcoming issues. However, a cost-benefit analysis is required for actual, well-informed policy- and decision-making based on the pathway map. Nonetheless, it assists in making decisions more strategically and to explain certain choices in decision-making, which helps in creating support and understanding. Even though there are difficulties in translating large-scale actions and their effects to a smaller scale, the scale of the case area proved not to be a major issue. At last, the DAPP approach is found useful for other polder areas as well. However, a general pathway map cannot be created, since each polder has its unique set of characteristics and stakeholders with mindset on urgency.<br/><br/>When the pathway map is utilised for actual policy- and decision making, the use of an extended model is recommended. Here, probabilistic simulations are suggested, as well as the incorporation of several components that were excluded in this research. For identifying an integral pathway map for Dutch polder areas, it is recommended to research the clustering of polder characteristics on their constraints and related measures. By selecting the clusters that fit a designated case polder, a tailored pathway map can be created.","Dynamic adaptive policy pathways; DAPP; Water management; Climate change; Polder","en","master thesis","","","","","","","","","","","","","",""
"uuid:b778843c-4996-434b-bf24-2b31820dd570","http://resolver.tudelft.nl/uuid:b778843c-4996-434b-bf24-2b31820dd570","Decision-making on pre-disaster evacuation strategies in danger of cyclone induced floods: Two case studies in Mozambique showing how to balance timeliness and uncertainty reduction in making shelter location decisions","Dregmans, Rob (TU Delft Technology, Policy and Management)","van de Walle, B.A. (graduation committee); Comes, M. (mentor); Warnier, M.E. (graduation committee); Wanner, E. (graduation committee); Delft University of Technology (degree granting institution)","2020","As Needham (2015) concluded based on researching 700 storm surge events: “tropical cyclone induced floods are among the world’s deadliest and destructive natural hazards”. Due to this growing threat, there is a growing need for evacuation policies in case of an impending cyclone, in order to reduce the negative effects of a cyclone. The literature review in this research points out that there are many pre-disaster evacuation models, which focus mostly on either small scale evacuation of a city, or large scale evacuation with the use of motorized vehicles. However, in stretched out rural and developing areas, where access to motorized vehicles is limited or non-existent, residents need ample time to leave the area that is in danger of cyclone induced floods. This means that there should be enough time between the issue of the evacuation order and the moment the cyclone is forecasted to make landfall. However, the sooner the evacuation order is issued, the more uncertainty there is regarding the area that may be subject to the devastating consequences of the cyclone. That means that many residents would be unnecessarily evacuated. This is why the moment of the evacuation order should be at a point where the timeliness of the evacuation order and the uncertainty of the cyclone are optimally balanced. Currently, there does not exist a pre-disaster evacuation model for cyclone-induced floods that accounts for this trade-off. This research uses concepts of existing evacuation models and extends them with the trade-off between timeliness and uncertainty reduction in order to research the added value and applicability of this trade-off. This leads to the following research question: How to balance the trade-off between timeliness and uncertainty reduction in making shelter location decisions in rural and developing areas, under impending cyclone induced floods, while accounting for behavioral aspects of the vulnerable residents? The computer model that is developed to answer the research question consists out of three parts, which are called the building blocks of the model. The first building block translates discrete forecast reports about a cyclone into an area that is vulnerable and should be evacuated, because it will possibly be affected by the cyclone. These forecast reports form the decision points for an evacuation moment. Based on this vulnerable area, possible shelter locations are found in the surroundings of (horizontal evacuation), or on higher grounds within (vertical evacuation), the vulnerable area using a shelter searching algorithm. This algorithm uses a certain safety margin, which is the distance between the possible shelter locations and the vulnerable area to look for possible locations that can shelter the evacuees. The second building block is the optimization part. This sub model optimizes over the complete set of possible shelter locations and selects a given number of shelters that minimizes the weighted distance between the evacuees and the shelters. This weighted distance minimization is also known as the Minisum optimization model (Boonmee, 2017). The third and final building block simulates an evacuation using the previous generated data and captures the results in key performance indicators, so that the effect of the different policy levers can be compared and the balance between timeliness and uncertainty reduction can be found. The models are connected to each other using a Python interface. The model is applied to two different case studies, on which the results and conclusions are based. Three levers that define the shelter location decisions are found relevant in balancing the trade-off between timeliness and uncertainty reduction. The first is the evacuation moment. It shows that a later evacuation moment reduces the number of total evacuees, but it also reduces the evacuees that are saved from the impact of the cyclone. More precisely, the model shows a clear break point, which means that there is a point in time after which it is no longer possible to evacuate all evacuees in danger. The two case studies have shown that this break point is around two days in advance of landfall. This means that the balance in this trade-off lies before this break point. Too early evacuations however, result in a high number of total evacuees, which is not desired as well. This reduction in evacuees over time is not always linear and depends on how the cyclone is forecasted and the characteristics of the geographical area that is under threat. Therefore, it can be concluded that evacuation should happen before the break point, but the exact moment also depends on the forecast reports and the geographical terrain, and is also dependent on the other two levers. However, it is shown that vertical shelter locations significantly reduce the evacuation time and enable later evacuations or evacuations with less shelters. The second lever is the safety margin. This research concludes that a relatively high safety margin is advised in early evacuation moments, but in later evacuation moments it is advised to make use of vertical shelter locations, which means that a low safety margin should be used. The low safety margin is the only way, in later evacuation moments, to save as many evacuees as possible, but it also reduces the accessibility and security of the shelter locations. The third and final lever is the number of shelters. In early evacuation moments, there are many evacuees, which increases the need for sufficient shelters. Therefore, in early evacuations, it is shown that additional shelters have a relatively high reduction in travel distance and high increase of rescued evacuees when compared to later evacuation moments. However, the marginal benefit of an extra shelter is reduced with each additional shelter, which means that the cost of each additional shelter should be balanced against the reduction in travel time and the increase in safely evacuated evacuees. Furthermore, when a distance minimization model is used, the largest shelters will be located closest to the areas with the highest population density. Regarding the sizes of the shelters, later evacuation decisions often means there is need for more shelters. This means that those shelters tend to be smaller, but there will always be larger shelters because of the larger cities. In summary, three policy levers have been identified that define the shelter location decision and that have an impact on the balance between timeliness and uncertainty reduction. None of these levers can single-handedly define how the right balance, and they should therefore be used all-together to define the best balance the trade-off. However, it has also been found that in both case studies the cyclone evolved differently and the geographical area is far from identical as well, which also influences the right balance. This means that every answer about how to balance the trade-off, will also be different in every case. Additionally, it is concluded that the trade-off between timeliness and uncertainty reduction is especially relevant for evacuees who are evacuating by foot. When their travel speed increases, the relevance of the trade-off decreases. This confirms the hypothesis that most evacuation models with motorized vehicles do not account for this trade-off because evacuees have a higher travel speed. Furthermore, this research concludes that when a cyclone is advancing and there is no time to deploy an evacuation model, a heatmap of the population density, together with an elevation map, can give rough estimates of where the largest shelters should be located. The elevation map gives insights into the possible shelter spots because it will point out the elevated locations, either within or outside of the estimated vulnerable area. Those spots that are located closest to the most dense populated areas will probably prove to be suitable shelter locations. Furthermore, in both case studies it is shown that the latest evacuation moment is around two days in advance of landfall of the cyclone and that after that moment it is highly advised to make use of vertical shelter locations. To conclude, this research recommends that the evaluation of the model results will be changed from retrospective to prospective, which means that the model can be deployed in real-time disaster management. Only then, the real value of the model can be shown.","Pre-disaster; Evacuation modelling; Timeliness; Uncertainty reduction; Evacuation behavior; Location optimization; Behavior exploration","en","master thesis","","","","","","","","","","","","","",""
"uuid:744e94b2-ebf9-4e05-8c31-f4a1dc439313","http://resolver.tudelft.nl/uuid:744e94b2-ebf9-4e05-8c31-f4a1dc439313","InSAR as a volcanic monitoring tool for Saba and St. Eustatius: A comparison of ALOS-2, Sentinel-1 and PAZ data","Korevaar, A. (TU Delft Civil Engineering and Geosciences; TU Delft Geoscience and Remote Sensing)","de Zeeuw-van Dalfsen, E. (mentor); van Leijen, F.J. (graduation committee); Hanssen, R.F. (graduation committee); Riva, R.E.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","In this study an analysis of the efficacy of using satellite data, in the form of InSAR measurements, as an extension of the volcanic monitoring network on Saba and St. Eustatius is performed. For this research, data from three different satellites that operate at three different wavelengths are available: ALOS-2 (L-band SAR), Sentinel-1 (C-band SAR) and PAZ (X-band SAR). The data are analysed through the formation of interferograms that are obtained using the Delft Object-oriented Radar Interferometric Software (DORIS) and Persistent Scatterer Interferometry (PSI) performed following the Delft Persistent Scatterer Interferometry (DePSI) algorithm.<br/>The interferograms and PSI results differ strongly per satellite and are affected by the combined impact of several factors. In this study the impact of the misalignment of the master image used in the generation of the interferograms with respect to the Digital Elevation Model (DEM) is discussed, as well as the impact of the incidence angle, the spatial resolution, the temporal resolution, the perpendicular baseline, the number of available images and the wavelength.<br/>The interferograms of ALOS-2 are of a good quality, however the low temporal resolution makes studying fast surface deformation difficult. However, they could be used to study surface changes in retrospect or to study slower processes, such as the pressurisation of a magma chamber, causing gradual surface deformation. The<br/>low spatial resolution makes the interferograms of Sentinel-1 difficult to interpret and the interferograms for the PAZ data currently show too large amounts of decorrelation to study surface deformations. <br/>The PSI analysis produces reliable results for Sentinel-1. The estimated linear deformation for the Persistent Scatterers (PS) shows constant values over both islands, which are centred around 0 mm/y and have low standard deviations. Therefore it is assumed, based on the data and prior knowledge about the area, that there is currently no deformation on either of the islands. The PSI analyses for the other two satellites do not provide reliable results, because the number of available images in the stacks is too low (only 10-12 images compared to the 116-123 available images for Sentinel-1). The PAZ data might be used in the future, when more images are available, however the low temporal resolution of the ALOS-2 data means that an appropriate stack cannot be acquired within the design lifetime of the satellite.<br/>The ALOS-2 interferograms and the PSI analysis for Sentinel-1 could thus at present be a useful addition to the ground-based monitoring network. When a larger stack of data for PAZ is available, the PSI analysis could potentially be conducted again in order to determine its use as a volcanic monitoring tool.<br","Saba; St. Eustatius; InSAR; PSI; Volcanic monitoring","en","master thesis","","","","","","","","","","","","","",""
"uuid:df8bfc0e-81da-45ad-b83e-8b9bd18ed4a6","http://resolver.tudelft.nl/uuid:df8bfc0e-81da-45ad-b83e-8b9bd18ed4a6","Simulations of Open Quantum Systems and Decoherence-Free Subspaces","Weerheim, M.W. (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Applied Sciences)","Dubbeldam, J.L.A. (mentor); Blanter, Y.M. (mentor); Delft University of Technology (degree granting institution)","2020","Complex quantum systems, such as a quantum computer, will always be coupled in some way to the environment. This can cause what's called decoherence, a destructive process by which information is lost from the system into the environment. In this bachelor thesis paper, we discuss decoherence-free subspaces within networks of coupled quantum harmonic oscillators (or QHOs). We investigate where such noiseless subspaces (or NSs) occur most frequently in an ensemble of Erdos-Renyi networks, for which we do not yet consider the influence of the bath. We then proceed by adding the bath into the equation, using some of the theory of open quantum systems. Specifically, we derive the Lindblad master equation and show its form for the case of our networks. Consequently, we simulate the behavior of the moments of the position operators for the graphs with 3 nodes, both by means of the full Lindblad equation, and by first tracing out those moments to obtain their differential equations. We compare those two results to each other, and also look back to the situation before adding the bath to see if the NSs are still present.<br/>From the results of the simulations, we can conclude several things. Firstly, we see that for ensembles with probability of connection p very close to either 0 or 1, both to number of noiseless modes and the probability of finding at least one is largest. This is credited to their relatively high degrees of symmetry. Secondly, in the results of the density matrix and moment simulations, we see that, indeed, the noiseless modes are preserved when considering the influence of the bath. Furthermore, we can conclude that simulation of the density matrix for the case of coupled QHOs in a network is in many cases not stable; the cutoff at a finite level s needed to simulate an otherwise infinite- dimensional operator leads to non-positivity of the density matrix. Therefore, it is best to simulate the moments from their respective differential equations, as opposed to the full Lindblad master equation. Finally, the differential equations for the moments and their solutions show that there are indeed noiseless clusters for eigenmodes perpendicular to the center of mass, as predicted.","","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics | Applied Physics","",""
"uuid:c836e462-b80e-4bf0-b1cb-7805574ebd0d","http://resolver.tudelft.nl/uuid:c836e462-b80e-4bf0-b1cb-7805574ebd0d","Classical and Quantum Simulation of Stoquastic Hamiltonian Systems","Stroeks, Maarten (TU Delft Applied Sciences)","Terhal, B.M. (mentor); Delft University of Technology (degree granting institution)","2020","Quantum systems are in general not e_ciently simulatable by classical means. If one wishes to determine (some of) the eigenvalues of a Hamiltonian H that is associated with a quantum system, there are two favoured strategies: Quantum simulation and quantum Monte Carlo schemes. The former strategy uses an experimentally well-controllable quantum system that emulates the system of interest, in a digital (i.e. universal) or analog manner. The latter, albeit with a limited range of applicability, uses classical stochastic processes to e_ciently obtain (often low-lying) eigenvalues of H. Quantum Monte Carlo methods may su_er from a sign problem when simulating fermionic or frustrated bosonic systems. This yields, for a given accuracy, a simulation time that scales exponentially in the system size and the inverse temperature.","Quantum Mechanics; Quantum Information; Stoquastic Hamiltonian; Quantum Simulation; Quantum Phase Estimation; Quantum Monte Carlo","en","master thesis","","","","","","","","","","","","Applied Physics | Casimir Track","",""
"uuid:461562db-f47b-42e8-a71d-a5f9796e8454","http://resolver.tudelft.nl/uuid:461562db-f47b-42e8-a71d-a5f9796e8454","Classical Capacities of Classical and Quantum Channels","Borsboom, Silvester (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Applied Sciences; TU Delft QuTech)","Elkouss Coronas, D. (mentor); Janssens, B. (graduation committee); Groeblacher, S. (graduation committee); Gijswijt, D.C. (graduation committee); Delft University of Technology (degree granting institution)","2020","This thesis investigates two types of classical capacities of both classical and quantum channels, giving rise to four different settings. The first type of classical capacity investigated is the ordinary capacity of a channel to transmit classical information with a probability of error which becomes arbitrarily small as the channel is used arbitrarily many times. The second type of classical capacity investigated is the capacity of a channel to transmit information with zero probability of error, called the zero-error classical capacity. The first setting which is studied is the ordinary capacity of a classical channel. The noisy channel coding theorem is proven in two different ways: one using the Markov inequality and the Law of Large Numbers and one using typical sets. The additivity of this capacity is also discussed. The second setting is the zero-error capacity of classical channel. Lower and upper bounds on this capacity are proven, and its superadditivity is discussed. The third setting is the ordinary classical capacity of a quantum channel. The Holevo-Schumacher-Westmoreland theorem is proven using typical subspaces and the packing lemma, and the superadditivity of the Holevo information is discussed in terms of entanglement at the encoder. The fourth and last setting investigated is that of the zero-error classical capacity of a quantum channel. It is shown that this capacity can be achieved using only pure input states and that this capacity never exceeds the ordinary classical capacity. Moreover, a detailed investigation of superactivation of the zero-error classical capacity is presented. A topic for further research would be an exposition of the analogous concepts in the case of the quantum capacity of quantum channels. Another topic for further research would be an explicit construction of two quantum channels whose zero-error classical capacity is superactivated.","Quantum; Information; Channel; Capacity; Classical","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics | Applied Physics","",""
"uuid:8b32481a-d3ac-4fff-a4ed-b5dca77ea172","http://resolver.tudelft.nl/uuid:8b32481a-d3ac-4fff-a4ed-b5dca77ea172","Simultaneous optimization of rolling stock maintenance scheduling and rolling stock maintenance location choice","Zomer, J. (TU Delft Civil Engineering and Geosciences)","Goverde, R.M.P. (graduation committee); Besinovic, N. (mentor); de Weerdt, M.M. (mentor); Holtzer, J.J.H.M. (mentor); Oldenziel, W. (mentor); Delft University of Technology (degree granting institution)","2020","The current research addresses a problem found in the area of railway operations regarding the maintenance of rolling stock units. It focuses on the situation in The Netherlands and approaches the problem from the perspective of its main railway operator N.V. Nederlandse Spoorwegen (NS).<br/>The increasing use of the capacity of the railway network leads to two issues. First, the complexity of the scheduling process is increasing, raising the need for tools that automate this process. Second, since NS is considering to perform more maintenance activities during daytime, raising the question at which locations maintenance teams needs to be stationed to perform daytime maintenance. These issues are interrelated.<br/>The model development in the current research, tackling the aforementioned issues, can be understood as a three-stage framework. Assuming a given rolling stock circulation, the first stage aims to find the maintenance schedule and maintenance location choice minimizing the total number of nighttime maintenance activities. The second stage introduces a model to compute the required capacity. The third stage integrates the first and second stage, aiming to find a solution to the first-stage model that satisfies some predetermined maintenance location capacity constraints that can be determined by the second-stage model.<br/>First, it is shown that, for a scenario with 20 maintenance locations for daytime maintenance, up to 42.0% of the work can be performed during daytime. Also, the second model can be used to efficiently (i.e. within seconds) compute required capacity and an accurate maintenance activity planning. Moreover, results for the third model have been generated showing, for example, that in one considered problem instance, the number of maintenance shifts for which the required capacity exceeds the available capacity can be reduced from 21 to 5 in 7.6 minutes. In addition to the aforementioned experimental results, a more practical approach is taken as well by constructing a small use case, demonstrating how the current research can be applied in practical situations. To this end, planning software Viriato is used, by which various visualizations of maintenance schedules can be provided.","","en","master thesis","","","","","","","","","","","","","",""
"uuid:a8f470b5-f2e2-4ede-a89e-f563a66e803e","http://resolver.tudelft.nl/uuid:a8f470b5-f2e2-4ede-a89e-f563a66e803e","Integrating vulnerability analysis into the early stage distributed ship system design process","van Diessen, Martijn (TU Delft Mechanical, Maritime and Materials Engineering)","Kana, A.A. (mentor); Duchateau, E.A.E. (mentor); Hopman, J.J. (graduation committee); Mohajerin Esfahani, P. (graduation committee); Delft University of Technology (degree granting institution)","2020","Naval ships need to be able to conduct missions in a variety of circumstances. This includes the ability to fulfil specific tasks in a damaged state. Vulnerability reduction measures are taken during the early stage distributed ship system design process, to ensure the availability of the required systems in damaged state. Traditionally these vulnerability reduction measures are based on design rules or best practices resulting from past experiences. Therefore the measures are not per definition applicable for future warships, as both the system concepts and operational environment changes. Recently developed vulnerability assessment methods are able to determine the vulnerability of a design early in the design process. With integration of these methods in the early stage design process, the results of the analysis can be used to generate less vulnerable distributed ship system designs. This thesis proposes an integral and holistic approach of optimization of the design variables and distributed networks as these are becoming increasingly interdependent. The result of this approach is a model which generates distributed ship system designs consisting of component positions, a topology and routed connections based on a pre-defined system configuration and constraining physical architecture. Five testcases were conducted using this model, showing the necessity of the integral and holistic approach as the extent to which the contemporary design rules are implemented depends on the network complexity and operational environment. The developed method assists the naval architect in generating designs and requirement elucidation in the concept exploration stage.","Vulnerability; Naval Ships; Distributed systems; Ship design","en","master thesis","","","","","","","","","","","","Marine Technology | Ship Design, Production and Operations","",""
"uuid:2d82e069-1036-4c80-8bc5-70be324d18f1","http://resolver.tudelft.nl/uuid:2d82e069-1036-4c80-8bc5-70be324d18f1","Optical performance and drilling forces of an orthopaedic DRS drill with a stagnant optical probe","Kan, Matthijs (TU Delft Mechanical, Maritime and Materials Engineering)","Hendriks, B.H.W. (mentor); Dankelman, J. (mentor); Swamy, A. (mentor); Bhattacharya, N. (graduation committee); Delft University of Technology (degree granting institution)","2020","Introduction. In spinal surgery, the misplacement of spinal screws is a problem that causes (severe) pain, bleedings or even paralysis [2]. Screw misplacements are common as navigating in the spine is difficult due to the small vertebral dimensions and a lack of anatomical landmarks [3] [4]. In order to improve the navigational support of spine surgeons, this research focuses on the development of an optical sensing diffuse reflectance spectroscopy (DRS) surgical drill that identifies bone tissue boundaries. The developed drill concept introduces a stagnant optical fiber-equipped probe into a cannulated orthopaedic drill. To verify the clinical applicability of the developed system, the accuracy of the optical tissue boundary detection has been analysed under different tissue penetration speeds, as well as the axial drilling force increases due to the introduction of a stagnant probe into a drill.<br/>Results. When increasing the drilling feed rate in the optical phantom, the drill overshoot (the difference between the DRS-derived tissue boundary location identification and the actual location of the phantom boundary) shows a larger spread. The maximum feed rate at which no overshoot takes place is 0,5mm/s. Increasing the sampling frequency –especially decreasing the inactive period between the measurements– can improve this.<br/>None of the K-wire equipped drills can penetrate the used Sawbones® cortical bone phantom. The axial peak feed forces occurring in the Sawbones® cancellous bone phantom while using a regular 2,7mmØ orthopaedic drill is 38,2N. When using the 2,7mmØ orthopaedic drill with a 1,6mmØ K-wire, a peak of 57,6N is observed. Because the data from drilling in the Sawbones® cancellous bone is not normally distributed, a benchmark experiment on cheese is analysed. On average, the introduction of a K-wire increases the required drilling forces by a 296% (roughly a factor 3). Among the different feed rates and drill types, the force increase of introducing a stagnant K-wire varies between 16% and 575%.<br/>Conclusion. To prevent orthopaedic screws from breaching the bone surface (an overshoot of 0mm) in spinal surgery, the established feed rate speed limit of 0,5mm/s is too low. To meet the observed feed rates applied by surgeons of up to 5mm/s, it is of interest to reduce the DRS sampling time – the inactive period between two measurements in particular. The feed force increase of approximately a factor 3 can be regarded as a challenge for surgeons, who indicated that they preferred feed forces to be kept low. Further testing on real (cadaveric) vertebrae can more give information about the DRS drill’s optical performance in pedicles, and whether the identified feed force increase proves to be problematic for clinical applications.","Orthopaedic; Drilling; Diffuse reflectance spectroscopy","en","master thesis","","","","","","","","2025-08-18","","","","Biomedical Engineering | Medical Instruments and Medical Safety (MIMS)","",""
"uuid:954099d2-93ca-429f-9571-e74172b9563c","http://resolver.tudelft.nl/uuid:954099d2-93ca-429f-9571-e74172b9563c","Could climbing up Maslow's pyramid help us solve the world's environmental problems?: A study of the impact of human development from material to non-material needs on the environment","Karathozhuvu Suresh, Ashwini (TU Delft Technology, Policy and Management)","Naastepad, C.W.M. (mentor); Schröder, E. (graduation committee); Slinger, J (graduation committee); Delft University of Technology (degree granting institution)","2020","Our planet is witnessing an unprecedented increase in temperature that is causing frequent damages such as extreme weather conditions, acidification of oceans and extinction of species that may soon become irreparable. Various studies have reported that greenhouse gas emissions (GHG) from human activities in industries that produce 'material goods' like transportation, energy, manufacturing and agriculture have been the chief drivers of the climate change crisis. Even as greener and renewable energy technologies are increasingly being adopted, since consumption of material goods in the rich parts of the world continue to increase, it may not be enough to solve the environmental problems in time. However, we may be able to solve them by adopting a different way of living. In order to do so, we need to understand the purpose of the economy. According to Aristotle, Eudaimonia or the 'good life’ which is the full development of human capabilities or virtues is the ultimate end of human life and the purpose of the economy or the production and consumption of material goods by people are simply a means towards this ultimate end. A similar idea that human beings have an ultimate end towards which all actions are directed can also be found with the more popularly known Maslow’s hierarchy of needs. This essentially means that human beings need material wealth only insofar that it supports the fulfilment of their non-material needs: the development of capacities/virtues. 'Non-material' can refer to needs such as enjoying a classical dance performance, or studying philosophy or engaging in therapy. This perspective allows us to rethink growth in terms of a shift from material to non-material needs, which could also help solve the world's environmental problems as long as non-material needs can be met in less polluting ways (as compared to how material needs are met). Following this, economic activities are classified as physical (or goods-producing) or non-physical. Activities in the physical economy meet material needs and have a higher potential for productivity growth. Activities in the non-physical economy, including health care, education, research and arts, meet non-material needs and have a lower potential for productivity growth since human work is generally the final output. Based on this classification, it is observed that, in the advanced economies, the share of the physical economy in total demand is getting smaller, while the share of the non-physical economy is getting bigger over time, reflecting human development from material to non-material growth. If the non-physical economy − which consists mainly of human work such as a doctor's advice, a lesson, a concert − is relatively less polluting, such a shift could mean good news for the environment. While this looks promising, a consequence of the lower potential for productivity growth in the non-physical economy is that their activities can be expensive. Baumol (1993), termed this the 'cost disease' and argued that people in the rich parts of the world can afford the expensive 'personal services' when funds resulting from the productivity gains in the physical economy (due to labour-saving innovations) are transferred to the non-physical economy. Yet, nowadays, the standard response to the 'cost disease' is to replace human work with technology through standardisation, computerisation and robotisation of hitherto human tasks as a way to minimise costs. Due to the nature of work in the non-physical economy, the growing technology/ material-intensity can affect the quality of the non-material value created, while it may also increase the pressure on the environment. This led me to investigate the impact of the rising technology-intensity in the non-physical economy on the quality of outcome and on the environment. One of the main activities in the non-physical economy, health care, is 'an art and a science' in the sense that it takes care of the health of a human being in order to enable him to develop intellectually and psychologically and it is not just about 'fixing' what is broken. Doctors, therapists and nurses are people who possess besides clinical knowledge, interpersonal skills such as understanding and empathy to carry out complex human interactions with patients. Yet, in recent times, especially in the United States, technologies such as electronic health records (EHR), e-prescribing, tele-medicine and health apps are increasingly being adopted to displace some of the creative work performed by health care professionals. The main drivers of such trends identified are: the privatisation of health care, the systems of 'Managed Care' and government measures such as the American Recovery and Reinvestment Act (ARRA) of 2009 that allocated funds to incorporate health information technologies in health care facilities across the country. Some of the common experiences found with the adoption of technology in health care are: a supplier-induced demand for drugs and medical technologies due to a 'fee-for-service' payment model for doctors, a 'technology arms race' between hospitals and ‘direct-to-consumer’ advertising of medicines and medical technologies. Some of the consequences of these trends found are: unnecessary testing leading to increased overall health care costs, 'physician deskilling' due to decreased clinical knowledge and psychological and health implications for patients due to less physician-patient interactions and more 'end-of-pipe' solutions. From a brief review, it is also found that the health care system in Canada is less technology-/material-intensive than the health care system in the U.S. with (roughly) the same quality of service which shows that different kinds of health care systems can coexist with one another. A second activity of the non-physical economy, education, is one that enhances the intellectual and spiritual development of students, guided by a curriculum. According to various studies, teachers are indispensable in this activity in terms of their personal knowledge, their pedagogical capacities and their ability to instill curiosity, enthusiasm, sympathy, and morality in students through complex and dynamic interactions. Yet, similar to health care, even the creative work of teachers are being displaced with Information and Communication Technologies (ICT) such as: talent management software, digital learning technologies, MOOCs, allegedly to improve quality of education. In the United States, some of the trends commonly found to promote such technologies are: a pay-for-performance model for teachers to improve productivity of student grades, a common core standard curriculum and standardized tests for students to get them ready for college and careers. Some of the consequences of the growing technology intensity in education are found to be: teacher deskilling, lack of evidence of improved student performances and psychological implications for students such as diminished social skills, lack of creative and original thinking etc. These findings suggest that the growing technology-intensity in health care and education may have not significantly improved the quality of service provided, especially since the nature of work in these activities are different. Besides this, they could also lead to a higher environmental burden. In this thesis, I investigate whether the latter is the case, which is done in two steps. First, I investigate whether the non-physical economy is less polluting than the physical economy. Next, I examine the environmental consequences of the rising technology-intensity of the non-physical economy. The empirical research method applied is the Environmentally Extended Input-Output (EE-IO) analysis, which is used to compute the direct and indirect environmental effects of the physical and the non-physical economy. Direct effects refer to the pollution recorded at the place where it arises (for example, emissions due to health care). Indirect effects refer to the pollution caused by industries that supply inputs to health care, and for which the health care sector (as sector of use) is (indirectly) responsible. Through an EE-IO analysis, environmental effects (such as emissions) are ascribed to the sector of use, by reallocating emissions from the sector where they originate (sector of origin) to the sector that uses the goods or services supplied by this sector. The EE-IO analysis makes use of an Input-Output (I-O) table which records intermediate deliveries of goods and services between sectors in an economy, as well as each sector's deliveries to final demand. In addition, it uses the environmental accounts of each sector to compute the total emissions for which a sector can be held responsible, which consist of its own (direct) emissions plus the emissions that are related to the inputs it purchases from other industries. The two equations that guide this computation are B=b*(1-A)¯¹ and E=B*f where B= a vector of total (direct+indirect) emission intensities (per sector); b=direct emission intensity vector; (1-A)¯¹= the 'Leontief Inverse matrix' (derived from an I-O table) that represents the technical coefficients or the total (direct+indirect) inputs required per unit of a sector's output; f=final demand and E=a vector of total (direct + indirect) emissions per sector for a given level of final demand f. The results found were that the non-physical economy in the United States is less polluting in terms of global warming and acidification potential, energy use and tropospheric ozone gas emissions, even if emissions are re-allocated from sector of origin to sector of use. This result suggests that the impact on the environment will be lower if human beings become increasingly interested in non-material rather than material growth. However, this result may not come about if the non-physical economy gets more technology-intensive. To empirically investigate the increase in technology-intensity in health care and its corresponding environmental burden, two comparative studies based on the EE-IO analysis were carried out. The first one compared the health care system in the United States between 1995 and 2015. After adjusting both I-O tables for inflation (using Miller &amp; Blair’s (2009) ""double deflation"" method) and regrouping them for comparable sector classifications, it is shown that the health care sector's technical (Leontief inverse) coefficients increased for 'computer, electronic &amp; optical equipment', 'post &amp; telecommunications', 'electricity &amp; water supply', and 'renting &amp; other business services' − indicating that the technology- or material-intensity (in terms of medical technology, ICT, administrative technology) as well as the electricity-intensity of health care increased from 1995 to 2015. Although the use of 'chemicals &amp; pharmaceutical products' in the health care sector itself decreased, final demand for chemicals &amp; pharmaceuticals per capita almost doubled between 1995 and 2015. In sum, the results found showed that technology/material-intensity in terms of ICT, medical technologies, energy use per unit of output and medicines per capita increased from 1995 to 2015. These data support, or at least do not falsify, the hypothesis of a trend towards higher technology-intensity of health care. However, the result for the environmental burden of the increased technology-intensity was found to be mixed. Firstly, total CO2 emission intensity of health care and the indirect contribution from 'post &amp; telecommunications', 'computer, electronic &amp; optical equipment' and 'renting &amp; other business services' decreased from 1995 to 2015, largely due to an economy-wide switch to less carbon-intensive sources of energy. Although the shift from coal to natural gas reduced CO2 emissions, it also led to other types of environmental problems, such as those associated with increased production of shale gas. Secondly, the indirect emission contribution from 'electricity &amp; water supply' industry to health care's carbon intensity increased due to the increase in energy use per unit of output (possibly due to increased use of medical equipment and other technologies in hospitals). This also led to higher total (direct+indirect) emissions from the health care sector in 2015 than in 1995 for the respective levels of final demand. Therefore, as long as the technology-intensity of health care keeps rising, this is likely to involve rising pressure on the environment (not only in terms of emissions but also in terms of increased use of earth's finite resources). The second study compared the health care system in the United States with the health care system in Canada for the year 2014. The results showed that the U.S. health care sector's technical coefficients were higher than those of Canada's health care for the relevant sectors examined in the previous study. This shows that U.S. health care is more technology-/ material-intensive in terms of medicines, medical technology, ICT and administrative technology than Canada's health care while reliance on human work is lower. Next, the total (direct+indirect) carbon-intensity of U.S. health care was also found to be higher than that of Canada's health care. This is mainly because the indirect emission contribution from sectors, namely, 'chemical &amp; pharmaceuticals', 'renting &amp; other business services', 'electricity &amp; water supply' 'computer programming &amp; information services' to health care are higher in the U.S.. However, the indirect emission contribution from sectors 'telecommunications' and 'computer, electronic &amp; optical products' are found to be lower in the U.S. (in spite of a higher use of their goods per unit of output), possibly due to a lower carbon-intensity of these two sectors in the U.S. than in Canada. All in all, the important insight from these two studies is that even though increased purchase of medicines, ICT and related medical &amp; administrative technologies by health care activities in the U.S. between 1995 and 2015 has not led to higher total CO2 emission intensity of health care, we know that as of 2014, high-tech health care in the U.S. is still more polluting than Canada's health care. This supports the argument that replacement of human work with technological solutions in the non-physical economy may lead to a higher environmental burden. In conclusion, since there is lack of conclusive evidence that the promotion of general, country-wide transition to high-tech health care (or education and arts) reduces costs while improving quality and reducing environmental burden, it may be desirable that free choice of technology in the non-physical economy is encouraged. The resulting diversity, or mix of low-tech and high-tech approaches in health care, education, arts, etc. would be less polluting than a linear high-tech approach in the non-physical economy, while leaving providers as well as recipients of services in the non-physical economy free to explore different technological paths.","Climate change; Eudaimonia; health IT; EEIOA","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:c05b1f17-866a-4e7d-986f-a99ef15b4c1c","http://resolver.tudelft.nl/uuid:c05b1f17-866a-4e7d-986f-a99ef15b4c1c","A framework to find applications for organic molecules","van Mullem, Jesse (TU Delft Applied Sciences; TU Delft Technology, Policy and Management)","Ortt, J.R. (mentor); van der Voort, H.G. (mentor); de Haan, A.B. (mentor); Delft University of Technology (degree granting institution)","2020","Innovation is an important determinant for success in a fast changing world. For innovation to take place, scientific knowledge that has a proven working principle needs to find an application. The process in which applications are generated or identified has been identified as an important aspect of the innovation process. However, scientific literature on application generation or identification is underdeveloped. The aim of this thesis was to develop a framework to generate or identify applications for organic molecules in a systematic way. This has been formulated into a research question as “Can a framework be developed to systematically search for applications for organic molecules?”. Before this framework for organic molecules was developed, first a general framework to generate or identify applications for technology was created. Apart from the main research question, three sub research questions are answered in this research: Can a framework to systematically search for applications for technology be developed? How can such a framework be translated to a framework for organic molecules? How can this/these framework(s) be validated? The framework was created using a design approach. The thesis draws on interviews with experts, scientific literature on application generation/identification frameworks and a discussion with experts. In the preliminary literature study, the notion that the literature on the subject of application generation or identification is underdeveloped was confirmed. The available literature provided insufficient base to build this thesis, so a design approach was taken as alternative. The first step in this approach was a series of interviews with experts on innovation and application generation/identification. With the data from these interviews, a first version of the general framework was created. This first version was validated and improved by comparing it to frameworks from literature, by conducting a second series of interviews and by a discussion with experts. The next step envisioned in the research was a translation of the general framework into a framework that can be used to generate or identify applications for organic molecules. A start was made on the translation of the framework by providing methods that can be used in subsequent research to translate the framework. The translation chapter used information from the second series of interviews as a starting point. Following this research, four recommendations were made for future research project. The first recommendation is to further develop the framework created in this research project, for example by exploring creativity methods. Secondly, it is recommended to conduct a full systematic literature review, using the vocabulary learned throughout this thesis. Thirdly, the framework created in this thesis should be translated. Before translation can take place, it has to be researched what the best method for this translation is. The translation methods provided in this thesis could be used. Alternatively, new methods for translation could be devised and implemented. Finally, in future research, several concept used in this research should be defined more carefully. Obtaining more clear and workable definitions for these concept will decrease the ambiguity of future research using these concepts. In conclusion, in this thesis, a framework to systematically generate or identify applications for technology (or rather, a concept in between scientific knowledge and technology) has been developed. Recommendations have been provided on how this framework could be further improved. On top of that, this research proposes methods for translation of this framework into a framework to systematically generate or identify applications for organic molecules. The actual translation has to take place in subsequent research.","","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:ed52186d-40b5-4ded-be97-388ad55d9aad","http://resolver.tudelft.nl/uuid:ed52186d-40b5-4ded-be97-388ad55d9aad","Machine learning and image analysis on photos of a solitary tree in a complex background: extraction and analysis of key properties for wind-tree interaction","Bekkers, Casper (TU Delft Aerospace Engineering)","Watson, S.J. (mentor); Viré, A.C. (mentor); Dellwik, E. (mentor); Dahl, A.B. (mentor); Delft University of Technology (degree granting institution); Technical University of Denmark (degree granting institution)","2020","A method is developed to automatically analyze over 200000 images of a single mature tree. This method is assessed and applied to a tree located at Risø in Roskilde, Denmark, next to two meteorological masts. Image aspects such as the surface area and the center of area are extracted from the images and they are related to the wind statistics. Concurrence is found between expected behaviors and observations to validate the method and unexpected behaviors are documented. Expected behaviors include the decrease in surface area with an increase in wind speed, swaying directional dependency with wind direction and swaying magnitude dependency with wind speed. New behaviors include a non-linear relationship between porosity and wind deficit and an increase in surface area with wind speed from infrequent wind directions. Furthermore, a specific period is analyzed which determined that for this tree, roughly half of the Vogel exponent is attributed to the decrease in surface area.","Wind; Energy; Image analysis; Tree models","en","master thesis","","","","","","","","2020-08-04","","","","European Wind Energy Masters (EWEM) | Rotor Design Track","","55.688686, 12.095864"
"uuid:5e53b541-1428-4292-8f09-e37248454b32","http://resolver.tudelft.nl/uuid:5e53b541-1428-4292-8f09-e37248454b32","Evaluation of Stability for Different Stoping Sequences through the use of Numerical Modelling: Case Study - Cavanacaw Gold Mine, Northern Ireland","Monteith, David (TU Delft Civil Engineering and Geosciences)","Buxton, M.W.N. (mentor); Dieudonné, A.A.M. (mentor); Brinkgreve, R.B.J. (mentor); Rinne, Mikael (mentor); Lottermoser, Bernd (mentor); Delft University of Technology (degree granting institution)","2020","The current plan of bottom to top bottom sublevel stoping for the Kearney gold vein at the Cavanacaw mine, Omagh, Northern Ireland may not be the most effective in terms of stability. The Kearney ore body is a narrow vein gold deposit, which has been previously exploited through an open pit and is currently being developed as an underground operation using sublevel stoping (modified Avoca mining method). Stability within the mine is one of the key factors to be considered when it comes to hard rock mining. It should be considered equally as important from a safety and economic point of view. The extraction sequence plays an important role when considering the stability of a designed mine. This thesis aims to establish if the current planned sequence of extraction of bottom to top sublevel stoping is the most effective in terms of overall rock stability, or whether an alternative plan would be better? In the context of this thesis, the modified Avoca mining method is a form of sublevel stoping where material is extracted (stoped) between two drives (blind tunnels) and then backfilled.<br/>The project addressed, a conceptual study, field testing and laboratory testing in order to yield the information required to build several numerical models. The numerical modelling was carried out on several different stoping orders which met the constraints set out by Galantas, using the Hoek-Brown model within Plaxis2D. The analysis was conducted on the total displacements, phase displacements, predicted failure points and safety factors. The analysis of the different models showed that an alter- native stoping method of middle to top bottom to middle sublevel stoping peformed better in terms of stability. This improvement in stability was shown by an increase in the minimum safety factor from 3.20 to 3.50, over the current plan. There is further evidence in the reduction of the total number of predicted failure point by 25%.","Numerical Modelling; Stoping; mining","en","master thesis","","","","","","","","","","","","","",""
"uuid:bb9d869e-f9a9-4a7f-8db0-9a16e4bda6b9","http://resolver.tudelft.nl/uuid:bb9d869e-f9a9-4a7f-8db0-9a16e4bda6b9","Effect of Melanoidins and Metals on Hydrolysis in Anaerobic Digestion","Sutaria, Sasha (TU Delft Civil Engineering and Geosciences)","de Kreuk, M.K. (graduation committee); van Lier, J.B. (graduation committee); Kleerebezem, R. (graduation committee); Pavez Jara, J.A. (mentor); Delft University of Technology (degree granting institution)","2020","Sludge management has gained importance over the years due to high sludge treatment and disposal cost, stringent disposal laws, and a need to move towards sustainable energy production. Anaerobic Digestion (AD) of waste activated sludge (WAS) is a favoured sludge stabilisation technique due to its low energy footprint. Hydrolysis – the first step in AD is often the rate-limiting step and thus pre-treatment such as Thermal Hydrolysis Process (THP) are implemented before AD to improve the biodegradability of WAS and biogas production. However, THP leads to the formation of recalcitrant compounds such as melanoidins which are presumed to have a similar effect as Humic substances on AD. Also, THP leads to the release of metals incorporated in sludge flocs by the degradation of extracellular polymeric substances (EPS) structures. Therefore, this study aimed to understand the effect of melanoidins and metals on the hydrolysis step in AD. <br/>The interaction between melanoidins and cations Fe<sup>2+</sup>, Ca<sup>2+</sup>, Mg<sup>2+</sup>, Cu<sup>2+</sup>, K<sup>+</sup>, and NH<sub>4</sub><sup>+</sup> was studied using ultra-filtration and ICP-MS. The effect of these melanoidins-metals interactions on enzymatic hydrolysis of cellulose and proteins was investigated using fluorescence essay and Response Surface Methodology (RSM) modeling. The mechanism of inhibition of hydrolysis by melanoidins and metal was investigated using SEC-HPLC. <br/>The results showed that complexation of melanoidins with metals shows the trend - Fe<sup>2+</sup> &gt; Ca<sup>2+</sup> &gt; Mg<sup>2+</sup> &gt; Cu<sup>2+</sup> &gt; K<sup>+</sup> ≥ NH<sub>4</sub><sup>+</sup>. The ions with higher charge and ionic radius interacted with melanoidins more effectively. The melanoidins-metal interaction increased with an increase in melanoidins concentration most likely due to more phenolic and carboxylic functional groups available for binding. Fe<sup>3+</sup> leads to an increase in molecular weight (MW) of melanoidins due to inter-molecular interaction caused by complete charge neutralisation, while no MW changes are observed with Cu<sup>2+</sup> and Ca<sup>2+</sup>. Individually, melanoidins decreased, Fe<sup>3+</sup> increased, while Cu<sup>2+</sup> decreased the rate of hydrolysis of cellulose. In the presence of melanoidins, the inhibiting effect of Cu<sup>2+</sup> is decreased with increasing melanoidins concentration. Similarly, the positive effect of Fe<sup>3+</sup> is decreased with increasing melanoidins concentration. Protein hydrolysis was completely inhibited with 3 mM metals concentration. Melanoidins and Fe<sup>3+</sup> concentrations had no major impact on protein hydrolysis while Cu<sup>2+</sup> inhibits hydrolysis even at 0.15 mM concentration. <br/>Therefore, it was hypothesised that Cu<sup>2+</sup> causes enzymatic inhibition, but in the presence of melanoidins, melanoidins-Cu<sup>2+</sup> complexes formation mitigates the toxic effect of Cu<sup>2+</sup> on hydrolysis thus improving the rate of hydrolysis. While, Fe<sup>3+</sup> improved hydrolysis by facilitating substrate-enzyme interaction but in presence of melanoidins, melanoidins-Fe<sup>3+</sup> complexation leads to the non-availability of Fe<sup>3+</sup> to facilitate hydrolysis process thus having no major impact on the rate of hydrolysis.<br","Thermal hydrolysis process; Anaerobic Digestion; Melanoidins; Humic substances; hydrolysis","en","master thesis","","","","","","","","2021-08-18","","","","Civil Engineering | Environmental Engineering","",""
"uuid:f1e4b495-d2ad-4a1e-803e-13e6c9b39f4a","http://resolver.tudelft.nl/uuid:f1e4b495-d2ad-4a1e-803e-13e6c9b39f4a","Predicting Short-term Bus Ridership with Trip Planner Data: A Machine Learning Approach","Wang, Ziyulong (TU Delft Civil Engineering and Geosciences)","Pel, A.J. (mentor); Verma, T. (graduation committee); Krishnakumari, P.K. (graduation committee); van Oort, N. (graduation committee); van Brakel, P. (graduation committee); Delft University of Technology (degree granting institution)","2020","To address the increasing passenger demand in the coming years and make public transport less crowded and delayed, insights into predicted passenger flow are needed. A wide range of studies has used and validated that smart card data can be one of the sound bases for predicting short-term passenger demand. However, it also has several disadvantages, such as the relatively long collection time, the insufficiency to reflect the relationship between passenger behavior and ridership. Trip planner data, which emerged as a type of real-time transit information, could reduce the perceived waiting time of passengers and increase the transit ridership due to the improved satisfaction. Combining these two types of data could potentially cater to the interest of operators in matching the vehicle supply and passenger flow demand at an operational level. Our results show that it is novel and useful to incorporate trip planner data in short-term ridership prediction, however, entirely based on this kind of data would be inaccurate. Random Forest Regression outperforms the other six models that we have selected. The request-related features (variables) can take up 20% of the importance of short-term ridership prediction.","Public transport; Trip Planner; Ridership prediction; Short term forecasting; Machine Learning","en","master thesis","","","","","","","","2021-05-31","","","","","",""
"uuid:b3e45f8a-ebef-4176-ae06-ac62827c1647","http://resolver.tudelft.nl/uuid:b3e45f8a-ebef-4176-ae06-ac62827c1647","Electrical Grid readiness for the European Energy Transition","Dalla Pozza, Gilberto (TU Delft Electrical Engineering, Mathematics and Computer Science)","Blok, K. (mentor); Scholten, D.J. (graduation committee); van der Meijden, M.A.M.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","Comparative study on the necessary upgrade in European interconnections to sustain solar and wind sources uptake in the energy mix. Grid Development for most difficult borders, and planning recommendations, to reach Paris compatible scenario by 2040.","Electrical Grid; Renewable Energy Sources; Paris agreement; Interconnection; ENTSO-e; Scenario planning; Grid Planning; 2040","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:c220c788-5402-479d-9dae-e8be12f2cadd","http://resolver.tudelft.nl/uuid:c220c788-5402-479d-9dae-e8be12f2cadd","Wind Turbine Design for a Hybrid System: with the emphasis on generation complementarity","Qamar, Fadhil Ahmad (TU Delft Electrical Engineering, Mathematics and Computer Science)","Zaayer, M.B. (mentor); Quist, J.N. (mentor); von Terzi, D.A. (graduation committee); Delft University of Technology (degree granting institution)","2020","The global issue on global warming leads nations to reduce their carbon emission, and one way to do it is by decarbonising the power system and employing higher penetration of renewable energy technology. However, due to the variable nature of renewable energy, their integration to the power system poses challenges to the utilities and system operators. Hybrid power system, due to its feature of complementary generations, serves as one of the option to answer the integration issues. This research studies the optimisation of a hybrid power system, consisting of a wind turbine and solar PV, by designing the wind turbine that operates in such systems. The design approach of the wind turbine design emphasises the complementary generation feature of the hybrid power system, which is conducted by optimising the wind generation for times when the output power from the solar PV are low. Thus, the wind turbine design considers the diurnal and seasonal variation. The diurnal turbine design is optimised for the night-time, and the seasonal turbine design is optimised for the low solar irradiance season. The wind turbine design is focused on the conceptual design phase with the objective of rotor diameter optimisation that generates electricity with the lowest cost. The cost function employed is taken from the NREL mass and cost model with additional adjustment, due to the different scaling approach. The data for the design process is obtained from a case study to represent real generation data, and the chosen location is Muppandal, India. The research aims to identify the impact of the specific operational conditions on the design parameters and the design result. Subsequently, the impact on the system performance is observed by modelling the hybrid power system in different topologies that include zero-curtailment, grid-constrained and demand load-supplying topology. The result on the site condition indicates that the affected important design parameters include wind speed distribution, wind shear profile and turbulence intensity. The research limits the analysis only on the wind speed distribution and the wind shear profile. The site condition analysis of the case study indicates that the diurnal variation of the wind speed distribution is similar to the full-year wind speed distribution and the seasonal variation that consider the season with low solar irradiance coincide with the low wind speed season. In zero-curtailment topology, higher wind speed distribution leads to smaller optimum rotor diameter and vice versa. In the grid-constrained and demand load supplying topology, larger rotor diameter suffers from curtailment due to the limited grid capacity and low demand load level. This condition leads to the shifts of optimum rotor diameter to the smaller rotor. The level of curtailment is higher in the demand load-supplying topology due to the overall lower evacuation capacity. When the night-time design and low-wind speed period design is fully operated in a year, the wind turbines are not operating at its optimum, and higher cost of electricity is expected. This result implies the higher cost for designs that correspond to the diurnal and seasonal variation. The storage system is applied to save the curtailment of wind energy. The result of this analysis suggests that the relationship between the amount of saved curtailment and the capacity of the storage is linear for higher storage capacity (&lt;10%) and non-linear at lower storage capacity. It is found that the first few additions of storage yield the most cost-efficient of curtailment saving. The cost and benefit analysis of the storage system also indicates that the current cost of the storage technology is not compensated by the benefit of evacuating the curtailment.","Wind turbine design; Hybrid Power System; Hybrid; India; Complementarity; Complementary generation; Renewable Energy; Wind Energy; Solar energy","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","","8.250000, 77.590000"
"uuid:61d261d7-4850-4e7b-972a-2582362dd568","http://resolver.tudelft.nl/uuid:61d261d7-4850-4e7b-972a-2582362dd568","Bridging the Science-Society-Policy Interface: A Comparative Case Study on Citizen Science for Policies","Cheng, Hsin (TU Delft Technology, Policy and Management)","Zuiderwijk, AMG (mentor); Enserink, B. (mentor); Jeng, W. (mentor); Delft University of Technology (degree granting institution)","2020","The rise of citizen science has drawn policymakers' attention. With a shift towards participatory and transparent governance, linking policies to citizen science could contribute to create the evidence base and social acceptance for policy-making, and further counter-play populism and post-truth politics. This study aims to gain empirical understanding on how citizen-generated data from citizen science initiatives could contribute to political decision-making and problem-solving in different contexts; more specifically, we aim to explore how citizen science initiatives were formed, what opportunities and challenges are for citizen-generated data, how such initiatives lead to a citizen-driven solution in the problem-solving process, and how the contextual settings and actors’ perceptions and actions interplay and potentially play a part along the process. In this study, a conceptual model was set up through a systematic literature review. Two case studies — the case of Hollandse Luchten in the Netherlands and the case of AirBox in Taiwan — were carried out and analyzed as guided by the conceptual model. Based on the findings and insights gained from the case studies, a revised, empirically-enhanced model of citizen science for policies was developed, whereby policy recommendations were formulated.","Citizen Science; Citizen Sensing; Citizen-generated data; Air quality sensing; Case studies","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:c3a23e3e-c4c9-47a4-9472-0e35fac77c5c","http://resolver.tudelft.nl/uuid:c3a23e3e-c4c9-47a4-9472-0e35fac77c5c","The study of calcium oxalate kidney stone growth in microfluidic channel","Wang, Jiali (TU Delft Applied Sciences)","Ibis, F. (mentor); Eral, H.B. (mentor); Delft University of Technology (degree granting institution)","2020","Kidney stone disease influences 10% of people in the world [36]. Calcium oxalate (CaOx) stones are the most common stones found in the kidney stone. In this research, ANSYS/Fluent CFD was used to determine the supersaturation profile in the microchannel for different constant flow rates and Ca and Ox inlet concentrations. The growth of the CaOx stones is studied by performing experiments in a microfluidic channel under an optical microscopy. The growth of the CaOx stones is also investigated by using a combined transport-kinetics model which couple both mass transport and CaOx precipitation<br/>reaction at the surface of the crystal. It is shown that the crystal growth rate increases with solution supersaturation increasing and decreases with the crystal size increasing. The findings also indicated that in cases of low bulk solution supersaturation and low surface reaction constant values,<br/>the crystal growth rates are controlled by the surface reaction kinetics and independent on the species transport. When the bulk solution supersaturation and surface reaction constant values are high, the Ca and Ox surface concentrations become lower than the bulk solution concentration values. Thus,<br/>the crystal growth rates are controlled by the species transport. The presented study also shows that in the presence of inhibitor osteopontin, the crystal growth rate was decreased.<br","kidney stones","en","master thesis","","","","","","","","2023-01-03","","","","Applied Physics","Kidney stone project",""
"uuid:c22b4cfe-d288-4092-b142-e4cc4d30c781","http://resolver.tudelft.nl/uuid:c22b4cfe-d288-4092-b142-e4cc4d30c781","Developing a tested vision for the design of a child participation toolkit for the SWKGroep","Welling, M. (TU Delft Industrial Design Engineering)","Gielen, M.A. (mentor); Stappers, P.J. (mentor); Hopmans, Manja (mentor); Delft University of Technology (degree granting institution)","2020","This report describes my graduation report for the Master Design for Interaction, part of Industrial Design Engineering at the technical University Delft. The project is in collaboration with both the Play Well Lab and the SWKGroep. <br/><br/>The SWKGroep asked for a child participation toolkit which would help them discover the latent knowledge of the children. In order to be able to go into depth while designing this toolkit, the project is split up into two individual graduation projects. This report describes the first project.<br/><br/>“My design goal is to develop a substantiated and partly tested vision for the development of a child participation Toolkit, which is suitable within the context of the SWKGroep facilities and based on the expectations, wishes, needs and capacity of both the staff members as well as the children.”<br/><br/>The first chapter will introduce the different stakeholders involved in the project. These are the SWKGroep and the Play Well Lab. The chapter will conclude with the relevance of this project for both stakeholders. <br/><br/>The second chapter will describe the research phase, including different interviews, a generative session and an analysis of the results. The chapter will conclude with the discovered problem area and my design focus within this project. <br/>Within the third chapter, an approach for this defined problem area will be defined. The chosen approach will be explained and the chapter concludes with an explanation on why this approach would fit the defined problem area. <br/><br/>After describing this approach, the approach will be elaborated into ideas. This is done in chapter 4, which includes the ideation phase. This chapter will end with a set of 23 ideas/tools which could be used for child participation at the BSO. <br/><br/>The next step, described in chapter 5, is validation of the approach. This is done by testing a selection of the ideas at the BSO to see what the obstacles and enablers are when doing child participation at the BSO. The insights from the user-tests are discussed and this chapter will conclude with a validation of the approach including conditions to be met and an overview of opportunities which were found during the tests. <br/><br/>Chapter 6 will conclude this report with recommendations for the follow-up project and a reflection on this project.","Child participation; After school daycare; Participation toolkit","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:770fd557-7054-450e-8edb-c61afa246e46","http://resolver.tudelft.nl/uuid:770fd557-7054-450e-8edb-c61afa246e46","Estimating Total Suspended Matter in Low to Extremely High Level Turbid River Surface Waters using a WISP-3 Hyperspectral Radiometer and Sentinel-2 Optical Imagery: A case study conducted on the Brantas River Basin, East-Java, Indonesia","Wiggins, J.C. (TU Delft Civil Engineering and Geosciences)","Ertsen, M.W. (mentor); Citrosiswoyo, W. (graduation committee); Hariyanto, T. (graduation committee); Hoes, O.A.C. (graduation committee); Laanen, M. (graduation committee); Lhermitte, S.L.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","This research focuses on using Sentinel-2 optical imagery to provide a means of high-resolution monitoring and evaluation of changes in Total Suspended Matter (TSM) concentration in the Brantas river basin. In situ spectral measurements as well as laboratory results show an extremely turbid nature of the Brantas River surface water. Current monitoring of the river water quality, is done by point measurements representing point estimations of the water quality in time and pace. Interactions within the system are mostly unknown. Having accurate knowledge of near real time water quality information will greatly enhance the effectiveness of the monitoring organizations, especially if this comes in a high<br/>spatial and temporal resolution. The Sentinel- 2 remote sensing platform delivers information which can be used to derive such data with a 10m resolution and revisit time of 5 days. To estimate TSM concentrations a multi-conditional algorithm is developed. It uses linear regression for low to medium<br/>TSM concentrations based on the green and red band reflectance values and polynomial regression for high to extremely high TSM concentrations based on the red edge NIR band. Testing the multi-conditional algorithm on the WISP-3 in situ spectral data shows the model’s performance is good with r2 = 0.79, RMSE<br/>= 66.5 mg/L and NRMSE = 9.7%. Performance of the multi-conditional algorithm is found to be poor when based on Sentinel-2 (S2) bottom of atmosphere data from bands green, red and red edge NIR. However, when recalibrating the polynomial model on Sentinel-2 atmospherically uncorrected top of atmosphere<br/>data, results are more promising: r2 = 0.75, RMSE = 64.2 mg/L and NRMSE = 11.3% . Also, TSM estimates from remote sensing reflectances atmospherically corrected by different processors are compared, from which ACOLITE (RMSE = 5.0 mg/L, NRMSE = 25.3%) performs significantly better than C2RCC (RMSE =<br/>11.3 mg/L, NRMSE = 57.5%) and Sen2Cor (RMSE = 42.8 mg/L, NRMSE = 217%). This study shows that 1) high-resolution spatial and temporal variation of TSM concentration estimation can be made visible within the Brantas river basin, 2) an overview of TSM concentration estimation of the entire basin at one<br/>moment in time can be achieved and visualised, 3) an extensive historical record of TSM concentration estimations can be accessed, and 4) information is provided to prioritize sampling locations and field surveying times.","Total Suspended Matter; Atmospheric Correction; Remote Sensing; WISP-3; Sentinel-2; multi-conditional algorithm,; Brantas river","en","master thesis","","","","","","","","","","","","","Fostering inclusive growth, health and equity by mainstreaming water quality in River Basin Management in the Brantas River Basin, Indonesia","-7.300380, 112.740183"
"uuid:59f3db59-f51d-40d8-a355-f12ae8964365","http://resolver.tudelft.nl/uuid:59f3db59-f51d-40d8-a355-f12ae8964365","Design of an AR-IoT Tool for Future Human Space Exploration","Rometsch, F.A.A.S.D.T. (TU Delft Aerospace Engineering; TU Delft Mechanical, Maritime and Materials Engineering)","de Winter, J.C.F. (mentor); Guo, J. (graduation committee); Cowley, Aidan (graduation committee); Delft University of Technology (degree granting institution)","2020","Humans are embarking on a new era of space exploration with the plan of sending crewed spacecraft beyond Low Earth Orbit (LEO), to the Moon, Mars and beyond. NASA is committed to land astronauts on the lunar surface by the year 2024. The goal of NASA's lunar exploration program - Artemis, a collaboration with commercial and international partners including the European Space Agency (ESA), is to establish sustainable exploration by the end of this decade. The plan is to use what is learned on and around the Moon to take the next giant leap, namely sending astronauts to Mars. Activities planned during the Artemis missions, especially in the early phases, involve finding critical resources needed for long-term exploration, and acquiring more knowledge on Moon, Earth and the universe by carrying out experiments. All these activities will involve extensive lunar geological field work, which is orders of magnitude more complex than field geology on Earth. Extravehicular activities (EVAs) will become increasingly more complicated than the tasks executed during the early Artemis missions and generally during human spaceflight missions so far. EVA systems and crewmember skills that currently do not exist will be required. This plan entails many challenges as real-time support from ground control cannot be provided to astronauts who thus need to become more autonomous. Hence, modern human-machine interfaces have to be designed to support astronauts during their deep space missions. Augmented reality (AR) and the internet-of-things (IoT) are changing the way industries work, especially AR has found application for space applications, specifically for procedural work. Nevertheless, only one AR space-related study focused on the use of AR for future human planetary exploration, namely on navigation and traverse planning. While cuff-checklists guided Apollo astronauts on the Moon, wrist displays and tablets represent the standard tools during today's astronaut analog planetary EVA missions. However, these are often operationally unfeasible as crew has to handle several tools simultaneously and/or repeatedly look at the display and thus gets distracted from the surroundings leading to a potential loss of situational awareness, affecting their safety. Based on the research that is currently being performed on IoT technologies in combination with AR for visualisation and enhanced situational awareness purposes, the benefits obtained through the use of these technologies applied to future human planetary EVAs, more specifically geological site inspections, were explored in this research. The AR-IoT surface exploration tool developed for this research introduces a new approach for astronauts to carry out geological site inspections. The tool enables hands-free operations such as data logging, detailed photo-documentation, taking site coordinates, descriptions of sites through the presence of a verbal “field notebook”, as well as mapping and highlighting features during a traverse by creating waypoints, while providing crew with suit diagnostics. A user-centered design method was adopted to design the AR-IoT tool deployed on the Microsoft HoloLens. This highly iterative design process involved two to three expert reviews for each of the first three concepts, and three heuristic evaluations for the fourth concept until the subsequent generation of the first prototype. Key usability and user interaction aspects, pertinent capabilities determining the adoption of innovative interfaces, essential insights into future human-machine interaction and design requirements for AR meant for EVA astronauts were gathered through semi-structured interviews held with four ESA astronauts and astronaut geological field activities experts. The interviews together with the qualitative and quantitative data collected through the questionnaires were then used to assess the usability of the AR-IoT tool. Moreover, these data provided with additional knowledge on user-centered design AR studies in general but also and particularly on user-centered AR space-related studies. Valuable insights into interface design and user interaction aspects were gained. Results from the qualitative content analysis of the interviews stressed the importance of user satisfaction (32% of 139 quotes) as a usability aspect. Key design factors identified were: displaying solely important information in the field-of-view while adjusting it to the user's visual acuity, easy usage, simplicity, helpfulness and extensibility. User interaction was the second most mentioned (24% of 139 quotes) aspect. While multimodal interaction was considered feasible, no conclusions could be drawn on the most suitable combination of inputs. Nonetheless, most experts defined voice the most intuitive input. Based on the positive feedback from ESA astronauts and other experts, the AR-IoT proof of concept proved to be a potentially usable tool for future geological site inspection activities. The AR-IoT tool is therefore a promising asset for analogue training missions, such as Caves &amp; Pangaea, and in the future for lunar geological field work. While limitations in both research and design are outlined, a set of recommendations aimed at warranting future testing and development of a more advanced AR-IoT tool for astronaut geological field activities is provided.","Augmented Reality; Internet-of-Things; Human Space Flight; Extravehicular Activities; User-centred design; Astronaut Geological Field Activities; Innovative Human-Machine Interfaces; Usability; Head mounted display; HoloLens","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:aa938c62-d43c-483d-9334-24794144c2a1","http://resolver.tudelft.nl/uuid:aa938c62-d43c-483d-9334-24794144c2a1","Developing sustainable service design for a pay-per-use dryer","Wei, S. (TU Delft Industrial Design Engineering)","Mugge, R. (mentor); van Dam, S.S. (mentor); Bom, Colin (mentor); Delft University of Technology (degree granting institution)","2020","Although manufacturers, designers, product/service providers are innovating for more sustainable products and business models to promote sustainable consumption, there are still gaps between satisfactory user experience and real-sustainable use behaviours. HOMIE.B.V offers pay-per-use household appliances and services to stimulate sustainable user behaviours and aims to achieve a more sustainable white goods industry. The company developed its pay-per-use washing machine model and now introduces a pay-per-use dryer model. However, the service needs to be further developed, and the specific influencing factors of sustainable dryer use behaviours are still unclear. This thesis aimed to figure out the influencing factors in dryer use experiences and investigate how to persuade the users to use a pay-per-use dryer more sustainably. From a literature review and twelve customer interviews, the key influencing factors in accepting and performing sustainable dryer use behaviours were investigated and concluded into a behaviour model. A usage data analysis further proved that financial concern is not a deciding factor of performing sustainable actions, but the convenience concern is. The drivers and barriers generated the design challenge and design requirements, which contribute as a guideline to the design solution. The final design is a service strategy called HOMIE STAR plan, which uses a mobile app as a communication channel for providing a set of services. The service plan has two phases: the onboarding month and every 6-month evaluation. Customers can learn how to make use of the services and tools to dry their laundry sustainably and conveniently in the onboarding month and achieve sustainable goals by becoming a good laundry organizer in daily use. The service patterns to help customers perform sustainable dryer use behaviours are (1)dryer setting instructions with environmental impact; (2) a HOMIE Planner with sustainable-oriented recommendation system that connects to customers' daily schedule; (3)a community with quick Q&amp;A and tips sharing; (4) a rewarding system with usage cost details. The prototyped concept and implementation suggestions were proposed and validated through interviews with potential dryer users, existing HOMIE customers, and HOMIE employees. HOMIE STAR plan made use of the identified influencing factors to persuade users to perform sustainable dryer use behaviours and meanwhile developed HOMIE's pay-per-use model services. The strategy provided HOMIE with a future direction of realizing its service value and sustainable goals on a larger scale and longer-term and suggested potential collaboration opportunities to influence other parts in the supply chain of the white goods industry. The project is focused explicitly on the pay-per-use dryer model but keeps an eye on the entire service of the company. The identified influencing factors and results can inspire other companies who are also trying to stimulate sustainable user behaviours.","Pay-per-use; Sustainability strategy; Sustainable behavior change; Laundry Dryer; Circular Economy","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:eba94071-5cfa-4132-93a8-5947fccdd731","http://resolver.tudelft.nl/uuid:eba94071-5cfa-4132-93a8-5947fccdd731","Exploring the effects of conditioning Independent Q-Learners on the sufficient plan-time statistic for Dec-POMDPs","Mandersloot, A.V. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Oliehoek, F.A. (mentor); Czechowski, A.T. (graduation committee); Jonker, C.M. (graduation committee); de Weerdt, M.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","The Decentralized Partially Observable Markov Decision Process is a commonly used framework to formally model scenarios in which multiple agents must collaborate using local information. A key difficulty in a Dec-POMDP is that in order to coordinate successfully, an agent must decide on actions not only using its own information, but also by reasoning about the information available to the other agents. Nevertheless, existing value-based Reinforcement Learning techniques for Dec-POMDPs typically take the individual perspective, under which each agent optimizes its own actions using solely its local information, thus essentially neglecting the presence of others. As a result, the concatenation of individual policies learned in this way has a tendency to result in a sub-optimal joint policy. In this work, we propose to additionally condition such Independent Q-Learners on the plan-time sufficient statistic for Dec-POMDPs, which contains a distribution over the joint action-observation history. Using this, the agents can accurately reason about the resulting actions the other agents will take, and adjust their own behavior accordingly. Our main contributions are threefold. (1) We thoroughly investigate the effects of conditioning Independent Q-Learners on the sufficient statistic for Dec-POMDPs. (2) We identify novel exploration strategies that the agents can follow by conditioning on the sufficient statistic, as well as their implications on the decision rules, the sufficient statistic and the learning process. (3) We substantiate and demonstrate that by conceptually sequencing the decision-making, and additionally conditioning the agents on the current decision rules of the earlier agents, such learners are able to consistently escape sub-optimal equilibria and learn the optimal policy in our test environment, Dec-Tiger.","Deep Reinforcement Learning; Independent Q-Learning; Partial Observability; Dec-POMDP; Multi-agent","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:9a4fd919-b0d0-443d-a66b-f42a3fe73f10","http://resolver.tudelft.nl/uuid:9a4fd919-b0d0-443d-a66b-f42a3fe73f10","Finite element modelling of open longitudinal stiffener to crossbeam connection in OSD bridges for hot-spot stress determination","Pandit, Sayantan (TU Delft Civil Engineering and Geosciences)","Veljkovic, M. (mentor); den Besten, J.H. (graduation committee); Wu, W. (graduation committee); Maljaars, J. (graduation committee); Wijnbeld, B. (mentor); Delft University of Technology (degree granting institution)","2020","The phenomenon of fatigue in orthotropic steel deck (OSD) bridges is a predominant problem because of complexity of the prediction methods. In the past, many researchers have studied the fatigue behaviour of various details in OSDs via both experiments and Finite Element Modelling (FEM). In the present research, the connection of open stiffener to crossbeam at the location of cope hole in OSDs has been be studied. Structural hot-spot stress method using surface stress extrapolation has been used to investigate the cracks in stiffener in the longitudinal direction and cracks in crossbeam.<br/><br/>FEM is extensively used for analysing OSDs. In engineering applications, 2D shell elements are widely used instead of 3D solid elements for analysis due to less computational cost. The welds are generally not modelled with shell elements for fatigue assessment of welded structures. In this study, large difference of SHSS is obtained by shell and solid elements for both simple and complex fillet welded details and also for the OSD. This difference in structural hot-spot stress (SHSS) is reduced by the application of three weld modelling techniques with shell elements: (i) the IIW approach, (ii) the Eriksson’s approach and (iii) a combination of IIW and Eriksson’s approaches. All the three methods are based on increasing the thickness of shell elements at the weld region which are easy to be applied in practice. The dependence of SHSS on mesh size and element type is also investigated in this thesis.<br/><br/>A parametric study is performed first on simple and then on complex fillet welded details to check whether the weld modelling technique can be applied to different geometries, loading and boundary conditions. The solid element model of the complex detail is first validated with experimental strain measurements. Then, SHSS values from other numerical models are compared with the solid model. Representative load cases are investigated initially followed by load combinations. The weld modelling method with shell elements gives good consistency in the ratio of hot-spot stress compared to the solid element model for these details. The deformations are also investigated for all load cases and load combinations. The combined weld modelling technique (iii) with shell elements replicated the weld stiffness of the solid model for both in-plane and out-of-plane load cases.<br/><br/>As a final step in checking the consistency of SHSS ratios between shell elements with welds and solid elements in the application of OSD, a parametric investigation is performed. This study involved two geometric variants of OSD with different load positions. These two variants were based on the design of existing bridges in The Netherlands with relatively thin plate and newly designed ones with thicker plates. The parametric study is divided into two parts. The first part is based on representative load cases. The second part is based on SHSS influence lines for determination of critical loading positions having maximum and minimum hot-spot stress. For both these studies, the weld modelling approaches with shell elements gave a good match of SHSS compared to the solid models. The SHSS results from the shell model with weld are more consistent compared to the regular shell model without weld. From the preliminary parametric study on OSD, it is found that after weld modelling with shell elements using the combined approach of IIW and Eriksson, less scatter is observed in the SHSS ratios. The coefficient of variation (CV) in SHSS ratio for crossbeam is 6.8% and that for stiffener is around 5.1% which is low. The SHSS values are computed based on the stress perpendicular to weld toe. From the detailed parametric study, the mean value of SHSS ratio is 1.07 (range: 0.99-1.15) for the crossbeam and 1.02 (range: 0.98-1.10) for the stiffener. The CV of SHSS ratio is 5.4% for the crossbeam and 4% for the stiffener. The stress profiles are also investigated at the critical locations of OSD. The shell model with the combined weld modelling approach is in good agreement with not only SHSS but also with the stress at a distance far away from the stress concentration when compared to the solid model. The deformations are also very similar for both the numerical models. Thus, it is concluded that the combined weld modelling technique using the IIW and the Eriksson’s approach with shell elements could be used for accurate fatigue life assessment using hot-spot stress method where the measure of accuracy is with respect to the solid element model.","Fatigue; Hot-spot stress; Finite Element Method; Orthotropic Steel Deck","en","master thesis","","","","","","","","","","","","Civil Engineering | Structural Engineering","",""
"uuid:214f02de-edf4-46d1-b5b6-876311852982","http://resolver.tudelft.nl/uuid:214f02de-edf4-46d1-b5b6-876311852982","Who is at risk of automation?: Estimating the effects of automation technologies on employment","Temizel, Irem Naz (TU Delft Technology, Policy and Management)","Schröder, E. (mentor); Enserink, B. (graduation committee); Postma, Roberto (graduation committee); Sprockel, Yuri (graduation committee); Delft University of Technology (degree granting institution)","2020","This study defines who is at risk of automation and discusses policies to ensure the vulnerable groups are seen. The study of Nedelkoska and Quintini (2018) is taken as the role model: The risk of automation for individuals across OECD countries is calculated by associating the expert assessment conducted by Frey and Osborne (2013) with individuals’ skills used at work collected by PIAAC. The analysis is improved by training the model with different country datasets and including additional skills into the analysis. 14% of the total employment of 33 countries is found to be at significantly high risk of automation. Workers at the highest risk of losing their jobs are more likely to be less-educated, low-income earners who perform unskilled jobs. The risk of automation declines as the level of education increases. Therefore, this study highlights the importance of training and reskilling the risky-groups to cope with the possible adverse effects of technological progress.","Technological change; Employment; Skills used at work; Econometrics; Data analysis","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:a6fbf53d-7175-4b2f-8a4f-f8730a4940b2","http://resolver.tudelft.nl/uuid:a6fbf53d-7175-4b2f-8a4f-f8730a4940b2","Aircraft Specific Carbon Emission Calculations For Air Freight Transportation: A Systematic Approach to Model Development to Promote Sustainable Purchasing and Green Market Positioning at PostNL","Chaturvedi, Rishabh (TU Delft Technology, Policy and Management)","Hartmann, L. (mentor); Fens, T.W. (graduation committee); Roling, P.C. (graduation committee); Delft University of Technology (degree granting institution)","2020","Commercial greenhouse gas emissions from aviation are proliferating, as is the concern among freight carriers to minimize their carbon footprint. From a corporate point of view, the United Nations International Civil Aviation Organization ( ICAO) expects aircraft emissions to triple by 2050, with aviation accounting for 25% of the world's carbon budget . While ICAO and the International Air Transport Association (IATA) release annual overview statistics on the aviation industry and its related business economy, relatively few research data on fuel consumption, fuel quality and carbon emissions are available at global and regional levels, respectively. Policymakers and top decision-makers at transportation and logistics companies such as PostNL cannot determine the exact amount of carbon emissions associated with departing flights and needs a more robust model to determine marginal emissions due to cargo freight. To solve this problem, the research predominantly aims to answer the following research question: ""How can PostNL be facilitated in calculating aircraft specific carbon emission factors, which can be used for accounting purposes, to promote sustainable purchasing and green market positioning?"". Using empirical data from public, private-owned confidential data sets, and the PianoX aircraft emissions modeling, this research outlines a consistent and globally dispersed methodology for estimating CO2 emissions for air freight. An extensive review of the literature was carried out in the field of the emergence of ""Sustainability Concept"" and antecedent research in the Netherlands. This was followed by evaluating the current situation and the emergence of the supply chain processes. The study also describes and analyzes the operational process at PostNL and discusses the current methodology used at PostNL, i.e. DEFRA method for carbon emission calculation. Later, the flaws in the model were evaluated and addressed. Based on the review of the literature on antecedent research and the analysis of different carbon emissions calculation methodologies being used internationally in various institutions, a method was proposed for the calculation of Co2 emissions due to air freight. In order to measure commercial fuel consumption, many publicly available data sources were collected and incorporated with Piano X, an aircraft performance and design platform from Lissys Ltd. The data on the fuel-burning process and projected Co2 emissions were then compared and validated with the ICAO dataset and later implemented in the model proposed. This was followed by the creation of a conceptual simulation and optimization model build using VBA in Excel, which helps the company in making data-driven air transport procurement decisions taking into account tradeoffs between carbon emission, lead time, and cost to gain a strategic business advantage. Strategic goals were broken down into the priorities of the individual divisions at PostNL, expressed with the goal values of the lead time and the performance metrics for cargo costs. A graphical comparison was followed with the EU ETS datasets and the DEFRA datasets to compare and correlate the results obtained using the proposed methodology. The result also helps PostNL drive business sustainability in their partnerships while maintaining their flexibility and bargaining power with suppliers. The limitations and errors with the research were acknowledged in the areas of uncertainty due to the use of publically available information and the absence of the inclusion of dynamically changing time-dependent variables, including privately owned airline data. It was also concluded that logistics companies such as PostNL should always bear in mind that, often drastically, the logistics networks may shift. New ways of doing business, such as coopetition and better modeling, can help to increase effectiveness. Scenario planning and better business management approaches will have an advantage in improving the transportation and logistics industry to face the demands of the future and become ever more competitive and sustainable.<br","Carbon emissions; Air Cargo; Transport; logistics; Supply chain; Optimization; Simulation; Air Freight; PostNL; Strategic competitive advantage","en","master thesis","","","","","","","","2021-08-17","","","","Management of Technology (MoT)","",""
"uuid:e781a759-55fb-450a-9e3c-dfd9f4b6ffaf","http://resolver.tudelft.nl/uuid:e781a759-55fb-450a-9e3c-dfd9f4b6ffaf","Green facades for cooling urban hot spots: The cooling effectivity of green facades on spaces adjacent to and inside dwellings in Amsterdam","Vessies, Florinde (TU Delft Architecture and the Built Environment)","Pijpers-van Esch, M.M.E. (mentor); van Hove, Bert (mentor); Jacobs, Cor (mentor); Delft University of Technology (degree granting institution); Wageningen University & Research (degree granting institution)","2020","To limit increasing heat problems in cities, green areas are being implemented in the urban context. Since space is often scarce, an opportunity lies in the use of green facades. This research has investigated the cooling effect of natural green facades in the form of He¬dera helix. Both the effect on thermal comfort inside and outside buildings was investigated during a five-day heatwave using a model approach in ENVI-met. For this purpose, energy labels and the urban heat island effect were used as heat exposure indicators to determine ur¬ban hot spots in Amsterdam. One study area was selected for which dwellings were simulated for four different orientations, namely facing north, east, south and west. The results demon¬strated that green facades could account for small decreases (&lt;1 °C) in air temperature and outdoor thermal comfort. This cooling effect was more pronounced for indoor temperatures, where the insulating function of the greening led to a maximum cooling of 3 °C for the sou¬thern oriented buildings within the first 24 hours. After a few days, the indoor effect appeared to fluctuate, resulting in lower temperatures during the night and higher temperatures during the day compared to a non-green facade. In conclusion, this research has demonstra¬ted that green facades can reduce the heat accumulation of buildings as they function as an extra insulation layer. Further research may be necessary to determine which accompanying measures can optimize the cooling effect of green facades to limit urban heat problems.","Urban Heat Island effect; green facades; ENVI-met; indoor air temperature; Physiological Equivalent Temperature (PET)","en","master thesis","","","","","","Joint Master of Science in Metropolitan Analysis, Design and Engineering at Delft University of Technology and Wageningen University & Research.","","","","","","Metropolitan Analysis, Design and Engineering (MADE)","",""
"uuid:4d16e140-1ffd-41d8-88fc-57e5d43598d5","http://resolver.tudelft.nl/uuid:4d16e140-1ffd-41d8-88fc-57e5d43598d5","Area Law violations for bipartite Entanglement Entropy in Quantum Spin Chains","van Laarhoven, Menno (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Applied Sciences)","Terhal, B.M. (mentor); Visser, P.M. (mentor); Gijswijt, D.C. (graduation committee); Thijssen, J.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","The concept of entanglement is one of the distinguishing features in quantum mechanics. Information about one particle can determine the state of another particle. This information and entanglement in subsystems is quantified by the entanglement entropy. The entanglement entropy has become an important research topic in recent years. Entanglement entropy is expected to grow with the boundary size for systems described by Hamiltonians with local interactions, described by the area law. For one dimension there exists a bound quantifying this area law S = O (2<sup>1/ΔE</sup>) in terms of the energy gap ΔE between the ground-state energy and the first excited-state energy. It is an open problem whether the area law holds in higher spatial dimensions. Therefore it is of great interest to study the entanglement entropy in systems that violate the area law. In this thesis spin chain models with local interactions are studied for arbitrary spin. Hamiltonians with a unique ground state are constructed by mapping spin chains onto (coloured) Dyck and (coloured) Motzkin paths. We show that these models express logarithmic or power law violations of the area law for the bipartite entanglement entropy. These results are presented in the table below. The known bound of the area law in one dimensional systems is dependent on the energy gap of these models. The energy gap of the Motzkin-path model is investigated by constructing the an orthogonal excited state with small energy. In doing so we associate the Hamiltonian with the Laplacian of a graph. We present an alternative proof for the bound on the energy gap of the colourless Motzkin-path model than S. Bravyi et al and R. Movassagh et al. We show that the energy gap ΔE scales in terms of the chain length n as ΔE = O(n<sup>-2</sup>) in the limit n →∞. Therefore ΔE → 0 in this limit, resulting in area-law violations of the entanglement entropy while maintaining the known bound on the entanglement entropy.","Quantum Mechanics; Entanglement Entropy; Area Law; Area Law violations; Spin chain; Combinatorics; Motzkin Paths; Dyck Paths","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics | Applied Physics","",""
"uuid:c878c9d5-f9af-44fd-83c4-a4bd8a7496b5","http://resolver.tudelft.nl/uuid:c878c9d5-f9af-44fd-83c4-a4bd8a7496b5","Simulation of a High-Redshift Line-Emitting Galaxy Detection with DESHIMA using TiEMPO","Roelvink, Y. (TU Delft Applied Sciences; TU Delft Tera-Hertz Sensing)","Endo, A. (mentor); Adam, A.J.L. (graduation committee); Yates, S.J.C. (graduation committee); Delft University of Technology (degree granting institution)","2020","In this report, we will focus on simulating galaxy observations with the Deep Spectroscopic High-redshift Mapper (DESHIMA). To do so, we will discuss and evaluate two main parts needed to accurately perform such a simulation:<br/><br/>Firstly, we will answer the question whether Time-dependent End-to-end Model for Post-process Optimization (TiEMPO), the modelling software used for DESHIMA observation simulations, is able to accurately simulate real life galaxy observations conditions. To do so, the simulation program is fed artificially created atmospheric data and its output is compared with sky brightness data of real measurements. More specifically, the time signal, power spectral density and noise equivalent flux density of both the simulation and the measurement data are derived and compared. This comparison showed, apart from a linear drift of the time signal data and a small offset of the power spectral density, good agreement between the simulation and the measurement.<br/><br/>The second part of this thesis discusses whether we can detect an artificially created galaxy, using the already verified atmospheric model of TiEMPO. To do so, the output of the simulation is run through a series of algorithms that calculate the observation spectrum of the telescope, as if it were a real measurement. In addition, the application of different observation tactics and telescope parameters are tested and visualised. Most importantly, two observational position-switching (chopping) techniques are applied and compared: the dual point and ABBA chopping techniques. To test the effectiveness of the two chopping techniques, both will be used to simulate atmospheric filtration using stationary, i.e. without telescope movement, simulation and measurement data, which do not contain the (to be detected) galactic data. As there is no telescope movement, nor galactic data, the spectra should ideally fluctuate around zero. However, as we will see in this report, this is not obtained in all cases. After further analysis, two main types of offsets could be identified: the first one originating from the linear drift of the measurement's time signal data, whereas the second one is due to the spatial displacement of the chopping positions. The former can be corrected by applying the ABBA chopping technique rather than the dual chopping method, whereas the latter cannot with either of the two.<br/><br/>Using the insights we acquire from running these simulations with observation conditions for DESHIMA, we are able to perform an actual galaxy observation simulation. The galactic data acquired from this observation simulation shows good agreement with the input values of the galaxy data of TiEMPO, assuring that TiEMPO can be used for galaxy observation simulations.<br","DESHIMA; Simulation; Spectrometer; Kinetic Inductance Detectors; infrared spectroscopy; Submillimeter-wave; Physics; Astronomy; Computer Model; Terahertz; superconducting; ASTE telescope","en","bachelor thesis","","","","","","","","","","","","Applied Physics","",""
"uuid:36e2b473-dccd-44e6-9c56-d827bb4b0eef","http://resolver.tudelft.nl/uuid:36e2b473-dccd-44e6-9c56-d827bb4b0eef","Factors Affecting the Decision-Making Process between Owner and Contractor Mining","Zhang, Yepin (TU Delft Civil Engineering and Geosciences)","Buxton, M.W.N. (mentor); Schipperheijn, Marco (graduation committee); Delft University of Technology (degree granting institution)","2020","When making a decision between conducting owner and contractor mining, it is common for the mine owner to take into consideration a number of factors to assess the suitability of either method for any particular project. This research identifies and investigates the key factors by means of literature review and questionnaires and interviews with representatives from the resource industry across all fields - mine owners, contractors, independent consultants and Original Equipment Manufacturer (OEM)’s. The responses from 12 professionals were synthesized and compiled to form a framework that can assist both the mine owners in the decision-making process and representatives from other fields to have a better overview of a particular project in the context of owner vs. contractor mining. The key factors identified are company factors (expertise and availability of capital and personnel/workforce), geology of the deposit, geographical and political variability, availability and suitability of contractors and project’s financial model and investment analysis. The research shows that there does not exist a single methodology used across the industry and that the decisions are case-specific and should consider the balance between risk, cost and benefit.","Contractor mining; Owner mining; Mining; Operations Research; Decision-making framework; Decision making process; Framework; Framework design; Contractor","en","master thesis","","","","","","","","","","","","Applied Earth Sciences | European Mining Course","","52.0126341, 4.3555860"
"uuid:f90dbcbd-a6c5-4077-829b-9cd716224c51","http://resolver.tudelft.nl/uuid:f90dbcbd-a6c5-4077-829b-9cd716224c51","Research into the potential effects of a receiver-led consolidation policy on costs, CO2 emissions and vehicle movements: A case study for the logistics service provider PostNL","Meulblok, Vera (TU Delft Technology, Policy and Management)","Tavasszy, Lorant (mentor); Warnier, Martijn (mentor); Ludema, M.W. (graduation committee); Kol, Jordy (graduation committee); Delft University of Technology (degree granting institution)","2020","The efficiency of a logistic service provider's network can be improved by implementing a receiver-led consolidation policy. This policy means that shipments destined to the same location are consolidated in one truck. The literature states that by doing this the costs, CO2 emissions and number of vehicle movements can be reduced. However, consolidating shipments towards hospitals is complex due to the fact that medication is a highly regulated product and non-regulated products are also needed at the hospitals. <br/>Furthermore, from the stakeholder analysis, it became apparent that such receiver-led consolidation policy is also favorable for hospitals. The efficiency of the operating practices in the logistics department in hospitals can be improved by reducing the number of deliveries. However, from the literature became apparent that the knowledge on the effects of a receiver-led consolidation technique implemented in a logistics service provider's network is still lacking. Especially on how receiver-led consolidation can improve the efficiency of a logistic service provider's network and how this affects the other stakeholders. This problem is stated in the following main research question: What is the impact of receiver-led consolidation alternatives in the PostNL supply chain with respect to trade-offs between costs, CO2 emissions and vehicle movements between PostNL and other stakeholders? In order to find an answer to this research question, a case study for the logistics service provider PostNL is carried out. PostNL has several networks that deliver shipments. However, mostly the Cargo, Pharma\&amp;Care and Mikropakket network deliver shipments to hospitals. It appeared that these three networks barely work together which results in overlap between destination addresses. This means that two or more networks can make a delivery to a certain address on the exact same date. Furthermore, the Pharma\&amp;Care network is meant for large deliveries. However, it sometimes occurs that this networks makes a stop for just one or two colli. This is an expensive stop in comparison to the Mikropakket network. Therefore, a conceptual model of the current data-processing system of PostNL is created. After brainstorm sessions and discussions with PostNL employees, it became apparent that many bottlenecks originate from this process. Therefore, a discrete event simulation model is created that captures this model. <br/>Furthermore, two design alternatives have been proposed to improve the efficiency in the current system. The two design alternatives that have been created are: (1) integrating the processes of different networks and (2) implementing a smart planning process which controls the data sets of all networks. In the first alternative, all shipments are checked on a pre-defined list. If the destination address is present on this list, the shipments are redirected to the Pharma\&amp;Care network. Otherwise, the shipments continue in their original process. The second alternative, consolidates all shipments of all networks in a certain network, based on their characteristics. These design alternatives have also been implemented in a discrete event simulation model. <br/>The data obtained from PostNL has been used to measure the effects of the design alternatives on the current system. When analyzing the results obtained from the simulation model, it can be seen that the overlap, the number of stops, operating costs and CO2 emissions have been reduced in both design alternatives compared to the current system. The second design alternative yields the highest benefits. However, this alternative is expected to be more difficult to implement in the current system of PostNL. <br/>Moreover, the analysis of the output data has also shown positive outcomes for the other two core stakeholders (hospitals and suppliers of end-products). According to the stakeholder analysis, the outcomes of the second design alternative are more favorable. To conclude, implementing a receiver-led consolidation policy in a logistics service provider network yields many benefits with respect to the efficiency. The overlap between networks on destination addresses, the number of stops, the operating costs and the CO2 emissions are reduced. Since, the second design alternative scores highest on all aspects, it is recommended to PostNL that this alternative is implemented. This way, all shipments are consolidated over the three networks and the efficiency of the logistics service providers network is improved the most.","Discrete Event Simulation; receiver-led consolidation policy; logistics","en","master thesis","","","","","","","","2022-08-17","","","","Engineering and Policy Analysis","",""
"uuid:7ec4362a-5c93-4b53-8bc0-ddc01958587a","http://resolver.tudelft.nl/uuid:7ec4362a-5c93-4b53-8bc0-ddc01958587a","Which error detection tool to choose?","Vermeulen, Martijn (TU Delft Electrical Engineering, Mathematics and Computer Science)","Katsifodimos, A (mentor); Koutras, C. (graduation committee); Houben, G.J.P.M. (graduation committee); Gousios, G. (graduation committee); Delft University of Technology (degree granting institution)","2020","The amount of data being collected is growing exponentially, both in academics as well as in business. Unfortunately, the quality of that data can be poor, leading to poor decisions and increasing costs. Data cleaning, the process of detecting and correcting errors from a dataset, could be the solution to improve bad data.<br/>This research focuses on detecting these errors. There are (semi-)automated error detection tools available, but it is unclear how well these tools perform under varying conditions and on different datasets.<br/>Following from this problem, the main research question was developed: How to<br/>choose a fitting error detection algorithm for a specific relational dataset?<br/>To answer this question, a comparative study has been done for error detection tools on relational data. An interactive error detection tool, Raha, performed best from the selected state of the art tools.<br/>Subsequently, an attempt was made to estimate the performance of error detection tools and particular configurations on unseen datasets, based on high-level profiles of these datasets. According to the qualitative and quantitative experiments in this research, the proposed estimators have been shown to be effective. Moreover, the performance estimators were analyzed to provide more interpretability on the functioning of the error detection tools on the datasets in this research.<br/>Ultimately, these performance estimators were used to generate suggested rankings of error detection strategies. The produced system outperformed the set baseline and was able to create valuable rankings. The proposed strategy ranking system could help real-world computer scientists and data experts choose a fitting error detection algorithm for a specific relational dataset.","error detection; relational data; comparison study; performance prediction","en","master thesis","","","","","","","","","","","","Computer Science | Software Technology","",""
"uuid:4690469f-fe3d-48a5-b708-66f24aea9808","http://resolver.tudelft.nl/uuid:4690469f-fe3d-48a5-b708-66f24aea9808","Creative Rooms: A supportive guide to boost creative confidence through the facilitation of a creative climate in an online environment","Noordermeer, M.J.E. (TU Delft Industrial Design Engineering; TU Delft Human-Centered Design; TU Delft Design, Organisation and Strategy)","Price, R.A. (mentor); Heijne, K.G. (mentor); Zijtregtop, E.E. (mentor); Delft University of Technology (degree granting institution)","2020","The need for creativity has never been bigger. Technological changes, raised expectations in the area of sustainability and safety, increased focus on customer experience ask for pro-active innovation. On top of that has Covid-19 changed the world fast and radically the past half year. The world went in lockdown and because of that organisations have accepted work-from-distance as the new normal. In order to stay relevant and be adaptive to the rapidly changing landscape, organisations have recognised creativity as catalyst for innovation. Organisations initiate innovation programs to evoke culture change by fostering experiential learning in creativity. Employees are expected to adopt a creative mindset by applying trained skills and knowledge into daily practice. However, uncertainty of learning something new and the ambiguity of creativity create resistance under employees making them fall back into their old routines. In order to make this cultural change stick, an employee-centered approach is necessary. To understand how employees can be guided/supported in learning experientially using creativity in their way of working, the central aim of this research is to define how creative confidence can be boosted. An extensive literature study showed that there are seven creative culture factors to empower employees in their confidence to use creativity. The extent employees feel empowered is interdependent on the culture factor work climate (domain-specific). A creative climate has the ability to empower autonomy and thereby the confidence to use creativity. Therefore, the other five creative culture factors need to be established, namely: integral strategic vision, supportive leadership style, flexible organisational structure, accessible professionalism and available resources. To develop a creative climate twelve dimensions are derived from insights of both literature and multiple exploratory research activities. These dimensions are either comfort (stability and direction)- or freedom (exploration and own interpretation) orientated. To boost creative confidence a creative climate should be evolved in which these orientations are experienced in balance. To be able to bring this balance into practice, a guide has been conceptualised focusing on online project meetings. Facilitators can use this guide to build-up an effective meeting flow for their weekly online progress meetings. This DIY-guide is called 'Creative Rooms', which includes a basis structure with different ‘meeting rooms’, a folder with extra templates and facilitating notes. With Creative Rooms a facilitator can build-up a meeting flow regarding guidelines based on the creative climate dimensions. Each meeting room in this flow contains activities and features to enhance a creative climate relevant for position in the meeting flow. The facilitator navigates the meeting group through the flow in order to achieve alignment, connectivity, implementation and creativity. These are the four success indicators for effective meetings with a creative climate (the 12 dimensions). The use of Creative Rooms has been evaluated with employees, faciliatory experts and a meeting group to test the clarity and effectiveness of the guide. These evaluations led to the revised design in the shape of a package containing: DIY guide, reference manual and implementation assistance from a customer support manager. Thereby the Creative Rooms package is a guide to boost creative confidence within and beyond online project meetings.","Organisational Transformation; Innovation; Creativity; Creative Confidence; Creative Climate; Facilitation; Project Meeting; Online Environment; Work-from-distance","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:e8410968-febb-47fd-b51c-79132326d3c9","http://resolver.tudelft.nl/uuid:e8410968-febb-47fd-b51c-79132326d3c9","Macomi Maintenance: A user-centric data-analytic platform for railway maintenance planning optimisation","Leung, S.Y. (TU Delft Industrial Design Engineering)","Bourgeois, J. (mentor); Goto, L. (mentor); Gerace, Marina (graduation committee); Delft University of Technology (degree granting institution)","2020","This thesis project investigated how user-centred design(UCD) contributes to the railway maintenance planning optimisation. A new UX concept and digital prototype were designed to provide intuitive interaction and clear structure to support the planners confidently and independently optimise railway maintenance planning on a digital platform. <br/><br/>This project is under the context of the Dutch railway infrastructure maintenance. With increasing demands for transport on the Dutch railway, optimising maintenance planning for existing infrastructure is challenging for the Dutch railway network management organisation ProRail. Thus, a data-analytic software ProRail Maintenance(PRM) for railway maintenance planning optimisation was developed for the maintenance planners at ProRail. However, as an analytic tool, the outcomes and functions came first for the company while the user experience(UX) was neglected at first, which leads to a series of usability problems and requires much learning time from the users.<br/><br/>Based on the above situation, two initial research questions were proposed: “What are the causes of these usability problems?” “Will UCD help to improve the UX of PRM and How?” A series of UCD methods were used in the whole process to understand users’ needs, generate and iterate concept and the final design was evaluated by the final evaluation test.<br/><br/>The initial goal in the research phase was to understand the context, problems of PRM and causes and users. Literature research was conducted combined with interviews with experts to understand the Dutch railway maintenance planning. By analysing the qualitative and quantitative data collected from interviews and user testing of PRM, a list of problem statements, design goal and requirements were defined. In the design phase, a series of design activities with users(e.g co-creation session, prototype tests) were conducted to generate ideas and iterate the concept by prototype tests with users. By involving users in every stage of the process, I got instant feedback and had a deeper understanding of the users’ needs and quickly verify the hypothesis and iterate concept. <br/><br/>The final concept called Macomi Maintenance consisting of four main functional pages: Homepage, Input, Analysis and Result. It covered the main operations needed to optimise the planning, which achieved an excellent usability performance evaluated by 8 participants in the online evaluation tests. It was found that showing information in an organised way(in this case I used cards and tabs) and provide enough guidance helped to reduce the time and fear of learning new software. All participants could finish the assigned tasks without hints in the evaluation test and show more willingness and confidence to learn Macomi Maintenance. <br","user centric design; Data Analytics; User experience design; Railway Maintenance planning; Optimisation; Co-creation","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:ef425cb0-5673-4621-80c6-1f84847b253d","http://resolver.tudelft.nl/uuid:ef425cb0-5673-4621-80c6-1f84847b253d","Printing Reinforcement Steel: A study towards optimised, additive manufactured steel for reinforced concrete","Drillenburg ook genaamd Lelijveld, M.P. (TU Delft Civil Engineering and Geosciences)","Rots, J.G. (mentor); Hendriks, M.A.N. (graduation committee); van der Linden, L.P.L. (graduation committee); Bartels, N.A.J. (graduation committee); Delft University of Technology (degree granting institution)","2020","In light of the global attempts to reduce material use by the construction industry, this research focuses on combining topology optimisation with additive manufacturing of steel. It is investigated whether an automated procedure can be developed to generate reliable strut and tie models for reinforced concrete elements, while satisfying the constraints that apply to 3D-printing using the Wire and Arc Additive Manufacturing(waam) technique. <br/>Additive manufacturing offers a fully automated production process where a large freedom in form can be achieved. Topology optimisation concerns with finding a good material distribution within a prescribed domain. A literature review was performed on current developments regarding both subjects. It was found that the waam-technique is very suitable for printing reinforcement designs. Sufficiently large models can be printed, and material properties can be achieved that match the properties of traditional reinforcement steel. This manufacturing process is expected to produce functional structures that can readily be used as reinforcement steel in buildings. Two main manufacturing constraints should be accounted for during design of the model. A minimum member inclination and a minimum member diameter are both expected to be necessary to ensure a smooth printing process. <br/>Several different topology optimisation algorithms are discussed in the second part of the literature review, and it is determined which algorithm is most suitable to continue with in the rest of this research. Examples are presented that explain the functionality of three important optimisation schemes: Bi-directional Evolutionary Structural Optimisation(beso, Solid Isotropic Material with Penalisation(simp) and Ground Structure Optimisation(gso). It was found that all three can be used to analyse reinforced concrete. Each algorithm has advantages and disadvantages, so there is no obvious best choice. However, motivated by the easy access to member forces and availability of a very good Python implementation, it is chosen to use gso for the remainder of this research. <br/>This Python script was modified to include the constraints that come with an additive manufacturing process. It was found that the minimum member inclination can straightforwardly be included. The new function that was proposed allows the user to specify a minimum inclination, and ensures that no members are generated within the design domain that violate this minimum angle. Experimenting with this new function revealed cases where material use increased significantly when this function was used. This lead to development of an alternative procedure to ensure a printable design. In this alternative procedure, an optimisation without any angle constraint is performed first. Then, in the form of a post-processing script, The complete model is rotated around two separate axes in an attempt to find a suitable printing orientation. <br/>The third and final proposition that was done in this part, consists of a post-processing script for the minimum member diameter. Including this minimum diameter in the optimisation would require rigorous changes to the optimisation script. Therefore it was chosen to investigate the performance of this post-processing script first. <br/>The case study that was performed in the third part of this research, proved that this post- processing script for member diameter is sufficiently efficient for practical implementation. Together with the ability to slightly suppress the amount of members that are generated in the design domain, the printing constraint for minimum diameter could relatively easily be enforced. A bigger challenge lies within ensuring the minimum member inclination. The 60◦ minimum that was set, proved to be very harsh on the solution space. In the example from the case study, no printable model could be generated without significantly reducing the material efficiency. However, it is argued that this minimum inclination constraint can possibly be relieved by recent developments in additive manufacturing techniques. An example of this could be a rotating printing surface, that has the potential to remove this angle constraint completely. <br/>Overall, the experience of combining topology optimisation, additive manufacturing and strut and tie modelling has been predominantly positive throughout this research. The combination of a state of the art manufacturing technique and a more performance driven design process with a labour intensive traditional calculation procedure has shown promising first results. In the example in this research, 30% less material was required to accommodate the tensile forces in the concrete.<br","additive manufacturing; topology optimisation; reinforcement; steel; strut and tie model; concrete","en","master thesis","","","","","","","","","","","","Civil Engineering","",""
"uuid:63ac9d18-9856-4bc6-bef5-6c7f4038b842","http://resolver.tudelft.nl/uuid:63ac9d18-9856-4bc6-bef5-6c7f4038b842","Analysis Methodologies for As-Manufactured Composite Pressure Vessels","Soriano Sutil, Alejandro (TU Delft Aerospace Engineering)","Kassapoglou, C. (graduation committee); van Campen, J.M.J.F. (mentor); Zarouchas, D. (graduation committee); Chen, B. (graduation committee); Nebe, Martin (mentor); Delft University of Technology (degree granting institution)","2020","Type IV composite pressure vessels (CPVs) are used commercially for the gaseous storage of hydrogen in fuel cell electric vehicles (FCEVs). However, their economic implementation requires material optimization and a reliable prediction of the vessel strength. In this regard, their burst when loaded under internal pressure is impacted by the combined effect of the stacking sequence design and the variability of mechanical properties resulting from the manufacturing process. This work shows a framework for analysis that accounts for some of these manufacturing-induced characteristics in the mechanical response, namely the relation between the vessel stacking sequence, its final geometry, and the material properties. Furthermore, vessel burst pressures are alternatively estimated from the failure criteria evaluation in constitutively elastic analyses and the modeling of damage progression. Predictions are reasonably accurate when the collapse occurs in the cylinder (+2.2 %), although a more considerable discrepancy exists with experimental results when vessels fail in the dome transition region (+12.3 %).","Composite pressure vessel; Finite element analysis; Continuum damage mechanics; Filament winding; Digital image correlation; Acoustic emission; Burst experiment; Hydrogen","en","master thesis","","","","","","","","2023-08-14","","","","Aerospace Engineering","Material & Process Development CHG-Tank Daimler AG",""
"uuid:7f04302b-a8ce-4424-b8c5-c3faaf8584ad","http://resolver.tudelft.nl/uuid:7f04302b-a8ce-4424-b8c5-c3faaf8584ad","The road to sustainable load bearing glass designs: possibilities and limitations of current glass design with focus on the connections","Hoogerwaard, Geert (TU Delft Civil Engineering and Geosciences)","Nijsse, R. (graduation committee); Veer, F.A. (graduation committee); Jonkers, H.M. (graduation committee); de Krom, Diana (mentor); Delft University of Technology (degree granting institution)","2020","Despite the increased popularity of the application of load bearing glass in the built environment, its design does rarely address sustainable or circular aspects. This Master’s Thesis analyses what the inﬂuence of connections is on the sustainable performance of structural glass and informs about the limitations and possibilities of sustainable glass design. To answer this question, sustainability has been deﬁned from literature which resulted in ten sustainable, circular design methods. The role of load bearing glass and its connections is discussed in these methods, and it is concluded that there are two main possible design strategies for a sustainable design. First, the biggest impact in design can be made when focus is on reuse as an afterlife application to increase the lifetime of glass elements. Secondly, impact can be made by limiting the<br/>environmental footprint of the structure in the initial design by material minimization and selection. Recycling is left out of the scope since recycling on a world-wide scale barely occurs. Even in a country with a well developed recycling network like the Netherlands, just 5-10% of discarded ﬂat glass waste ends up back in the ﬂoat glass industries and the rest is downcycled to container glass or glass ﬁbres. Besides, the sustainable impact from recycling compared to reuse is far smaller, and measures to limit contamination are out of control of the designer. At ﬁrst, in order to design for reuse as an end-of-life application, demountable connections are essential and adhesive based connections should be avoided. Although demountability is a key to the circular economy, this study concludes that there are various technical barriers to overcome to make glass elements actually reusable. One important barrier is the lack of standardization in glass structures. As is shown in the redesign of ""Kasteel Ruurlo"", implementing standardization leads to a modular design and is integrated by using minimum size deviation and the use of a single type of connection. However, as a result of standardization, the design freedom of the architect is taken away and the mechanical connections lead to a less elegant design. Therefore, it is recommended to further development these modules and discuss elegance and design freedom in standardization. Another technical barrier to overcome is the performance and quality of glass elements which makes current reuse impossible: insulated glass units will loose their insulating performance due to failure of the edge sealant after 20 to 25 years, and laminated glass is prone to delamination over time. There is a lack of legislation which sets requirements to the quality and performance of these elements. Only for laminated glass, there is a potential reuse strategy which has been used in the redesign of ""Kasteel Ruurlo"". It is proposed to use a high quality interlayer as SentryGlas or Troﬁsol. For both interlayers, delamination problems should be further researched in order to assure a long technical lifetime.<br/>Secondly, in order to minimize the environmental impact of the structure, the impact has been quantiﬁed using Life Cycle Analysis data and Environmental Product Declarations. With the method by ""Stichting Bouwkwaliteit"", this data is converted to shadow costs which is used to calculate the environmental footprint of a connection. Different structural connections are considered: various facade connections, different moment rigid frame connections and various ways to connect a panel. From this calculation, the different connections are compared and it is concluded that adhesive based connections have both a smaller environmental footprint than mechanical connections, and that these result in less material use in the overall structure and thereby limiting the environmental footprint. This is also reﬂected in the redesign of ""Kasteel Ruurlo"", where due to the mechanical demountable connections, the environmental impact increases compared to the current design. With current possibilities, the relation between the connection and a sustainable design depends on the type of connection: an adhesive based connection will result in an overall low environmental impact but makes reuse unlikely. A mechanical connection could be an outcome here, but with current possibilities, reuse cannot be guaranteed either. The application of current demountable connections on the reuse possibilities can therefore be argued. In order to succeed with structural glass in the circular economy, this research emphasizes the need for legislation, standardization and to solve problems like delamination and leaking insulated glass units which now determine the lifetime of glass structures. It also shows the need for demountable connections which increase the reuse potential and which ideally do not increase the environmental footprint.","Glass; Sustainability; Structural glass; Reuse; Recycling; Environmental impact; LCA; EPD; Connection; Adhesive; Mechanical connection","en","master thesis","","","","","","","","","","","","Civil Engineering | Structural Engineering","",""
"uuid:21d7a772-46dc-4a1e-84c4-51d23cee67e2","http://resolver.tudelft.nl/uuid:21d7a772-46dc-4a1e-84c4-51d23cee67e2","Optimisation of control for an airborne wind turbine: with maximum power point tracking","Fisscher, W.D. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Schmehl, R. (mentor); Dong, J. (graduation committee); Qin, Z. (graduation committee); Breuer, J. (graduation committee); Delft University of Technology (degree granting institution)","2020","Airborne wind energy is a promising newly emerging wind energy harvesting technology. Due to low material use and high potential harvesting density it aspires to be competitor to the conventional wind turbines we see today. Kitepower bv, a company in the Netherlands, is developing a airborne wind energy system based on a flexible kite. To be able to get a share in the energy market, reliability, safety and long term operation are aspects that are still challenging. The kite is controlled by a robot, called a kite control unit(KCU), that is suspended under the wing and steers the wing inside the wind window to create a traction force. This research focuses on improving long term operation by improving the power supply of this KCU. A wind turbine attached to the KCU is used as a power supply, but the electronic power conversion has not been optimized yet. A maximum power point tracker is optimised for this system, in which a new control model is used. Here the rotational speed is taken as a controlled variable. In addition, a method to protect the battery and the electrical system is implemented when abundant energy is available. This research shows how a converter is designed and how it can be controlled to provide the demanded functionalities.","kitepower; Airborne Wind Energy; Maximum Powerpoint Tracking; Wind Energy; Control; Stall","en","master thesis","","","","","","","","2025-08-14","","","","","",""
"uuid:769ac095-ae4e-45f5-ba76-344a89014121","http://resolver.tudelft.nl/uuid:769ac095-ae4e-45f5-ba76-344a89014121","Design and simulation of an invisibility cloak device in Julia","Voskamp, R. (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Applied Sciences)","Cools, K. (mentor); Adam, A.J.L. (mentor); Delft University of Technology (degree granting institution)","2020","Mankind has always adapted materials to fullfil a need. Recent developments in nano-science allows us to construct objects with varying permittivity and permeability. One possible structure is an invisibility cloak device. This device is put around an object. Any plane wave that enters the cloak should go around this object. The wave exits the cloak as a plane wave, rendering the object on the inside invisible. Since making such a device is quite dicult, it is useful to simulate it first. A relatively new programming language is Julia [1], [2]. Julia has a high performance and this makes it an interesting language to use for these simulations. In this work, the material properties of such a device was calculated. A simulating tactic was developed. This tactic was a hybrid version between the Method of Moments (MoM) and the Finite Elements Method (FEM). Both these methods and the hybrid method were implemented in BEAST.jl [3]<br/>and CompScienceMeshes [4] and were tested using simulations in EMwavesBEP.jl[5]. While the FEM and MoM gave great results, the hybrid algorithm had only a good result for the electric fields. The magnetic elds failed to show the wanted results. The previous determined cloak was simulated using the hybrid algorithm. The cloaking property was clearly visible and the wave<br/>exited as a plane wave. A far field should be calculated to verify this further.<br","Julia; finite element method; method of moments; Boundary element method; invisibility","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics | Applied Physics","",""
"uuid:aea11311-2ca8-46bb-97d5-ac451d01783a","http://resolver.tudelft.nl/uuid:aea11311-2ca8-46bb-97d5-ac451d01783a","River discharge modelling based on surface flow velocity estimations: A combination of Large-Scale Particle Image Velocimetry and three dimensional discharge modelling","Schurer, Sten (TU Delft Civil Engineering and Geosciences)","Winsemius, H.C. (mentor); Luxemburg, W.M.J. (graduation committee); Kok, M. (graduation committee); Delft University of Technology (degree granting institution)","2020","Rivers have long since exceeded their natural purpose of discharging excess water, by becoming subject to many practical applications demanded by present day society [61]. In order to comply withthis variety of needs and demands, the necessity for proper water management arises, which in turn requires data and knowledge of hydrological parameters like water levels, water quality and river dis-charge [50]. This research focuses on the hydrological data demand and specifically on the measurement of riverdischarge. Discharge is generally estimated with intrusive measurement methods [64], this means that the measurement device is in physical contact with the water which can be difficult in strong current or high discharges and even dangerous during floods . Furthermore, in remote and low-resource settings, collecting discharge data is compromised by accessibility problems and difficulties maintaining and acquiring monitoring equipment. When numerous measurements are performed, it is common practice to establish a stage-discharge relationship [66] to facilitate discharge determination, i.e. by shifting to stage measurements. However, due to the empirical character of the method and the sporadic occurrence of high discharges, the relationship can contain considerable uncertainties for these higher discharges [67]. The aim of this research is to provide a sustainable and low-cost data collection and processing method in order to establish a rating curve based on a three dimensional hydraulic modelling approach. One of the main processing methods is Large-Scale Particle Image Velocimetry (LSPIV). LSPIV is a computer based technique that computes flow velocities at the river surface based on video images. Hence, with the development of such a model a more physically based stage-discharge relationship can be determined based on non-intrusive measurements, meaning that measurements can be taken during safe (low flow) conditions in a restricted amount of time. Furthermore, due to the sole use of relatively simple methods and the limited amount of observations needed, this method is particularly suitable for remote and low resource settings. The study is based on data collected during a two month field trip at the Luangwa river in Zambia. The dataset consists of point clouds collected with the aid of photogrammetry, sonar and RTK GPS which are used to create a bathymetric chart, videos recorded with a drone for the computation of the surface flow velocities, surface flow velocities measured with a current meter for LSPIV validation and discharges measured with an ADCP. The bathymetric chart is used as bed level for the three dimensional discharge model created with Delf3D D-Flow FM which is calibrated with the surface flowvelocities (LSPIV) and ADCP discharge measurements. The discharge model represents approximately 9.2 kilometres of the Luangwa river in length and can reach a maximum width of about 390 metres. The model is calibrated at a discharge of 191 m3/s by minimising the difference between measured and simulated values of ten surface flow velocities and five water levels. This resulted eventually in a Manning friction coefficient of푛= 0.014 s/m1/3. The calibrated model resembles the actual river in location, depth, width and surface flow velocity. The LSPIV velocities are approached to a mean average deviation of 0.07 m/s (1.1 m/s average) and the water level deviates 0.06 m at the research area (1.3 m average). The model is used to establish a stage-discharge relationship which is subsequently compared to two existing relationships, one based on a similar approach using a 1D model and one based on stage-discharge data measured at a conventional gauging station. The three stage-discharge relationships are in the same order of magnitude although the geometry of the river at all sites is likely to be different. Since a stage-discharge relationship is heavily dependent on the geometry [66] this comparison is only a rough indication of the accuracy. Ideally, the discharge, water level, and surface flow velocity should be measured for different discharges and compared (using the model) to the established relationship. The stage-discharge relationship could, if needed, be adjusted based on the new measurements.","Discharge modelling; LSPIV; Bathymetric chart; RTK GPS; Zambia; Stage-discharge relationship; Width-discharge relationship","en","master thesis","","","","","","","","","","","","Water Management","",""
"uuid:74aabb03-145f-4edf-817c-1731bab086d2","http://resolver.tudelft.nl/uuid:74aabb03-145f-4edf-817c-1731bab086d2","Procedural Content Generation for Math Education","Xu, Y. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Bidarra, Rafael (mentor); Eisemann, Elmar (graduation committee); Lofi, C. (graduation committee); Delft University of Technology (degree granting institution)","2020","Mathematics education plays an essential role in children’s development. In the past few years, online mathematics learning has gained increasing popularity. The online learning platform needs a large variety of textual and visual content to offer children a convenient learning experience and help them practice various mathematical skills. However, manually creating content is hugely time-consuming, expensive, and tedious for the content editors. <br/><br/>This project proposes a generic approach for procedural generation of mathematical problems and corresponding textual and visual content. We analyzed and clustered hundreds of primary school curriculum-based math knowledge components, and built flexible templates for generating abstract math problems, including arithmetic, comparison, ordering, mathematical relationships, measurements, and geometry. Then our system realizes the abstract math problems in natural language through the lexicalization of language-independent semantic configurations and syntactically structured templates. Our system generates visual content through text-based image retrieval and visualization of abstract math content, varying in the forms of table, chart, geometry, or picture for counting objects. Human expert evaluations found that our generated contents are understandable, sensible, and achieve well usefulness for primary school students.","Procedural Content Generation; Math Education; Online learning","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:1d568346-86d5-402b-babe-26d2ba46809b","http://resolver.tudelft.nl/uuid:1d568346-86d5-402b-babe-26d2ba46809b","Realising platform control in data marketplaces through Secure Multi-Party Computation: A qualitative study exploring the use of Secure Multi-Party Computation (MPC) as an instrument for realising platform control in data marketplaces","Dolci, R. (TU Delft Technology, Policy and Management)","de Reuver, G.A. (mentor); Warnier, M.E. (graduation committee); Wirawan Agahari, Wirawan (graduation committee); Delft University of Technology (degree granting institution)","2020","Practical problem: In today's digitally transformed and connected world, data has become a critical strategic corporate resource. In this context, data marketplaces are becoming more popular since they enable wider accessibility and more efficient interaction among companies. Despite this, there are several barriers in sharing data through this type of platforms, for instance, lack of trust, security, privacy and transparency. The introduction of privacy-enhancing technologies, such as secure Multi-Party Computation (MPC) could offer a significant contribution to overcoming these barriers. However, it is still unclear if secure MPC could be implemented in the data marketplace domain, especially as an instrument for controlling the platform, and what are the affordances that it could offer to data marketplace providers. For this reason, this research study aims to investigate the potential adoption of secure MPC by a data marketplace provider for realising platform control. Methodology: the exploratory nature of this research required to conduct a qualitative study to address the problem and achieve the aforementioned target. In particular, given the specific characteristics of this research, a survey research was undertaken. Regarding the data collection method, semi-structured interviews were conducted among data marketplace providers operating in the mobility domain, data marketplace experts and MPC developers and experts. Results: the adoption of MPC could generate three main affordances for a data marketplace provider in terms of platform control: (1) preserving the data, (2) enabling data ownership and (3) preserving the result of the computation. These affordances are generated by the relationship between the data marketplace provider’s goals in terms of platform control and the features of the MPC technology. Regarding the former, the following goals were identified: (1) ensure the security and the privacy of the data; (2) guarantee that a data provider has complete control over its data; (3) ensure the correct execution of the computation. Concerning the latter, three key features offered by the MPC technology could enable platform control: (1) information-theoretic security or computational security, (2) agreement protocols before starting the computation and identification mechanisms if someone deviates from it, (3) and correct execution of the computation. <br/>The realisation of the affordances could be influenced by three factors: (1) perception of the technology, (2) need for the technology, and (3) degree of effort required. The results showed that secure MPC could satisfy several different needs of a data marketplace provider. However, some constraints could influence the adoption of MPC among data marketplace providers. Firstly, a data marketplace provider may perceive the MPC as unsafe because of the difficulty to understand the technology. Secondly, a data marketplace provider could consider that secure MPC does not currently present an adequate maturity level to adopt the technology in its platform. Finally, a data marketplace provider could prefer to maintain its current situation in order to avoid a radical change. <br/>The adoption of MPC technology by a data marketplace provider could cause several impacts on its platform. If the platform has a centralised structure, the data will not be stored in the platform anymore, but they will remain with the data provider. Moreover, if a data marketplace focuses only on data exchange offerings, it would be able to offer a new type of product in its platform (e.g. insights). Finally, the adoption of the MPC in a data marketplace could cause additional overhead in the functioning of the platform. Theoretical and practical contributions: regarding the former, this study contributes to the literature of data markets, platform control, MPC, and affordance theory. Concerning the latter, this research provides practical contributions to the business actors involved in data-sharing domains and to MPC developers. Limitations: firstly, it was not possible to focus the research on data marketplace involved exclusively in the mobility domain and to reach theoretical saturation also for the fourth sub-research question of the study because of the difficulty of reaching informants. Secondly, two of the data marketplace providers interviewed worked for a data marketplace, which is not currently operating anymore. Moreover, in some cases, it was necessary to interview a person with a different role in the company compared to the one initially selected. Thirdly, since some of the interviewees did not have the time to study the MPC description document before the interview, it was necessary to verbally explain it, thus possibly affecting both the validation of the document and the understanding of the technology. Future research: Firstly, by conducting more interviews, it could be possible to identify more factors. Secondly, future research could be undertaken to validate the model of this research through quantitative studies. Thirdly, further researches could be pursued to update the taxonomy of data marketplaces. Fourthly, future research could be carried out to explore the introduction of secure MPC in other settings. Finally, it could be interesting to explore the different perspectives of the actors involved in a data marketplace (e.g. data providers and buyers).","Data sharing; Data Marketplaces; Platform control; Secure multi-party computation; Affordance theory","en","master thesis","","","","","","","","","","","","","",""
"uuid:374fb4d1-220b-424b-a8fc-e6b3332a1397","http://resolver.tudelft.nl/uuid:374fb4d1-220b-424b-a8fc-e6b3332a1397","Proactive-Reactive Approach for Stable Rescheduling of the Train Unit Shunting Problem","Stelmach, Fabian (TU Delft Electrical Engineering, Mathematics and Computer Science)","de Weerdt, M.M. (mentor); Bliek, L. (graduation committee); Spaan, M.T.J. (graduation committee); Aardal, K.I. (graduation committee); Delft University of Technology (degree granting institution)","2020","This research is focused on the proactive-reactive rescheduling process of the Train Unit Shunting Problem (TUSP) on train maintenance shunting yards. An important difference between a scheduling process and the rescheduling process is that a reschedule must be both feasible and desirable (similar to pre-schedule), while a schedule does not require desirability. Firstly, an abstract proactive-reactive rescheduling framework is proposed. This framework is proposed as a base for the general problem of proactive-reactive rescheduling. A total of four reactive rescheduling methods for the TUSP are proposed and implemented as extensions to the Simulated Annealing local search algorithm. The extensions are created in order to achieve reschedule desirability by either guiding the local search process during its iterations or influencing its starting point. Using experiments based on realistic data, it is concluded that the Simulated Annealing can be used to create reschedules that are both feasible as well as desirable. It is shown that both proposed extensions are required for the best reschedule quality. Finally, further analysis of the results shows that the schedule resilience to late arrival of trains can be improved upon by increasing the amount of time between a train arrival and the time at which its services are scheduled.","Train Unit Shunting Problem; Schedule Repair; Scheduling under Uncertainty; Proactive-reactive scheduling","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:5d856ba9-a207-4b61-8bb7-703322fe3154","http://resolver.tudelft.nl/uuid:5d856ba9-a207-4b61-8bb7-703322fe3154","Flood Wave Monitoring using LSPIV: A methodology for monitoring flood waves in an equatorial urban stream with fast response time","Gerritsen, G.H. (TU Delft Civil Engineering and Geosciences)","Winsemius, H.C. (mentor); Annor, F.O. (graduation committee); Kok, M. (graduation committee); Luxemburg, W.M.J. (graduation committee); Delft University of Technology (degree granting institution)","2020","To develop warning systems for flood events, create precipitation-runoff relationships, validate runoff models, or to understand the behaviour of rivers, understanding of the amount of water flowing through rivers is needed. The low-cost and novel gauging method using Large-Scale Particle Image Velocimetry (LSPIV) could complement discharge measurements at locations and stages where the possibilities of using traditional gauging methods are limited. This report investigates the feasibility of using LSPIV to quantify river discharges in an equatorial urban stream with fast response time.<br/><br/>LSPIV uses videos to extract surface flow velocities by tracing movements of seeds on the water's surface. Combined with the local bathymetry and water level, an estimation of the river's discharge can be made. This study consists of two sets of experiments. The first set of experiments were performed at the Dommel regarding processing software, image preparation, seeding densities, and point of views and discussed by assessing their accuracy relative to benchmark measurements -- using the mean error and root mean squared error -- and the method's precision – using the relative standard deviation.<br/><br/>The second set of experiments were performed along the Chuo Kikuu, Dar es Salaam, Tanzania. A flood wave was monitored through the capture of 73 5 second videos. These videos were turned into separate frames and corrected for lens distortion and perspective distortion. Thereafter the frames were gray scaled and gamma correction was applied. After the LSPIV process additional filtering removed unrealistic low flow velocities, and through substitution missing velocities were replaced with flow velocities based on the vertical logarithmic progression relationship between the surface flow velocities and water depth. The surface flow velocities found using this method match optical observations. Discharges were estimated using the empirical depth-average coefficient and local bathymetry. Results showed that the post-processing reduces the uncertainty bandwidth with 37% and increases the mean flow velocities with 96%.<br/><br/>The found discharges were compared with precipitation measurements observed at a nearby TAHMO meteorological station. The total volumetric precipitation was determined by estimating the contributing catchment using a digital elevation map and the locations of man-made drainage systems. When comparing the volumetric precipitation with the flood wave, a runoff coefficient of 53% [35-68] is found. This coefficient falls within the ranges found in literature, but is probably an underestimation of the true runoff due to an overestimation of the catchment area and underestimation of the discharges.<br/><br/>This study shows that the LSPIV method is feasible for continuously monitoring flood waves in an urban environment. Especially during peak flows LSPIV proves to be valuable, as observations using conventional gauging methods are labour intensive, unsafe, or not executable. Because of the possibility to monitor streams from a distance -- which ensures access to power and safety against vandalism -- there is a possibility to observe complete flood waves at regular intervals without the need for direct contact with the water. For Dar es Salaam, this method opens doors for continuous and secure stream monitoring, at low costs and with local devices.","LSPIV; Hydrology; Dar es Salaam; Flood wave; Monitoring","en","master thesis","","","","","","","","","","","","","","-6.769165, 39.251976"
"uuid:7fa236fe-686a-423b-ad56-5ac81e07d129","http://resolver.tudelft.nl/uuid:7fa236fe-686a-423b-ad56-5ac81e07d129","Improving the robustness of decision trees in security-sensitive setting","Buijs, Cas (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Cyber Security)","Verwer, S.E. (mentor); Lagendijk, R.L. (graduation committee); Tax, D.M.J. (graduation committee); Delft University of Technology (degree granting institution)","2020","Machine learning is used for security purposes, to differ between the benign and the malicious. Where decision trees can lead to understandable and explainable classifications, an adversary could manipulate the model input to evade detection, e.g. the malicious been classified as the benign. State-of-the-art techniques improve the robustness by taking these adversarial attacks into account when building the model. In this work, I identify three factors contributing to the robustness of a decision tree: feature frequency, shortest distance between malicious leaves and benign prediction space, and impurity of benign prediction space. I propose two splitting criteria to improve these factors and suggest a combination with two trade-off approaches to balance the use of these splitting criteria with a common splitting criterion, Gini Impurity, in order to balance accuracy and robustness. These combinations allow building robuster models against adversaries manipulating the malicious data without considering adversarial attacks. The approaches are evaluated in a white-box setting against a decision tree and random forest, considering an unbounded adversary where robustness is measured using a L1-distance norm and the false negative rate. All combinations lead to robuster models at different costs in terms of accuracy, showing that adversarial attacks do not need to be taken into account to improve robustness. Compared to state-of-the-art work, the best approach achieves on average 3.17% better accuracy with an on average lower robustness of 5.5% on the used datasets for a single decision tree. In a random forest the best approach achieves on average 2.87% better robustness with a 2.37% better accuracy on the used datasets compared to the state-of-the-art work. The state-of-the-art work does not seem to affect all of the identified factors, which leaves room for even robuster models than currently existing.","Adversarial Machine Learning; Decision Trees; Robust learning","en","master thesis","","","","","","","","","","","","Computer Science | Cyber Security","",""
"uuid:9102f269-ca73-4281-99e0-ea911282859e","http://resolver.tudelft.nl/uuid:9102f269-ca73-4281-99e0-ea911282859e","Generalised Motions in Active Inference by finite differences: Active Inference in Robotics","Hijne, Iris (TU Delft Mechanical, Maritime and Materials Engineering)","Wisse, M. (mentor); Babuska, R. (graduation committee); Pezzato, C. (graduation committee); Delft University of Technology (degree granting institution)","2020","This thesis is a contribution to the research on Active Inference for Robotics. Active Inference is an intricate, intriguing theory from neuroscience, a field in which it has already gained a greater following and popularity. This theory, based on the underlying Free Energy Principle, provides a unified account of perception, action and learning in the biological brain. It has great explanatory power of the function of the biological brain and furthermore it is mathematically well-defined. This property makes the theory suitable for a translation to robotics, in which it can also provide a unified account of action and perception. This is not only elegant, but potentially very powerful too. The research for Active Inference in robotics is young, but the current research already shows that Active Inference indeed has great potential for robotics control. Literature on Active Inference is narrow and complex, and provides a lot of concepts to work with in a translation to robotics control. Once such concept are the generalised coordinates of motion, which are the instantaneous derivatives of a dynamic variable. The incorporation of generalised coordinates, especially in combination with the assumption that the noise encountered in a dynamic environment is coloured, has great potential to be beneficial for both action and perception when it comes to robot control in real environments. Generalised coordinates provide a reference frame for the gradient descent that is applied to provide the action and perception laws, which in a dynamic setting has to `hit a moving target'. Furthermore, in combination with coloured noise the generalised coordinates are advantageous for dealing with such noise. In this thesis, detailed research is provided with regards to the application of generalised coordinates in Active Inference for robotics. Current research for robotics in which Active Inference has been applied doesn't exploit the full potential of generalised coordinates. Therefore, this research aims to explore the constructs necessary to apply generalised coordinates of motion in an on-line Active Inference control loop of an LTI State Space system. A detailed derivation of the generalised precision, which relates generalised coordinates and coloured noise, is provided. A method for obtaining generalised output by means of finite differences is proposed, that constructs generalised coordinates from the on-line data in scenarios in which the environment does not provide the required generalised coordinates naturally. The method is implemented in the simulation of a one degree of freedom SISO LTI State Space scenario which highlights the potential but also the difficulties still faced when applying Active Inference for on-line robotics control. Besides the detailed derivations of some aspects of Active Inference for robotics, open problems are identified and suggested for future research that can potentially yield methods to apply Active Inference in robotics at full capacity, providing a true biologically plausible robot control method.","Active Inference; Free Energy Principle; Robotics; LTI State Space; Finite Difference Method (FDM); coloured noise; Bio-inspired","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Biomechanical Design - BioRobotics","",""
"uuid:e7bb26fe-da1a-4dd0-a0e8-da017c190730","http://resolver.tudelft.nl/uuid:e7bb26fe-da1a-4dd0-a0e8-da017c190730","Exploring the value-stacking opportunities of batteries providing frequency containment reserve services in different regulatory environments","Visser, Jelle (TU Delft Technology, Policy and Management)","Heijnen, P.W. (mentor); Warnier, Martijn (mentor); Okur, Ö. (graduation committee); Delft University of Technology (degree granting institution)","2020","The security and reliability of the European power system network that is used to transmit electricity from producers to consumers is under increasing pressure. The penetration of renewable energy resources that have a variable and unpredictable energy output and the rising cost of the operation of fossil-based power generators are negatively influencing the availability of controlling power that is critical for normal system functioning. Without this controlling power, there is a risk of electricity network imbalances and complete electricity blackouts. To be able to guarantee the continuity of electricity supply, transmission system operators are required to search for new and alternative flexibility resources, including resources that could provide the primary system response (frequency containment reserve) to these grid imbalances. Battery energy storage systems are one of the most promising alternative resources that could provide this load controlling capacity. These systems are, however, extremely cost-intensive. Using a battery for multiple battery applications simultaneously could improve the financial viability of these battery energy storage systems and thereby, accelerate their deployment in society. To be able to get the full potential out of this value-stacking opportunity, more insight into the technical and operational compatibility of using a battery for frequency containment reserve and other battery applications is required. In this master thesis, a research was conducted to obtain a better understanding of the opportunities to create added value in the utilization of a battery that is providing frequency containment reserve services. By means of a (multiple-)case study research (including a literature review, a simulation model and a time series analysis and forecasting model), more insight was obtained in the power and energy capacity utilization of a battery that is providing frequency containment reserve services and the usability of the leftover capacities of this battery for serving other battery applications. In the literature review that was performed, it was demonstrated that the activation of batteries for frequency containment reserve is mainly dependent upon the regulations and grid characteristics that are present in the area of interest. These regulations provide terms and conditions for the theoretical use of a battery’s power and energy capacity and therefore, the theoretical opportunities for valuestacking. These value-stacking opportunities include the use of moments in which a battery is idle and the time periods in which a battery is not using its full energy capacity. The simulation study that was performed subsequently showed that for all frequency containment reserve markets examined in this research, there are moments and periods in time in which a battery is not using its entire reserved frequency containment reserve power and energy capacity. This indicates that using a battery at these particular moments and periods in time for other battery purposes might create substantial added value to the overall system operation. The analysis of the data that was obtained from the simulation study showed that the practical usability of these moments and periods in time for value-stacking opportunities seems limited. Although it was illustrated that there are moments in which the battery’s power capacity is not used, no clear prediction can be made of these so called ‘idle moments’. Consequently, it is uncertain at what exact moments in time the battery is idle and could be used for other battery purposes. The duration of the idle moments is furthermore relatively short, which makes it difficult to use these idle time periods for applications that require consecutive power supply or energy storage. Results of the time series analysis and forecasting model demonstrated that there might be opportunities to predict the required energy capacity for frequency containment reserve. This indicates that forecasts can be made of the state of charge development of a battery over a certain time period. This information can be used to identify the underutilized battery energy capacity, which subsequently could be used for other battery applications. The combination of both the power and energy capacity limitations prove to be a challenge when aiming at value-stacking of a battery. Using the idle moments and the forecasted available energy capacity of a battery for other battery applications requires expert knowledge of the energy capacity that is needed for the additional application and seems to require flexibility of power capacity utilization of the additional application itself. Further research should focus on the improvement and validation of the frequency containment reserve activation forecasts to be able to make a better estimation of the battery energy capacity that is available for serving other battery purposes. Research should moreover be conducted to examine the energy and power requirements of other applications over time. This includes the need for state of charge control. The information that is obtained from these studies is essential to identify how various battery applications, including frequency containment reserve, can be properly aligned and could add value to the battery system operation.","","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:07be93ff-1b18-43f8-a2df-224d856f5e55","http://resolver.tudelft.nl/uuid:07be93ff-1b18-43f8-a2df-224d856f5e55","System Identification using Dynamic Expectation Maximization: From neuroscientific principle towards filtering and identification under the presence of correlated noise","Žnidaršič, L.Y.D. (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Delft Center for Systems and Control; TU Delft Biomechanical Engineering)","Wisse, M. (mentor); Mohajerin Esfahani, P. (mentor); Babuska, R. (graduation committee); Anil Meera, A. (graduation committee); Delft University of Technology (degree granting institution)","2020","A fundamental task of intelligent and autonomous robots is to infer from observations the state of the world. This inference is generally achieved by employing a filter, which consists of a model and filtering law. Learning this model and filtering law from observations is another fundamental part of robotics, and is generally referred to as system identification. <br/><br/>Neuroscientist K.J. Friston has developed a relatively novel theory on biologically plausible human brain inference called the Free-Energy Principle. One of the theories within the Free-Energy Principle, namely that Dynamic Expectation Maximization (DEM), has been suggested as a novel method for filtering and system identification. This method is expected to outperform standard Expectation Maximization (EM) in terms of hidden state and parameter estimation in settings where noise is correlated. However, in order for this neuroscientific theory to be properly used for robot inference, two problems must first be solved. <br/><br/>The first of these problems is the fact that the theory is defined in the continuous-time domain, whereas data available for system identification is always discrete. In this thesis I will suggest three discrete-time interpretations for DEM-based system identification. The major difference between the three methods is the information that is embedded in the generalized signals: predictions, derivatives and past data.<br/><br/>The second problem is that the filtering method corresponding to the Free-Energy Principle depends on data which is not available: the derivative signals of measured in- and outputs. I introduce two fundamentally different solutions to this feasibility issue: a numerical differentiator and a stable filter. Both of these solutions are shown to find an estimate for the unavailable data. However, the former is shown to significantly outperform the latter.<br/><br/>Furthermore, the theory described in this thesis is implemented into a novel python toolbox for system identification. This toolbox can be used as a basis for further research and be approved along with it, until at some point it is ready to be used for real applications.<br/><br/>Using the toolbox, the DEM-based identification and filtering methods are tested though various numerical simulations and the results are compared with the EM method. Results show that with the implemented settings none of the suggested discrete-time filtering methods outperforms the conventional Kalman filter. The main cause of this inferior performance is shown to be instability in the filtering method. I make some suggestions for overcoming this problem. As a result of the inferior performance, the joint-performance of the suggested DEM-based parameter- and state- estimation methods also proves to be inferior in terms of parameter estimation accuracy. <br/><br/>However, results show that the theoretical parameter optima of the Free-Energy as determined from known hidden states are in fact close on the real parameters, and furthermore show to be invariant to noise correlation. This suggests that should the instability issue as some point be solved and a better means to approximate the theoretical optimum be found, the DEM-based methods might in fact outperform EM both in terms of hidden-state and parameter accuracy in settings with correlated noise.<br","dem; em; robotics; filtering; identification; inference; corellated noise","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:ca6e6b0b-a0f1-4214-9212-0d172af7e10c","http://resolver.tudelft.nl/uuid:ca6e6b0b-a0f1-4214-9212-0d172af7e10c","Modeling of an Electrochemical Flow-through Reactor for Mediated Alcohol Oxidation","Doorn, Max (TU Delft Mechanical, Maritime and Materials Engineering)","Haverkort, J.W. (mentor); Latsuzbaia, Roman (mentor); Delft University of Technology (degree granting institution)","2020","The increasing penetration of renewable energy in the energy grid causes intermittency, resulting in fluctuating prices. This in turn forges windows of opportunity for the electrochemical production of chemicals that would otherwise be too expensive. This research aims to optimize a continuous-flow-through reactor hosting the production of chemicals by mediated electrochemical oxidation, using organic aminoxyls (i.e., electrocatalysts), specifically 2,2,6,6-tetramethylpiperidinyloxyl (TEMPO) and 4-acetamido-TEMPO (ACT). <br/>The first chapter addresses the main motivation behind- and the aims of this research. In the second chapter, an extensive literature review is provided on the physico-chemical and electro-catalytic properties of the TEMPO mediators, that are important for the modelling of the electrochemical reactor. The third chapter describes the analytical- and computational models that were created to investigate the influence of mediator properties, current density, specific surface area, velocity, and electrode thickness on the energy efficiency of the reactor. More specifically, a flow-through electrochemical reactor with metal foam electrodes and divided anolyte and catholyte compartments.<br/>The solutions obtained from the analytical model are in good agreement with the solutions of the computational model. The analytical model was extended with the Hatta analysis to include mass transfer in the porous electrode. It was found that ohmic losses, due to an expanding reaction zone from the membrane inward in the anode, caused by mass-transfer and/or kinetic limitations of the mediator, pose the biggest obstacle in reaching high conversion with reasonable efficiency.<br/>The main result of this study is a mathematical formula, that allows for quick prediction of the performance of mediated electrochemical oxidation in a flow-through reactor with a porous foam electrode.<br","Porous electrode; Coupled Reaction; Mediator; Modeling","en","master thesis","","","","","","","","2022-02-23","","","","","",""
"uuid:f41a24dc-634b-43c2-b5b1-6cd5162a073a","http://resolver.tudelft.nl/uuid:f41a24dc-634b-43c2-b5b1-6cd5162a073a","Can nudges be used as a driver for sustainable behavior?: Is a transparent Foot-in-the-Door behavior influencing intervention an acceptable and effective driver for fruit and vegetable waste separation?","Huntjens, Remco (TU Delft Technology, Policy and Management; TU Delft Multi Actor Systems)","de Vries, G. (mentor); Pesch, U. (mentor); Delft University of Technology (degree granting institution); Universiteit Leiden (degree granting institution)","2020","A replication of the classic Foot-in-the-Door experiment to observe if it can be used as a driver of fruit and vegetable waste separation. Move over, for the first time the transparency and the online use of this behaviour influencing tool are discussed within this thesis.<br","Foot-in-the-door; Nudging; Waste-separation; Behavior influencing tools; Online Nudging","en","master thesis","","","","","","","","","","","","Industrial Ecology","",""
"uuid:e566edb9-2627-411f-926e-d33af62298d4","http://resolver.tudelft.nl/uuid:e566edb9-2627-411f-926e-d33af62298d4","Relations between the obstacle space of cycling infrastructure and bicycle crashes: An analysis of Amsterdam","van Weelderen, Guus (TU Delft Civil Engineering and Geosciences)","Hagenzieker, M.P. (graduation committee); Maat, C. (graduation committee); Annema, J.A. (graduation committee); Wijlhuizen, Gert Jan (graduation committee); Delft University of Technology (degree granting institution)","2020","The objective of this study is to strengthen literature about cyclist safety and help prevent bicycle crashes in the future. It looks into the gap about the relation between the obstacle space of cycling infrastructure (that involves the space that is available for cyclists to avoid crashes with the obstacles therein) and the visibility thereof, and bicycle crashes. Next to a brief literature research, the main method used to answer this question is modelling of generalised linear models with a negative binomial distribution, that link independent variables concerning the obstacle space to the dependent count variable crashes. Results show that the relation is apparent in data concerning 50 km/h streets in the municipality of Amsterdam: infrastructure on a street level can indeed predict bicycle crashes on the same level. Fewer obstacles next to the road and higher widths were found to lead to fewer crashes. For lanes and one-way tracks holds that an increase in width of smaller sections has a bigger impact. The effect of obstacles in the shoulder also reduces at higher widths. A significant relation for light conditions was not found. Further research should look into different types and clustering of obstacles and improve the light analysis. Recommendations include providing dedicated cycling infrastructure with sufficient widths and few obstacles, and better registration of bicycle crashes. The study demonstrates that infrastructure is an important factor for the occurrence of bicycle crashes, that should certainly not be disregarded alongside the road user and vehicle. It hopes to push infrastructure policies for cycling more on the agenda.","Active modes; Road safety; Bicycle crashes; Infrastructure; Generalised linear models; Negative binomial distribution","en","master thesis","","","","","","","","","","","","Transport, Infrastructure and Logistics","",""
"uuid:2945dcc8-e7b9-4536-b9e7-074cfe86d3f9","http://resolver.tudelft.nl/uuid:2945dcc8-e7b9-4536-b9e7-074cfe86d3f9","Learning What to Attend to: Using bisimulation metrics to explore and improve upon what a deep reinforcement learning agent learns","Albers, Nele (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Interactive Intelligence)","Oliehoek, F.A. (mentor); Suau de Castro, M. (mentor); Spaan, M.T.J. (graduation committee); Brinkman, W.P. (graduation committee); Delft University of Technology (degree granting institution)","2020","We analyze the internal representations that deep Reinforcement Learning (RL) agents form of their environments and whether these representations correspond to what such agents should ideally learn. The purpose of this comparison is both a better understanding of why certain algorithms or network architectures perform better than others and the development of methods that specifically target discrepancies between what is and what should be learned. The concept of ideal representation we utilize is based on stochastic bisimulation and bisimulation metrics, which are measures of whether and to which degree states are behaviorally similar, respectively. Learning an internal representation in which states are equivalent if and only if they are bisimilar and in which distances between non-equivalent states are proportional to how behaviorally similar the states are has several desirable theoretical properties. Yet, we show empirically that the extent to which such a representation is learned in practice depends on several factors and that a precise such representation is not created in any case. We further provide experimental results that suggest that learning a representation that is close to this target internal state representation during training may improve upon the learning speed and consistency, and doing so by the end of training upon generalization.","Representation Learning; Bisimulation Metrics; Generalization; Deep Reinforcement Learning; Auxiliary Loss; Markovianity","en","master thesis","","","","","","","","","","","","Computer Science | Data Science and Technology","",""
"uuid:615d5f26-7bb4-4a9a-807c-7fecf9d8c862","http://resolver.tudelft.nl/uuid:615d5f26-7bb4-4a9a-807c-7fecf9d8c862","Learnable weight initialization in neural networks","Bhattacharya, A. (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Gemert, J.C. (mentor); Tax, D.M.J. (graduation committee); Spaan, M.T.J. (graduation committee); Delft University of Technology (degree granting institution)","2020","A new method of initializing the weights in deep neural networks is proposed. The method follows two steps. First, consider each layer as a model and perform a linear regression to keep the mean of the layer output to zero and variance<br/>after the data is passed through the activation function to one. Once each layer converges to the target mean and variance, initialize the weights of the original model with the learned weights. Performance is evaluated on LeNet and ResNet18 architectures on FashionMNIST and Imagenette datasets. The activation functions used to analyze the performance are sigmoid, tanh and ReLU. Findings show that the learned weights can perform similarly, and for certain scenarios, better than the different types of weight initializers used frequently in the field of deep learning. It is important to mention that this method requires the weights to be learned independently of the training of the model. Thus, there is a small time overhead. Moreover, it is required to adjust the hyperparameters(learning rate, epochs etc) to find the optimal weights. The findings from this thesis can be used in the future to better understand how the gradient flow could be controlled<br/>through the network and finding a more generic approach towards the vanishing and exploding gradient problem. The method requires to learn the weights followed by training the network. Learning the weights involves tweaking the hyperparameters(learning rate, number of epochs, etc). For future work, these aspects could be automated for the optimal performance of the network.","","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:e34b6f21-3379-41fe-9f3d-67c3953d8333","http://resolver.tudelft.nl/uuid:e34b6f21-3379-41fe-9f3d-67c3953d8333","Nonlinear 2D Finite Element Modeling: Cyclic Energy Storage in Salt Caverns with Creep Deformation Physics","Makhmutov, Artur (TU Delft Civil Engineering and Geosciences)","Hajibeygi, H. (mentor); Ramesh Kumar, K. (graduation committee); Bertotti, G. (graduation committee); Wolf, K.H.A.A. (graduation committee); Herder, P.M. (graduation committee); Delft University of Technology (degree granting institution)","2020","A novel 2D finite element method (FEM) on unstructured grid for nonlinear time-dependent deformation of materials is developed. The objective is to model the complex deformation behavior of the rock salt, inside which caverns are mined to store green fuels (such as hydrogen). The analyses and the developments of the present work allow for quantification of the state of the stress of the cavern, and assess the safety and reliability of the storage structure over time. The novelty of the approach is in using minimization of the potential energy principle in conjunction with nonlinear creep deformation physics. While the available FEM-based simulators offer tools only for solving linear and non-linear elastic models, the developed simulator takes into account cyclic loading and material’s damage evolution in time with possibility to predict the material’s failure. Apart from that, the stored product (hydrogen) density is taken into account, which affects cavern’s pressure variation with depth. Impurities,causing heterogeneous rock salt properties, are also considered in the developed model. Multivariate Gaussian distribution is utilized to generate distribution of the heterogeneous mechanical properties. Eulerian strains are introduced in the model to take into account deformation of the mesh. As such,the computational grid changes its geometry according to the deformation. Several numerical test cases are studied. Firstly, a consistency (verification) study is performed, to validate the linear elastic model. Remark that the linear elastic deformation model casts the basis of the non-linear model with creep physics. Then, several studies have been performed to analyze, quantify and approximate the deformation of the salt cavern under the gas pressure change, including the time-dependent creep physics.","geomechanics; Salt cavern; creep; finite element method","en","master thesis","","","","","","","","","","","","","ADMIRE",""
"uuid:9fee3e61-5bb2-4d39-a237-40d15da25f08","http://resolver.tudelft.nl/uuid:9fee3e61-5bb2-4d39-a237-40d15da25f08","Optical performance and drilling forces of an orthopaedic DRS drill with a stagnant optical probe (Article): An article on a Biomedical Engineering Master thesis about orthopaedic DRS drilling at the Delft University of Technology","Kan, Matthijs (TU Delft Mechanical, Maritime and Materials Engineering)","Hendriks, B.H.W. (mentor); Dankelman, J. (mentor); Swamy, A. (graduation committee); Bhattacharya, N. (graduation committee); Delft University of Technology (degree granting institution)","2020","In spinal surgery, the misplacement of spinal screws is a common problem that causes (severe) pain, bleedings or even paralysis [1] [2] [3]. In order to improve the navigational support of spine surgeons, this research focuses on the development of an optical sensing diffuse reflectance spectroscopy (DRS) orthopaedic drill that identifies bone tissue boundaries, based on fat fraction. The developed drill concept introduces a stagnant optical fiber-equipped probe into a cannulated orthopaedic drill. To verify the clinical applicability of the developed system, the accuracy of the optical tissue boundary detection has been analysed under different tissue penetration speeds, as well as the axial drilling force increases due to the introduction of a stagnant probe into a cannulated drill. The maximum feed rate at which the drill consistently detects the tissue boundary before breaching it, is 0,5mm/s. The force increase due to the introduction of a stagnant probe is a factor 2,96 on average and varies widely between different feed rates and probe diameters (a factor 1,15–5,75). The established feed rate speed limit of 0,5mm/s is lower than drilling feed rates of up to 5mm/s, observed in the operation room. Increasing the sampling frequency –especially decreasing the inactive period between the measurements– is required. The feed force increase of approximately a factor 3 can be regarded as a challenge for surgeons, who indicated that they preferred feed forces to be kept low.","Diffuse reflectance spectroscopy; Orthopaedic; Drilling","en","student report","","","","","","","","2025-08-12","","","","Biomedical Engineering | Medical Instruments and Medical Safety (MIMS)","MMIS",""
"uuid:439cedce-e9ed-4a1d-8e50-d8237e569d7f","http://resolver.tudelft.nl/uuid:439cedce-e9ed-4a1d-8e50-d8237e569d7f","DNS of heat transfer in a turbulent channel flow over fractal roughness","Suvarna, Pranav (TU Delft Mechanical, Maritime and Materials Engineering)","van de Water, W. (mentor); Pourquie, M.J.B.M. (mentor); Peeters, J.W.R. (graduation committee); Laskari, A. (graduation committee); Delft University of Technology (degree granting institution)","2020","Convective heat transfer finds applications in several domains of industry like heat exchangers, gas turbine blades, IC engine surfaces etc. The surfaces of these heat transfer applications are either naturally rough owing to manufacturing techniques or become rough over a period of time during operation. These rough surfaces usually contain multiple length scales and exhibit random and heterogenous properties. Fractal roughness, in principal, is characterized by self-similar detail on smaller and smaller length scales and hence fractal dimension which is independent of any length scale can become a very viable option to characterize these multi-scale random surfaces. Therefore in the current thesis, rough surfaces characterized by fractal dimensions were designed and their role in the heat transfer enhancement relative to the pressure drop was studied using DNS. <br/><br/>The fractal surfaces were designed by randomly placing five generations of self-similar cuboids with decreasing sizes from higher to lower generations. The quantity of cuboids sprinkled randomly for each generation followed a fractal dimension. Two principal fractal dimensions were selected, i.e 퐷 = 1 and 퐷 = 2 and eight random realizations of each were generated in order to study the averaged effect of the heat transfer performance. Since the cuboids were randomly placed, different realizations within<br/>the same fractal dimension experienced varied sheltering effects by larger generation cuboids. This ultimately produced a fluctuation in the ”sheltered” solidity of the fractal surface for different realizations whose effect was also studied. The cuboids were resolved in the simulation using an immersed boundary method.<br/><br/>To quantify the heat transfer performance of the rough surfaces, two performance factors namely the aero-thermal efficiency and Reynolds analogy factor were defined. It was found that the two types of fractal surfaces performed approximately similarly with a slight higher mean for 퐷 = 2 based on the above heat performance parameters even though the two surfaces looked very different. However, the above performance factors showed a very strong correlation with the ”sheltered” solidity of the fluctuating realizations displaying an increasing trend.","fractals; heat transfer; fractal roughness; DNS; Turbulent flows; Convective heat transfer","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Sustainable Process & Energy Technology","",""
"uuid:765b00ba-7a80-4588-8476-774d7badc6cb","http://resolver.tudelft.nl/uuid:765b00ba-7a80-4588-8476-774d7badc6cb","3D Aerodynamic Effects and Circulation Control of Vertical Axis Wind Turbines","Keijer, Wessel (TU Delft Aerospace Engineering)","Ferreira, Carlos (mentor); De Tavernier, D.A.M. (mentor); Hansen, Martin O.L. (graduation committee); Schmidt Paulsen, Uwe (graduation committee); Pirrung, Georg (graduation committee); Delft University of Technology (degree granting institution); Technical University of Denmark (degree granting institution)","2020","The vertical axis wind turbine (VAWT) concept in its current, fixed-pitch iteration is hindered by lower aerodynamic efficiency compared to existing horizontal axis wind turbines. Implementing a form of circulation control on the VAWT by actively pitching the blades throughout the turbine’s rotation could potentially enhance power capture efficiency and reduce loads variability. In this thesis, circulation control is investigated in 3D, since the 3D flow field differs significantly from the 2D equivalent.After a review of available 2D and 3D aerodynamic models for the VAWT, a suitable candidate emerges in the form of HAWC2 NW, which is a lifting-line based extension to popular aeroelastic modelling suite HAWC2 designed to model trailed vorticity in the near wake of the blade. HAWC2 NW is used to conduct fast 3D aerodynamic simulations of a highly simplified vertical axis wind turbine geometry to demonstrate the influence of 3D effects on the flow field surrounding the VAWT. The slenderness of the turbine geometry, expressed using the turbine aspect ratio H/D, turns out to be a major factor in determining the performance losses due to 3D effects.Subsequently, HAWC2 NW is used to analyze optimized pitch sequences with various objectives, such as maximum power or a certain normal loading distribution. A relationship is found between the ratio of upwind and downwind normal loading, the turbine aspect ratio H/D and the 3D power coefficient CP,3D. The most important conclusion is that when considering the design of a vertical axis wind turbine with a turbine aspect ratio H/D &lt; 5, losses due to 3D effects can be minimized by implementing a circulation control strategy in such a way that the normal loading is uniformly distributed between the upwind and downwind half-cycles.","VAWT; Aerodynamics; HAWC2; Near Wake; Wind Energy; circulation control; active pitch control; aerodynamic modelling","en","master thesis","","","","","","DTU Wind Energy-M-0380","","","","","","European Wind Energy Masters (EWEM) | Rotor Design Track","",""
"uuid:a3944cfc-a831-4d6c-ad0a-04605a0f1b91","http://resolver.tudelft.nl/uuid:a3944cfc-a831-4d6c-ad0a-04605a0f1b91","Estimating links between latent variables using Structural Equation Modeling (SEM) in R","Plomp, V.R. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Cabo, A.J. (mentor); Delft University of Technology (degree granting institution)","2020","Structural equation modeling is a statistical analysis technique used to analyse structural relationships between observed variables and unobserved latent variables, and can be used to estimate links between latent variables. The technique is most commonly used in the field of psychology, and is not well known in the field of mathematics. Literature on structural equation modeling often lacks mathematical formulation. In this work, the mathematical theory of the method is discussed and where needed mathematical formulation is introduced. This is done by discussing the five steps in which the method can be summarized. After analysing the mathematical theory of the method, we illustrate the method by applying it to collected data, and we interpret the results.","","en","bachelor thesis","","","","","","","","","","","","","",""
"uuid:f3b852ca-0bbd-487c-9593-e5cad1cbb4d0","http://resolver.tudelft.nl/uuid:f3b852ca-0bbd-487c-9593-e5cad1cbb4d0","A combined forecasting and packing model to optimize decision-making under uncertainty in transportation logistics: an application to air cargo revenue management","Tseremoglou, I. (TU Delft Aerospace Engineering)","Bombelli, A. (mentor); Lopes Dos Santos, B.F. (graduation committee); Ragni, D. (graduation committee); Sharpans'kykh, O.A. (graduation committee); Delft University of Technology (degree granting institution)","2020","Cargo airlines' Revenue Management (RM) departments oversee the acceptance/rejection process of incoming bookings. The overarching goal is to accept as many bookings as possible, hence maximizing profit, while avoiding overbooking and offloading of already accepted shipments, to ensure customer satisfaction. This whole process is characterized by great uncertainty, arising from the fact that the exact shipment dimensions and the available aircraft capacity are not always known beforehand. The decision process is further complicated by the fact that loading of shipments is generally performed by experience, resulting to inefficient use of the available space. These factors pose challenges to the acceptance/rejection of an incoming booking request, that can lead to loss of potential revenue for the airline. A novel combined forecasting and stochastic packing model is presented, that tackles the aforementioned issues. The forecasting block of our model, instead of providing point estimates, generates the probability distribution of the predicted capacity and shipment dimensions through the use of the Monte Carlo (MC) dropout technique in Long Short Term Memory (LSTM) and Multi-Layer Perceptron (MLP) network respectively. The stochastic packing block falls into the general category of Knapsack Problems and is solved using the Extreme Point (EP) heuristic within a user-defined confidence level. It uses the generated distributions to select the optimal ULD configuration and palletization strategy, and makes a decision to accept or decline an incoming booking request accordingly. For evaluation purposes, four case studies with real booking data provided by our partner airline are carried out. The results support the validity of the model as well as the efficiency and robustness of the solution method followed.","Air cargo; Forecasting; Stochastic Packing; Uncertainty; Multi-layer Perceptron; Long Short-Term Memory networks; Extreme Points; Heuristics","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:09fcb08c-370d-45b6-b887-8dd8aa908ffd","http://resolver.tudelft.nl/uuid:09fcb08c-370d-45b6-b887-8dd8aa908ffd","Investigating Physics-Informed Neural Networks for solving PDEs","Wasei, E.A.A. (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Numerical Analysis)","Toshniwal, D. (mentor); Heemink, A.W. (graduation committee); Delft University of Technology (degree granting institution)","2020","Physics-Informed Neural Networks (PINNs) are a new class of numerical methods for solving partial differential equations (PDEs) that have been very promising. In this paper, four different implementations will be tested and compared. These include: the original PINN functional with equal weights for the interior and boundary loss, the same functional with custom weights, and the First Order Least Squares (FOSLS) functional with equal weights and custom weights. These custom weights are chosen to be equal to the optimal weights derived by Oosterlee et al. as well as slightly bigger and smaller. These methods will be applied to the 1D stationary advection-diffusion equation where we vary the difficulty by configuring the diffusion parameter epsilon. Furthermore, for each method we have done an elaborate parameter study where we varied epsilon and the number of collocation points. We have found that the weights derived by Oosterlee et al. did not provide accurate results. Instead, equal weights usually performed best. Also, the two functionals turned out to have very similar performance.","numerical methods; machine learning; deep learning; convection-diffusion","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:482c9001-68e5-4b64-a22d-1cc1f5f5c9a2","http://resolver.tudelft.nl/uuid:482c9001-68e5-4b64-a22d-1cc1f5f5c9a2","Schedule Rearrangements in the Autonomous Vehicle Era: An Empirical Study","Debbaghi, Fatima-Zahra (TU Delft Technology, Policy and Management)","Kroesen, M. (mentor); Pudane, B. (mentor); de Vries, G. (graduation committee); Chorus, C.G. (graduation committee); Delft University of Technology (degree granting institution)","2020","Autonomous vehicles are expected to become an inevitable reality in the coming years, as their uncovered benefits are increasingly proven to be positive, such as increased safety and traffic efficiency. However, their impacts on travel choices have often been represented with an assumed reduction in the travel time penalty, which oversimplified AVs' subsequent effects activity-travel scheduling choices. As such, models and assessment methods do not accurately represent travel behavior implications of autonomous vehicles. Thus, using survey data, this thesis identifies possible rearrangements in activity-travel schedules, classifies the respondents into classes with similar profiles of expected rearrangements, and identifies further classification on the basis of socio-economic, personal, and travel characteristics. The survey to be used is one in which respondents were asked to report a full, regular working day activity schedule using their currently preferred mode of transport, then report the schedule as they expect it to be if they could use an autonomous vehicle. The initial exploration of the data identified the occurrence of activities on-board (work, spare-time, meals, and getting ready), changes to the duration of activities outside travel, as well as travel (delay of work-bound trips, and advancement of home-bond trips). Next, we used latent class models to cluster the responses with respect to on-board activity duration changes, stationary activity duration changes, and travel departure time changes. The clustering uncovered types of classes: no change, single activity on-board (work and spare-time), multiple activities on-board. Interactions between stationary and on-board activities were identified, with some direct activity transfer to travel episodes being common (with work, meals, and getting ready), while other activities were generally not transferred (spare-time). Finally, the addition of personal characteristics and demographics highlighted the limited influence of socio-economic factors, with the exception of education, on activity changes. In contrast, the most significant factors were mostly associated with work (daily time pressure and the ability to do work in the car) and travel time duration. An important insight uncovered was that the travel changes were limited and not as dramatic as expected, highlighting that the value of time impacts alone are not as representative as expected.","","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:1a6b5001-d213-40d9-bc2c-5e831eda527d","http://resolver.tudelft.nl/uuid:1a6b5001-d213-40d9-bc2c-5e831eda527d","Geometrically Nonlinear High Fidelity Aerostructural Optimisation for Highly Flexible Wings","Christison Gray, Alasdair (TU Delft Aerospace Engineering)","Veldhuis, L.L.M. (mentor); De Breuker, R. (graduation committee); Martins, Joaquim (graduation committee); Delft University of Technology (degree granting institution)","2020","In the past decade, MDO researchers have developed capabilities to simultaneously optimise the shape and internal structure of aircraft based on coupled high fidelity Computational Fluid Dynamics and Finite Element Analysis. However, to date the finite element methods used for the structural analysis are typically linear and are known to be inaccurate for structures experiencing large deformations, as modern high aspect ratio wings do. To address this challenge, robust and efficient solution strategies for nonlinear structural analysis and coupled aerostructural analysis have been developed for the high-fidelity MACH MDO framework. Structural and aerostructural analyses and optimisations are then performed to investigate the effect of geometrically nonlinear structural phenomena on the results of high-fidelity aerostructural analyses and, consequently, how these changes effect the optimal design of aircraft wings.","MDO; Aeroelasticity; Aeroelastic tailoring; geometrically nonlinear structures","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:6138255e-e243-490f-85fc-24dc72fd40ab","http://resolver.tudelft.nl/uuid:6138255e-e243-490f-85fc-24dc72fd40ab","Impact of Safe Return to Port regulatory framework on cruise ship concept design: A software tool to mitigate design risks in early stages of the process","Valcalda, Alfredo (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Ship Design, Production and Operations)","Kana, A.A. (mentor); Hekkenberg, R.G. (graduation committee); Yang, M. (graduation committee); Jovanova, J. (graduation committee); Delft University of Technology (degree granting institution)","2020","The expansion of the cruise market in the last decades and the significant increase in the size of cruise ships, led to a revision of the safety standards for passenger vessels which resulted in the introduction of the so-called ""Safe Return to Port"" regulatory framework (SRtP). These regulations strongly impacted every aspect of the life of passenger ships, from commissioning to operations. Clearly also the design of these vessels was highly affected, inducing the design companies to face with the risks entailed by SRtP regulations on a daily basis. Indeed these regulations require great complexity of the systems in terms of redundancy and segregation, and their great interdependence further complicate the assessment of the functional capabilities requested by SRtP. The complexity required in the designs and the difficulties in assessing the compliance with the regulations contribute to increase the risks associated with SRtP projects. Obviously design companies are negatively affected by these risks and preventing expensive re-designs in later stages of the process is mandatory to improve the company's performance. Due to the complexity of the task, a support method for the mitigation of the risks entailed by the non compliance of the designs with SRtP regulations is proposed. The method comprises a through analysis of the spaces on board and a software tool to support designers in the assessment of the correct placement of the components of the systems, in order to guarantee the required capabilities in every casualty scenario.","Safe Return to Port; Design risks; Assessment tool","en","master thesis","","","","","","","","","","","","","",""
"uuid:cb9a2652-6382-4dac-8c46-01a86b5d048f","http://resolver.tudelft.nl/uuid:cb9a2652-6382-4dac-8c46-01a86b5d048f","Estimating NOx emissions using S5-P TROPOMI: An adjoint-free 4DVAR approach","Zijlker, Tammo (TU Delft Electrical Engineering, Mathematics and Computer Science)","Heemink, A.W. (mentor); Delft University of Technology (degree granting institution)","2020","This study aims to improve estimates of NOx emission strengths by assimilation of TROPOMI satellite retrievals in the LOTOS-EUROS chemical transport model. Nitrogen oxides (NO and NO2) play a pivotal role in atmospheric chemistry, are an important source of air pollution and contribute to nitrogen deposition over vulnerable natural areas. Therefore, it is paramount to have accurate estimates of emissions. Emissions are parameterised by multiplicative correction factors for NOx emission strengths from existing inventories. Optimal estimates of the correction factors are calculated by assimilation of TROPOMI NO2 retrievals in LOTOS-EUROS. This study proposes an adjoint-free approach to solving the 4DVAR data assimilation problem. Due to the near linearity of LOTOS-EUROS with respect to NO2, an approximate model is proposed that calculates NO2 concentrations from the background state and a linear combination of the influences of the parameters on the state. This approximate model is calculated from an ensemble of LOTOS-EUROS simulations with perturbed parameters. After substitution of the approximate model in the 4DVAR cost function, it is quadratic and the minimum can be calculated directly. For this approximate cost function, the optimal estimate of the parameters and the covariance of this estimation can be obtained with negligible computational costs. Twin experiments, where synthetic satellite observations are assimilated, show that the adjoint-free 4DVAR method is able to accurately minimise the cost function. Errors in estimated parameters are in agreement with the covariance calculated for the estimate. It was also shown that by using domain decomposition, it is possible to generate the approximate model from fewer simulations of LOTOS-EUROS and thereby increasing the computational efficiency of the method. In experiments using TROPOMI NO2 retrievals, the method performs well when modelled plumes align with the retrievals. However, differences between modelled plumes and retrievals, that are resolved by the high resolution of the TROPOMI instrument, may strongly hamper results as the method is only able to correct the intensity of the plumes but not their positions. This leads to an underestimation of NOx emission strengths. Further research is required to handle differences of plume positions in LOTOS-EUROS and TROPOMI retrievals to apply the method to actual TROPOMI retrievals. In addition, more research into domain decomposition may further increase computational efficiency of the method.","TROPOMI; Inverse Modelling; Data Assimilation; LOTOS-EUROS; Emission; NO2; NOx; 4DVAR; Adjoint-based optimization","en","master thesis","","","","","","","","","","","","Applied Mathematics | Computational Science and Engineering","",""
"uuid:14c0323f-dfbb-4d72-82a2-ac240a1ccfc5","http://resolver.tudelft.nl/uuid:14c0323f-dfbb-4d72-82a2-ac240a1ccfc5","Blockchain in Supply Chain Management. An Empirical Study into the Key Factors Influencing the Intention to Adopt Blockchain by SMEs","Lanzini, Filippo (TU Delft Technology, Policy and Management)","Ubacht, J. (mentor); Rezaei, J. (graduation committee); van Wee, G.P. (graduation committee); de Greeff, Joachim (graduation committee); Delft University of Technology (degree granting institution)","2020","Blockchain Technology has gained popularity in recent years and one of its most promising applications is in Supply Chain Management. The visibility enabled by distributed ledger technology can empower Real-Time Tracking of Products (also referred to as the ‘Holy Grail’ of logistics), a faster and leaner Global Trade, and automatic controls with Smart Contracts. However, to realize this potential, all of the members of a supply chain have to be on board, including small-to-medium-sized enterprises (SMEs), which often have neither the resources nor the expertise to join a blockchain-based network. Hence, as part of the Spark! Living Lab, a consortium that comprises TNO and TU Delft among other partners, my research was aimed at providing recommendations on how to support SMEs in the adoption of blockchain. First, a set of twenty-three factors relevant to blockchain adoption intention have been identified through a systematic literature review. Then, an online questionnaire has been employed to collect the factors' preferences of twenty respondents from the target population. The collected data has subsequently been processed with the Bayesian BWM, a novel MCDM method, to establish a weight-wise ranking of the identified factors. Finally, the results obtained have been used to provide suggestions to the Spark! Living Lab on the factors they should put more emphasis on when supporting SMEs in their blockchain journeys.","Blockchain; Adoption; Factors; SMEs; BWM; Bayesian BWM; MCDM; Living Lab","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:8b51cbf0-d335-4430-a72a-a67da98e74d2","http://resolver.tudelft.nl/uuid:8b51cbf0-d335-4430-a72a-a67da98e74d2","Improving and evaluating the methodology for calculating offshoring of emissions","Wiersema, Jeroen (TU Delft Technology, Policy and Management)","Schröder, E. (mentor); Blok, K. (mentor); Delft University of Technology (degree granting institution)","2020","This research aimed to improve the method to calculate offshoring of emissions to understand if developed countries were increasingly offshoring emissions towards developing countries. By offshoring, developed countries can achieve their climate goals without improving their carbon efficiencies. The widely-used method of the balance of emissions embodied in trade (BEET) is not a suitable method to calculate offshoring because it is influenced by differences in technologies between countries. Therefore, it may seem that countries are offshoring emission-intensive industries, while in reality, they are improving their domestic carbon efficiencies. To deal with this issue, previous work adjusted the BEET for technology differences between countries by adjusting for differences in emission intensities based on output. We proposed to use the value-added instead of output to adjust the emission intensities to deal with the issue of double-counting. We used both technology adjustments to calculate the BEET for the years from 2000 to 2014 using a multi-regional input-output analysis with data from the World Input-Output Database 2013 and 2016. Globally, offshoring was not increasing during this period and stabilized at less than 5% of global emissions for both technology adjustments. Furthermore, using linear regression analysis, we did not find a relationship between income and specialization towards emission-intensive industries. This result suggests that developed countries were not displacing emission-intensive industries towards developing countries. Finally, we found that the differences in emission intensities between countries were not only caused by differences in technologies, but also by the heterogeneity of firms aggregated within the same sector. However, with increased sector granularity, this limitation of both technology adjustments decreases. While the value-added adjustment solved the issue of double-counting, it had the limitation that firms differ in their value-capturing ability. Therefore, we concluded that the value-added adjustment was not a significant improvement of the output adjustment.","Emissions; Offshoring; Economics; Sustainabilty; Specialization","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:b77b2b8c-5dec-42fd-8e1a-bb7898984214","http://resolver.tudelft.nl/uuid:b77b2b8c-5dec-42fd-8e1a-bb7898984214","High fidelity simulations of Taylor bubbles in turbulent co-current flow","Karageorgiou, Traianos (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Delft Institute of Applied Mathematics)","Vuik, Cornelis (mentor); Toshniwal, D. (mentor); Heemink, A.W. (graduation committee); Delft University of Technology (degree granting institution); Technical University of Berlin (degree granting institution)","2020","The graduation project was conducted at the CFD department of Nuclear Research And Consultancy Group (NRG) in Petten. The modeling and simulation of Taylor bubble flow using CFD can contribute significantly to the topic of nuclear reactor safety and in particular, in the emergency cooling of nuclear reactors during a loss of coolant accident, or in the U-tubes of a stream generator during a pipe rupture. To achieve an accurate representation of the gas-liquid interface for high values of Reynolds number, a general interfacial turbulence model should be developed which adapts to local conditions automatically. Direct Numerical Simulation (DNS) of relevant large interface two-phase turbulence has the potential to contribute to this, as it can produce more refined insight while being complementary to experimental data. The current graduation project illustrates a simulation approach towards DNS of turbulent co/countercurrent Taylor bubble flow. It comprises a continuation of the novel simulation strategy indicated by (Frederix et al., 2020) in which LES of co-current turbulent Taylor bubble flow using OpenFOAM were indicated and the authors concluded that LES mesh resolution is not sufficient to capture accurately the gas-liquid interface, velocity fluctuations, and bubble disintegration rate. To counter this, in the current work, a Basilisk code is developed which due to its adaptive local grid refinement and its accurate solution of advection equation, comprises a better choice than OpenFOAM for DNS in two-phase flows (via the settings of (Hysing et al., 2009) for laminar bubble flow and (Shemer et al., 2007) for turbulent co-current flow) since it captures sharper the interface and reduces the computational cost significantly. Except for OpenFOAM, Basilisk is also successfully validated against ANSYS (Araujo et al., 2012) for the laminar Taylor bubble flow. Last but not least, the work is further extended to the simulation of laminar and turbulent counter-current Taylor bubble flows in which the effect of the choice of the pipe diameter and the initial bubble length on the bubble’s decay rate is analyzed for the experimental setting of (Mikuz et al., 2019). Overall, despite the lack of fully DNS quality, this study extends the work of (Frederix et al., 2020) and provides further insight into the performance of Basilisk in two-phase flows at a reasonable computational cost. The results and conclusions from the current study may contribute to the development of low-order turbulence models and the validation of more general two-phase modeling strategies.","CFD; Taylor bubble flow; DNS; Multiphase Flow; Basilisk; Nuclear Safety; turbulent flow; simulation; Volume of fluid","en","master thesis","","","","","","","","2021-08-11","","","","Applied Mathematics | COSSE (Computer Simulations for Science and Engineering)","",""
"uuid:b662ebbc-0df0-49ce-8058-98dc660ab105","http://resolver.tudelft.nl/uuid:b662ebbc-0df0-49ce-8058-98dc660ab105","Two hands, one goal: Functional coupling in the wrist joints during a bimanual task","Pries, Rosanne (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Biomechanical Engineering)","Schouten, A.C. (mentor); Mugge, W. (mentor); Dodou, D. (graduation committee); Hellendoorn, J. (graduation committee); Delft University of Technology (degree granting institution)","2020","Bimanual coordination is essential for the performance of daily activities, but the underlying motor control mechanisms are not yet fully understood. The goal of the present study is to identify the contribution of contralateral responses in the wrist joints to the performance of a bimanual task. Contralateral responses could possibly be used in rehabilitation therapy to activate hand functions that are affected by a neuromuscular medical condition. In our experiment, participants had to balance a tray in a virtual environment, while either the left or right hand was perturbed. Two identical robotic wrist manipulators intermittently applied force perturbations in flexion or extension direction. Following a perturbation, contralateral responses were present and operated towards stabilization of the tray, for example by allowing an overall faster correction of the perturbation. Notably, flexion perturbations resulted in much larger contralateral responses than extension perturbations. Contralateral responses occurred mainly in the time window for voluntary responses. Results were consistent with our hypothesis for discrete bimanual movements based on optimal feedback control theory: when both hands share one goal, functional coupling occurs in the wrist joints.","Contralateral response; Bimanual postural control; Common goal task; Robotic wrist manipulators","en","master thesis","","","","","","","","2022-08-11","","","","Biomedical Engineering","",""
"uuid:01e548bb-5416-4eb9-804e-df3654920436","http://resolver.tudelft.nl/uuid:01e548bb-5416-4eb9-804e-df3654920436","Financing the circular economy: The role of financial institutions in “greening” the European Steel Industry","Makrogamvraki, A. (TU Delft Technology, Policy and Management)","Storm, S.T.H. (mentor); Enserink, B. (mentor); Delft University of Technology (degree granting institution)","2020","The notion of a Circular Economy is an integral part of the European Green Deal. The change in legislation within EU, will bring the steel industry, in front of a radical, costly transition of their production processes. In this research, the role of the banking sector in assisting the transition of the steel industry, is examined. Our main objective is to answer: How can the European banking industry be incentivised to assist their basic material clients and specifically the steel industry to move towards CE? To do so, a circular scenario of a steel industry is built based on the case of Tata Steel NL to identify the bottlenecks of this transition. These hypotheses are then used in a series of interviews with selected actors. Based on the empirical information collected in and new insights from these interviews, an empirically-tested classification of the uncertainties in the transition of the European steel industry to a circular-economy model is provided. To cope with these uncertainties, a set of policies is proposed, to address the current open loops in the supply chain, to deal with the uncertainties of the “transition period” until we have mature alter-native technologies, to help in the access of green finance and to strengthen the European market.","","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:6dcc70eb-7e53-4dfe-b6e7-0dece0a4a548","http://resolver.tudelft.nl/uuid:6dcc70eb-7e53-4dfe-b6e7-0dece0a4a548","Using relaxations of sum of squares formulations for the kissing number problem","Rang, J. (TU Delft Electrical Engineering, Mathematics and Computer Science)","de Oliveira Filho, F.M. (mentor); Delft University of Technology (degree granting institution)","2020","In recent years the importance of sum of squares and semidefinte pro-gramming has been seen in the field of combinatorial optimisation. Alllinear programs can be rewritten into a semidefinte one and by usinghierarchies of semidefinite programs these can be solved for polynomialoptimisation problems. Recently, in 2019, A.A. Ahmadi and A. Majumdarreleased a paper called “DSOS and SDSOS Optimization: More TractableAlternatives to Sum of Squares and Semidefinite Optimization”[1] wherethey introduced the concept of sum of square polynomials obtained fromdiagonally dominant matrices. Since this concept is relatively new I amgoing to look at the viability of these sum of square polynomials in olderknown optimisation problems such as the kissing number problem. I willdo this by writing a semidefinite program in which the sum of square poly-nomials are created by diagonally dominant matrices. I will then comparethe newly found upper bounds with the upper bounds found by samplingand the volume bound.","","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:fb875b84-b2b2-47e8-a7cf-4068074ce907","http://resolver.tudelft.nl/uuid:fb875b84-b2b2-47e8-a7cf-4068074ce907","Bayesian estimation in a bidimensional Ornstein-Uhlenbeck process","van der Voort, J.C. (TU Delft Electrical Engineering, Mathematics and Computer Science)","van der Meulen, F.H. (mentor); Delft University of Technology (degree granting institution)","2020","The goal of this thesis is to estimate parameters in a bidimensional Ornstein-Uhlenbeck process, namely a diffusion model which can be found in Favetto and Samson (2010), which considers plasma and interstitium concentrations. We first look at a general linear stochastic differential equation and some properties. Then we simulate possible paths and observations based on the diffusion model, and derive the underlying state space model. We consider state estimation, where we use the Kalman filter and smoother algorithm. It turns out that the smoother outperforms the Kalman filter. Next, we apply and derive the Liu and West filter for state estimation. We see that the performance for the Liu and West filter is close to the Kalman filter. Furthermore, we look at the parameter estimation. We again use and derive the Liu and West filter, but now for parameter estimation. We first apply this filter to a linear AR(1) model, which gives good results. Then we start with estimating one parameter in the diffusion model and finally we estimate all 7 parameters in the model, using priors concentrated around the true value and 10.000 particles. For one parameter, we obtain good results. For all 7 parameters, results are satisfactory, with for fully observed data better results than for partially observed data. We also look at the influence of the number of particles: for 5.000 particles estimation results are somewhat worse than for 10.000 particles. Furthermore, we change some priors such that they are no longer concentrated around the true value. From this, we see that the Liu and West filter does not seem to perform as well for certain choices of priors. Next, we look at state and parameter estimation in a non-linear AR(1) model using the Liu and West filter, which gives rather good results. Finally, we apply the Liu and West filter once more, but now with a real data set. In this case we are able to obtain parameter values that provide a reasonable estimate for the sum of the concentrations, but for the interstitium concentration it leaves much uncertainty.","statistics; particle filter; Bayesian; Kalman filter; state estimation; parameter estimation","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:bc879c32-2ef9-4150-b43f-9b4ce3fc1c6e","http://resolver.tudelft.nl/uuid:bc879c32-2ef9-4150-b43f-9b4ce3fc1c6e","Managing complexity of Digital Twin models: Development of NewMODE as a network theory approach to model decomposition","Crowley, L. (TU Delft Technology, Policy and Management)","Warnier, M.E. (graduation committee); Huang, Y. (mentor); Kwakkel, J.H. (mentor); Lazovik, Elena (mentor); Pileggi, Paolo (mentor); Verriet, Jacques (mentor); Delft University of Technology (degree granting institution)","2020","Modelling and simulation is at the heart of Digital Twin technology, which is revolutionising many industries. Organisations have access to legacy models that are too complex to maintain, preventing them from operationalising complex systems like Digital Twin. By creating an automated tool for model decomposition, it is possible to breathe life into complex models by extracting their embedded functionality as managable components. This thesis presents NewMODE as a network theory approach to model decomposition; a novel methodology that aims to automate the tedious task of model decomposition. Important contributions include the network theory metamodel specification, the decomposition criteria and the adaption of the Girvan Newman algorithm to identify components of the model. NewMODE has been implemented for models in developed in LSAT (Logistics Specification and Analysis Tool). In partnership with TNO and their Embedded Systems Innovation (ESI) group, NewMODE has been evaluated quantitatively and qualitatively with promising results to aid model developers in model decomposition.","Digital Twin; decomposition; directed acyclic graph; model development; system modelling; simulation model","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:6be8ea7b-2a87-45d9-aaa8-c82ff28d56c2","http://resolver.tudelft.nl/uuid:6be8ea7b-2a87-45d9-aaa8-c82ff28d56c2","Machine Learning with Care: Introducing a Machine Learning Project Method","Hoozemans, Steven (TU Delft Technology, Policy and Management)","Bharosa, N. (graduation committee); Janssen, M.F.W.H.A. (mentor); Warnier, Martijn (graduation committee); Groenveld, B. (graduation committee); Delft University of Technology (degree granting institution)","2020","Worldwide, machine learning is increasingly used to achieve optimal analytics and outcomes in business and governmental organisations. However, it has become evident that structural guidance for creating machine learning projects is needed. Machine learning projects are dependent on multiple factors. This thesis focuses on three factors influencing machine learning projects: the technical aspects of machine learning, the organisational aspects of successful implementation of machine learning projects and last the ethical aspects, since difficulties coming with meeting ethical standards contribute to the suboptimal use of machine learning projects. The research was done in accordance with Design Science Research Methodology (DSRM). Ten steps to setup machine learning projects were identified and a method has been designed, demonstrated and evaluated. The research included an extensive literature search which provided the main contributing theories of Knowledge Discovery in Databases and Ethical Impact Assessment. Furthermore, multiple experiments in Standard Business Reporting (SBR) context were done. Expert interviews provided input for optimisation and evaluation. In this thesis a method for setting up creating machine learning projects, including ten steps with accompanying sub steps, was created. A single method combining and integrating technical, ethical and organisational aspects was not yet available. At this moment, it is unique in comparison to other methods, as it combines interdisciplinary aspects into one method and provides guidance for management and engineers. Apart from the developed method, this thesis also provides structured insights in the use of machine learning in SBR context.","Machine Learning; ethics; Standard Business Reporting; Machine Learning Project Method; Strategy Map","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:2e83b73f-a078-40fe-9862-7156dc263d47","http://resolver.tudelft.nl/uuid:2e83b73f-a078-40fe-9862-7156dc263d47","Using Game Theory to analyse the diffusion of shore power","van der Meer, David (TU Delft Technology, Policy and Management)","Stikkelman, R.M. (mentor); van Duin, Ron (mentor); Roeser, S. (mentor); Delft University of Technology (degree granting institution)","2020","This research investigates the diffusion of Shore Power in ports. Shipping Companies and ports are dependend on the strategies of each other. Using Game Theory and Agent Based Modelling, the network and parties are simulated.","","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:91424510-f76d-485c-b54c-c8ce9ef107c4","http://resolver.tudelft.nl/uuid:91424510-f76d-485c-b54c-c8ce9ef107c4","The Dynamics of Open Science Adoption: A Choice Modelling-Based Approach","de Graaf, Maarten (TU Delft Technology, Policy and Management)","Kwakkel, J.H. (mentor); Zuiderwijk-van Eijk, A.M.G. (mentor); Delft University of Technology (degree granting institution)","2020","As open science has attracted attention within the academic world, the potential for innovative ways of information sharing offers multiple benefits, such as increased opportunities for collaboration an enhanced research transparency (Forrester, 2015). However, a transition from traditional science to the realm of open science requires vast infrastructural changes, as well as a widespread adoption by researchers themselves. It has been found the latter is not intrinsically omnipresent throughout academics from various disciplines. Throughout literature, qualitative typologies comparing the drivers and inhibitors of open science are widely available. Nonetheless, quantitative, comparative research to distinguish their relative importance remains highly underrepresented in open science publications. Therefore, the purpose of this study is to investigate and rank the barriers academics face with regard of adopting an open science perspective, whilst assessing fruitful incentives as well. In order to do so, this study will employ a choice modelling approach of quantitative nature. That is, rather than descriptive, qualitative results, this study yields the relative importance of factors relevant to open science principle adoption. Furthermore, it is expected this typology will serve as a framework for academic bodies considering the implementation of open science.","Open Science; Choice modelling; Open Data; Open Access","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:433d4c00-e063-4614-9c78-2849870d8d7f","http://resolver.tudelft.nl/uuid:433d4c00-e063-4614-9c78-2849870d8d7f","Simulation of Two-Dimensional Steady State Boundary Layers Applied to Nonideal Gas Flows","Dijkshoorn, Dominic (TU Delft Mechanical, Maritime and Materials Engineering)","Head, A.J. (mentor); de Servi, C.M. (graduation committee); Pecnik, R. (graduation committee); Boersma, B.J. (graduation committee); Delft University of Technology (degree granting institution)","2020","class=""MsoNoSpacing"">Organic Rankine Cycle (ORC) Power Plants can be of greatimportance in the energy transition as they are suitable for converting wasteheat to power and can utilize renewable energy for their operation. To improvethe efficiency of ORC Power Plants, the physical phenomena inside thesemachines must be understood. Understanding the boundary layer of complexorganic fluid flows in these systems is crucial, as it is estimated to beresponsible for one-third of the losses in turbomachinery. n this thesis, two-dimensional steady state boundarylayer flows of nonideal gas have been investigated numerically. The objectivewas to find the influence of complex fluid nonideality, characterized by idealgas departure, on boundary layer flows. In particular, a high-speed densevapour expansion of organic fluid Hexamethyldisiloxane (MM) inside a de Lavalnozzle test section has been studied. The nozzle is part of a measurementcampaign to collect experimental data with the purpose of validation andcalibration of Non-Ideal Compressible Fluid Dynamics (NICFD) software.  MATLAB program was developed for solving thetwo-dimensional steady state boundary layer equations including generalthermophysical properties. Transition prediction methods, the algebraicCebeci-Smith turbulence model (CS-model), and state-of-the-art thermophysicalmodels were implemented. The program was verified and validated for air withliterature. The turbulence model was validated with experimental data oflarge-scale zero pressure gradient adiabatic flows. The results match for theentire Mach-number range from 0.2 up to 2.8. The program also proved to becapable of predicting the turbulent boundary layer along a flat wall inside ade Laval nozzle expanding air. Deterministic simulations of the boundary layer along thecurved wall surface of the aforementioned nozzle expanding MM were performed.The results showed a larger decrease in the newly defined property <i>C</i><sub style="""">e</sub> inthe core flow along expansion compared to air. In contrast, the propertygradients; namely density ratio <i>c </i>and Chapman-Rubesin parameter <i>C</i>,inside the boundary layer were found to be negligible. Furthermore, the resultsshow that the influence of the pressure history upstream of the nozzle throatis relatively small or even negligible in the diverging nozzle section. Theboundary layer displacement thickness for both laminar and turbulent flow wasfound to be negligible compared to the nozzle cross section, which results in anegligible effect on the nozzle core flow. The program needs further validation for flows departingfrom ideal gas. First, the flow condition in de Laval nozzles, laminar orturbulent, needs to be obtained by conducting experiments. Then, sensitivitystudies need to prove if the inviscid nozzle design is a robust design forviscous flows too; namely, being insensitive to changes in total inputconditions, uncertainties in closure coefficients, and variations in upstreampressure history.","compressible; incompressible; Laminar-turbulent transition; laminar; turbulent boundary layer; ideal gas; nonideal gas; vapour flows; NICFD; ORC; Thermodynamics; Boundary Layer; Boundary Layers; eddy viscosity; turbulent prandtl-number; eddy conductivity; algebraic turbulence model; turbulence modelling; ideal gas departure","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Energy, Flow and Process Technology","",""
"uuid:bbc1f51a-9406-49c5-a235-7eac90270bb8","http://resolver.tudelft.nl/uuid:bbc1f51a-9406-49c5-a235-7eac90270bb8","A review of Reverse Innovation: From bibliometric analysis to a conceptual framework and future research directions","Tijhof, B.R. (TU Delft Technology, Policy and Management)","van Beers, C.P. (mentor); Roosenboom-Kwee, Z. (mentor); Sand, M. (mentor); Delft University of Technology (degree granting institution)","2020","This study reviews Reverse Innovation (RI) literature by analysing the conceptual, intellectual and social structure of the field. Furthermore, it proposes a comprehensive view of the structural associations amongst RI influencing factors, drivers, antecedents and practices. Bibliometrix R-package and VOSViewer software were used to conduct a bibliometric meta-analysis on 208 articles, obtained from ISI Web of Science and Scopus databases. Influential journals, institutions, scholars and trending articles in RI research were revealed. Concept co-occurrence identified three main sub-fields (a) Conceptual development of RI, (b) Sustainable Dimension of RI, (c) RI for healthcare. Through content analysis of these sub-fields, conceptual conflicts were identified and solved. Based on this content analysis a conceptual framework was proposed which has structured influencing factors and relations to the RI process.","Reverse Innovation; Bibliometrics analysis; Innovation diffusion; Innovation management; Conceptual development; innovation; strategic","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:f1923c90-2385-4b4e-a42d-440bc692adbc","http://resolver.tudelft.nl/uuid:f1923c90-2385-4b4e-a42d-440bc692adbc","Validating and comparing frequency-domain electromagnetic database inversion for top layer estimation","Tatar, Hamza (TU Delft Civil Engineering and Geosciences)","Slob, E.C. (mentor); Delft University of Technology (degree granting institution)","2020","Clay has been used for many hundreds of years in building dikes. Their physical properties and thickness are essential for a dike to maintain its function. For the last fifteen years electromagnetic induction instruments (EMI) have been playing a growing role in mapping electromagnetic soil properties. Layered models with sharp boundaries between different soil units represents the soil profile accurately. Therefore, two database inversion procedures are developed and proposed. Synthetic data sets and field measurements have been used to validate and compare our retrieved electrical conductivity/resistivity models. Field measurements of a so-called multi-receiver EMI instruement (CMD-Explorer and CMD-MiniExplorer) have been used to perform the database inversion on, and are being compared to ERT data and hand drill data. The EMI instruments (CMD-Explorer and CMD-MiniExplorer) consisting of three receiving antennas, fixed operating frequency and two measurement configurations will not allow us more information than of a estimate three-layered model. Therefore, the calibration process here proposed is based on finding the best fit of the electromagnetic responses (in the least squares sense) in a 5-D solution space created by calculating the electromagnetic responses using five medium parameters and the layered earth response. These medium parameters are the three layered conductivity’s and thicknesses of the first two layers. Using these five medium parameters, a database is built based on predefined ranges of medium parameters and is being used to perform the inversion procedure with. Two methods of inversion have been proposed: constrained and full database inversion. The synthetic models have been recovered with an average data misfit of 0.0096 and 0.0032 for the constrained data base inversion for respectively model 1 and model 2. For the full database inversion data misfit values of 0.00316 and 0.0021 were accomplished. Comparing ERT and electrical resistivity obtained from EMI measurements, one could see that the trend and first two layer thicknesses were recovered. Verifying EMI measurements using hand drill data, we were able to recover the top layer at few locations.","","en","master thesis","","","","","","","","","","","","Applied Geophysics | IDEA League","",""
"uuid:38ff4e9a-222a-4987-998c-ac9d87880907","http://resolver.tudelft.nl/uuid:38ff4e9a-222a-4987-998c-ac9d87880907","Studying the Machine Learning Lifecycle and Improving Code Quality of Machine Learning Applications","Haakman, M.P.A. (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Deursen, A. (mentor); Finavaro Aniche, M. (graduation committee); Liem, C.C.S. (graduation committee); Miranda da Cruz, L. (graduation committee); Delft University of Technology (degree granting institution)","2020","As organizations start to adopt machine learning in critical business scenarios, the development processes change and the reliability of the applications becomes more important. To investigate these changes and improve the reliability of those applications, we conducted two studies in this thesis. The first study aims to understand the evolution of the processes by which machine learning applications are developed and how state-of-the-art lifecycle models fit the current needs of the fintech industry. Therefore, we conducted a case study with seventeen machine learning practitioners at the fintech company ING. The results indicate that the existing lifecycle models CRISP-DM and TDSP largely reflect the current development processes of machine learning applications, but there are crucial steps missing, including a feasibility study, documentation, model evaluation, and model monitoring. Our second study aims to reduce bugs and improve the code quality of machine learning applications. We developed a static code analysis tool consisting of six checkers to find probable bugs and enforcing best practices, specifically in Python code used for processing large amounts of data and modeling in the machine learning lifecycle. The evaluation of the tool using 1000 collected notebooks from Kaggle shows that static code analysis can detect and thus help prevent probable bugs in data science code. Our work shows that the real challenges of applying machine learning go much beyond sophisticated learning algorithms -- more focus is needed on the entire lifecycle.","Machine Learning Lifecycle; FinTech; Static Code Analysis","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:e99150f3-b009-4bf1-b487-f02016d7ec87","http://resolver.tudelft.nl/uuid:e99150f3-b009-4bf1-b487-f02016d7ec87","Facilitating Application Identification for 3D Printing in Manufacturing Environments: In pursuit of new 3D printing applications: a bottom-up approach","Deurvorst, C.E. (TU Delft Industrial Design Engineering)","Doubrovski, E.L. (mentor); Pasman, G.J. (mentor); Delft University of Technology (degree granting institution)","2020","The use of 3D printing technology in manufacturing environments has experienced rapid growth. Manufacturers have realised the potential of the technology. 3D printing enables the reduction of costs and lead-times of parts, components and tools used in production processes. Adoption of this technology is facing various challenges. A major challenge is the identification of suitable parts for Additive Manufacturing technology. Assessing a part’s suitability for 3D printing requires a substantial amount of knowledge of 3D printing technology. Within manufacturing and production environments, a limited group of people is trained to do understand the technology. It is expected that the frequency and quality of applications will increase the value that will be added by 3D printing. This development will be driven by the capability to identify new applications. The more stakeholders are educated in this field and understand the technology, the more opportunities will be identified. Given the above, this objective of this research project is to investigate how production line operators can be more actively involved in the initial stages of the 3D printing workflow. Through extensive literature and contextual research, the potential to enable production line operators to identify parts and problems in their section of the facility has been exposed. Various influential opportunities and challenges in their participation have been established. After a round of internal validation of the research insights, a strategic decision was made to focus design efforts on developing a digital platform. The objective of this platform is to enable operators to participate in the relevant steps of the 3D printing workflow. Through an iterative process, an Application Portal has been designed. This portal is a mobile application that supports production line operators in submitting new ideas. In addition to the above, the system offers the following functions: <br/>1.Active collaboration between stakeholders <br/>2.Exchange of project developments insights <br/>3.Validation of application suitability A prototype is developed in Axure. This software is used to validate the concepts with a variety of manufacturing clients, operators and 3D print experts. The applicability of the concept has been validated for a majority of clients. These results illustrate that the solution offers significant value to achieve active participation. Additional design goals have been achieved to a great extent. The application portal provides operators with a tool to express their ideas. They can actively participate in innovation and take ownership of the applications they have identified themselves. Additionally, the platform offers Ultimaker and its manufacturing clients an opportunity to gather relevant data to work towards a future of automated part identification. Inevitably, the prototype has its limitations. However, this study represents a step forward in the acceleration towards accessible part identification by novice users in manufacturing environments.","3d printing; Manufacturing; User Centered Design; Additive manufacturing; accessibility; Bottom-Up","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:bb2314c8-9bf8-4141-bc3d-050a784b65ca","http://resolver.tudelft.nl/uuid:bb2314c8-9bf8-4141-bc3d-050a784b65ca","Finding a balance between meaningful and useful participation by improving information provision: Assessing the effectiveness of information provision approaches in participatory value evaluation on empowering participants to give informed input on urban climate adaptation projects","Nouws, Sem (TU Delft Technology, Policy and Management)","Doorn, N. (graduation committee); Timmermans, Jos (graduation committee); Mouter, N. (graduation committee); Itten, A.V. (graduation committee); Delft University of Technology (degree granting institution)","2020","Participatory Value Evaluation (PVE) is a webtool-based participation method that is used to increase participation by others than the usual suspects. In PVE, respondents are asked to allocate a budget or points to a portfolio of projects that reflect real policy options, therewith evaluating the projects by stating their preferences. However, the provision of information in PVE on complex subjects such as urban climate adaptation still is characterized by some problems such as susceptibility by framing, misinterpretation and self-selection. In other words, information provision often does not comply with wishes and needs of participants. In this research, two information provision approaches are tested in PVE in an information manipulation experiment. From the research both quantitative as qualitative results are obtained, analysed by using a mixed methods approach. It is observed that the tested information provision approaches do not affect the choices made in PVE or participants’ feeling of empowerment. Moreover, it appears that the wishes and needs for information in PVE vary widely between participants. It is concluded that this heterogeneity should be the starting point in designing information provision. Deliberative participation and progressive disclosure of information are ways to accomplish this. It is recommended to apply these approaches in PVE in future research.","Participatory Value Evaluation; Public Participation; information provision; mixed methods","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:1cb58aa2-22f6-49d9-afdb-d7f19c9f23ea","http://resolver.tudelft.nl/uuid:1cb58aa2-22f6-49d9-afdb-d7f19c9f23ea","Seismological characterization of the Theistareykir geothermal field (Iceland)","Naranjo Hernandez, David (TU Delft Civil Engineering and Geosciences)","Jousset, Philippe (mentor); Toledo, Tania (mentor); Erbas, Kemal (mentor); Maurer, Hansruedi (mentor); Delft University of Technology (degree granting institution); ETH Zürich (degree granting institution); RWTH Aachen University (degree granting institution)","2020","In 2017 the National Power Company in Iceland, Landsvirkjun, started the operation of a geother- mal power plant in Theistareykir (Northeastern Iceland). The plant’s operation requires extraction, circulation, and injection of the geothermal fluids to produce energy. These processes depend on the existing fracture network of the reservoir. Therefore, geothermal energy exploitation requires knowledge of underground structures to identify potential fluid flow pathways. These are, in many cases, evidenced by the local seismicity. In this context, the GFZ German Research Center for Geo- sciences and Landsvirkjun chose this site for deploying a dense network of fifteen seismic broadband stations to monitor and characterize the field’s seismicity. The data coming from this very dense network allows us to implement and test an optimized processing scheme to perform a detailed analysis of the local seismicity. This study’s primary goal is to implement an efficient and reliable scheme to characterize the local seismicity of the Theistareykir geothermal field using the collected high-resolution seismic data from the dense network. I used several traditional earthquake seismology methods to detect, analyze, classify, and localize, repeating microseismic events. I first used a recursive STA/LTA algorithm to detect the local seismicity between January 1, 2018, until June 30, 2018. Using the detections, I manually reviewed and picked P- and S-phase arrival times. After an initial non- linear localization, I performed a correlation clustering analysis and identified two events with a high degree of waveform similarity. I corrected the picked phase arrivals using the cross-correlation coefficients of the events to a master trace. These events were relocated to improve their relative locations. Events of both clusters will be used in future studies for template-matching to detect and pick additional events within this period. The methodology applied here is meant as a guide to process upcoming seismic data of the geothermal field and efficiently perform a full seismological characterization using more massive data-sets.","Geothermal system; Microseismicity analysis; Iceland; Seismic data processing; Waveform analysis; Cross-correlation analysis; Clustering","en","master thesis","","","","","","","","2021-03-25","","","","Applied Geophysics | IDEA League","MicroGraviMoTiS project",""
"uuid:998b7bea-1ec2-492e-9a3b-94b878bf0dab","http://resolver.tudelft.nl/uuid:998b7bea-1ec2-492e-9a3b-94b878bf0dab","Extracting geomechanical information from borehole microseismic data with machine learning","Carrizo Mascarell, Maria (TU Delft Civil Engineering and Geosciences)","Drijkoningen, G.G. (mentor); Rovetta, Diego (graduation committee); Delft University of Technology (degree granting institution); RWTH Aachen University (degree granting institution); ETH Zürich (degree granting institution)","2020","A key practice in the development of unconventional hydrocarbon resources is to monitor hydraulic fracturing operations and analyze in detail the induced microseismicity, for understanding the extent of the volume affected by the fractures. Even though microseismic data are one of the few geophysical measurements that can be used for this purpose they are not always used at their full potential: the common analyses are limited to the interpretation of the locations of the induced seismic events in terms of fractured volume, while the propagation and the dynamic evolution of the microseismic events that are directly related to the source process are not studied. The source moment tensor can be used to describe the deformation mechanism occurring at the seismic source and the corresponding geomechanical parameters, which are relevant aspects for the monitoring of hydraulic fracturing operations. Its value can be estimated through an inversion process using the P-wave and S-wave waveforms from the observations at the seismic receivers. However, the limited aperture of the receiver arrays in borehole acquisition is inadequate to solve the inverse problem. The goal of this thesis project is study the feasibility of estimating the source moment tensor with borehole microseismic data making use of machine learning algorithms. The task is done by implementing a forward model to compute waveforms generated by known values of the source moment tensor in a borehole acquisition geometry (forward problem). Forward modeling was carried out using a modied version of the discrete wavenumber method. Afterwards, this data is used to train a neural network to estimate the moment tensor at the source given the microseismic data (inverse problem). The neural network was designed, adapting an existing architecture used in previous studies to solve similar inverse problems. The implementation was done entirely in the Python programming language, using the Tensorflow library for the machine learning parts. The network was trained with the dataset generated in the forward model until reaching an optimal mean squared error minimum. Finally, the capability of the network to invert microseismic measurements and retrieve acceptable values of the source moment-tensor components was tested using synthetic data, resulting in an average prediction accuracy of 0.997. Our results indicate that for this case, a neural network is able to satisfactory invert for the full moment-tensor components. Additionally, the neural network was also trained to handle the presence of Gaussian noise, achieving an average prediction accuracy of 0.990 for tested synthetic data with 10% Gaussian noise.","machine learning; moment tensor inversion; borehole microseismic; microseismic monitoring","en","master thesis","","","","","","","","","","","","Applied Geophysics | IDEA League","",""
"uuid:cbe79b05-69f4-418a-a570-a01b57f495dc","http://resolver.tudelft.nl/uuid:cbe79b05-69f4-418a-a570-a01b57f495dc","Het voorspellen van de verspreiding van het COVID-19 in Nederland aan de hand van het Ensemble Kalman Filter","Fick, I.S.A. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Heemink, A.W. (mentor); van Iersel, L.J.J. (graduation committee); Delft University of Technology (degree granting institution)","2020","Al ruim een half jaar houdt het de hele wereld in zijn greep: het Corona virus. Waar we dachten dat het allemaal begon als een onschuldige griep, werd al snel duidelijk dat er meer aan de hand was. Wuhan kampte al een tijdje met dit onbekende virus en op 23 januari 2020 werd het zelfs zo serieus dat de Chineese overheid een lockdown afkondigde voor Wuhan en andere steden in de provincie Hubei. Winkels, openbare plekken en -vervoersmiddelen werden gesloten, kinderen zouden vanuit huis geschoold gaan worden en waar mogelijk werd opgedragen thuis te werken. Zoiets hadden we nog nooit meegemaakt.Toch leek dit voor menig Nederlander één grote ver-van-mijn-bed-show, tot het nieuws ons bereikte dat ook in Italië besmettingsgevallen van het COVID-19virus werden geconstateerd. Langzaam maar zeker kroop het virus verder naar ons kikkerlandje en op 23 maart 2020 was ook in Nederland het virus zo serieus aanwezig dat een lockdown werd aangekondigd. Nu, zo’n 4 maanden verder, weten we niet meer beter. Iedereen is in bezit van één of meerdere mondkapjes, op het verplichte gebruik van een winkelkar in de supermarkten wordt niet meer gemopperd en anderhalve-meter-samenleving maakt grote kans om de Woord van het Jaar-verkiezing 2020 te winnen.Toch blijft iedereen het spannend vinden hoe deze crisis zal aflopen. De voortgang van en nieuwe informatie over het virus zijn al tijden hot topic op social media en bijna dagelijks verschijnen er nieuwe wiskundige modellen met aanvullende informatie in de krant. Deze modellen geven ontzettend veel informatie over onder andere de verspreiding en het verloop van het Corona virus. In dit verslag bekijken we met statistische methoden hoe we ziektes kunnen voorspellen. Daarnaast gebruiken we een methode om voorspellingen met data te combineren. Dankzij het RIVM zijn er veel gegevens over de huidige Corona situatie beschikbaar. We gebruiken deze data om het verloop van het virus te modelleren, rekening houdend met een modelfout en een meetfout. Hiermee brengen we in kaart hoe het virus zich de afgelopen tijd heeft gedragen en wat we in de toekomst kunnen verwachten van een vergelijkbare ziekte. Alle berekeningen en plots die zijn gebruikt, zijn gemaakt in Rstudio, een statistisch computerprogramma.","","nl","bachelor thesis","","","","","","","","","","","","","",""
"uuid:3fd09cd7-f66c-43e9-ae85-367fe30d31fb","http://resolver.tudelft.nl/uuid:3fd09cd7-f66c-43e9-ae85-367fe30d31fb","The Feasibility of Using Jarosite Waste From the Zinc Industry for HIsarna Ironmaking","Sivaraj, R. (TU Delft Mechanical, Maritime and Materials Engineering)","Yang, Y. (mentor); Kerry, T.J. (graduation committee); Delft University of Technology (degree granting institution)","2020","Jarosites are an Fe-rich waste product from the Zn industry. They contain toxic heavy metals like Pb, Zn, Cu, Ni, and are consequently disposed of in regulated ponds. With Zn demand projected to continually increase in the future, it is anticipated that by 2023, the Fe content in these jarosites will amount to 2.2 million tonnes/year. With the advent of the circular economy and raw materials scarcity it has become imperative that ’wastes’, like jarosite, are converted to resources. Since jarosites are Fe-rich, they can be used for ironmaking. HIsarna is a revolutionary ironmaking process that has greater flexibility in the raw materials it uses. It can potentially utilise jarosite, which was unsuitable for a conventional blast furnace, to make hot metal. However, steelmaking, which occurs downstream of HIsarna ironmaking, requires the removal of Cu, Ni, Cr, Sn and Mo (termed CEF metals). Removal of these CEF metals, particularly Cu, from jarosite whilst fixing sulfur is necessary before it is acceptable for HIsarna. This thesis evaluated several metallurgical approaches in removing the CEF metals from a locally sourced jarosite whilst fixing sulfur. The jarosite was sourced from Nyrstar (Budel, Netherlands) and is commercially known as Budel Leach Product (BLP). The BLP had a CEF concentration of 1.8 wt% which was substantially higher than the HIsarna limit (0.2 wt%); it also had a sulfur content of 9.3 wt%. The metallurgical approaches taken to treat the BLP included: hydrometallurigcal (acid, alkaline. ammoniacal and DES leaching); pyrometallurigcal (thermal decomposition and chloridisation); and a combined pyro- and hydrometallurgical approach (sulfur fixation with Na2CO3 with water washing). Ammoniacal leaching was the most effective hydrometallurgical approach in selectively removing Cu from the BLP, however, leaching efficiencies were low. Thermal decomposition resulted in an upconcentration of the CEF metals whilst releasing SO2 . Sulfur could be fixed with the combined approach, however, the presence of Na2CO3 converted any soluble CEF metal sulfates to insoluble oxides which increased CEF concentration. The most effective approach was the chloridisation of BLP which reduced the CEF concentration in the treated residue while fixing sulfur. Although the CEF concentration using the chloridisation approach (0.84wt%) was above the HIsarna limits, further refinement of the treatment strategy shows promise for utilising BLP in HIsarna ironmaking.","Jarosite; HIsarna; Ironmaking","en","master thesis","","","","","","","","","","","","","P91383",""
"uuid:6a7f1da8-88bd-44a4-9ef2-e9e7903e832f","http://resolver.tudelft.nl/uuid:6a7f1da8-88bd-44a4-9ef2-e9e7903e832f","Discrete state-space active inference and unknown controlled state transitions","van Roessel, L. (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Cognitive Robotics; TU Delft Biomechanical Engineering)","Wisse, M. (mentor); Anil Meera, A. (graduation committee); Kober, J. (graduation committee); Delft University of Technology (degree granting institution)","2020","Active inference is a process theory arising from neuroscience which casts perception, action, planning and learning under one optimisation criterion: minimisation of free energy. Current literature on the implementation of discrete state-space active inference focuses on scalability, the comparison to reinforcement learning and its performance to learn the state-observation mapping of the environment. In these implementations, active inference is supplied with accurate predefined information (knowledge) about the transition dynamics (controlled state transitions) of the environment. However, it is likely that in practical settings, knowledge gaps about controlled state transitions are involved. This thesis analyses the influence of knowledge gaps about controlled state transition on the active inference process. First, we provide a comprehensive overview of active inference and related principles. Secondly, we expand current active inference formulations with the power to actively evaluate the consequences of actions in their ability to resolve transition knowledge gaps. Thirdly, we analyse the behaviour of this expanded version of active inference once concerned with uncertain transition knowledge in a pure explorative setting (no task set). We found that active inference can deal with minor transition uncertainty, however, fails to operate when no initial transition knowledge is supplied due to a failing parameter updating mechanism. After proposing an alternative parameter updating mechanism, we found that active inference can deal with total uncertainty. Finally, we analysed the performance of active inference (with alternative parameter updating mechanism) to reach goals, starting without knowledge about transitions. We found that the resulting behaviour is a trade-off between exploration and exploitation and that the active inference agent gains transition knowledge while reaching the goals. In short, by investigating the influence of knowledge gaps in controlled state transitions, we aim to bring discrete state-space active inference one step closer to practical applications.","Active Inference; Free Energy Principle; Generative Model; Grid world; Epistemic value; Exploration; Exploitation; Transition Uncertainty; Active Learning; Transition Novelty","en","master thesis","","","","","","","","","","","","Mechanical Engineering","",""
"uuid:8e4ca59e-19e6-4e80-b456-63c99732395e","http://resolver.tudelft.nl/uuid:8e4ca59e-19e6-4e80-b456-63c99732395e","Passive Autonomy: Hygromorphic Rotational Actuators: Design &amp; Evaluation","Joosten, Sebastiaan (TU Delft Mechanical, Maritime and Materials Engineering)","Radaelli, G. (mentor); Vallery, H. (mentor); Delft University of Technology (degree granting institution)","2020","Inspired by phenomena in the plant world, a<br/>meteoro-sensitive rotational actuator is developed. The design<br/>uses a hygro-active shell, whose water-based swelling is restricted<br/>at selective locations to form a helicoid structure. The influence<br/>of geometrical parameters on the performance is investigated<br/>using a numerical analysis of various geometries, by looking at<br/>resulting rotation and torque during this rotation. Prototypes<br/>are built of five key geometries in the design space, to validate<br/>the simulations and to investigate the real-life behaviour<br/>of the design. These prototypes are submerged in water to<br/>investigate their deformation, after which they are placed in<br/>a torsion machine to investigate the torque during rotation.<br/>The experiments result in similar rotations and torques as the<br/>simulations. The designed Hygromorphic Rotational Actuator is<br/>capable of passively rotating its own structure, thereby expanding<br/>the possibilities of engineers and designers when designing passive<br/>autonomous systems.","Hygromorphing; Compliant Shell Mechanisms; multi-stable; zero-moment; Adaptive structures; actuator","en","master thesis","","","","","","","","2022-08-31","","","","","",""
"uuid:c0532ddc-e5b6-40dc-aff3-771bbcc7545d","http://resolver.tudelft.nl/uuid:c0532ddc-e5b6-40dc-aff3-771bbcc7545d","Feature extraction of GPR data for the classification of reflectors in reinforced concrete","Gierens, Lena (TU Delft Civil Engineering and Geosciences)","Niederleithinger, Ernst (mentor); Schmelzbach, Cedric (graduation committee); Delft University of Technology (degree granting institution); ETH Zürich (degree granting institution); RWTH Aachen University (degree granting institution)","2020","During their service live reinforced and prestressed concrete structures experience deterioration. Therefore, to effectively assure the safety and durability of the compounds, non destructive testing methods, such as Ground Penetrating Radar, employed at high frequencies, provide a rapid assessment of the geometry of the compound. Although amplitude and traveltime evaluations are the most widely used techniques, attribute based analysis to enhance the interpretation quality has gained interest in recent years. A great quantity of surveys exist that attempt to determine the diameter of cylindrical targets such as reinforcement bars or tendon ducts. Indeed, the affiliation of a reflector to one of the two groups is still a challenging task. Therefore, different attribute approaches are applied to four data sets with high spatial sampling rates collected under controlled conditions, to derive features that unambiguously assign the considered reflection hyperbolas to either reinforcement bars or tendon ducts. For this purpose, B-scans are reduced to the individual reflectors by manual selecting the desired windows. Then, attributes are applied to the hyperbolas and the results are compared with each other to derive features describing the two reflector types. For attributes where features can be extracted, they are tested for measurements with relatively low spatial sampling rates and for one on-site data set. It is shown that the analysis provides sufficient classifications for six out of the nine tested attributes when data with high spatial sampling rates under controlled environment conditions are considered. In contrast, relatively low spatial sampling rates yield to accurate results for only three attributes: The maximum absolute amplitude, the cumulative energy and the amplitude at the apex. Although promising results for low spatial sampling rates are obtained, the application to on-site data is still complicated. Nevertheless, this study provides the basis for automated reflector classification.","GPR; Non destructive testing; NDT; Attribute Analysis; Feature extraction; Reinforced concrete; Prestressed concrete; Rebar; Tendon duct; Classification","en","master thesis","","","","","","","","","","","","Applied Geophysics | IDEA League","",""
"uuid:e04c2a93-55f4-4dbb-bcb4-f71d02cb32ad","http://resolver.tudelft.nl/uuid:e04c2a93-55f4-4dbb-bcb4-f71d02cb32ad","DESC glove: Prototyping a novel wearable device for post-stroke hand rehabilitation","Baldi, Rebecca (TU Delft Mechanical, Maritime and Materials Engineering)","Smit, G. (mentor); Plettenburg, D.H. (graduation committee); Trauzettel, F. (graduation committee); Delft University of Technology (degree granting institution)","2020","The human brain integrates tactile sensory information from the fingertips to efficiently manipulate objects. Sensory impairments due to neurological disorders, e.g. stroke, largely reduce hand dexterity and the ability to perform daily living activities. Several feedback augmentation techniques have been investigated for rehabilitative purposes with promising outcomes. However, they often require the use of unpractical, expensive, or complex devices. In this work we propose the delivery of vibrotactile feedback based on the Discrete Event-driven Sensory feedback Control (DESC)to promote motor learning in post stroke rehabilitation. For this purpose, we prototyped a novel wearable device, namely the DESC glove. It consisted of a soft glove instrumented with PolyVinylidene Fluoride (PVDF) sensors at the fingertips and eccentric-mass vibration actuators to be worn on the forearm. We proceeded with the characterization of the device, which resulted in promising outcomes. <br/>The DESC glove was tested with ten healthy participants subsequently in a pick and lift timed task. The effects of augmented vibrotactile feedback were assessed comparing it to a baseline, consisting of wearing the device unpowered. The results of this pilot study showed a decrease in the time necessary to perform the task, a reduction in the time delay from load force to grip force activation and a diminishing of the grip force applied on the object, which led to a lower breakage rate in the intervention condition. These promising outcomes encourage further experiments with stroke survivors to validate the effectiveness of the device to improve hand dexterity and promote stroke rehabilitation.<br","Stroke; Hand; Rehabilitation; Sensory; Vibrotactile; Feedback; Wearable; Glove","en","master thesis","","","","","","","","2021-08-05","","","","Biomedical Engineering","DESC glove",""
"uuid:e54bbdca-3e9f-4c23-8c89-463751193061","http://resolver.tudelft.nl/uuid:e54bbdca-3e9f-4c23-8c89-463751193061","Scaling up data analytics in Python using multiple FPGAs","Aggarwal, S. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Al-Ars, Z. (mentor); Rellermeyer, J.S. (graduation committee); Hofstee, H.P. (graduation committee); Hoozemans, J.J. (graduation committee); Delft University of Technology (degree granting institution)","2020","Big data applications are becoming more commonplace due to an abundance of digital data and increasingly powerful hardware. One of these classes of hardware devices are FPGAs, which are being used today in various ways such as data centers and embedded systems. High performance, power efficiency, and reprogrammability are the primary reasons behind their wide use. Another trend over the previous years has been to use distributed data processing frameworks such as Apache Spark to improve the performance of big data applications. Traditionally, such frameworks are deployed on commodity hardware to save costs. This approach is fairly popular, with organizations often having on-premise compute clusters or using a cloud provider to access a managed cluster. This project attempts to combine the above-mentioned worlds - FPGAs and dis- tributed data processing. We have designed an architecture that allows us to use FP- GAs as end-devices in a compute cluster to perform the actual computation instead of CPUs. This architecture is designed by composing together several open source technologies and allows us to interact with an FPGA cluster using Python. Using a high-level programming language such as Python makes this system easy to use for software developers and data scientists, and also abstracts away the internal commu- nication within the cluster. We have built prototypes based on this architecture for 3 hardware platforms (FPGA families) and 3 specific applications to demonstrate general applicability. We have observed noticeable performance gains in these applications by scaling up the FPGA cluster.","FPGA; Distributed systems; Data Science; Fletcher","en","master thesis","","","","","","","","","","","","","",""
"uuid:76b1aaca-f1f6-4eb5-9fbb-fec2fe443f10","http://resolver.tudelft.nl/uuid:76b1aaca-f1f6-4eb5-9fbb-fec2fe443f10","Measuring the robustness of network controllability","Dhiman, Ashish Kumar (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Network Architectures and Services)","Kooij, Robert (mentor); Sun, Peng (mentor); Kitsak, Maksim (graduation committee); Dubbeldam, Johan (graduation committee); Delft University of Technology (degree granting institution)","2020","Networks are all around us, telecommunication networks, road transportation networks, and the Internet are a few examples of networks that we encounter every day. The entities in a network are represented by nodes and the interconnections between them are represented by links. For example, in a telecommunication network, a node could be an end point for data transmission, a redistribution point or in physical terms, an entity that is capable of receiving, transmitting or redistributing information and a link could be a wired or a wireless connection between the nodes. It is of prime importance that the networks perform their functions properly. To ensure the effective operation of such networks, we need to control them by applying external inputs on some nodes which are known as driver nodes. We say that a network is controllable if it can be driven from any arbitrary state to any desired state in finite time under the control of driver nodes which are attached to the external inputs. Networks are often confronted with perturbations in the form of targeted and random attacks to disrupt their operation. Such perturbations make these networks less controllable. Thus, more driver nodes are needed to gain the full controllability of these networks. As a result, the robustness of network controllability decreases. In this study, the minimum number of driver nodes which gain full controllability after failures or attacks is chosen as the robustness metric.<br/>Existing closed-form analytical approximations estimate the normalized minimum number of driver nodes as a function of the fraction of removed links in both targeted and random attacks. However, the approximations sometimes do not fit with the simulations and the errors between the approximations and simulations are large. The main objectives of this study are to improve the analytical approximations using machine learning methods for both targeted and random attacks and additionally, derive a suitable analytical approximation for the out-in degree-based attack. Specifically, we use Linear Regression, Random Forest, and Artificial Neural Networks. To evaluate the performance of our machine learning models, we compare them with analytical approximations and simulations. In addition to this, we also study the attack based variability in estimating the minimum number of driver nodes using robustness envelopes.<br/>Based on the performance evaluations, we found that the approximations using machine learning models significantly outperform the existing closed-form analytical approximations for the minimum number of driver nodes, both in real-world and synthetic networks. Furthermore, we also assess the performance of our analytical approximations for the out-in degree-based attacks by comparing them with simulations.<br","Network controllability; Robustness; Targeted attacks; Random attacks; Machine Learning","en","master thesis","","","","","","","","","","","","Electrical Engineering | Telecommunications and Sensing Systems","",""
"uuid:51ae2adb-8f08-4c6b-b8e1-f59ef698da03","http://resolver.tudelft.nl/uuid:51ae2adb-8f08-4c6b-b8e1-f59ef698da03","Ice Loads: The effect of climate change on Arctic offshore structure design","Ordeman, Gertjan (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Offshore and Dredging Engineering)","Riska, K.A. (mentor); Hendrikse, H. (mentor); Jarquin Laguna, A. (mentor); Delft University of Technology (degree granting institution)","2020","For the development of Arctic offshore structures, design ice loads are required. These design loads represent the ice loads a structure may be exposed to for specified requirements. The design ice loads depend on magnitude of the ice loads and on the probability of exposure to the ice loads. Both are impacted by local sea ice conditions.<br/><br/>Climate change affects the sea ice conditions causing change in the ice loads Arctic offshore structures are expected to experience. To obtain accurate design loads, the effect of climate change should be considered in defining those. <br/><br/>Conventional methods to determine design ice loads are based on historical data and assume this data can be used to represent the loads during the lifetime of the structure. However, historical data cannot represent future ice conditions if climate change is considered as sea ice conditions will change. This means that the effect of climate change is not incorporated in the design ice loads when these are based on conventional methods. To include the effect of climate change a new method needs to be developed.<br/><br/>In this thesis, such a new method is proposed that enables to include the effect of climate change into the design ice loads. Instead of historical data, the new method considers the future ice conditions. The method allows to base the design ice loads on sea ice conditions that change over time.<br/>To determine design ice loads, extremal distributions are used. Extremal distributions describe the probability of seasonal maximum ice loads. Commonly, the extremal distribution is based on data covering multiple seasons and cannot properly include inter-seasonal change in sea ice conditions. The new method allows to determine the design ice loads based upon changing extremal distributions. The extremal distributions are determined for seasons separately based on sea ice conditions of one season only. <br/><br/>For the proposed method, a concept referred to as an 'ice state' is introduced. Ice states describe a period of time in which the sea ice conditions are assumed to be constant. When sea ice conditions are constant, the corresponding short-term ice load distributions and the ice load frequency can be determined. Both are required to be able to determine the extremal distribution for one season.<br/><br/>According to the new method, the increase of drift speeds causes increase of design ice loads whereas the decrease of ice concentration, thickness and compressive strength causes decrease of the design ice loads. Based upon expected future climate change scenarios, the new method indicates that design ice loads are lower when compared to the design ice loads according to the conventional method. <br","Sea; Ice; Climate; Change; Design; Loads; Arctic; Offshore","en","master thesis","","","","","","","","2025-08-04","","","","Offshore and Dredging Engineering | Bottom Founded Structures, Arctic and Wind","",""
"uuid:174e465e-380f-4605-99c7-582f6c3aae4a","http://resolver.tudelft.nl/uuid:174e465e-380f-4605-99c7-582f6c3aae4a","De verstrooiing van het licht berekend voor het Asahi-U substraat","Kooiman, M.J. (TU Delft Electrical Engineering, Mathematics and Computer Science)","Cools, K. (mentor); van Iersel, L.J.J. (graduation committee); Santbergen, R. (graduation committee); Delft University of Technology (degree granting institution)","2020","In dit project is gewerkt aan een manier om de reflectie van het licht op de textuur van een zonnecel te berekenen. Deze reflectie is berekenend voor de verschillende hoeken van inval en uitval en omgezet in een reflectie matrix. In dit<br/>project is verder gewerkt aan een al bestaand wiskundig model. Dat model was<br/>in staat het door de verstrooiing ontstaande verre veld te berekenen. Dit model maakt gebruik van de methode van momenten, en past deze toe op eerder<br/>ontwikkelde integraal vergelijkingen , die volgen uit de wetten van Maxwel.<br/>Tijdens dit project is dit model aangepast zodat het ook bruikbaar werd voor<br/>het door ons gemodelleerde substraat, van het Asahi-U type. Ook is in dit project gewerkt aan een manier om de bekende data van het Asahi-U substraat om<br/>te zetten naar een wiskundig model .Dit is gedaan door het Asahi-U substraat<br/>om te zetten naar een graaf van knopen en takken, met behulp van het programma GMSH. Vervolgens is gewerkt aan een manier om de berekende data<br/>van het verre veld om te verwerken tot de reflectie matrices. Dit is gedaan met<br/>behulp van een numerieke methode om integralen uit te werken. Tenslotte is de<br/>reflectie matrices opgesteld, waaruit de reflectie van het licht op het substraat<br/>kan worden afgelezen. Deze opgestelde matrix is anders dan de verwachting<br/>niet symmetrisch. De waardes verschillen ook van de waardes die gevonden<br/>zijn met behulp van een empirische meting.","Numerical Analysis; Solar Cells; Reflection of Light","nl","bachelor thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:5466d32f-f19c-4e2d-958f-10b55cf7d0ab","http://resolver.tudelft.nl/uuid:5466d32f-f19c-4e2d-958f-10b55cf7d0ab","Assessing the Impact of Condition-Based Maintenance as a Function of the Variation in Prognostics Performance Levels","Vlamings, Bob (TU Delft Aerospace Engineering)","Verhagen, W.J.C. (mentor); Freeman, F.C. (mentor); Santos, Bruno F. (graduation committee); van Kampen, E. (graduation committee); Bieber, M.T. (graduation committee); Delft University of Technology (degree granting institution)","2020","As the profit margins of the airline industry are relatively low, it is of utmost importance to keep costs low in order for airlines to stay competitive. An important cost factor is maintenance costs, as it can take up around 10-20 % of the total direct operational costs. Currently, much development is taking place in developing condition-based maintenance (CBM) strategies. These strategies on the one hand leverage remaining useful life (RUL) predictions of components to enable better planning and lower repair costs while on the other hand less preventive maintenance tasks are required due to the increase of useful sensor data available. This paper develops insights in the potential benefits that CBM can have as a function of different prognostic performance levels. This is done by developing cost- benefit models which accept a wide range of parameters being able to simulate prognostic effectiveness on different aircraft fleets. Results are obtained by using real MRO and operator input data. The results show that CBM can be beneficial, given that the model has a sufficient specificity and the component supply chain scales accordingly.","prognostics; prognostics and health management; condition-based maintenance; predictive maintenance; cost-benefit analysis","en","master thesis","","","","","","","","2024-07-29","","","","Aerospace Engineering | Air Transport and Operations","",""
"uuid:5dbe0031-cea8-4e4b-a6e6-021ce1458205","http://resolver.tudelft.nl/uuid:5dbe0031-cea8-4e4b-a6e6-021ce1458205","Deriving Timing Properties from System Traces using Data-driven Techniques","Vădineanu, Serban (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Embedded and Networked Systems)","Nasri, Mitra (mentor); Kuipers, F.A. (graduation committee); Rellermeyer, Jan S. (graduation committee); Delft University of Technology (degree granting institution)","2020","With the growth in the complexity of real-time embedded systems, there is an increasing need for tools and techniques to understand and compare the observed runtime behavior of a system with the expected one. Since many realtime applications require periodic interactions with the environment, one of the fundamental problems in guaranteeing/monitoring their temporal correctness is to be able to infer the periodicity of certain events in the system. The practicability of a period inference tool, however, depends on both its accuracy and robustness (resilience) against noise in the output trace of the system, e.g., when the system trace is impacted by events that have a non-deterministic nature such as the presence of aperiodic tasks, release jitters and runtime execution-time variations of the tasks.<br/>This work (i) presents a period inference framework that uses regression-based machine-learning (RBML) methods, (ii) thoroughly investigates the accuracy and robustness of different families of RBML methods in the presence of uncertainties in the system parameters, and (iii) proposes further accuracy improvements by deriving candidate pruning rules based on the inherent properties of the underlying scheduling policies. We show, on both synthetically generated traces and traces from actual systems, that our solutions can reduce the error of period estimation by two to three orders of magnitudes w.r.t. state of the art. Also, our methods showed to be robust against most sources of disturbance.<br","real-time systems; Machine Learning; Regression; Periodicity","en","master thesis","","","","","","","","","","","","Electrical Engineering | Embedded Systems","",""
"uuid:7e3b431d-0a63-400f-ba8c-63acb11a3180","http://resolver.tudelft.nl/uuid:7e3b431d-0a63-400f-ba8c-63acb11a3180","Classical and Quantum Simulation of Stoquastic Hamiltonians","Stroeks, Maarten (TU Delft Applied Sciences)","Terhal, B.M. (mentor); Delft University of Technology (degree granting institution)","2020","","","en","master thesis","","","","","","","","","","","","Applied Physics","",""
"uuid:846f5532-3c42-4b93-b7de-cab1b2b3bbf8","http://resolver.tudelft.nl/uuid:846f5532-3c42-4b93-b7de-cab1b2b3bbf8","A Novel Formulation of the Vehicle Routing Problem for Humanitarian Applications","Mekking, Yoram (TU Delft Aerospace Engineering)","Delft University of Technology (degree granting institution)","2020","The United Nations Humanitarian Air Service (UNHAS) currently performs their flight planning by hand, resulting in possibly non optimal routing with little decision support. Research has mainly focused on commercial applications, leaving humanitarian applications underexposed. This study aims at improving the efficiency and effectiveness of flight routing and scheduling in a humanitarian setting by creating a linear programming model. A novel, airport-based, formulation of the vehicle routing problem is presented. Based on this formulation a model is created that also incorporated the monthly minimum guaranteed flight hours per aircraft. The results of this model are compared to human flight planners and a reference model. When considering day-to-day optimization, the model realized cost savings of 4.6% till 10.5% with respect to the human flight planners and 1.8% compared to a reference model. When considering the minimum guaranteed hours, the model obtained solutions that were 4% cheaper compared to the daily optimization mode and 1.6% compared to the human flight planner. Furthermore, analyses were performed that offer insight in the effect of the contract structure on the operational costs.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
