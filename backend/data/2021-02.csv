"uuid","repository link","title","author","contributor","publication year","abstract","subject topic","language","publication type","publisher","isbn","issn","patent","patent status","bibliographic note","access restriction","embargo date","faculty","department","research group","programme","project","coordinates"
"uuid:56f2948a-4110-49c1-846d-7204ea966d49","http://resolver.tudelft.nl/uuid:56f2948a-4110-49c1-846d-7204ea966d49","Ultra-Low Energy Time-Mode ADC with Background Calibration for Biomedical Sensing Applications","Kandilakis, Manos (TU Delft Electrical Engineering, Mathematics and Computer Science)","Serdijn, W.A. (mentor); Akg√ºn, O.C. (graduation committee); Delft University of Technology (degree granting institution)","2021","Biomedical engineering focuses in advancing health care by taking advantage of the technological improvement. An important part of biomedical engineering is biomedical sensing, that focuses in the acquisition of biopotential signals. Through time, a lot of research has been done on the acquisition of biopotential signals and a variety of methods has been presented. The main goal of the front-end circuits of the biomedical sensing devices is to convert the analog value obtained by a sensor to its digital equivalent. In order to achieve an accurate conversion, the analog-to-digital converters used, need to achieve a medium resolution and a sampling frequency at the kilohertz range. Another important aspect in biomedical sensing devices is to achieve minimum power and area consumption. The properties of the biopotential signals and the requirements set by the biomedical applications, make the design of ADCs based on classical mixed architectures increasingly difficult, as technology scaling deteriorates the performance of the analog part of the devices. In the presented thesis, time-domain signal processing techniques have been used in order to develop a programmable resolution, low-voltage, low-power and small-area time-mode ADC for biomedical applications. The proposed time-mode ADC is a novel architecture and it is composed of a voltagecontrolled ring oscillator based analog-to-time converter, followed by an asynchronous, unfolded SAR, coarse TDC and an asynchronous, enhanced range. fine flash TDC, As the input is sensed, the analog-to-time converter, embeds the analog informationwithin the time period between a rising and a falling edge of the output signal. Following, the output time pulse is fed to the TDC that quantizes the pulse and produces the digital equivalent representation of the sensed value. The resolution of the ADC can be programmed from 8 to 10 bits. The delay elements of the coarse TDC are based on a novel modified version of Dynamic Leakage Suppresion delay elements. Moreover, a novel background calibration mechanism is introduced to correct the errors due to process variation. The calibration removes the offset and gain error of the ADC and achieves DNL and INL reduction. The integrated circuit has been implemented in a 65nm TSMC process and its performance has been evaluated through Cadence and Synopsys tools. The ADC uses a 0.5V supply voltage and consumes 771 nW for 10-bit resolution. The total area of the ADC is 0.01342 mm2. The maximum sampling rate is 2.2 KS/s. The DNL and INL of the 10 bit converter are +0.86/-0.83 and +0.88/-1.79 respectively. The simulation results indicate an SNDR of 61.3 dB and an ENOB of 9.8 bit for a 10mV peak-to-peak 1kHz input frequency.","time-mode; ADC; TDC; ATC; Biomedical sensing; low energy","en","master thesis","","","","","","","","","","","","","",""
"uuid:b55c53f9-df45-4629-afd6-073bae268f2b","http://resolver.tudelft.nl/uuid:b55c53f9-df45-4629-afd6-073bae268f2b","Parametric comparison of stability systems: Development of a parametric tool for the comparison and optimisation of four concrete stability systems for high-rise buildings between 100 m and 250 m in an early design phase","Jongenotter, Jesse (TU Delft Civil Engineering and Geosciences)","Terwel, K.C. (mentor); Noteboom, C. (mentor); Eigenraam, P. (mentor); van Eerden, A.R. (mentor); Delft University of Technology (degree granting institution)","2021","The aim of this research is to make the early design process more efficient. This is done with a parametric model, which compares high-rise stability systems. The research is focused on the stability systems shear walls, core, outrigger and tube. All systems are executed in concrete cast-in-situ, in the range from 100 to 250 m. The parametric model is executed in Grasshopper and Karamba. Four performance criteria are checked in the model. These are strength, stiffness, foundation design and comfort. An optimisation procedure has been applied to find the most optimal system based on input and optimisation goal. Three optimisation goals have been appointed. These are slenderness of wall and column elements, total weight and carbon emission and flexibility. Flexibility is defined as effective floor area and ratio facade openings. The results of each optimisation goal are plotted with respect to the height to obtain insight in the suitability per system. Input parameters, optimisation procedure and performance criteria have been processed in a tool in Human UI. The model and tool have been applied on De Zalmhaventoren to verify the outcomes. It can be concluded that the model, tool and optimisation results have led to more insight in the high-rise early design process and ease decision making.","parametric design; high-rise; stability systems; optimisation; Grasshopper; Karamba","en","master thesis","","","","","","","","","","","","","",""
"uuid:4d4c05bb-70f6-4504-8ed9-98c6d18a4373","http://resolver.tudelft.nl/uuid:4d4c05bb-70f6-4504-8ed9-98c6d18a4373","The effect of engine sound and power-train enhancement on sportiness and driving behaviour: A driving simulator study","Visser, Peter (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Cognitive Robotics)","de Winter, J.C.F. (mentor); Melman, T. (mentor); Dodou, D. (graduation committee); Delft University of Technology (degree granting institution)","2021","Many modern vehicles are equipped with a sport mode, which intends to increase drivers' perceived sportiness of the vehicle, via e.g. power-train enhancement (PTE) or engine sound enhancement (ESE). However, to the best of authors' knowledge, no studies are available that investigated the individual or combined effects of PTE and ESE on perceived sportiness and driving behaviour. Therefore, this study aimed to investigate the effects of ESE, PTE and their combination on perceived sportiness and driving behaviour. <br/>In a within-subject driving simulator study, thirty-two participants drove under five conditions: no enhancement (Off), PTE, ESE, PTE and ESE combined (PTE-ESE) and a control condition (Control) with a physically sportier car (i.e., more engine power and a sports car sound). PTE provided a more sensitive pedal-to-throttle mapping and ESE an engine sound associated with increased engine speed. Both implementations did not increase engine power. Perceived sportiness was measured using a questionnaire, whereas driving behaviour was retrieved from the simulator.<br/>The results showed that ESE contributed significantly to perceived sportiness and perceived engine responsiveness, whereas PTE had no to limited effect. Furthermore, ESE created the impression of enhanced engine responsiveness, more so than PTE. PTE resulted in increased acceleration during acceleration from standstill, whereas driving behaviour was not significantly affected by ESE compared to Off. In addition, PTE significantly influenced control behaviour: it led to a decreased mean accelerator pedal depression angle and an increased mean throttle reversal rate compare to Off.<br/>We conclude that ESE increases perceived sportiness to the extent it approaches the perceived sportiness of an actual sportier car without altering the driving behaviour or decreasing safety margins. The findings of this study support the use of ESE in sport mode. PTE should be further explored in an experimental setup that provides vestibular feedback.","perceived sportiness; engine sound enhancement; power-train enhancement; driving simulator","en","master thesis","","","","","","","","","","","","Mechanical Engineering","",""
"uuid:197d1f7d-2981-4f08-b8e2-800de6a05e19","http://resolver.tudelft.nl/uuid:197d1f7d-2981-4f08-b8e2-800de6a05e19","Investigating Domain Transfer and Viewpoint in the Context of Person Re-Id","Liu, Zheng (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Gemert, J.C. (mentor); Napolean, Y. (mentor); Delft University of Technology (degree granting institution)","2021","Deep learning has significantly improved Re-Id per- formance but it requires a large amount of data, however, obtaining data is expensive from both time and money perspective. Inspired by ImageNet pre- trained models and synthetic data generation techniques, this paper investigates to utilise real-world and syn- thetic Re-Id datasets to augment task performance. Firstly, we propose two methods to apply external Re-Id data, NDTL (Neighbour-Domain Transfer Learning) and NDDS (Neighbour-Domain Data Stitching). Secondly, we quantitatively illustrate that both real-world and syn- thetic data could mitigate Re-Id data shortage problems, using Re-Id dataset to pre-train models is better than us- ing ImageNet, we achieve up to 28.2% mAP improvement on DukeMTMC and 5.2% on Market-1501. Moreover, we find out that viewpoint, one of Re-Id relevant factors, has the an influence on the system performance due to viewpoint-wise non-alignment and unbalance of the orig- inal dataset, it also assists the performance if train set is augmented balanced. Our research strongly illustrates both real-world and synthetic Re-Id dataset can effec- tively augment Re-Id task, viewpoint is an essential fac- tor and based on which, train-test distribution dramati- cally influences Re-Id performance, and balancing train classes are also helpful to improve the performance.","Person Re-Identification; transfer learning; synthetic data; augmentation; viewpoint","en","master thesis","","","","","","","","","","","","","",""
"uuid:731b92cc-ec9e-4543-a608-c0edbdb14aaf","http://resolver.tudelft.nl/uuid:731b92cc-ec9e-4543-a608-c0edbdb14aaf","AI for Experience: Designing with Generative Adversarial Networks to evoke climate fascination","Uebersch√§r, Frederik (TU Delft Industrial Design Engineering)","Lomas, J.D. (graduation committee); Bozzon, A. (mentor); Delft University of Technology (degree granting institution)","2021","Our world climate is an incredibly complex and ever-changing system. The reality of climate change and the consequential pressure to act fast to reduce greenhouse gas emissions requires immediate attention. And yet, despite this unprecedented urgency, active public engagement needed to motivate meaningful change is still missing.<br/> <br/> This graduation project explores how to utilize Generative Adversarial Networks (GANs) ‚Äì a subset of artificial intelligence (AI) ‚Äì to motivate public engagement through the emotion of fascination and element of play. The final design of this exploration is an interactive exhibition piece that allows its users to create novel, AI-generated landscapes.<br/><br/> In the first phase of the project, hands-on exploration of the use of GANs as a design opportunity was conducted and the experiences of the exploration process documented. Further research through interviews with climate researchers and literature review into the topics of climate change helped to get an understanding of the climate context and map out and narrow down the solution space for the following ideation phase. The context research revealed that the current climate debate is deeply emotional, with mostly negative emotions like fear and hopelessness in its center. Yet, it was also found that fostering positive emotions like fascination and joy is a potential means to increase interest and motivate people to engage with climate initiatives. Based on the context exploration, a series of design prototypes were created and tested with participants to inform the final design.<br/><br/>The final concept LANDSHAPES is an interactive exhibition piece intended for the museum context. It features a circular projection of AI-generated aerial landscapes ‚Äì images that look real, yet have never been seen by anyone before. The installation enables participants to become absorbed in the morphing landscapes and experience their potential impact on our surroundings in a playful, open-ended manner.<br/> A preliminary installation was evaluated with participants using qualitative methods of observation and interviews. The installation evoked a deep sense of beauty, calmness, and inspiration that contributed to a meditation-like, engaging experience. Even without a predefined narrative, participants automatically associated the morphing images with our changing planet and ascribed meaning to the abstract visuals. The addition of control over the moving landscapes resulted in a mindset shift, as the experience transformed from a passive and meditative experience to an experience with additional cognitive involvement. The preference of experience differed between participants.<br/><br/> The design research conducted in this project strengthens the assumption that experiences with positive emotion in its center can be used to foster initial engagement with the topic of climate change. Furthermore, it showed that GAN technology can be used to evoke an emotional response, which offers interesting opportunities for future work. More specifically, the research suggests the potential for further development of playful experiences to make climate data accessible and engaging to the general public, as well as an opportunity to explore GANs that utilize emotional value as an input to generate targeted media that reinforces or counteracts the viewer‚Äôs emotional response.","Artificial Intelligence; Satellite Imagery; Generative Adversarial Network; Playful Interactions; Installation design; Climate engagement","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:d57d831a-0c34-4822-9005-63fee99ff2c4","http://resolver.tudelft.nl/uuid:d57d831a-0c34-4822-9005-63fee99ff2c4","NeuroAesthetic Resonance: Designing for Multi-sensory Optimisation through EEG and Continuous Aesthetic Ratings","Beardow, Caiseal (TU Delft Industrial Design Engineering)","Lomas, J.D. (mentor); Ozcan Vieira, E. (mentor); Delft University of Technology (degree granting institution)","2021","The brain is the foundation of human experience. Our sensory and emotional perceptions of the world around us are all based in neural activity. But does physical brain activity correspond with subjective aesthetic experience? Is it possible to optimise for both?<br/><br/> My project seeks to answer this question by framing brain response and aesthetic experience as forms of resonance. The brain functions through oscillation (commonly known as ‚Äòbrainwaves‚Äô) and as such produces measurable resonance phenomena. Aesthetic resonance is a far more metaphorical concept, but has been explored in design literature as a model of enjoyable and meaningful aesthetic experiences, in which a person feels connected to the aesthetic properties of their environment. In my work, I explore how design might produce experiences that are optimised for both forms of resonance. In doing so, I aim to contribute knowledge that furthers scientifically informed interaction design and enables the design of effective, enjoyable and personalised brain-computer interfaces (BCIs) and neurotherapeutics. My findings are expressed through an audiovisual installation that uses a feedback loop between participant and designer to co-compose a data-driven resonant experience. The installation gathers synchronised, labelled EEG and multi-sensory stimulation data, enabling future research in the joint optimisation of neural response and aesthetic experience.","Empirical Aesthetics; Data-driven Design; Brain-computer Interface","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:f398ea1b-4d72-4e25-90b6-3a31fa401aa4","http://resolver.tudelft.nl/uuid:f398ea1b-4d72-4e25-90b6-3a31fa401aa4","Application of Analytical Second-Order Methods for Re-Entry Mission Design","Meeuwissen, Bart (TU Delft Aerospace Engineering; TU Delft Astrodynamics & Space Missions)","Mooij, E. (mentor); Visser, P.N.A.M. (graduation committee); van Kampen, E. (graduation committee); Delft University of Technology (degree granting institution)","2021","Re-entry mission design remains an active field of study to safely return space missions back to Earth. With the developments in on-board computers, mission design and especially optimization of these missions has been performed numerically at an increasing rate at the cost of computing power. Analytical second-order methods have previously been shown to provide accurate results for mission design with less computational effort, but have not been applied to mission optimization. The analytical method was tested and shown to provide good results for a range of initial conditions. During optimization, restrictions arising from their derivation show that fundamental problems remain for application in mission optimization as the entry state cannot be freely defined. Additionally, two new optimization algorithms have been tested for re-entry mission optimization, a variable chromosome length algorithm and the Multi-objective Hypervolume-based Ant Colony Optimizer, both are found to provide results similar to the MOEA/D algorithm.","Re-entry; Optimisation; Guidance","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:a3e588a9-9d21-4170-a973-c53eb3b45afc","http://resolver.tudelft.nl/uuid:a3e588a9-9d21-4170-a973-c53eb3b45afc","Aerodynamic Analysis of Engine Integration during the Preliminary Design Phase","Heimans, Colin (TU Delft Aerospace Engineering; TU Delft Flight Performance and Propulsion)","la Rocca, G. (mentor); Veldhuis, L.L.M. (graduation committee); van Zuijlen, A.H. (graduation committee); Elmendorp, R.J.M. (graduation committee); Delft University of Technology (degree granting institution)","2021","To reduce the environmental impact of aviation, new aircraft configurations are investigated. One of these researches is the PARSIFAL project, that investigates an efficient box-wing aircraft for passenger transport. In previous work, an engine sizing tool is developed to design the engines of the PARSIFAL aircraft. The tool is developed as part of the Multi-Model Generator (MMG), a knowledge based engineering application developed in the Flight Performance section. This work also included an engine integration study, which showed that a fuselage mounting is preferred over a wing mounting. However, the integration study lacked the desired design sensitivity for small design changes, e.g. engine diameter and length. Because of this lack of design sensitivity, the question whether the engine installation following from this work is ideal remains open. Therefore, in this thesis a best practice for engine integration studies during the preliminary design phase is investigated. The found best practice is then used to re-asses the engine installation by aligning the engines with the local flow. The best practice is also employed to asses under wing engine installations, to establish the potential use of the practice for this type of installations. Before the trade-off study for a best practice could be performed, changes to the MMG had to be made. Three primitives, the building blocks that create an aircraft geometry, had to be adapted. A new wing primitive, through flow nacelle (TFN) geometry, and a pylon primitive are introduced. In search of a best practice, textbook analyses, 3d panel solvers, and combinations of the two are compared. To fully assess an engine integration, information on lift, drag, and pitching moment is required. Since textbook methods only provide information on drag, these are not satisfactory on their own. Nonetheless, these methods can be used to predict the drag addition of a pylon, when only airframe and nacelle are simulated. In two panel solvers, FlightStream and VSAERO, two analysis practices are tested. The first being a simulation including airframe, nacelle, and pylon and the second being a simulation including airframe and nacelle complemented with a textbook correction for the pylon drag. Following a trade-off, using speed, accuracy, ease-of-use, and design sensitivity as criteria, a simulation with FlightStream of airframe and nacelle with a textbook addition of pylon drag proved to be the best analysis practice. This best practice is employed to re-asses the engine installation of the PARSIFAL aircraft. While the location is fixed, since it aligns with the structure inside the airframe, the orientation is changed to align with the local flow. This alignment results in a 3% decrease of aerodynamic efficiency loss and a 17% reduction of pitching moment increase, with respect to the original engine orientation. In a second study, the potential of the best practice to analyse under wing engine installations is tested by changing the location of an engine under the rear wing of the PARSIFAL box-wing. These results show that with proper placement, the same aerodynamic efficiency loss can be obtained as for fuselage installations.","Airframe-engine integration; Aerodynamic performance; Best practice; Box-wing; Panel solver; Textbook analysis; Preliminary design; Knowledge based engineering","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:2dfe2d61-c707-45e5-9a35-8a15101853ee","http://resolver.tudelft.nl/uuid:2dfe2d61-c707-45e5-9a35-8a15101853ee","Characterization and Design of a Stripper for a Continuous Direct Air Capture System","van de Poll, Nelson (TU Delft Mechanical, Maritime and Materials Engineering)","Goetheer, E.L.V. (mentor); de Jong, W. (graduation committee); Boersma, B.J. (graduation committee); Sinha, M. (graduation committee); Delft University of Technology (degree granting institution)","2021","Capturing CO2 directly from the air has gained wide attention as it is one of the possible solutions to mitigate the risks of climate change. Zero Emission Fuels (ZEF) is a start-up in Delft that develops a small-scale plant to produce methanol from sunlight and air only. CO2 and H2O are captured from the air by a direct air capture unit that operates continuously by means of an absorption and stripping column. Liquid amines are investigated as chemical sorbent. In this work, the stripping column is characterized and optimized for the liquid amine tetra-ethylenepentamine (TEPA). A vapor-liquid equilibrium based stage-by-stage stripper model was established using mass and energy balances for each stage individually. A number of input parameters was specified to understand the effect of those parameters on the performance of the stripping column. The parameters include; composition, temperature and mass flow rate of the feed, number of stages, H2O reflux ratio, temperature of the reboiler and absolute pressure of the column. The mass balance was solved according to the Rachford-Rice equation while using bisection as numerical root finder. To validate the stripper model, experiments were performed for varying configurations regarding the input parameters mentioned above. For this, a trayed stripping column with bubble caps, was build and adjusted according to the experimental plan. Furthermore, single stage kinetic experiments were performed at 115 ¬∞C and 950 mbar to find the limitations of the desorption process inside the column. Subsequently, the Damk√∂hler number was estimated to understand the effects of reaction rate and diffusion during the process. Sensitivity analyses were performed to find the effect of input parameters on the performance of the stripping column. The effect was measured in terms of; CO2 concentration in the outlet stream, cyclic capacity of the liquid solvent, CO2 and H2O vapor ratio in the top stage of the column and energy demand per desorbed mol of CO2. Based on the results, a tool to predict the performance of the stripper in an elementary way was produced. Based on the kinetic experiments, it was found that a typical hold up time that is required for the system to reach equilibrium was measured at 600 s. This number was used to estimate the liquid hold up volume per stage in the final stripper design. The experimental and model results were combined in a new stripper design considering the operating conditions stated by ZEF. The 5 stage column operates at 1000 mbar and a reboiler temperature of 120 ¬∞C. The feed was preheated up to 105 ¬∞C and the mass flow rate was determined at 0.31 g/s resulting in a hold up volume of 187 ml per stage. The cyclic capacity of the system equals 3.3 mol CO2 per kg TEPA and the energy demand was found to be 279 kJ per mol CO2. In addition, a new design for ZEF's direct air capture system was presented where the absorption column is modelled as a black box. An heat exchanger was implemented to minimize the energy demand of the system, which resulted in a lowest energy demand of 2319 kWh per ton of CO2. This is slightly higher than the DAC energy demand of companies like Climeworks, Carbon Engineering and Global Thermostat, but could potentially decrease when optimizing the system.","Direct air capture; Stripping; Liquid amines; CO2 capture; Desorption","en","master thesis","","","","","","","","2024-02-26","","","","","",""
"uuid:c0535b3e-a01b-4b11-ad5c-4b53ffd2753c","http://resolver.tudelft.nl/uuid:c0535b3e-a01b-4b11-ad5c-4b53ffd2753c","Quantum Test for Higher Order Gowers Norms","Westdorp, Rik (TU Delft Electrical Engineering, Mathematics and Computer Science)","Bri√´t, J (mentor); Delft University of Technology (degree granting institution)","2021","In this work, a quantum self-test which certifies that measurements of a quantum device have a large Gowers norm of order k is presented and analysed. The test protocol is described as a two-player quantum game, in which players provide answers based on measurements on subsystems of a maximally entangled<br/>bipartite state. The protocol makes use of 2k +1 subtests. It is shown that strategies that succeed in the test with success rate 1-E must have a Gowers norm larger than 1-O(E). This test generalizes measurement tests that certify measurements based on the second order Gowers norm.","Quantum testing; Gowers norms","en","student report","","","","","","This work resulted from an internship at QuSoft, CWI, under supervision of Dr. J. Bri√´t as part of the Applied Mathematics Masters program at the Delft University of Technology.","","","","","","Applied Mathematics","",""
"uuid:faf40cc7-3e1c-4cf9-90f0-1a9ac879ef4f","http://resolver.tudelft.nl/uuid:faf40cc7-3e1c-4cf9-90f0-1a9ac879ef4f","Investigation of crystallographic disorientation topology in simulation of rolling textures with the ALAMEL model","Pirani, Aleem (TU Delft Mechanical, Maritime and Materials Engineering)","Kestens, L.A.I. (mentor); Ochoa Avenda√±o, Jhon (graduation committee); Scholten, V.E. (graduation committee); Ghiabakloo, Hadi (graduation committee); Delft University of Technology (degree granting institution)","2021","The crystallographic texture of a material has a direct impact on its mechanical and functional properties. As a result, texture control is an imperative part of manufacturing processes, especially those involving plastic deformation, such as rolling, which significantly impact crystallographic texture. The exact mechanisms and underlying causes behind such texture evolutions are not well understood. This study investigates the effect of initial disorientation topology on plastically deformed texture, with the help of mean field crystal plasticity simulations performed using the ALAMEL model. The simulated textures are compared to experimentally measured textures of IF steel samples with symmetric rolling reductions of 55 % and 83 %. The results indicate a clear distinction between low disorientation topologies and high disorientation topologies, most evident at high rolling reductions. The study aims to incorporate the disorientation information into the ALAMEL simulations, by re-ordering textural input orientations. The Monte Carlo algorithm is used in addition to the Hungarian Algorithm to re-order orientations based on pre-set disorientation angles. A comparison between the two re-ordering algorithms is also performed, and the Hungarian algorithm is found to have a disorientation distribution closer the ideal result. A comparison between the two yields minimal differences, with the difference between the two results being the error index local minima for minimum disorientation evolved textures and average disorientation (between 35¬∞. Local maxima for error index comparisons are observed for very high disorientation values of over 60¬∞. In the present study, we also result spread for similar disorientation topologies orders to discount the randomness associated with such a process. Thus, multiple files are created with largely similar disorientation characteristics but different grain orders. An overlap is observed for high disorientation simulations, at a higher frequency for lower rolling reductions. The deviation of obtained results is also highest for a disorientation angle average of 15¬∞. The simulated texture comparisons between textures with modified and unmodified texture disorientation topology also indicate a higher disparity with minimum disorientation modified texture. A convergence is observed at a disorientation value between 35¬∞ and 40¬∞, close to the disorientation average of the unmodified texture, and an overlap is observed at higher disorientation values. The valorisation of such a technology is also considered in this study. The current study precedes applied research and is assessed as a level 2 on the technology readiness scale, in danger of facing the ‚Äòvalley of death‚Äô. This is owing to fading interest and funding unless the private sector see‚Äôs value in the technology. The domain most aligned for the application of such technology is electrical steels, which is set to see a large increase in demand and will play a significant role in the energy transition and move towards electrical mobility. The high cost of development and price sensitive market serve as barriers of entry, and entry into the niche beachhead market of DC converters for next generation ‚Äòmore electrified aircraft‚Äô is determined to be an appropriate valorisation strategy. The study also proposes a ‚Äòway to market‚Äô strategy, drawing parallels with other high tech and high value material industries, to determine ‚Äòcritical partnerships‚Äô with high levels of integration in addition to leadership in materials and manufacturing development as key factors for a successful market entry.","Crystal Plasticity; Electrical Steels; Monte Carlo; ALAMEL; Disorientation Topology","en","master thesis","","","","","","","","","","","","","",""
"uuid:b41f4ac8-a0d1-4697-83e2-5830a3cfeccb","http://resolver.tudelft.nl/uuid:b41f4ac8-a0d1-4697-83e2-5830a3cfeccb","Capacity benefits of Virtual Coupling over ETCS L3 Moving Block in a realistic operational environment","Spartalis, Panagiotis (TU Delft Civil Engineering and Geosciences)","Goverde, R.M.P. (mentor); Quaglietta, E. (graduation committee); Wang, M. (graduation committee); van Koningsbruggen, P. (graduation committee); Delft University of Technology (degree granting institution)","2021","As the demand for transport of goods and passengers increases, the capacity of railway networks is becoming more and more saturated. Railway infrastructure managers aim to increase the rail network capacity with the minimum possible investments in infrastructure. Next generation signalling concepts such as Moving Block (MB) and Virtual Coupling (VC) are expected to bring significant capacity benefits to railway corridors. The aim of this thesis is to identify capacity benefits of Virtual coupling over ETCS L3 MB considering a realistic operational setup, where different rolling stock characteristics, driving behavior and traffic information updates exist. Inspired by safety distance car-following models, the multi-state train-following model developed by Quaglietta et al. (2020) is enhanced with a dynamic term, called Dynamic Safety Margin (DSM). The DSM ensures that the following train can come to a standstill at any time applying service braking, even in the worst-case scenario when the leading train applies emergency braking. The DSM accounts for positioning errors, the Vehicle-to-Vehicle (V2V) communication update delay, different train control delay times, and braking capabilities of trains running as a convoy. An One-at-a-time (OAT) sensitivity analysis of the proposed model is conducted to evaluate the importance of selected model parameters in railway capacity. The model parameters under investigation concern the V2V update delay, the train control delay time, and the braking rate of the following train. The braking rate of the following train is proved to have a significant impact on railway capacity, implying that trains with better braking performance imply shorter time headways. To identify potential capacity benefits of the proposed model over ETCS L3 MB, operational scenarios are executed through microscopic simulation in the EGTRAIN tool. The scenarios consider three different rolling stock types, being suburban, regional, and intercity trains. For trains running on open track without stops, the proposed model promises the highest capacity benefits over ETCS L3 MB, for trains with improved braking and acceleration characteristics. For train services with stops, all the train convoy combinations show promising capacity benefits, which are higher for heterogeneous train convoys. Moreover, headways can be reduced to the minimum possible when faster trains follow slower trains. Finally, this model enables multiple train convoy formation based on a predecessor-follower communication topology, where a safety distance is always ensured between trains.","Virtual coupling; Dynamic safety margin; Safe train separation; Sensitivity analysis; Railway capacity","en","master thesis","","","","","","","","","","","","Civil Engineering | Transport and Planning","",""
"uuid:ba31a4b8-2ce0-46e6-9cb5-e07c39f0bb3d","http://resolver.tudelft.nl/uuid:ba31a4b8-2ce0-46e6-9cb5-e07c39f0bb3d","Techno-economic Analysis of Sustainable Aviation Fuels by Using Traffic Forecasts and Fuel Price Projections: A Case Study at TUI Aviation","van Bentem, Koen (TU Delft Civil Engineering and Geosciences; TU Delft Technology, Policy and Management; TU Delft Mechanical, Maritime and Materials Engineering)","van Wee, G.P. (graduation committee); Annema, J.A. (graduation committee); Duinkerken, M.B. (graduation committee); Sutherland, Tom (graduation committee); Delft University of Technology (degree granting institution)","2021","This research focused on the techno-economic implementation of Sustainable Aviation Fuels (SAF). Carbon reduction in commercial aviation could be done via four key levers; technological efficiency improvement (aircraft or engine replacement), operational efficiency improvement (air traffic management or airline operations), the implementation of Sustainable Aviation Fuels, and carbon offsetting by using economic measures. This research was done by doing a case study at TUI Aviation, thus using their demand data. After developing a traffic forecast and resulting CO2 forecast, the four levers were used to limit carbon emissions toward a net-zero emission scenario in 2050. The 22 ASTM certified SAF alternatives were tested against carbon mitigation power and costs, the latter being determined by using the experience curve theory of decreased prices with increased cumulative production. This results in the FT-SPK fuel made from Municipal Solid Waste as being the most attractive SAF alternative with a Net Present Value of 875 million USD. However, it is recommended to include extra fuel alternatives in this research in the future. For example, Power-to-Liquid fuels will have great potential, but are not certified yet.","Aviation; aircraft emissions; environmental economics; traffic forecasting; Cost-Benefit Analysis; experience curve; sustainable mobility","en","master thesis","","","","","","","","","","","","Transport, Infrastructure and Logistics","",""
"uuid:478f2651-c351-4460-a817-f06468ecfdfd","http://resolver.tudelft.nl/uuid:478f2651-c351-4460-a817-f06468ecfdfd","SLOWLY: A digital reflection tool to help Dutch nurses tell their story.","Sab√©e, Merijn (TU Delft Industrial Design Engineering; TU Delft Design Aesthetics)","Ozcan Vieira, E. (mentor); Vegt, N.J.H. (mentor); Delft University of Technology (degree granting institution)","2021","The extraordinary working conditions caused by the first wave of COVID-19 patients caused stress, anxiety and lack of sleep in frontline nurses. This negatively impacted their psychological well being which is important for providing optimal care and maintaining long-term employability (Schoonhoven &amp; Trappenburg, 2020). There is a lack of accessible and low-threshold support tools such as online peer support platforms for nurses. While storytelling driven online peer support is a promising tool, it is unclear how it should be designed. This project aimed to design a storytelling tool, specific to the psychological needs of the Dutch nurses, that best facilitates online peer support. This report describes the research, design and evaluation activities as part of the design process of SLOWLY - A tool that helps nurses reflect on their experiences, preparing them to write a story to be shared as part of online peer support. A context and target group analysis lead to the assessment of the thirteen fundamental needs (Desmet &amp; Fokkinga, 2020). Fulfilment of autonomy, competence and relatedness, as part of self determination theory (Deci &amp; Ryan, 2000), was found to be critically low. This was the primary source for the design requirements of SLOWLY. After using the design requirements to access a wide variety of design interventions, SLOWLY proved to be the most promising concept due to its potential to provide understanding about an experience in an accessible, low-threshold and safe manner. A detailed digital prototype was created, which used five storytelling prompts (character, setting, plot, conflict and theme) to guide nurses in a five day reflection process. Their responses were shown to them during the writing process to help them write stories with more details relevant to their experience. SLOWLY was found to provide increased understanding of the experience based on user testing with seven participants. It showed potential to fulfil all three critically affected fundamental needs. An additional expert review with one nurse yielded a positive response to the likeability, ease of use, clarity and benefit of SLOWLY. The results of this project provided insight into the potential role of storytelling in facilitating online peer support for nurses. Further research is recommended to evaluate longitudinal effects and possible interactions as a result of story sharing.","Nurses; Healthcare; Reflection; Well-being; Peer support","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:d1c07931-6164-4d0c-a9bd-4720a675fc31","http://resolver.tudelft.nl/uuid:d1c07931-6164-4d0c-a9bd-4720a675fc31","Automatic algorithm selection and hyperparameter optimization for medical image classification","Deen, Mitchell (TU Delft Electrical Engineering, Mathematics and Computer Science)","Yorke-Smith, N. (mentor); Starmans, M. P. A. (mentor); Klein, S. (mentor); Chen, Lydia Y. (graduation committee); Delft University of Technology (degree granting institution)","2021","Recent years have shown a tremendous increase in the application of Artificial Intelligence to the field of radiology, often through the extraction and analysis of large numbers of quantitative features from medical images. These applications increase the demand for machine learning models to extract information from these images. To provide these models, improve their performance and reduce the time that experts have to spend on manually tuning them, the field of Automated Machine Learning (AutoML) aims to automate the design process of machine learning models by optimizing the selection of algorithms and their hyperparameters for each application. This work applies an AutoML approach to medical image classification, using a Bayesian optimization strategy to automatically optimize the selection of preprocessing and classification algorithms and their hyperparameters. Its performance is compared with the performance of a random search optimization strategy, evaluated on three datasets from three different clinical applications. The results show that the Bayesian optimization and the random search return models that achieve similar performance on the unseen test sets. We show that a random search with relatively few evaluations and a simple ensemble strategy is sufficient to achieve performance comparable to a more sophisticated and more computationally demanding Bayesian optimization approach, therefore validating the use of a random search optimization strategy in this medical image classification setting. All found models generalize poorly, with average F1-scores on the validation sets used for optimizing the models being at least 20\% lower than the average F1-scores on the unseen test sets. Finally, we further emphasize the difficulty to generalize in this setting, by showing that the differences between subsets of the evaluated datasets are large and that increasing the computation time of the optimization does not benefit the test set performance of the final solution.","Automated Machine Learning; Radiomics; Bayesian Optimization; Random Search; Image Classification","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:4069131f-f254-4d1f-b0b1-c28cdb29f71f","http://resolver.tudelft.nl/uuid:4069131f-f254-4d1f-b0b1-c28cdb29f71f","Numerical Analysis of Angled IRJs","Rijneveld, Martin (TU Delft Civil Engineering and Geosciences; TU Delft Railway Engineering)","Dollevoet, R.P.B.J. (graduation committee); Yang, Z. (mentor); Hoogenboom, P.C.J. (graduation committee); Anupam, K. (graduation committee); Bos, Jelte (graduation committee); Delft University of Technology (degree granting institution)","2021","For railway travel the Insulated Rail Joint (IRJ) is a critical part in most railway safety systems but at the same time also considered a weak link. The IRJ creates a discontinuity in stiffness and geometry that leads to wheel-rail impact forces. The angled IRJ is a proposal to reduce these impact forces. Despite the real-world experiences with angled IRJs the research on the topic is marginal. In this thesis a study is presented into the dynamic behaviour of the wheel-rail impact occurring at IRJs. Numerical models are established to simulate a wheel rolling over IRJs with angles of 0, 15, 30 and 45 degrees, using the implicit-explicit sequential finite element method with the software ANSYS/LS-DYNA. The impact forces are the main output and analysed. Three variations of the IRJ models were used for simulations. The basic version IRJ model is built up with a fully constrained rail foot to simulate an infinite support stiffness condition. The second version is supported by spring and damper elements to simulate supports such as ballast and rail pads. Height differences between the rail ends are generated when a wheel passes the joint, which corresponds to a real-world scenario. Different degrees of support degradation are simulated by varying the support stiffness, using the spring and damper element parameters. The third version also incorporates the spring and damper elements as support but couples some nodes between the fish plate and rail web in vertical displacement to reduce the rail height difference caused by wheel pass-by, aiming to simulate a ‚Äòfactory-new‚Äô condition joint. The established models were validated in terms of wheel-rail contact solution and contact force amplitude. In comparison with existing FE wheel-rail impact models the proposed models in this thesis are less time consuming and more flexible for joint angle adjustments. The second version simulating degraded joint conditions provided the most interesting findings and was used in a sensitivity analysis by varying the velocity and wheel load. The simulation results show that angled IRJs are advantageous when degradation is present, whereas in ‚Äònew joint‚Äô conditions the gap width plays a significant role and angled IRJs with larger gaps produce higher impact forces. Based on the results the recommendation is given to consider angled IRJs on tracks with a low maintenance scheme and further research is suggested.","insulated rail joint; IRJ; angled; FEM modelling; implicit-explicit; contact force; wheel-rail; impact force","en","master thesis","","","","","","","","2021-12-31","","","","Civil Engineering","",""
"uuid:8fd1bd1a-d7c2-4da8-8959-722456a57de5","http://resolver.tudelft.nl/uuid:8fd1bd1a-d7c2-4da8-8959-722456a57de5","The effect of timber bands and columns on the seismic behaviour of rubble stone masonry: A numerical study on Nepal's proposition for reconstruction of residential buildings","van Hoogdalem, Carlijn (TU Delft Civil Engineering and Geosciences)","Rots, J.G. (mentor); Messali, F. (mentor); Schipper, H.R. (mentor); Ravenshorst, G.J.P. (mentor); Delft University of Technology (degree granting institution)","2021","This research investigates if confining rubble stone masonry by timber bands and columns increases resistance against earthquake loads, by performing a number of numerical analyses in the finite element software program Diana. In order to establish a reliable model, the input parameters are investigated by means of a literature study and sensitivity study. Additionally, the numerical model is validated by comparing the results to an analytical study. From the analytical study it is determined that the failure mechanisms are correctly estimated by the numerical analysis. However, differences between the values of ultimate strength and ductility were observed. The effect of the confinement is investigated by a pushover analysis on a shear wall with two different masonry tensile strengths: ft = 0.01 N/mm2 and ft = 0.03 N/mm2. These values are selected to show how such a small difference in tensile strength results in a different failure mechanism of the wall, and therefore results in a vastly different displacement capacity and ultimate strength. Additionally, a shear wall with and without a window opening is studied. If the building is constructed with extremely low-strength masonry (ft = 0.01 N/mm2), the timber frame confinement will increase the resistance of the wall (with or without window opening) against the pushover load. If the building is constructed with masonry having a tensile strength of 0.03 N/mm2 or higher, the confinement has a negative impact on the ductility of the closed wall. For the wall with window opening the confinement triples its ultimate strength. Weather a strong or a ductile structure is more desirable, depends on the demand with respect to the seismic spectrum. If the ground motion demands a strong structure, it is advised to confine the masonry with a timber frame consisting of four timber bands, and columns at each wall junction. The design of the timber frame as recommended by the Nepali building codes is determined to not be sufficient and must be altered in order to provide this positive impact on the structure‚Äôs resistance. Firstly, the columns must be placed at both sides of the band, instead of on the inner side only, to avoid eccentric loads on the bands. Secondly, the cross-sectional dimensions of the bands and columns must be increased avoid failure of the connections and splitting of the timber. Taking these aspects into account, a new design for the confinement method is presented in this study. The limitations of the conclusions of this research follow from the investigation of a single, in-plane wall only. One of the goals of the use of bands is to improve the box behaviour, for which the out-of-plane performance must be investigated. Moreover, an analysis on a three-dimensional structure is needed to fully answer the research question. In a three-dimensional study, the closed walls and walls with opening give a combined response to the load, therefore, the advantages and disadvantages of the confinement are combined as well.","rubble stone masonry; earthquake; numerical analysis; seismic bands; Nepal","en","master thesis","","","","","","","","","","","","Civil Engineering | Structural Engineering | Hydraulic Structures","",""
"uuid:afd9fcbd-3259-4f9c-a37d-4eefabccd169","http://resolver.tudelft.nl/uuid:afd9fcbd-3259-4f9c-a37d-4eefabccd169","Transceiver design for reciprocal operation of ultrasonic flow measurement systems","Shuverov, Vassiliy (TU Delft Electrical Engineering, Mathematics and Computer Science)","Pertijs, M.A.P. (mentor); van Willigen, D.M. (graduation committee); Delft University of Technology (degree granting institution)","2021","In transit-time ultrasonic flow measurement systems, the system's ability to operate reciprocally in the absence of flow is a highly desirable property. If the reciprocity is lacking in the system, any time delay that appears between the upstream and downstream signals at zero-flow conditions will result in false flow measurement. This phenomenon is known as the zero-flow error. <br/>This thesis presents a system in which the reciprocity property has been ensured by matching the electrical impedances of the front-end electronic circuits, namely: the output impedance of the transmitter Z$_\text{out}$ and the input impedance of the receiver Z$_\text{in}$. To achieve this, a circuit has been developed that can be used as both a transmitter and a receiver. This is the main feature that distinguishes the proposed design from those presented in previous work. The transmitter-receiver circuit has been implemented using a three-stage operational amplifier in unity gain feedback configuration. The class AB output stage of the amplifier is equipped with an additional function being used in receive mode for sensing and amplification of the signal. The simulation result obtained by the cross-correlation method yields a zero-flow error value of 30 fs, which is at least by three orders of magnitude smaller than the results achieved in prior work. The input and output impedances are equal to Z$_\text{in}$=73.2$\angle$80.7$^ \text {o}$ m$\Omega$ and Z$_\text{out}$=79.6$\angle$77.3$^ \text {o}$ m$\Omega$ respectively. A small mismatch remaining between the impedances prevents perfect reciprocity to be established in the system. A prototype IC has been taped out in TSMC 0.18 ¬µm BCD Gen2 technology.","zero-flow error; Ultrasonic measurements; Impedance matching","en","master thesis","","","","","","","","2022-02-26","","","","","",""
"uuid:52051ab7-c319-4a41-868c-1dd996cd7892","http://resolver.tudelft.nl/uuid:52051ab7-c319-4a41-868c-1dd996cd7892","Sound-recognition using Spiking Neural Networks","Proz√©e, Randy (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Signal Processing Systems)","van Leuken, T.G.R.M. (mentor); Kumar, S.S. (graduation committee); Zjajo, Amir (graduation committee); Al-Ars, Z. (graduation committee); Delft University of Technology (degree granting institution)","2021","The development of the Spiking Neural Network (SNN) offers great potential in combination with new types of event-based sensors, by exploiting the embedded temporal information. When combined with dedicated neuromorphic hardware it enables ultra-low power solutions and local on-chip learning. This work implements and presents a viable architecture and training methodology to detect and classify audio data using Spiking Neural Networks. The architecture consists of two core components: the first component is an auditory front-end that performs low-level feature extraction. The second component is the SNN classifier supported by the spike encoder and decoder. The results show that the encoder has a major impact on the overall performance of the network. The temporal-based network is trained with help of common training methods, both supervised and unsupervised. The performance of the network is validated under both clean and different levels of noisy conditions. The impact on classification performance is analyzed and compared with traditional non-spiking Artificial Neural Networks. This in terms of classification accuracy, estimate energy consumption, and latency of inference. The proposed architectures achieve a max accuracy of 97.0% under ideal conditions. This is comparable to other non-spiking artificial neural networks, which require significantly more energy for inference. The implementation demonstrates that the architecture is a viable solution for detecting and classifying audio data.","Soud-recognition; spiking neural networks; classification; low-power","en","master thesis","","","","","","","","2023-02-26","","","","Electrical Engineering | Circuits and Systems","",""
"uuid:a470acae-1238-4e47-a986-11fc69378f6b","http://resolver.tudelft.nl/uuid:a470acae-1238-4e47-a986-11fc69378f6b","Turbulent Viscous Drag Reduction in Air by Compliant Surfaces","Lai, Yu-Jui (TU Delft Aerospace Engineering)","van Oudheusden, B.W. (mentor); Schrijer, F.F.J. (mentor); van Nesselrooij, M. (mentor); Delfos, R. (graduation committee); Baars, W.J. (graduation committee); Delft University of Technology (degree granting institution)","2021","This research studies the fluid-structure interaction (FSI) of compliant surfaces in air flows, with an objective of finding possible turbulent viscous drag reduction. A compliant surface is a thin layer of viscoelastic material drawing inspiration from dolphin epidermis, which was thought to have drag-reducing capabilities by Gray (1936). Research into the drag reduction capabilities of compliant surfaces has been long going for more than five decades, starting with Kramer (1960), yet no firm conclusion has been reached. In addition, most of the experimental research has been focused on water flows, with air flows regarded as incapable of inertially forcing a compliant surface to deform. This research attempts to disprove this assumption by applying the proper inertial scaling to the FSI between the compliant surface and air flows. Compliant surfaces are characterised by the stiffness and thickness, which are presumed to be of first-order influence on the FSI. A parameter sweep of these compliant surface properties was conducted by drag delta measurements and flow visualisation by planar particle image velocimetry (PIV) in the M-Tunnel at the Low Speed Laboratory (LSL) Drag delta results confirm the possibility of turbulent viscous drag reduction by compliant surfaces, with a measured drag delta of -3.43 %. This result is further supported by the decrease in 1D turbulence intensity at the test plate's trailing edge from hot-wire measurements, and a smaller decay of the shape factor H from PIV. Quadrant analysis of the PIV data found evidence of a reduction in combined Q2 and Q4 events, further supporting the drag delta measured. Correlation between the compliant surface's viscoelastic properties and the drag delta found a negative correlation between the magnitude of complex shear modulus and a positive correlation between the loss tangent and drag reduction. The high loss tangent for the drag-reducing compliant surface and its subtle positive correlation with the drag reduction indicates that the viscoelasticity might have a greater influence on the FSI than expected.","Drag reduction; Turbulent boundary layer; Passive flow control; Compliant surface; Fluid-structure interaction; Quadrant analysis","en","master thesis","","","","","","","","2023-02-26","","","","Aerospace Engineering","",""
"uuid:97daa834-d189-433d-8c39-f7697f194d61","http://resolver.tudelft.nl/uuid:97daa834-d189-433d-8c39-f7697f194d61","Design and analysis of an optical system to detect changes in the optical payload on a Cubesat","Deshpande, Parth (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Precision and Microsystems Engineering)","Bhattacharya, N. (graduation committee); Cacace, L.A. (mentor); Botma, P.J. (graduation committee); Spronck, J.W. (graduation committee); Kappelhof, J.P. (mentor); Delft University of Technology (degree granting institution)","2021","Use of earth observation satellites have grown at a very high rate over the past few decades. On a closer observation of things around, most of them uses satellites, directly or indirectly. Satellites are being used in the day-to-day life without being aware of its application. Satellites are used for small things like weather report, communication to very large things like internet of things (IOT) and earth observation. Some CubeSats are also used for interplanetary missions. For the purpose of earth observation missions, the satellites are installed with an optical payload which is a camera. The cameras used for space are different from the regular camera and have special specifications in terms of the materials, components and the design which make them suitable for space missions. The optical payload which is to be launched has to be made sure that it can survive the launch and in orbit environment. This research focuses on the testing of these CubeSats and check if they are suitable for launch. The research starts with reviewing the testing procedure that is followed before the satellite is launched. A setup is provided for checking the performance of the camera mounted on the CubeSat and its suitability for launch. To investigate the performance of the camera, MTF and correlation techniques are used on different images to come to a conclusion.","MTF; Correlation; Space camera; CubeSat","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Mechatronic System Design (MSD)","Opto Mechatronics",""
"uuid:253bb213-7e23-4b59-9f82-9ac8414e29e0","http://resolver.tudelft.nl/uuid:253bb213-7e23-4b59-9f82-9ac8414e29e0","Developing Context and Culture driven Design Philosophy","Changavi Shiva Prasad, Sambhram (TU Delft Industrial Design Engineering)","van Boeijen, A.G.C. (mentor); Sonneveld, M.H. (graduation committee); Delft University of Technology (degree granting institution)","2021","As a part of JMP at TU Delft, we had the opportunity to design for implementation of sex education in Indonesia. We were unable to explore the culture of Bali together as a design team because of which we had our own assumptions, perceptions of what the culture is or could be. And most importantly in the project we had reduced a whole culture to a set of constraints we needed to design for. This was deeply troubling. So in order to tackle this issue of culture clash and the need to be sensitive to other cultures, this project was born. The cultural element of Japan and their design philosophy were an inspiration. Their design philosophy and culture are weaved together to form one coherent Japanese Design Philosophy. To address the cultural dilemma for designers, it was decided to bring design philosophies into this project so that one could frame design philosophies based on the culture they design for. The target group for this project was the Master‚Äôs design students of TU Delft from the Industrial Design Engineering department. The research began with understanding of existing design philosophies such as Japanese Design Philosophies, Bauhaus and De-Stijl movements, Buen-Vivir centric design model. These formed the basis on how the design philosophies manifested and how it was culturally connected with their respective cultures. Interviewing two design studios viz. Butterflyworks, Netherlands and Whitenoise Design, India gave an opportunity to understand the workings, the tools they used for designing and gave an in-depth understanding of their design philosophy. These case studies provided a strong basic understanding of design philosophy and when should one consider a design philosophy a design philosophy. Keeping this in mind, the next step was to see how one can frame design philosophies depending on a certain context and culture. This was executed by having design students from TU Delft undergoing co-developing sessions using sensitising material and insights from Cultura tool. Students from the sessions developed the design philosophies which were rooted to the context and the culture. These sessions were analysed to extract the process of developing design philosophies along with the content that required to develop the design philosophies. These inputs were further translated to toolkit requirements and interventions. This way a toolkit could aid the designers in developing culture and context driven design philosophies. The ideation for the toolkit began with ‚ÄòThe Card Set‚Äô which was tested with designers. Though it had some flaws, the participants were able to successfully develop design philosophies. A new concept ‚ÄòThe Board Set‚Äô was born which was much more refined. In order to make the interactions much more fun and meaningful, a third concept ‚ÄòThe Block Set‚Äô was developed. This involved exploration cards, blocks, response sheets. The designers would undergo initial exploration of self, culture and later develop the design philosophy as a team. This was surveyed with designers, who mentioned that the toolkit definitely provides moments of reflection and brings teams and cultures together without compromising on either of them.","Design Philosophy; Reflection; Culture; Teamwork; Exploration; Sensitivity","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:5c9b4c42-8fdc-4170-b978-f80cd8f00753","http://resolver.tudelft.nl/uuid:5c9b4c42-8fdc-4170-b978-f80cd8f00753","An OS-level adaptive thread pool scheme for I/O-heavy workloads","Timm, Jannes (TU Delft Electrical Engineering, Mathematics and Computer Science)","Rellermeyer, J.S. (mentor); Epema, D.H.J. (graduation committee); Katsifodimos, A. (graduation committee); Delft University of Technology (degree granting institution)","2021","Thread pools are a pervasive building block for concurrent applications, but their optimal size is often tedious to determine or it changes during execution. Many modern systems use dedicated thread pools for operations that are restricted to a specific resource (e.g IO-bound), their performance can be correlated to OS metrics such as disk throughput. We propose an OS-level adaptive scheme for disk-IO workloads that can act as drop-in replacement for such use cases. Our approach often performs close to optimally tuned fixed-size pools, while being prone to fluctuations in the chosen target metric. The results warrant further exploration of more sophisticated OS metrics and the development of more tightly integrated global in-kernel implementations.","thread pool; concurrency; operating systems; linux","en","master thesis","","","","","","","","","","","","","",""
"uuid:bc6bbb5f-c74c-4457-a9a8-09a847fbc951","http://resolver.tudelft.nl/uuid:bc6bbb5f-c74c-4457-a9a8-09a847fbc951","The interaction between a sonic transverse jet and an oblique shock wave in a supersonic crossflow: An experimental study","Dacome, Giulio (TU Delft Aerospace Engineering)","Schrijer, F.F.J. (mentor); van Oudheusden, B.W. (mentor); Delft University of Technology (degree granting institution)","2021","The development of air-breathing propulsion systems as a mean to propel high-altitude high-speed transport and single-stage-to-orbit (SSTO) vehicles promises to be a viable alternative to chemical rocket propulsion. In order to enhance mixing, an oblique shock wave is introduced into the combustion chamber as a source of baroclinic vorticity as well as a static temperature and pressure augmenter. An experimental campaign was conducted in the ST-15 supersonic test facility at Mach 2 to analyse the effect of three main control variables: the jet momentum flux ratio, the flow deflection angle and the impingement position of the shock on the jet plume. Measurements were acquired with Schlieren photography and stereo PIV techniques. Results suggest that, while near-field momentum-driven mixing remains unaltered following the introduction of the impinging shock wave, mid-to-far-field mixing mechanisms do change. An increase in the jet plume elevation was observed together with one in lateral expansion as a consequence of the introduction of a shock wave. Also, the formation of a strong shear layer downstream of the jet was observed, which acts as a source of vorticity to promote entrainment towards the jet mid-field. A stronger wave was noticed to produce more optimistic results for the mixing performance. This effect was seen to decrease with the introduction of a weaker shock or by shifting the strong shock downstream.","Mixing; supersonic; experimental; PIV; jet in crossflow","en","master thesis","","","","","","","","","","","","Aerospace Engineering | Aerodynamics","",""
"uuid:0fa88eaa-ef57-43d7-9312-ed82876da5fe","http://resolver.tudelft.nl/uuid:0fa88eaa-ef57-43d7-9312-ed82876da5fe","Towards Digital Twins in Healthcare: How would a meaningful Digital Twin for the user look like?","Strasser, Carla (TU Delft Industrial Design Engineering)","Bos-de Vos, M. (mentor); Mulder, S.S. (graduation committee); de Boer, Bas (graduation committee); Delft University of Technology (degree granting institution)","2021","Healthcare is starting to change fundamentally. One of the disruptive technologies that can be seen as an enabler for this change is the technology of a Digital Twin (DT). A DT is widely adopted in the field of engineering for predictive maintenance and testing of parameters of physical objectives such as engines to increase the effectiveness and optimize processes. A DT consists of three major factors: a physical object, its virtual representation and a continuous data stream between the two. In the healthcare sector this could mean to represent not an engine but a whole human with the potential goal for predicting a disease, taking necessary actions for prevention or identifying optimal treatments. This could shift the current underlying paradigm in medicine of curing a disease towards preventing a disease. The extent of representing a whole human body with this technology is still only a vision, but first steps towards this concept have been taken. This development may come with a lot of responsibility so that a user-centered perspective needs greater attention. This thesis aimed at unraveling users‚Äô values for a meaningful DT as innovative technology. By using the concept of Responsible Research in Innovation (RRI), I addressed the importance of grasping, anticipating, and evaluating the potential impact of a DT on the individual interview partners. In a first step, I identified the field of diagnosis as a central research topic with high importance for the user. The semi-structured interviews were conducted with a focus on the context of diagnosis and followed a practice-based approach of Interpretative Phenomenological Analysis (IPA). This allowed me to explore underlying values from the past into the future of diagnosis with and without DTs. A six-step analysis approach proposed by IPA led to the discovery of values embedded in the (anticipated) experience of diagnosis of the interviewees. Finally, the findings led to the development of different forms or concepts a DT could take. These are meant to start a reflection. The findings showed that the meaningfulness of a DT may change significantly by age, life situation, preferences or also individual personality. In contrast to current company visions which visualize a DT as dashboard overview of the human, I assumed that this may lead to an objectification of the body and might rather support the development of an alienate feeling. Furthermore, it might be that the possibility of constant confrontation of one‚Äôs own objective status of the body might rather have negative effects on the individual. Additionally, time, place and frequency an individual interacts with a DT seemed to play an important role and should be reflected upon. In order to complement the development of a more user-centered and meaningful DT, I concluded this work with nine guidelines that can be a starting point for further reflection on responsible innovation of a DT. Taken together, I showed that meaningfulness of a DT is highly variable and would need a dynamic, personalized approach to create and implement a meaningful and responsible innovation for the user.","Digital Twin; Healthcare; Responsible Research and Innovation","en","master thesis","","","","","","","","","","","","Strategic Product Design","Pride and Prejudice",""
"uuid:0451c073-c704-4e59-9306-6c1717b484c3","http://resolver.tudelft.nl/uuid:0451c073-c704-4e59-9306-6c1717b484c3","Direct Numerical Simulations of Boundary Layer Stability for Non-ideal Fluids","Christofi, Marios (TU Delft Mechanical, Maritime and Materials Engineering)","Pecnik, R. (mentor); Padding, J.T. (graduation committee); Boersma, B.J. (graduation committee); Bugeat, B. (graduation committee); Delft University of Technology (degree granting institution)","2021","The process in which a smooth laminar flow transits to a chaotic to a chaotic, turbulent state, is a topic of particular interest in the sectors of energy technology and aerodynamics. To study the different paths that can be followed during the transition process, various tools and methods have been developed. A preliminary investigation of the response of a laminar flow to an internal or external disturbance can be performed by applying Linear Stability Theory principles. In the recent years, the Direct Numerical Simulations of flows offer a more insightful method to study the transition process, since the flow fields are numerically solved using high computational power. Previous research has primarily focused on the stability and transition of Ideal Gas flows, with little attention to the effects of a highly Non-Ideal behaviour. The present work aims to develop a DNS code that can be used to investigate the stability of compressible boundary layers in the vicinity of theWidom Line. For the initialization of a DNS, a two dimensional base flow profile is required. For the calculation of the base flow, a self-similar solution is obtained, using a MATLAB script that has been developed for the purpose of this study. The DNS code is developed in FORTRAN. An inviscid characteristic wave analysis is utilized for the implementation of the boundary conditions, along with numerical sponges to avoid reflections. To trigger the instabilities, periodic suction and blowing is incorporated. For the simulations of non-ideal fluids, a thermodynamic table interpolation tool is incorporated. For the validation of the results obtained by the DNS code, an in-house MATLAB script is used to for the calculation of the growth rate and fluctuation amplitude profiles using LST. Initially, the FORTRAN code is used on ideal-gas simulations, to investigate how different computational parameters will affect the flow field. The parameters are related to mesh resolution, boundary conditions and numerical sponges. To investigate the stability of non-ideal fluids, cases of different free-stream temperatures and Eckert numbers are simulated. The free-stream temperature is altered to control the non-ideal gas effects, whereas the Eckert number is used to control the compressibility effects. In general, the flow is stabilized as non-ideal gas and compressibility effects become more prominent. However, a second unstable mode is observed in the case where the temperature profile crosses the pseudo-critical point. This second mode has a higher growth rate of instabilities, compared to the first mode. All the results are validated using the LST predicted profiles.","DNS; Direct; Numerical; Simulations; fluid; mechanics; compressible; flow; carbon; dioxide; supercritical; ideal; gas; stability","en","master thesis","","","","","","","","","","","","","",""
"uuid:fe77d69f-66cf-45e1-9eda-f1dc6c809dc0","http://resolver.tudelft.nl/uuid:fe77d69f-66cf-45e1-9eda-f1dc6c809dc0","Trailer Sway Stabilization by Active Control of the Towing Vehicle","Gunalan, Manish (TU Delft Mechanical, Maritime and Materials Engineering)","Shyrokau, B. (mentor); Delft University of Technology (degree granting institution)","2021","A combination vehicle system consists of a lead vehicle that powers the motion, and one or more trailers that are towed by the lead vehicle. Any such vehicle system is unstable due to the presence of a coupling joint that disconnects the driver from the trailer. The risk of an accident is increased since many trailer parameters are variable and change with operating conditions. In light combination vehicles where the towing vehicle is a passenger car or SUV, the situation is more serious because the driver is necessarily not skilled enough to perceive the effects of steering and braking actions on the response of the trailer. A method to stabilise the car-trailer system by controlling the actuators of only the towing car is presented. Although similar attempts have been made in the past, they have been limited by their scope of applicability. The main component of the sway stabilization system is the Sliding Mode Controller (SMC) that is robust and has a good transient performance. This controller is combined with a weighted least squares control allocation method to control the rear-wheel steering and the brakes of the towing car. The control allocation method provides flexibility and redundancy to the system. Based on simulations over different test cases, it is seen that the car-trailer system can be stabilised significantly, resulting in an improvement in the lateral handling characteristics, and reducing the chances of an accident occurring due to driver error. The thesis concludes by highlighting the advantages of the design and proposing recommendations for further improvement.","Trailer; articulated vehicle; Sway Stabilization","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Vehicle Engineering | Dynamics and Controls","",""
"uuid:1fa997b7-c286-4cf3-b3cc-4cfca7cf58f2","http://resolver.tudelft.nl/uuid:1fa997b7-c286-4cf3-b3cc-4cfca7cf58f2","Plastic Identification Anywhere: Development of open-source tools to simplify plastic sorting","de Vos, Jerry (TU Delft Industrial Design Engineering)","Diehl, J.C. (mentor); van Engelen, J.M.L. (graduation committee); Delft University of Technology (degree granting institution)","2021","Plastic pollution is a well-known problem worldwide, and is still growing. It negatively affects humans and wildlife through animal death, groundwater pollution and incorporation of micro plastics in our digestive system. There are many initiatives focusing on reducing the negative effects of plastic pollution, but the amount of plastic consumed and the subsequent pollution is still increasing every year. Additionally, in the current COVID-19 pandemic the dependency on single-use plastics has increased exponentially. That is why it is important to keep improving recycling infrastructure, especially in low and middle-income countries. Their plastic waste management is often informal, and tools are insufficient for the correct management of plastic waste, resulting in plastic pollution.The research conducted in this thesis showed that especially t he sorting stage of the plastic recycling process is very time consuming and labor-intensive. This discovery led to the central research question: which resources can be developed to accelerate the process of plastic sorting for informal recyclers? Discrete near-infrared spectroscopy makes it possible to identify over 75% of all plastic used in everyday life. Therefore, it became my mission to make this technology accessible to recyclers in low and middle-income countries. By applying principles of context variation, local manufacturing and open development in the design process, tools that accelerate the sorting of plastic waste were created. This brings Plastic Identification Anywhere another step closer, with the end goal of fighting plastic pollution, together, today. The project described in this paper resulted in a complete ecosystem of open-source resources (figure 1) that can be used to implement near-infrared spectroscopy in any plastic waste management setting, especially in low and middle-income countries. This ecosystem consists of: -A breakout board that combines all components to emit and sense infrared light on a small printed circuit board with standard communication protocols. -A handheld scanner that integrates the breakout board into real-world applications. It enables local machine-learning processing of the sample, all in a compact form factor. -A kit that delivers all the components for the breakout board in a small package with clear instructions on how to assemble a breakout board, making board building more accessible. -A website that informs (and inspires) all potential users about the Plastic Scanner, connecting those who want a Plastic Scanner to those who can build a Plastic Scanner. -Documentation that is published online in its entirety, to enable cooperative working and transparency. This also makes it possible to modify a Plastic Scanner to personal preference. -Software that communicates with the hardware and implements machine learning for optimal and quick prediction of plastic types.","Plastic recycling; infrared spectroscopy; open source","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:e9b551d8-8f2d-4ca3-b0b6-ea72330636d5","http://resolver.tudelft.nl/uuid:e9b551d8-8f2d-4ca3-b0b6-ea72330636d5","Shape Optimization of a Flapping Wing for the Atalanta Project FWMAV","Amer, Hakim (TU Delft Mechanical, Maritime and Materials Engineering)","Goosen, J.F.L. (mentor); Delft University of Technology (degree granting institution)","2021","Flapping Wing Micro Air Vehicle (FWMAV) technologies are emerging due to the vast number of applications that they can be utilized in. Researchers and scientists are constantly seeking to push the boundaries to the extreme in terms of miniaturization of this technology, making it smaller, lighter and better performing. In order to achieve this we need to look for new approaches in the design of FWMAVs at the component and at the system level. This research explores a new approach for the flapping wing design. Inspired by insects, the corrugation pattern on the wing can be optimized in order to achieve the required passive pitching behaviour of the wing. Optimized corrugated wings has the potential to achieve a higher strength to weight ratio than available flapping wing designs, while at the same time exhibiting the required passive pitching behaviour. Moreover, the manufacturing process of the wing is more reproducible compared to conventional wing manufacturing methods. This is important because at such a small scale, a minor deviation in the wing features can drastically affect the wing properties, which has implications on performance and control. In this study shell shape optimization method was utilized to obtain passively pitching wing designs. The obtained wing designs performance is then evaluated qualitatively and quantitatively, through a time dependant study of the flapping motion of the wing. Finally, a wing prototype is manufactured and the results are experimentally validated.","FWMAV; Optimization; Shell Structures; Bio-inspired design; Insect flight; Shape Optimisation","en","master thesis","","","","","","","","","","","","Mechanical Engineering | High-Tech Engineering","",""
"uuid:8bd63dec-b67b-496b-92bc-3d5c07ff859f","http://resolver.tudelft.nl/uuid:8bd63dec-b67b-496b-92bc-3d5c07ff859f","Conceptual Design of Hydrogen Fuel Cell Aircraft: Flying on hydrogen for a more sustainable future","Vonhoff, George (TU Delft Aerospace Engineering)","Oliviero, F. (mentor); van Benthem, Roel (graduation committee); Delft University of Technology (degree granting institution)","2021","The demand for air travel is increasing as more people gain access to commercial aviation. As the current generation of aircraft makes use of fossil fuel combustion, this growth results in an increase in the global emissions. This is at odds with the worldwide efforts of reducing the adverse effects of climate change. Therefore, advanced propulsion systems must be developed to limit the emissions caused by the commercial aerospace industry. Using hydrogen fuel cells for propulsion is a promising technology to potentially get the sector to zero emissions. It is of interest to explore the capabilities and feasibility of aircraft with a hydrogen fuel cell powertrain. To determine the feasibility for a wide range of aircraft, a general design methodology is required.Current research efforts focus on component level performance, however system level design research, while present, didn't introduce a general methodology. The most pressing challenge was found to be related to the system level design of a CS-23 category hydrogen fuel cell aircraft. The CS-23 category aircraft class has been identified as the most suitable focus for research efforts, due to the lower technical and certification requirements placed on the components to reach a feasible design. A general methodology for the design of CS-23 category aircraft was therefore found to be a useful contribution to the state of the art. This additionally provides a deeper understanding into the most important parameters of the power and propulsion systems design.In this report, a general methodology for the conceptual design of hydrogen fuel cell powered CS-23 category aircraft is presented. The methodology makes use of a modified class 1 weight estimation for initial sizing according to customer requirements and component technology levels. The generated aircraft is refined using further aerodynamic analysis, which results in a feasible aircraft concept, as well as component level specifications for important aircraft components.The methodology is implemented in a software tool, HAPPIE (Hydrogen Aircraft Power \&amp; Propulsion Initial Estimator), which allows for rapid sizing of different hydrogen fuel cell concepts. This makes the methodology accessible, and additionally provides feedback on the effects of individual design choices and technology levels on system level performance. SUAVE is used to perform the refined aerodynamic analysis.The methodology is validated using existing conventionally powered aircraft, by comparing the sizing results from the methodology with publicly available data. The methodology's ability to analyse conventional as well as hydrogen fuel cell powertrains, furthermore allows for performance comparison between current and future technologies.The results of the sizing methodology demonstrate the viability of hydrogen fuel cell aircraft in the CS-23 category. A conceptual design is generated, which serves as a baseline for the sensitivity analyses. It is found that hydrogen fuel cell aircraft are generally heavier than conventional aircraft, using current technology levels. Liquid hydrogen is identified as the best hydrogen storage method. Compressed hydrogen storage is also possible, however this results in a heavier aircraft with limited range. The current methodology does not predict thermal behaviour to have a significant effect on the mass of the aircraft. A component sensitivity analysis determined that the fuel cell efficiency, fuel cell specific power and hydrogen storage efficiency are the most important parameters.The ideal cruising altitude for fuel cell aircraft is at an intermediate altitude, due to the fact that the fuel cell powertrain performance decreases at increasing altitude, which balances with the lower drag in lower density air.The research demonstrates that hydrogen powered CS-23 aircraft are viable for current technology levels, and are a suitable way in reducing carbon emissions in this category.","Hydrogen; Fuel Cell; Sustainable Aviation; CS-23; Aircraft Performance; Aircraft Design; Aircraft Conceptual Design; Aircraft sizing; Design methodology","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:1c7943c4-fe28-4898-ad36-76118269d000","http://resolver.tudelft.nl/uuid:1c7943c4-fe28-4898-ad36-76118269d000","Predicting Infections in Preterm Infants with Thermal Imaging Technology","Wirianto, Erik (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Bio-Electronics)","French, P.J. (mentor); Rassels, K. (mentor); Theuwissen, A.J.P. (graduation committee); van der Helm, F.C.T. (graduation committee); Delft University of Technology (degree granting institution)","2021","Neonatal sepsis is a dangerous non-specific disease in babies, especially neonate/newborns. It is one of the leading causes of neonate mortality rate, because of the difficulty to diagnose, leading to late or false treatment. Previous research has found the promising feature of artificial intelligence or machine learning in solving the problem. After analysing hours of the electronic health record data available, they are able to diagnose sepsis condition on neonates. However, the accuracy and time needed before diagnosis are still concerning considering the risk of mistreated or late diagnosed sepsis cases. In this research, machine learning and thermal imaging technology is used to explore the possibility of predicting sepsis. 57 thermal videos from 26 babies are processed to track the highest skin temperature visible to the thermal camera. The temperature data then is utilized to train and test several machine learning models for predicting sepsis cases. Support Vector Machine (SVM) was found to be the best sepsis predictor using time-series variation of the temperature data as the feature. The model needs 10-30 minutes of thermal recording, 19 minutes in average, to predict sepsis and achieved 82\% accuracy. Simulation also shows the high possibility in increasing the accuracy when more data/thermal videos are available to train the model. High accuracy model with fast reacting sepsis prediction could help doctors precisely treat septic neonates in timely manner, decreasing the mortality rate for sepsis cases.","Neonatal sepsis; Machine learning; Thermal imaging","en","master thesis","","","","","","","","2024-12-31","","","","","",""
"uuid:c6b9227d-835c-4886-99b0-df4807fbdfc7","http://resolver.tudelft.nl/uuid:c6b9227d-835c-4886-99b0-df4807fbdfc7","Improving water surface current estimation from radar data","Bristogiannis, Yperion (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Delft Institute of Applied Mathematics)","van Gijzen, M.B. (mentor); Delft University of Technology (degree granting institution)","2021","The offshore industry can increase safety and efficiency during offshore operation by predicting actual wave induced ship-motions minutes ahead of time. By only using on-board equipment, such as the navigational radar, it is possible to deterministically predict incoming waves since the phase resolved<br/>description of the waves can be acquired. The accuracy of the speed with which the these waves travel can be improved by taking into account the water surface current velocity. The state of the art method on computing the water surface current velocity is based on the three-dimensional Fourier transform over a large number of radar images followed by a LLSQ fit. For real time wave prediction, collecting a large number of radar images can result in long start up times.<br/>This MSc thesis looks into an alternative method based of the polar Fourier tranform over fewer radar images, the conjugate product of the resulted spectra and a LLSQ fit. In addition, this thesis improves the method studied based on further work on the state of the art method found in literature. In the scope of this project the alternative method based on the polar Fourier transform is implemented as well as the suggested improvements. For evaluation, a comparison takes place between the alternative method and different approaches on the final part of the algorithm around the LLSQ fit. However, it is also shown that the goal, estimating the water surface current velocity, is potentially unachievable and the estimation of the effective velocity is proposed instead for the purpose of wave prediction.","sea current estimation; radar images; polar Fourier transform; LLSQ fit","en","master thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:55f6f319-f43f-458e-9df7-4311bd9cc81c","http://resolver.tudelft.nl/uuid:55f6f319-f43f-458e-9df7-4311bd9cc81c","Food as a culture carrier","Strzelczuk, Miko≈Çaj (TU Delft Architecture and the Built Environment)","van Zalingen, J.M. (mentor); Holst, J.P.G. (graduation committee); Smidihen, H. (graduation committee); Delft University of Technology (degree granting institution)","2021","Have you ever wondered what the food you eat everyday can tell you about where you come from? Have you ever wondered why people from different parts of the world eat different types of food? There is more connection between food and culture than you may think. On an individual level, we grow up eating the food of our cultures. It becomes a part of who each of us are. On a larger scale, food is an important part of culture. Traditional cuisine is passed down from one generation to the next. It also operates as an expression of cultural identity. Immigrants bring the food of their countries with them where cooking traditional food is a way of preserving their culture when they move to new places. <br/>With the influx of immigrants, cultural diversity in the city of Rotterdam has increased since the 1980s. More and more places where you could try foreign culture began to appear. This is Rotterdam, the city of diversity, the city of immigrants, who add both cultural richness and social encounter to this town. But as time goes by, exclusivity in the city Centre also progresses. Hot spots in Rotterdam are becoming more and more exclusive, which results in a slow displacement of cultural diversity.<br","Fenix; Rotterdam; Market","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Complex Projects","Complex Project",""
"uuid:f755b538-ce55-440e-947e-d08e224ac9b6","http://resolver.tudelft.nl/uuid:f755b538-ce55-440e-947e-d08e224ac9b6","Seawater Intrusion Modeling with Single Density Codes","Hatch, Nathan (TU Delft Civil Engineering and Geosciences)","Bakker, M. (mentor); Schoups, G.H.W. (graduation committee); van Breukelen, B.M. (graduation committee); Kraemer, S. (graduation committee); Delft University of Technology (degree granting institution)","2021","Seawater intrusion modeling is challenging either because of a lack of many approaches' ability to cope with complex environments or significant computational expense. Seawater intrusion models also face issues with parameterization and validation due to problems with many parameters and also a lack of observational data. Bakker and Schaars (2013) proposed a method to solve for the steady-state interface using a single-density flow model (MODFLOW). In this thesis, this method was applied to 3 existing coastal flow models and shown to be able to compute the steady interface. The work also contains examples of applying critical pumping solutions to the models to demonstrate its applicability as a management tool. The research also contains an effort to solve for an interface when the saltwater is moving but was ineffective. Modifications may be made to resolve the issues with the latter approach that could lead to a advances in interface modeling methods.","groundwater modelling; Saltwater intrusion; MODFLOW","en","master thesis","","","","","","","","2021-03-31","","","","","",""
"uuid:47d5dffc-d688-4c19-849a-875147bf1703","http://resolver.tudelft.nl/uuid:47d5dffc-d688-4c19-849a-875147bf1703","Self-sufficient living in agricultural heritage","B√ºno Heslinga, Annelijn (TU Delft Architecture and the Built Environment)","Koorstra, P.A. (mentor); van Dooren, E.J.G.C. (graduation committee); Delft University of Technology (degree granting institution)","2021","","","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences","",""
"uuid:337807a6-c5cf-453c-8f17-2e9ff1c336ef","http://resolver.tudelft.nl/uuid:337807a6-c5cf-453c-8f17-2e9ff1c336ef","Safety implications of the introduction of Autonomous Vehicles on rural roads: An agent-based modeling approach","Brouwer, Joey (TU Delft Technology, Policy and Management)","Warnier, Martijn (mentor); Annema, J.A. (graduation committee); Delft University of Technology (degree granting institution)","2021","With the increasing research of autonomous vehicles coming closer to introduction in society, it is necessary to research the effects on traffic safety for the introduction of these types of vehicles for rural roads. A lot of research has been done for the introduction of AVs on highway roads, researching the introduction for rural roads is the next step for the implementation of AVs in society. With this thesis the goal is to explore the traffic safety effects on rural roads with the help of agent-based modeling. An agent-based model was created to examine the effects of the penetration rate of AVs on traffic safety and how the characteristics of rural roads would affect traffic safety in this regard. Two main conclusions were drawn from the results. The first is that the introduction of AVs would lead to a lesser heterogeneity of speed between vehicles, this would in turn result in fewer casualties. The second conclusion is a conclusion drawn based on the emergent behavior of the model, the introduction of AVs would lead to less headway for AVs. Future research could be undertaken to study effects of overtakes on vehicle platoons.","AVs; rural roads; agent-based modeling; overtaking; Traffic safety","en","master thesis","","","","","","","","2021-02-12","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:4059fa74-78b7-4941-be61-595bfaf06dcc","http://resolver.tudelft.nl/uuid:4059fa74-78b7-4941-be61-595bfaf06dcc","Development of a temperature-based potential evaporation algorithm for supporting integrated and global-scale climate classifications","Touloumidis, D.T. (TU Delft Civil Engineering and Geosciences)","Coenders-Gerrits, Miriam (mentor); ten Veldhuis, Marie-claire (graduation committee); Delft University of Technology (degree granting institution)","2021","The assessment of potential evaporation or reference combined evaporation and transpiration is among the most important components for many hydro-climatic applications such as irrigation design and management, water balance assessment studies, and assessment of aridity classification indices. Aridity classification indices such as UNEP, Thornthwaite and others are usually employed at large scale applications and require respective estimations of potential or reference combined evaporation and transpiration. The major problem in such applications is not only the limited availability of stations per se but also the limitation of many stations to provide data for a complete set of parameters (i.e., precipitation, temperature, solar radiation, wind speed, humidity). A complete set of climate parameters is prerequisite for accurate estimations of potential or reference combined evaporation and transpiration using the most advanced methods, which are expressions of energy balance (e.g., ASCE-standardized method, successor method of Penman-Monteith FAO-56). Unfortunately, large scale applications of aridity indices suffer from this limitation and the common solution is to use temperature-based formulas. The most popular and historical temperature-based formula is the one of Thornthwaite, which was developed to support the respective aridity classification index. The popularity of this formula is based on the minimum requirement of mean monthly temperature and latitude at the location of interest. Considering the above, this study aims to develop a global database of local correction factors for the original Thornthwaite formula that will better support all hydro-climatic applications but mostly to support large scale applications of aridity indices, which are highly prone to data limitations. The hypothesis that is tested in this work is that a local correction factor that integrates the local mean effect of wind speed, humidity and solar radiation can improve the performance of the original Thornthwaite formula and to convert it at the same time to a formula of reference combined evaporation and transpiration for short reference crop. The global database of local correction factors was developed using gridded climate data of the period 1950-2000 at 30 arc-sec resolution (~1 km at the equator) from freely available climate geodatabases. The correction factors were produced as partial weighted averages of monthly ratios between the benchmark ASCE-standardized method for short reference crop versus the original formula of Thornthwaite by giving more weight to the warmer months and by excluding colder months of Epr&lt;45 mm month-1 where monthly ratios are highly unstable with unrealistic values. The validation of the correction factors was made using raw data from 525 stations of Europe, California-USA and Australia that cover periods mostly after 2000 and up to 2020. The validation procedure showed significant improvement in the estimations of reference combined evaporation and transpiration using the corrected Thornthwaite formula that led to a 19.4% reduction of RMSE for monthly and a 55% reduction of RMSE for annual estimations compared to the original formula. The variation of the correction factor was also investigated in different major K√∂ppen climate classes and it was found that tends to increase in drier and warmer territories. The five major K√∂ppen groups were ordered as follows B &gt; C &gt; A &gt; D &gt; E considering the magnitude of the correction factors values. The corrected and original Thornthwaite formulas were also evaluated by their use in UNEP and Thornthwaite aridity indices using as a benchmark the respective indices estimated by the ASCE-standardized method. The analysis was made using the validation data of the stations and the results showed that the corrected Thornthwaite formula increased by 18.3% the accuracy of detecting identical aridity classes with ASCE-standardized method for the case of UNEP classification, and by 10.4% for the case of Thornthwaite classification in comparison to the original formula. The performance of the corrected formula was extremely improved especially in the case of non-humid classes of both aridity indices. The overall results showed that the correction factors produced in this study can improve the performance of the original Thornthwaite formula providing better estimations of the aridity classification indices.","Reference Evaporation; Climate analysis; Thornthwaite","en","student report","","","","","","","","","","","","Water Management","",""
"uuid:58bc3434-251b-4a89-9ff7-5743742616fc","http://resolver.tudelft.nl/uuid:58bc3434-251b-4a89-9ff7-5743742616fc","Effect of sterilization on 3D printed patient-specific surgical guides","van Dal, Vito (TU Delft Mechanical, Maritime and Materials Engineering)","Harlaar, J. (mentor); Bemelman, M. (mentor); Zhou, J. (graduation committee); Heyligers, J. (mentor); Brouwers, L. (mentor); Delft University of Technology (degree granting institution); Universiteit Leiden (degree granting institution); Erasmus Universiteit Rotterdam (degree granting institution)","2021","Background The current workflow for the design and production of patient-specific surgical guides at the Elisabeth-TweeSteden hospital is out-sourced to external companies, making it a time-consuming and costly task. In order to minimize the production time and expenses, the design and fabrication of these guides could be implemented into the hospital‚Äôs workflow using an in-house available 3D printer. Compared to the current gold standard for the production of patient-specific surgical guides, a different printing technique and 3D print material will be used. Therefore, it should be determined whether these are suitable for the production of the guides. Moreover, the 3D printed models must be compatible with the in-house sterilization method in order to ensure quality and reliability. The aim of this thesis was to investigate the effect of the in-house available sterilization method on the mechanical, dimensional, and sterility properties of a novel biocompatible 3D printing material. Methods and results BioMed Clear resin specimens were tested according to the ISO standards for mechanical testing of plastics. Overall, steam sterilization changed the mechanical properties of the material, making it stronger and stiffer but more brittle, as compared to unsterilized specimens. The dimensional tests indicated that sterilization resulted in a dimensional change, up to 0.12 mm, which mostly occurred in the small crevices of the model. The deviations of the dimensions of the resulting 3D printed model compared to the digital 3D model were roughly less than 0.3 mm, which is comparable to the accuracy of the gold standard material, polyamide 12. Sterility tests showed that sterilization of the 3D printed models is indeed mandatory for the guides to be used intraoperatively. Also, the Central Sterile Services Department of the hospital is able to deliver sterile medical devices that can be stored for a minimum of four weeks at the sterile storage room. Conclusion With the feasibility confirmed for the hospital to be able to design and produce patient-specific surgical guides in-house, it is necessary to stress that the hospital must meet the Medical Device Regulations by complying with an appropriate quality management system, documenting the manufacturing process, evaluating the performance, and reviewing the experiences from clinical use.","3D Printing; patient-specific; surgical guide; Sterilization","en","master thesis","","","","","","","","","","","","Technical Medicine | Imaging and Intervention","",""
"uuid:5a3b7590-bca5-46bd-ab4c-842cbe992a41","http://resolver.tudelft.nl/uuid:5a3b7590-bca5-46bd-ab4c-842cbe992a41","High Throughput Parallel Computation with High Bandwidth Memory on FPGA","Dumont, Joep (TU Delft Electrical Engineering, Mathematics and Computer Science)","Al-Ars, Z. (mentor); Hoozemans, J.J. (mentor); Hofstee, H.P. (graduation committee); Rellermeyer, Jan S. (graduation committee); Delft University of Technology (degree granting institution)","2021","With the increase of available storage bandwidth, CPUs can not keep up with the compute throughput needed to process this amount of incoming data. GPUs and FPGAs are generally better suited for such tasks. To assist FPGAs in their functions, some boards are equipped with one or more high bandwidth memory (HBM) stacks, with a bandwidth of 230 GB/s each. This thesis presents a hardware design for the Alveo U280 FPGA board with HBM. Each HBM stack provides multiple interfaces to the full range of memory within HBM. Utilizing these multiple interfaces, a hardware decompressor for the Snappy compression algorithm is placed in parallel to achieve a higher end-to-end throughput. Additionally a design is created to perform benchmarks on HBM where varying sizes of data are transported between HBM and logic within the FPGA. The hardware decompressor and component that interfaces to memory within HBM were found to be incompatible and required additional logic to become able to transport data between them. To ease the parallelization of the decompressor a custom Snappy framing format is implemented. Using this format a softcore processor on the FPGA is able to buffer the locations of compressed data within HBM and divide these over available decompressors. The design is successfully synthesized into a kernel that can be loaded by the FPGA. From the moment compressed data is sitting in HBM until it is decompressed, a single decompressor reaches a maximum end-to-end throughput of 4.0 GB/s. When eight or more decompressors are activated, they reach a throughput between 20.0 to 26.2 GB/s. The hardware decompressor designs uses less than 10% of the resources of the U280 with little power usage. Compared to a software implementation, using multithreading, the hardware solution is 1.5-2.5x faster on a set of files that is used for benchmarks on decompression speed with varying compression ratios.","FPGA; parallel; decompression; snappy; HBM","en","master thesis","","","","","","","","","","","","Electrical Engineering | Embedded Systems","",""
"uuid:83e1f56b-40b8-44fe-9372-9eb3b52a70fa","http://resolver.tudelft.nl/uuid:83e1f56b-40b8-44fe-9372-9eb3b52a70fa","Secondary Nodes within the Densifying Inner-city of Rotterdam","Souren, Lotte (TU Delft Architecture and the Built Environment)","Holst, J.P.G. (graduation committee); van Zalingen, J.M. (mentor); Delft University of Technology (degree granting institution)","2021","The idea of mobility nodes has been migrated and developed over time. A lot of research has been focused on those (inter)national nodes of a train station, this article is focused on the ‚ÄòSecondary Nodes‚Äô. Those regional nodes, of multiple transportation flows, are situated in densifying metropolitan cities. In Rotterdam, the Node Beurs is situated in the inner-city and contains a junction of traffic flows of the metro, tram, bus, ferry, car, pedestrian and bike. Prospects indicate that the rising densification, leads to almost double amount of people using the metro at Beurs. At the moment Beurs is already an overloaded and fragmented node that forms a barrier within the urban tissue. While the Node Beurs has the potential to be a clear entrance to the inner-city and guide the traffic flows that cope with the capacity increase. The Node also has the potential to be part of the patchwork of public spaces, adding to the public floor-line of Rotterdam. Generating a multiple leveled open space and place to stay, with leisure, shops and other facilities. The project is establishing new urban connections, as well as strengthen the existing once by interweaving the hard infrastructure with the soft program and public space by making it pedestrian-oriented. The main goal of this architectural project is creating a new entrance that functions as a gateway to the inner-city, connecting the surrounded neighbourhoods, unravel the flows and directly connect the different types of transport. As well as it is an area that gives breathing space to the densifying city. The multiple leveled square function as a social place where people meet and are invited to explore the daylight perforated underground world. The recognizable entrances adding to the human scale and add to the local and regional character. As well as the pillars influence the local climate, by giving shelter for the rain and heat, function as a sounding board translating the weather to the underground area. The flexibility of the transport hub is key for future developments, as the underground is already quite full, there is still some room to extend the entrance or bike facility or add an extra metro line possibly. Interweaving, perforating and breaking the underground open, increase the accessibility and mobility of the secondary node Beurs and the inner-city itself.","Stations; Rotterdam; Mobility hub","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Complex Projects","",""
"uuid:ff4c0f1c-5cc1-41f8-96ef-3ca62ece82e5","http://resolver.tudelft.nl/uuid:ff4c0f1c-5cc1-41f8-96ef-3ca62ece82e5","The effect of IMC bus charging behavior on the trolleygrid","Eggermont, Rik (TU Delft Electrical Engineering, Mathematics and Computer Science)","Chandra Mouli, G.R. (mentor); Diab, I. (graduation committee); Bauer, P. (graduation committee); Cvetkovic, M. (graduation committee); Delft University of Technology (degree granting institution)","2021","We are in the middle of a transition to zero-emission mobility. The European Union has set high targets for zero-emission bus sales. Many European local governments and public-transit operators are looking to replace their GHG-emitting diesel/gas bus fleets with clean alternatives. One such alternative is In Motion Charging (IMC) technology for trolleybuses. With this technology trolleybuses are able to charge an on-board traction battery whilst in motion and connected to the overhead wires. This makes it possible for these buses to extend their range outside the trolleygrid infrastructure. These IMC buses can replace diesel/gas buses. IMC is of particular interest for municipalities that currently have a functioning trolleybus fleet and infrastructure. Existing infrastructures are however not built with the increased power demand of IMC buses in mind. A good understanding of the power demand of IMC buses and the limits of a trolleygrid is necessary before implementing IMC buses. The explanatory research that is presented in this report aims to give insight in the design factors that influence the feasibility of adding in-motion charging buses to an existing trolleybus network. It does so by first explaining the difference in energy consumption between IMC buses and regular trolleybuses through simulations. Next, by performing a case study on the Arnhem trolleygrid the effect of IMC buses on the trolleygrid is discovered. The results of the energy consumption comparison indicate that there is promising potential for IMC implementation. It shows that there is a large margin in which IMC buses can make more efficient use of their regenerative energy compared to their regular trolleybus counterparts. It also shows that there are large degrees of freedom in IMC bus implementation leaving room for errors. The Arnhem case study uncovers where exactly these errors lie by looking at potential power demand, minimum voltage and maximum current limit breaches on the network. As long as these breaches can be mitigated through smart charging strategies there is a lot of promise for IMC bus implementation on existing trolleygrid infrastructures.","IMC; Trolleybus; Electric mobility; In Motion Charging; Dynamic charging","en","master thesis","","","","","","","","2023-02-19","","","","","",""
"uuid:75c6790f-7faa-4831-91e4-6dd6b0fcb92c","http://resolver.tudelft.nl/uuid:75c6790f-7faa-4831-91e4-6dd6b0fcb92c","Machine Learning-based Classification of Different 3D Point Cloud Data of Railway Environments using Random Forest and DGCNN","PAPALEXIOU, ANNIE (TU Delft Civil Engineering & Geosciences; TU Delft Geoscience and Remote Sensing)","Lindenbergh, R.C. (mentor); Glassmeier, F. (mentor); Nunez, Alfredo (mentor); Vo√ªte, R.L. (mentor); Delft University of Technology (degree granting institution)","2021","Although monitoring and maintenance of railways is important to ensure safety and avoid delays and financial losses, it is still mainly based on human inspection. The complexity of a railway along with the large area it extends makes manual monitoring difficult and time-consuming. The increasing availability of 3D acquisition technologies has made point clouds a widely used 3D data form. Thus, identifying the key components of a railway and its environment using 3D point cloud data can be the first step for automating this procedure. The past years, machine learning has become the most popular subfield of artificial intelligence used for various different applications, with its subfield of deep learning evolving dramatically. Although deep learning has been vastly researched on 2D data, applying deep learning on 3D point clouds can be challenging due to the irregularity, unstructuredness and unorderedness of such data. To overcome those challenges, recent approaches use projection or voxelization, while the latest methods focus on working directly on raw point cloud data.<br/><br/>In the present research, 2 machine learning methods are implemented to classify 3D point cloud data of railway environments into 7 categories of rails, sleepers, track bed, masts, overhead wires, trees and other. To this end, the ensemble method of Random Forest, and the deep learning method of DGCNN (Dynamic Graph Convolutional Neural Network) are implemented. While Random Forest is a simple and handy ensemble algorithm used for a wide range of applications, DGCNN is a deep learning method based on PointNet, the pioneer method on raw point clouds, and graph CNNs. The methods are validated under 3 case studies, produced by structure from motion photogrammetry, airborne laser scanning and terrestrial laser scanning, and locating in 2 different areas within the Netherlands. For each method, 2 scenarios are developed for classifying colored and uncolored point clouds, respectively. Finally, the 2 methods are combined for the first scenario, as a first attempt to further improve the final results. <br/> <br/>The obtained results show that, in this work, DGCNN performs better than Random Forest, and both methods approximate state-of-the-art performance. The contribution of colors is important to improve both the overall accuracy of the models, as well as the classification results of the individual classes. More specifically, Random Forest scenario 1, Random Forest scenario 2, DGCNN scenario 1, DGCNN scenario 2, and the combination of Random Forest and DGCNN scenario 1 result in an overall accuracy of 88.65%, 83.39%, 89.19%, 88.20% and 90.57%, respectively. The corresponding per class F1-scores for all methods and scenarios range between 43% and 94%. Both methods meet difficulties in generalizing on data from different sensor systems and different areas with very different point density and missing data. Nonetheless, the individual methods are already very promising, while they are able to achieve the required accuracy of more than 90% when combined.","Classification; 3D point cloud; Machine learning; Deep learning; Random Forest; DGCNN; Railway","en","master thesis","","","","","","","","2023-02-25","","","","","",""
"uuid:a39110c4-63c9-493d-9eff-cb66e90e358d","http://resolver.tudelft.nl/uuid:a39110c4-63c9-493d-9eff-cb66e90e358d","Understanding wrinkle formation in roll-to-roll top encapsulant production process for thin-film solar cells: Modelling approach","Alkanbar, Tarek (TU Delft Electrical Engineering, Mathematics and Computer Science)","Smets, A.H.M. (graduation committee); Limodio, G. (graduation committee); Khadikova, Ekaterina (mentor); Lekic, A. (graduation committee); Manganiello, P. (graduation committee); Delft University of Technology (degree granting institution)","2021","Thin-film flexible solar panels can be utilized on many surfaces where conventional solar panels are hard to be used such as side walls of buildings, ship roofs or curved surfaces. In conventional solar cells, glass is used to protect the panels from external damage. However due to its heavy weight and rigidity, glass is not an option for thin-film flexible solar cells. HyET Solar, a company based in the Netherlands that produces flexible thin-film solar cells uses a transparent foil produced using a roll-to-roll process to encapsulate and protect their solar panels. In order to reduce the amount of materials used and cut the costs, a thinner foil is being developed. Producing the thinner foil in a roll-to-roll process causes different defects in the foil, among which half sinusoidal waves forming mostly in the bottom side of the foil, these waves are called wrinkles. The process of manufacturing the top encapsulant layer involves changing temperatures and mechanical stresses applied on the foil. Therefore, two models were developed to understand the effect of three process parameters (web force, web speed and temperatures of each production zone) on wrinkle formation. First, a thermal model of the process using ANSYS program was developed to understand the temperature profile of the produced foil along the process. Then, a mechanical model that uses the output of the thermal model and the applied mechanical forces to study the effect of the investigated production parameters on wrinkle formation was worked out. The results show that operating at higher temperatures and reducing the thickness of the foil are directly responsible for decreasing the threshold of the critical stress that causes wrinkle formation and thus reducing the range and the magnitude of the force to 1.4 N is needed to perform the process without forming wrinkles in the foil. Varying web speed between 0.3 m/min and 3m/min is found to have a minor effect when varied under high temperatures. Finally, decreasing the temperature of the first and second zones by 10 ¬∞C is found to extend the range of the web force that can be applied. Performing the process under lower temperatures or reducing the mechanical forces that act on the foil will reduce wrinkle formation in the developed foil; web speed should not be considered in mitigating wrinkle formation.","Flexible solar cells; Top encapsulant; Wrinkling","en","master thesis","","","","","","","","2023-02-25","","","","Mechanical Engineering","",""
"uuid:61bd4444-7ea6-4677-a02a-30f3b93b1d0d","http://resolver.tudelft.nl/uuid:61bd4444-7ea6-4677-a02a-30f3b93b1d0d","Topology Optimization of Launcher Structures under Multiple Critical Load Cases","Bharteeya, Siddharth (TU Delft Aerospace Engineering)","Guo, J. (mentor); Turteltaub, S.R. (mentor); Vleugels, Dieter (mentor); Giovani Pereira Castro, S. (graduation committee); Delft University of Technology (degree granting institution)","2021","The launch vehicle industry is undergoing a major shift as new commercial organizations are staking claim to large market shares with bold technologies. To stay competitive in this new era, launch vehicle companies must develop new technologies to reduce launch costs while serving the growing demand for space accessibility. A possible solution is to use additive manufacturing in combination with topology optimization to relieve manufacturing and assembly burdens in addition to reducing launch mass. Topology optimization is a mathematical method that optimizes the distribution of material in a design domain for a given combination of loads, boundary conditions and constraints with the objective of maximizing mechanical performance. Now an increasingly popular design tool in the aerospace and automotive industries, topology optimization is used to redesign structures to reduce mass while increasing stiffness. To effectively apply this design tool to launcher structures, the optimization process must take into account multiple load cases to represent the large number of load cases such structures are subjected to, throughout the various flight phases. In this thesis, a design methodology was established for topology optimization of launcher structures under multiple load cases by redesigning a launcher structure produced by Airbus Defence and Space Netherlands. The thesis used two analytical models; a simple cantilever beam model to set baseline expectations of design methodologies which were then verified on the launcher structure demonstrator model. To achieve the objective, a suitable multiple load case objective function was identified for the design problem at hand by testing different objective functions on both analytical models. In the process, efficient ways to accommodate the large number of load cases in the objective were also studied through which promising methods to reduce the number of load cases were identified. The final optimized design was compared to the original launcher structure which showed that the optimized design exhibited organic design features, higher stiffness with the same mass. This thesis provided insight into multiple load case topology optimization which is expected to accelerate its adoption in the launch vehicle industry and pave a new path for more efficient space travel.","Topology Optimization; Multiple Load Case; Multi-Objective Optimization; Launch Vehicle","en","master thesis","","","","","","","","2026-02-24","","","","Aerospace Engineering","",""
"uuid:d7004ec3-ad9f-4a3f-a710-522c3f76559d","http://resolver.tudelft.nl/uuid:d7004ec3-ad9f-4a3f-a710-522c3f76559d","Applicability of a modular powerplant with alternative fuels: A case study to determine the impact on ships operation capabilities and power plant performance, when using a modular power plant for a 2999 gross tonnage general cargo concept ship","Pik, Harmen (TU Delft Mechanical, Maritime and Materials Engineering)","de Vos, P. (mentor); Hekkenberg, R.G. (graduation committee); Miedema, S.A. (graduation committee); Linskens, Harry (mentor); Delft University of Technology (degree granting institution)","2021","This paper examines a case study to determine the effects on system performance of the power plant and ship operational capabilities, this case is a ship designed by the company DEKC. It is a small general cargo vessel of 2999 GrT (Gross Tonnage) called the Future Trader. The ship design is finished and the ship will be equipped with a modular power plant and fuel storage on the aft of the ship. In total four different power plants will be compared. The first is the base line system, this consists of a single internal combustion engine fuelled by Marine Diesel Oil (MDO). The three other systems will be modular systems. They all use the concept of distributed generation. There is looked into a system with three internal combustion engines fuelled by MDO. Besides this there are two fuel cell systems. Each consists of two separated fuel cells and one uses hydrogen and the second ammonia as fuel. For those systems mathematical models are created to compare three modular power plants to each other and to a base line. With those models the effects on the Future Trader's range, fuel costs (operational capabilities) and emissions are researched. A modular power plant is installed on the aft of the ship, constructed of four power packs each in a Twenty foot Equivalent Unit (TEU). The four systems will be simulated on four voyages and the results will be normalised with respect to the first setup. It can be concluded that a modular system with the concept of Distributed Generation (DG) will reduce the ships overall performance in comparison to the single engine diesel electric system (base line). When reviewing the fuel cell systems with respect to the base line system it is found that the ammonia fuel cell system has zero emissions and it still offers a sufficient range. The increases in fuel costs are lower than that of the hydrogen fuel cell system. Hydrogen will also reduce harmful emissions to zero but the reduction in range is more severe. The increase in fuel costs is also significantly higher than for the base line. Overall ammonia seems the most promising of the non hydrocarbon fuels. The DG system is also useful as long as emission regulations remain unchanged. The MDO DG system can be loaded for large distance voyages and hydrogen can be loaded for short voyages if desired.","Ships operation capabilities; Power plant systems; Distributed generation; Mathematical modelling; Modular shipping; Alternative fuels","en","master thesis","","","","","","","","","","","","Marine Technology | Marine Engineering","",""
"uuid:dfdad923-1fbd-44be-9ddc-3dceabd7598f","http://resolver.tudelft.nl/uuid:dfdad923-1fbd-44be-9ddc-3dceabd7598f","Determining the effects of a hydropower dam and climate change on salt intrusion in the Gambia estuary up to 2100","van der Scheer, Bor (TU Delft Civil Engineering and Geosciences)","Rutten, M.M. (mentor); Luxemburg, W.M.J. (graduation committee); Wang, Zhengbing (graduation committee); Savenije, Hubert (graduation committee); Simpson, Brent (graduation committee); Delft University of Technology (degree granting institution)","2021","Due to climate change, temperatures are rising worldwide resulting in sea level rise, higher evaporation and possible changes in precipitation patterns. These effects of climate change influence salt intrusion, particularly by affecting the freshwater supply. In The Gambia also a planned hydropower dam and possibly future irrigation development will affect the freshwater supply. The combined effects of climate change, the hydropower dam and irrigation development on salt intrusion are unknown. A river south of The Gambia, the Casamance, turned strongly hypersaline during the Sahelian droughts, which strongly affected the rivers discharge in the early 80s. The freshwater supply in the Casamance after these droughts was insufficient to flush away the salt and the estuary never restored. This led to the decay of the entire ecosystem that existed in and around the Casamance. The Gambia river is of major importance to the country, the agricultural sector relies on the freshwater it supplies for growing crops, the fishing industry relies on sufficient numbers of fish to catch and the forestry industry makes use of the mangroves growing around the river. All these industries combined account for ¬±75% of the working force in The Gambia. If the Gambia estuary turns strongly hypersaline such as the Casamance, this would have disastrous results. This thesis aims to clarify the effect that climate change, the hydropower dam and irrigation development have on salt intrusion in the Gambia river. A 1D model, SALNST, is used to model salt concentrations over the river length up to the year 2100. The effects of climate change, the hydropower dam and irrigation development are represented by four model parameters: climate projections, sea level rise, dam operations and irrigation development. Multiple parameter values, ranging from mild to strong conditions or impact are implemented, creating a set of 27 scenarios. These scenarios treat the parameters independently to distinguish the individual parameters effect on salt intrusion. It can be concluded that The Gambia is prone to climate change when considering salt intrusion. Due to the importance of the river, monitoring sea level rise and the development of climate change will be essential for planning and taking counter measures. Understanding the effects that climate change can have regarding salt intrusion can also be used in negotiations to reserve some freedom in the hydropower dam operations. In addition, solutions that limit the increase in evaporative surface for strong sea level rise (e.g., dikes along a part of the Gambia river) prevent extreme salt intrusion lengths and hyper salinity. The hydropower dam causes a reduced range of salt intrusion lengths, this creates easier to predict salt concentrations which is beneficial for aquaculture. Furthermore, the reduced maximum salt intrusion is also beneficial for agriculture that makes use of irrigation.","Salt Intrusion; climate change; 1D Model","en","master thesis","","","","","","","","","","","","Water Management | Hydrology","","13.4457859,-15.3061209"
"uuid:b79bbfa7-0c57-4949-b974-83a7d9ee6b39","http://resolver.tudelft.nl/uuid:b79bbfa7-0c57-4949-b974-83a7d9ee6b39","Scalable GPU Acceleration for Complex Brain Simulations","Engelen, Max (TU Delft Electrical Engineering, Mathematics and Computer Science)","Al-Ars, Z. (mentor); M√∂ller, M. (graduation committee); Stydis, Christos (mentor); Negrello, Mario (graduation committee); Delft University of Technology (degree granting institution)","2021","Complex mathematical models are used in computational neuroscience to stimulate brain activity to understand the biological processes involved. The simulation of such models is computationally costly, and thus highperformance<br/>computing systems are selected as a potential solution to increase performance.<br/>This thesis aims to implement a new versatile, multi-GPU eHH simulator (mgpuHH), explore its performance and make general observations on performance scalability over different modeling and cluster configuration properties. This work offers a multinode multi-GPU solution that offers excellent<br/>scalability performance due to how the simulator is constructed, with the use of OpenMPI and CUDA. The simulator is configured with JSON configuration files, containing the neural descriptions and simulatorspecific settings. Consequently, enabling a userfriendly environment, for the neuroscientists, without the need of recompiling or understanding the source code. The gap junction calculations are identified as the critical function bottlenecking performance of the simulator. Therefore, an algorithm tailored to utilize GPU performance is implemented to decrease wallclock time for these specific calculations. For internode<br/>communication, OpenMPI can be configured in two ways. Eiter share all possible compartments potentials with every node in the network or only share the compartments potentials to nodes that need them. These methods rely internally on MPI Allgather and Alltoallv respectively. When available, GPUDirect, NVlink, and RDMA are supported. The implementation hides communication overhead, when possible, by concurrently executable compute kernels. A neuron model from the Inferior Olivary Nucleus is selected for benchmarking. Reported results go up to 32 Nodes with a total of 64 GPU cards. The design shows linear weak and strong scaling within the experimental setups for intranode and internode scalability. With this simulator, networks over 10 million cells become available to model on largescale GPU clusters, setting a new standard for eHH simulations. Comparisons against related work on CPU and FPGAs have been conducted, a 100x speedup is achieved versus a single cpu threaded solution. Furthermore, a 2x speedup is achieved over an FPGA solution (flexHH) and 10 fold over a multithreaded CPU (GenEHH, with 128 threads) solution, both reported speedups are for a fully connected network with 7000 IO cells.","","en","master thesis","","","","","","","","","","","","Computer Engineering","",""
"uuid:e418ca00-6aa1-4255-9eb2-a837f155871f","http://resolver.tudelft.nl/uuid:e418ca00-6aa1-4255-9eb2-a837f155871f","Distributed and Asynchronous Algorithm for Smooth High-dimensional Function Approximation using Orthotope B-splines","Meyer, Johann (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Aerospace Engineering)","de Visser, C.C. (mentor); Al-Ars, Z. (graduation committee); Mulder, M. (graduation committee); Delft University of Technology (degree granting institution)","2021","Aircraft are complex systems with, in some cases, high-dimensional nonlinear interactions between control surfaces. When a failure occurs, adaptive flight control methods can be utilised to stabilise and make the aircraft controllable. Adaptive flight control methods, however, require accurate aerodynamic models - where first-order continuity is necessary for estimating the control derivatives and mitigating chattering that can reduce the longevity of components. Additionally, high-dimensional offline model identification with current approaches can take several hours for a few dimensions and this means model iterating and hyper-parameter tuning is often not feasible. Current approaches to smooth high-dimensional functional approximation are not scalable, require global communication between iteration steps, and are ill-conditioned in higher dimensions. This research develops the Distributed Asynchronous B-spline (DAB) algorithm that is more robust to ill-conditioning, due to low data coverage, by using first-order methods with acceleration and weighted constraint application. This algorithm is also suitable for continuous state-spaces. Smooth aerodynamic models can be determined in exactly nŒár iterations, where r is the number of continuity equations in a single dimension and n is the number of dimensions. Moreover, memory reorganisation is proposed to avoid false sharing and conflict-free use of shared memory on the GPU to ensure that the algorithm runs efficiently in parallel.","Smooth High-dimensional Linear Function Approximation; Linearly-constrained Convex Quadratic Programming; Asynchronous Algorithms; Parallel Algorithms; Multivariate B-spline; System Identification; GPU; Cache-aware","en","master thesis","","","","","","Double degree in Aerospace and Computer Engineering","","2026-02-24","","","","","",""
"uuid:fcef2325-4c90-4276-8bfc-1e230724c68a","http://resolver.tudelft.nl/uuid:fcef2325-4c90-4276-8bfc-1e230724c68a","Deep Reinforcement Learning for Flight Control: Fault-Tolerant Control for the PH-LAB","Dally, Killian (TU Delft Aerospace Engineering; TU Delft Control & Simulation)","van Kampen, E. (mentor); van Paassen, M.M. (graduation committee); Hulshoff, S.J. (graduation committee); Sun, B. (graduation committee); Delft University of Technology (degree granting institution)","2021","Fault-tolerant flight control faces challenges as developing a model-based controller for each unexpected failure is unrealistic, and online learning methods can handle limited system complexity due to their low sample efficiency. In this research, a model-free coupled-dynamics flight controller for a jet aircraft able to withstand multiple failure types is proposed. An offline-trained cascaded Soft Actor-Critic Deep Reinforcement Learning controller is successful on highly coupled maneuvers, including high-bank coordinated climbing turns. The controller is robust to six unforeseen failure cases, including the rudder jammed at -15¬∞, the aileron effectiveness reduced by 70%, a structural failure, icing and a backward c.g. shift as the response is stable and the climbing turn is completed successfully. Robustness to biased sensor noise, atmospheric disturbances, and to varying initial flight conditions and reference signal shapes is also demonstrated.","Deep Reinforcement Learning; Fault Tolerant Control; Intelligent Flight Control; Machine Learning; Flight Control Systems","en","master thesis","","","","","","","","","","","","Aerospace Engineering | Control & Simulation","",""
"uuid:9052e394-a518-4b03-95cd-c31d9e9065c4","http://resolver.tudelft.nl/uuid:9052e394-a518-4b03-95cd-c31d9e9065c4","Predicting the effects of ankle-foot orthoses on the gait of patients with calf muscle weakness: A predictive forward dynamics simulation study","Kiss, Bernadett (TU Delft Mechanical, Maritime and Materials Engineering)","Harlaar, J. (mentor); Seth, A. (mentor); Smit, G. (graduation committee); Happee, R. (graduation committee); Waterval, N.F.J. (graduation committee); Delft University of Technology (degree granting institution)","2021","Various neuromuscular disorders such as spinal cord injury, Charcot-Marie-Tooth disease and poliomyelitis lead to calf muscle weakness, which limits the patient's ability to propel their body forward during gait. Their abnormal gait pattern is characterized by increased ankle dorsiflexion, excessive knee flexion during stance and reduced ankle push-off power which leads to decreased walking speed and increased energy cost of gait. To improve walking ability, dorsal leaf spring (DLS) ankle-foot orthoses (AFOs) are often worn that provide stiffness around the ankle joint which is its most important characteristic. Selecting optimal AFO stiffness is important because it can substantially reduce the net metabolic cost of gait, while improper AFO stiffness can lead to discomfort, fatigue and overall reduced activity. Experimental data shows that the effect of AFOs is dependent on the individual characteristics of the patients, such as level of muscle weakness, spasticity and body mass. Despite the importance of AFO stiffness, empirically determining the stiffness of the applied AFO remains time-consuming and ad hoc. This master thesis aims to uncover the mechanism relating AFO stiffness to the metabolic cost of transport (CoT) as observed in experimental trends from individuals with calf muscle weakness. We used predictive forward musculoskeletal simulations to reproduce the experimental trends and analyzed our simulations to explain the relationship between AFO stiffness and metabolic CoT. The predicted optimal AFO stiffness was within 1 Nm/deg of the patient's experimentally measured one. From the experimentally observed effects, all kinematic and kinetic trends were predicted within 0.5-2.5 SD from the mean of the experimental slopes of all patients' results. Moreover, the differences between the slopes of the simulation results were mostly lower compared to the modelled patient's individual experimental slopes than compared to the experimental slope of the group average results. We identified a reduction in the vasti muscle metabolic cost due to larger external knee extension moments with increasing AFO stiffness as the main mechanism resulting in the net metabolic CoT trend. Limitations on translating our findings to patient behavior include: modelled calf muscle strength, where the model may be significantly stronger or weaker than the patient, and the relative importance of metabolic cost minimization to other goals during walking, such as minimizing the loading rate at heel strike.","Ankle Foot Orthosis; calf muscle weakness; forward simulation; SCONE; OpenSim; metabolic energy cost of transport","en","master thesis","","","","","","","","","","","","","",""
"uuid:7e2f77f6-3d8c-4926-8232-be1d701acbaa","http://resolver.tudelft.nl/uuid:7e2f77f6-3d8c-4926-8232-be1d701acbaa","Developing a Spectral Radiance Model to Enable Radiometric Analysis for HCPV","Menken, Oliver (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Photovoltaic Materials and Devices)","Smets, A.H.M. (mentor); Santbergen, R. (graduation committee); Delft University of Technology (degree granting institution)","2021","Concentrator Photovoltaics (CPV) employs optical elements such as mirrors to focus solar flux to a small target area with a photovoltaic (PV) receiver. CPV system design is hindered by the fact that there is no standardised workhorse model to accurately evaluate CPV topologies. The spectral irradiance standards - the backbone of PV system analysis - could be used, but lose in validity the higher the concentration as the Sun is not a point source. The sunshape, a different model widely used in Concentrated Solar Power (CSP), considers the Sun as an extended source but does not consider spectral information. It follows that CPV system analysis requires a spectral radiance model of the Sun that contains both spectral and directional information. In this thesis, a model from the astronomical literature is combined with the spectral irradiance standards to establish the spectral sunshape, a spectral radiance model of the Sun. The spectral sunshape is proposed as a workhorse model of the Sun for CPV system analysis.","Concentrated solar power; Mirror; Photovoltaics; Irradiance models; multijunction solar cells","en","master thesis","","","","","","","","","","","","Electrical Engineering | Electrical Power Engineering","",""
"uuid:92126ff7-bb17-461c-90fe-87861cf04174","http://resolver.tudelft.nl/uuid:92126ff7-bb17-461c-90fe-87861cf04174","Probabilistic analysis of slope stability in spatially variable soils using Monte Carlo simulation","Han, Han (TU Delft Civil Engineering & Geosciences)","van den Eijnden, A.P. (mentor); Hicks, M.A. (graduation committee); Lanzafame, R.C. (graduation committee); Delft University of Technology (degree granting institution)","2021","Soil properties are spatially variable due to the natural deposition process. Because of this inherent spatial variability, a slope can actually fail along any potential slip surface. A single value of Factor of safety cannot account for this variation dominated the slope stability problem. Probabilistic analysis considering the spatial variability is a reasonable method to quantify the risk of the slope stability problem. Thus, in order to better simulate this variation, the theory of random field has been widely used in the slope stability problem. However, statistical outcomes derived from the probabilistic analysis will be influenced by how the random fields are generated and how the random field values are assigned to each potential slip surface. In order to investigate the extent of this influence, this study proposed a new probabilistic slope stability analysis method and compared it with the other two methods in terms of accuracy and efficiency. In this report, three different probabilistic slope stability analysis methods are presented. These methods combined the traditional limit equilibrium method of slices with random fields, which can account for the inherent spatial variability of soil properties. An exponential decaying function is used to describe the correlation structure of this spatial variation. This correlation structure is further expressed by the form of covariance matrix. Since the covariance matrix is a symmetric positive definite matrix, Cholesky decomposition is used to decompose it into the product of two triangular matrices. Because the triangular matrix is more computationally efficient, the two-dimensional random field is generated by multiplying a normal random number vector with the lower triangular matrix derived from Cholesky decomposition.","Slope Stability; Probabilistic analysis; Limit equilibrium method; Random fields; Monte Carlo simulation; Cholesky decomposition; Spatial variability; System probability of failure","en","master thesis","","","","","","","","","","","","","",""
"uuid:17428c84-4813-4fd3-9370-527fd3ea3774","http://resolver.tudelft.nl/uuid:17428c84-4813-4fd3-9370-527fd3ea3774","Predicting Infection Using Infrared Thermography in Premature Infants: Quantifying the Interaction Between Infrared Thermography and a Neonatal Incubator","Bosma, Bas (TU Delft Mechanical, Maritime and Materials Engineering)","Serdijn, W.A. (mentor); Jonker, P.P. (graduation committee); Delfos, R. (graduation committee); de Graaf, G. (graduation committee); Delft University of Technology (degree granting institution)","2021","class=""MsoNormal"">Predicting when a neonate will fall victim to an infection or a disease allows prevention through early medicine administering. Such physiological conditions can be made visible using infrared thermography (IRT). This is a technique for measuring heat emitted in the infrared spectrum and transforming them into visible signals that can be recorded photographically. This thesis will contribute to the prediction of infection in (pre)term neonates by quantifying the interaction between IRT and a neonatal incubator without (and with) a neonate in it.¬† A system was designed that consisted of three modules: a measurement (incubator and IRT camera), back-end (embedded system and server), and front-end module. The scope of this thesis is limited to the measurement module and the embedded system of the back-end module. Minimum camera requirements were set up which required the camera to: be inexpensive (i.e. ‚â§ ‚Ç¨1000,-), be mobile, be open-source (for Linux), have a minimum frames-per-second of 5, have a resolution of at least 160x160 pixels with a field of view (FOV) of 27¬∞, sensitivity of &lt; 0.1¬∞C, and safe to the patient. Such a camera was found in the FLIR One Pro. For this thesis a different FLIR camera was used due to lack of budget, namely the FLIR A305sc, which was already available at the TU Delft. The A305sc is not open-source, which required a work-around. The Aravis Open Source Project allowed for communication with the camera. Internal camera parameters had to be determined to calculate temperature based on analogue-to-digital values. ExifTool was used on a file stored by the camera to extract these parameters. This calculated temperature was compared to the temperature as determined by FLIR‚Äôs software and led to a difference in the range of 1¬∑106¬∞C. An open-source application was written that can connect with this IRT camera that has a GenICam interface using Aravis. Additionally, this application implemented the temperature calculation based on the internal camera parameters. The hood of the incubator is opaque to infrared, which required the design of a measurement setup to circumvent this. Three different setups were discussed, with the final choice falling on placing the camera in front of an opened incubator porthole on a tripod, and sealing this porthole with high or low density ethyl polyethylene (HDPE/LDPE). Regular H/LDPE used for construction site was found to have a attenuated transmissivity as found in literature. To quantify the interaction between IRT and a neonatal incubator, the IRT measurements were to be compared against the current golden standard sensor, namely thermistors. These sensor values were to be read out from the incubator as this would also be used in the final product. Code was written which allows for automatic detection between the GE GiraffeTM Omnibed and the Dr√§ger Caleo¬Æ incubator, automatic connecting, and manipulation of all sensors values to a standard string which allows for easy uploading to the InfluxDB database on the server. To be allowed to perform measurements on human subjects, approval had to be acquired by the human research ethics committee (HREC) of the TU Delft and the respective hospital. A ‚Äúnon-wet medisch wetenschappelijk onderzoek met mensen‚Äù (nWMO) request was submitted and approved, which resulted in 25 recorded sick and healthy neonates in incubators divided over two hospitals (the JKZ in The Hague, and the RDGG in Delft), with over 25 hours of recording material. Simultaneously, measurements were performed on an empty incubator to gain an understanding in the behaviour of an incubator when actors from outside interacted with the internal environment. Measurements that were performed included determining the reflected apparent temperature (RAT) for every possible opened porthole and for both incubator types. The RAT for the Caleo was found to be higher for every measurement for the GE. The accuracy of the IRT and hospital skin temperature sensors was compared against a calibrated Pt-100 sensor, which show that the Pt-100 sensor measures an equal value as the hospital skin temperature sensor, whereas The IRT camera measured .6¬∞C higher. The effect of changing the distance on IRT values was measured, which shows that for a distance of 0.2m to 1.2m the accuracy of the IRT camera is within the specified accuracy. Finally, the effect of opening additional portholes on IRT was measured, the effect of the airboost setting on IRT, and the measurement of opening additional portholes was repeated with a different IRT camera. Overall the IRT camera measures a higher temperature than the hospital skin temperature sensors, but follows the skin temperature sensors‚Äô pattern.¬† ¬†¬†","infrared; thermography; neonate; infant; premature; incubator; camera","en","master thesis","","","","","","","","2022-03-01","","","","","",""
"uuid:d11bd563-fcf2-4525-8912-b0288639d855","http://resolver.tudelft.nl/uuid:d11bd563-fcf2-4525-8912-b0288639d855","Actuator concept comparison for the next-gen Ampelmann hexapod platform","Frateur, Thomas (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Precision and Microsystems Engineering)","van Ostayen, R.A.J. (mentor); Polinder, H. (mentor); Jarquin Laguna, A. (graduation committee); Nijssen, J.P.A. (graduation committee); Delft University of Technology (degree granting institution)","2021","The Ampelmann A-type hexapod platform is a motion compensating gangway system designed to transfer offshore personnel between a crew transfer ship and an offshore bottom founded structure. During operation, the platform is moved to compensate wave induced ship motion and create a still standing platform from which crew can safely transfer to the fixed structure. The hexapod platform is actuated by six high power linear actuators each capable of delivering 150 kW of power. To reduce the platform mass and reduce the operational energy requirements of the A-type, new actuator technologies are considered to replace the current conventional hydraulic actuators. Especially electro-hydrostatic and electro-mechanical actuation are promising alternatives to reduce mass and increase efficiency. Currently, properties of these technologies are only described up to power levels of 45 kW. Relative advantages of one over the other technology are not readily available in literature for higher power requirements. <br/>To be able to compare both actuator technologies for use in the Ampelmann A-type, a preliminary design tool is made using existing and newly developed actuator mass and power loss models. General mass and loss properties of both actuators are determined and compared to develop a better insight in the optimal high power linear actuator technology for a specific application. Insights are applied but not limited to the Ampelmann application.<br","Linear actuator; Actuator comparison; EMA; EHA; Ampelmann; Actuator Sizing; Actuator losses","en","master thesis","","","","","","","","2023-02-24","","","","Mechanical Engineering | Mechatronic System Design (MSD)","",""
"uuid:52ad7b94-027f-4d62-b98f-e9c00ce1a773","http://resolver.tudelft.nl/uuid:52ad7b94-027f-4d62-b98f-e9c00ce1a773","Lubricated friction on pipeline pigs","van Zelderen, Bas (TU Delft Aerospace Engineering)","van Oudheusden, B.W. (mentor); Henkes, R.A.W.M. (graduation committee); Delft University of Technology (degree granting institution)","2021","Pigs are devices that are transported from time to time through a pipeline, mainly to either clean the pipeline or to inspect the integrity of the pipeline wall. Conventional models for the friction between the pig and the pipe wall, as used in the oil and gas industry, are often criticized for their inaccuracies. To obtain a more accurate model, this thesis investigates the detailed physics behind the frictional forces. The effect of the sliding conditions on the wall-normal force and on the friction force was investigated by conducting 1D lubricated sliding experiments for a rubber lip moving along a metal surface and by performing model simulations, including a parameter sensitivity study. The experiments were conducted for dry water, dodecane and castor oil under varying sliding velocities and loads. The loads were measured with a dual axis transducer and the lubrication film was observed during the experiments with a microscope set-up. The experimental results consist of friction forces for various configurations, which show that the frictional behaviour depends strongly on the lubrication regime in which the rubber lip is operating. The friction coefficients for the boundary lubrication regime and the mixed lubrication regime were measured and compared with results from the model. Among the tested fluids, castor oil showed a non-proportional decrease in friction force when the sliding velocity was increased. This decrease in friction force was interpreted as a transition from the boundary lubrication regime to the mixed lubrication regime. The other tested fluids remained in the boundary lubrication regime in the experimental runs. A validation study was performed by fitting the friction model to the experimental results. Only the dry friction coefficients are in good agreement with the model. Both the water and dodecane experiments show a slight increase for the friction coefficient with increasing lubrication factor and are in mediocre agreement with the friction model. The castor oil experiments are in the mixed lubrication regime of the Stribeck curve and are in reasonable agreement with the model. The results can be linked to the oil and gas industry as pigs can operate in different regimes of the Stribeck curve. Stalled pigs can be the result of transitions from the mixed lubrication regime to the boundary lubrication regime. This can happen when a pig is momentarily slowed down in the pipeline. Recommendations for future experimental work are: performing experiments at higher sliding velocities, using an emulsion as lubricant and finding suitable methods to calibrate models that have a range of input parameters. This work was carried out by the author at the Shell Technology Centre in Amsterdam. The supervision by the Shell staff and the support obtained in carrying out the experiments in the Shell lab are greatly acknowledged.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:d658ac52-b3b1-48e3-9ba0-d96e1be18937","http://resolver.tudelft.nl/uuid:d658ac52-b3b1-48e3-9ba0-d96e1be18937","Automated lane changing using deep reinforcement learning: a user-acceptance case study","van den Haak, Daniel (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Cognitive Robotics)","de Winter, J.C.F. (mentor); Bazilinskyy, P. (mentor); Dodou, D. (graduation committee); Wang, M. (graduation committee); Delft University of Technology (degree granting institution)","2021","Lane change decision-making is an important challenge for automated vehicles, urging the need for high performance algorithms that are able to handle complex traffic situations. Deep reinforcement learning (DRL), a machine learning method based on artificial neural networks, has recently become a popular choice for modelling the lane change decision-making process, outperforming various traditional rule-based models. So far, performance has often been expressed in terms of achieved average speed, absence of collisions or merging success rate. However, no studies have investigated how humans will react to the resulting behavior as potential occupants. This study addresses this research gap by validating a self-developed DRL-based lane changing model (trained using proximal policy optimization) from a technology acceptance perspective through an online crowdsourcing experiment. Participants (N=1085) viewed a random subset of 32 out of 120 videos of an automated vehicle driving on a three-lane highway with varying traffic densities featuring our proposed model or a baseline policy (i.e. a state-of-the-art rule-based model, MOBIL). They were tasked to press a response key if the decision-making was deemed undesirable and subsequently rated the vehicle's behavior along four acceptance constructs (performance expectancy, safety, human-likeness and reliability) on a scale of 1 to 5. Results showed that the proposed model caused a significantly lower amount of disagreements and was rated significantly higher on all four acceptance constructs compared to the baseline policy. Moreover, considerable differences between individual disagreement rates were observed for both models. Our findings offer prospects for the practical application of DRL-based lane change models in a use-case scenario, depending on the user. Further research is necessary to examine whether these observations hold in other (more complex) traffic situations. Additionally, we recommend combining DRL with other modelling techniques that allow for personalization of behavioral parameters, such as imitation learning.","automated lane changing; automated vehicles; deep reinforcement learning; artificial neural networks; proximal policy optimization; technology acceptance; crowdsourcing; MOBIL","en","master thesis","","","","","","","","","","","","Mechanical Engineering","",""
"uuid:e06d4f4c-8f9e-49a3-a841-463efc6d35af","http://resolver.tudelft.nl/uuid:e06d4f4c-8f9e-49a3-a841-463efc6d35af","Predicting Probabilistic Flight Delay for Individual Flights using Machine Learning Models","Vorage, Laurence (TU Delft Aerospace Engineering)","Mitici, M.A. (mentor); Delft University of Technology (degree granting institution)","2021","To ensure continuous operations at airports, operational schedules need to be able to cope with early and late arriving/departing flights. To optimize such schedules for these events, flight delay predictions are necessary. Till now, flight delay has been studied mainly from a binary and regression standpoint. These type of predictions lack a certainty indication, which is needed by decision-makers to optimize a schedule. This research focuses on probabilistic predictions of flight delay on an individual flight level. Flight operation data from Amsterdam Schiphol airport and weather data from METAR is used to train four machine learning models that predict probabilistic flight delay distributions on a prediction horizon of one day. The first two developed models, a Dropout neural network and a Random Forest, predict empirical distributions. The other two models, a Mean Variance Estimator (MVE) and a Mixture Density Network (MDN) model, predict continuous distributions by predicting the parameters of an assumed distribution. The MVE predicts a single normal distribution, while the MDN model predicts a mixture of multiple normal distributions. Two interval-based performance metrics are suggested which assess the probabilistic predictions from different perspectives. It is concluded that arrival delay is best modelled with a MDN model with ten components, while departure delay is best modelled with only three components. Both models outperform a baseline statistical method on all considered interval widths. The MDN models outperform the other machine learning models by predicting more early arrivals and early departures correctly. The proposed models show that they can provide certainty indications of flight delay on an individual flight level, as opposed to binary and regression models. In the future, these certainty indications can assist airport operators with optimizing operational schedules, ensuring continuous operations and making ultimately air travel more pleasant.","Flight delay; Probabilistic predictions; Machine Learning","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:a198ce3a-0d7f-4cd2-a3b6-c17fe86ba42c","http://resolver.tudelft.nl/uuid:a198ce3a-0d7f-4cd2-a3b6-c17fe86ba42c","Improving Ultrawide Band Ranging Using Two Antennas","Jain, Akhil (TU Delft Electrical Engineering, Mathematics and Computer Science)","Nasri, Mitra (mentor); Garvey, Kenneth (mentor); Kornek, Daniel (mentor); Zuniga, Marco (graduation committee); van der Veen, A.J. (graduation committee); Delft University of Technology (degree granting institution)","2021","Ultrawideband technology can be used to measure the distance between two device equipped with ultrawideband transceivers. Multiple ultrawideband devices known as anchors can localize a device that supports ultrawideband communication after each anchor measures the distance between itself and the device. The anchor and the tag can measure the distance between themselves by measuring the time of flight of the ultrawideband messages exchanged between them. If the location of the anchors are known, the location of the device can be computed. However, errors in range measurements can cause errors in localization of the device. There are many sources that can cause errors in the measured range between the anchor and the tag. For example, when the tag transmits a signal, and the path between the anchor and the tag is blocked, the signal may be attenuated to such an extent that it may go undetected at the anchor, causing the anchor to measure the time of arrival of a delayed reflection. In this thesis, we aim to find a solution to improve the ranging accuracy when an anchor is equipped with two antennas. We target approaches that can be implemented on an embedded processor with limited resources. In order to improve the ranging accuracy, we first investigate various machine learning based classifiers that can identify non-line of sight and line of sight signals. Next, for each of the classified signal, we train and test various machine learning based regression models that will predict the true distance from the distance measured by the anchor. We conclude the thesis, by assessing the robustness of the derived classification and regression models by evaluating the range improvements in measurements taken in different scenarios.","Ultrawide Band; machine learning; Ranging","en","master thesis","","","","","","","","","","","","Electrical Engineering | Embedded Systems","",""
"uuid:3c77b976-d574-4a68-a320-ebd559b0a52f","http://resolver.tudelft.nl/uuid:3c77b976-d574-4a68-a320-ebd559b0a52f","Improved risk management process in construction projects","Christodoulou, Vaso (TU Delft Civil Engineering and Geosciences)","Brazier, F.M. (graduation committee); Leijten, M. (mentor); van Nederveen, G.A. (mentor); van den Berg, I. (mentor); Delft University of Technology (degree granting institution)","2021","Risk management, a process aiming to decrease or eliminate the likelihood and impact of unwanted effects on a project during its lifecycle, has become highly significant due to complexity, uncertainties and high competition. Numerous tools and techniques have been developed for successfully implementing risk management. However, risk is frequently inadequately addressed and existing tools and knowledge are not used and exploited at a high degree. This research examines current practices of the risk management process and identifies barriers and opportunities pointing to improve its implementation through the exploitation of information and knowledge of past projects. The investigated knowledge and information focus on project drivers, characteristics and other KPI‚Äôs. The empirical study of the research incorporates the analysis of seven risk registers/projects of Witteveen+Bos and development of interviews of W+B risk and project managers involved in the analyzed projects. Subsequently, validation of the results is achieved through extra interviews of risk management experts external to Witteveen+Bos and a conceptual framework is developed. The last step of this qualitative research entails the validation of the conceptual framework which is tested with a case study implemented through an online workshop and a questionnaire. <br/>By analyzing the literature findings and empirical data, it is concluded that information and knowledge management during the implementation of risk management are not adequately developed while simultaneously constitute a major barrier to its success. Therefore, a conceptual framework that incorporates a way of structuring risk related information is developed while targeting to also tackle certain identified barriers of the current procedures such as the understanding of risk structure to the whole project and the adequate exchange of information during the process.<br/>The framework suggests a higher quality use of risk registers while structuring information and afterwards exploiting the information for capturing lessons that can be reused in future projects. It provides a way of clustering information during the development of projects and at the same time incorporates the development and use of risk networks. The development of risk networks is initiated by grouping risks based on their source. The aforementioned sources are selected based on the results of the research and named ‚ÄòKey Sources‚Äô. The aim of using risk networks is to increase risk insights while displaying risk exposure visually. In this way barriers such as lower understanding of risks, incomplete communication of risks as well as short term view of risks may be addressed or eliminated. Another part of the framework concerns the development of evaluation concerning the process as well as the description of risk related information. It is concluded that even though, there is a wide array of identified barriers to the effectiveness of risk management implementation, overcoming information and knowledge management barriers can constitute a higher level way of overcoming other barriers as well.<br","Risk management; risk registers; information; knowledge management","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:f991ba7c-0760-4276-a0ac-90e7be6399c0","http://resolver.tudelft.nl/uuid:f991ba7c-0760-4276-a0ac-90e7be6399c0","The future roadmap of an artificial intelligent eye tracking platform","Gratama van Andel, Seerp (TU Delft Industrial Design Engineering)","Coelen, J. (mentor); van Engelen, J.M.L. (mentor); van der Wiele, Daan (graduation committee); Delft University of Technology (degree granting institution)","2021","This thesis was performed in assignment of Alpha.One for their new eye tracking prediction platform expoze.io. The project started of with the brief; What does the future of expoze.io hold? This indicates the need for a future vision. In order to create a future vision the company purpose must first be researched, the reason why they exist. The purpose of the company is often related to the customer needs, therefore it is important to understand the subjective value that the product offers to the customer. Therefore before the preliminary research the research questions proposed were; What does the future roadmap of expoze.io look like? What is the future vision for the predictive eye tracking platform expoze.io? What is the purpose of expoze.io? What is the customer value of expoze.io? What are market gaps / differentiating factors in the market? The preliminary research revealed that for the roadmap to succeed a process integrating the roadmap should be designed. This process should also fit the company as it is still a startup, therefore it must be time, effort and cost efficient. Another insight was that there needs to be a shift to a more human oriented mindset within the company. These insights led to the addition of the following research questions. What does the future roadmap of expoze.io look like? How can the roadmap assist in adapting the product to be more Human? How could the roadmap be best adopted into the operation of the expoze.io team? (process) How to build an innovation process that fits a small startup team? cost, time, effort efficient How to create a shift to a more human oriented mindset in this process? How to make sure that ideas selected fit the needs of the customers? Through customer interviews it became evident that the subjective customer value that expoze.io brings to the customer is confidence. Through eye tracking analysis the customer gains confidence in their advertisements and if they will perform in the market as they would like it to perform. It also brings confidence in presenting their analysis to their bosses or clients. This in turn makes the purpose of expoze.io ‚Äúbringing confidence to marketeers‚Äù. By accompanying the purpose with the insights from competitor analysis, customer research, trend analysis and market research the future vision could be created. Through brainstorming the following vision was proposed; ‚ÄúBringing the brains to the art of marketing‚Äù. This vision was tested through a workshop with the employees at Alpha.One. The workshop also ensured the involvement of the people working at Alpha.One in the creation of the roadmap, it also facilitated communication about everyone‚Äôs ideas about the future path of the company. The vision was chosen by the most people and is therefore implemented into the roadmap. The roadmap was based on the vision that was created accompanied by the insights from the research to fill in the steps that need to be taken in order to reach that future. The core strategy of the roadmap is to create confidence by facilitating deeper insights through the platform. In order for the roadmap to succeed an innovation process to support roadmapping was designed. This innovation process will also facilitate the shift towards a more human mindset by incorporating the customer in the ideation and validation of ideas. The innovation process revolves around three meetings on the following topics; strategy, ideas and planning. For every meeting a process is designed that interacts with the roadmap and makes sure that ideas added are actual customer needs and will create an impact for the customer.","Roadmap; Artificial intelligence; eye tracking; Innovation process","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:46f3e897-b0bb-43a7-a680-8e9e96503b90","http://resolver.tudelft.nl/uuid:46f3e897-b0bb-43a7-a680-8e9e96503b90","Selective transport between monovalent and divalent ions in electrodialysis: The effect of current density and ionic species concentration","Opschoor, Tobias (TU Delft Civil Engineering and Geosciences)","Spanjers, H.L.F.M. (mentor); van Lier, J.B. (graduation committee); Vermaas, D.A. (graduation committee); Narayen, D. (graduation committee); Delft University of Technology (degree granting institution)","2021","Industrial and municipal wastewaters often contain a high concentration of NH4+<br/>To prevent excessive discharge into the environment, these wastewaters need to be treated. Electrodialysis has been shown to be a suitable technique for the removal and recovery of NH4+ from both synthetic and real wastewaters such as digestate rejection water and industrial condensate. These wastewaters can contain varying concentrations of Mg2+, Ca2+ and CO32-. Treating these waters with ED for NH4+ recovery also causes recovery of these divalent ions. The recovery of these ions can potentially cause scaling. Scaling is undesired and needs to be prevented. The main objective of this research was to analyse what the applied current density, Mg2+/NH4+ ratio and total ion concentration had on the the selective transport between NH4+ and Mg2+.","Electrodialysis; Selective","en","master thesis","","","","","","","","","","","","Civil Engineering","",""
"uuid:7a50f78c-b587-4ebb-b397-fd33164b9e2e","http://resolver.tudelft.nl/uuid:7a50f78c-b587-4ebb-b397-fd33164b9e2e","Fault Detection and Diagnosis in Industrial Refrigeration Compressors of GEA B.V.","Ressa, Cesare (TU Delft Mechanical, Maritime and Materials Engineering)","Infante Ferreira, C.A. (mentor); Delft University of Technology (degree granting institution)","2021","Compressors play an essential role in refrigeration. Recent industrial compressors are more efficient, less energy-demanding, and provide higher modularity than ever before. On the other hand, such innovation led to a higher degree of complexity of the equipment, which could undermine the reliability.Every compressor unit has sensors, programmable logic controller (PLC), and human-machine interaction (HMI) modules. The PLC can stop the equipment in case of danger, and the HMI displays the reason why the compressor stopped (e.g. high oil temperature).However, data from the sensors installed on the machinery can be used to obtain more insight to the status of the compressor. Less severe faults can be detected and diagnosed earlier, interrupting in advance the chain of events that leads to more expensive failures.GEA is one of the largest players in industrial refrigeration and produces different models of compressors, such as screw and piston compressors. The company performs maintenance services to their equipment located in different locations worldwide and they made available for this thesis multiple datasets of compressors experiencing different faulty behaviors. The aim of this project is to define methods of fault detection and diagnosis of faulty non-return valves, liquid refrigerant carryover in the compressor crankcase, and an investigation on faulty bearings.Different solutions about fault detection &amp; diagnosis (FDD) in reciprocating compressors have been found in the literature. Among the proposed solutions, two rule-based methods have been developed for the leaking non-return valve. The same fault has then been detected by classifying the data with three supervised machine learning (ML) techniques: decision tree, random forest, and XGBoost. In the end, all the different models have been compared and their respective strengths and weaknesses analyzed. All the ML models showed an advantage in detecting the leaking in non-return valve compared to the rule-based models because the trend of such fault is not always predictable with a series of if-then-else rules.A similar approach has been used for the detection of liquid carryover in the compressor's crankcase. In this case, a rule-based model detected the fault accurately. This was due to the lower grade of complexity in detecting the symptoms of such fault. The ML models required a data augmentation step for the training dataset since the ratio between faulty and non-faulty data was too big. Two data augmentation methods have been used: random oversampling and synthetic minority over-sampling (SMOTE) technique.For the last study case, an investigation and detection of symptoms to detect faulty bearings has been performed. Multiple rule-based algorithms have been defined to detect the symptoms of such fault, while a model-based approach has been proposed to compare the measured power demand with the predicted power demand of GEA's proprietary compressor model.In conclusion, a hybrid approach, rule-based + ML, is the proposed method for the development of GEA's FDD program, since there is no outstanding method that fits all the possible faults. Based on the results of the models developed in this thesis, GEA can choose which algorithm is worth implementing in the FDD program embedded in their compressors.","Fault Detection; refrigeration; Compressor","en","master thesis","","","","","","","","2026-02-23","","","","Mechanical Engineering","",""
"uuid:907d0bdd-1ff3-4720-96e7-750661d21b83","http://resolver.tudelft.nl/uuid:907d0bdd-1ff3-4720-96e7-750661d21b83","Vacation destination choice as a positional good: Are individuals‚Äô preferences influenced by others?","Quesada Pacheco, Jorge (TU Delft Civil Engineering and Geosciences)","van Wee, G.P. (mentor); Molin, E.J.E. (mentor); Maat, C. (mentor); Delft University of Technology (degree granting institution)","2021","","Positional Goods; Destination Choice; Stated Preference Experiment; Utility; Accessibility","en","master thesis","","","","","","","","","","","","","",""
"uuid:9a389ff4-94da-4d37-8c9b-80843916b8ff","http://resolver.tudelft.nl/uuid:9a389ff4-94da-4d37-8c9b-80843916b8ff","Nesterov Accelerated ADMM for Distributed Pose Graph Optimization in SLAM problems","Bosland, Liam (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Delft Center for Systems and Control)","Keviczky, T. (mentor); Kok, M. (graduation committee); Kooij, J.F.P. (graduation committee); Delft University of Technology (degree granting institution)","2021","A common problem in robotics is the simultaneous localization and mapping (SLAM) problem. Here, a robot needs to create a map of its surroundings while simultaneously localizing itself in this map. An unknown environment is assumed. Traditionally, it has been approached through filtering solutions. This paradigm has shifted to pose graph optimization (PGO). This method scales well with large maps and is fast and accurate. Furthermore, it is especially suited to the distributed SLAM problem as existing distributed optimization methods can be leveraged. One such method is the alternating direction method of multipliers (ADMM), which has been used in distributed PGO. ADMM has a simple implementation and can achieve high accuracies in distributed PGO. A solution of good quality can be acquired in a few iterations with ADMM. However, ADMM is slow to converge to high accuracies. This thesis introduces an algorithm which implements Nesterov acceleration in the ADMM algorithm for distributed PGO in SLAM problems. Such an implementation will be novel. To create the proposed Nesterov accelerated ADMM (N-ADMM) algorithm, the current literature is adapted and extended based on the choices made in this thesis. The main research question is how to make these choices. The proposed N-ADMM algorithm is implemented in C++ and compared with unaccelerated ADMM and the state of the art. N-ADMM has shown better performance in some scenarios. To further research what these scenarios are characterized by, two models are introduced to create new datasets of which the parameters can be controlled. The effects of graph size and bad initial guesses are investigated.","SLAM; pose graph; distributed optimization; Nesterov; ADMM","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:5908400a-cad8-4b62-a6a1-c15aca923374","http://resolver.tudelft.nl/uuid:5908400a-cad8-4b62-a6a1-c15aca923374","Anaerobic Conversion of Proteins in Aerobic Granular Sludge","Sathish, Samyuktha (TU Delft Civil Engineering and Geosciences; TU Delft Sanitary Engineering)","de Kreuk, M.K. (graduation committee); van Lier, J.B. (graduation committee); Pronk, M. (graduation committee); Toja Ortega, S. (mentor); Delft University of Technology (degree granting institution)","2021","In an aerobic granular sludge (AGS) reactor treating urban wastewater, nutrient removal depends on the availability of carbon source. Domestic wastewater consists of 40-60% of slowly biodegradable complex substrates, out of which proteins form a major fraction. Despite this, little is known about the mechanisms of protein degradation in AGS. This research assessed the anaerobic availability of protein substrates for enhanced biological phosphorous removal (EBPR) in an aerobic granular sludge reactor. Proteins have to be first hydrolyzed before being assimilated by the bacteria, and nutrient removal is often limited by the rate of hydrolysis. Therefore, a major part of this thesis attempted to look into the mechanisms of proteolysis in AGS. Next, the utilization of amino acids - the hydrolysis product of proteins - by PAO was explored, based on critical evaluation of available literature. Firstly, it is proposed that the important aspect likely to govern the hydrolysis of proteins in AGS is the substrate-granule interaction, taking into account the diffusion limitation of particulate substrates within the granules and the probable presence of hydrolytic enzymes on the granular surface. Further, it is seen that the amino acids may be utilized by the polyphosphate accumulating organisms (PAOs) either directly or after the anaerobic degradation of amino acids to simple VFAs (volatile fatty acids), which are then taken up by the PAOs. The anaerobic degradation or fermentation of amino acids may occur via two well-known pathways- Stickland pathway and the non-Stickland pathway. Non-Stickland reaction requires syntrophy with hydrogen consuming bacteria whose presence in AGS is questionable. The bacteria responsible for Stickland reaction are obligate anaerobes belonging to the genus Clostridium which has not been found in aerobic granular sludge. Thus, it seems more likely that the amino acids are directly taken up by the PAOs in an AGS reactor. However, the direct uptake of amino acids by the PAOs has been reported only for eleven amino acids in total. More research on the likely fate of the remaining amino acids is recommended, considering that very little is known about the fate of amino acids in AGS. Few laboratory experiments were also conducted to study the effect of substrate size and granule size on the rate of hydrolysis of proteins. From preliminary experiments, it was seen that aerobic granular sludge exhibited significant anaerobic phosphate-release activity when casein (protein) was the only available carbon source. In the lab experiment carried out with different sizes of protein substrates, the observed anaerobic phosphate-release activity was used to obtain the rate of hydrolysis of different sizes of casein. Based on the hydrolysis rate obtained, it is seen that in an AGS reactor with a typical sludge concentration of 8g/l, up to 90% of the proteins present in domestic wastewater influent could be potentially taken up by the PAOs, provided that the proteins are completely dissolved. It was also seen that 60-80% of the particulate casein COD (&gt;0.45um) was hydrolyzed within 24 hours of the assay. In another lab experiment, fluorescent protease assay was performed to assess the effect of granule size on the rate of hydrolysis. A significant decrease (by at least 2 times) in the specific rate of protein hydrolysis was observed when the aerobic granule size was increased from 1-2mm to 3.15-4mm. This may be significant especially when the stratification of granules and plug-flow feeding in an AGS reactor is taken into account. Further research is recommended to analyze the relative effect of substrate size and granule size on the rate of hydrolysis of proteins in AGS.","Aerobic Granular Sludge; Hydrolysis; Proteins; EBPR; PAO","en","master thesis","","","","","","","","","","","","Civil Engineering | Environmental Engineering","",""
"uuid:8d682d8f-0e05-4170-8a8d-406bb3854f99","http://resolver.tudelft.nl/uuid:8d682d8f-0e05-4170-8a8d-406bb3854f99","Predicting Flight Delay Distributions: A Machine Learning-Based Approach at a Regional Airport","Dutrieux, Sarah (TU Delft Aerospace Engineering)","Mitici, M.A. (mentor); Zoutendijk, M. (graduation committee); Delft University of Technology (degree granting institution)","2021","class=""MsoNormal"" style=""margin: 0cm; font-size: 12pt; font-family: Calibri, sans-serif;"">In an effort to improve an airport operation optimization model, this research investigates the possibility of predicting probability distributions of flight delays with machine learning algorithms. The research is centered around Rotterdam The Hague Airport, a regional airport in the Netherlands. The first objective is to test how well machine learning classifiers can predict whether a flight will be delayed for a regional airport. This results in accuracies of around 70%, while taking precision and recall into account. The second objective is to predict the probability distributions of flight delays, for which three models are selected: a modified Random Forest Regressor, a Mixture Density Network and a Dropout Network. The main finding is that accurately predicting distinctive delay probability distributions for individual flights is possible. As a final objective, the predicted flight delay distributions are incorporated into an existing Flight-to-Gate Assignment Problem. It is found that this improves the robustness of the resulting schedules, although associated with a small reduction in their efficiency. The overall conclusion of this research is that machine learning-based prediction of flight delay distributions is possible, sufficiently accurate, and can improve at least one airport operation optimization problem. Further research will have to show whether this approach can be extended to other airports, other aviation optimization problems, or even optimization problems in other research areas.","machine learning; flight delays; airport operation optimization; regional airport; probabilistic forecasting","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:34b3732e-2960-4374-94a2-1c1b3f3c4bd5","http://resolver.tudelft.nl/uuid:34b3732e-2960-4374-94a2-1c1b3f3c4bd5","A Study of Performance and Security Across the Virtualization Spectrum","van Rijn, Vincent (TU Delft Electrical Engineering, Mathematics and Computer Science)","Rellermeyer, J.S. (mentor); Chen, Y. (graduation committee); Verwer, S.E. (graduation committee); Delft University of Technology (degree granting institution)","2021","Virtualization is the fundamental technology that enabled the widespread adoption of cloud computing. With the ever-increasing pervasiveness of the cloud computing paradigm, strong isolation guarantees and low performance overhead from isolation platforms are paramount. An ideal isolation platform offers both: an infallible isolation boundary while it retains a negligible performance overhead. In this thesis, we examine various isolation platforms (containers, secure containers, hypervisors, unikernels), and conduct a wide-array of experiments to measure the performance overhead and degree of isolation offered by the platforms. We find that container platforms have the best, near-native, performance. The highest degree of isolation is achieved by unikernels, closely followed by containers.","virtualization; containers; performance; cyber security; unikernel; linux; cloud computing; QEMU","en","master thesis","","","","","","","","","","","","","",""
"uuid:4d3a43b6-25d0-452d-9906-5da597fb0ea1","http://resolver.tudelft.nl/uuid:4d3a43b6-25d0-452d-9906-5da597fb0ea1","Accounting for distributive justice in Integrated Assessment Models: Towards a more equitable climate policy agenda","Tjallingii, Ivar (TU Delft Technology, Policy and Management)","Kwakkel, J.H. (graduation committee); Taebi, B. (graduation committee); Dijstelbloem, Huub (graduation committee); Delft University of Technology (degree granting institution)","2021","Integrated Assessment Models (IAMs) are widely used tools for estimating climate change's impacts on the socio-economic system. However, IAMs possess a limited ability to represent the impact on vulnerable populations. Influential IAMs use highly aggregated outcomes masking significant relative differences in impacts across heterogeneous populations and time. Therefore IAM studies systematically undervalue the need for faster CO2 emission reductions to prevent substantial climate impacts on low-income groups. Previous literature has proposed alternative distributive principles to use in IAMs to overcome inequity problems in current abatement pathways. Due to the heterogeneous models, scenario assumptions, and principles used, comparison between studies has been difficult. Therefore the literature lacks an overarching comparative study of the performance of various distributive principles. Furthermore, deep uncertainty present within climate change is often not considered because most studies focus on single-scenario optimality. Therefore, current abatement pathways contribute to maintaining current economic inequalities and possess exposure to uncertainty. This thesis applies alternative principles to the RICE model through a MORDM method. Alternative distributive principles are used to generate more equitable abatement strategies using a MOEA. This research analyses four main principles: the Prioritarian, Sufficitarian, Egalitarian, and the Utilitarian principle. Alternative principles generate significantly different abatement trajectories than the Nordhaus optimal policy. Sufficitarian policies have the most stringent abatement targets focusing on reaching net-zero emissions by 2065. Prioritarian strategies aim at 2065-2105. Utilitarian strategies focus on reaching net-zero emissions around 2135. Lastly, Egalitarian policies enforce slow climate abatement. Abatement strategies have been stress-tested through an uncertainty analysis based on the SPP-framework and exposure to long-term climate uncertainty. Sufficitarian strategies possess high robustness to climate extremes and high average performance across all scenarios. Prioritarian strategies possess high average robustness but lower regret-based robustness. This research shows that alternative principles can successfully generate well-performing abatement pathways in the RICE model that outperform Utilitarian-based policies. The Sufficitarian principle's capacity to produce equitable and economically optimal strategies has been undervalued in previous research. Lastly, this thesis emphasizes that stronger climate action is needed to prevent possible disastrous worldwide impacts on low-income groups. Global emission reductions should adhere to a global warming of 1.5 degrees set out by the IPCC, which is consistent with the best-performing pathways found in this research. A first step would be to reduce existing economic inequalities to overcome exposure to climate extremes for lower-income groups. <br","integrated assessment modelling; Deep Uncertainty; Climate Change; Distributive Justice; RICE Model","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:8cf98ff7-ef0e-4152-8077-4bee5f209775","http://resolver.tudelft.nl/uuid:8cf98ff7-ef0e-4152-8077-4bee5f209775","High-dimensional numerical optimization of fiber reinforced polymers with variational autoencoders and Bayesian optimization","Storm, Joep (TU Delft Civil Engineering and Geosciences)","Sluijs, L.J. (mentor); Barcelos Carneiro M Da R, I. (graduation committee); li Piani, T. (graduation committee); Bierkens, G.N.J.C. (graduation committee); Delft University of Technology (degree granting institution)","2021","Designing engineering structures relies on accurate numerical simulations to predict the behaviour of a structure before its realization. In the design process, many variables influence the final structure. There is an incentive for optimizing the design based on the desire for cheaper structures and less material usage. Although a wide variety of optimization techniques exist, in practice many structures are not fully optimized and could fulfill their purpose with less material usage. This partly results from optimization techniques generally requiring many simulations for problems with a high number of variables. In creating increasingly complex models, simulating its performance can take up to days or weeks to compute, incentivizing the development of optimization methods that use as little simulations as possible. The goal of this thesis is to provide a method of optimization which significantly reduces the required number of simulations to be performed, aiming to overcome the issue of required computational effort. The optimization problem used in this thesis is the geometric optimization of a fiber reinforced polymer (FRP) microstructure. Each evaluation requires a Finite Element analysis, and many parameters are required to describe the geometry. The goal is to find the maximum stress at perfect plasticity during uniaxial tension, interpreted as a measure of strength. While generally only fibers with a circular cross-section are used, here a morphing parameter is introduced that changes this shape between being circular and square. Furthermore, fibers are allowed to overlap, effectively creating a single fiber with a complex shape. This geometry optimization provides a challenging problem for which different optimization techniques can be compared. The approach taken in attempting to minimize the number of function evaluations is a combination of several machine learning methods. Based on a limited number of initial samples, Bayesian optimization (BO) is applied. In BO a prediction model in the form of a Bayesian Neural Network (BNN) is created and used to inform further sampling. This prediction model provides a mean and a standard deviation in its prediction, both of which are used to find the best point to sample next. The number of initial samples required to create an accurate prediction model increases exponentially with the number of parameters. It is therefore opted to first use a variational autoencoder (VAE) to reduce the number of parameters in which BO is performed, by encoding the parameters in a lower dimensional representation. The variational autoencoder does this without requiring any function evaluation. Results show that when encoding the original parameters using the VAE, the encoded representation is unable to recreate all possible configurations of the original parameters. Furthermore, by transforming to a lower dimensional representation, within this representation the complexity of a function increases compared to the original function, generally leading to many local optima. This complexity proves difficult for the BNN to accurately predict based on a limited number of samples. As a result, BO does optimize the result, but does not reliably find the global optimum of the reduced parameter space. No clear conclusion can be made on the overall performance of the method compared to alternative optimization methods. Recommendations are made for what additional studies could be performed. Further recommendations are given for solving issues limiting the current performance as well as possible additions to the framework. The fiber geometry optimization serves as a good case to compare different optimization methods. It is shown that the geometry has a significant influence on the mechanical performance of a FRP microstructure, and optimization is therefore beneficial. The load case considered is however too specific for the optimized result to have direct practical use. Still, it does demonstrate that the results of an optimization study can be generalized. As the optimization framework is data driven, the optimization objective could easily be extended to study more realistic problems.","Bayesian Optimization; Variational Autoencoder; machine learning; Regression; high-dimensional; Fiber Reinforced Polymers - FRP; Artificial intelligence; optimization; Genetic Algorithm - GA; Bayesian neural network; Neural Network","en","master thesis","","","","","","","","","","","","Civil Engineering","",""
"uuid:a028ea99-5e1c-41de-8fc4-458ace4833a5","http://resolver.tudelft.nl/uuid:a028ea99-5e1c-41de-8fc4-458ace4833a5","Influence of the combination of ambient and glacial stresses on the response of a viscoelastic Earth","Morra, Fabrizio (TU Delft Aerospace Engineering)","van der Wal, W. (mentor); Blank, B. (graduation committee); Delft University of Technology (degree granting institution)","2021","The evolution of ice loads during the last Ice Age causes an ongoing Earth response with deformations and stress fields. The viscosity of the mantle depends on stresses, therefore the model stresses should be combined with ambient stresses such as due to mantle convection. This combination has been successfully simulated in the FEM software ABAQUS.<br/><br/>At each timestep background stresses are added to existing component and the Mises stress is recalculated to be used in a custom creep law. This leads to a new viscosity leading to different stress components, which is solved an iterative procedure.<br/><br/>This work shows that the initial model provided can be adapted to simulate this iterative process with a loop inside each timestep of the computation. Results show that stresses increase with time while deformations and viscosity decrease, an opposite trend compared to a non-ambient stresses case.","geodesy; Finite Element Method; Python; MATLAB; Data analysis; Glacial isostatic adjustment; Planetary Sciences","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:9f95c482-939d-42f4-81a8-15ba18594d0e","http://resolver.tudelft.nl/uuid:9f95c482-939d-42f4-81a8-15ba18594d0e","Site-specific validation of turbulence models on large offshore wind farms for improving fatigue assessment","Ghauri, Rameen (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Wind Energy)","Watson, S.J. (mentor); Valldecabres Sanmartin, Laura (graduation committee); Iliopoulos, Alexandros (graduation committee); Delft University of Technology (degree granting institution)","2021","Wind turbines installed in a wind farm are typically subject to increased turbulence because they are in the wake of upstream wind turbines that generate additional turbulence. Accurate prediction of turbulence in wind farms is critical as it is proportional to wind turbine fatigue loads, power losses and prediction of wind farm lifetime. IEC Standard 61400-1 suggests the use of the semi-empirical turbulence model called Frandsen model, which was originally proposed in 1999. Since the development of the Frandsen model, the size of wind turbines and wind farms has increased significantly. Therefore, this work aims to determine the accuracy of two versions of the Frandsen model: Standard and Modified, when applied to large offshore wind farms experiencing a combination of atmospheric stability conditions. This is done by comparing the estimated wind farm turbulence under specific atmospheric stability conditions with measurements from Westermost Rough and Horns Rev 2. It was found that the atmospheric stability distribution and the distance of the upstream wake inducing wind turbine at the offshore site plays a significant role in the accuracy of the estimated turbulence from the Frandsen models. The estimated turbulence intensity from the Standard and Modified Frandsen models was found to be under-predicted with respect to the measured turbulence for all atmospheric stability conditions at both wind farms. For wind directions with wake flow for upstream wind turbines more than 10 rotor diameters away, the Modified Frandsen model showed better prediction of turbulence intensity compared to the Standard Frandsen model. On the other hand, for wind directions with wake flow for upstream wind turbines less than 10 rotor diameters away, the Standard Frandsen model showed better turbulence intensity estimation compared to the Modified Frandsen model. Among all atmospheric stability conditions, the turbulence intensity estimate was closest to the measured data for unstable conditions. It is suggested that this fact can be attributed to the presence of a significant number of unstable conditions in the offshore wind farms used for the design of the semi-empirical Frandsen model.","Frandsen model; Turbulence Intensity; Wake model; atmospheric stability; Offshore Wind Energy; Wind Farm","en","master thesis","","","","","","","","2023-03-10","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:0ac3d3b5-c1f5-4858-ae8a-df9d05ccb684","http://resolver.tudelft.nl/uuid:0ac3d3b5-c1f5-4858-ae8a-df9d05ccb684","Laser-beam welding as a method to characterise in-situ local thermo-mechanical conditions leading to liquid zinc embrittlement of Dual-Phase steel","Rombouts, Huub (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Team Marcel Hermans)","Hermans, M.J.M. (mentor); Agarwal, G. (graduation committee); Popovich, V. (graduation committee); Gao, He (graduation committee); Sood, A. (graduation committee); Delft University of Technology (degree granting institution)","2021","Liquid metal embrittlement (LME) is a problem encountered in the resistance spot welding joining process of advanced high-strength steels in the automotive industry. Its occurrence reduces the mechanical performance of welds. The nature of resistance spot welding prevents in-situ characterisation of thermo-mechanical conditions causing LME. Laser-beam welding (LBW) under tension is proposed as an alternative method to analyse LME cracks growing during the welding process of a DP1000 dual-phase steel grade. The influence of global thermo-mechanical parameters on the degree of embrittlement is investigated through Gleeble hot tensile tests. LBW schedules are explored, and material characterisation used to find and prove LME crack occurrence. Finite element analysis with COMSOL is used to connect results from Gleeble hot tensile tests with results from LBW and relevance to RSW is outlined. Results show that a temperature dependent ductility trough is present between 750 and 900¬∞C. The Fe-Zn system is further found to require specific mechanical conditions (stress and strain rate) to become susceptible to LME. The proposed LBW setup is found to be susceptible to LME, but not in a high enough severity to be detectable through SEM and EDS. Changes should be made to the loading setup of the LBW setup to induce LME crack growth to a sufficient degree to allow for in-situ monitoring of local thermo-mechanical conditions surrounding the crack.","Liquid metal embrittlement; DP steel; Laser Beam Welding; Resistance spot welding","en","master thesis","","","","","","","","","","","","Materials Science and Engineering","",""
"uuid:0fd717ea-7edc-4b25-bea1-f3d8276f5f07","http://resolver.tudelft.nl/uuid:0fd717ea-7edc-4b25-bea1-f3d8276f5f07","Zachte Wacht: a concept promoting long-term social support for CSN parents","Kingma, Irene (TU Delft Industrial Design Engineering; TU Delft Human-Centered Design)","Stappers, P.J. (mentor); van Boeijen, A.G.C. (graduation committee); Delft University of Technology (degree granting institution)","2021","When a child with special needs is born, the lives of all family members radically change, and so does their family culture. For the well-being of their parents, it is crucial that they feel connected with the people in their surroundings, for fulfilling their fundamental human needs, for maintaining their connection with their surrounding culture, and to get support in the many challenges they encounter. Therefore, the first aim of this graduation project is to provide the designers of Ontzorghuis with an overview of information that contributes to their understanding of the bigger picture regarding the relationship between CSN parents and the people in their surroundings. Insights from literature research, interviews with experts, and contextmapping research with 6 highly educated CSN parents with Dutch heritage, have resulted in 3 overviews of information. The Opportunity Framework lays out the different levels in capacities that CSN parents desire from people in their social surroundings, going from a vague acquaintance to a close friend. The Framework of Values illustrates 3 influential values of CSN parents, to better understand what is important to them and how their coping strategies are affected. The Practical Learnings and Attitudes offers designers an understanding on a more practical level. It offers insight into the psychological challenges CSN parents can face, navigating their own and other people‚Äôs expectations and attitudes. Secondly, this project proposes a design intervention that supports CSN parents in awaking a feeling of ownership among a few people in their social surroundings. The final design is a DIY-booklet with the following key aspects: it invites CSN parents to be soft with themselves, it promotes the common recognition and acceptance of long-term social support, and it inspires CSN parents to make it a positive event to ask for long-term support. The main message incorporated in the booklet is: it is important to be kind to yourself and it is okay to need support. First, the booklet introduces them to the novel concept of ‚Äòzachte wacht‚Äô or soft guard, a long-term social support circle for CSN parents. Secondly, it encourages them to reflect on what they expect of themselves, what they need to stay on their feet in the long term, and what they can expect of people in their surroundings. Thirdly, it guides CSN parents through the steps of setting up their own support circle, the final step being a small ceremony to seal their supporters' commitment. Although there is still room for iteration, the evaluations of 6 CSN parents demonstrated that the design is desirable for the target group. Everyone that expressed their opinion of the zachte wacht, CSN parents as well as experts, considered it to be a beautiful concept. The design capabilities, understanding of the target group, and network needed to implement the booklet and other aspects of the concept are a perfect fit with the unique strengths of Ontzorghuis. The concept has the potential to appeal to a large and growing target group. Moreover, promising opportunities for collaborations, funding, and subsidies are awaiting.","culture change; CSN parents; Design for well-being; Context mapping; Medisign","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:b7b03c36-899f-44d9-b57e-b9e7f2b7bec8","http://resolver.tudelft.nl/uuid:b7b03c36-899f-44d9-b57e-b9e7f2b7bec8","System identification of a dynamical model of a vehicle using data generated by a high-fidelity simulator","Zhang, Chenxi (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Delft Center for Systems and Control)","Ferrari, R. (mentor); Mazo Espinosa, M. (graduation committee); Keijzer, T. (graduation committee); Delft University of Technology (degree granting institution)","2021","Unmanned vehicles are a vital topic in today‚Äôs science and technology field. The safety problem of unmanned vehicles has been paid more attention from researchers. People are continually developing new control technologies, making the auxiliary driving or control of vehicles more accurate and reliable. Before designing a reliable controller, researchers need to obtain an accurate model of the vehicle system. However, the vehicle is a complex system, and various vehicle parameters are difficult to obtain by direct sensor measurement. In addition, there are deviations between the actual vehicle and the simulation model. At this time, it is necessary to make system identification to obtain reliable vehicle parameters and models. In this paper, vehicle simulation is carried out based on the CarSim C-Class model under the environment of CarSim vehicle simulation software. The model includes tire, suspension, steering, driver, and other subsystems. This platform can simulate a vehicle closed to the real one. The vehicle model can be controlled through Simulink and output the real-time data of various variables of the vehicle system. Then, the data required for identification and validation can be obtained through the joint simulation of CarSim and Simulink. By comparing different vehicle and tire models, different identification data sets and different algorithms, this paper summarizes the advantages and disadvantages of different choices and their applicability. First, the comparison between the bicycle model and the four wheels vehicle model is implemented. The Interior-point algorithm was used to identify the two models under different control data sets. The results of parameter validation and vehicle validation are analyzed. Then, under the same control data set, the four wheels model is selected for the comparative experiment between different algorithms. The first comparison with the Interior-point algorithm is the Unscented Kalman Filter (UKF) and its improved method Particle Swarm Optimization-Unscented Kalman Filter (PSO-UKF). The Magic Formula tire model was then identified by Genetic Algorithm (GA) algorithm, which compares with the Dugoff tire model. Each model and algorithm has its suitable scenarios. Also different data sets lead to various result. The analysis and application suggestions of different algorithms, data sets and models will be given in the end.","system identification; vehicle dynamics; interior-point method; Unscented Kalman","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:ca4a458f-6307-4268-8ea8-969d37e95631","http://resolver.tudelft.nl/uuid:ca4a458f-6307-4268-8ea8-969d37e95631","A new approach in optimal sensor placement for smart hydraulic monitoring in intermittent water supply (IWS) systems: A technical and financial analysis of the use of flow and pressure meters to detect hidden leaks in large cities in sub-Saharan Africa","Verbart, Joost (TU Delft Civil Engineering and Geosciences)","van der Hoek, J.P. (mentor); Abraham, E. (graduation committee); van Andel, E. (graduation committee); de Groot, R. (graduation committee); Delft University of Technology (degree granting institution)","2021","This thesis proposes a novel design approach for a monitoring system that can detect hidden leaks in intermittent water supply (IWS) systems. Cities with IWS conditions in their drinking water network, such as Nairobi and Harare, often have a high percentage of non-revenue water (NRW) in their system. Estimations of the amount of NRW in these cities range from 40% to 50%, of which a large part is due to a leaky infrastructure. Intermittency of water supply is usually caused by a shortage of available supply, making it extra poignant to notice that these areas lose significant volumes of water. The leaks are also important locations for contaminant intrusion, which deteriorate the quality of drinking water. Additionally, intermittency of supply results in people using storage to fulfill themselves with their weekly water demand, which provides new challenges when constructing hydraulic models. Hidden leaks, which are leaks that do not appear at the surface, can be noticed in continuously supplied areas through reports of pressure deficiencies or the absence of supply. As these are regular circumstances in IWS areas, these hidden leaks are seldom noticed. Therefore, methods that are applicable in IWS systems need to be developed to detect these hidden leaks. This thesis proposes a new approach to detect hidden leaks in IWS areas with a smart hydraulic monitoring system. The approach optimizes the design of such a system in a district metered area (DMA) with IWS conditions in sub-Saharan Africa, by balancing information density and investment costs. By using as little equipment as possible, this optimization study aims to be not only scientifically and practically relevant, but also cost-effective. The methodology that was used to design the monitoring system makes use of a similar concept as the Dynamical Bandwidth Monitor (DBM), which is a smart hydraulic monitoring system that has been applied regularly in networks with continuous supply. The monitoring system consists of sensors that continuously measure flow or pressure and it compares these measurements to a range of expected values, attributing deviations from these expected values to a potential leak. A case study of Ashdown Park, a DMA with IWS conditions in Harare, was used to assess the performance of the design. The flow into this DMA and the pressure at its inlet had been monitored for one year. Two designs of the monitoring system were made, one which mainly consisted of flow sensors and one with mostly pressure sensors, to showcase which type of sensor could best be used in Ashdown Park. A hydraulic model was constructed for the DMA using pressure dependent outflow modelling. Daily demand patterns were constructed from analyzing the inflow measurements and used to calibrate the hydraulic model. The proposed calibration method assumes linear relationships between the demands and inlet pressure on one side and the pressure at a specific node and flow at a specific pipe on the other side. The range of expected flows and pressures within the DMA was calculated by Monte Carlo analyses, during which demand realizations were modelled by using a novel method which made use of a random weighted choice of demand, based on the outflow from a single tap. The ability of the monitoring system to detect leaks during different demand realizations was stored in a three-dimensional Boolean matrix, which was then used to determine the optimal sensor placement. A social and financial analysis, summarized in a business model canvas, shows more practical challenges and opportunities that could arise from implementing the monitoring system. The lessons learnt from this thesis were used to showcase whether the monitoring system could be applicable for IWS systems around the globe. Several conclusions can be drawn from the results of this thesis. The daily demand patterns in Ashdown Park showed a different pattern than in continuously supplied systems, showing less strong peaks. This could be due to a constant water demand for filling storage, leaks in the system or different consumer behaviour. The calibration method made it possible to model flows and pressures at the DMA inlet which were comparable to the measurements. The novel method to model demand realizations with a random weighted choice and a single tap capacity, showed promising results since the spread of the modelled inflow was well comparable to the spread of the inflow measurements. This standard tap capacity is especially suitable for IWS areas, since most people in IWS areas usually only have one tap directly connected to the water supply system and water end-use devices are not directly connected to the network. Furthermore, it was found that the water use behaviour of inhabitants of Ashdown Park had been more constant than the supply behaviour of the water utility. This irregular supply behaviour of the utility increased the difficulty of designing a pressure monitoring system. Using a flow monitoring system to detect leaks showed a better performance (leaks could be found on a daily basis in 25% of the pipes in the DMA) than using a monitoring system with pressure sensors (leaks could be found in 1% of the pipes). Making the monitoring system with pressure sensors dependent on the inlet pressure increased its performance (from 1% to 8.3%). Branched parts of the system were more favorable locations to place sensors and sensors at the DMA inlet were crucial for calibrating the hydraulic model. Practical barriers that were identified during this thesis were irregular operational schemes, unknown demand patterns and incomplete GIS data. Furthermore, costs can be saved as soon as leaks are detected, making the financial profitability very dependent on the performance of the system and the occurrence of leaks. The applicability of the monitoring system in IWS areas around the globe is determined by the priorities of a local water utility, its network characteristics and the ability of the local utility to overcome implementation barriers. The main limitations in this research are due to making some simplified assumptions, such as assuming a constant flow-rate from the tap in all households in Ashdown Park, and due to a lack of understanding of the local situation, since this research was performed in the Netherlands. To validate assumptions and get better understanding of the local situation, it is advised to conduct follow-up research at the location of interest. Especially a pilot project of the proposed monitoring system would likely find more practical barriers and limitations than could be thought off in this thesis and therefore bring more valuable information for the implementation of a smart hydraulic monitoring system. If prioritized, properly installed and operated, the proposed smart hydraulic monitoring system could generate substantial water savings and provide many social benefits, such as an increased access to clean drinking water and employment opportunities. Above all, it can assist a local utility with fulfilling their responsibility: supplying people with the basic need of drinking water.","water supply system; intermittent water supply; Leak; leak detection","en","master thesis","","","","","","","","","","","","Water Management","",""
"uuid:fec55def-38b1-44d6-ad36-0c7e080b43bc","http://resolver.tudelft.nl/uuid:fec55def-38b1-44d6-ad36-0c7e080b43bc","The repairability of car body panels in a circular economy: case study: Microcab Industries Ltd","Mak van Waay, Rutger (TU Delft Industrial Design Engineering)","Joustra, J.J. (mentor); Bakker, C.A. (graduation committee); Delft University of Technology (degree granting institution)","2021","The current vision of Microcab is to increase the repair capabilities of the VIANOVA. Part of that vision is to begin the shift towards a circular economy in which the lifecycle of the product is extended, and parts can be processed in a circular manner during the lifecycle. Considering that Microcab is a small company and the challenge is considerable, additional safety regulations mean that a vehicle should become a road-safe vehicle. This graduation project contributes to this challenge by researching the main question that focusses on the front section of the vehicle: ‚ÄòHow can Microcab design the front section of the VIANOVA to increase the repairability and solve the safety issues?‚Äô. Through several analyses and explorative design directions, the result is a concept that reconfigures the front section of the VIANOVA to allow for increased repairability and better safety requirements while maintaining the goal of becoming more circular. An important requirement is that the concept should allow for a production volume of 500 units annually. The current design of the front clip is a single large body panel hand-made from a glass fibre reinforced thermoset, which is difficult to repurpose and recycle. Based on research data, a sustainable alternative known as thermoplastic olefin (TPO) is introduced. Furthermore, the front clip has been split into four segments. These changes allow for better repair capabilities and lower the overall impact of a low-speed collision. In order to make this possible, structures were required to support the panels and increase energy absorption. The bonnet with incorporated headlights is enlarged to increase accessibility during service and fixated on the support structure, removing it from the impact zone. The support was required to improve safety for pedestrians and increase protection of internal components. This support consists of adding an energy absorber, upper load beams, cross member, and extending the width of the bumper beam. Additionally, it is recommended to use plastic fasteners to increase circular capabilities, considering that these are more likely to break, allowing for the body panels to remain intact. Lastly, it is recommended to implement a different type of surface finish. 3M provides an PVC-free wrap material, reducing the use of harmful chemicals and increasing repairability and circularity. This change also provides opportunities to illustrate internals or implement advertisement. Therefore, the project reveals that there are multiple elements that can have a positive influence on the repairability and safety issues while at the same time, shift towards a circular economy. The recommendations that emerged from the project provide a high desirability, but will require follow-up research am physical crash testing to determine optimal configuration of the front section, and create a better understanding of the elements and how they influence impact resistance and repairability.","Circular economy; Repairability; Safety; Car body panels","en","master thesis","","","","","","","","","","","","","",""
"uuid:9e6ce94e-d103-4a35-857c-648715614a9e","http://resolver.tudelft.nl/uuid:9e6ce94e-d103-4a35-857c-648715614a9e","A physics guided neural network approach for dose prediction in automated radiation therapy treatment planning","Meerbothe, Thierry (TU Delft Applied Sciences; TU Delft RST/Medical Physics & Technology)","Perko, Z. (mentor); Janssen, Tomas (mentor); Hoogeman, M.S. (graduation committee); Greplov√°, E. (graduation committee); Delft University of Technology (degree granting institution)","2021","Radiotherapy treatment planning is a complex and time consuming process prone to differences as result of choices of individual planners. Autoplanning systems have been introduced to both reduce the time consumption and to counteract the influence of individual planning choices. Although autoplanning generally increases performance of the treatment plans, the plans still need to be checked manually to ensure plan accuracy. Increasing plan consistency with knowledge based planning (KBP) or automatic plan evaluation would be clear ways to improve upon this problem. For both improvements, deep learning can be an important tool to produce accurate and fast 3D dose distributions. In this study such a deep learning tool is developed in two parts to accommodate this. <br/>In the first part a structure based deep learning model, using a U-Net architecture is developed, used for dose distribution prediction for prostate patients treated with volumetric modulated arc therapy (VMAT) plans, generated by autoplanning. Different loss functions have been tested to see which achieve the best results. In the second part physics information is included in the neural network prediction by using a hybrid physics-data approach. For this, an approximate dose distribution, the segment dose, is used as extra input for the dose prediction network. This segment dose is created by predicting multi leaf collimator (MLC) positions and reconstructing the corresponding dose with a simple dose engine. The predictions are evaluated using several dose characteristics, dose volume histogram (DVH) curves and other clinically relevant metrics. The U-Net architecture proved able to accurately predict the dose of patients in the test set. The best performing loss function for accurate dose characteristics prediction was found to be the weighted mean squared error (WMSE) loss, which predicted several PTV DVH statistics within a 1.5 % error and the rectum statistics within 3.5 % error. Furthermore, the model predicts the DVH points of the PTV within 0.84 ¬± 0.40 Gy average absolute dose difference and the rectum in 0.91 ¬± 0.72 Gy average dose difference. The hybrid physics-data model did not improve the prediction accuracy of the dose prediction model in terms of DVH statistics and DVH prediction, as the MLC positions could not be predicted accurately enough. The performance of the structure based prediction is similar to the performance of state-of-the-art prediction models. Although the hybrid model with the predicted segment doses did not improve the prediction accuracy, a significant effect could be seen from using the correct MLC positions instead. The bottleneck of the prediction is therefore identified to be the segment prediction. As such, it would be interesting to focus on segment prediction in follow up research.","Radiotherapy; Treatment Planning; Deep learning","en","master thesis","","","","","","","","","","","","","",""
"uuid:6377ff43-78c3-4afa-bdc2-a65d0a90860f","http://resolver.tudelft.nl/uuid:6377ff43-78c3-4afa-bdc2-a65d0a90860f","Collaborative identity in project alliances: improving collaboration through collaborative identity formation","Ligthart, Chiara (TU Delft Civil Engineering and Geosciences)","Soltani, P. (mentor); Straub, A. (graduation committee); Bosch-Rekveldt, M.G.C. (graduation committee); Delft University of Technology (degree granting institution)","2021","As a result of the high failure costs and many project delays in the construction industry, collaborative contracts emerged in an attempt to improve project performance. The project alliance was one of them. This integrative way of working requires a focus on the human aspects, because people from different organisational cultures are brought together, but this is not the case in practice. One of these human aspects is the formation of a collaborative identity.A collaborative identity refers to the collaborative values and working practices that form the organisational self-image and differentiates the organisations from others. It provides a feeling of belonging for each individual within the project alliance. The collaborative values and working practices that are required to build a collaborative identity are unknown, and therefore this research answers the question ""How can collaboration within a project alliance be improved through a focus on the formation of collaborative identity?"". The research is performed by means of a literature study as well as a Delphi study with two participating project alliances. The main outcome of the research was that forming a collaborative identity requires a different combination of working practices and collaborative values, that were defined during this research, for different project alliances.","Project alliancing; Collaboration; Collaborative identity formation; Project delivery method; Client-contractor collaboration; Delphi study","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:582a1501-01c0-4492-99ba-df0a524535de","http://resolver.tudelft.nl/uuid:582a1501-01c0-4492-99ba-df0a524535de","The Design and Validation of a Dynamic Arteriovenous System Valve Mechanism","White, Nick (TU Delft Mechanical, Maritime and Materials Engineering)","Horeman, T. (mentor); Rotmans, Joris (graduation committee); Delft University of Technology (degree granting institution)","2021","Background: Patients suffering from end-stage renal disease (ESRD) often require haemodialysis to filter the blood of waste products. Currently, an arteriovenous fistula (AVF) or graft (AVG) is used in most cases to enable sufficient blood flow for haemodialysis, but these have been associated with a large number of undesirable patient outcomes. Most of these can be linked to the resulting constant high blood-flow and the anastomosis remaining in an open position. To counter this, an implantable Dynamic Arteriovenous System (DAS) that can regulate blood flow through an anastomosis is to be developed. For this, a valve mechanism is to be designed and validated, that converts a mechanical translation from an actuator into an opening and closing motion on a synthetic graft.<br/>Objective: The goal of this research is to design a proof-of-concept DAS valve mechanism, and validate this ex vivo.<br/>Method: A methodological approach was utilised to generate concepts for a DAS valve that can fully collapse and open a synthetic graft acting as anastomosis. A Harris profile with a set of grading criteria is set up to determine the optimal concept. This concept is assessed through means of a number of test setups, that includes force measurement during collapse and opening of the graft, traction, and lifetime.<br/>Results: The result of the design study is a linkage mechanism utilising pinhole joints that converts the input into an (approximately) vertical translation on the top and bottom of the graft. A transmission ratio that approaches infinity when the graft is fully<br/>collapsed is achieved, whilst allowing an infinite number of states to control flow when open. The majority of the requirements set are met, but the necessary input force, traction andmass require some optimisation to fulfil the criteria.<br/>Conclusion: From this study it was concluded that the current design shows promise but a next design iteration is necessary to fully meet all design criteria. Future research should include the transmission of the actuator input to the valve and the assessment of foreign body response, which may require the development of a sealing method.","Haemodialysis; Implantable Medical Devices (IMDs); Mechanical; Design; Validation and Verification","en","master thesis","","","","","","","","2026-02-26","","","","","",""
"uuid:e5da7c83-7e6c-43d2-80b6-7e9d9dd34706","http://resolver.tudelft.nl/uuid:e5da7c83-7e6c-43d2-80b6-7e9d9dd34706","The application of differentiable programming frameworks to computational fluid dynamics","Vos, Bart (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Delft Institute of Applied Mathematics)","Verlaan, M. (mentor); Nuttall, Jonathan (mentor); Budko, N.V. (graduation committee); Delft University of Technology (degree granting institution)","2021","In recent years many automatic differentiable programming frameworks have been developed in which numerical programs can be differentiated through automatic differentiation (AD). Examples of these frameworks are Theano, TensorFlow and Pytorch. These frameworks are widely used in Machine Learning. AD also finds applications in the field of computational fluid dynamics (CFD). It is used to develop discrete adjoint CFD code for research concerning for instance sensitivity analysis, data assimilation and design optimization. However, the use of the automatic differentiable programming frameworks in the field of CFD is limited. One can find some examples in the literature on how to find a numerical solution to an initial value problem using a differentiable programming framework. In this work it will be clarified how one can implement an semiimplicit<br/>time integration scheme for a staggered grid to simulate the propagation of long waves in water with a free surface in TensorFlow. A main advantage of the automatic differentiable programming frameworks is the user friendly application<br/>programming interface (API) for AD. No research has been conducted to use this API in the field of CFD. In this work an example will be given how one can use TensorFlow for research concerning sensitivity analysis. AD requires a significant allocation of memory on a CPU/GPU when working with fine meshes and/or long simulations and since CPU/GPU memory is finite, the method checkpointing is<br/>proposed to make it feasible to perform sensitivity analysis when working with fine meshes and/or long simulations. Another main advantage of the differentiable programming framework TensorFlow is the use of compute unified device architecture (CUDA) of a NVIDIA GPU in order to perform computations in parallel, which results in a significant reduction in computation time. A Benchmark will be given that indicates the computational efficiency of TensorFlow compared to a loop over grid implementation in NumPy and a Fortran CPU scalar implementation.","Computational Fluid Dynamics (CFD); Tensorflow; Shallow Water Equations; Automatic Differentiation; Sensitivity Analysis; Checkpointing; Adjoint-based optimization; Partial Differential Equations solver; Differentiable programming","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:e95d9e3f-e5c3-41c3-a093-7c3fbbc6f579","http://resolver.tudelft.nl/uuid:e95d9e3f-e5c3-41c3-a093-7c3fbbc6f579","Buckling of Isotropic and Composite Cylindrical Shells with Circular Cutouts","Schiller, Arne (TU Delft Aerospace Engineering)","Bisagni, C. (mentor); Kassapoglou, C. (graduation committee); Bergsma, O.K. (graduation committee); Hilburger, Mark W. (graduation committee); Delft University of Technology (degree granting institution)","2021","Predicting the critical buckling load of cylindrical shells with circular cutouts subjected to uniform axial compression is an important part of the structural design in the aerospace industry as buckling significantly reduces the load-carrying capability of the structure. A cutout constitutes a major disruption in the shell geometry, and therefore it should be expected that it has a significant effect on the sustainable buckling load. An analytical solution for estimating the buckling load of isotropic and quasi-isotropic composite cylindrical shells with circular cutouts is developed to assess changes made to the geometry and the material during the preliminary design phase quickly. The Ritz method is employed to minimize the total potential energy of an ideal shell that contains a central opening in order to predict a linear buckling load. Finite element simulations are conducted to verify the accuracy of the analytical solution. In addition, they are used to investigate the evolution of buckling modes, the effects of initial geometric imperfections, as well as the shell failure mode. The nondimensional curvature parameter Œ± can be used to categorize the buckling behavior of cylindrical shells and is a function of the cutout radius, the shell radius, and the shell thickness. A small cutout has virtually no influence on the buckling load compared to a pristine shell and the displacement pattern at buckling is global. The buckling load decreases rapidly for moderately large cutouts where the stability loss is the result of a local buckling mode that immediately leads to global buckling. Cylindrical shells with large cutouts are again relatively insensitive to an increase of the cutout size, but the buckling load is greatly reduced relative to a shell without a cutout. Large openings also feature a stable local buckling mode where substantial lateral prebuckling displacements emerge before the structure buckles globally. While the analytical procedure theoretically should not capture the onset of global buckling independent of local buckling, it follows numerical trends for cutouts of moderate and large size regardless. Therefore, it may be used during preliminary design to estimate the impact of changes made to the shell geometry and material. Local buckling is caused by high compressive stresses next to the cutout and, in some cases, large lateral prebuckling displacements. The detrimental effect of the stress field may be partially relieved in composite cylindrical shells by reducing the amount of axial bending stresses that occur. Hence, the chosen stacking sequence can have a significant influence on the buckling load of shells with moderate and large openings.","Buckling; Cylindrical Shell; Cutout; Analytical Solution; FEM","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:3d1f41c7-da33-42e7-a76f-414d93907eac","http://resolver.tudelft.nl/uuid:3d1f41c7-da33-42e7-a76f-414d93907eac","Auction-based task allocation for online pickup and delivery problems with time constraints and uncertainty","Rizzo, Paolo Rizzo (TU Delft Aerospace Engineering)","Sharpans'kykh, O.A. (mentor); Delft University of Technology (degree granting institution)","2021","Auctions have established themselves as highly efficient mechanisms for the online allocation of time-constrained pickup and delivery tasks, which is an important problem in the domain of distributed autonomous systems. Current methods leverage simple temporal networks (STNs) to allow agents to efficiently process temporal constraints in the bidding phase of the auction. However, they suffer from two major weaknesses which limit their applicability in real-world systems. Firstly, they are relatively ineffective when tasks have non-deterministic durations, as the STN representation enforces a binary notion of plan controllability which is highly restrictive. We remedy this by introducing the probabilistic temporal sequential single item auction (pTeSSI), a novel polynomial-time auction-based task allocation mechanism in which plans are represented as simple temporal networks with uncertainty (STNUs). Using a recently proposed non-binary characterization of controllability in STNUs, agents efficiently determine the risk of unsuccessful dispatch of their temporal plans and incorporate this in their bids. We evaluate our auction mechanism in an online simulation of an on-demand UAV delivery system and demonstrate that it is more effective and efficient than the current state of the art method. In addition, we propose a dynamic re-auctioning routine to address the second main weakness of sequential auctions when applied to online problems, namely that they do not revisit existing partial allocations over time. We demonstrate that dynamic re-auctioning increases the quality of the allocation and improves system performance, but also increases the auction duration. We mitigate this downside by bundling tasks based on their spatio-temporal synergy and auctioning bundles, rather than single tasks, at once.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:719b0197-dfce-4d6c-8437-e3011ff3bb1f","http://resolver.tudelft.nl/uuid:719b0197-dfce-4d6c-8437-e3011ff3bb1f","Designing a compliant hip-back support for an exoskeleton","Cratsborn, Tom (TU Delft Mechanical, Maritime and Materials Engineering)","Amoozandeh Nobaveh, A. (mentor); Radaelli, G. (graduation committee); Herder, J.L. (graduation committee); van den Dobbelsteen, J.J. (graduation committee); Delft University of Technology (degree granting institution)","2021","This report is written for the thesis of my master Mechanical Engineering that was conducted at the department Precision and Microsystems Engineering of the Delft University of Technology. The goal of the project was to design a compliant hipback support of an exoskeleton while researching how to achieve desired directional compliance on this application. This work starts with an introduction to exoskeletons and explaining their working principles. The problem is that the reduction of range of motion for wearing an exoskeleton reduces the adoption of exoskeletons in industry. The objective of this study was to solve this by creating a hipback support with compliant behaviour in torsion and lateral bending while remaining stiff in the supporting forward bending direction. For inspiration, the state of the art of current hipback supports and research projects was reviewed. Also, the characterization methods of compliant mechanisms were reviewed for inspiration, to come up with a suitable design method for developing a compliant structure for a hipback support. By tuning stiffness of the structure in distinct directions, a conventional synthesis method for compliant mechanisms could be applied, namely the Freedom and Constraint Topologies method. This was used to come up with a preliminary design. This design was extended to improve stiffness behaviour for coupled motions by researching how to change stiffness on demand. The only categories to change stiffness are shape, material, prestress and boundary condition. For each category, a promising highlevel design was worked out with improved stiffness behaviour for coupled motions. To generate an even more satisfying solution, optimization of the beam shape was applied to handle the defined rather complex kinetostatic task and to develop a lightweight structure. The objective function was to reach specified deflections where shaperelated parameters are optimized. These parameters were the spine shape of the beam, the crosssection and orientation of the crosssection. To generate a design, a selfdeveloped optimizer using beam modelling was extended and applied. The extensions were to optimize a doubleclamped beam that was loaded in the middle point and optimizing for angular deformations as a set objective function. This extended optimizer generated the final design which was a thin rectangularshaped beam with threedimensional curves. This design was not straightforward to fabricate into a prototype. Multiple manufacturing methods were evaluated and one final method was selected to fabricate a close approximation of the final design. This final manufacturing method was to produce the prototype by roll bending and manually applying a twist on a curved lasercut strip which was extracted from flattening of the spatial shape. This prototype was verified by simulations and experiments. Simulation tests were run on an original design of the back support and compared with the new optimized shape based on the requirements. The results, for similar loadings and material, are 27 times more lateral flexibility, 1.25 more torsional flexibility and a design that is four times lighter in comparison to the original design. The original relative stiffness of 1 to 1 for forward relative to lateral bending improved to 2 to 1. An important remark to note is that the beam model generated a thin section which was less suitable for 1D beam modelling of the implemented FEM. Creating an optimizer based on 2D shell modelling code might give more accurate results and can be considered for future work.","","en","master thesis","","","","","","","","","","","","Mechanical Engineering","",""
"uuid:3014e195-28c7-49e9-9e29-1e468d045325","http://resolver.tudelft.nl/uuid:3014e195-28c7-49e9-9e29-1e468d045325","Adaptive Incremental Nonlinear Dynamic Inversion for Consistent Pitch Rate Control","Smit, Beau (TU Delft Aerospace Engineering)","van Kampen, E. (mentor); Pollack, T.S.C. (graduation committee); Delft University of Technology (degree granting institution)","2021","Control augmentation systems based on Incremental Nonlinear Dynamic Inversion (INDI) are able to provide high-performance nonlinear control without the need for a model of the complete system. Considering a pitch rate control law for a fixed-wing aircraft, only a model for the elevator control effectiveness (CE) and sensor feedback of the pitch acceleration are required for the model inversion. Despite the increased robustness against model error due to the decreased model dependency, control laws based on INDI could still show performance variation when the on-board CE model deviates from the actual CE. This thesis will put this in the context of the control performance of high-performance aircraft. Furthermore, multiple adaptive INDI control techniques are investigated as possible solutions. This study revealed that adaptive control based on Least-Mean-Square (LMS) parameter estimation has the most potential. A second analysis using handling quality and stability (HQ&amp;S) requirements showed that this approach is able to decrease variation in the HQ&amp;S as well. However, the results also show that HQ&amp;S variation for large centre of gravity shifts could not always be fully mitigated by adaptive control as it is possible that the time-scale separation assumption becomes impaired.","Incremental Nonlinear Dynamic Inversion; flight control; Adaptive control; Handling Qualities","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:dab8c214-1203-458b-ad60-ef831c5b62a4","http://resolver.tudelft.nl/uuid:dab8c214-1203-458b-ad60-ef831c5b62a4","Designing Efficient Renewable Energy Portfolios: A Dutch Case Study Including Dynamic Tidal Power: A Novel Application of the Modern Portfolio Theory","T√∂nis, Max (TU Delft Technology, Policy and Management)","Stikkelman, R.M. (mentor); Schr√∂der, E. (graduation committee); Jonkman, Sebastiaan N. (graduation committee); Delft University of Technology (degree granting institution)","2021","By signing the Paris Climate Agreement, The Netherlands has committed itself to curtail its CO2- emissions in order to keep global warming well below 2¬∞C above pre-industrial levels. Pivotal to achieve these targets is the phase-out of CO2-intensive electricity generation technologies and investments in renewables. Current investments aiming to decarbonise the electricity system are predominantly allocated to solar PV and off- and onshore wind energy. However, this trajectory might change as the development of Dynamic Tidal power (DTP) might soon enable The Netherlands to harvest the North Sea‚Äôs currently unutilised tidal currents to generate clean electricity. DTP uses a 30-70 kilometre long dam perpendicular to the coast to capture the North Sea‚Äôs tidal currents. The alternating currents that proceed parallel to the coast create a hydraulic head over the dam, which turbines in the dam convert into electricity. However, the variable availability of solar irradiation, wind, and tidal currents makes it increasingly complex and costly to match electricity supply and demand as their shares in the electricity mix increase. To ensure electricity security, freely dispatchable energy generators (e.g. natural gas, biomass or coal turbines) are deployed to cover the electricity load that could not be met by the variable renewable energy (VRE) generators. However, due to the fuel used to generate electricity, dispatchable energy sources tend to emit CO2 and bear higher marginal energy generation costs than VRES. To address this problem, the portfolio shares of solar PV, offshore wind, onshore wind and DTP that minimise the need for dispatchable backup capacity and the energy generation costs were computed in this study. Due to its novelty, special attention was paid to the effect of DTP on a VRE system‚Äôs ability to efficiently match supply and demand. In order to achieve these objectives, a novel application of the Modern Portfolio Theory (MPT) was used. The MPT originates from the stock market but is often used to comprise VRE portfolios that maximise the electricity output. However, as the aim was to minimise the residual load, demand-variability was introduced into the MPT. Existing literature had not covered this topic. Hence, by assessing to what extent including demand-variability in the MPT affects the selection of efficient VRE portfolios, this study filled a gap in the literature and serves as a starting point for future research into the application of the MPT. In total, three different electricity demand scenarios were optimised; the contemporary load profile (1), increased peak loads due to an extreme penetration of electric vehicles (EV) and electric heat pumps (HP) (2), and a flat load profile due to an extreme penetration of demand-responsive measures (3). The most efficient portfolio shares for each demand scenario were found by computing how 35GW should be distributed among solar PV, offshore wind, onshore wind and DTP in order to minimise the need for backup capacity and energy generation costs. The results of this study indicate that regardless of the demand profile, The Netherlands‚Äô VRE system would be most cost-efficient in meeting demand when comprised of approximately 75% DTP and 25% offshore wind. However, only under the condition that the DTP-dams are geographically dispersed. Geographically dispersed DTP-dams, for example, located in Zeeland (south of The Netherlands) and off the coast of Texel (north of The Netherlands), cancels out the volatility in the electricity output caused by high and low tide. This reduces a VRE system‚Äôs volatility in electricity output and stabilises the electricity output from the dispatchable backup system, which minimises the system‚Äôs electricity generation costs. However, in terms of the amount of backup capacity required, it was found that a system comprised entirely of DTP with an integrated battery storage system would be even more efficient. The battery storage system eliminates all variability in the electricity output from DTP, which minimises the need for dispatchable backup capacity. However, as battery storage costs are significant (approx. 100,000 ‚Ç¨/MWh), it is unlikely that a DTP-dam with a storage system large enough to flatten its electricity output is economically viable under the current market circumstances. This might change when DTP is combined with other storage systems or if battery storage costs reduce due to learning-effect, economies of scale or technical innovations. As DTP is still in its initial development phase, it is not certain DTP will successfully penetrate the power generation market. If DTP fails to enter the market, the current VRE system (61% solar PV, 8% offshore wind and 31% onshore wind) is fairly cost-efficient. However, if the aim is to reduce the amount of dispatchable backup capacity required to ensure energy security, future investments should be allocated to offshore wind. The overarching conclusion is that there is no unequivocal VRE portfolio that is most efficient to meet demand as it depends on the perspective taken (required backup capacity versus electricity generation costs). However, this study shows that the current VRE system benefits from the inclusion of DTP, both in terms of the required amount of backup capacity and the system‚Äôs energy generation costs. Only if DTP is combined with a large battery storage system to flatten its electricity output do the system‚Äôs energy generation costs surpass the costs of the current VRE system. In regards to the effect of including demand-variability in the MPT, it was found that demand variability has a limited effect on the selection of efficient VRE portfolio shares. Only in a scenario (2) with increased peak loads did the share of offshore wind slightly increase. This is due to the fact that the peaks in electricity supply from offshore wind coincide with the peaks in demand from electric HP (winter).","Dynamic Tidal Power; Wind Energy; Solar PV; Modern Portfolio Theory; Demand-Variability; Renewable Energy; Energy Transition; Tidal Energy","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:7db77462-e6d7-4116-b00d-1c118f1de4c4","http://resolver.tudelft.nl/uuid:7db77462-e6d7-4116-b00d-1c118f1de4c4","Optimization of the short-term labor and task scheduling in the maintenance of regional trains","van Leeuwen, Anouk (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Transport Engineering and Logistics)","Duinkerken, M.B. (mentor); Schott, D.L. (graduation committee); Horjus, S.E. (mentor); Delft University of Technology (degree granting institution)","2021","The Dutch Railways (NS) is the Dutch national passenger railway operator. They own rolling stock that has to be maintained regularly. One of the maintenance facilities executing regular maintenance on regional trains is the maintenance department (OB) in Leidschendam. The aim of this project is to develop a framework for optimizing the productivity in the combined labor and task scheduling in the maintenance of regional trains on a daily perspective to increase the delivery reliability. A mathematical model has been developed based on the Resource-Constrained Project Scheduling Problem. To solve the model a hybrid method combining a genetic algorithm and an annealing-like search heuristic is proposed. Three experiments are performed using real data. During the fist experiment the schedule performance of the algorithm is compared with the performance of the schedules generated by the planners of the OB. The second experiment evaluates different qualification distributions for the available workforce. During the last experiment, the effect of the tardiness cost as introduced in this research is evaluated. The experiments show that the scheduled productivity is increased with an average of 18% per day when the algorithm is used and on average 3 more train units are completely scheduled per day.","Rolling Stock Maintenance Scheduling; Resource-Constrained Project Scheduling Problem; Hybrid Heuristics; Genetic Algorithm; Simulated Annealing","en","master thesis","","","","","","","","","","","","Marine Technology | Transport Engineering and Logistics","",""
"uuid:e0937bfd-cf55-47b6-aa6e-21cf67602490","http://resolver.tudelft.nl/uuid:e0937bfd-cf55-47b6-aa6e-21cf67602490","Artificial intelligence in local governmental agencies: Exploring the process of adopting AI-systems","Volmer, Ellard (TU Delft Architecture and the Built Environment)","Kortuem, G.W. (mentor); van der Voort, H.G. (mentor); Delft University of Technology (degree granting institution); Wageningen University & Research (degree granting institution)","2021","This MSc. Thesis explores the adoption process of Artificial Intelligence (AI) systems in local governmental agencies. The research uses a Design Science Research approach to explore this adoption process in the innovation adoption literature. The outcomes of this literature analysis are used to create a meaningful arrangement of determinants in a single framework. The use of this framework is demonstrated and tested through expert interviews. The results of this evaluation are used to iterate on a final framework that shows the adoption process of AI-systems in local governmental agencies.","Artificial Intelligence; Design Science Research; Government; public innovation; adoption process; Process design","en","master thesis","","","","","","Joint Master of Science in Metropolitan Analysis, Design and Engineering at Delft University of Technology and Wageningen University & Research.","","","","","","Metropolitan Analysis, Design and Engineering (MADE)","",""
"uuid:5e9baf63-8a8f-4c1b-98cd-5aa993938027","http://resolver.tudelft.nl/uuid:5e9baf63-8a8f-4c1b-98cd-5aa993938027","The Impact of Control Allocation on Optimal Control Surface Positioning and Sizing: A comparative study for a PrandtlPlane","Wahler, Nicolas (TU Delft Aerospace Engineering)","la Rocca, G. (mentor); Varriale, C. (graduation committee); Oliviero, F. (graduation committee); van Kampen, E. (graduation committee); Delft University of Technology (degree granting institution)","2021","Classically, aircraft controls are designed such that every control surface type primarily influences a single degree of freedom by creating a moment. Increased availability of computational resources and novel aircraft configuration allow a deviation from this approach and to utilize individual control surfaces to generate moments around multiple axes. The research investigates the impact of control allocation algorithms on the required control surface span and area for a box-wing configuration aircraft, the PrandtlPlane. The unique geometry of two full wings allows more flexibility in control surface placement. An optimization system for automatic control surface sizing under the constraints of adequate handling qualities has been developed and used to compare mechanical gearing, the constrained pseudo inverse, and the direct allocation algorithms. The results show that the PrandtlPlane configuration can benefit from the use of control allocation, showing a clear advantage of the direct allocation algorithm. <br/><br","box wing; PrandtlPlane; control allocation; direct allocation; pseudo inverse; mechanical gearing; control surface; Optimisation framework; box-wing","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:6bd0f3e6-8aa4-42ac-a2e7-c8cf3dc925d4","http://resolver.tudelft.nl/uuid:6bd0f3e6-8aa4-42ac-a2e7-c8cf3dc925d4","High throughput data interfacing: for real-time medical imaging applications","FLOROS, Theofanis (TU Delft Electrical Engineering, Mathematics and Computer Science)","Al-Ars, Z. (mentor); de Jong, Rob (graduation committee); Remis, R.F. (graduation committee); Delft University of Technology (degree granting institution)","2021","Current high-end medical X-ray intervention devices provide a tremendous amount of high-definition images per second. Combined with the additional inputs from the numerous auxiliary devices, processing and compositing the data in real-time quickly becomes an arduous engineering challenge. Furthermore, the critical nature of this application domain allows no room for error, whereas the process has to be simultaneously flexible enough to permit the unhindered work of the corresponding medical professional. Such medical imaging applications presently rely on complete hardware implementations of their processing pipelines and compositor engines, as opposed to earlier adopted paradigms of hardware-accelerated solutions. Said engines are usually realised in FPGA platforms due to their massively parallel computational capabilities and exceptional connectivity. However, given the vast amount of input streams arriving at the compositor's pipeline, switching and routing to available processing resources has remained a persistent issue. Present commercial solutions prove to be either too costly, too slow or too inflexible for developers to consider. On the other hand, academic literature centred around the subject is severely lacking. This thesis proposes a unique hardware architecture solution to mitigate the aforementioned problem. The proposed architecture, developed in collaboration with Philips Healthcare and TU Delft, exhibits an average end-to-end latency of 100 ns and a throughput of 7.2 Gb/s. Additionally, these results were realised under marginal resource utilisation, proving that such a switch can fit in the FPGA device and, subsequently, be developed as an integrated part of the compositor engine. Finally, the limited amount of reserved memory resources allowed for near-linear scalability of the proposed design should an increased amount of I/O devices be added; as well as dynamic portability should migration to smaller devices be a concern.","Image composition; FPGA acceleration; High-throughput interface; Low-latency switch","en","master thesis","","","","","","","","2022-02-11","","","","Electrical Engineering | Embedded Systems","FitOptiVis",""
"uuid:ef279f99-6af3-46df-ab17-59477bc80dc9","http://resolver.tudelft.nl/uuid:ef279f99-6af3-46df-ab17-59477bc80dc9","Evaluation of global glacio-hydrological model coupling for runoff prediction: PCR-GLOBWB 2 and GloGEM","Wiersma, Pau (TU Delft Civil Engineering and Geosciences)","Hrachowitz, M. (mentor); Hut, R.W. (graduation committee); Aerts, J.P.M. (graduation committee); Zekollari, H. (graduation committee); Delft University of Technology (degree granting institution)","2021","Global hydrological models (GHMs) have become an increasingly valuable tool in a range of global impact studies related to water resources. However, glacier parameterization is often overly simplistic or non-existent in GHMs. The representation of glacier dynamics and evolution, including related products such as glacier runoff, can be improved by relying on dedicated global glacier models (GGMs). In this study we test the hypothesis that coupling a GGM to a GHM can lead to increased GHM predictive skills and decreased GHM uncertainty through better glacier parameterization. To this end, the GGM GloGEM is coupled with the GHM PCR-GLOBWB 2 within the eWaterCycle II framework. For the years 2001-2012, the coupled model is evaluated against the uncoupled benchmark in 25 large (&gt;50.000 km2) glacierized basins. Across all basins, the coupled model produces higher runoff throughout the melt season. In July and August, it ranges between 100.07% and 352% of the mean monthly benchmark runoff in lowly and highly glaciated basins respectively. The difference can primarily be explained by the inability of PCR-GLOBWB 2 to simulate snow redistribution and glacier retreat, causing an underestimation of glacier runoff. The coupled model better reproduces basin runoff observations primarily in highly glaciated basins, i.e. where the coupling has the most impact. This study underlines the importance of glacier representation in GHMs and demonstrates the potential of coupling a GHM with a GGM for better glacier representation and runoff predictions in glaciated basins.","Global Hydrological Model; Global Glacier Model; eWaterCycle II; Snow towers; Glacier runoff; Evaluation","en","master thesis","","","","","","","","","","","","Civil Engineering | Environmental Engineering","",""
"uuid:bf74862f-5b7f-460f-8d09-712d32d29c91","http://resolver.tudelft.nl/uuid:bf74862f-5b7f-460f-8d09-712d32d29c91","On the primitive equations and the hydrostatic Stokes operator in L¬≤","Muguruza Lasa, Garazi (TU Delft Electrical Engineering, Mathematics and Computer Science)","Veraar, M.C. (mentor); Sauer, J. (graduation committee); Schuttelaars, H.M. (graduation committee); Delft University of Technology (degree granting institution)","2021","In 2016 Hieber and Kashiwabara showed that the three dimensional primitive equations admit a unique, global, strong solution for all initial data in a closed subspace of the Bessel space $H^{2/p,p}(\Omega)$ provided $p\geq6/5$, being this the first result in the general $L^p$-setting. Their approach consisted in studying the properties of the hydrostatic Stokes operator $A_p$ defined on the solenoidal subspace $L^p_{\overline{\sigma}}(\Omega)$ of $L^p(\Omega)$. In 2017 Giga et. al. further proved that the hydrostatic Stokes operator $A_p$ admits a bounded $H^\infty$-calculus, obtaining maximal $L^q-L^p$ regularity estimates for the linearized primitive equations in a much simpler way. In this work we will study Giga et. al.'s and Hieber and Kashiwabara‚Äôs works particularized for the $L^2$-case as well as all the necessary literature to replicate the proofs. The goal of the thesis is to present an extended version of Giga et. al.‚Äôs proof to make it more accessible. Although the $L^p$-case is not studied for lack of time, we differentiate between the Sobolev-Slobodeckij, Bessel potential and Besov spaces to accentuate how we could extend the proofs to the $L^p$-setting.","hydrostatic stokes operator; h infinity calculus; primitive equations","en","master thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:346f2743-121c-419f-afa2-96c8745d1003","http://resolver.tudelft.nl/uuid:346f2743-121c-419f-afa2-96c8745d1003","Teleoperated online Learning from Demonstration in a partly unknown environment: using a semi-autonomous care robot","Meccanici, Floris (TU Delft Mechanical, Maritime and Materials Engineering)","Peternel, L. (mentor); Abbink, D.A. (mentor); Karageorgos, Dimitris (mentor); Heemskerk, Cock J.M. (mentor); Ferranti, L. (graduation committee); Delft University of Technology (degree granting institution)","2021","The general approach to generate collision free motion in a constraint environment is to use path planners, which demand a known environment and potentially fail otherwise. Learning from Demonstration (LfD) can be used instead to teach the robot unknown parts of the environment, such as a goal deviation or an unforeseen obstacle. The general approach is to train a model offline and expect it to perform well afterwards. Problems arise however when the model is trained insufficiently or unknown variations have occurred in the environment, which demand for refinement of the model. In online learning the operator is allowed to refine a predicted trajectory during execution time, where the state-of-the-art methods focus on kinaesthetic teaching. The contribution of this research is the development of a teleoperated online learningmmethod, where the operator can make refinements by moving a haptic stylus (Phantom Omni) in the desired direction. By doing this, a force is felt proportional to the magnitude of refinement. After creating such a refined trajectory, it is used to update a condition dependent probabilistic trajectory model. The proof of concept was shown on a 2D example and on a simulated robot that shows that we can adapt an initial model when unknown variations occur and that the method is able to deal with different object positions and initial end effector poses. To show if other people can use the method, a human factors experiment is performed, comparing the developed method against three other methods on how much time it takes to successfully adapt a model (refinement time) and on the perceived workload. Two different parameters are varied, which are the teaching device (stylus or keyboard) and the learning mechanism (online or offline). The expectation was that both online with stylus has the lowest refinement time and workload, but the results show that only online has a significant improvement over offline methods (p = 7.94 √ó 10^‚àí12 and p = 0.000512 respectively). This is explained by the fact that only small corrections have to be made and in a maximum of three degrees of freedom (DoFs). No significant difference was found between keyboard and stylus (p = 0.755 and p = 0.302 respectively). An explanation for this is that this is task, person and implementation dependent. The recommendations are to evaluate the proof of concept on the real robot and to extend the method with orientation refinement, such that more complex tasks can also be dealtwith. We hypothesize that with these tasks the combination of online with stylus does perform the best.","Learning from Demonstration; Online Learning; Human-Robot Interaction; Unknown Environment","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Biomechanical Design - BioRobotics","",""
"uuid:277983c0-1cfe-4f85-8114-a6566c013751","http://resolver.tudelft.nl/uuid:277983c0-1cfe-4f85-8114-a6566c013751","An Agent-Based Safety Analysis of the Third Party Risk of UAS operations in the urban environment","Zwanenburg, Bastiaan (TU Delft Aerospace Engineering)","Sharpanskykh, Alexei (mentor); Delft University of Technology (degree granting institution)","2021","There are many diverse concepts for autonomous drone operations. One of these concepts is the delivery of packages in urban areas. Transportation companies are already testing vehicles capable of performing such operations, and many studies indicate that this concept is both technically feasible and financially attractive. However, how much risk do civilians living in cities (also called third-party-risk, or TPR) face following these drone operations? Moreover, what measures can be employed to mitigate this risk? Regulators demand answers to these questions before allowing autonomous Unmanned Aircraft Systems (UAS) operations to take off. Recent research has focused on developing methods of calculating the TPR, or on creating models that accurately resemble drone operations in urban cities. The model proposed in this work bridges the gap between these categories using an agent-based safety risk analysis. In this analysis, we study the TPR of UAS package delivery operations in Delft, New York and Paris. This model leads to two main contributions. The first considers observations regarding the influence of the environment on the TPR. In particular, our model suggests that if the low-risk areas are clustered in a city, this leads to higher TPR. The second contribution is derived from the interaction of the risk computation with our model of the environment. Global- and local sensitivity analyses led to a few interesting observations. For example, our model suggests that it is more important to understand the vehicle's failure rate in the cruise-phase, than in the takeoff- and landing-phase. It is also suggested that it is more important to understand how buildings protect people from impact than to understand the effects of an impact directly on a human. Another finding is that modelling the impact speed with the terminal speed, as is common in literature, leads to a TPR that is 15% - 26% higher than when the impact speed is modelled based on the drone's dynamics.","","en","master thesis","","","","","","","","2023-02-02","","","","Aerospace Engineering","",""
"uuid:16b7990c-2648-4eef-855c-877a74117bb0","http://resolver.tudelft.nl/uuid:16b7990c-2648-4eef-855c-877a74117bb0","Characterization of reactive oxygen species responsive copolymeric micelles for drug delivery purposes","Bouwmans, Pepijn (TU Delft Applied Sciences)","Denkova, A.G. (mentor); Eelkema, R. (mentor); Djanashvili, K. (graduation committee); Delft University of Technology (degree granting institution)","2021","Treatment of cancer requires local medication at the tumor site to prevent side-effects of chemotherapy. Nanocarriers, such as micelles, can be used to transport drugs to the tumor site and limit side effects of cancer treatment. Micelles are easy to produce, have a high solubilization potential for hydrophobic drugs and therefore can have high loading capacity. Due to the increase in cell division and higher activity of cancer cells, elevated levels of reactive oxygen species (ROS) are often present at the tumor site. ROS have a highly oxidizing agent property by damaging DNA of cancer cells, it can be used to treat tumors. Beside ROS formation of the metabolic cycle, ROS can also be produced by ionizing radiation. With radiolysis of water, caused by radiation, the ROS concentrations at tumor sites can be increased. This research aimed to prepare micelles made from a block copolymer, that are sensitive to ROS and that are sensitive to ROS formed by radiolysis of water with gamma radiation for drug release purposes. 4-(methylthio)phenyl acrylate (MTPA) groups present in the block copolymer (PDMA-MTPA), are sensitive for oxidation reactions which will lead to decomposition of the polymer, and thus of the micelles. During this research, micelles with a hydrodynamic diameter between 30 and 50 nm were exposed to H2O2 levels between 2 wt% (0.6 M) and 0.007 wt% (2 mM) and a change in hydrodynamic diameter and light intensity scattering was observed, meaning that micelles decompose with elevated concentrations of H2O2. In addition, an increase in hydrodynamic diameter was observed for micelles exposed to a dose between 67 and 500 Gray by irradiating with gamma rays of 1.25 MeV originating from a 60Co source, indicating that micelles cluster after sufficient dose of gamma radiation. These characteristics can be useful for making PDMA-MTPA micelles, a suitable candidate for drug delivery applications.","Copolymeric Micelles; Oxygen Species; Drug delivery","en","master thesis","","","","","","","","","","","","Chemical Engineering","",""
"uuid:25d39913-4bed-4361-9813-f521a57a5f6d","http://resolver.tudelft.nl/uuid:25d39913-4bed-4361-9813-f521a57a5f6d","Developing the e-Kick for Swapfiets","Koudijs, Sjoerd (TU Delft Industrial Design Engineering)","Oberdorf, J.E. (mentor); Kroon, C.P.J.M. (mentor); Delft University of Technology (degree granting institution)","2021","The design of Swapfiets‚Äô first electric kick-scooter, the e-Kick 1.0, is not specified on the Swapfiets user and Swapfiets operations. Therefore the new e-Kick model needs to to comply with the lifestyle of the end user and improve his daily routines. For the Swapfiets mechanics the solidity and repairability is an important objective. The kick-scooter manufacturer must be able to make it, delivering high quality products. Looking at the timeframe of the project, the aim for the launch of the new e-Kick design is around Q1 2022. The target user lives in a big city using the e-Kick in combination with other transportation. He wants the e-Kick to be safe, carryable and reliable. For the mechanic multiple bad quality parts need upgrading and the steering console is repair unfriendly. Next to that, the waterproofing of the e-Kick is not according to standards. This thesis contains the new e-Kick 2.0 design ready to be ordered at the manufacturer. Next to that, the e-Kick 3.0 is shown which is the next generation e-Kick design with future possibilities for Swapfiets operations.","Swapfiets; Kickscooter design; Product development; electric scooter","en","master thesis","","","","","","","","","","","","","",""
"uuid:c4a106a0-e35e-4b29-843f-cc3e0bba1472","http://resolver.tudelft.nl/uuid:c4a106a0-e35e-4b29-843f-cc3e0bba1472","An IMU tracking algorithm for 3D motion reconstruction using OpenSim dynamical models: Implementation on a robot manipulator","de Kanter, Daan (TU Delft Mechanical, Maritime and Materials Engineering)","Kok, M. (mentor); Seth, A. (mentor); Peternel, L. (graduation committee); Veeger, H.E.J. (graduation committee); Delft University of Technology (degree granting institution)","2021","Inertial Measurement Unit (IMU)-based motion capture has gained interest over the years due to its potential to measure human movement in the clinic and on the sports field at low cost. Still, IMU-based motion reconstruction remains a challenging task as these IMU measurements are corrupted by noise and bias. There have been many filtering and sensor fusion algorithms developed to address this problem, but limited attention has been paid to including the system dynamics of the subject to estimate kinematics and kinetics from multiple IMUs. I propose a novel motion reconstruction algorithm for capturing 3D motions in a markerless and unconstrained environment using gyroscope and accelerometer measurements. The algorithm is based upon an Iterated Extended Kalman Filter for state estimation and the 3D dynamical model of the subject created in OpenSim (IEKF-OS). The IEKF-OS algorithm consists of two stages. The first stage incorporates the dynamics of the subject to predict the motion. The second stage tracks measurements from multiple IMUs to improve model estimates of joint angles and speeds. The goal of this thesis is threefold. Firstly, the IEKF-OS is derived and verified using simulations performed on a six-link robot manipulator including sensor placement errors. Secondly, experiments are performed to validate the algorithm‚Äôs estimations against the robot‚Äôs ground truth joint encoder values. Thirdly, the algorithm is compared against an inverse kinematics method to track IMU estimated orientations (OpenSense) provided by OpenSim. The IEKF-OS algorithm showed lower motion tracking errors compared to OpenSense for various motions performed by the robot manipulator. The joint angle estimations as computed by both methods are compared against the gold-standard ground truth robot encoder values. OpenSense joint angle values were in the range of 0.6-6.4 [deg] RMSE, whereas the IEKF-OS algorithm estimated joint angles and speeds in the range of 0.4-2.8 [deg] and 0.3-2 [deg/s] RMSE, respectively. These results highlight accurate 3D motion reconstruction on a six-link robot manipulator. Contrary to OpenSense, the IEKF-OS is able to accurately reconstruct motions regardless of magnetic disturbances because it does not rely on magnetometer data.","IMU Sensor Fusion; Biomechanical Model; OpenSim; 3D Motion Reconstruction; Kalman Filtering; State Estimation","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:3bd817ad-792d-4279-8c8a-5b571466eada","http://resolver.tudelft.nl/uuid:3bd817ad-792d-4279-8c8a-5b571466eada","A New Dispersion Model to Control the Emission Levels in the Vicinity of Freeways","Damoiseaux, Michiel (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Delft Center for Systems and Control)","De Schutter, B.H.K. (mentor); Delft University of Technology (degree granting institution)","2021","One of the main sources of greenhouse gasses is the vast and still expanding road transport sector. The number of vehicles utilizing freeways increases every day, with more and more traffic jams as a result. Lately, the development of smart traffic management systems seems to be a way out and these systems are used extensively. In this thesis, smart traffic management systems are used to control a freeway network in order to achieve an optimal flow, as well as a minimal amount of emitted gasses, and to protect target areas in the vicinity of freeways from dispersed gasses. Smart traffic management systems use control measures such as ramp metering and variable speed limits. To control these measures in an optimal way, model predictive control is found to be a suitable control method. In order to simulate the behavior of freeway traffic and traffic emissions, a model predictive control scheme uses traffic models. The METANET traffic flow model and the VT-macro traffic emission model are suitable models for control purposes in traffic networks, and therefore, these are used in this work. In order to predict the amount of pollutant gasses distributed in the area downwind of the freeway, a third model has to be used. Multiple authors have proposed so-called dispersion models, but none is yet suitable for on-line control of freeway networks. This is due to high computational costs, the inapplicability in constantly changing traffic networks, or deviating purposes of models. This work proposes a new dispersion model that is able to model the distribution of pollutant gasses in the vicinity of a freeway and which is applicable in real-time traffic control. The proposed model, the line source Gaussian puff model, is an extension of the existing Gaussian puff model. The Gaussian puff model is suitable for the modelling of point sources such as industrial stacks. In this work, the Gaussian puff model is modified to make it suitable for the dispersion modelling of freeway sections. This is done by implementing line sources instead of point sources. The proposed model has a small normalized error such as the validation data set generated by a CFD model, implying a good performance. Compared to alternative models used in freeway traffic control, the new model has a smaller error. The LSGP model is used in a case study to get an understanding of what level of pollutant gasses can be averted to disperse to target areas. In this case study, an MPC scheme is used to control a freeway. The aim is to find an optimal situation where the flow of the freeway is optimal, the total amount of emitted gasses is minimal, and the concentration level in the target area is reduced. The results show that the new model is able to minimize the amount of pollutant gasses nearby a freeway with a low computational complexity in a model predictive control scheme.","Dispersion; Traffic control; Freeway Traffic Control; model predictive control","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:8e0e459e-da61-4632-95ff-e0ba02c0c30c","http://resolver.tudelft.nl/uuid:8e0e459e-da61-4632-95ff-e0ba02c0c30c","Major incident detection","Kolenbrander, Thomas (TU Delft Electrical Engineering, Mathematics and Computer Science)","Proksch, S. (mentor); van Deursen, A. (graduation committee); Tax, D.M.J. (graduation committee); Delft University of Technology (degree granting institution)","2021","Incident management is one of the top priorities for IT companies. Within incident management the so-called major incidents, incidents with a severe impact on the company, require emergency actions to reduce this impact. An earlier detection of these major incidents will lead to a faster resolution time and this can be achieved by using software analytics methods. These methods have been used on incident management before which faces challenges with data quality and imbalance. However, software analytics have not been applied to major incidents in particular, which is what this thesis aims to do. To gain more insight into the possibilities and challenges of automated major incident detection, a case study at ING (a large global bank) was performed. For this case study a machine learning system has been created and assessed by eight<br/>experts through interviews. Following from these interviews, three novel challenges were identified. The first challenge is that the impact should be measured to make a more accurate prediction. The second challenge is combining multiple information sources and the third challenge is the explainability of the decision. Furthermore, two solutions to existing challenges were investigated during the creation of the machine learning system. The first being the suitability of different machine learning models for incident data, as no direct comparison is available in literature. It is shown that Logistic Regression is best suited for this use case while the Support Vector Machine and Neural Network also perform well on incident data. Finally, some findings on the<br/>pre-processing of the incident data are reported. It is shown that assumptions in literature about automatically generated incident data being easier to use, can not always be made and that imbalanced data still remains an unsolved problem as sampling is not suited. The main contribution of this thesis are the insights and challenges in the unexplored topic of major incident detection and general recommendations for handling incident data.","incident management; software analytics; machine learning; major incidents; it service management","en","master thesis","","","","","","","","2021-04-01","","","","Computer Science","",""
"uuid:a86053c4-3b35-4f92-a0ee-54f690a53f1d","http://resolver.tudelft.nl/uuid:a86053c4-3b35-4f92-a0ee-54f690a53f1d","Assessment of the usability of OpenGeoSys tools for Aquifer Thermal Energy Storage (ATES) simulations","Liu, Haoyue (TU Delft Civil Engineering and Geosciences)","Bakker, M. (graduation committee); Bloemendal, J.M. (mentor); Voskov, D.V. (graduation committee); Delft University of Technology (degree granting institution)","2021","Aquifer thermal energy storage (ATES) is an energy efficient technology to temporarily store groundwater of different temperatures in an aquifer. The basic idea behind ATES is to store thermal energy in warm and cold wells so that the energy can be used for heating and cooling of buildings in the next season. Design and planning of ATES systems requires numerical simulation tools such as SEA- WAT, COMSOL, and FEFLOW. COMSOL and FEFLOW are expensive commercial products. SEAWAT is a free computer program based on MODFLOW and MT3DMS. The flow field is modelled with the finite difference method while there are several methods to simulate the heat transport including the finite difference (FD) method and the total variation diminishing (TVD) method. OpenGeoSys (OGS) is an open-source alternative based on the finite element method which is able to simulate groundwater flow and heat transport processes and can potentially be used for design and planning of ATES systems. There are very few applications of OGS to simulate ATES systems. The main goal of this research is to assess the usability of OpenGeoSys in the simulation of ATES sys- tems. The numerical solutions of OGS and SEAWAT (both the TVD scheme and FD scheme) are compared to the analytical solutions for a single well that injects water with a constant flow rate of water and constant temperature. For a doublet with a cold well and a warm well, the OGS solution is compared to the SEAWAT solution for both a sin- gle cycle system and a multiple cycles system with constant flow rates and temperatures. Finally, a field case of a doublet with varying flow rates and injection temperatures is studied to compare the performance of OGS to SEAWAT. The main findings of this study are as follows. Both OGS and SEAWAT can reproduce the heat transport process of the analytical solutions for a single well injecting warm or cold water. There are some deviations between the temperature distributions computed by the numerical models and the analytical solutions which are primarily caused by nu- merical dispersion. The TVD scheme results in the smallest numerical dispersion while OGS shows slightly more numerical dispersion when applying the same number of cell- s/nodes. Numerical dispersion can be reduced by application of finer spatial resolution for the SEAWAT since the time step is adjusted automatically. For OGS, the time step must be reduced manually when the grid is refined. Both OGS and SEAWAT show energy balance errors smaller than 1%. Numerical dis- persion has an effect similar to physical dispersion so that the thermal radius increases when the numerical dispersion is larger. The interaction between the warm well and cold well of a doublet increases when the thermal radius increases, which may result in an increase of the energy balance error. According to the analytical solution for the model where the heat transport between the aquifer and aquitards is included, OGS shows the smallest overestimation of thermal energy that remains in the aquifer part compared to the two solution schemes of SEA- WAT. The vertical temperature distribution in aquitards simulated with OGS is closer to that of the analytical solution compared to SEAWAT. Both numerical dispersion and the overestimation of thermal energy in the aquifer have an influence on thermal recovery efficiency of an ATES system. Larger numerical dis- persion indicates a longer heat transport distance, resulting in more time needed for thermal energy to transport back to the wells during the extraction period. Similarly, the overestimation of the thermal energy in the aquifer provides more thermal energy dur- ing the extraction period. There are some overshoots/undershoots when simulating an ATES system with varying flow rates and injection temperatures by the TVD scheme. This can be eliminated by refining the spatial resolution. It is more complicated to simulate an ATES system with OGS than SEAWAT. The com- putational time is much longer for OGS compared with SEAWAT by a factor of around 10 for the same number of cells/nodes. Despite these drawbacks, OGS is suitable for the simulation of ATES systems as the simulated temperature distribution in both the aquifer and aquitards compares well to the analytical solution, and there are no prob- lems of overshoots/undershoots in the simulation of varying flow rates and injection temperatures.","OpenGeoSys; SEAWAT; ATES systems","en","master thesis","","","","","","","","","","","","","",""
"uuid:570bae7d-cb67-465a-a31f-26e14f21316c","http://resolver.tudelft.nl/uuid:570bae7d-cb67-465a-a31f-26e14f21316c","Fighting Child Sexual Abuse Material better together: A stakeholder central review of the government policies","Rutten, Marie Sam (TU Delft Technology, Policy and Management)","van Eeten, M.J.G. (mentor); van Wegberg, R.S. (mentor); Fiebig, T. (graduation committee); Lone, Q.B. (graduation committee); Delft University of Technology (degree granting institution)","2021","This study aims to make recommendations about how the Internet can be more thoroughly cleaned of Child Sexual Abuse Material (CSAM), focusing on the Dutch government policies. In the past years, several organizations, including the European Commission, called out the Netherlands for the role Dutch companies have in the hosting of CSAM. According to INHOPE, the CSAM hotline umbrella organization, the Netherlands is responsible for 20\% of the hosted CSAM worldwide and 79\% within the EU. For this study, a mixed-methods approach is chosen. A mixed-methods approach combines a qualitative and a quantitative method. The qualitative analysis is used to reveal relevant stakeholders, their positions, how they participate in the policymaking process, how they evaluate the government policies, and what they believe are the most significant improvements to the system. The quantitative results map information flows and processing times of the Dutch CSAM NTD mechanism. Combining the qualitative and quantitative research has revealed several pitfalls. Firstly, much CSAM remains unfound. Secondly, hotlines have a very important but also insecure position in the government policies. Further, are direct incentives for the sector more than moral duty are missing and the organizational degree of the sector is low. Also, the set norms and policies of the government and self-regulation are not accounting for the high diversity of the sector. There is a lack of financial resources. Finally, several stakeholders question the adequacy of law enforcement in regard to CSAM. Consequently, recommendations in three areas are made: (1) expanding and strengthen the current policies, (2) enhancing the collaboration between the stakeholders and their own position and (3) introducing new policy initiatives.","Notice-and-takedown; Child Sexual Abuse Material (CSAM); Regulation; Participation; Stakeholder perspective; Rounds model","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:a791a7d4-6c76-4886-86a9-aee22356e733","http://resolver.tudelft.nl/uuid:a791a7d4-6c76-4886-86a9-aee22356e733","Optimizing smart waste collection through container selection","van Zeijl, Jelmer (TU Delft Mechanical, Maritime and Materials Engineering)","Atasoy, B. (mentor); Brandt, Jelmer (graduation committee); Delft University of Technology (degree granting institution)","2021","A significant growth of the world‚Äôs population together with fast growing urbanization is causing challenges for cities in the future. One of these challenges is how to deal with waste production and therefore the waste collection in such areas. Smart waste collection is a promising solution since it optimizes an already excising infra structure including vehicles and since the collection and transportation of the produced waste accounts for roughly 70% of the waste management costs. Smart waste collection is a routing problem and can be categorized both as a vehicle routing problem (VRP) or as an inventory routing problem (IRP) depending on which container selection method is used. Smart waste collection uses sensors to measure and communicate the fill levels of the waste containers. This data can be used to optimize the process of waste collection and optimize the chosen KPIs. When all fill levels are known, routes can be optimized and containers can be collected at exactly the right time. This article will use real data obtained from the containers collected by OMRIN with the help of AMCS and their software. Container selection methods can be categorized as threshold based, attractiveness based or must-go may-go based. Containers can be selected for collection, roughly based on three methods. The interesting thing is that these three methods have not yet been compared to each other. Therefore the main goal of this research is to compare the three aforementioned methods based on real data and investigate certain tuning parameters to optimize each model based on the chosen KPIs. The models are first individually optimized by changing their tuning parameters and keeping the overflow in an acceptable range of the baseline, calculated based on real data. Overall a strong negative correlation is found between the total traveled time and the amount of overflows. Furthermore a warm-up period of three days is used, meaning the first three days of a test instance will be removed in order to capture only the steady state of the models. The individual optimization shows the best solutions for a 1% threshold buffer for the threshold model, a three-day horizon with 110% upper limit for the attractiveness model and a three-day horizon with an threshold buffer of 7% and a 110% upper limit for the must-go may-go model. When compared the attractiveness model shows to have the smallest total travel time. However, its computational time exceeds the actual total travel time. The must-go may-go model shows a slightly higher total travel time, but has a significant lower computational time. Therefore making it more suitable for real world application. This research as well shows that the two-day horizon instances of both the attractiveness model and the must-go may-go model barely improve the solution of the one-day horizon. Finally a true forecasting model was used to see what potential lies with designing a detailed forecasting model, which shows to be in the same order of improvement as was obtained by tuning parameters of each model.","Smart waste collection","en","master thesis","","","","","","","","","","","","Marine Technology | Transport Engineering and Logistics","",""
"uuid:5fb2abb8-941e-4df0-9222-52b79fbd2706","http://resolver.tudelft.nl/uuid:5fb2abb8-941e-4df0-9222-52b79fbd2706","Wind optimised trajectory generator for automated wind turbine inspector drones","Gooijaers, Leo (TU Delft Aerospace Engineering)","de Visser, C.C. (mentor); Delft University of Technology (degree granting institution)","2021","To be able to increase the safety and efficiency of automated wind turbine inspection a robust solution is needed that takes into account wind during trajectory planning. This paper presents such a solution in the form of an algorithm, which uses Dijkstra‚Äôs algorithm as a basis for optimisation. To allow for online replanning the horizontal and vertical trajectory planning are separated, creating a computationally cheap problem. The solution is based on<br/>an in advance known static environment, hence no time and resources are spend before the inspection. Three experiments show that the presented algorithm is safe and is able to take into account wind during emergency procedures. In addition it is shown that it is able to safely replan when the wind changes during an emergency. These results show that the proposed algorithm can serve as a viable basis for a safe and efficient solution for automated wind turbine<br/>inspection.","Trajectory generation; Wind turbine; inspection; dijkstra","en","master thesis","","","","","","","","2023-02-17","","","","Aerospace Engineering","",""
"uuid:3eb89f98-72a6-4334-9bcb-e382ea9bcf84","http://resolver.tudelft.nl/uuid:3eb89f98-72a6-4334-9bcb-e382ea9bcf84","MRI-Ready Actuation System for a Self-Propelling Needle: A Design and Experimental Approach","Bloemberg, Jette (TU Delft Mechanical, Maritime and Materials Engineering)","Trauzettel, F. (mentor); Dodou, D. (mentor); Breedveld, P. (mentor); Jovanova, J. (graduation committee); Langelaar, M. (graduation committee); Delft University of Technology (degree granting institution)","2021","Standard treatment methods for prostate cancer often result in side-effects because of damage to the surrounding tissue. Magnetic resonance imaging (MRI) guided focal laser ablation to treat prostate cancer reduces the risk of adverse effects by preserving noncancerous tissue. Prostate cancer diagnosis and focal laser ablation treatment both require the insertion of a needle for biopsy and optical fibre positioning. The insertion of needles in soft tissues causes tissue motion and deformation, resulting in tissue damage. In this study, we propose an MRI-ready actuation system for a needle that can be inserted into tissue with a zero external push force and without buckling. The zero external push force is achieved by moving parallel needle segments in a reciprocating manner. The actuation unit‚Äôs design inspired by the click-pen mechanism actuates the reciprocating motion of six parallel needle segments by solely a discrete manual translating actuation as its input. A prototype, called the Ovipositor MRI-Needle, was built using 3D printed parts and six 0.25-mm diameter Nitinol rods. Experimental validation of the Ovipositor MRI-Needle in ex vivo human prostate tissue inside a preclinical MRI scanner showed that the needle could advance in three out of five measurements through the tissue. The Ovipositor MRI-Needle is a step forward in the direction of developing a self-propelling needle for MRI-guided transperineal laser ablation to treat prostate cancer.","Medical needle; magnetic resonance imaging; additive manufacturing; manual actuator; biologically inspired design","en","master thesis","","","","","","","","2023-03-01","","","","Mechanical Engineering | BioMechanical Design","",""
"uuid:ced9a5ad-fc3e-4e91-a2a2-1aa0d69af270","http://resolver.tudelft.nl/uuid:ced9a5ad-fc3e-4e91-a2a2-1aa0d69af270","Modelling shoreline evolution in the vicinity of shore normal structures: Implementation and validation of ShorelineS model using the case study of Constanta, Romania","Overgaauw, Tim (TU Delft Civil Engineering and Geosciences)","de Schipper, M.A. (mentor); Luijendijk, A.P. (graduation committee); Storms, J.E.A. (graduation committee); Huisman, B.J.A. (graduation committee); Brandenburg, Peter (graduation committee); Elghandour, Ahmed (graduation committee); Delft University of Technology (degree granting institution)","2021","While waves are propagating towards the shore and are interrupted by an obstacle like a groyne, they will turn around the tip into the sheltered region of the groyne. This sheltered region is called the shadow zone and contains a reduced wave climate. The turning of the waves is based on the lateral transfer of wave energy along the wave crest, caused by a gradient in wave height. This process is called diffraction. Breaking wave heights and angles inside the shadow zone will be influenced significantly because of wave diffraction. Since variations in breaking wave height and/or angle are responsible for gradients in the alongshore sediment transport, should the process of wave diffraction be taken into account while simulating the shoreline evolution in the vicinity of a groyne. Different methods were found to incorporate the effects of wave diffraction inside the coastline model ShorelineS.<br/><br/>The improved model performance of ShorelineS regarding a real-world case study is addressed by using the shoreline of Constanta, Romania. The consequence of incorporating wave diffraction effects onto the shoreline evolution of Constanta is demonstrated in detail. The accretion close to the Southern groyne and erosion near the Northern groyne is visible in the numerical result of the improved model. Therefore, matching the observed anti-clockwise rotation of the coastal cell. Without accounting for diffraction effects, this matching result was not achievable. The transition zone width is found to be an important factor in determining the coastline shape affected by diffraction. After calibration of this parameter, the numerical result demonstrated to be in almost perfect agreement with the observed coastline shape. The root mean square error and bias reduced with factors of 5.5 and 5 compared to the numerical result excluding diffraction effects. <br","Diffraction; ShorelineS; Coastline evolution; Groyne field","en","master thesis","","","","","","","","","","","","Civil Engineering | Hydraulic Engineering | Coastal Engineering","",""
"uuid:30897d96-871e-43e1-aa7d-5dd3d09d6d5f","http://resolver.tudelft.nl/uuid:30897d96-871e-43e1-aa7d-5dd3d09d6d5f","The effect of porosity gradients on compressive strength of hydroxyapatite scaffolds","van Heijningen, Irene (TU Delft Mechanical, Maritime and Materials Engineering)","Dankelman, J. (graduation committee); Jelinek, Filip (mentor); Delft University of Technology (degree granting institution)","2021","Nowadays, the main treatment for children with bone cancer is limb salvage. To prevent this, a new design for an expandable endoprosthesis for the knee has been developed. This proposal contained a bioresorbable ceramic component, made out of hydroxyapatite (HA), with a porosity gradient which will be subjected to a compressive load. In order the prevent mechanical failure of the prosthesis, the compressive strength of the ceramic component must be investigated. Therefore, the influence of a porosity gradient on the compressive strength compared to a homogeneous porosity is researched in this study. Six different designs, one containing a porosity gradient (ranging from 23% to 30% to 37%) and five containing a homogeneous porosity (18% ,23%, 30%, 37%, 50%) were manufactured and tested on their ultimate compressive load (UCL) and first maximum compressive load (FCL). The UCL seemed to decrease with an increasing porosity and the FCL was around 400 N for every configuration. Heterogenous scaffolds seemed to have a lower UCL compared to homogeneous scaffolds containing a porosity equal the heterogenous lowest porosity. However, this heterogeneous UCL seemed to be higher than the UCL of a scaffold with a porosity equal to the average and highest porosity present in the layered configuration. Significant differences were only found between the UCLs for the 18% and 37% porosity configuration. Not all scaffolds showed the required UCL for the current application. However, HA is still a promising material, although the manufacturing of the scaffolds and other production techniques should be investigated further to obtain the desired UCL and FCL","","en","master thesis","","","","","","","","2026-02-16","","","","","",""
"uuid:2b88a1ff-a14d-4c94-b5b9-48376aa5b911","http://resolver.tudelft.nl/uuid:2b88a1ff-a14d-4c94-b5b9-48376aa5b911","Enhancing reliability of dikes: An approach for assessing benefits of pore pressure monitoring and pressure relief wells in spatially variable soils","Bruins Slot, Hilco (TU Delft Civil Engineering and Geosciences)","Klerk, W.J. (mentor); Aguilar Lopez, J.P. (mentor); Jonkman, S.N. (mentor); Bogaard, T.A. (mentor); Steenbergen-Kajabov√°, Jana (mentor); Delft University of Technology (degree granting institution)","2021","The Netherlands is a country prone to flooding. Recent assessments led to the insight that protection levels of many flood defences should be increased. Integrating reinforcement measures is a difficult task as many dikes are situated in densely populated areas. Conventional reinforcement measures include berm construction or the implementation of sheet pile walls. The first can become very expensive in case houses are situated close to a dike, the latter is rather expensive and irreversibly changes dike composition. Geotechnical failure modes piping and slope instability are most important failure modes for Dutch river dikes. In this thesis a case study is carried out on such a dike that is disqualified for those failure modes. The dike is situated in an urban area with limited space available for reinforcement works. It is studied whether pore pressure measurements behind the dike can be used to improve the reliability estimate for piping. Subsequently it is analyzed whether implementing pressure relief wells can be used to increase dike reliability for both considered failure modes. For the case study an advanced modelling framework was used consisting of groundwater modelling software and a random field generator. The case study was divided into two parts. The first part consisted of a dike section of 100 m based on a dike section at Wijk bij Duurstede. The second part consisted of the same dike section, only now extrapolated over a length of 2 km for which variations in soil conditions become more important. First, an analysis was conducted to define the optimal amount of pore pressure sensors behind the dike. It was found that for a dike section of 100 m a total of four sensors could be used to perform reliability updates, for a dike section of 2000 m it was found that a total of six sensors could be used. For the 100 m section piping failure probability improved from 5.21E-3 per year to 1.62E-4 per year. For the 2000 m section piping failure probability improved from 5.21E-3 per year to 1.89E-4 per year. Pressure relief well implementation behind the dike was considered as a measure to increase dike reliability for both failure modes. The system was designed based on a target reliability level for slope instability. The same modelling framework was applied. An analysis was conducted and it was shown that for the 100 m section a well spacing of 50 m would sufficiently increase dike reliability for slope instability. For the 2000 m section a well spacing of 45 m was found. For the 100 m section failure probability for slope instability increased from 8.81E-5 per year to 1.22E-6 per year, failure probability for piping increased from 1.62E-4 per year to 2.03E-7 per year. For the 2000 m section failure probability for slope instability increased from 8.81E-5 per year to 1.30E-6 per year, failure probability for piping increased from 1.89E-4 per year to 1.02E-7 per year. It was shown that for both trajectories target reliability levels for all failure modes were met. For this case study it was shown that pressure relief wells provide a good design alternative for dike reinforcement in urban areas. A life cycle cost analysis was applied and it was shown that implementation of relief wells is economically attractive compared to traditional design alternatives berms and sheet pile walls. For the first relocation of houses forms an important cost driver, for the latter initial construction cost are high. Furthermore it was shown that implementation of pore pressure monitoring prior to the design of a relief well system yields a positive value of information.","Dike reinforcement; Probabilistic design; Bayesian updating; Dike reliability; Pore pressure monitoring; Pressure relief wells; Backward erosion piping; Slope instability","en","master thesis","","","","","","","","","","","","Civil Engineering | Hydraulic Engineering","","51.972179, 5.349489"
"uuid:e3b56111-7911-4854-a759-87e5f45db118","http://resolver.tudelft.nl/uuid:e3b56111-7911-4854-a759-87e5f45db118","Monitoring the impact of droughts on vegetation in Australia using MetOp ASCAT Dynamic Vegetation Parameters","Walraven, Bas (TU Delft Civil Engineering and Geosciences)","Steele-Dunne, S.C. (mentor); Hrachowitz, M. (graduation committee); Lhermitte, S.L.M. (graduation committee); Delft University of Technology (degree granting institution)","2021","Droughts are considered to be one of the most damaging, yet least understood, natural hazards of all. Despite their prevalence, a thorough understanding of them lacks because they are such complex phenomena, and their manifestation can differ depending on the region they occur in. Monitoring hydrological variables and processes is imperative for a good understanding of how droughts develop and persist. Backscatter from ASCAT and previous scatterometers has long been used for soil moisture retrieval. The first and second order derivative, slope and curvature respectively, of the backscatter - incidence angle relation in the TU Wien Soil Moisture Retrieval algorithm are used to correct for vegetation effects. Recently, new developments to this algorithm have allowed to account for interannual variations in the slope and curvature. This has given rise to the potential of monitoring vegetation directly with slope and curvature, rather than only using it to correct for vegetation effects in soil moisture retrieval. The long data record of ASCAT and previous scatterometers combined has the potential to provide valuable information for drought monitoring. This study investigates if ASCAT could be used as a self-contained dataset in drought monitoring. The spatial variability, the seasonal cycle, and the drought response of backscatter, slope and curvature across different vegetation types in Australia is assessed. Simulated surface- and root zone soil moisture, LAI and GPP from the land surface model ISBA are used to aid in the interpretation of the ASCAT signal. The results from this study show that backscatter, slope and curvature can adequately capture vegetation dynamics in times of drought across dry semi-arid grasslands and croplands. Over these regions the soil moisture and vegetation anomalies observed with ASCAT and simulated in ISBA correspond well. Considerable information into the vegetatin dynamics can be gained from analyzing the backscatter - incidence angle relationship. Especially the ability to monitor drought in crops with a coarse spatial resolution is promising for future applications. It proved more difficult to accurately capture the propagation from a soil moisture anomaly into vegetation anomaly across forests and mixed vegetation with grasses and trees. The first reason for this is the increased attenuation of the signal by vegetation, which hampers accurate measurements of soil moisture content. The second reason is that it is more difficult to separate the soil moisture and vegetation effects due to the fact that less is known about the scattering mechanisms induced by vegetation structure and moisture distribution. Overall the results support earlier findings the slope can be used as a measure of vegetation wet biomass and confirm that curvature is also a valuable source of information that gives insight into the relative contribution from surface or volumetric scattering to total backscatter. These relations have been shown to also adequately describe vegetation dynamics in times of drought.","ASCAT; Drought monitoring; Dynamic Vegetation Parameters; Scatterometer; Vegetation water dynamics; Backscatter; Australia; Slope; Vegetation monitoring; Curvature","en","master thesis","","","","","","","","2021-08-16","","","","Water Management","",""
"uuid:b1057961-87f5-4a21-91f2-bb03a72d6742","http://resolver.tudelft.nl/uuid:b1057961-87f5-4a21-91f2-bb03a72d6742","The North Sea becoming an Energy Hub: How the deployment of renewables and integration of national grids can contribute to a cost-efficient electricity &amp; hydrogen supply in 2050","Leerling, Anne-Jo√´l (TU Delft Technology, Policy and Management)","Blok, K. (mentor); van der Meijden, M.A.M.M. (mentor); Delft University of Technology (degree granting institution); Universiteit Leiden (degree granting institution)","2021","To fight the threat of global warming, nations worldwide are currently in the transition towards a renewable-powered energy system. One of the main technologies represented in a renewable-powered energy system is wind energy. Rapid developments in the offshore wind sector caused the rise of offshore wind farms in the North Sea and more wind farms are expected for the years to come. As this renewable-powered energy system will be heavily dependent on the availability of wind and solar energy, great challenges will arise to the security of supply in the energy system. To tackle this challenge, nine countries surrounding the North Sea (called NSEC) cooperate on researching a cost-efficient energy system design which enables the large-scale deployment of wind and solar energy. One aspect that hasn‚Äôt been researched for the NSEC so far is the potential of hydrogen for this energy system. Hydrogen can play an important role in the future renewable energy system as fuel and feedstock for different sectors and as energy carrier that allows for seasonal storage. The question of what energy system design choices bring the most cost-efficiency for the NSEC, considering the hydrogen and electricity demand in 2050, will be researched. For this research, results have been based on optimizing the future energy system in the simulation modelling program Powerfys. This model optimizes power plant utilization while taking the constraints assigned to the power plants and to the energy system infrastructure into account. Powerfys operates on a rolling planning on the intra-day and the day-ahead market. The model consists of 50 nodes, divided over 9 countries and the North Sea. By simulating scenarios focused on either renewable energy capacity expansions or transmission infrastructure design, different levels of cost-efficiency are determined. These outcomes will allow to answer the research question. This research shows that a cost-efficient energy system for both electricity and hydrogen in the NSEC can exist with the current planned electricity and natural gas transmission grid for 2050, assuming a fully retrofitted natural gas grid, exclusively utilized for hydrogen transmission. What this study does show is that extensive amounts of offshore wind (285 GW) and other renewables (245 GW of onshore wind and 434 GW of PV) must be deployed, to meet the expected electricity and hydrogen demand of 2050. For offshore wind this means that not only the potential of bottom-fixed wind turbines should be accounted for, but also the potential of the novel technology of floating wind turbines must be considered. On top of that, this study shows that only 4 to 5% of all hydrogen demand must be imported from outside NSEC. Even without the imports of any hydrogen, meeting full electricity and hydrogen demand would be technically possible, but this would lead to higher energy system costs for the deployment of higher capacities of renewables and the storage for hydrogen in salt caverns. Though, the sensitivity analysis shows that hydrogen imports can increase significantly when price levels related to hydrogen (import-, electrolyser- or hydrogen storage prices) will turn out different in 2050 than currently expected. Nevertheless, this research also shows that such a significant increase in hydrogen imports will not lead to remarkable deviations in the overall energy system design or the energy system costs.","","en","master thesis","","","","","","","","2021-08-01","","","","Industrial Ecology","",""
"uuid:4d0ae29f-3534-420e-91c5-88d12574451f","http://resolver.tudelft.nl/uuid:4d0ae29f-3534-420e-91c5-88d12574451f","Towards energy efficient shipping: Using machine learning to support a ship's crew in energy efficient sailing","van der Bos, Jelle (TU Delft Mechanical, Maritime and Materials Engineering)","Geertsma, R.D. (mentor); Tiddens, Wieger (mentor); Visser, K. (graduation committee); de Koning Gans, H.J. (graduation committee); Cavalcante Siebert, L. (graduation committee); Delft University of Technology (degree granting institution)","2021","In recent years, ships are expected to improve energy efficiency and reduce carbon emissions. For naval vessels, it is important to be able to maintain their mission profile. It is therefore required to provide real-time advice to the ship‚Äôs crew on the optimal speed and propulsion mode settings that include the actual environmental conditions. This paper proposes a novel machine learning approach to establish the ship‚Äôs fuel consumption per mile for the actual environmental conditions and develop fuel consumption curves for the various propulsion configurations. The proposed approach uses a multi-layer perceptron (MLP) model to establish the ocean parameters based on the own ship data, with an accuracy of 4.150 %. Using these ocean parameters combined with the own ship data, the fuel per mile is predicted and fuel consumption curves are established using an MLP-model, with an accuracy of 1.551 %. This thesis shows that the proposed approach makes it possible to help a ship‚Äôs crew make well informed decisions to reduce their CO2 emissions in real time while still meeting their mission profile. The proposed approach is especially useful for military operators since there is no need for external data sources. Further research is identified to optimize the proposed approach using a dataset containing a higher variety and number of environmental conditions and propulsion modes to improve and validate the fuel consumption curves for the entire spectrum of speeds, environmental conditions and propulsion modes.","Machine Learning; Energy Efficiency; Ship's data; Multi-layer Perceptron","en","master thesis","","","","","","","","","","","","Marine Technology | Ship Design, Production and Operations","",""
"uuid:a651b745-b21a-4ee2-87b9-11b5a8cbe950","http://resolver.tudelft.nl/uuid:a651b745-b21a-4ee2-87b9-11b5a8cbe950","Supporting consumers to make sustainable food choices: Changing the consumption behaviour of consumers from a system perspective","van Hemert, Pascalle (TU Delft Industrial Design Engineering)","Price, R.A. (mentor); Bluemink, R.G.H. (mentor); Delft University of Technology (degree granting institution)","2021","The daily consumption of food influences the health of society and the planet. The current food consumption of an average Dutch consumer could be described as unsustainable behaviour (Muilwijk et al., 2019). Especially the intake of animal proteins should decrease and be replaced with plant proteins to realise a positive impact (Kramer &amp; Blonk, 2015). However, the consumer is not the only responsible stakeholder for this, because food processors, foodservice operators and retailers shape the market and influence consumers‚Äô dietary choices (European union, 2020). In other words, the consumption system influences the consumer. Therefore a transition of the system is required to realise sustainable food consumption. This thesis applies a system perspective to explore essential actors and identify barriers and triggers for the transition (Loorbach et al., 2017). The system is locked in the feedback loop of demand and supply and the consumer strongly influences the demand side of the system. A change in demand means a change in consumer behaviour. Behaviour is influenced by a complex interplay of factors and to change the system a bottom-up strategy is applied. This requires a context-specific case to change the consumption system (McKenzie-Mohr,2011). In conclusion, the focus of this project is to design an intervention which supports consumers to replace animal proteins with plant proteins when ordering food. The consumer journey emphasises the importance of the right choice in order to change behaviour and purchase differently. Due to unconscious routine behaviour, the consumer needs support in the decision process. Personalised triggers and simplification of the consumption process supports the desired behaviour and could lead to a new habit of consuming sustainable food (Eyal, 2014). A concept is designed to match personalised meal suggestions with consumer preferences. Additionally, actionable support is provided to ease the choice between different forms of food delivery. The goal of the concept is to offer personalised inspiration, actionable support and accessible education for the consumer and the foodservice stakeholders to realise sustainable food consumption. The concept operates according to a platform business model where multiple stakeholders are included to add value. The added value for every stakeholder is validated with several expert interviews and online consumer discussions. The platform is self-learning and uses consumer data to advise the foodservice actors about anticipation of consumer needs. The translation of consumer data into valuable insights for the industry generates a viable revenue model. The key business activities are the data analysis and the matchmaking between consumers and meals. The implementation of the concept is explained according to a roadmap and indicates a strategy for entering the market. The concept is positioned as an honest and truthful platform that serves and supports stakeholders in their sustainable consumption behaviour. This creates a competitive advantage compared to other delivery platforms. The concept covers all SHIFT factors to encourage sustainable food consumption and therefore owns the potential to change consumer behaviour (White, 2014). A change in consumer behaviour results in new consumer demand. The change will affect the supply side of the feedback loop and contributes to the transition of the consumption system.","Behaviour Change; System Design; Food Design","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:022cdfe2-737e-44f4-8497-0159a826b9ea","http://resolver.tudelft.nl/uuid:022cdfe2-737e-44f4-8497-0159a826b9ea","Safe Curriculum Learning for Linear Systems With Unknown Dynamics in Primary Flight Control","De Buysscher, Diego (TU Delft Aerospace Engineering)","de Croon, G.C.H.E. (mentor); van Kampen, E. (graduation committee); Mooij, E. (graduation committee); Pollack, T.S.C. (graduation committee); Delft University of Technology (degree granting institution)","2021","Safe Curriculum Learning constitutes a collection of methods that aim at enabling Rein- forcement Learning (RL) algorithms on complex systems and tasks whilst considering the safety and efficiency aspect of the learning process. On the one hand, curricular reinforce- ment learning approaches divide the task into more gradual complexity stages to promote learning efficiency. On the other, safe learning provides a framework to consider a system‚Äôs safety during the learning process. The latter‚Äôs contribution is significant on safety-critical systems, such as transport vehicles where stringent (safety) requirements apply. This pa- per proposes a black box safe curriculum learning architecture applicable to systems with unknown dynamics. It only requires knowledge of the state and action spaces‚Äô orders for a given task and system. By adding system identification capabilities to existing safe cur- riculum learning paradigms, the proposed architecture successfully ensures safe learning proceedings of tracking tasks without requiring initial knowledge of internal system dynam- ics. More specifically, a model estimate is generated online to complement safety filters that rely on uncertain models for their safety guarantees. This research explicitly targets linearised systems with decoupled dynamics in the experiments provided in this article as proof of concept. The paradigm is initially verified on a mass-spring-damper system. After that, the architecture is applied to a quadrotor where it is able to successfully track the system‚Äôs four degrees of freedom independently, namely attitude angles and altitude. The RL agent is able to safely learn an optimal policy that can track an independent reference on each degree of freedom.","Reinforcement Learning; Curriculum Learning; Safe Learning; Machine Learning; Q-Learning; flight control","en","master thesis","","","","","","https://github.com/DBdiego/SafeCurriculumLearning.git Git repository containing the code of the implementation","","","","","","Aerospace Engineering","",""
"uuid:b35b0984-1fbb-4f18-81d3-a01a8c9c8060","http://resolver.tudelft.nl/uuid:b35b0984-1fbb-4f18-81d3-a01a8c9c8060","Investigation of isostatic slabs in timber","Church, Matt (TU Delft Civil Engineering and Geosciences)","van de Kuilen, J.W.G. (mentor); Hoogenboom, P.C.J. (graduation committee); Ravenshorst, G.J.P. (graduation committee); Crielaard, R. (mentor); Delft University of Technology (degree granting institution)","2021","The isostatic slab was developed by Pier Nervi and his colleague Aldo Arcangeli to create an elegant and easy to produce floor system, with efficient use of material. These slabs are designed with ribs aligned to the principal bending stress lines that support a flat deck. Concrete isostatic slabs are no longer constructed due to their expensive formwork. However, this system could be advantageous when made from timber as the grain direction will be aligned to the optimal flow of forces. Additionally, isostatic slabs can be designed for any support conditions, so an isostatic timber slab may be more desirable than the typical one-way spanning timber systems. The isostatic timber slab is a new concept and has not been previously used. Therefore, before the system can be applied, there needs to be a greater understanding of the design process. This research achieves this goal by splitting the process into two parts. Firstly, the rib geometry is created by generating the principal bending stress lines. Secondly, the system is designed and analysed for a case study. The aim is achieved by creating a functional design and identifying the critical areas in the design process. An approach for measuring the accuracy of stress lines is developed and used to test different methods for improving the stress line generation process. The improved process uses a more advanced integration method and a holistic seeding method. Additionally, a novel method for interpolating the principal stress trajectories from finite element analysis (FEA) results is established by utilising the shape functions from the theory of FEA. An iterative approach used to select stress lines to create optimised truss geometries in in-plane-loaded plates is tested for its applicability to out-of-plane loaded plates (i.e. slabs). The rib geometry produced was measured by the approximation error and the deck elements' span lengths. This iterative approach does not apply to slabs as it creates clustered areas and excludes symmetries. Analysis of principal stresses under different load cases shows that the most considerable difference from the primary load case is when half of the slab is loaded with a maximum load and half with a minimum load. (The primary load case is the condition used to create the stress lines for the rib geometry). Using FEA to calculate the stresses under each load case shows that uneven loading of the slab does not produce higher stresses than the primary load case. A functional isostatic timber slab design is made for the case study using laminated veneer lumber (LVL) for the ribs and plywood for the deck. Linear elastic FE modelling of the structure shows that increasing the deck thickness and decreasing the rib depth, causes the deck to carry more load and the ribs to carry less and vice versa. Increasing the rib thickness has a small effect on the force distribution due to the available LVL thicknesses. The FE modelling also showed that the torsional load transfer mechanisms are reduced by increasing the rib slenderness. The design is made based on the ultimate limit state (ULS) stress requirements for the elements and three critical connections, and the deflection under the serviceability limit state (SLS). The rib-to-deck joint requirements determine the deck thickness, and the deck has a low utilisation for the stress conditions, meaning that the deck span lengths are not critical. The ribs' depth is heavily dependent on the rib-to-rib moment connection as a large lever is needed. The cross-sectional properties of the ribs are also dependant on the standard LVL sizes. This system is compared to several conventional one-way spanning alternatives based on the total material volume, the structural weight, and the structural depth. The isostatic timber slab has a reduced volume and weight compared to a flat cross-laminated timber (CLT) slab, a Kerto-Ripa slab, and a concrete hollow-core slab; however, the isostatic timber slab has a larger structural depth. A ‚ÄòT‚Äô-beam equivalent to the two-way spanning isostatic slab has less volume and weight while maintaining the same structural depth, but has a larger average deflection. Timber isostatic slabs are complex to design with a highly connected network of parameters. The system should be designed by minimising the peak moment forces at connections, curating the support conditions to reduce stress line clustering, and selecting stress lines for the rib geometry which ensure sufficient stiffness at the peak deflection location. It is advised to produce a parametric model of the slab that can quickly assess the design performances and efficiently complete design cycles.","Timber; Isostatic Slabs; Optimisation; Principal Stress Lines","en","master thesis","","","","","","","","","","","","Civil Engineering | Building Engineering","",""
"uuid:65390269-8a73-4de4-8fb0-b56a350ae807","http://resolver.tudelft.nl/uuid:65390269-8a73-4de4-8fb0-b56a350ae807","Do we get what we want?: On stakeholder management related to the verification and validation process in large infrastructure projects","Ridderinkhof, Geert (TU Delft Civil Engineering and Geosciences)","Veeneman, Wijnand (graduation committee); Steenhuisen, B.M. (mentor); Bosch-Rekveldt, M.G.C. (graduation committee); Davidse, Christine (mentor); Delft University of Technology (degree granting institution)","2021","The increased complexity and changes in collaboration between involved actors in the realization of large infrastructure projects (LIP‚Äôs) cause major challenges. One of these challenges entails meeting stakeholders‚Äô requirements through verification and validation (V&amp;V) during the design phase. Coordinating the design with the stakeholders can easily lead to delays or bad relationships. The V&amp;V process originates from systems engineering (SE) and it seems that an attempt is being made to reduce the complexity by performing the V&amp;V process in a systematic way. However, various researchers indicate that there is a need for interaction and it is doubted if this need for interaction is taken into account in this SE approach. The V&amp;V process half-heartedly relates to stakeholder management (SM) while they seem to be a good fit. It is expected that a successful performance of SM can fill this need for interaction in the complex environment of LIP‚Äôs. Therefore, this research sought an answer to the question: How can stakeholder management help to improve the verification and validation of the stakeholders‚Äô requirements during the design phase of large infrastructure projects in the Netherlands? Through a literature study into SM, an evaluation tool is formulated consisting of four core values. These values are: setting goals together, assessing stakeholders, involving stakeholders in the decision-making, and continuously interacting with stakeholders. A case-study approach is used to allow a deeper understanding of the application of SM in relation to the V&amp;V process during the design phase in practice. Through semi-structured interviews, based on the evaluation tool, the perspectives of contractors, clients, and stakeholders on SM in relation to the V&amp;V process were investigated. Conclusively, the findings from the three cases were compared based on different themes to gain an understanding of the role SM plays in relation to the V&amp;V process. Setting goals together, appears to be truly important in relation to the V&amp;V process. Respondents believe that by setting goals together, parties involved become more aware of the underlying interests and concerns behind the requirements of the project and thus get a better picture of the purpose of the requirements. Consequently, it brings parties closer together from the start. Furthermore, continuously interacting with stakeholders during the process in an open way is important as this creates support among stakeholders. Through this, the contractor must discuss the progress of the design by reflecting on the overall picture and not only on the problems that arise. The stakeholders, but the client as well, find it very meaningful to be thoroughly informed about the reasoning behind the design choices of the contractor. This applies to involving stakeholders in the decision-making as well. The current way in which the stakeholders and the client actually participate in making decisions seems sufficient on condition that stakeholders and client are sufficiently informed about the motives of the contractor. In the context of the studied cases, assessing stakeholders does not appear to be important in the V&amp;V process of the design phase. This research has not identified a clear correlation between the performance of the V&amp;V process and a contractor or a client who is carrying out the SM related to the V&amp;V process, the degree of collaboration seems much more important. Both the contractor and the client have substantial resources that are required to coordinate the design with the stakeholders and they have a common interest in monitoring the contract. Therefore, it is the interest of both of them to enter into good collaboration in managing the stakeholders in relation to the V&amp;V process. The ambiguity of the V&amp;V process is recognized in practice as well, where the contractor and client struggle to find a more SE-driven approach or a more SM-driven approach. The context in which the process takes place determines which approach is more effective. There are several directions for further research. First of all, this research uses an evaluation tool based on research into SM focusing on LIP‚Äôs in general. Therefore, this research can be seen as an exploratory study into SM specifically aimed at the V&amp;V process. It is recommended to conduct follow-up research into further testing and specifying the evaluation tool. Furthermore, this research shows that there is a tension in the V&amp;V process regarding monitoring the contract. Further research into contract management in relation to the V&amp;V process is recommended as well. Based on the evaluation tool, this research has made recommendations for determining an SM strategy in relation to the V&amp;V process. Since every V&amp;V process takes place in a different context, no unambiguous advice can be given. However, this research has shown that setting goals together and continuously interacting with stakeholders are both very important for the performance of the V&amp;V process, regardless of the conditions of the process.","Stakeholder management; Verification and validation; Stakeholders","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:ddf56550-e2d5-40b6-9ff4-3564931f47c4","http://resolver.tudelft.nl/uuid:ddf56550-e2d5-40b6-9ff4-3564931f47c4","Recycling 3D Prints: Enabling material reuse in prototyping facilities","Aliana Guardia, Marc (TU Delft Industrial Design Engineering)","Balkenende, A.R. (mentor); Minnoye, A.L.M. (graduation committee); Delft University of Technology (degree granting institution)","2021","In Fused Deposition Modeling (FDM) for rapid-prototyping, the 3D printed parts usually have a short life, generating a constant stream of waste material and lost value. This issue becomes more relevant in the early stages of product development, where 3D printed prototypes become rapidly obsolete due to design iterations and advances in the project. Polylactic Acid (PLA) is one of the most popular in early prototyping. As a result, prototyping facilities generate a constant waste stream of PLA from failed prints, support material and obsolete prints. A material stream that is currently not being reused, recycled or industrially biodegraded. This project investigated the opportunity of reusing this waste stream by recycling it back to FDM filament, closing the material loop in a prototyping facility context. First, insights from industry experts, prototyping users and state of the art were collected and an opportunity was identified in low-fidelity prototyping. Then, the production and low-fidelity printability of recycled PLA from 3D printing waste was tested. The printability results demonstrated that recycled PLA filament produced with a desktop recycling setup can be 3D printed, achieving similar low-fidelity prototyping capabilities for design projects as virgin material. The findings gathered in the research phase were converged into a future vision, a roadmap and a short-term solution to explore and facilitate its implementation. Additionally, a printing guide summarized the adjustments and recommended settings for future end-users and a design case study demonstrated its feasibility and implications on the design process in practice. The solution is evaluated by a prototyping facility and the recommendations for its implementation are outlined.","3D Printing; FDM; Sustainabilty; Recycling; PLA; Prototyping","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:16dcfe6c-5b60-45b1-8b1d-892e53db8ecb","http://resolver.tudelft.nl/uuid:16dcfe6c-5b60-45b1-8b1d-892e53db8ecb","The effect of localised laser treatment on the deformation behaviour of a Fe-Ni-C steel","van Seumeren, Mark (TU Delft Mechanical, Maritime and Materials Engineering)","Hidalgo Garcia, J. (mentor); Santofimia Navarro, M.J. (mentor); Popovich, V. (graduation committee); Sedighiani, K. (graduation committee); Delft University of Technology (degree granting institution)","2021","The strength-ductility trade-off has been a long standing dilemma in material science. With the use of laser surface treatments, effort has been made in order to obtain a heterogeneous material with a well defined architectured microstructure to optimize this trade-off. In the present study, it is investigated how the deformation behaviour of Martensite/Austenite steel microstructures in a Fe-25Ni-0.2C alloy can be tailored by the creation of patterned microstructures with localized laser treatment. Due to these treatments strong variations in microstructure are observed. Two different patterns are created (i) a dotted diagonal pattern and (ii) a dotted horizontal pattern which are both evaluated using as-quenched and tempered martensite as base material. The deformation behaviour of the patterned microstructures is investigated using both experiments and simulations. In the experimental approach characterization of the laser treated specimens is carried out using Optical Microscopy (OM) and micro-hardness measurements. The local deformation of the patterned microstructure is investigated using Digital Image Correlation (DIC). During deformation, strain partitioning is observed in the austenitic areas. In these areas mechanically induced martensitic transformation takes place, influencing the hardening of the material. The phase strength does not seem to influence the austenite stability in the analysed patterns, however it does show difference in hardness of the freshly formed martensite. For the simulation, Crystal Plasticity Finite Element Modelling (CPFEM) is used to describe the plastic deformation of the patterned material. Both the local and overall behaviour are investigated and validated with the experimentally obtained results. The simulation can serve as a tool to identify patterns which show promising deformation behaviour.","","en","master thesis","","","","","","","","","","","","","",""
"uuid:1217e087-a4fd-49f2-b817-20cf2ba12c49","http://resolver.tudelft.nl/uuid:1217e087-a4fd-49f2-b817-20cf2ba12c49","Washing as a Service - Quantifying the Environmental Impact of a pay-per-use washing machine through Life Cycle Assessment","Steunenberg, Kirsten (TU Delft Technology, Policy and Management)","Bakker, C.A. (mentor); Guin√©e, J.B. (graduation committee); Delft University of Technology (degree granting institution); Universiteit Leiden (degree granting institution)","2021","In order to live more sustainably on this planet, the world‚Äôs population needs to transform the current take-make dispose society towards a society with more maintainable consumption patterns and more sustainable business models. A way to achieve this, is a circular economy in which value is maintained within the product cycle, by sharing, repairing, reusing, refurbishing and recycling. Product-service systems, such as leasing, sharing and pay-per-use models, are presented as a way to contribute to the circular economy. Product-service systems (PSS) could potentially reduce environmental impacts, however, PSS do not automatically lead to positive environmental impacts and not all PSS are by default environmentally benign. Therefore, several authors call for quantifications of PSS‚Äô environmental impacts, because the benefits of PSS remain inexplicit in literature and are mostly qualitatively described. Life Cycle Assessment (LCA) is a common method to evaluate the environmental impacts over a product‚Äôs lifecycle. LCAs compare the function that products or services fulfil over their entire life cycle and over various impact categories. As such, they provide an appropriate method to assess PSS‚Äô environmental impacts.","LCA; Product-Service System; Pay-per-use; Washing machine; Environmental Impact Assessment","en","master thesis","","","","","","","","","","","","Industrial Ecology","",""
"uuid:95595ab8-1f83-4ea5-8eee-e091beab0224","http://resolver.tudelft.nl/uuid:95595ab8-1f83-4ea5-8eee-e091beab0224","The application of a Fuzzy Adaptive Learning Control Network in cost estimates for road bridges","ten Have, Mark (TU Delft Civil Engineering and Geosciences)","Wolfert, A.R.M. (mentor); Binnekamp, R. (graduation committee); Demiroviƒá, E. (graduation committee); Schulte Fischedick, Erik (graduation committee); Delft University of Technology (degree granting institution)","2021","In general, costs are an important aspect long before the construction of a civil project starts. In the conceptual phase, which is the first phase of a civil construction project, little cost information is available, and the cost estimate is at that stage of project development less accurate than when the project is almost completed. When a cost estimate is made with a conventional method, such as SSK, in the conceptual phase of a civil construction project, the Association for the Advancement of Cost Engineering, AACE, argues that the error of a cost estimate compared to the real price can be 15-50%. The lower accuracy in the conceptual phase is caused by several obstacles: a lack of estimating experience, lack of information, and a method that cannot calculate an accurate cost estimate. Besides, the conventional approach is time-consuming. Machine learning models can overcome these obstacles. This research is initiated by a practical problem within the company Witteveen+Bos. Witteveen+Bos uses a conventional approach for cost estimates and wants to improve the accuracy and calculation time of cost estimates of road bridges in the conceptual phase of a project. This research aims to improve the cost estimates of bridges in the conceptual phase of bridge projects by use of the machine learning model called FALCON. This model is already successful applied in the field of cost estimates for construction project types. Improvement that should be realized in the reduction of the calculation time from hours to minutes. Besides the research aims to reduce the maximum deviation of estimates for road bridge projects to 30%. The FALCON model is not the only model to solve an estimation problem. Standard models, suitable for estimation problems, are multiple linear regression, K nearest neighbors (KNN), and decision trees. The results show that the average absolute deviation is 34% for the KNN model, 36% for the decision tree regression model, 57% for the multiple linear regression model, and 24% for the FALCON model. All 4 models are able to calculate results within a couple of minutes. FALCON is the most accurate model The error of the individual predictions of the FALCON model roughly corresponds to the bandwidth of the AACE (15-50%) for the conceptual phase of a project. The validation of the FALCON model is realized through interviews with cost estimators of Witteveen+Bos. These interviews showed that the realized results meet the expectations of the interviewees. Besides, the interviewees are willing to implement the model in practice. In the end, it must be concluded that the FALCON model can calculate a cost estimate, of bridge projects in the conceptual phase, more quickly, and with a comparable accuracy level as with conventional methods that are used today. For future research, it is recommended to use a larger dataset that has less variation. The used dataset consists of 39 bridge projects. Besides, it is recommended to use international standards for data structuring instead of national standards.","FALCON; Artificial Intelligence; Neural Network","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:6bb92e8f-76f1-420a-8343-12bf27fedd8f","http://resolver.tudelft.nl/uuid:6bb92e8f-76f1-420a-8343-12bf27fedd8f","The role of subjectivity on sustainability and risks of novel material solutions for anthropogenic municipal solid waste incineration bottom ash in the Netherlands: An investigation using Q-methodology","Piltz, Gunilla (TU Delft Technology, Policy and Management)","Annema, J.A. (mentor); Pesch, U. (graduation committee); Delft University of Technology (degree granting institution)","2021","Municipal solid waste incineration (MSWI) bottom ash is a by-product of Waste-to-Energy recycling and has until today been used for construction purpose or been landfilled. Especially in the Netherlands the regulatory regime constantly changes and increases the applicability of novel materials from MSWI in construction. Due to the Green Deal a step was taken to ban the former IBC-quality and prescribes the immobilisation or treatment into freely applicable bottom ash that is said to have the highest value. Connected to these regime changes, values about sustainability and risk of the bottom ash materials are regularly changing. In order to provide insights for informed decision making on novel solutions for bottom ash, this study was subject to examine expert‚Äôs subjective opinions about sustainability and risk of freely applicable bottom ash. Q-methodology has been chosen as qualitative and quantitative method as it can derive interesting insights in the debate on MSWI bottom ash, without making conjecture of any industrial perspectives. The established framework consists of 44 statements about sustainability aspects such as the circular economy, the role of Waste to Energy, Climate resilience and certification as well as risk aspects like leaching, chain risks, the application for the circular economy and project complexity. The participant sample consists of 15 experts from the construction and built environment, waste management and consultancy. The results present 4 perspectives that distinguish each other by the attitude towards the Green Deal and the role of Waste-to-Energy in the Circular Economy. While the freely applicable quality is widely approved for reductions of the leaching potential, the regulation does not yet sufficiently cover new risks arising from the free application potential for precautious experts. Furthermore, it should be taken into account in decision making that the communication about freely applicable bottom ash is subject to multiple inherent biases.","MSWI BA; bottom ash; Q-methodology; Q-sorting; freely applicable; Green Deal; decision making","en","master thesis","","","","","","","","","","","","Industrial Ecology","",""
"uuid:78ea9a50-e38e-49af-9472-13fc1fd4f33e","http://resolver.tudelft.nl/uuid:78ea9a50-e38e-49af-9472-13fc1fd4f33e","Comparison of Different Methods to Solve the Steady-state Flow Problem of District Heating Networks and Gas Networks","Mahieu, Mare (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Numerical Analysis)","Romate, J.E. (mentor); Markensteijn, A.S. (mentor); Vuik, Cornelis (graduation committee); Dubbeldam, J.L.A. (graduation committee); Delft University of Technology (degree granting institution)","2021","There are several different methods to solve the steady-state flow problem of district heating networks and gas networks. In this thesis, the nodal method, the loop method, and the loop-node method are compared. This is done in order to determine for what type of network, with specific characteristics, which of these methods is preferred. In this comparison, the focus is on computer storage, sensibility to starting values, convergence properties, and computational time.","Gas network; District Heating Network; Loop method; Nodal method; Loop-node method; Steady-state flow problem","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:7c2e5cc4-abf4-425e-98fa-f4ca5490529c","http://resolver.tudelft.nl/uuid:7c2e5cc4-abf4-425e-98fa-f4ca5490529c","Designing for Post-Processing: A Case Study of a 3D Printed Surgical Instrument","Bruins, Mathijs (TU Delft Mechanical, Maritime and Materials Engineering)","Lussenburg, K.M. (mentor); Breedveld, P. (graduation committee); Zhou, J. (graduation committee); Delft University of Technology (degree granting institution)","2021","In this report a design is proposed for a laparoscopic gripper that can be manufactured with metal 3D printing and polished with mass finishing. The design is a continuation of the development of a laparoscopic gripper that can be 3D printed in plastic. Laparoscopic grippers 3D printed solely out of metal have not yet been presented. Laparoscopic instruments are limited in width to 5 mm, which is bordering the manufacturing limits of selective laser melting 3D printing. The use of 3D printing for medical instruments has the potential to customise instruments specific to patient, procedure, and surgeon. Metal 3D printing can produce complex parts, albeit with a high surface roughness. Post-processing is required to reduce the surface roughness. Mass finishing techniques are a group of mechanical polishing techniques, of which centrifugal disc finishing was selected due to its capability to process parts in bulk without requiring workpiece fixation. To synthesise a suitable design, the processes of printing and polishing were analysed to formulate design guidelines. The analyses were part literature study, part experimental study. The experimental study had the aim to quantify and supplement the guidelines found in handbooks and articles. Using a novel visualisation technique, the polishing of different geometries could be distilled into quantitative design considerations. Here, a marking lacquer was applied to the surface of workpieces, which remained on unpolished surfaces. In this experiment a number of features were used, which corresponded to aspects that had potential to be used in the design. The use of channels was deemed unviable for polishing at the scale of laparoscopic instruments, which required the removal of these from the design. Mass finishing polishing removed the coarse surface structure present on metal produced with 3D printing, and brought surfaces of the test pieces to 0.05 mm below their desired width. Application of the design guidelines to the laparoscopic instrument was focused on making printing and polishing compatible joints. The laparoscopic gripper has two degrees of freedom for increased manoeuvrability. The features that comprise the joint are protrusions and cut-outs, sinusoidal gear arches, and actuation cable guides. Each of these features were dimensioned with values from the guidelines. The joint design required a number of components to be split so polishing access could be guaranteed, specifically for the cable guides. This had the added benefit of having each part be orientated during printing individually. The final design is based on application of the relevant design guidelines, and has been validated using scale models for mechanical stability.","3D Printing; mass finishing techniques; Metal Additive Manufacturing; Laparoscopic","en","master thesis","","","","","","","","","","","","","",""
"uuid:84932cd4-1510-4793-9a19-f62b90b9c20e","http://resolver.tudelft.nl/uuid:84932cd4-1510-4793-9a19-f62b90b9c20e","A new perspective on the challenges of contract management information systems","van Triest, Harmen (TU Delft Civil Engineering and Geosciences)","Chan, P.W.C. (mentor); Houwing, E.J. (mentor); van Nederveen, Sander (graduation committee); Mochawer, Shahnam (graduation committee); Goosens, Michiel (graduation committee); Delft University of Technology (degree granting institution)","2021","One of the cornerstones of construction project delivery is contract management. It can be directly related to business and project performance (Muhammad et al., 2019). Nevertheless, contracts and contract management have proven to be a complex and risky undertaking. It has been named as one of the main causes of conflict in the construction sector (Jaffar et al., 2011). To mitigate these problems, information systems have been implemented in contract management. Nevertheless, these systems are not fully delivering on their promises. Evidence that overall costs were reduced or an improvement in project performance is very limited (Zhai et al., 2009), and contemporary information systems have often failed to realize their goals (Mutschler et al., 2008). These developments indicate that the implementation process needs optimization. Preliminary research identified two socio-technical theories that are useful for analyzing human-system interactions during the implementation and use of information systems. Activity theory provides the framework for the analysis of human-system interaction. At the same time, boundary objects seem to be involved when multiple specialists transfer knowledge through the use of objects. Information systems are highly involved in this process. Therefore, boundary objects are also included as a focus of this research. These two theories should provide a new perspective on the challenges concerning contract management information systems. This analysis brought a few bad practices to light: ‚Ä¢Support for the system users was severely lacking ‚Ä¢Wrong tactics were used to incentivize system use ‚Ä¢Responsibilities were unclear, and accessibility of necessary knowledge was limited ‚Ä¢Solutions were often late and ineffective or only partly effective ‚Ä¢Turnkey solutions rarely functioned as desired ‚Ä¢Boundary objects are often not handled correctly Generally, the implementation process was characterized as unstructured and reactive. Next, these lessons learned were applied to create a set of recommendations that should improve current practices. The first set of recommendations was aimed at creating the right information system. The creation of a development team is key in facilitating this process. By sharing responsibility over multiple specialists under the guidance of a system coordinator, the information systems can be correctly created. Next, Including feedback from users, keeping the system as simple as possible, and using proper specifications make sure the information system is fit for purpose. The second set of recommendations cover the realization of the requirements for the correct supporting infrastructure for the information system. This consists of the introduction of a few new roles under the support team and some supporting tools to align the supporting structures with the users. This supporting infrastructure requires the introduction of system ambassadors, a system developer, a system coordinator, and a trainer. The necessary supporting mechanisms are two-stage training, system meetings, clear and targeted manuals, and rules, and finally, the securing of common interpretations. Finally, to make the recommendations more usable, they were transformed into the tool-support implementation (TSI) roadmap. This roadmap transforms the recommendations into a two-phase strategy that managers can apply in their projects. The first phase ensures the right conditions to build the correct information system. Consequently, the second ensures the right conditions to create the right supporting structures. Following this roadmap should ensure the proper creation and implementation of a contract management information system. Finally, to bring these conclusions back to the starting point, the following answer to the main research question is provided. Contract management can indeed be improved with an analysis of the implementation process based on socio-technical perspectives. The application of this new perspective brought a new set of problems concerning the implementation of contract management information systems to light. By showing what went wrong, changes could be recommended in order to improve current practices. Therefore, the importance of these challenges lies in the fact they need to be addressed to gain the benefits that information systems are supposed to have. To realize this goal of the research, the recommendations, and tool-support implementation roadmap have been constructed. When these recommendations are applied by using the TSI roadmap, the presumed benefits of information systems should finally be unlocked. As a result of these benefits, current contract management practices are likely to be improved.","Contract management; BIM; information systems; activity theory; boundary objects","en","master thesis","","","","","","","","2024-02-11","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:4bc769b7-4249-43b6-bcc5-7daf6303e054","http://resolver.tudelft.nl/uuid:4bc769b7-4249-43b6-bcc5-7daf6303e054","Calf muscle model parameters in children with cerebral palsy compared to typically developing children","Mackenbach, Caroline (TU Delft Mechanical, Maritime and Materials Engineering)","Seth, A. (mentor); Harlaar, J. (mentor); Marchal Crespo, L. (graduation committee); Bar-on, Lynn (graduation committee); van der Krogt, Marjolein (graduation committee); Delft University of Technology (degree granting institution)","2021","class=""MsoNormal"">Background: In children with cerebral palsy(CP), muscle-tendon structures are altered. While interventions exist to treataltered structures, the selection of the most suitable treatment is verycomplex with highly variable outcomes. Musculoskeletal models have thepotential to support clinical decision making. However, a known limitation isthe translation of altered muscle-tendon parameters into musculoskeletalmodels. The aim of this study was to estimate the intrinsic calf musclesproperties using neuromuscular simulations of a passive ankle rotation intypically developing children and children with CP. With these simulations wedetermine to what extent optimal fiber length, tendon slack length, stiffness,and strain differ between typically developing (TD) children and CP children. ¬†Methods: Experimental data was collected onthirteen children with spastic CP (6 diplegia, 7 hemiplegia, age 11.6 ¬± 3.1years) and 17 TD children (age 10.4 ¬± 3.3 years) during a slow passive anklerotation. Ankle angle, external forces applied on the ankle, and medialgastrocnemius fascicle length were measured. An OpenSim model with four musclesaround the ankle, GASM, GASL, SOL, and TA, was used to simulate passive anklerotation experiments. Optimal fiber length, tendon slack length, stiffness atlow force, strain at zero force, and strain at maximum force were optimized tomatch the measured ankle moment-angle curves and the GASM fascicle length-anglecurves. ¬†Results: The ankle moment-anglecurves could be successfully matched in both CP and TD (RMSE &lt; 0.42 Nm) byoptimizing individual calf muscle-tendon parameters. The fascicle length-anglecurves could be predicted much better in CP children by optimization, howeverrelatively large residuals remained (RMSE 0.40 cm). These simulations revealthat children with CP have a shorter normalized optimal fiber length and alonger triceps surae normalized tendon slack length compared to TD children.Also, CP triceps surae was found to be stiffer and undergoes less fasciclestrain compared to TD children. Further, the triceps surae passive fiberforce-length curve in CP children is engaged at shorter fiber lengths whencompared to that of TD children. ¬†Conclusion:Simulations show that intrinsic calf muscle-tendon properties aresystematically different between CP and TD children. However, large variancesin fascicle lengthening muscle-tendon parameters in CP children exist. Futureresearch should attempt to better match groups in terms of age, height, andweight. A next step would be to apply these optimized parameters to simulationsof CP gait. This would help identify to what extent altered muscle propertiesaffect gait in children with CP and subsequent treatment decisions.","Musculoskeletal Model; Cerebral Palsy; subject-specific model; neuro-muscular simulation","en","master thesis","","","","","","","","","","","","Biomedical Engineering","",""
"uuid:4c90803a-4980-44e4-9edd-29184d687207","http://resolver.tudelft.nl/uuid:4c90803a-4980-44e4-9edd-29184d687207","Identifying barriers hindering the Aquaponics as an emerging value-conscious socio-technical system in the Netherlands","Piptov√°, Marianna (TU Delft Technology, Policy and Management; TU Delft Applied Sciences; TU Delft Industrial Design Engineering)","Kamp, L.M. (mentor); Pesch, U. (graduation committee); Delft University of Technology (degree granting institution); Universiteit Leiden (degree granting institution)","2021","In the current times when ""facts [are] uncertain, values in dispute, stakes high and decisions urgent"" (Funtowicz &amp; Ravetz 1990) humanity reaches for new ways of improving our life through resilient technology enhancements embedded in a socio-technical landscape. This thesis presents an effort to develop a theoretical framework that can be used to analyse the barriers hindering the Aquaponics as an emerging value-conscious socio-technical system in the Netherlands. The barriers are identified in institutional, technical, economic, infrastructural, knowledge, socio-cultural, ethical and biophysical dimensions. In the research, the initial barrier criteria theoretical framework was established based on combining Functions of innovation system, Circular economy theoretical models in the Verhulst (2017) theoretical framework with ethical barriers based on Value Sensitive and Value Conscious Design approach. This primary theoretical framework Piptov√° 1 (2018) was applied to the current Aquaponics case in the process of desk research and in-depth interviews with stakeholders. This resulted in a list and description of barriers. The high initial investment costs, scalability issues due to the niche character of the market for Aquaponics products, cold climate in the Netherlands, current non profitability due to incumbent infrastructure of cheap vegetables supplied by elaborate Dutch horticulturalists from their greenhouses and cost-effectively imported fish, biophysical limitations as well as several ethical barriers in the form of value tensions and values not represented by a value advocate in the Aquaponics discourse were identified as the barriers hindering the Aquaponics as an emerging value-conscious socio-technical system in the Netherlands. Based on the list and description of barriers, the primary theoretical framework was revised and adapted by adding and removing indicators. The final theoretical framework Piptov√° 2.0 (2020) was established. It reflects on the malfunctions, ethics and risks of new technologies but also democratisation in the design process and science in general through an ecocentric prism due to the fact that it contains a consideration for all directly and indirectly affected stakeholders, whether presented or not by an actor, including the non-human ones. Via employing the fundamental capabilities of the created framework and adapting it in order to be able to detect a wider horizon of developmental bottlenecks from the systemic Industrial ecology perspective, a novel generally applicable theoretical framework was also created. Producers, consumers, scholars, practitioners, policy makers and other actors might utilise this framework with improved generalizability when executing improvements on targeted hotspots in the transition towards a ‚Äòresponsible society‚Äô via a variety of ‚Äòfair‚Äô innovations emerging as value-conscious socio-technical systems. These are the advancements that not only ‚Äòlook good on paper‚Äô but truly are more innovative in a ‚Äòresponsible and responsive‚Äô manner due to the fact that they challenge the status quo of problem shifting; the one which Beck (1998) in his sociological understanding defined as the ‚Äòorganized irresponsibility‚Äô.","Industrial Ecology; Aquaponics; Value Sensitive and Value Conscious Design; Ecocentrism; Responsible Innovation; Functions of Innovation System; Circular Economy; Non-human Well-being","en","master thesis","","","","","","","","","","","","Industrial Ecology","",""
"uuid:c3b8c6da-28a5-44c0-ad64-6e3e077af751","http://resolver.tudelft.nl/uuid:c3b8c6da-28a5-44c0-ad64-6e3e077af751","Development and optimisation of the lift beams topsides removal concept","Karliƒçiƒá, Arso (TU Delft Mechanical, Maritime and Materials Engineering)","Hoving, J.S. (mentor); van der Stap, A.C.M. (graduation committee); Meeuws, Pim (mentor); Duvekot, Heerema (graduation committee); Delft University of Technology (degree granting institution)","2021","A large number of light, modular topsides in the southern North Sea is planned to be removed in the near future. Heerema Marine Contractors (HMC) is currently not the most competitive in this market as smaller contractors can often provide cheaper removal solutions with the use of smaller heavy lift vessels. HMC therefore aims to find a more economically attractive solution for the removal of these topsides. Within HMC, a concept has been proposed to remove these modular topsides using so¬≠called lift beams. The lift beams are large beams that are installed underneath the topsides, and are connected to the topsides‚Äô strong points. The ends of the lift beams provide lift points for the complete topsides, enabling removal in a single lift. Due to their high lifting capacity, and large available deck space, the modular topsides on the lift beams can easily be lifted by a single crane of one of the company‚Äôs semisubmersible crane vessels (SSCV). Performing the lift by a single crane allows to put the topsides on deck of the SSCV for transportation. The concept is intended to be reused for a variety of modular topsides in the southern North Sea. In this thesis, the lift beams are designed, and optimised, to withstand the governing load cases, while complying with the practical boundaries that each topsides imposes. Hereafter, it is investigated whether it is structurally feasible to lift the modular topsides using the lift beams. To determine this, structural integrity analyses are performed on a reference topsides using FEM software. Hereby the optimal lift beam setup to lift the topsides is determined. Furthermore, methods are designed for the connection between the lift beams and the topsides, and the installation of the lift beams.The efficiency of the final lift beams concept design is assessed by comparing its performance to conventional removal methods for modular topsides. The lift beams are designed as stiffened box profile beams with a weight of more than 250 mT. The topsides is found to have sufficient capacity to withstand the loads during lifting. The optimal setup to lift the topsides consists of two lift beams per jacket leg row, and cross¬≠beams at each end¬≠on side of the lift beams. The cross¬≠beams add stiffness to the lift beams and thereby redistribute the lift loads in a favourable manner over the connection points. Using a pin¬≠hole connection between the lift beams and the topsides‚Äô legs is found to be most suitable. The lift beams are installed one¬≠by¬≠one using water as the counterweight component. Compared to conventional removal methods, the lift beams concept appears to be profitable after a relatively small number of topsides removals. For future research, it is recommended to investigate the possibilities of performing the lift beams concept with a dual crane lift. It is expected that the practicality of the removal process can be improved in this manner. The increased lifting capacity also allows for removal of wider range of modular topsides. After lifting off its substructure, the topsides could be transported while suspended in the cranes. Furthermore, it is recommended to extend the structural integrity analyses to the other topsides of interest. The structural limitations of the other topsides can be investigated, and the possibility to apply one¬≠sided leg support can be considered. The weight and costs of the lift frame, as well as the installation procedure can be improved this way.","Topsides decommissioning; Single lift; Modular Topsides; Lift beams; Steel design; Structural integrity; SSCV; Connection concept design; Installation concept design","en","master thesis","","","","","","","","2026-02-10","","","","Offshore and Dredging Engineering","",""
"uuid:6da44788-be32-4cf7-8624-fa3c1f1c1966","http://resolver.tudelft.nl/uuid:6da44788-be32-4cf7-8624-fa3c1f1c1966","Electrochemical degradation of GenX using boron-doped diamond anodes","Suresh Babu, Diwakar (TU Delft Mechanical, Maritime and Materials Engineering)","Buijnsters, J.G. (mentor); Mol, J.M.C. (graduation committee); Taheri, P. (graduation committee); Pabst, Martin (graduation committee); Delft University of Technology (degree granting institution)","2021","The presence of harmful pollutants and toxic pathogens in water is a risk to both living beings and the environment. Water treatment plays a crucial role in the removal of these contaminants through different stages of filtration. Among the existing pollutants, a family of per-and polyfluoroalkyl substances (PFAS) escapes from all treatment methods and ends up in our food, water and, finally, in our blood. Current treatment methods are not effective due to their inability to break the strong C-F bonds in PFAS. Perfluorooctanoic acid (PFOA) and perfluorooctanesulfonate (PFOS) are the most widely studied PFAS due to their widespread contamination of various environmental and biological matrices. Due to the global ban of PFOA, a short-chain fluorinated compound named GenX (the ammonium salt of hexafluoropropylene oxide dimer acid) is currently used as an alternative. However, recent studies have shown that GenX has higher toxicity compared to PFOA and is more easily soluble in water, thus making it more difficult for removal. Hence, this research surveys the potential of using boron-doped diamond (BDD) anodes, which are known to have the largest potential window and high stability over time, for GenX degradation. During the electrochemical advanced oxidation process (EAOP), the highly reactive hydroxyl radicals (OH‚Ä¢) produced at the BDD surface break the C-F bonds to form fluoride (FÀâ) and CO2 products. Till date, very limited research is reported on the GenX degradation and they present a contradiction on the effect of sulfate radicals (SO4‚Ä¢Àâ), considered for their high redox potential, in the GenX degradation. In the present study, we investigate the degradation and defluorination efficiency of GenX using boron-doped diamond anodes in EAOP. This study aims to elucidate the first step in the degradation mechanism of GenX and to clarify the contradictions previously reported on the role of sulfate radicals. Experiments are performed separately with sodium sulfate and sodium perchlorate to assess the effect of SO4‚Ä¢Àâ. The results demonstrate that sulfate radicals are ineffective in GenX degradation due to the steric hindrance by the -CF3 branch which blocks the trajectory of SO4‚Ä¢Àâ for electron transfer reaction. The effects of electrolyte concentration, current density, and chloride radicals on the degradation and defluorination are investigated for the first time to provide in-depth understanding of the degradation mechanism. A possible degradation pathway is proposed by determination of the intermediate products using mass spectrometry. From the proposed pathway, it is inferred that GenX completely mineralizes to CO2 and FÀâ via formation of three intermediates. By comparing the electrochemical degradation of GenX with that of PFOA, it is observed that the presence of the -CF3 branch increases the complexity of electron transfer in the GenX degradation even though the mineralization rate is faster for GenX than for PFOA due to lesser number of intermediates. Hence, the direct electron transfer from GenX to the BDD anode is observed to be the rate-determining step in the GenX degradation. Additionally, by comparing different BDD anodes based on their material properties and surface morphology, it is observed that the presence of sp2 regions which act as active sites for effective electron transfer is necessary to initiate the GenX degradation mechanism. Electrochemical degradation of GenX using the BDD anodes has resulted in the complete mineralization to CO2 and FÀâ which supports EAOP using BDD anodes as a promising approach towards effective PFAS degradation.<br","Boron-doped diamond; Hexafluoropropylene oxide dimer acid (HFPO-DA); GenX; Electro-chemical oxidation; Hydroxyl radicals; Perfluorooctanoic acid (PFOA)","en","master thesis","","","","","","","","2023-02-10","","","","","",""
"uuid:8a6daa50-83c3-4af1-9d32-201ba262d497","http://resolver.tudelft.nl/uuid:8a6daa50-83c3-4af1-9d32-201ba262d497","Hydrogen turbines, Effects of an increasing power density on the levelised cost of hydrogen","de Klerk, Felix (TU Delft Electrical Engineering, Mathematics and Computer Science)","von Terzi, D.A. (mentor); Zaaijer, M B (mentor); Groenemans, J.H.G.H. (graduation committee); Mulder, F.M. (graduation committee); Delft University of Technology (degree granting institution)","2021","In the current world, fossil fuels and non-renewable energy sources are being phased out and renewable energies are taking their place. Electrical energy from these renewable energies are more difficult to store than fossil fuels. Transportation and feedstock for industries can also not always be supplied through electricity. Here, hydrogen has the potential to be a good alternative, clean energy source. However, hydrogen is currently either not produced in a renewable manner (grey hydrogen), or renewable but too expensive (green hydrogen). Grey hydrogen is less expensive at a cost of around 1.50 ‚Ç¨/kg, while green hydrogen has a cost of 2.50 - 5.00 ‚Ç¨/kg. A new method to produce green hydrogen at a lower cost is the hydrogen turbine developed by HYGRO. This method uses an integrated electrolyser system in an existing wind turbine to produce green hydrogen and has the potential to drop the cost of green hydrogen to a more competitive level. Since this new method changes design questions of the wind turbine, a potential increase in specific power, along with a decrease in cost of hydrogen (expressed in levelised cost of hydrogen, or LCoH) is expected. In order to research these effects, this thesis investigated the effects of an increased specific power on the cost of the components of the turbine and its design, as well as the amount of hydrogen it was able to produce. This investigation was done through a model along with a case study to determine the results for a specific case. The increase in specific power was achieved by increasing the power rating of the turbine, but maintaining a constant rotor radius and maximal rotor speed. The case study performed investigates the effects based on a 15 MW reference turbine, which has a specific power of 331 W/m2. Its power rating was increased from 15 MW up to 35 MW and the resulting costs and production amount were compared to determine an optimal point were the resulting LCoH would be lowest. The result of the case study suggests that if the 15 MW reference turbine was converted to a hydrogen turbine, the optimal power rating would be in the range of 25-30 MW, where an LCoH of around 1.69 ‚Ç¨/kg was achieved. These power ratings are equal to a specific power range of 553 - 663 W/m2 or 66 - 100 % higher than the reference. Through an error analysis, the results were validated and determined to have a reasonable degree of certainty. The main component of the model that could be improved upon to increase its robustness is the wake loss model, which was not precisely modelled but does have a significant effect on the results.<br/>The increase in specific power suggests that hydrogen turbines have the potential to perform at higher power ratings than the wind turbine it is based on. This would allow the green hydrogen cost to drop significantly, down to a value were it is nearly competitive with grey hydrogen.","","en","master thesis","","","","","","","","2023-02-10","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:e6398079-c2c7-4360-a6ce-270b33f1baa4","http://resolver.tudelft.nl/uuid:e6398079-c2c7-4360-a6ce-270b33f1baa4","Design and Evaluation of an Ecological Interface for Separating UAV from Manned Air Trafc in Tower Control","van Aken, Daan (TU Delft Aerospace Engineering)","Janisch, D. (graduation committee); Borst, C. (mentor); Mulder, M. (mentor); Delft University of Technology (degree granting institution)","2021","The expected increase in unmanned aerial vehicle (UAV) traffic in European airspace raises concerns regarding the human factors of tower controllers. Dynamic geofences offer tower control a means to safely separate UAVs from manned traffic, without direct interactions with individual UAVs. A preliminary support interface was designed, supporting the operator in separating UAV traffic from manned traffic, while minimising impact on (high priority) UAV efficiency. The effects of traffic conditions and geofence size on control behaviour, safety, efficiency and interface usage were investigated in a human-in-the-loop experiment with active tower and air traffic controllers. Results show that geofences are considered a useful tool in maintaining safety, that larger geofences significantly increase average traffic separation and that the effect on efficiency differs per traffic scenario. Performance could be improved by increasing transparency and predictability of UAV routing, for example by optimising the geofence structure around the runway and by more clearly presenting high-level UAV information to the controller. Further work is needed to investigate controller behaviour and performance in an environment with control over both UAV and manned traffic, considering the temporal aspect of geofences, as well as a broader range of UAV missions and capabilities.","UAVs; U-space; Geofences; Tower Control; Ecological Interface Design; Human Control Behaviour","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:d9d4d66f-93e0-4691-a300-8e5d2630710b","http://resolver.tudelft.nl/uuid:d9d4d66f-93e0-4691-a300-8e5d2630710b","Mixed in place permeability reductive layer through Al and OM precipitation","Kaptein, Milou (TU Delft Civil Engineering and Geosciences)","Heimovaara, T.J. (mentor); Jumelet, D. (graduation committee); Hrachowitz, M. (graduation committee); Askarinejad, A. (graduation committee); Delft University of Technology (degree granting institution)","2021","class=""MsoNormal"">The control of infiltration and seepage of water is one ofthe most challenging tasks in water management and civil¬≠-engineering and, inan attempt to control this, methods for forming a water¬≠impermeable layer inthe soil have been widely practised in soil engineering (Laumann et al., 2018ÕæProto et al., 2016). The use of natural processes to modify the engineeringproperties of the subsurface could help to develop cost-¬≠effective, robust andsustainable engineering technologies and is attracting increasing attentionfrom the industry (Zhou, 2020). This research aims to reduce the permeabilityby using aluminium (Al) and organic matter (OM) precipitates mixed ex¬≠-situwith porous media to create a horizontal barrier. The Al¬≠-OM precipitates wereexpected to clog the pore space with a reduction in permeability and hydraulicconductivity as result. To find out if it is feasible to use Al¬≠-OMprecipitates mixed ex¬≠-situ with porous media for a permeability reductivelayer, the Al¬≠-OM precipitates and the permeability of the medium wereresearched. ¬†To characterise the flocculation reaction, experiments onthe flocculation were performed. The yield of the reaction was obtained byadding certain amounts of Al and OM solutions to form particular amounts of drymass of flocs. This experiment confirmed the hypothesis that 85% of the addedmass of OM will result in dry mass of flocs. The concept of a critical metal tocarbon ratio (M/C¬≠-ratio), indicating flocculation regardless of the inputconcentrations, was tested by measuring the pH over an increasing M/C-¬≠ratio.From this titration curve, the found critical M/C ratio is between 0.023¬≠0.031,and the pH stabilises at a level lower than pH 4. This result proves theconcept behind the numerical scenarios describing the titration of OM solutionswith Al3+, with a critical molar M/C ratio independent of the inputconcentrations (Veerkamp, 2018Õæ Zhou, 2020). After determining the yield of thereaction and concluding that the concentration of Al and OM was not ofinfluence, the by-products of the Al¬≠-OM reaction were quantified. The ionicstrength of the supernatant of an increasing density of flocs in solution wasdetermined by measuring the electrical conductivity (EC). The results showedthat the ionic strength increased linearly with an increasing density of flocs.The relationship between the ionic strength and the density of flocs was coupledto the linear relationship between concentrations potassium chloride (KCl) andits EC. From the results, the measured EC can be used as a tracer since the K+and Cl¬≠ are non¬≠reactive. ¬†The hydraulic conductivity measurements were conducted by afalling head test to be able to make an indication of the change inpermeability when adding the Al¬≠-OM precipitates to the sand. To find theoptimal method to mix the Al, OM and porous media, the influence of differentmethods of producing, adding and mixing the materials on the permeabilityreduction is explored. In the first mixing method, the Al and OM were added insolution, the solution containing Al-¬≠OM precipitates was centrifuged until thereduced ionic strength was at an EC value less than 700 ¬µm/cm. The hydraulicconductivity measurements were used to obtain the relationship between thehydraulic conductivity reduction over an increasing concentration of flocsretained by one kilogram of sand. The hydraulic conductivity was reducedexponentially over an increasing concentration of flocs up to a magnitude of 3.The results imply a large variability in the achieved reduction dominated bythe amount of retained flocs. The second method is using Al and OM in powderformat and adding them to the dry sand and adding 500 ml of water to thismixture. This mixing method resulted in a completely different floc structure.The flocs produced by mixing in solution have a shear dependency feature, whiledry mixing created particles that have a constant size. For this method, theincrease of the reduction is linear over an increase of concentration of flocsretained by the soil. The highest reduction for this method was found to be ofa magnitude of two, measured at 50 grams of flocs retained by one kilogram ofsand. Finally, this research gave proof of principle of using Al¬≠-OMprecipitates mixed directly with sand could reduce the permeability up to amagnitude of 3. These results present a new road to research on this Al-¬≠OM¬≠-sandmixture‚Äôs strength parameters and compaction over time over an increasing flocdensity, since these parameters are critical for using the layer in practice. ¬†","SoSEAL; Permeability Reduction; Hydraulic Conductivity; Hydraulic conductivity reduction; Al-OM","en","master thesis","","","","","","","","","","","","","SoSEAL",""
"uuid:06662806-f380-44ef-99da-0ee6f36cfdd5","http://resolver.tudelft.nl/uuid:06662806-f380-44ef-99da-0ee6f36cfdd5","The climate adaptive behaviour of smallholder farmers in the Gumera sub-basin, Ethiopia: A socio-hydrological approach","Schuurman, Ludo (TU Delft Civil Engineering and Geosciences)","Abraham, E. (mentor); Pande, S. (graduation committee); Scholten, L. (graduation committee); Delft University of Technology (degree granting institution)","2021","In Ethiopia, rainfall variability and changes in rainfall patterns, induced by climate change, could increase the frequency and occurrence of floods and droughts. Due to smallholder farmers in the Gumera sub-basin, Ethiopia, mostly relying on rainfed agriculture, climatic changes highly influence the agricultural production with corresponding negative effects on food security and their economic well-being. To reduce their vulnerability to climate variability, the majority of smallholder farmers take up adaptation strategies, whereas a small group of farmers does not have the capacity to adapt. However, the understanding of what factors drive the climate adaptive capacity of farmers and how climate adaptive behaviour influences a farmer‚Äôs economic well-being is limited. Therefore, via a bottom-up approach, this study aims to determine what factors drive the climate adaptive capacity of smallholder farmers in the Gumera sub-basin and how they adapt to climate variability. Focus Group Discussions are conducted prior to an individual household survey to obtain local-level knowledge and data on the characteristics of smallholder farmers. Subsequently, this data is used to develop a methodology to incorporate the climate adaptive behaviour of smallholder farmers in socio-hydrological modelling. By implementing a logit model, the (dynamic) adaptive capacity of smallholder farmers is implemented, which provides the opportunity to create a better understanding of why farmers adapt to climate variability and its impact on their economic well-being. From the Focus Group Discussions and the individual household survey it is observed that the majority of farmers adapt to climate variability in case of a bad year, defined as a drought, by changing to a short cycle crop, mostly potato, and adjusting the planting and harvesting dates. The drivers that are found to mainly influence the uptake of these adaptation strategies are farm size, altitude, level of education, the number of livestock owned, capital, experience, access to a weather forecast, and labour availability. A small group of farmers does not take up adaptation strategies instead. First of all, their adaptive capacity is constrained by a lack of land, labour, and a weather forecast. Secondly, the rather optimistic perception of non-adapting farmers towards climate change seems to limit their adaptive capacity. Thirdly, especially the limited use of the onset of rains by non-adapting farmers was observed to negatively influence their climate adaptive capacity. Incorporating the climate adaptive behaviour of smallholder farmers in socio-hydrological modelling by enabling a logit model showed to be a successful approach. Based on the main drivers for the climate adaptive capacity, the model is able to simulate the agricultural practices with respect to climate variability. As such, the model has shown to be able to simulate agricultural practices that better coincide with what is observed during both the Focus Group Discussions and the household survey. In addition, the methodology used to evaluate the long-term effect of climate adaptation on the economic well-being of a farmer has the potential to help in creating a better understanding of why farmers adapt to climate variability. <br","Small-holder farmers; Climate adaptive capacity; Socio-hydrological model; Ethiopia","en","master thesis","","","","","","","","","","","","","","11.768623, 37.787051"
"uuid:b25f5133-7710-4a2c-abd8-3e4a5d929a97","http://resolver.tudelft.nl/uuid:b25f5133-7710-4a2c-abd8-3e4a5d929a97","Industry4.0 Technology Battles in Manufacturing Operations Management: Non-technical dominance factors for IIoT &amp; MES","de Vries, Aksel (TU Delft Technology, Policy and Management)","Janssen, M.F.W.H.A. (mentor); Delft University of Technology (degree granting institution)","2021","With the Fourth Industrial Revolution, new industrial automation technologies (Industrial IoT) may replace the existing standard (MES). Most literature analyses software vendor techno-functional design, or manufacturer‚Äôs digital transformation. This paper takes a novel approach, by analysing the Business Eco-System with a lens of 11 nontechnical dominance factors. Evolutionary Economics and Economics Networks models are employed, such as Platform Wars, Technology Battles and Hughes‚Äô Large Technical System. Can existing vendors adopt the new technologies, or will market entrants gain market dominance? How can manufacturers respond to the market uncertainty? A lot is at stake; will Europe be able to re-industrialise, and re-shore millions of jobs lost to Asia?","Technology Battle; Platform War; MOM; MES; IIoT; Industry 4.0; Factory of the Future; ISA-95; RAMI4.0; B2MML; MAAS; Manufacturing as a Service; System Builder; Collaborative Supply Chain; Smart; Creation of Meaning","en","master thesis","","","","","","","","2021-03-31","","","","Management of Technology (MoT)","",""
"uuid:398f8607-ea58-4a81-8e2a-4646fc69659d","http://resolver.tudelft.nl/uuid:398f8607-ea58-4a81-8e2a-4646fc69659d","A civic building as urban stage for public life and democracy: An investigation of the city of Brussels, the public realm and its citizens","Br√∂ckel, Marion (TU Delft Architecture and the Built Environment)","De Vocht, S. (mentor); Rosbottom, D.J. (graduation committee); Parravicini, M. (graduation committee); Delft University of Technology (degree granting institution)","2021","Research__Brussels as an urban stage of differences__Activism I Activation__Political Space My work is an investigation of the city of Brussels, of public space and its citizens. The results of the analysis of the city of Brussels show above all the diversity of the city. The city can be seen as a fragmented, heterogeneous and superimposed space of differences, complexity and problems, but also as an opportunity and place of appropriation. The city is therefore the subject of attention and observation. By using the method of making a section through the city, it can be seen that the east-west connection through the city brings together politically important institutions, cultural facilities and public spaces, but is separated by certain obstacles (boundary), such as streets, topography or the canal. These different demonstrations of power can be seen throughout the city; from the ornamental town hall on the Grand Place to the transparent monoliths of the European Quarter, these buildings are theatrical yet tired and seem to actively distance themselves from their citizens. However, it has become clear that public spaces in the city centre extend around the chosen site (pedestrian zone - ground floor). I would like to link these public spaces further and consolidate them as a place of expression for the citizens. Instead of taking public space, I would like to give the citizens space to participate in political and democratic events. It is clear in Brussels that the willingness of citizens to participate is high and that they articulate this. The possibility of gathering in public spaces reveals to citizens a sense of power through the crowd. There is an awareness of power within the amount of people.‚ÄòLike a Greek agora, the city must reassert its most ancient function as a place where people come together face-to-face.‚Äô City: Rediscovering the Center by William H. Whyte (Author), Paco Underhill (Foreword); University of Pennsylvania Press; Reissue edition (September 22, 2009)But what is a political space and how does it express itself? Can we find this political space in everyday life? In my work I take the stairs as a political space. It is not so much the polarity of start and end that is recorded in this difference in level, but rather the tension between rise and fall, light and shadow, gravity and levitation, mind and body. The stairs are a primary motif of social interaction. A space that is constantly in motion due to the purpose of movement. This political space is especially intended to address the idea of being in between._Concept and Design__Site &amp; ProgrammeThe location is in the city centre. In the past, it was also occupied by an architecture that was intended to serve the population. However, as a public institution: market, event location and parking garage. The starting point of the project is the new centre of the city administration, the so-called BRUCITY, where the Brussels city administration is centralised. It is a project under construction. I see the resulting building as a provocation to investigate the nature of civic architecture in relation to public space and democracy. I set myself the task of designing a building that occupies less public space and thus creates a place to meet and pause in front of the building. The building will be the workplace for civil servants and at the same time the interface between them and the citizens of the city. The above ground floors will serve as workplaces for different departments of the city administration. The underground floors will house the municipal archives and the Council Chamber. While the meetings are often closed to the general public, the Council will be visible to the citizens from the street. The building will be accessible from different directions, and will initially lead everyone through a public space. There you will have the possibility to get orientation, information and if necessary to register. A public staircase with different framed views of the city and into the building will guide the person or group of persons through the building. On the top floor, the citizens will be offered a room with different and individual possibilities of use, as well as for meetings and events. It leads to a belvedere and opens up a clear view over the city. The citizen stands on the roof and sees the own city surrounding oneself.The new urban configuration will be a place of connection between people, but also of political and cultural exchange. Not only can we make demands on democracy, we must allow ourselves to be demanded.","Brussels; City Hall; Democracy","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Interiors Buildings Cities","",""
"uuid:08c50a62-9110-43c3-a623-0d5e2209d604","http://resolver.tudelft.nl/uuid:08c50a62-9110-43c3-a623-0d5e2209d604","Constrained Single-Error-Detecting codes for DNA-based Storage Systems","Vermeer, Hennes (TU Delft Electrical Engineering, Mathematics and Computer Science)","Weber, J.H. (mentor); de Groot, J.A.M. (graduation committee); Delft University of Technology (degree granting institution)","2021","The amount of data being produced is growing exponentially. An im-<br/>portant challenge is to find methods to store this data efficiently and in an<br/>environmentally friendly way. One idea that is a growing research topic in-<br/>volves using synthetic DNA. DNA has the potential to be more efficient and<br/>environmentally friendly than current methods. DNA is made of a sequence of<br/>four nucleotides, Adenine (A), Cytosince (C), Guanine (G), and Thymine (T).<br/>To store data, DNA strands can be created with specic nucleotide sequences.<br/>In the process of reading and storing data substitution errors can occur. Two<br/>constraints are introduced to minimise the number of errors. The GC-weight<br/>constraint which states that every DNA sequence must have a fixed number<br/>of G and C nucleotides, and the runlength constraint, which states the maxi-<br/>mum number of repeating nucleotides possible in every DNA sequence.","","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:e3b8dac2-600a-463d-a93e-0e503eb31d06","http://resolver.tudelft.nl/uuid:e3b8dac2-600a-463d-a93e-0e503eb31d06","Wall-Resolved Large Eddy Simulation of a Wing-Body Junction: High-Fidelity Data Generation for Data-Driven Turbulence Modelling","Alberts, Jasper (TU Delft Aerospace Engineering)","Dwight, R.P. (mentor); Delft University of Technology (degree granting institution)","2021","A wall-resolved Large Eddy Simulation (LES) of a wing-body junction is performed. The aim is to generate high-fidelity junction flow data to be used in a data-driven turbulence modelling approach, specifically to improve the accuracy of RANS-simulations in junction flows. The simulation is performed on a 61.5 million C-grid body fitted mesh in the pimpleFoam solver of OpenFOAM, with a turbulent channel flow precursor providing the unsteady inlet boundary condition. Analysis of the wall-resolved LES shows that the simulation accurately captures the complex flow phenomena in the wing-body junction flow including intermittency for the present inflow condition. Comparisons of the wall-resolved LES with a coarse-grid RANS simulation and the wall-modelled LES of Srikumar [2019] show that the wall-resolved LES in the present study is an improvement over the other two numerical methods. Most notably, an improvement in terms of the prediction of the location and magnitude of the mean spanwise vorticity and the mean turbulent kinetic energy of the horseshoe vortex systems was observed. Especially the RANS-simulation was unable to accurately capture the complex flow physics in the junction due to the limitations of RANS-methods, which are unable to accurately capture Reynolds stress anisotropy due to the Boussinesq hypothesis. An analysis of the high-fidelity junction flow data was performed to indicate regions where the Boussinesq hypothesis breaks down. The most notable region where the Boussinesq hypothesis was found to be not valid, was the region in close proximity to the wing-body junction upstream of the wing. Due to the breakdown of the Boussinesq hypothesis in the junction region, significant improvements of the accuracy of junction flow RANS-simulations can potentially be achieved by using the high-fidelity data from the present study in a data-driven turbulence modelling approach.","LES; Junction flow; CFD","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:af8d2840-f4c0-402c-ab91-08f1cffa55b6","http://resolver.tudelft.nl/uuid:af8d2840-f4c0-402c-ab91-08f1cffa55b6","Systems Navigator - Dropboard - Advanced predictive planning","Klop, Pepijn (TU Delft Electrical Engineering, Mathematics and Computer Science); Shah, Mozafar (TU Delft Electrical Engineering, Mathematics and Computer Science); Sitaram, Ashwin (TU Delft Electrical Engineering, Mathematics and Computer Science)","Spaan, M.T.J. (graduation committee); Delft University of Technology (degree granting institution)","2021","During this project, we have explored the possibilities for an algorithm that can schedule multiple visits taking into consideration constraints and KPIs. The solution we came up with has been integrated into Dropboard and is ready to be used in production by Dropboard‚Äôs clients. Our algorithm takes as input the visits to be scheduled. It then sorts these visits based on heuristics and schedules each visit in this order on its best location, using the single visit/ single resource allocation algorithm that was already present in Dropboard. Multiple plans are generated and post schedule optimised to possibly improve their rating. These plans are shown to the user with their rating in each KPI, and the user can select them to view them on the chart. Finally, a user is able to select a plan and persist it into the operational plan.","Multi job scheduling; Advanced predictive planning","en","bachelor thesis","","","","","","","","","","","","","",""
"uuid:eeea93ef-3a6b-4595-83d3-370a4abf75b3","http://resolver.tudelft.nl/uuid:eeea93ef-3a6b-4595-83d3-370a4abf75b3","State estimation and validation of currents using Delft GNSS single-frequency precise point positioning algorithm: With emphasis on the variance model","Oudejans, Erik (TU Delft Civil Engineering and Geosciences)","Tiberius, C.C.J.M. (mentor); Hanssen, R.F. (mentor); de Schipper, M.A. (graduation committee); Delft University of Technology (degree granting institution)","2021","The Delft real-time GNSS single-frequency precise point positioning (RT-SF-PPP) algorithm is extended to include velocity and receiver clock drift as unknown states to be estimated from Global Navigation Satellite Systems (GNSS) measurements. Carrier-phase ambiguities are assumed constant over time. Two different variance models are used, one obtains variance as a function of satellite elevation, and the other obtains variance as a function of carrier-to-noise density ratio as estimated by the receiver. The elevation based variance model was used in the original RT-SF-PPP algorithm, and adapted to include Doppler measurements. The carrier-to-noise density ratio based variance model components are estimated from double difference (DD) observation combinations using measurements obtained from a shortbaseline experiment with two receivers setup over multiple days. Two velocity observables are used and related to velocity and clock drift through the extended functional model of the original algorithm: the receiver generated Doppler and a time-derivative of the carrier-phase observable: the time-differenced carrier-phase (TDCP). Algorithmic performance is evaluated by the horizontal RMSE, which represents accuracy as the variance plus bias squared, precision and reliability. This was validated using three different experiments: a stationary receiver on top of a roof, a buoy freely adrift in the North Sea, and a receiver mounted on a car driving a regional road. It was found that in terms of position in the static experiment and under calm water conditions during the drifting buoy experiment the horizontal RMSE was between 0.429 and 0.530 [m], and under rough water conditions and a road partly flanked by fences and trees between 0.682 and 0.812 [m]. Furthermore in terms of velocity it was found that the TDCP observable in combination with the carrier-to-noise density based variance model has a horizontal RMSE between 0.014 and 0.068 [m/s] over all experiments, and using the Doppler observable with either variance model a RMSE between 0.033 and 0.122 [m/s]. The algorithm was even found by means of external reliability to be capable of detecting faults at the boundary of 0.5 [m] for position and 0.1 [m/s] for velocity in the TDCP observable case.","GNSS; PPP; Velocity estimation; Drifter; Buoy; Currents; Geodesy","en","master thesis","","","","","","","","","","","","","","52.10799121631562, 4.253567236008856"
"uuid:962e722a-7ac4-4bee-ba41-1bd15fa0b3f8","http://resolver.tudelft.nl/uuid:962e722a-7ac4-4bee-ba41-1bd15fa0b3f8","Investigation of the onset of chaos in an ergodic cavity","Looman, Freek (TU Delft Applied Sciences; TU Delft Electrical Engineering, Mathematics and Computer Science)","Dubbeldam, J.L.A. (mentor); Kuipers, L. (mentor); Delft University of Technology (degree granting institution)","2021","The behavior of light is well understood and well documented in many different scenarios. Nonetheless the situations can get more complicated. We can easily calculate the electromagnetic field confined to a cubic volume by solving the wave equations. However, this is not so easy for arbitrary geometries of the boundary. The wave equation most likely does not have well defined Eigenmodes for arbitrary shape of the boundary and conditions on this boundary. This complex situation can give a chaotic field. In this bachelor thesis we are going to investigate this situation for a 2-dimensional cavity in the shape of a quarter stadium, in which light can move freely and is reflected on the boundaries. The shape of our cavity is expected to result in a really chaotic field, whose properties will be studied in detail below. We will introduce ergodicity and compare the behaviors of a chaotic and non-chaotic cavity using ergodic properties and looking at the divergence of two neighboring trajectories. Furthermore we will look at the onset of chaos in the wave field inside the cavity and suggest a test to determine if a field is completely chaotic.","Ergodic; Chaos; Ray tracing; Cavity","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics | Applied Physics","",""
"uuid:661ddb37-f84c-404e-b471-cdf925297fd7","http://resolver.tudelft.nl/uuid:661ddb37-f84c-404e-b471-cdf925297fd7","Transonic Dimples: An experimental study of the flow structures formed at transonic speeds over dimpled surfaces","Claro Dittrich, Eric (TU Delft Aerospace Engineering)","van Oudheusden, B.W. (mentor); Schrijer, F.F.J. (graduation committee); van Campenhout, O.W.G. (graduation committee); Delft University of Technology (degree granting institution)","2021","Dimples are shallow surface indentations that have been recently considered as a passive viscous drag reducing technique for turbulent boundary layers. Studies so far were limited to incompressible low-Re flows and display little consensus on whether dimples can actually produce net improvements in total drag. Conversely, dimple geometry can be regarded as the inverse of transonic bumps, a matured wave drag reduction. In light of this, this thesis sets off to analyse the flow structures that arise over dimples at transonic speeds provide, serving as an initial assessment of their wave drag reducing potential.<br/> <br/>A transonic flow was reproduced experimentally using an asymmetric nozzle. Then, the performance of five dimple designs was evaluated against the criteria adopted for transonic bumps. Measurements included Schlieren, surface pressure and PIV. Results reveal that small spherical dents seem to produce spanwise excitations that subdue the detrimental effects of expansion fans formed at their edges, and ultimately allow for a higher momentum retention across the interaction.","wave drag; shock wave; dimples; drag reduction; transonic flow","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:0191762e-fed2-467e-9038-858c96dcefc4","http://resolver.tudelft.nl/uuid:0191762e-fed2-467e-9038-858c96dcefc4","Population Step Forward Encoding Algorithm: Improving the signal encoding accuracy and efficiency of spike encoding algorithms","de Gelder, Luuk (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Leuken, T.G.R.M. (mentor); Zjajo, Amir (graduation committee); Delft University of Technology (degree granting institution)","2021","Conversion from digital information to spike trains is needed for Spiking Neural Networks. Moreover, it is one of the most important steps for Spiking Neural Networks. This conversion could lead to much information loss depending on which encoding algorithm is used. Another major problem that can occur in a specific use-case is the limited bandwidth for the spikes that get generated through the encoding algorithm. In this thesis, we propose population Step Forward Encoding algorithm. This algorithm takes the signal encoding accuracy of Step Forward encoding algorithm and makes it into a population, generating multiple spike trains. This allows a higher threshold to encode a large part of the signal, increasing the efficiency. We show that population Step Forward Encoding algorithm doesn't just work good for the signal encoding accuracy, but also for the classification accuracy. Moreover, population Step Forward Encoding algorithm does not only have a high efficiency with a low spike count, it can also achieve higher efficiency with higher spike count. Thus, population Step Forward can make most use of a limited bandwidth of spikes.","Spiking Neural Networks(SNNs)); Spiking Neural Networks; spiking neural networks; Encoding Algorithms; Temporal Encoding Algorithms; temporal data; Encoding; Algorithm; Algorithm Configuration; Population Step Forward Encoding","en","master thesis","","","","","","","","2023-02-08","","","","Electrical Engineering | Circuits and Systems","",""
"uuid:e817096e-16e7-4cb0-9a80-891acce42217","http://resolver.tudelft.nl/uuid:e817096e-16e7-4cb0-9a80-891acce42217","Modelling participatory modelling","Peters, Nourian (TU Delft Applied Sciences; TU Delft Technology, Policy and Management)","Nikolic, I. (mentor); van der Sanden, M.C.A. (mentor); Wehrmann, C. (graduation committee); de Vries, G. (graduation committee); Delft University of Technology (degree granting institution)","2021","To deal with increasing complexity and connectivity of socio-technical systems it becomes unlikely for individuals to be able to oversee all possible changes. These systems are riddled with a plurality of actors with differing interests, disciplines, institutions and ecological limitations. Examples of systems like these are energy and gas grids. If one wants to tackle problems on these systems one would ideally understand possible results of changing things in these systems as a change in one part of the system can lead to results in other subsystems. If a tree falls down on an energy pole, for example, chemical plants can stop functioning. This in turn can cause orders to be late, influencing a whole production chain.<br/>To this end one would ideally one would ideally apply systems thinking: ‚ÄùSystems thinking is a set of synergistic analytic skills used to improve the capability of identifying and understanding systems, predicting their behaviors, and devising modifications to them in order to produce desired effects. These skills work together as a system.‚Äù<br/>However, because the earlier pluralities it unlikely for a single individual or organisation to have all the required information for this. Processes are required where information is collected and co-created with multiple parties in such as system to enable the creation of comprehensive solutions for these problems. What is required is social learning. Social learning (SL)is learning that happens by people participating in so called communities of practice. A community of practice can be seen as a group of people with converging interests and skills. An example would be a grid operator, which have their own sub-communities (E.G. cable technician or systems manager). They can be smaller groups, E.G. a family, and participation is often not mutually exclusive. Rather than being part of a community of practice one could be seen as being part of the landscape of practice, consisting out of multiple communities. By partaking in these communities people gain experiences by both learning and expanding on a communities‚Äô knowledge.<br/>The aim of this thesis is to gain insights into:¬†1. mechanics shaping and steering social learning¬†2. how to measure social learning processes for in vivo experimentation¬†3. design mechanics for participatory modelling processes and Social learning in general to improve development of such processes¬†<br/>To do this a theory has been made on the mechanics and behaviour of individuals in a SL process. This has been done in chapters 4, 5 and 6. To do this a PM perspective has been used as this give a structure on the actions someone can take and requires shared information to be structured. Additionally it is seen as a useful tool for tackling socio-technical problems.<br/>The theory thus focussed on the main action of PM, namely sending information, receiving and processing information and deciding upon the model. To develop the theory knowledge from multiple disciplines is needed. To this end a theory has been developed using supersynthesis. This is a research method where multiple theories are combined to make a new on to explain something. The aim is not to supersed the combined theories, but to explain something new. The fields that have been the focus are communication science, helping understand how information is processed and sent, and social psychology, helping understand why and when individuals take certain actions. The theories have been synthesised in two rounds of conceptualisation, with the first focussing on conceptualising every possible action and mechanic. The ones that were deemed most interesting or useful have been conceptualised more in depth. To this an additional conceptualisation of knowledge and information is made. The final theory is as follows:<br/>Knowledge takes the shape of a knowledge graph. In this graph fields of expertise are called topics. One can think about the weather as such a topic. These topics consist out of information items, think cloudiness or temperature, and links between these items indicating their relation, think cloudiness leads to lower temperatures. These items may have links to items from other topics. For example cloudiness is related to sun hours and yields of Photovoltaics from th topic of Photovoltaics.<br/>It is assumed that a complete knowledge graph exists. Each individual knows part of this graph, signifying knowledge or expertise in the topic. The larger part of a topic they know the more expertise they have in that topic. This includes both information items as their links (relationships). All these items, links and topics also have a perceived relevance for people. This is based on interests or affiliation. Affiliation means relationship with a group of people, for example, meteorologists. Something is also seen as more relevant if it is discussed often, attributed to common knowledge effects. In a social learning process there are several individuals. Each round they are able to share information. Information is seen as information items and/or their links. A topic as a whole can also be discussed, but this is not seen as actual information for learning. What they share is based on the amount of energy they have and are willing to spend on sharing information. This is dependent on perceived relevance of the item they are considering to share, their expertise on the related topic and their tiredness. It is assumed that the energy one has decays over rounds.<br/>Shared energy is received by others and they start to process it. Here something is integrated or learned if they are able or willing to invest enough energy in the processing. This is dependent on their expertise of the related topic, their perceived relevance of what is shared and their attitude with regards to the sender. If expertise, relevance and attitudes are high enough someone will process and integrate information. Processing energy is also assumed to decay each round.<br/>In addition to information on knowledge, individuals can also share relational information. These are details like hobbies and other personal details. These are processed as either positive or negative and influence attitudes.<br/>Processing of shared information may also happen during breaks or downtime. Here one has more energy to spend and attitudes are less relevant. Total recall of information is assumed in the whole model (I.E. people do not forget anything).<br/>To allow for further reflection on the theory and to act as a proof of concept of the theory the theory has been translated into an agent based simulation model. This model has been analysed in a sensitivity experiment using LHS and extremely randomised forest in addition to a variety of plotting techniques in R.¬†<br/>Additionally two experiments are designed, inspired by real cases. These are used to reflect on the theory and find less noticeable quirks from the ABM.¬†<br/>Based on the theory and ABM the following things have been concluded: ¬†-While communication science theories and social psychology theories have been used for theory development, they are not a be all end all. One can apply other fields if one wants. This specific combination, however works especially well for an individual perspective.-The theory can be used to reflect on SL by practitioners as it tells why and how people can act. Furthermore the idea of the knowledge graph can be¬†connected to landscapes of practice, with topics relating to a community and links between items of these topics to those of other relating places where boundaries interact -Matters like conflict and increasing conflict, coalitions, personal inhibitions and norms are some of the values that would make sense to include in the theory. This would make the theory less usable for simulation modelling, however and would add a lot of behaviour that is not directly related to the learning process. To implement these additional behaviour could be conceptualised and added, making the theory more complete but less comprehensive. The most important addition that could be made according to me would be an extension on the actions influencing attitudes and the actual definition of a process result (a participatory built model or a plan). -This new theory is valuable as this individual based perspective has not been taken before, inviting to reflection on practice.-The knowledge graph could be used as a means for building new theories that are comparable. Additionally it is a way to explicitly learning. -The combination between social learning and Participatory modelling has not been made this explicit before. It would allow participatory modellers to reflect on their practice.-The ideas of energy for sharing and processing are quite influential in the ABM. They are interesting as they give clear reasons why learning may not happen or happen suboptimally. For learning to happen information need to be shared. If people lack the energy or the willingness to spend energy sharing will not happen. If they do not have the energy to process this they will also fail to learn. This highlights the need for keeping energy levels in mind when designing these processes. It is assumed that these energy levels decay linearly. While arguably too simplistic still it does show how intensive processes or boring processes can fail.<br/>The following design mechanics are proposed:1. Usage of a knowledge graph to keep track of what is learned by researchers¬†2. Usage of knowledge graph to steer the process order that makes learning more likely (topics that closely relate to all participants first and expand that towards specific participants later down the line).¬†3. Use set structures, conceptual modelling, drawings and other tools to make information sharing and processing easier and less intensive. This would make the process spend less energy if the used tools are chosen well (I.E. a conceptual drawing of what is said or what someone wants to explain using causal diagramming is probably better to explain ideas than doing so via live programming of a simulation model).¬†4. Use actions like summarizing what has been said to slow down the process if it becomes to quick, leading to a processing energy deficit.¬†5. Use means like using an agenda to ensure the speed of the process does not become to slow, leading to boredom and potential energy decays","Social learning; Agent based modelling; Social psychology; Participatory Modelling; communication science; Systems thinking","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:578a26af-1b80-44a2-b7f2-543f57521280","http://resolver.tudelft.nl/uuid:578a26af-1b80-44a2-b7f2-543f57521280","Exploring the Effect of Model Assumptions on Prediction Performance of Bayesian Networks","Goslings, Wessel (TU Delft Electrical Engineering, Mathematics and Computer Science)","Nane, G.F. (mentor); Delft University of Technology (degree granting institution)","2021","This thesis concerns itself with the effect of the normality assumption, the effects of discretisation choices and other assumptions made by software on prediction performance, when using Gaussian Bayesian Networks. To test these effects, different types of Bayesian Networks are constructed and made to perform predictions, using the same dataset. The dataset used contains records regarding the citations and other bibliometric statistics of articles published by authors aliated with the Delft University of Technology between 2010 and 2014. The first model is a Gaussian Bayesian Network (GBN), which assumes that the conditional probability distributions (CPD) of all variables concerned are Gaussian. The second model is a Multinomial Bayesian Network (MBN), which uses discrete variables. To accommodate to this model, the data is discretized. The third model is the Hybrid Bayesian Network (HBN, which can handle both discrete and continuous data and has no normality assumption on the distribution of the variables. The last model is a non-parametric Bayesian Network (NPBN). To compare the different models, they are used to perform a set of predictions in the form of quantile estimation. The results show that the GBN performs as well as the NPBN, when looking at the bulk of the data. When looking at data, where the mean citation score (mcs), the predicted variable, exceeds the 75-% quantile, the performance of the GBN becomes much worse than that of the NPBN.","Bayesian Network; Structure learning; Citation; Normality Assumption","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:45d174b0-af4b-4154-b4b0-7250e5d668c2","http://resolver.tudelft.nl/uuid:45d174b0-af4b-4154-b4b0-7250e5d668c2","A Metamodelling Approach to Reliability Updating with Dike Construction Survival","Kentrop, Dani√´l (TU Delft Civil Engineering and Geosciences)","van der Krogt, M.G. (mentor); van den Eijnden, A.P. (graduation committee); Kok, M. (graduation committee); Delft University of Technology (degree granting institution)","2021","The construction of a dike improvement often causes a decrease in reliability during construction. Raising a dike may give rise to excess pore water pressures in the subsoil, resulting in a temporal strength decrease. Observing the survival of such a loading condition might provide information on the strength of a dike. Therefore, this research investigates the effect of incorporating construction survival in estimating the slope reliability of dikes. Assessing slope reliability can be done by means of simulation. However, due to the high reliability of dikes, many realizations and thus model evaluations may be needed to achieve sufficient accuracy, leading to infeasible computation times. In this research, a method is developed for reliability updating using metamodelling, providing reasonable computation times while not losing accuracy. The effect of incorporating construction survival is explored by updating the inward slope reliability of a case study dike improvement. The case study shows that the current semi-probabilistic approach to assessing construction stability in practice leads to situations not effective for reliability updating. Though adjusting the construction phasing may lead to a significant update. It is shown that adapting the dike improvement design after survival of the critical construction step results in a 75% reduction of the dimensions of the berm to be constructed, while achieving the same reliability as prior to the update. The main finding of this research is that incorporating construction survival in the reliability assessment can be very effective in terms of reliability, and in making dike improvements more efficient and less space consuming.","reliability updating; metamodelling; slope stability; past performance; construction survival; surrogate modelling","en","master thesis","","","","","","","","","","","","","",""
"uuid:55cdb0d6-ad39-49e3-8ff9-e6986c9ee20d","http://resolver.tudelft.nl/uuid:55cdb0d6-ad39-49e3-8ff9-e6986c9ee20d","The Wood Knowledge Centre: A knowledge centre for education and practice in wood and woodworking craft.","Smit, Thijn (TU Delft Architecture and the Built Environment)","Stuhlmacher, M.E. (mentor); Warries, G.Y. (mentor); Reinders, L.G.A.J. (mentor); Delft University of Technology (degree granting institution)","2021","The Netherlands is building to little in wood and relies way too much on high-emission materials, such as concrete. The building culture is changing, but way to gradual. In response to the scarcity of resources, nitrogen crisis, climate change and the housing crisis, the Netherlands has to turn more to biobased materials, foremost wood, as a resource, in particularly for construction. <br/>There are to many outdated prejudices, to name one fire safety issues, which technology solves. In order to achieve the required change, the knowledge of wood and the crafts related to woodworking should be given more awareness and education has to be improved and intensified. In response, a centre for woodworking is proposed, where education and practice takes place on a daily basis and visitors are welcome to explore the world of wood and woodworking.","Wood; Woodworking; Rotterdam; Knowledge Centre; Zoho; Craft school; Crafts","en","master thesis","","","","","","","","","","","","","Craft in the City",""
"uuid:89cab481-ecf8-4cb7-a0f0-70b9a7ab0e39","http://resolver.tudelft.nl/uuid:89cab481-ecf8-4cb7-a0f0-70b9a7ab0e39","Universal Charger for Shared E-Bikes: Design of a universal wireless charging solution for integration in publicly shared e-bike systems","Verwijmeren, Teun (TU Delft Industrial Design Engineering; TILER Charge)","Crone, H.E.C. (mentor); Vink, P. (graduation committee); van Nispen, C. (graduation committee); Delft University of Technology (degree granting institution)","2021","The market for shared mobility has seen massive growths in recent years. Pollution and congestion requires us to rethink how we move around and new technologies make sharing continuously easier and more convenient. Society is slowly moving towards a mindset that values access over ownership, and this is also the case for (urban) mobility. Research has shown that convenience is the most important factor for people to engage in shared mobility and the rising demand leads to all kinds of light electric vehicles popping up in our streets. Especially e-bikes gain market quickly, both in the form of publicly shared vehicles as well as within corporate fleets. But with operating shared mobility programs also come challenges, and keeping all those vehicles charged is definitely a major one. Free-floating vehicles are often charged by manually swapping its batteries, while dock-based schemes rely on its users connecting the charger after use of the service. Docking stations for e-bikes exist that combine locking the bike in a physical dock with charging its batteries, but they are often expensive, take up a lot of valuable (public) space and are bike-specific. Next to that, contacts suffer from breaking, mechanical wear and corrosion. The start-up TILER is currently developing a universal wireless charging solution for e-bikes, however the physical form of a charging tile with an accommodating kickstand is not considered as the ideal physical form to apply wireless charging to shared vehicles. Therefore, a graduation project was set up to explore alternative solutions and design a universal and convenient charger for shared electric bicycles. The result of this project is the TILER Click, a product that makes charging an integral part of retrieving and returning shared e-bikes from their hub. The easy alignment in combination with a simple yet efficient clicking mechanism make the TILER Click so simple to connect and disconnect that it is no longer an effort to charge the bike. Placement of the receiver on the rear of the electric bicycle make the product extremely universal and versatile, regardless of bike geometry. The TILER Click offers a convenient, simple and reliable way of keeping e-bike fleets charged. With that, it not only enhances the experience of charging itself, but also has a positive impact on the user experience of the entire system. Being able to charge shared e-bikes in a uniform and simple way can play a crucial role in the future of (shared) mobility.","Shared Economy; Bike Sharing; E-bike; Wireless Power Transfer; Charging","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:ce869dba-cd32-471c-a88f-9b3c333a4e5c","http://resolver.tudelft.nl/uuid:ce869dba-cd32-471c-a88f-9b3c333a4e5c","Use of RFID at Nike: A study of Nike's RFID technology benefit analysis","Walaskar, Sukanya (TU Delft Technology, Policy and Management)","Ludema, M.W. (mentor); Pesch, U. (graduation committee); Tavasszy, Lorant (graduation committee); Lagrand, Eric (mentor); Brauckmiller, Ken (graduation committee); Delft University of Technology (degree granting institution)","2021","This report presents an analysis of a new technology integration, namely Radio Frequency Identification technology (RFID) within Nike‚Äôs supply chain processes. This analysis considers a metrics relevant to operational efficiency in terms of costs savings, reduction in labour hours and increase in revenue through sales. These metrics are benchmarked using cross sectoral data from other retail stores such as Macy and analytics obtained from Accenture. Once identified, similar parameters are estimated for Nike internal operations building on the company‚Äôs own pilot test run data. The mathematical calculation showed that using RFID technology will reduce the labour costs associated to inventory counting by 75\% and the sales generated through revenue will increase by almost 4\%. The increase in sales is compared using three different strategies. According to the research, for the complete integration of RFID technology at Nike, it might take three or more/fewer years. But this research empirically provides three different penetration strategies showing that Nike will benefit with the use of RFID technology.","","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:da4a8d74-32fa-45f1-9f92-d01d45fdea01","http://resolver.tudelft.nl/uuid:da4a8d74-32fa-45f1-9f92-d01d45fdea01","Cockpit Design and Integration into the Flying V","van der Pluijm, Ricardo (TU Delft Aerospace Engineering)","Vos, R. (mentor); Delft University of Technology (degree granting institution)","2021","The Flying V is an innovative new aircraft concept currently being developed by the faculty of Aerospace Engineering at Delft University of Technology. This aircraft is a flying wing having a large sweep on the inner section, and a small sweep angle at the outer, giving the aircraft its characteristic V shape. The objective of this research is to create a parameterisation of the cockpit and aft center fairing for the Flying V that includes an integration of pilot anthropometry, satisfies visibility certification constraints, ensures positioning of nose landing gear and radar, while providing a high probability of good aerodynamic performance and being able to be used in an aerodynamic design optimisation. To accomplish this, a geometric parameterisation of the cockpit model is made by means of defining a rail on which cross-sectional profiles are placed. A loft through the profiles creates the outer mold line of the cockpit. Constraints were imposed on the cockpit model by pilot anthropometry, the required view angles at the pilot design eye point and by the presence of the radar and nose landing gear. Additionally, a center fairing is defined to reduce the root effect caused by the high sweep angle of the aircraft. Finally, the geometrical model is coupled to an aerodynamic solver to assess its performance and to make future aerodynamic optimisation possible. Demonstration of the model has shown that a cockpit design for the Flying V is possible at a 0.8% reduction of the aircraft lift to drag ratio while satisfying all constraints. Furthermore, the center fairing has shown to increase lift at the root by 13.5%, resulting in an increase of 0.94% in the aircraft lift to drag ratio. Lastly, the robustness of the cockpit and center fairing geometric models was found to be up to 20.3% and 39.9% respectively, where the former can be increased to 50.4% if a lower tolerance on the geometric model is chosen.","Flying V; cockpit; fairing; model; parameterisation; design; cockpit design; integration; anthropometry; overnose angle; pilot compartment view; constraints; root effect; aerodynamics; semi-empirical methods; robustness; Parapy; SU2; nose landing gear","en","master thesis","","","","","","","","","","","","Aerospace Engineering | Flight Performance and Propulsion","Flying V",""
"uuid:ac19345f-0f16-466e-8e80-4b6f16acbe6b","http://resolver.tudelft.nl/uuid:ac19345f-0f16-466e-8e80-4b6f16acbe6b","The debugger as a learning tool for object-oriented programming","Visser, John (TU Delft Electrical Engineering, Mathematics and Computer Science)","Zaidman, A.E. (mentor); Delft University of Technology (degree granting institution)","2021","Novice students still have problems with the abstraction of object-oriented programming. This research shows that the debugger could be used to clarify abstraction of the object-oriented programming with the C++ program language. Our investigation spans two consecutive courses on object-oriented programming. For the introduction course on the object-oriented programming, we modified both lectures and lab sessions so that with the help of the debugger objects could be visualised, and we could walk through the program step by step. In the second course, the lectures were extended by forty-five minutes, allowing the students to do assignments during the lectures with the help of the debugger. The results of the written examination and the completed questionnaire showed that working with the debugger in both the lectures and the practical exercises had a positive influence, especially for the introductory course on object-oriented programming. Although the Corona pandemic influenced part two, the results of the written exam did improve, but it is unclear which influence the use of the debugger had during this course. Visualising objects and walking through methods step by step could help in understanding the fundamentals of object-oriented programming language C++.","debugger; Object-Oriented Programming; education","en","master thesis","","","","","","","","","","","","Computer Science","","52.0017011, 4.3678927"
"uuid:559282f4-5343-4993-b18c-a1fbb6006b53","http://resolver.tudelft.nl/uuid:559282f4-5343-4993-b18c-a1fbb6006b53","Spatial disparities in operator performance and attractiveness of ride-pooling in Amsterdam","Mariƒçiƒá, Marko (TU Delft Civil Engineering and Geosciences)","Kucharski, R.M. (mentor); Cats, O. (mentor); Delft University of Technology (degree granting institution)","2021","Despite its potential benefits of reduced traffic congestion and discounted trips, incorporating ride-pooling in a city comes with a set of challenges that require thorough analysis, optimisation, and planning. Even though, services like \textit{Uber} have existed in Amsterdam for over a decade, city wide ride-pooling has yet to be implemented. This paper uses an algorithm for exact matching of attractive shared rides (ExMAS) and Albatross travel demand data to map and analyse the spatial disparities of key performance indicators of a ride-pooling service in Amsterdam and discover the potential of certain areas in the city. The experiments utilised a set of increasing discounted fares for ride-pooling with increasing travel demand levels. A ride-pooling service with higher discounted fares generally increased the attractiveness of the system and reduced the total vehicle hours, when compared to its non-shared counterpart. It was found that the largest vehicle hour reduction were in areas on the periphery of Amsterdam (namely the West, North, and East areas) where rides of higher degree and longer trips lengths were more likely. However, the user attractiveness of the system tended to be higher in central areas of the city where trip density was higher, trip length shorter, and ride degrees lower. The study also determined that variance of the vehicle hours and user attractiveness decreased and stabilised with increasing demand level. This paper could be a starting point in optimising the possible roll out schemes for a ride-pooling service in Amsterdam.","ride-sharing; ride-pooling; Amsterdam; performance; Spatial analysis","en","student report","","","","","","","","","","","","Civil Engineering | Transport and Planning","",""
"uuid:f8f87593-97aa-483e-a2c0-0b766f4286ba","http://resolver.tudelft.nl/uuid:f8f87593-97aa-483e-a2c0-0b766f4286ba","Effect of the surrounding on the construction cost of district heating networks and similar infrastructures: Analysis based on drinking water and natural gas replacement projects","Mieras, Jorn (TU Delft Electrical Engineering, Mathematics and Computer Science)","Pothof, I.W.M. (mentor); Heijnen, P.W. (graduation committee); van der Hoek, J.P. (graduation committee); Delft University of Technology (degree granting institution)","2021","","District heating; Construction costs; Linear Regression","en","master thesis","","","","","","","","","","","","","",""
"uuid:5bfd6486-bf23-42d1-89f4-e0fe41ebc286","http://resolver.tudelft.nl/uuid:5bfd6486-bf23-42d1-89f4-e0fe41ebc286","Deployable radiator wing for high performance CubeSats: Designing, analysing, prototyping and testing","van Lierop, Casper (TU Delft Aerospace Engineering)","Guo, J. (mentor); Grimminck, Mark (mentor); Delft University of Technology (degree granting institution)","2021","The goal was to provide a solution to the thermal problem of high-performing CubeSats. These CubeSat generate much heat due to a combination of increased power generation capabilities and miniaturisation. A deployable radiator is designed to solve this problem using HiPeR technology developed by Airbus Defence and Space Netherlands. This design is analysed, a prototype is produced and tested. The design is proposed after iteratively sizing the shape, dimensions, location of the interface and number of layers. The design is a T-shaped laminate of 12 sheets of PG, and a top and bottom protective sheet of Kapton adhered with 3M966. This shape allows for easy folding over the outside of a CubeSat to minimise volume while being compliant with the P-POD requirements. Some parts of the PG sheets are not adhered, allowing for local bending with a small bending radius. A tape spring hinge provides support and the actuation for deployment. The radiator allows for an efficient heat flow path between the payloads and space. This reduces the temperatures of the payloads and allows for CubeSats to continuously generate up to 30W of heat.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:d693df7f-f1c5-4db8-9324-0fc2ad9b2c50","http://resolver.tudelft.nl/uuid:d693df7f-f1c5-4db8-9324-0fc2ad9b2c50","Initial morphodynamic changes in the Voordelta in response to the Delta21 interventions","IJntema, Jelmer (TU Delft Civil Engineering and Geosciences)","Aarninkhof, S.G.J. (mentor); Luijendijk, A.P. (mentor); Voorendt, M.Z. (mentor); Onderwater, Martijn (mentor); Delft University of Technology (degree granting institution)","2021","In recent years, the awareness of climate change and sea level rise has grown. Especially in low lying countries like the Netherlands, with a large river delta with a high economical and natural value, extreme variations in water levels will have great impact. Former used solutions proofed to be expensive and in some cases disturbed the dynamics of nature. Consequently, the need of new solutions of flood protections grows in which the negative impact on nature environments should be limited. The Delta21 plan proposes a future-proof design for the Dutch Southwest delta, that aims to tackle the growing need for flood protection, while contributing to nature and storing energy all at once. However, the coastal structure, located in the Haringvliet mouth, is likely to produce large disturbances in the environment. Since the Haringvliet mouth is located in the 'Voordelta', a Natura2000 area, it is essential to study the initial response of the proposed interventions to the hydraulics and morphodynamics that shape the system. Hence, the objective of this research is to determine the initial impact of the Delta21 plan on the large scale multi-year average hydro- and morphodynamics of the Northern Voordelta. To this end, a literature review was performed to analyse the evolvement of the Northern Voordelta since the closure of the Grevelingen and Haringvliet estuaries by the Delta Works in 1970. This study showed that the closure caused the tidal prisms to reduce strongly resulting in the tidal propagation to change from cross¬≠shore to longshore. The remaining ebb tidal deltas started to follow the characteristics of a short basin, in which water levels offshore and nearshore are in phase. Flow velocities reduced strongly and channels started to fill up, at the foreshore waves started to dominate the morphodynamics. Waves began to 'bulldoze' the former ebb-tidal deltas onshore, creating shore parallel sandbars like the Bollen van de Ooster and the Hinderplaat. Besides, the construction of the Maasvlakte 2 triggered further sedimentation of the Haringvliet mouth, landward of the Hinderplaat, by sheltering the area from NW waves. The initial response of the system to Delta21 has been studied using a short-term morphostatic 2DH computational model simulation. The complexity of the processes inside the study area caused the need of the process based model Delft3D, in which flow, waves and sediment transport computations can be carried out. To reduce computational times, the applied modelling setup made use of reduction techniques and schematisations of the hydraulic forcing, while maintaining the natural character of the system. The computed flow and sediment transport patterns were used as indicators, in order to predict and compare the feedback of the system of the various scenarios. Model results showed that the tidal propagation inside the Haringvliet estuary, which is opened in the Delta21 scenario, changes to cross-shore again. Similar to the situation prior to the closing, the area will start to follow the characteristics of a long-basin. This implies that water levels in the estuary are out of phase with the offshore water levels. A cross-shore tide dominated flow prevails in the area, while the Grevelingen delta remains unchanged in the Delta21 scenario. The cross-shore action influences the offshore wave- and setup-driven residual currents. In the same offshore area, the Delta21 pump discharge develops a similar cross-shore acting influence area. Model results further showed that the Delta21 geometry causes a 'tidal squeeze', similar to the present-day processes around Maasvlakte 2. Altogether, the large disturbances to the hydrodynamic forcing, triggers morphodynamic activity. Concluding from literature and the model results, this leads to the erosion and formation of ebb and flood channels in the Haringvliet mouth and the formation of an ebb- and flood-tidal delta around the inlet. Processes in and around the ebb-tidal delta adjust towards a balance between the wave and tidal action. These findings agree with the known processes of a mixed-energy tidal inlet system that is adjusting towards a dynamic equilibrium. Conceptualised results are shown in Figure 1. Concluding, the analysis on the initial response of the system, as well as the expected initial dynamic behaviour, provides useful insight and a good basis for future optimisation studies on the Delta21 design. This study reveals the disturbed areas caused by the presence of Delta2 l and relates it to the contribution of the various hydrodynamic processes. Furthermore, the development of this type of study can be significantly relevant to the evaluation of other preliminary studies on solutions to sea level rise.","morphodynamic; Delft3D; Coastal Engineering; The Voordelta; DELTA21","en","master thesis","","","","","","","","","","","","Civil Engineering | Hydraulic Engineering","DELTA21",""
"uuid:54b01377-1f79-4758-b79b-4859df05dbd6","http://resolver.tudelft.nl/uuid:54b01377-1f79-4758-b79b-4859df05dbd6","Implementing the Decomposition of Soundness Proofs of Abstract Interpreters in Coq","de Waard, Jens (TU Delft Electrical Engineering, Mathematics and Computer Science)","Visser, E. (mentor); Gousios, G. (graduation committee); Krebbers, R.J. (graduation committee); Keidel, S. (graduation committee); Delft University of Technology (degree granting institution)","2021","Abstract interpretation is a way of approximating the semantics of a computer program, in which we derive properties of those programs without actually performing the necessary computations for running the program, through the use of an abstract interpreter. To be able to trust the result of the abstract interpretation, we would to able to prove the soundness of the approximations of the interpreter. Previous work by Keidel et al. has shown that the soundness proofs of an entire abstract interpreter can be simplified by decomposing the interpreter by implementing concrete and abstract interpreters as instantiations of a generic interpreter. The goal of this thesis is to explore and implement mechanical proofs of soundness of such interpreters. To this end, we have used the interactive proof assistant Coq to implement a generic interpeter for a simple imperative language and instantiate it both concrete and abstract versions. The abstract interpreter is automatically proven sound via the use of Coq's automatic proof capabilities and typeclass system. Both the interpreted language and the used abstractions can be expanded to allow for more features. Soundness proofs can then be written for just the new components, those proofs will then be automatically resolved by Coq.","Coq; Abstract interpretation; Proof assistant; soundness; Proof","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:ef5f2813-d5cf-4338-bea3-ecc0597b7d38","http://resolver.tudelft.nl/uuid:ef5f2813-d5cf-4338-bea3-ecc0597b7d38","Optimisation of Interior Permanent Magnet Generator in Propeller Type Tidal Turbines","Bindhu Sreevalsan, Devika (TU Delft Electrical Engineering, Mathematics and Computer Science)","Dong, J. (mentor); Bauer, P. (graduation committee); Lahaye, D.J.P. (graduation committee); Delft University of Technology (degree granting institution)","2021","Over the past few decades, there has been a steep increase in efforts to generate electricity from clean and renewable energy sources so as to reduce consumption of fossil fuels. A considerable amount of research is in progress to explore the scope of various sustainable power sourcesÕæ among which tidal energy is estimated to have a huge potential. With advancements in technology, it is predicted that electricity from tidal energy would increase in the coming years. It is necessary to have highly efficient generators that can convert tidal energy to electricity. Propeller type generation system using Permanent Magnet Synchronous Machines (PMSMs) are found to be suitable for the application of tidal generators. For the best utilisation of resources, it is essential to improve the performance of these machines in several aspects. And hence, multi-objective optimisation of electrical machines is emerging to be of high significance. The key goal of this thesis is to design, model and optimise a PMSM generator so as to get the desired power while considering other design objectives, including the efficiency, total volume of the machine and weight of magnets. The thesis is divided into two parts. The first part consists of design, modelling and analysis of the PMSM machine. Initially, all the required machine constraints are identified and a topology is selected. An analytical model is built after which the machine is modelled using the Finite Element Method (FEM). The model is analysed where various key characteristics of the machine such as flux linkages, induced EMF, inductance and torque are calculated. This is validated by ensuring that results from FEM model and analytical model match. In order to optimize the machineÕæ certain geometric parameters are varied to locate the dominant geometrical parameters. The second part of the machine consists of optimisation. A multi-objective Genetic Algorithm (GA) optimization is carried out to generate data to search for an optimal design. The three objectives for optimisation are higher efficiency, lower total volume and lesser weight of magnets. The analytical model is used in the optimisation algorithm. Since this is a multi-objective optimisation, a set of solutions (Pareto set) is generated from which a single solution is chosen. This selected solution is applied to the FEM model and thus finally an optimized model of the machine is developed. An analysis is carried out on the optimised model. Finally, the optimised model and the initial model are compared and the results are explained.","Optimisation; FEM modelling; modelling; Electrical machines","en","master thesis","","","","","","Master Thesis -M Sc. Electrical Power Engineering (Power Electronics and Electrical Machines)","","","","","","Electrical Engineering | Electrical Power Engineering","",""
"uuid:916dfc24-a2ac-45e7-aa6f-9e7509c5513d","http://resolver.tudelft.nl/uuid:916dfc24-a2ac-45e7-aa6f-9e7509c5513d","Improving Ergonomics in the Professional Kitchen: Introducing a New Method of Porcelain Heating","van Bussel, Maurice (TU Delft Industrial Design Engineering; TU Delft Design Aesthetics)","Ninaber Van Eijben, B. (mentor); Orsini, G.A. (graduation committee); Delft University of Technology (degree granting institution)","2021","This report presents the design process of the development of a new heating concept for the professional kitchen. The project is executed on behalf of the TUDelft and the kitchen manufacturer Qook!. Project Topic: Cooks in Michelin starred and fine dining restaurants cope with long working days under high pressure. Although there are many legislations and rules, on a certain culinary level the circumstances are tough and are accepted as part of the job. Working weeks of 70 to 80 hours and the constant pressure of performing better everyday requires a productive and ergonomic work environment. This design project aims to improve the physical and cognitive ergonomics, which simultaneously will improve the efficiency of the professional kitchen. Design Direction: Cooks in Michelin starred and fine dining restaurants cope with long working days under high pressure. Although there are many legislations and rules, on a certain culinary level the circumstances are tough and are accepted as part of the job. Working weeks of 70 to 80 hours and the constant pressure of performing better everyday requires a productive and ergonomic work environment. This design project aims to improve the physical and cognitive ergonomics, which simultaneously will improve the efficiency of the professional kitchen. Concept: A new heating method of ceramic dinnerware is developed. Combined with a special porcelain coating, conceived and manufactured by the German company Sch√∂nwald, a concept is developed that uses a field of induction coils to replace the current heating systems. It improves thermal comfort, manoeuvrability, visibility and the working posture. During the concept phase a prototype has been built as a proof-of-principle of the newly developed heating system. I conclude with a number of recommendations that can be used for the development of the concept toward a final product.","Ergonomics; Professional Kitchen; Porcelain Heating; Induction","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:a0f6dea3-e71c-48c7-9eb3-1ceb43e367ce","http://resolver.tudelft.nl/uuid:a0f6dea3-e71c-48c7-9eb3-1ceb43e367ce","A Propeller Analysis and Sizing Method in Takeoff Conditions","Heeres, Floris (TU Delft Aerospace Engineering)","Delft University of Technology (degree granting institution)","2021","Current preliminary aircraft design cycles use empirical relations to great the wing and power loading diagrams to size the aircraft and its engine. These empirical relations are based on historical aircraft data to relate the aircraft weight to engine power. To enhance the design capability for novel propeller aircraft types and increase the accuracy in general, a takeoff performance analysis and propeller sizing method is developed to create analytical and physics based takeoff and cruise constraints. The sizing method focusses on takeoff conditions, taking into account the low speed aerodynamic effects on the propeller and the resulting effect on the takeoff performance. The point mass takeoff performance model and BEM propeller analysis iterate the propeller sizing parameters; number of blades and chord ratio factor to determine the propeller that precisely achieves the required takeoff distance. Two case studies with reference aircraft are presented to demonstrate the impact of the developed sizing method on the preliminary aircraft and engine design solution with respect to reality and the empirical method. The results show the created constraints follow the same trends, however the power loading takeoff constraint is lower than the empirical constraint.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:86022778-0316-4661-aed5-d25256f18303","http://resolver.tudelft.nl/uuid:86022778-0316-4661-aed5-d25256f18303","A Data Management System for P3D: Building a data management system for a moulding company","Mouw, Zeger (TU Delft Electrical Engineering, Mathematics and Computer Science); Bharos, Abri (TU Delft Electrical Engineering, Mathematics and Computer Science); Pelser, Tim (TU Delft Electrical Engineering, Mathematics and Computer Science); Sennema, Erik (TU Delft Electrical Engineering, Mathematics and Computer Science); Paardekooper, Gijs (TU Delft Electrical Engineering, Mathematics and Computer Science)","Katsifodimos, A (mentor); Visser, O.W. (graduation committee); Gross, J. (graduation committee); Delft University of Technology (degree granting institution)","2021","P3D is an injection moulding company that uses a technology called PRIM¬Æ (Printed Injection Mould) to create products for its customers. Different from traditional moulding companies, P3D‚Äôs main business model resolves around an efficient workflow and fast delivery of products to its customers. At the moment P3D is able to quickly fabricate and deliver its products be-cause of a small team of skilled designers and engineers who have lots of expertise in the field of injection moulding. Unfortunately, relying on the expertise of its employees, a lot of data about the company‚Äôs workflow is memorised or written down. This poses a problem as P3D would like to grow in the future and will not be able to entirely rely on memorised or analogue data.The goal of this project is to create a data management system (DMS) that digitises information about P3D its workflow and saves it in an easily accessible centralised system.","Data Management System; P3D; Microservices; Process Optimisation; Process Analysis","en","bachelor thesis","","","","","","","","","","","","Computer Science","",""
"uuid:a8f23924-b4e3-43de-8205-497bea680335","http://resolver.tudelft.nl/uuid:a8f23924-b4e3-43de-8205-497bea680335","Urban Farming in the Western Garden City: A study to the employment and benefits of urban farming techniques in three neighbouhroods of Amsterdam","Valdes Troncoso, Joaquin (TU Delft Architecture and the Built Environment)","Smit, M.J. (mentor); Adema, F. (graduation committee); Tsui, T.P.Y. (graduation committee); Delft University of Technology (degree granting institution)","2021","The linear food supply chain is putting significant pressures on our resources and our environment. Moreover, global warming is leading to climate change, making our environment more uncertain and challenging food safety around the globe. Therefore new ways of producing food locally need to be researched. This paper investigates how food can be produced within the boundaries of the city of Amsterdam. It studies the suitability of different urban farming techniques within the infrastructure of the neighbourhood through three different scenarios. The scenarios are based on the three pillars of sustainability (social, economic and environmental) and measure a set of indicators (food production, monetary income, job creation, water retention, energy production, esthetic values, social values and biodiversity). The results of the scenarios are afterwards compared to the social and spatial needs of the neighbourhood, from which the most suitable scenario can be chosen. The research has been done for three neighbourhoods from the New West borough in Amsterdam: Geuzenveld, Osdorp Midden and Middenveldsche Akkerpolder. The results show that for Osdorp Midden and Geuzenveld, the scenario focusing on economics is the most suitable for helping with the high rate of poverty and unemployment in the neighbourhood. On the other hand, for Middelveldsche Akkerpolder the scenario focused on creating social values can help strengthening the missing social ties and create a sense of community in the neighbourhood.","Urban Farming; Circularity; Value Creation; Urban Metabolism; Neighbourhood; Urban Planning; Nieuw West; Amsterdam","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences","","52.356300, 4.809600"
"uuid:bedc2f78-3f43-4e3c-aa49-532fdc9d2110","http://resolver.tudelft.nl/uuid:bedc2f78-3f43-4e3c-aa49-532fdc9d2110","An automated approach to estimate car- bon monoxide emissions from steel plants by utilizing TROPOMI satellite measure- ments","Anema, Juliette (TU Delft Civil Engineering and Geosciences)","Basu, S. (mentor); Borsdorff, Tobias (mentor); Delft University of Technology (degree granting institution)","2021","Since the 13th of October 2017, the Tropospheric Monitoring Instrument (TROPOMI) aboard ESA‚Äôs Sentinel 5-Precursor (S5-P) satellite enables daily global measurements of carbon monoxide (CO) total column con- centrations at an unprecedented spatial resolution of 7√ó5.6 km. TROPOMI has the ability to detect distinct pollution plumes, arising from point source emissions, from which emission rates can be derived. We in- vestigate the potential of CO column concentrations observed by TROPOMI to estimate the CO emissions of point sources on an operational level. This study developed a Python framework that for pre-defined point sources automatically detects pollution plumes and from which it estimates CO emissions using a mass bal- ance approach directly from single overpass CO observations. The algorithm is based on concepts from the computer vision to identify the plume and extract the plume center line while respecting the plume orienta- tion. The emission rate is approximated from flux profiles through multiple plume cross-sections following the plume center line. The performance of the developed framework and its potential is demonstrated by the application on 132 identified steel plant facilities over a time period of more than 2.5 years. Currently the lack of accessible and quality-wise good data limits spatial or even temporal comparison of CO emissions from steel plants. Therefore the control and understanding of emission rates could greatly benefit from the proposed approach. In total we obtained 1,774 emission estimates for 97 facilities. Up to 119 measurements per facility are derived where for the majority of the facilities the average number of measurements is around 10. The obtained time series showed large variation in the distribution of measurements over time as well as the emission values itself. For a number of higher emission values, that exceeded up to 2 times the aver- age emission, measured for e.g. the Bhilai Steel Plant, India, the outliers corresponded with interference of another source. Although individual plumes could be identified for two sources (‚àº35 km apart) in the same Bhilai area, no non-merged plumes were detected for the Schwelgern and Huttenheim sites (‚àº18 km apart) in Duisburg, Germany. Moreover, we tested the agreement of our measurements with recorded or stated events: i) The emission estimate from the afternoon of the 24th of May 2019, Bhilai site, confirmed the manufacturers statement that the operations had continued that day despite a reported fire in the morning. ii) Our results did not match the significant global drop noted in steel production during the first period of 2020 as a result of the pandemic. The scattered distribution of measurements and their emission values over time seem to limit the representation of a small time frame needed for such analysis. iii) We found a positive correlation with a Pearson Coefficient of 0.76 between the European Pollutant Release Transfer Register (E-PRTR) and our data. For all examined facilities our obtained emissions were greater than reported by the facilities to E-PRTR. This might indicate an underestimation of the data registered. This first evaluation emphasizes the potential of TROPOMI observations to improve our understanding of point source emissions and to compliment existing data such as the E-PRTR. However, to be able to interpret the data from TROPOMI indeed structurally and to develop a reliable validation method extensive data-analysis on plant and area-level is required, especially to be able to rule out interfering factors.","Plumes; TROPOMI; CO; Automatic; Detection","en","master thesis","","","","","","","","","","","","Civil Engineering | Environmental Engineering","",""
"uuid:c8dae0b2-be56-43e6-86cd-b0278332f60a","http://resolver.tudelft.nl/uuid:c8dae0b2-be56-43e6-86cd-b0278332f60a","Aerodynamic Effects of the Flow Field in a Vehicle Rear Wheel Arch and its Effect on the Driving Resistance","Kaiser, Philipp (TU Delft Aerospace Engineering)","Sciacchitano, A. (mentor); Cogotti, F. (mentor); Gerritsma, M.I. (graduation committee); van Zuijlen, A.H. (graduation committee); Avallone, F. (graduation committee); Delft University of Technology (degree granting institution)","2021","The increasing importance of climate change and stricter regulations for greenhouse gas emissions raise the pressure on the automotive industry to develop more efficient products. Besides a reduction of emissions by new combustion engines, electric vehicles are being introduced to lower the fleet fuel economy. Especially this new drivetrain technology benefits from an improved driving resistance of the vehicle, as an increase in range is highly valued for current electric vehicles. The aerodynamic drag, a considerable contribution to the driving resistance, therefore plays an important role in automotive development. With a significant contribution to aerodynamic drag, the wheels and surrounding wheelhouses are considered to have potential for possible improvements and are currently one of the focuses of research. This thesis examines the aerodynamic flow in a rear wheel arch of a low drag electric sedan to identify areas of potential improvement and derive recommendations for future developments. Three major parameters of the rear wheelhouse geometry are therefore modified and their influence on the aerodynamic drag and the flow field is assessed. These include the wheelhouse radius, wheelhouse width and the wheel track. For this purpose, Reynolds Averaged Navier Stokes (RANS) simulations are used to both calculate the effect of the variations on aerodynamic drag and analyse the origin of changes in the flow field. For parameters where it is possible, tests on a detailed full scale model are carried out in a modern full scale wind tunnel.","Aerodynamics; Vehicle Aerodynamics; Drag; Wheelhouse; CFD; Wind Tunnel","en","master thesis","","","","","","","","2026-02-02","","","","Aerospace Engineering","",""
"uuid:4f6f4b70-2dc4-49aa-a33f-bd5d195f1a1f","http://resolver.tudelft.nl/uuid:4f6f4b70-2dc4-49aa-a33f-bd5d195f1a1f","Creating adaptive master Applied Mathematics graduates: Closing the gap between programme and professional career","Babel, Angelica (TU Delft Applied Sciences)","Wehrmann, C. (mentor); Kalm√°r, Eva (graduation committee); Kraaikamp, C. (graduation committee); Delft University of Technology (degree granting institution)","2021","We live in a fast-changing world, where higher engineering education focusses on creating engineers that will deal with upcoming technological innovations. It is important to think ahead and educate engineers that could work on these problems and develop technological solutions for them, and are adaptable to deal with the changes in the world. This thesis focusses on how the master programme Applied Mathematics at the TU Delft could prepare their graduates for their professional career, by including adaptability in the curriculum. Adaptability is the ability to settle more easily in a new and unfamiliar environment, and to withstand changes in a changed environment or a new environment. Starting a new job after graduation is new, unfamiliar and unpredictable, so being adaptable could smoothen the transition from programme to labour market. The results of this thesis showed that two adaptive competencies, Dealing with Uncertain and Unpredictable Work situations, and Demonstrating Interpersonal Adaptability, were found to be most interested and relevant to include in the master programme. A tool was developed for the internship to make students more aware about these competencies, make them practice these competencies at their internship by developing personal learning goals and have them reflect on their experiences at the end. This tool could make the AM students more adaptive, what might prepare them for their professional career.","adaptability; professional career; adaptive; graduates; education; labour market; career","en","master thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:c370597d-8fd3-4a1e-89a2-33e8e6f84264","http://resolver.tudelft.nl/uuid:c370597d-8fd3-4a1e-89a2-33e8e6f84264","‚ÄòImproving on supply chain performance regarding throughput time, by designing a Digital Chain that is based on the combination of IoT-sensors and blockchain technology‚Äô","Rooijakkers, Benno (TU Delft Mechanical, Maritime and Materials Engineering)","Beelaerts van Blokland, W.W.A. (mentor); Delft University of Technology (degree granting institution)","2021","In recent years market expansion and globalization have led to new market requirements, which resulted in more complex supply chains. Within these complex supply chains, the lack of visibility and cross-enterprise data-exchange on the whereabouts of goods has led to the occurrence of undesired dwell-time of products between processes, resulting in a decrease in supply chain performance with regards to throughput times. This paper addresses the current lack of visibility and cross-enterprise data-exchange in supply chains by designing a Digital Chain that is based on Internet of Things (IoT)-sensor technology and blockchain technology. Through use of a Digital Chain, undesired dwell-time of goods is diminished and therefore supply chain performance is improved concerning Service-Level Objectives regarding Throughput Times (SLOTT). A Digital Chain is defined as a digital representation of a physical supply chain that mimics its counterpart in great detail through continuous updating of state changes of the physical counterpart via sensor-based data. Digital Chains are expected to improve supply chain SLOTT performance as they provide for upfront, iterative forecasting of arrival times of goods. In this paper the following research question is answered: ‚ÄòWhat are the design characteristics to develop a Digital Chain, based on combining IoT-sensors with blockchain technology, to improve supply chain SLOTT performance?‚Äô","","en","master thesis","","","","","","","","","","","","Marine Technology | Transport Engineering and Logistics","",""
"uuid:79b71f4a-034c-42cd-92a8-bf44a084eb7c","http://resolver.tudelft.nl/uuid:79b71f4a-034c-42cd-92a8-bf44a084eb7c","The role of cybersecurity in hospital procurement processes","van Baren, Rutger (TU Delft Technology, Policy and Management; TU Delft Organisation and Governance)","van Eeten, M.J.G. (mentor); Labunets, K. (graduation committee); van de Poel, I.R. (graduation committee); Delft University of Technology (degree granting institution)","2021","Cybersecurity is important to hospitals and patients alike and is becoming more important as healthcare is experiencing more cybercrime over time. It is the result of complex interactions between actors and their environment during procurement, but research has not yet studied the combination of cybersecurity, healthcare and procurement together. The main research question is: What is the role of cybersecurity in hospital procurement processes and how can that role be analysed across the sector? Nine semi-structured interviews were conducted with hospital cybersecurity experts. Using a combination of a purchase process model and complex decision-making framework and using semi-grounded theory techniques for analysis, five key factors and their interrelations were identified: supplier-hospital relationship, knowledge exchange and retention, alternative purchase processes, cloud transition and conflicting priorities. These factors influence the decision power of hospitals and their internal departments before and after signing off on a purchase. Based on the results, a complementary survey was developed to scale this research across Dutch hospitals. This survey serves as a stepping stonet for future research efforts.","cybersecurity; procurement; healthcare","en","master thesis","","","","","","","","2022-01-26","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:2d5bd109-cbc4-4cd2-a83a-930813bd980d","http://resolver.tudelft.nl/uuid:2d5bd109-cbc4-4cd2-a83a-930813bd980d","Model-Driven Objective Functions in MPC using Economic Engineering Systems Theory: With an Application to Supply-Chain Scheduling at Shell","Meegdes, Jordan (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Delft Center for Systems and Control)","Mendel, M.B. (mentor); Delft University of Technology (degree granting institution)","2021","This thesis introduces a theory for model-driven objective functions in Model Predictive Control (MPC) algorithms. For scheduling supply chains, such model-driven objective functions allow the MPC algorithm to make optimal scheduling decisions by anticipating future changes in product flow and transfer price dynamics. Including such dynamics introduces new insights in the decision-making process for supply chains, as current supply-chain management relies on professional expertise and modelling techniques with static product flows and transfer prices. In this thesis, a dynamic model for product flows and transfer prices at a storage depot in the supply chain is developed with Economic Engineering Systems Theory. We develop a model-driven objective function for profit-maximization in an MPC scheduling algorithm using the Economic Engineering storage depot model. The advantage of the model-driven objective function is the ability to assess the product flow and transfer price dynamics that affect the revenues and costs for various decisions. The MPC algorithm for scheduling shipments towards storage depots includes the constraints in the supply chain and offers the potential to control processes in the supply chain in a dynamic and automated way. This thesis applies the modelling technique and scheduling algorithm to the refined oil product supply chain of Shell for DACH. The algorithm automates processes that form the bridge between the yearly tactical planning and the day-to-day scheduling operations. Supply-chain companies like Shell benefit from the scheduling algorithm by optimal decision-making, additional time for strategic activities and less room for human error.","Model Predictive Control; Supply Chain; Scheduling; Economic Engineering; Dynamic modelling","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:e8f2c0d3-2028-44d4-bf9a-1ef353280667","http://resolver.tudelft.nl/uuid:e8f2c0d3-2028-44d4-bf9a-1ef353280667","The public interior: A Social condenser in Hong Kong","Ho, Wai Sum Michelle (TU Delft Architecture and the Built Environment)","Pimlott, M. (mentor); Rosbottom, D.J. (mentor); De Vocht, S. (mentor); Parravicini, M. (mentor); Delft University of Technology (degree granting institution)","2021","Since the transfer of sovereignty over Hong Kong in 1997, the opportunities for political conversation are diminishing, censorship has been gradually imposed on different means of mass media. In the face of the gradual loss of freedoms, the people of Hong Kong have demonstrated an atmosphere of solidarity through social movements and physical engagement with the city. Under the contexts of top-down political and urban conditions, how can architecture, enable a democratic space that favours political debates and effective communication between different parties? An independent art institution, Green Wave Art, is looking for a new physical platform to gather the artist/cultural community and expand their ways of working with the social scope. The art corporate wishes to fund a place, with intentional openness that provides public enlightenment and entertainment. As they have always been outspoken on political issues, the challenge arises as looking for a space for ‚Äúunderground‚Äù activities in the critical condition of Hong Kong today is scarce. Inspired by the act of queering spaces in the protest, the project speculates a new public building typology that takes advantage of an undervalued urban space, which was formerly a car-park building. In the public Transcript, it suggests an alternative immediate solution for the underused building: to be kept and appropriated into spaces for street vendors to occupy the garage floors, which also saves the government from extra costs in demolition and rebuilding. In the hidden transcript, the artists would further re-appropriate the architectural framework provided by the government under the camouflage of the street market, into a free-space that invites political debates and public engagement at the rooftop, where the citizens can lookout and possess the city.","Hong Kong; Agency; Democracy; Reapproproation; Bottom-up approach; Protests; Public Transcript; Transformation; Hidden Transcript; The Art of Resistance; Public interior; interior building cities; The Independent group","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Interiors Buildings Cities","",""
"uuid:80bb7806-325f-48e2-9a97-bba4d80b2184","http://resolver.tudelft.nl/uuid:80bb7806-325f-48e2-9a97-bba4d80b2184","Celebration as Revolution: Transformation of Copenhagen's First Waterworks to Public Baths","Zeng, Danyu (TU Delft Architecture and the Built Environment)","De Vocht, S. (mentor); Pimlott, M. (graduation committee); Parravicini, M. (mentor); Rosbottom, D.J. (graduation committee); Delft University of Technology (degree granting institution)","2021","The project ""Celebration as Revolution - Transformation of Copenhagen's First Waterworks to Public Bath"" investigates how the celebration of worker's movement in the 1970s has developed into Copenhagen's largest annual festival ""Distortion"". An industrial heritage site, the Waterworks plant, is proposed to be reappropriate for cultural and celebrative purposes in relation to water and pleasure.","Transformation project; Revolution; Festival; Industrial","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Interiors Buildings Cities","",""
"uuid:fdb44fe9-1807-4dd9-9780-02f6df09ae25","http://resolver.tudelft.nl/uuid:fdb44fe9-1807-4dd9-9780-02f6df09ae25","DEMO DOMAIN; for of and by the local people of Europe: Revitalising European Democracies by the re-introduction of Public Sphere in local society.","Baggerman, Sandra (TU Delft Architecture and the Built Environment)","de Haas, M.J. (mentor); van de Voort, J.A. (graduation committee); van de Pas, R.R.J. (graduation committee); Delft University of Technology (degree granting institution)","2021","The binding factor of the European Union's diverse nations is their practice of democracy. However, recently the EU has been dealing with the rising power of populism, increasing polarization and strong bubble forming; all leading to a weakening practice of local, national and union scale democracies. An important factor in this is the lacking tradition of Public Sphere in our society; a safe and comfortable space that invites and facilitates dialectic engagement between people of different believes. Bringing back this sphere into the spatial realm, accessible to people, will strengthen the local practice of democracy. An institution that has played an import role in the traditional practice of European Democracy is that of the Public Domain; the space that derives its function and value based on the peoples' needs. This locally strong embedded institution already facilitate the Expression Sphere and Protests Spheres hence it needs to evolve, adding to it the Public Sphere. Public Domains through the whole of Europe need to spatially evolve in a bottom-up and gentle manner. Above all; the manifestation of Public Sphere needs to become deeply rooted in the local society and context to connect to the local society and its people. This relation between local people and the Public Sphere is coloured by the qualitative application of architectural atmosphere as it has the capacity to colour and define the emotional relationship between institution and space. One of the evolved manifestations of the public domain is that of the Demo Domain of Nowa Huta; a former utopian socialist town, close to Krakow, Poland.","European Union; Ecosophy; Democracy; Atmopshere; Contextualism; Public Sphere; Public Domain; Ecosophic Contextualism; Explore Lab","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Explorelab","","50.075360, 20.039977"
"uuid:ce4a02fe-f0af-42ba-91a3-377af9f187f8","http://resolver.tudelft.nl/uuid:ce4a02fe-f0af-42ba-91a3-377af9f187f8","The Urban of Art: designing a live-work building for art and culture","Theijse, Teun (TU Delft Architecture and the Built Environment; TU Delft Architecture)","Kupers, T.W. (mentor); Adema, F. (mentor); van der Putt, P.S. (mentor); Chan, P.W.C. (graduation committee); Delft University of Technology (degree granting institution)","2021","The theme of the Dutch Housing Studio was that of the Inclusive City. So the goal was to improve the inclusivity of the modern city, Rotterdam in this case. The focus of this design project was artists. The research goes into artists and their issues, gentrification and possible strategies to solve those issues. It also delves into historical artist housing. The design itself revolves around the incorporation of those lessons from history into modern times and deals with the creation of a community of artists and art enthusiasts.","Artist Housing; Dwelling; Dutch Housing; Gentrification","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Dwelling","","51.908830, 4.432415"
"uuid:d5f3a53d-c667-4e9f-a8a0-9d359caf9b94","http://resolver.tudelft.nl/uuid:d5f3a53d-c667-4e9f-a8a0-9d359caf9b94","Imponderabilia: The Agency of the Border between Land and Sea","Grgic, Petra (TU Delft Architecture and the Built Environment)","Calabrese, L.M. (mentor); Ordonhas Viseu Cardoso, R. (graduation committee); Delft University of Technology (degree granting institution)","2021","The globalization that we are facing completely transformed the world as we knew it fifty years ago. The historical era we live in today is cha- racterized by the use of technology, which is one of the factors that made globalization possible. While some time ago it was possible to define and identify the ‚Äúcenter‚Äù of powers, of cities, it became more challenging today. Nowadays different types of centralities exist, ranging from the new transnational networks of cities to electronic space (Sassen, 2001). The urban question addresses the cities as the main places where the activities that arose from globalization are focused and they are characterized by different degrees of virtuality. Finance is one of them, probably the most virtual, thanks to the liberalization that happened in the eighties of the last century (Harvey, 2007). (Sassen, 2001) proposes a challenge to the archi- tects and urbanists in this sense: are we able to study and imagine projects for the places of intersection between the global, mostly virtual dynamics, and the local realities? The research that is explained here wants to take up this challenge. It focuses on the topic of the global commercial networks that have been developing in the last years. Such corridors aim at creating new con- nections between cities around the globe, by building new infrastructure in strategic points, among them harbors too. The practice of allowing den- ser flows between these areas is less virtual than the activities of finance, for instance. Every commercial corridor needs to take into consideration the question of logistics, mobility and consequently infrastructure whose physical implications are tangible. Similarly, some of the flows that pass through the hubs are flows of very tangible objects such as containers or liquids. Along with the concrete passengers of the commercial there will be the unofficial ones, whose presence is intrinsic every time there is an exchange of goods: the knowledge and culture from the places connected by the new economic corridor. Just like in the case of finance, explained by Sassen (2001), there is a variety of other activities and spaces that emer- ge along with it. This research wants to address the ones that emerge and could emerge from the development of harbor cities in the current logic of globalization and growth of global flows.<br/>This research wants to underline that the answer is not in the obedient ac- ceptance of the conditions that the global powers dictate. That is why, the outcome of this thesis wants to be a new method, and a new lens through which we can all choose to look at the urban paradigm of harbor cities.","Port city; border; theatre; global networks","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Transitional Territories","","45,6362, 13,8042"
"uuid:6073d329-49e5-4669-98ab-ddfbd1ed0cef","http://resolver.tudelft.nl/uuid:6073d329-49e5-4669-98ab-ddfbd1ed0cef","Fleet Level Multi-Unit Maintenance Optimization Subject To Degradation: Maintenance Scheduling For Aircraft Brakes Using Remaining-Useful-Life Prognostics","Boekweit, Stan (TU Delft Aerospace Engineering)","Mitici, M.A. (mentor); Lee, J. (graduation committee); de Pater, I.I. (graduation committee); Delft University of Technology (degree granting institution)","2021","During operation aircraft brakes degrade due to wear. This degradation can be continuously monitored using brake degradation sensors. Using this monitored degradation data the remaining useful life of the brakes can be estimated by means of a prognostic model based on a Gamma probability distribution. Using the remaining useful life estimations a maintenance schedule can be optimized for a fleet of aircraft each fitted with multiple brakes accounting for maintenance constraints. Considered maintenance constraints include the availability of the maintenance hangar and the aircraft flight schedules. Because the problem contains multi-unit systems opportunistic maintenance can be applied, specifically economic dependance between components is considered in the optimization. Using a rolling horizon approach a long-term maintenance schedule can be created and evaluated. This long-term schedule is simulated using Monte Carlo simulation to achieve robust results on which meaningful conclusions can be drawn. To compare the results of the condition-based maintenance strategy a time-based maintenance strategy with fixed replacement intervals is used. It has been shown that the application of a condition-based maintenance strategy which makes use of prognostics can significantly improve the scheduling performance.","Maintenance; optimization; Prognostics; remaining useful life","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:5f653238-746c-4579-bd0f-f1b7b928f603","http://resolver.tudelft.nl/uuid:5f653238-746c-4579-bd0f-f1b7b928f603","Numerieke simulatie van een bewegend randprobleem voor plaque-ontwikkeling bij atherosclerose: Een onderzoek naar de invloed van shear stress op de plaquevorming","Bosman, Angeline (TU Delft Electrical Engineering, Mathematics and Computer Science)","Dubbeldam, J.L.A. (mentor); Delft University of Technology (degree granting institution)","2021","In dit verslag wordt onderzoek gedaan naar het verloop van de ziekte Atherosclerose. Dit is een ziekte waarbij de wand van het bloedvat uitzet en verhardt. Dit gebeurt doordat er in de bloedwand ophoping plaatsvindt van plaque, bestaande uit LDL-deeltjes, immuuncellen en foam cellen. In dit onderzoek wordt gekeken hoe deze plaquevorming zal gaan verlopen, en specifiek wat de invloed hierop zal zijn van de shear stress, oftewel de frictiekracht van het bloed op de bloedwand. Eerder onderzoek heeft al uitgewezen dat er een positief verband bestaat. Ook wordt gekeken hoe de binnenwand zal gaan veranderen in de tijd. Vooral bekeken wordt of de binnenwand sneller of anders zal gaan krimpen bij verschillende shear stresses. Er wordt een stelsel opgesteld van vijf parti√´le differentiaalvergelijkingen, bestaande uit geoxideerde LDL-deeltjes, monocyten, macrofagen, foam cellen en chemoattractant. Deze zullen gedefinieerd worden op het volgende domein: een dwarsdoorsnede van een bloedvat. De vergelijkingen beschrijven de evolutie van de plaquevorming. Om de bewegende binnenwand van de bloedwand te beschrijven wordt een snelheidsveld opgesteld, dat de verandering in de tijd beschrijft. Er wordt met behulp van numerieke methoden een benadering gezocht als oplossing voor dit probleem. Het model, bestaande uit de differentiaalvergelijkingen, wordt opgelost met de eindige volume methode. Hierbij is gekeken naar de stationaire oplossing. De bewegende rand is opgelost met de level set methode. Hierbij wordt wel gekeken naar de evolutie in de tijd. Alles is vervolgens ge√Ømplementeerd en opgelost met het computerprogramma matlab. De volgende resultaten zijn gevonden. Als een initi√´le concentratie geoxideerde LDL-deeltjes aanwezig is, zal daar plaquevorming optreden. De plaque zal zich niet verdelen over de bloedwand, maar redelijk lokaal blijven. Dit kan worden verklaard doordat gekeken wordt naar de stationaire oplossing en de diffusie effectief nul wordt genomen. Ook is gevonden dat de bewegende rand mee zal bewegen met deze lokale plaquevorming, maar dat deze na 10 jaar een afwijking aan de onderkant van de bloedwand vormt. Ten derde is gevonden dat bij een plaatsafhankelijk lagere shear stress meer plaque gaat vormen op deze plek. Ook is gevonden dat een lagere shear stress zorgt voor een duidelijk zichtbaar hogere monocyt dichtheid. De laatste bevinding is dat een algeheel lagere shear stress ervoor zorgt dat het lumen-oppervlak sneller zal afnemen. Dit resultaat is echter erg subtiel.","","nl","bachelor thesis","","","","","","https://github.com/angelinebosman/Bachelorproject","","2021-02-08","","","","Applied Mathematics","",""
"uuid:e4e11548-f4f8-4728-8213-98f313d800c6","http://resolver.tudelft.nl/uuid:e4e11548-f4f8-4728-8213-98f313d800c6","Numerical investigation of the turbulent boundary layer over dimpled surfaces","Lin, Yuyu (TU Delft Aerospace Engineering; TU Delft Aerodynamics, Wind Energy & Propulsion)","Hickel, S. (mentor); van Oudheusden, B.W. (mentor); Casacuberta Puig, J. (mentor); van Campenhout, O.W.G. (mentor); Delft University of Technology (degree granting institution)","2021","Dimples are shallow, indented surfaces that attempt to reduce drag in turbulent boundary layer flows. However, the underlying effect of the dimples on the drag is not entirely understood. This thesis sets out to expand our understanding; a numerical investigation of turbulent boundary layer flow over dimpled surfaces is conducted. This research aims to verify the drag results from recent experimental studies and investigate the possible drag-reducing mechanism of a dimpled plate. The research considers shallow, rounded-edge dimples with a staggered layout. Implicit large eddy simulation (ILES) is carried out with the cell spacing close to direct numerical simulations (DNS). Simulation outputs conclude that the dimple plate causes a total drag increase of approximately 1% compared to a smooth plate. This value confirms the results of Spalart et al. and recent wind tunnel measurements within the Aerodynamics group. The turbulent coherent structures are further investigated by performing hole-filtering sampling to the quadrant events. Results suggest that the dimple plate induces a more intense turbulent activity in the buffer layer. The increased occurrence contributes to a higher Reynolds shear stress. The development of quadrant events is further analysed using a Variable-Interval Time-Averaging (VITA) technique. It reveals that the averaged quadrant event development between two plates is almost the same. However, a more extended sweep development is found in the wake region. Given such a mild even evolution, the resulting Reynolds shear stress generation remains the same. Lastly, the coherent structure response is linked to the skin friction response through the Fukagata-Iwamoto-Kasagi (FIK) identity. The resulting decomposition using the FIK identity reveals that dimples contribute to higher total drag due to increased Reynolds shear stress. On the other hand, the observed skin friction reduction seems relative to the mean flow convection.","drag reduction; turbulent boundary layer; passive flow control","en","master thesis","","","","","","","","2022-02-28","","","","Aerospace Engineering","",""
