"uuid","repository link","title","author","contributor","publication year","abstract","subject topic","language","publication type","publisher","isbn","issn","patent","patent status","bibliographic note","access restriction","embargo date","faculty","department","research group","programme","project","coordinates"
"uuid:5d2337cf-95ff-4148-8ae9-6e39dfeca492","http://resolver.tudelft.nl/uuid:5d2337cf-95ff-4148-8ae9-6e39dfeca492","Smart Grid in China: Policies, Markets and Future Plans","Yalei, L.","Yannick, P. (mentor)","2012","Growing demand of reliability and efficiency in electricity sector has aroused electricity grid modernization in the vision of smart grid platform. The essence of the vision is an autonomous electricity network with two-way electricity power flows and extensive real-time information between the generation nodes, various electricity-dependent appliances and all points in-between. In China, China’s State Grid Corporation announced plans to invest 1500 billion RMB in electric power infrastructure upgrades over the next five years and another 1500 billion RMB between 2016 and 2020 to complete the built-out of a stronger and smarter Chinese power grid. This thesis aims to examine the drivers and vision of China’s smart grid, current smart grid policy background, and smart grid market analysis by sector, potential investment and business opportunities in China’s smart grid market .The results suggest strategies to succeed in China’s smart grid market for foreign investors.","smart grid; chinese electricity industry; market analysis","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","EPA","","EPA, Erasmus Mundus Master EMIN","",""
"uuid:641d573e-18bb-45d9-bb74-4fc55c479757","http://resolver.tudelft.nl/uuid:641d573e-18bb-45d9-bb74-4fc55c479757","Dynamic Indirect Illumination in Real-Time Ray Tracing using Lightcuts","Reijerse, R.H.","Jansen, F.W. (mentor); Bikker, J. (mentor)","2012","This thesis describes a system that adds plausible indirect illumination to the Arauna real-time ray tracer. Only the first diffuse reflection of light on static geometry is simulated. Light sources are allowed to be dynamic. Virtual point lights (VPLs) are used to simulate the reflection of light by surfaces. Their contribution to the final shading is stored in a sparse point set distributed randomly over the surfaces. During rendering the direct light is obtained through ray tracing and the indirect light from the VPLs is interpolated from the nearby points of the point set. When light sources are dynamically changed, the VPLs are updated and the indirect shading at the point set is updated. To avoid having to calculate the contribution of all VPLs (which may be thousands) for each point of the point set, the Lightcuts algorithm is used to approximate the illumination from the VPLs for each point. This sublinear scaling algorithm first creates clusters of lights which are adaptively selected during run-time while maintaining an upper bound on the approximation error. We describe bounding spheres as an alternative to the bounding boxes used in the original Lightcuts algorithm and derive new formulae for the error upper bounds. The system is tested with three different scenes. Our bounding sphere alternative is on average 1.3× faster than the box variant. In the tested scenes, plausible indirect illumination is obtained at interactive frame rates on commodity hardware.","computer graphics; real-time ray tracing; indirect illumination","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Software Technology","","EWI-CG","",""
"uuid:432189de-d549-43af-88ae-7fc396234aea","http://resolver.tudelft.nl/uuid:432189de-d549-43af-88ae-7fc396234aea","Compile time aanalysis for hardware transactional memory architectures","Chahar, A.","Van Leuken, T.G.R.M. (mentor)","2012","Transactional Memory is a parallel programming paradigm in which tasks are executed, in forms of transactions, concurrently by different resources in a system and resolve conflicts between them at run-time. Conflicts, caused by data dependencies, result in aborts and restarts of transactions, thus, degrading the performance of the system. In case these data dependencies are known at compile time, then the transactions can be scheduled in a way that conflicts are avoided, thereby, reducing the number of aborts and improving significantly the system’s performance. This thesis presents the Compiler insights to Transactional memory (CiT) tool, an architecture independent static analyzer for parallel programs, which detects all potential data dependencies between parallel sections of a program. It provides feedback about load-store instructions in a transaction, dependencies inside of a loop and branches, and severals warnings related to system calls which can affect the performance. The efficiency of the tool was tested on an application including different types of induced data dependencies, as well as several applications in the STAMP benchmark suit. In the first experiment, a 20% performance improvement was observed when the two versions of the application were executed on the TMFv2 HTM simulator.","GNU; GCC; compiler; plugin; transactional; hardware; memory; software; hardware; dependency; data flow; feedback; intraprocedural analysis","en","master thesis","","","","","","","","2013-02-12","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","Circuits and Systems","",""
"uuid:a04416b7-e8c0-499d-81c7-48c51b5e7fda","http://resolver.tudelft.nl/uuid:a04416b7-e8c0-499d-81c7-48c51b5e7fda","Reuse of hollow core slabs from office buildings to residential buildings","Naber, N.R.","Van der Horst, A.Q.C. (mentor); Haas, E.M. (mentor); Pasterkamp, S. (mentor); Van Keulen, D.C. (mentor); Strik, J.H.A. (mentor)","2012","The subject of this thesis is the reuse of hollow core slabs from office building to residential buildings. It was written as final part of the master Civil Engineering of the TU Delft. The occasion for this particular topic is the short functional lifetime of buildings compared to the technical lifetime of their concrete load bearing structure. By reusing instead of recycling concrete, a higher level on the waste management hierarchy is reached. This implies an environmental gain since less connections have to be broken within the concrete and less new ones have to be formed to build up the new construction. This fits well into the chain-aimed policies of the government that are partly drawn up to reduce the environmental impact of the building sector. The question that is attempted to be answered within this research is if it is feasible to reuse concrete elements present in buildings, both technically as well as on process level.","hollow core slabs; reuse; sustainibility; LCA","en","master thesis","","","","","","","","2012-09-04","Civil Engineering and Geosciences","Structural Engineering","","Building Engineering","",""
"uuid:e1736bc2-1d13-471a-80f2-73c1243a1f2f","http://resolver.tudelft.nl/uuid:e1736bc2-1d13-471a-80f2-73c1243a1f2f","Influence of dynamic surface tension on foams: Application in gas well deliquification","Kawale, D.","Van Nimwegen, A.T. (mentor); Portela, L. (mentor); Henkes, R.A.W.M. (mentor); Van Dijk, M. (mentor)","2012","In natural gas production, along with gas, a small amount of liquid is produced. Towards the end of a reservoir life, the gas velocity reduces due to a decline in pressure. A low gas velocity in a gas well causes undesirable liquid accumulation (loading) in the production tubing. One of the ways to postpone liquid loading is by injecting surfactants in the well. The agitation by gas/liquid flows causes the surfactants to foam. The actual mechanism of how the surfactant injection which causes deliquification is poorly understood. There is an impetus from the gas industry to develop a mechanistic foam flow model that can predict the flow in the well for different surfactants. This requires identification of the surfactant properties that influence the flow characteristics. Based on a literature study it was concluded that the dynamic surface tension (DST) and equilibrium surface tension (ST) are few characteristic properties of a surfactant that affects the foaming ability. There is no general agreement about the relation between the foamability and the DST. This thesis is formulated to investigate the influence of the DST and the ST on the foaming ability in a customized setup. In gas well deliquification, foams serve the purpose of removing liquids. Therefore, in this work foamability is defined as the liquid content of the created foam. The foamability of different surfactants is tested in a modified Bikerman setup, in which foam is generated by sparging N2 through the surfactant solution. The weight of the produced foam was measured in time. High speed movies were also recorded and analyzed to determine bubble sizes and their velocities in the foam as well as in the bulk liquid. The calculated foam density includes the weight and the foam velocity. DST is measured by the maximum bubble pressure method in a time range of 1 ms to 100 s and the equilibrium surface tension is measured using the du Noüy ring method. The equilibrium surface tension was compared through the corresponding surface pressure, whereas, the DST was compared through the Rosen parameter and the dynamic surface excess concentration. Dynamic surface excess concentration is defined as the surface excess concentration at the time scale of foaming. In the experiments, Sodium dodecyl sulfate (SDS), cetyltrimethylammonium bromide (CTAB) and polyoxyethylene - 4 lauryl ether (Brij 30) are used as the pure surfactant. In addition a commercial proprietary surfactant successfully applied to deliquify actual gas wells, Trifoam Block 820 (TB820) is also used. The influence of salt is investigated by varying NaCl concentration in a solution with fixed SDS concentration. In the pre-micellar region the foam density increases with the Rosen parameter. However in the micellar region this trend was not consistent for all the surfactants used. An overall comparison showed a logarithmic dependance of the Rosen parameter on the foam density, whereas a linear dependance of the dynamic surface excess concentration on the foam density was observed. In order to obtain a dense foam, the Rosen parameter and the dynamic surface excess concentration should be high. More experiments are needed to determined if these trends are general. This dependance of foam density on DST could assist in choosing the ideal surfactant for a particular gas well deliquification application. A denser foam would potentially be more effective in removing liquids (owing to higher liquid content). The mechanistic foam flow model being developed for real life applications should benefit from this qualitative trend.","foamability; wetness of foams; rising foams; dynamic surface tension; foam correlation; adsorption isotherms; bikerman setup; maximum bubble pressure tensiometer; gas well deliquification; liquid loading","en","master thesis","","","","","","","","","Applied Sciences","Multi-Scale Physics","","Chemical Engineering","",""
"uuid:f4516fb0-d7cf-493a-b3c0-d8a0423038e2","http://resolver.tudelft.nl/uuid:f4516fb0-d7cf-493a-b3c0-d8a0423038e2","A system dynamics model for knowledge and technology of enterprises in the open innovative environment","Wei, D.","Zou, B. (mentor); Van Daalen, E. (mentor); Ravesteijn, W. (mentor)","2012","In the fast developing knowledge economy age, the internal resources of an enterprise are usually not enough for proper development, and cooperation with external organizations becomes a popular approach for many enterprises to improve their knowledge storage and technology level, the background of which is called open innovative environment. The knowledge and technology development of Chinese enterprises in the open innovative environment is the research focus of this paper. This research is about the mechanisms and development of knowledge and technology of Chinese enterprises through cooperating with external organizations in the open innovative environment. System Dynamics, a method to provide model analysis and dynamic simulation of large and complex social problems, is applied to model this case and answer the following questions: -What factors can influence knowledge absorption and technological innovation in a Chinese enterprise? -What are the relationships among the key factors in the system? -How to explain the dynamic process of knowledge flow from external sources through organizational cooperation and technology changes in the inner organization? -What policy alternatives can be implemented to improve the system behaviour of the enterprise? And what are the consequences of the alternatives? The complex phenomenon is structured and explained and the above questions are answered by following the classic steps of System Dynamics modelling, i.e. conceptualization, formulation, verification and validation and system behaviour analysis. The conclusion is that, in the open innovative environment, the process of organizational cooperation and knowledge absorption indeed has a strong influence on the development of knowledge storage and technology innovation in a certain time period, through interacting of various factors and relationships. And the influence can be effectively measured and actively controlled. Then, several policy alternatives to improve the system behaviour are proposed as follows: -Alternative 1 of “Consideration of external cooperating organization” means in the beginning of the cooperation, investigation of the external partner from many aspects is necessary and important. -Alternative 2 of “Emphasis on self-development” means to improve the knowledge absorptive capacity of the enterprise in order to make knowledge absorption more feasible and effective, and to prepare the proper basis for internal technological innovation. -Alternative 3 of “Increase in market sensitivity” means the enterprise should speed up the process of market investigation, strategies planning, decision making and policy implementation, in order to be more flexible in market competition. Based on specific analysis and simulation results, there are both advantages and disadvantages in each of the alternatives. Alternative 1 is a necessity and can improve the knowledge storage in the enterprise to a high level in the long term, but an incorrect application of it has the risk of rushing into the “cooperation trap” that seems profitable in a short period while is actually not suitable or even harmful to the long-term development. Alternative 2 is the most sustainable policy and its effect can be obvious from at least five years on, while the price is that it requires high and continuous investment. The effect of Alternative 3 is obvious for both knowledge and technology of the enterprise, even in a short period of time; but the effort cost is also large, in human resource, financial input and policy design. Therefore, a kind of combination of the three policies is recommended based on the above idea. With proper and allowable budgets and conditions, an objective selection of external resources goes first, and then special efforts should be put into increasing market sensitivity and continuous and stable self-development, instead of sharp and intensive.","knowledge absorption; technological innovation; open innovative environment; system dynamics model","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Department of Technology, Dynamics and Sustainable Development","","Engineering and Policy Analysis","",""
"uuid:63a0d200-b44a-40c1-b0ef-35a3f0bcf34a","http://resolver.tudelft.nl/uuid:63a0d200-b44a-40c1-b0ef-35a3f0bcf34a","Simulations of the Optical Behaviors of Nanostructured Phosphors Based on FDTD Method","Kong, F.","Urbach, H.P. (mentor); Boer, D.D. (mentor)","2012","This thesis has studied how to modify the optical behaviors of the luminescent phosphors by introducing a 1D nanostructure.","FDTD Simulation; Nano; Grating; Phosphor","en","master thesis","","","","","","","","2014-05-15","Applied Sciences","Imaging Physics","","Optics","",""
"uuid:6d553910-2169-4c2c-a494-bdc2abd838b9","http://resolver.tudelft.nl/uuid:6d553910-2169-4c2c-a494-bdc2abd838b9","Detection of Duplicate Content on Twitter","Gadiraju, U.K.","Houben, G.J. (mentor); Abel, F. (mentor)","2012","Depending on the needs of a user, searching on Twitter streams has proven to be very useful for a wide range of applications. Twitter however, has large volumes of information available in the form of tweets, that are shared by mil- lions of users. We have observed that many of these tweets contain mutually redundant information and due to this, there is a consequent impact on the search and retrieval process on Twitter streams. Redundancy in the information pre- sented to a user, hinders with the objective of a search engine to limit a user’s effort, by presenting content that has already been seen. Detecting redundant information in tweets is all the more challenging, due to the colloquial nature of the language that is used. In addition to this, the presence of tweet-specific constructs like hash-tags, shortened URLs and @-mentions further complicates the task of detecting mutually redundant tweets or duplicate tweets. Although it is relatively easy to automatically detect duplicate tweets which are syntactically identical (i.e., the text in the tweets is identical), it is challenging to detect tweets that are semantically equivalent (i.e., tweets have the same underlying meaning) but syntactically different. By analyzing a large Twitter benchmark dataset (provided as a part of the TREC microblog search challenge) used for the micro-blog search task in 2011, we ob- served that there is a varying extent to which a pair of tweets can be duplicates. We developed a scale that can be used to measure the extent of semantic over- lapping in a pair of tweets. Through our analysis, we identified the key aspects around which strategies for the detection of duplicate tweets can be designed, namely, terminological, semantic and linguistic aspects. We designed and imple- mented strategies for the detection of duplicate tweets from that perspective. Our main contributions are four-fold. Firstly, we developed a scale that can be used to measure the degree of a pair of duplicate tweets. Secondly, we analyzed the top-k search results on Twitter and observed the extent to which duplicates appear in top-k retrieval. Thirdly, we designed and implemented the strategies for the detection of duplicates. Our best strategy combination results in a commend- able F-measure of just over 80% (0.82). Finally, we develop a prediction model that can predict the duplicity order of a tweet-pair with an average accuracy of over 80%.","Twitter; Microblog; Duplicate detection; Tweets","en","master thesis","","","","","","","","2012-08-31","Electrical Engineering, Mathematics and Computer Science","Software Technology","","Computer Science/ Web Information Systems","",""
"uuid:fe84782b-dd29-4a20-a92e-cafc3ebb3f76","http://resolver.tudelft.nl/uuid:fe84782b-dd29-4a20-a92e-cafc3ebb3f76","Stabiliteit van automatische rijen","Krebs, T.J.P.","Fokkink, R.J. (mentor)","2012","In dit werk hebben we drie verschillende bewerkingen op automatische rijen onderzocht en vastgesteld of we kunnen garanderen dat de resulterende rij automatisch blijft. In het algemeen is het antwoord hierop voor alle drie negatief, maar voor elk zijn er gevallen te onderscheiden met een positief antwoord. De bewerkingen in kwestie zijn het veranderen van de getalbasis waarin indices gerepresenteerd worden, het indiceren met een automatische verzameling en het transduceren.","automatische rijen; eindige automaten","nl","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Delft Institute of Applied Mathematics","","Probability","",""
"uuid:4c3c83ad-580f-4950-ac48-da8807395ab3","http://resolver.tudelft.nl/uuid:4c3c83ad-580f-4950-ac48-da8807395ab3","Advanced Path Planning for a Neurosurgical Flexible Catheter: Improving the performance of sampling-based motion planning","Falatehan, K.","Langendoen, K.G. (mentor); Rodriguez y Baena, F. (mentor)","2012","At Mechatronics in Medicine (MiM) Laboratory of Imperial College London, a neurosurgical steerable flexible probe ( STING) that is used to access deep brain lesions through curved trajectories is currently being developed. The focus of my research project is mainly on trajectory planning of the flexible probe i.e. investigation on how to increase efficiency and performance of the trajectory planning. Some experiments have been thoroughly done to measure the performance of a well known sampling based path planning method, Reachability-Guided Rapidly-exploring Random Tree (RG-RRT). The first step to improve the performance was to migrate from MATLAB to Python-C++ which yielded 12-13 times performance speedup. Besides taking a close look at the software implementation details, the second step was to improve the algorithm by implementing a waypoint cache and exploiting some parallelization techniques. The parallelization techniques cover multi-core CPU (OR parallel, AND parallel, OR+AND parallel and Manager-Worker) and GPGPU techniques. At the end of my research project, RG-RRT with waypoint cache was experimentally able to reach 4 times performance speedup, while parallelization on multi-core CPU with AND parallel technique has shown the most significant result by obtaining approximately 5 times performance speedup. The other parallelization, which was done through the use of an NVIDIA CUDA-enabled GPU, has successfully obtained 10 times performance speedup. Despite its higher rate of performance speedup, later it was shown that GPGPU technique suffers the most from inefficiency due to I/O bottleneck that is caused by device-host memory transfer.","STING; Catheter; Neurosurgery; Imperial College London; Mechatronics in Medicine Laboratory; Path Planning","en","master thesis","","","","","","","","2012-10-04","Electrical Engineering, Mathematics and Computer Science","Embedded Software","","Embedded Systems","",""
"uuid:18e03136-f0e6-4419-bd5b-0de385982e28","http://resolver.tudelft.nl/uuid:18e03136-f0e6-4419-bd5b-0de385982e28","Investigating the usefulness of stack traces in bug triaging","Krikke, M.M.","Pinzger, M. (mentor)","2012","In software engineering, resources such as time, money and developers, are limited. Often when bugs are found in the software developed, bug triaging is used to prioritise bug reports and allocate resources to it. When the number of bugs is considerable, this will require a vast amount of time and effort. The goal of this research is to investigate the usefulness of stack traces in bug reports for the assessment of bug report properties, using existing metrics of bug reports and files, being severity, priority and time-to-fix. In order to investigate the usefulness of stack traces, a research framework and methodology are developed. Overall, we can conclude that stack traces can be used to link software artifacts. Also, stack traces can be a valuable input for prediction models, for example using metrics of related bugs and source files.","software engineering; bug reports; stack traces; bug triaging","en","master thesis","","","","","","","","2012-09-01","Electrical Engineering, Mathematics and Computer Science","Software Technology","","Software Engineering","",""
"uuid:2c870df5-1379-4ea6-8c65-d578684fe4e5","http://resolver.tudelft.nl/uuid:2c870df5-1379-4ea6-8c65-d578684fe4e5","Development of a New Sleep Position Trainer","Zhao, J.","Goossens, R.H.M. (mentor); Hajian, M. (mentor)","2012","Obstructive Sleep Apnea Syndrome (OSAS) is characterized by periods of cessation and reduction of the nasal airflow during sleep. 2 - 4% of the western population suffers from the OSAS which enormously impacts the sleep quality and is associated with significant morbidity of other diseases. Due to its physical cause, a steady 56% of OSAS patients show the correlation of the total number of apneas and the supine position (sleeping on the back). For these position dependent patients, the Sleep Position Trainer (SPT) developed by NightBalance has been proved to be effective. The development of a new head wearing SPT is assigned when the head position is found to be more important than the trunk position. As a result, the new SPT is a small and light device which patient can comfortably wear around the upper head with an ergonomic band. It gently trains the patient not to sleep on the head supine by triggering a controllable auditory stimulation. Initial prototype tests have shown a more than 50% reduction of the time sleep on the supine position. Most participant’s sleep architecture are well preserved. The project has built up a strong foundation for the company to continue the developing of the product in the future.","Sleep Apnea; Sleep Position Sensor; Auditory Stimulation; Medesign; Positional Therapy","en","master thesis","","","","","","","Campus only","2013-08-31","Industrial Design Engineering","Industrial Design","","Master of Science Integrated Product Design","",""
"uuid:ab78f04a-35d1-43f0-94c5-f41ada32c67a","http://resolver.tudelft.nl/uuid:ab78f04a-35d1-43f0-94c5-f41ada32c67a","Water quality in bathing waters: An analysis to determine the influencing factors on faecal indicator bacteria concentration peaks","Blommers, I.","Medema, G.J. (mentor)","2012","A statistical analysis of water quality data in bathing waters and relations with pollution sources. Main research question is: Why do microbial pollution peaks occur on certain locations and certain periods in time and can we predict these peaks?","","en","master thesis","","","","","","","","2012-09-08","Civil Engineering and Geosciences","Water Management","","Sanitary Engineering","",""
"uuid:0ec097a5-aaab-4143-a347-039d19be15fc","http://resolver.tudelft.nl/uuid:0ec097a5-aaab-4143-a347-039d19be15fc","Gevoeligheidsanalyse ondiepe bodemenergie: Kwantitatieve beschrijving van invloed systeem- en omgevingsparameters op efficiëntie ondiepe bodemenergie","Ligtenbarg, N.","Heimovaara, T.J. (mentor); Olsthoorn, T.N. (mentor)","2012","In dit BSc eindwerk is onderzocht welke systeem- en omgevingsparameters invloed hebben op het rendement van een Warmte Koude Opslag (WKO) systeem. Er is gekeken naar grondwaterstroomsnelheid, bronafstand, het temperatuursverschill tussen de bronnen, en de vorm van de thermische bel. Voor realistische waarden van WKO systemen is kwantitatief beschreven wat de invloed van de parameters is op het rendement van het systeem. Modellering is uitgevoerd met de eindige elementen methode software COMSOL.","WKO; Warmte Koude Opslag; Rendement; Bodemenergie; Aquifer Thermal Energy Storage; ATES; COMSOL","nl","bachelor thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","","",""
"uuid:01d92598-ee50-46d7-944e-53300a60875c","http://resolver.tudelft.nl/uuid:01d92598-ee50-46d7-944e-53300a60875c","Intelligently-Sustainable Cities? Assessing the contribution of Intelligent and Knowledge City Programmes to the achievement of urban sustainability","Gargiulo Morelli, V.","Weijnen, M. (mentor); Van Bueren, E. (mentor); Wenzler, I. (mentor); De Reveur, M. (mentor)","2012","The current challenges that the world is facing are urging us to re-think the structure and functioning of our social and economic systems. A critical paradigm shift is required if issues such as climate change, growing poverty, depletion of natural resources and uncertain energy futures are to be effectively solved. Global leaders and scientists all over the world have agreed that the time has come for a new form of development to radically transform our classic models of growth so that they embrace the concept of sustainability. But if achieving sustainability appears as a straightforward solution, the same cannot be said regarding the strategies required for turning this new paradigm of development into concrete actions. In this scenario, cities are called to take the lead. In fact, cities are the systems where the three pillars of sustainability merge together (i.e. economy, environment and society), they are the largest consumers of resources and producers of waste, and they are the center of economic activities and engines of wealth production. But above all, their key role in guiding this transition is evidenced by the prospect of a dramatic increase in urban population. Cities urgently need new forms of urban planning and management that can deal with these challenges while remaining competitive as they enter in the era of Global City Regions. In a nutshell, they have to become socially, economically and environmentally sustainable. In the quest for achieving Sustainable Cities, many governments have placed their bid on Intelligent and Knowledge City Programmes (ICPs and KCPs), mainly as a consequence of the uncertainties related to the performance of different urban structures in terms of sustainability, their excessively long implementation time and their significant costs. These programmes exploit state of the art Information and Communication Technologies (ICT) and the city’s digital infrastructure for different purposes. The goal of ICPs is to pursue urban operational excellence through the improved management of the city’s sectors and infrastructure, while KCPs are designed for improving territorial governance systems and for turning the city into an innovation hub that nurtures knowledge and creativity. ICPs and KCPs are being mostly implemented in the more developed regions of the world, where mature cities characterized by abundant infrastructure legacy and scarcity of land are located. But as governments believe that the strategy of creating “smarter cities” will also result in the achievement of sustainability, the precise connection between the concepts of sustainable and intelligence is not entirely clear. Nobody argues on the desirability of making cities smarter, but the fundamental questions of how and to what extent can ICPs and KCPs contribute to the achievement of urban sustainability lack a precise answer. The goal of this research project is to determine whether the connection between Sustainable and Intelligent Cities is supported by evidence or simply affected by wishful thinking. To accomplish the goal, a methodology for investigating the modalities through which ICPs and KCPs contribute to the achievement or urban sustainability is developed. The proposed assessment model is then applied to general theory on Intelligent and Knowledge Cities, and to case studies which will provide more insights on the nature of these two urban initiatives. This research is structured as follows: Chapter 1: Understanding the essentials of Sustainable Development. Chapter 2: Recognizing the configuration of Sustainable Cities. Chapter 3: Developing a system for monitoring the progress of cities towards sustainability. Chapter 4: Identifying the features and value added of ICPs and KCPs Chapter 5: Assessing the contribution of ICPs and KCPs to urban sustainability Chapter 6: Final conclusions The number of case studies analyzed only allows the formulation of preliminary conclusions (the project provides recommendations for directing future research efforts). The results of this research evidence that: A. Through improved management of urban sectors and infrastructure (with particular emphasis on the electricity grid), ICPs mainly contribute to the achievement of a sustainable urban metabolism (i.e. reduced consumption of non-renewable energy and natural resources, and reduced environmental impact of urban sub-systems), while KCPs support this goal by promoting behavior changes within the community and, in some cases, through the promotion of innovation-based activities. B. Through improved urban safety and mobility, better governance systems and the development of a knowledge-based economy, ICPs and KCPs contribute to the achievement of a sustainable society (i.e. improved quality of life and attractiveness of the city). C. Through improved management of urban sectors and infrastructure and the development of a knowledge-based economy, ICPs and KCPs contribute to the achievement of a sustainable economy (i.e. higher short- and long-term competitiveness). D. Through the improved management of environmental compartments, ICPs are facilitators for the achievement of a sustainable environment (i.e. preservation of the three environmental compartments and biodiversity). However, the main contribution of ICPs to this pillar derives from the optimization of the city’s infrastructure and services, which reduces the environmental impact of urban sectors by lowering the emissions of toxic substances and consumption of natural resources. KCPs also contribute to this goal by promoting behavior changes within the community which are more eco-compatible. Despite the positive contribution of ICPs and KCPs to the achievement of urban sustainability, this research evidences that other actions are required for pursuing truly sustainable urban environments. In fact, the achievement of Sustainable Cities is compromised by the prospects of a dramatic growth in urban population and increasing consumption levels in emerging countries. These two trends seriously hamper the world’s journey towards sustainability, and there is not much that ICPs and KCPs can do to slow them down. These programmes can, however, limit the negative impacts of these two trends, but other actions are urgently required. Furthermore, this research underlines that in order for ICPs and KCPs to successfully leverage sustainability, “optimization” of urban sectors and “behavior changes” need to be pursued in tandem. The main reason justifying this need is to reduce the probability that higher urban efficiency indirectly translates into increasing per capita consumption levels. Reflecting in general terms on the contribution of ICPs and KCPs to urban sustainability, this research noticed that a considerable number of these programmes deeply rely on the extent to which humans become “intelligent”. In fact, both ICPs and KCPs are enablers of human and collective intelligence, which means that their implementation does not guarantee that citizens will change their behaviors as planned. While the effects of ICPs directly optimizing urban sectors and infrastructure (i.e. through automated management systems or by supporting urban managers take more efficient and effective decisions) are more quantifiable, the indirect contribution of programmes ultimately relying on the “good will” of citizens is hard to predict. In fact, most of these programmes dealing with human behavior are being implemented in the form of pilots (i.e. Amsterdam Smart City). Whereas the costs of ICPs and KCPs are quantifiable, their exact benefits are still vague and too dependent on the assumption that humans act rationally and that they are willing to change their consumption habits. The basic principle is that, besides the obstacles faced by Intelligent and Knowledge Cities, becoming smart requires efforts, and not just in the form of investments in ICT and digital infrastructure. In conclusion, this research demonstrates that urban intelligence and sustainability are strongly related, but it is incorrect to consider them as the two opposite sides of the same medal. At the present moment, ICPs and KCPs represent the best tools for supporting cities (especially the ones with significant infrastructure legacy) in their journey towards true sustainability, but other actions are required for the achievement of this goal. Altogether, the conclusions of this research indicate that Intelligent and Knowledge City Programmes are the best known enablers of sustainable urban environments. ""Being an Intelligent-Knowledge City is a necessary but not sufficient condition for being a Sustainable City.""","Sustainable Development; Sustainable Cities; Intelligent and Knowledge City Programmes","en","master thesis","","","","","","","","","Technology, Policy and Management","Policy, Organization, Law and Gaming","","Engineering and Policy Analysis","",""
"uuid:d82980e2-b9e1-497c-a1f0-be1d379f081b","http://resolver.tudelft.nl/uuid:d82980e2-b9e1-497c-a1f0-be1d379f081b","Weak signal detection on twitter datasets: A non-accumulated approach for non-famous events","Song, B.","Abel, F. (mentor); Houben, G.J. (mentor)","2012","With the rise of social networking platforms, a great amount of data has been generated. Extracting information regarding interesting events from this large data pool has become an interesting direction of research. Multiple tools have been built for this challenge. Detecting the signals for a target event has thus become a crucial task and it is the starting point for many subsequent activities, such as, for example, extracting information from the targeted text. Meanwhile, most event detection relies on a certain volume of messages for its detection. This may lead to the effect that only famous events are detected with their strong signals. Waiting for the accumulation of signals for them to become strong signals may delay the detection of an event. So, our goal is an approach which can detect events based on weak signals represented by very few messages. In this thesis work, we designed, implemented and evaluated a feature-based weak signal detection approach on a Twitter dataset by applying a machine learning method on a sample use case with a manually labeled dataset. The approach achieved a high rate for correct classification of 0.885 and an F-measure of 0.892 by combining semantic and sentiment features to the traditional syntactic features. During this procedure, we also gave detailed analysis on the features we designed, and showed how they worked together to give a better result. The performance has also been compared with a key word based classifier, and our approach has given a more than 10 percent improvement on the correct classification rate. It also showed that the semantic and sentiment features could lift the performance given by syntactic features. We also see how the approach itself has the potential to be generalized.","twitter; weak signal; event detection","en","master thesis","","","","","","","","2013-08-31","Electrical Engineering, Mathematics and Computer Science","Software and Computer Technology","","Web Information Systems","",""
"uuid:275ae2a1-664f-4d5d-af67-154ed8fbceb9","http://resolver.tudelft.nl/uuid:275ae2a1-664f-4d5d-af67-154ed8fbceb9","Project Sensory room: From isolation to interaction","Li, W.L.","Melles, M. (mentor); Desmet, P.M.A. (mentor)","2012","In the psychiatry, isolation cells are used to lock up patients, when they become emotionally instable, behave aggressively and become a danger towards their selves or his environment. The isolation cell is a low stimulus and high safety environment. This means simply put that the patient has no control in the room. He is dependent on the staff for daily needs, e.g. get food, and get drink, and personal hygiene. The staffs also control activities such as listening to the radio, reading a book and even flushing the toilet and controlling the lighting in the room. The period of seclusion can vary from a couple of days to weeks and in some cases even more than a year. The main target group in this project are patients with a mental disorder called psychosis. Psychosis is an umbrella terminology for disorders such as schizophrenia, borderline, hallucinations, delusions and paranoia. Psychosis can be viewed as the loss of touch with the reality and having an over stimulated mind. Patients are often stuck in their own chaotic thought, which makes it hard to focus. That is why low stimulus isolation cells are used to give the psychotic mind peace. However in practice, patients often suffer from traumas after seclusion. Many patients described the experience as inhumane: feelings of boredom, abandoned, humiliation, loneliness and anxiety were dominating. In project Sensory rooms, an alternative solution for the isolation cell is developed, which should reduce the negative feelings caused by seclusion. The challenges in this project are restricted context in the psychiatry, and the fact that the main users are not allowed to be contacted nor are they able to be involved in a user research which requires their attention. And the target group is very heterogenic, which probably will require a very versatile solution. Alternative ways to research the context and the main user group were used, e.g. extended literature research, interviews with experts, experience mapping with ex-patients and caregivers, experiencing myself a seclusion of 24 hours at the psychiatry and shadowing a caregiver during his shift at the psychiatric ward. Literature research showed that the uncertainty and loss of control over the situation, failure to comprehend the situation, or solely the imagination of the threat are sources for anxiety. Giving back control and provide crucial information helps the patient to reduce anxiety. In the healing environment theory, just watching nature views has proven to be effective in reducing anxiety. Interactional objects and interacting with animals showed potential. Literature indicated that watching TV only distracts momentarily the mind from the psychotic symptoms, and will increase the frequency and anxiety caused by the psychosis. A strategy in which the patient accepts and interacts positively with their psychotic symptoms reduces anxiety and gave them the ability to be more in control over their psychosis. Interview with experts in the fields concluded that the communication between patient and caregivers is complex. Patients feel overruled in conflicts with the caregivers, they feel misunderstood and powerless. Some patients have difficulty with expressing themselves, due to the psychosis. In the post-evaluation, patients indicated that if the communication between them and the caregiver would improve, they would have solved the conflict earlier and got out of the seclusion faster. The caregivers appear strong and in lead when dealing with patients, however they feel in fact vulnerable in many cases. They are cautious, due to past negative experience with patients, and arm themselves emotionally to keep a professional posture. This often reduces their openness to listen or going into discussion with the patient, when the decision is made that he needs to be secluded. During the seclusion, the caregivers are in charge of observing the status of the patient. However the interaction between the patient and caregiver is limited, which also limits the observational value. For both parties it is hard to start a conversation, due to lack of topic or not knowing what the background is of the involved people. From patient perspective, a source of anxiety is the fact that they are dependent of unfamiliar people. Caregivers do not have different clothes or any marks to indicate that they are the medical or nursing staff. The most important moments of a day in the seclusion are the short contacts with caregivers. Even though a conversation might not emerge, the fact that there is company gives a positive feeling. An interactive wall in the Sensory room has been designed, with a special user interface (UI) that supports the patient during the seclusion. The UI is displayed on a 55” portrait monitor with touch screen function, and placed behind 17 mm safety glass. The usability is designed using intuitive gestures to control the UI. The UI appears simple but flexible. The features are categorized into different screens. Each screen has a different level of stimulus. The features are chosen to provide different level of interactivity. Features which make the patient passive, such as TV are avoided at the beginning. The chosen features were: nature videos, drawing program, picture wall, digital pet dog, information screen, video call, radio and ambient lighting. In the final user evaluation, both the affection for the chosen features and the usability were tested with real patient at the department of psychotic disorder. The patients diverged in their preference to the features. The more active patient liked the features with higher interactivity and the freedom to explore, while the passive patient rather watches the videos from the Ambient Experience and pictures of nature. In terms of usability the patients were surprisingly able to navigate through the UI with minimal issues. They were able to complete all the given tasks during the evaluation session of the usability. The evaluation was positive; however the effect of reducing anxiety and give emotional support could not be evaluated due to conditions. In the feature if the sensory room reach the stage that it is used as a living lab, the effects should be tested and feedback to the further development of the interactive wall.","isolation; design; psychosis; separation; psychiatry; seclusion; cell","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","","",""
"uuid:0147bb86-7252-40f1-9d67-6605717476a1","http://resolver.tudelft.nl/uuid:0147bb86-7252-40f1-9d67-6605717476a1","Bonding and bridging in capacity development networks to address wicked water challenges","Pieron, M.M.","Van de Giesen, N.C. (mentor); Van der Sanden, M.C.A. (mentor); Mostert, E. (mentor); Van der Zouwen, M. (mentor); Wehrmann, C. (mentor)","2012","Capacity development has become an increasingly hot topic in the water sector. The development of individual, organisational, institutional and even societal capacities is argued to be required to be able to addressing the present-day water challenges. From a natural resources management context, much literature is available on WHAT is required for capacity development: social learning in social networks, by means of which an integrated view of the challenges under consideration could be established, effective participation is enabled, and a resilient adaptive water system should be developed. However, HOW to achieve this is a much less considered topic in water related contexts and forms the main topic of this thesis, which centres on the following central research question: Which social network characteristics, with a focus on bonding and bridging mechanisms, facilitate social learning in capacity development networks that aim to address wicked water challenges? Combing insights from the Science Communications field and other related fields of study regarding knowledge management, social network analysis and social capital provided a framework on the important roles of bonding and bridging mechanisms in social networks and their benefits for social learning for capacity development. Bonding mechanisms are closely related to similarities between network members (also called relational proximity), while bridging mechanisms are on the contrary characterised by diversity on the relational level. Paradoxically both mechanisms, and both proximity and diversity, turn out to have important benefits for capacity development to address water challenges, which are often considered to be ‘wicked’ due to the involvement of great systems complexity, stakeholders diversity and uncertainty. Bonding mechanisms in social networks benefit the knowledge sharing efficiency, quality and frequency, resulting in a high potential for effective stakeholder participation. Cross-boundary bridges within such capacity development networks facilitate social learning by introducing novel and nonredundant knowledge into the network, enabling the establishment of in integrated multidisciplinary view on the water system and an adaptive water management approach. This thesis concludes that a careful balance is required between bonding and bridging on the network level, proximity and diversity on the relational level, and the ‘right’ personal characteristics on the individual level. It provides a scientific basis for practical insights and recommendation for capacity developers on how to design their capacity development projects.","capacity development; water management; social capital; social learning","en","master thesis","","","","","","","","2012-09-15","Civil Engineering and Geosciences","Water Management","","Water Resources & Science Communication (Double Degree)","",""
"uuid:a947fb54-f14b-456d-b99c-321ee52a5c75","http://resolver.tudelft.nl/uuid:a947fb54-f14b-456d-b99c-321ee52a5c75","Convex coastline induced rip currents at the Sand Engine","Schlooz, G.","Stive, M.J.F. (mentor); De Schipper, M.A. (mentor); Hoekstra, R. (mentor); Smit, P.B. (mentor); Luijendijk, A.P. (mentor); Swinkels, C.M. (mentor)","2012","This study investigates the hydrodynamics at a convex coastline. The Sand Engine, a man made peninsula in the Netherlands, is used as a case scenario. It is hypothesized that a rip current can develop under certain wave conditions due to the change in coastline orientation. The main goal of this research is to obtain a better understanding of the relevant processes for this rip current to develop near convex coastlines and to investigate if these currents pose a hazard for swimmer safety. On March 8, 2012, a field experiment was conducted at the Sand Engine to measure flow velocities in the surfzone. In this experiment GPS tracked buoys were released in the surfzone. Two drifter deployments are presented in this study, one of these showed a circular flow pattern, the second a large offshore directed current, with a maximum velocity of 0.8 [ms?1]. The data set, from the fieldwork, was then used to optimize and test the abilities of a numerical model, Delft3D. A hindcast, of the conditions during the field experiment, in Delft3D gave results that were in good agreement with the field data. Furthermore the model results showed that the offshore current from the second deployment was partly due to the coastline convexity. A simplified alongshore uniform model is constructed in Delft3D to test a variety of scenario’s. Most scenarios focused on coastline convexity (between 35.5 and 0 [deg]) and wave directions as it was found likely that these are the most relevant processes. Other scenarios tested the influence of a tide, a rip channel, wave height and bottom profile. For this model it was found that the most relevant processes for a rip current at a convex coastline are; (1) Wave direction, when waves approach the shore along the mean shore normal the offshore velocity is highest. (2) Coastline convexity, a more convex coastline inducing a higher offshore current velocity and has a larger range of wave direction that induce a rip current. (3) Wave height, higher waves give more offshore flow. (4) The tide, tidal current extends the range of wave directions that induce a rip current. Moreover it was found that a rip channel induces higher rip current velocities. The implications for swimmer safety were examined by predicting the rip current strength under typical wave conditions during summer beach days. It was concluded that a convex change in coastline orientation larger then 15 [deg] results in an enhanced risk for swimmer safety. Up to a 5 times higher rip current frequency is anticipated on summer beach days due to coastline convexity.","rip current; mega rip; Sand Engine; coastline orientation; GPS drifters; Delft3D","en","master thesis","","","","","","","","2012-09-25","Civil Engineering and Geosciences","Hydraulic Engineering","","","",""
"uuid:fb22fe02-4df9-4ce9-9806-c584f7392569","http://resolver.tudelft.nl/uuid:fb22fe02-4df9-4ce9-9806-c584f7392569","Design and Automated Implementation of a DfT Architecture for 3D-SICs","Papameletis, C.","Hamdioui, S. (mentor)","2012","Three-dimensional stacked integrated circuits (3D-SICs) implemented with through silicon vias (TSVs) and micro-bumps open new horizons for faster, smaller and more energy-efficient chips. As all microelectronic structures, these 3D chips and their interconnects need to be tested for manufacturing defects. This thesis was executed in the context of the joint development program (JDP) on 3D Design-for-Test (DfT) between Cadence and IMEC. Extensions for an existing 3D-DfT architecture based on die-level wrappers were designed, and their implementation was automated in Cadence' electronic design automation (EDA) tools. The 3D-DfT architecture and the corresponding tools were augmented with support for (1) test data compression (TDC) and (2) embedded-core wrappers, as most modern designs employ these DfT techniques. Support for (3) multi-tower 3D-SICs was added as well, as they seem to gain ground in the 3D integration technology. Finally, (4) automated tool flows were designed and implemented for inserting the 3D-DfT to a design, and for performing ATPG at the die-level and at the stack-level in order to verify the correct operation of the 3D-DfT. These flows were applied to a test case and the results were verified through ATPG and simulation of the application of the generated test patterns.","3D-SIC; 3D integration; TSV; Design-for-Test; DfT; ATPG; EDA","en","master thesis","","","","","","","","2012-09-17","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","Embedded Systems","",""
"uuid:292038c9-79c8-4d25-b8c5-8ac705cad1c7","http://resolver.tudelft.nl/uuid:292038c9-79c8-4d25-b8c5-8ac705cad1c7","Effect of Overdisplacement of Proppant in Hydraulic Fracturing Treatments on the Productivity of Shale Gas Reservoirs","Moralesrussi Becerra, M.A.","Zitha, P.L.J. (mentor); De Pater, C.J. (mentor); Barnhoorn, A. (mentor)","2012","Overdisplacement of proppant in hydraulic fracturing treatments is an operational consequence dependent on the type of completion. It is described as the injection of clean fluid to remove residual proppant from the wellbore lateral and/or to transport plugging elements after the pumping of the designed fracturing treatment is finished. This thesis investigates the effect of overdisplacement of proppant on the productivity of Shale gas reservoirs stimulated with transverse fractures. In tight gas reservoirs, where permeabilities are higher if compared with Shale gas reservoirs, overdisplacement is considered detrimental for the productivity, but studies of this effect are scarce in the literature neither for tight nor Shale gas reservoirs. In the case of Shale gas applications, where many treatments are required in the same well, there is a large economic benefit due to time savings when treatments can be overdisplaced. In Shale gas wells, where the gas flow rates per propped fracture are low, it has been proposed that overdisplacing the treatments does not impair productivity. The effect of overdisplacement is strongly related to formation strength (influencing fracture opening) and completion type, where for the latter, the perforate and plug systems, the treatments are normally overdisplaced. For modern ball drop systems, it is claimed that overdisplacement is not required, and it has been suggested that this can potentially improve the production compared to wells where the treatments have been overdisplaced. This work presents an analytical model that quantifies what is the erosion effect of overdisplacement on the proppant bank. The model is based on the physics that describe the slurry transport in pipes. A rock mechanics approach was adopted to calculate the geometry of the fracture after overdisplacement assuming the formation of an arch at the top of the proppant bank. Productivity calculations were done based on analytical solutions for gas wells including the effect of reducing fracture connectivity to the perforations due to overdisplacement. The results showed that even in low permeability formations, the reduction of the proppant bank height due to overdisplacement will impair fracture productivity. The height of the open fracture and the permeability of the different fracture zones, specially the closed fracture, will define the impact of overdisplacing the treatment. An analysis about the impact of changing overdisplacement operational parameters, such as viscosity, proppant size and concentration, showed that significant erosion rates occurred when using low viscosity fluids and larger proppant sizes. The results presented in this work calculated the impact of overdisplacement for a set of specific treatment and reservoir parameters and constitute a first step in the modeling of overdisplacement effect. Accurate prediction of the overdisplacement effect may certainly lead to benefits on production and costs reduction for future treatments. Further modeling of proppant distribution and fracture mechanics in Shale reservoirs will be the next step to have a better understanding of the effect and relevance of overdisplacement in fracturing treatments.","Hydraulic Fracturing; Shale Gas Reservoir; Overdisplacement; Proppant","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Petroleum Engineering","",""
"uuid:b50386e5-448d-49d9-90b0-851bd041288d","http://resolver.tudelft.nl/uuid:b50386e5-448d-49d9-90b0-851bd041288d","Project Monitoring Practices: Case Study in the Healthcare Imaging Industry","Yela Bastidas, F.D.S.","Filippov, S. (mentor)","2012","This document presents a qualitative research developed within the context of an organization that is well positioned in the Healthcare Imaging Industry. The methodology employed to collect data is a Multiple Case Study that was used to explore monitoring practices among four important projects. Interviews, corporate records and non-participatory observations were performed within the Case Study framework.","Project Monitoring and Control","en","master thesis","","","","","","","Campus only","2012-08-31","Technology, Policy and Management","Technology, Strategy & Entrepreneurship","","Management of Technology","",""
"uuid:f6941a4d-12ad-4262-9804-27f769daac64","http://resolver.tudelft.nl/uuid:f6941a4d-12ad-4262-9804-27f769daac64","Scoop: A multisensory way of relaxing on festivals","Marsman, C.","Schifferstein, H.N.J. (mentor); Karana, E. (mentor)","2012","The aim of this project was to create a concept for a suitable relax object for Dutch festivals that offered a unique experience and would provide a successful and profitable entry to the festival market for the new company EventBeds. To understand the context, Dutch festivals were analyzed, underlying user needs to relax were explored, the various influencing factors on a festival experience were studied and current relaxing objects were compared. Dutch festivals come in all sizes and flavours concerning programme, target group and location. However, there is a number of similarities: the biggest revenue at festivals comes from drink sales, especially alcoholic drinks. Therefore, a lot of these drink brands are represented at festivals. Next to bars, food stalls, toilets and other facilities are provided to let the visitor have a good festival experience. These are often placed in between the various music stages, to prevent the music, coming from these stages, from colliding. Dutch festival visitors mainly range from 18 to 25 years old. The use of alcohol and drugs, mainly cannabis and xtc, is highly accepted amongst the visitors. One motivation to go to festivals is restoring the balance between the fast, daily working life and peace of mind, between being serious and having fun. Another aspect is interest in novelties and curiosity; exploring new things that they do not know yet, or in another form. A third motivation is socialization; this can be both in an established social group of visitors, as well as with people from outside this group. A fourth motivation is event excitement: the buzz of all those people on one place, having a good time. Visitors of festivals call this shared happiness an important motivation. Next to all this, gregariousness is an important aspect: the feeling to be part of a group makes many people happy. So, if a large part of a group of friends decides to go to a certain event, the rest often follows. Friends that are not physically present at the festival are often updated through social websites like Facebook, as many of the visitors have a smartphone and use it to share experiences. A creative session with experienced and inexperienced festival visitors was held to establish the underlying user needs of festival visitors in order to truly relax outdoors. This was done through sensitizing booklets, guided fantasies, open discussions and brainstorms. The fact that the session was not focussing primarily on relaxing on festivals, but relaxing in general, led to a number of inspiring outcomes. First of all, the social aspect was affirmed as they stated that sharing a unique experience with loved ones makes it more intense and memorable. This experienced is intensified if people can let this experience sink in. Another outcome was that active relaxation and passive relaxation can enforce each other. However, the contrast between both should not be too much in order to not loose the ‘flow’ (of the thing they were doing before the break) when relaxing. A feeling of connection to nature, as well as a clean space around them can also raise the level of relaxation. The festival experience, as well as the possibilities of placing objects on festivals, is influenced by a large number of aspects. One of those is the Dutch weather, as it is very precarious: rain, sun and wind alternate quickly. Next to this, the safety regulations and wantonly behavior of festival visitors put a constraint on the possibilities of festival objects. Adding to this, since a festival is a one-time event, a festival object should be suitable to be rented out. The demands of sponsor brands are also taken into consideration, since this is the most likely way to make such an object profitable. Finally, An increasing amount of organizations have attention for the environment. Sustainability was therefore also of importance to this project. All these aspects lead to a large number of requirements. The benchmark of current relax objects showed that these objects do not comply with (most of) these requirements. Through ViP, a design statement and human-product interaction was established to create an inspiring design context for the project. This design statement shows what the future design should offer to the people of the domain (outdoor relaxation): By offering different experiences under different circumstances, I want festival visitors to indulge in their surroundings in a surprising and fascinating way, either alone or with others, which will intensify their festival experience by gratifying the senses. The intended human-product interaction is stated as Invited by Fascination. The corresponding product qualities are divided into product characteristics: overwhelming, cheeky, exciting, friendly and protective and the user-related qualities: open, safe, dynamic, unforced and diverse. The human-product interaction and qualities were used during the ideation phase. During the ideation phase, the weather elements were used as a unique input to the object. Various possibilites were explored through sketching and experiential prototypes in order to create fascinating elements. Next to this, inviting shapes were created. A derivation of these shapes was built in the faculty’s workshop and tested on the IO-Festival, during day and night. The outcomes on the aspects size, comfort, appearance, weather elements and ‘other’ were used to improve the concepts. After this, a shape was chosen based on the requirements, outcomes of the creative session, ViP and test results. A cocoon-shaped design was chosen. All pieces of the puzzle come together in the final design: Scoop. Its inviting shape attracts visitors and protects them from the weather elements. It uses these weather elements to provide many different experiences with the object. Next to this, it offers a choice to either be socially active on one side or to retreat for a while on the other side. By using Natural Fibre Composites for the biggest part of the object, it offers a fascinating and different appearance from various distances. This material and the shape give the object a feminine appearance, which is counterbalanced by the use of the masculine Legno-Legno material for the mattress, as well the big black bolts that hold it together. Various types of roofs offer unique experiences that either mimic the features of ice (R-Cast Ice), are made of NFCs or are easily brandable by banners. The last two options make the entry to the festival very feasible as the cost price is respectively 951,- (investment of 47,550,-) and 891,- (investment of 44,550). The Scoop complies with all influencing aspects of festivals as it is very weather resistant, can withstand a lot of wantonly behavior, complies with all safety requirements, is very suitable to be rented, uses sustainable and durable materials and offers diverse ways to be branded.","festivals; multisensory; relaxing; social; retreat","en","master thesis","","","","","","","Campus only","2013-08-31","Industrial Design Engineering","Industrial Design","","Design Aesthetics","",""
"uuid:302ebb8b-d161-4d00-82c3-bd69e278cf04","http://resolver.tudelft.nl/uuid:302ebb8b-d161-4d00-82c3-bd69e278cf04","De overlevingskans van een G-eiwit op een celmembraan","Ruckstuhl, Y.M.","Dubbeldam, J.L.A. (mentor)","2012","Cellen in ons lichaam beschikken over het vermogen om zich gericht te bewegen. Dit fenomeen wordt chemotaxis genoemd. Chemotaxis wordt onder anderen mogenlijk gemaakt door een samenwerking tussen twee soorten moleculen binnen een cel, receptoren en boodschappers. Een receptor vangt signalen uit de omgeving op en geeft dit door aan boodschappers die toevallig dicht genoeg in de buurt zijn. Als dit voor geen boodschapper geldt, krijgt de cel de informatie niet door. Uit experimentele gegevens blijkt dat de efficientie van dit mechanisme ondanks de ruis heel hoog is. De nu bestaande wiskundige modellen kunnen dat echter nog niet goed simuleren. In dit verslag word de kans dat de door een receptor ontvangen signalen doorgegeven worden aan een boodschapper met behulp van een stelsel differentiaal vergelijkingen gemodelleerd. Ook wordt een stukje algemene random walk theorie behandeld.","","nl","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","Mathematical Physics","",""
"uuid:ab259d2a-bd7a-43c6-9b38-9e12cc25d245","http://resolver.tudelft.nl/uuid:ab259d2a-bd7a-43c6-9b38-9e12cc25d245","Wayfinding for families - ""Families finding their way in the museum of Naturalis""","Hoogenberk, B.J.W.","Van Mourik, F. (mentor); Van Boeijen, A. (mentor); Aartsen, P. (mentor)","2012","This master thesis describes the design of new wayfinding system to help families find their way in the museum of Naturalis, situated in Leiden, the Netherlands. Next to being a museum Naturalis is a Biodiversity Center with a research institute, an academic working group, and university programs in biodiversity and taxonomy. Resulting from a fusion between several institutes and university collections in the Netherlands, Naturalis is going through a renewal. The collection has grown to 37 million biological and geological objects. Due to this renewal a lot is going to change, but those changes are still unknown. One thing is sure: Naturalis will be a family friendly museum when they open their new doors in 2016. Becoming a family friendly museum is a trending topic these days in the museum world. Literature shows that being a family friendly museum is more then focussing on children, it is the combination of adults and children in a family that makes it interesting. Children’s museums mostly forget the adults, who only have a facilitating function during the visit, for instance when the children are participating in an activity adults only have to wait and watch. At a family friendly museum the whole family should be involved at all times. It is not possible as a museum though, to fully cover the facilitating role. The adults will always be responsible for the children in the family group. The museum, however, could make the facilitating tasks of adults easier by offering enough services and clearly indicated facilities. This makes it possible for adults to enjoy their visit as much as their children do, and diminish the worry about taking care of the children. One of those services is the wayfinding system in the museum. Visitors will not directly refer to the wayfinding system when they are asked about their experiences in a museum. Nevertheless it does influence the experience of a visitor. As stated above, families are a special kind of visitor groups, resulting in an extraordinary wayfinding process. In order to create and design a new wayfinding system, values and desires of families need to be studied as well as their behaviour and wayfinding process during a visit. The observational study showed that all families are different and have different habits, values and desires. Nevertheless children always highly influence the route through the museum. The building of Naturalis has a very complicated structure, which makes it difficult to orientate and the current wayfinder leaflet does not enhance the visitors’ sense of orientation. From the questionnaire it appeared that people do use the wayfinder for information and to orientate. Nonetheless it is mentioned several times that it did not help them to find the way. Mostly the wayfinder leaflet was used to make sure that they have seen everything. Another interesting note from several participants is that the museum gives a save feeling for several reasons: * The exhibition rooms mostly have one entrance and exit therefore adults are able to keep their children at sight at all times. * Children are welcome at Naturalis, because they are able to have fun, participate in activities, touch things, and it is almost impossible that they do things that are not allowed. Interesting outcomes from the creative sessions on family activities were the indirect influence of the children on deciding which activity will be done, and the influence of money on this decision. A model of guiding themes was formed to conclude the research. These themes describe the important influences of a family visit, on the one hand there are the aspects directly related to the family, and on the other side there are the aspects related to the wayfinding process. Nevertheless all aspects influence on both the family and the wayfinding process. Families visiting the museum are on an activity aiming to spend quality time together. Therefore the ‘together experience’ of the family during their visit is very important, also for the new wayfinding design. The facilities are the most important part of the wayfinding system. When these are difficult to find and to reach it can have a large negative impact on the success of the visit. All families are very different and all these different families should feel at home, meaning a safe surrounding, with enough service and facilities, and where they can do everything on their own way, like they normally would as a family. The orientation phase, the warming up of the visit, is the most important aspect in the wayfinding process, especially for families. They should be able to set their goals for the coming hours in the museum, and learn how to find these goals, including the facilities. The wayfinding system should be clear enough that both children and adults are able to use it. The focus of the design phase is on the together experience and on the preparation and orientation phase of the visit. The final concept is a new wayfinding structure for family friendly museums. A new family friendly museum wayfinding model is designed to explain this structure. The model shows the wayfinding means that communicate together through visuals. Visuals are very important for a family friendly wayfinding design, as both adults and children should be able to use and understand the design. The design should appeal both parties, which makes colours and graphics very important. The visuals should return in all the wayfinding means, starting at home on the website, when entering the entrance area, when studying the wayfinding tool, when finding the way in the museum with signs and directions, and when reaching the entrance of the destinations. Repetition is very important to gain recognition and to support the learning process of the wayfinding system. The structure is translated into a design for Naturalis. For this design the current structure and exhibitions are used as a base. The pesthouse, which serves as the current entrance and is connected to the main building by the zebra bridge, will not be part of the new museum. In the design the new entrance is located at ground level as that will be best for the orientation of the visitors. All wayfinding means are worked out graphically and an overview is developed where each floor has its colour and each exhibition and facility its unique icon. The website, the interactive overview at the entrance, the wayfinding tool, a collecting game, signs and directions are all worked out. The website consists of an interactive design with the visual overview of the museum, which is used at the entrance area as well. The ticket of the museum is part of a collecting game throughout the museum that will function as an alternative checklist to see if you have visited all floors. When all the cards are collected the family is able to build a 3D puzzle of a dinosaur at home while reviewing the nice visit and creating a nice physical memory. The puzzle changes each two months to keep it interesting for frequent visitors. Old puzzles can then be sold at the shop to let people collect all animals. By means of guidelines the requirements for introducing this new wayfinding design of Naturalis are described. It is also possible to use these guidelines to translate the design for another museum that wants to become family friendly. The model is used as a format to create the wayfinding design, and it is important that all the wayfinding means are present and use the same visuals. The repetition, stimulating recognition and the learning process, is the important base of this concept. At the end there will be recommendations to Naturalis in order to implement the design. The most important recommendation is to create a full pilot version of the whole wayfinding system to test it with families. Finally, the project and my personal process trough the project will be reflected.","wayfinding; families; Naturalis","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Design for Interaction","",""
"uuid:4ba569dd-590f-4a40-b711-307861c22e1f","http://resolver.tudelft.nl/uuid:4ba569dd-590f-4a40-b711-307861c22e1f","Analyzing and improving client-contractor relationships at Amsterdam Airport Schiphol - an agency theory and transaction cost theory approach","Leussink, B.D.G.","Herder, P.M. (mentor); Stikkelman, R.M. (mentor); Cunningham, S. (mentor); Van Stekelenburg, J. (mentor)","2012","Large infrastructure promotors progressively outsource parts of their organization to contractors. For them, outsourcing brings along a dependency on contractors for the realization of their objectives. With control over outsourced processes declining, these large organizations risk failure to capitalize on the economic and ecologic potential of outsourced processes. A theoretical framework based on agency theory and transaction cost theory is constructed that can be used to analyze and improve the cooperation of organization with their infrastructure contractors. The theoretical framework is operationalized to allow for observations from a case study at Amsterdam Airport Schiphol (SG). The topic of the case study is the governance of construction materials. SG appears to coordinate construction materials predominantly using behavior-based mechanisms. Comparing this with the prescribed way contracting by the theoretical framework, it is determined that this cooperation is inefficient. Recommendations for SG include adopting an approach where the contractor is freer in its construction material decision making. This harnesses the vast market knowledge as well as the economic and ecologic potential of construction materials on the airport. Recommendations for further research include extending the theoretical framework with additional theory and the use of additional cases of similar outsourced processes.","client-contractor; relationship; agency theory; transaction cost theory; construction materials","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Infrastructure Systems & Services","","Energy & Industry","",""
"uuid:cb47a416-9547-4e91-81d8-9c8b060ed7d8","http://resolver.tudelft.nl/uuid:cb47a416-9547-4e91-81d8-9c8b060ed7d8","Developing a CUDA solver for large sparse matrices for MARIN","De Jong, M.A.","Vuik, C. (mentor); Lin, H.X. (mentor); Van der Ploeg, A. (mentor); Ditzel, A. (mentor)","2012","The Maritime Research Institute Netherlands (MARIN) supplies innovative products for the offshore industry and shipping companies. Among their products are highly realistic real-time bridge simulators. Currently, the waves are deterministic and are not affected by ships, moles, breakwaters, piers, or any other object. To bring the simulators to the next level, a new interactive wave model is being developed. This is the so-called Variational Boussinesq model (VBM) as proposed by Klopman. The main improvement will be that the waves and ships really interact, i.e., the movements of the ship are influenced by the waves and the waves in their turn are influenced by the ship. However, one pays for the higher realism: the new model is much more computational intensive and therefore a really fast solver is needed to fulill the requirements of real-time simulation. In this thesis we present how a very efficient iterative solver can be combined with a very efficient implementation on the graphical processing unit (GPU). Speed up factors of more than 30 can be obtained for realistic problems. With the new solver interactive waves can be computed in real-time for large domains. Necessary theory on iterative solvers and GPU programming is included.","GPU; CUDA; CG; Conjugate Gradient; Preconditioning; Poisson; RRB; Repeated Red-Black; Incomplete LU; Cholesky; VBM; Variational Boussinesq; Diagonal scaling; Parallelism; Parallel; Multigrid; MARIN; Sparse; Linear","en","master thesis","","","","","","","","2012-08-16","Electrical Engineering, Mathematics and Computer Science","Numerical Analysis","","","",""
"uuid:a62c5c53-9999-4c6a-bbd6-5d581070ab61","http://resolver.tudelft.nl/uuid:a62c5c53-9999-4c6a-bbd6-5d581070ab61","De Effectieve Kiplengte van Houten Liggers (Lateral Torsional Buckling)","Saleh, K.","Welleman, J.W. (mentor); Ravenshorst, G.J.P. (mentor)","2012","In dit Bachelor eindwerk is onderzoek gedaan naar de effectieve kiplengte van liggers met rechthoekige doorsneden. In een voorgaand eindwerk is hier al onderzoek naar gedaan door Roeland van Straten. Daarom zijn er bepaalde delen uit het desbetreffende onderzoek overgenomen ter ondersteuning van dit eindwerk. Het gaat hierbij om de paragrafen 1.4 en 2.1. Tevens zijn er in paragraaf 2.2 delen gedeeltelijk overgenomen. Dat wil zeggen dat ze gebruikt zijn ter ondersteuning, maar zodanig aangepast dat ze beter in dit eindwerk pasten. Allereerst is er op analytische wijze een oplossing gevonden voor het kritieke kipmoment van een ligger, belast met een constant moment over de liggerlengte. Bij een moment ter grootte van zal de ligger gaan kippen. Aangezien er voor andere belastingsgevallen geen uitdrukking gevonden kan worden op deze wijze is gebruik gemaakt van energievergelijkingen om het kritieke kipmoment te berekenen. Deze energievergelijkingen zijn gebaseerd op het feit dat de totale energie in de ligger tijdens het kippen gelijk moet blijven. Zo bezit de ligger potentiële energie ten opzichte van een referentielijn gelijk aan , waarbij de massa in kg is, de valversnelling in en de hoogte boven deze referentielijn. Door het kippen buigt de ligger dichter naar de referentielijn toe zodat de potentiële energie afneemt, maar de vervormingsenergie is dan wel toegenomen. Aangezien men in de praktijk niet alleen te maken heeft met één enkele ligger maar met meerdere steunpunten is gekeken wat hier de invloed van is. Dit was van groot belang bij de berekening van de kritieke last bij het fysieke model. Daar is de proef op de som genomen en voor een aantal belastingsgevallen getest of het theoretische kipmoment overeen komt met het werkelijke kipmoment.","Buckling; Lateral Torsional Buckling; Energy Equations","en","bachelor thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Structural Mechanics","",""
"uuid:ae2f973b-769f-4646-ad12-03f498f00a1c","http://resolver.tudelft.nl/uuid:ae2f973b-769f-4646-ad12-03f498f00a1c","The use of numerical models to determine the response of moored vessels to waves in a complex harbour geometry","Van der Ven, P.P.D.","Vellinga, T. (mentor); Ligteringen, H. (mentor); Van der Hout, A.J. (mentor); De Jong, M.P.C. (mentor); De Jong, M. (mentor); Zijlema, M. (mentor)","2012","A moored vessel can experience large motions when agitated by waves. As a result, mooring lines risk breaking, the ship becomes a dangerously uncontrolled object, but most importantly unloading and loading the ship is made impossible. From an economic perspective, it is thus important to determine vessel motions due to waves at a berth. A suitable method including this in a port design would prevent an unexpectedly high inoperativeness of a built quay. The determination of vessel motion is, however, not an easy matter; wave penetration in a harbour is not easily simulated due to its complex geometry and bathymetry. This is further complicated by the high influence of low-frequency waves. These waves, especially bound low-frequency waves, impose a strict demand on the used method. The method used in the present thesis is a chain of the Boussinesq-type model Triton (Deltares) with the panel-method diffraction model Harberth (Van der Molen) and the time domain vessel motion model Quaysim (Van der Molen). This chain adequately takes into account the non-linear wave component, having an important influence on the motion and provides a complete indication of the relevant processes, using a single model chain. An example of the aforementioned problem is the oil berth A in the Port of Leixões, Portugal. This berth experiences a mean inoperativeness of 23%. Within the present thesis, this case has been elaborated both to obtain an insight on the origin of the problem as to assess the potential of the model chain for practice-driven engineering activities. The application of the model chain has been restricted by the limited amount of available time and the results of the validation of the diffraction and motion model. [Validation results] Due to a discrepancy found between the measured and theoretically expected low-frequency energy content, the wavemodel's wave input used in the validation has been defined on the boundary using a measured timeseries. This improved the global reproduction of the low-frequency wave energy content. It is expected that the discrepancy, the high amount of low-frequency energy in the physical scale model basin, is due to the control of the wavemaker, in which this energy has been overestimated. Using the vessel motion a priori, without using physical measurements for calibration, is limited too. The sensitivity for fender friction on the surge-motion, a very relevant motion for loading and unloading vessels, induces a high inaccuracy in case of uncalibrated settings. [Case study results] The study regarding berth A, Leixões, shows that the quay is relatively unprotected for low-frequency waves. Their wave height is considerable with respect to the imposed low-frequency wave height (approximately 60%), particularly due to the profound shoaling towards the beach and the reflection off the beach. An added value of the models used in the present report has been shown by including the harbour basin of the Port of Leixões. The occurrence of seiching is recognized and spatially analysed using a method developed within this project. The energy of these eigenwaves and their nodal patterns are an indication of a significant influence of these waves on vessel motion. Finally, the wave model indicates a current caused by wave-driven setup. The influence thereof on the quay is likely, although the magnitude of this current in reality needs to be verified. [Applicability of the method] The method used in the present report adequately takes into account the relevant wave processes. Vessel dynamics are properly accounted for too, allowing the inclusion of reflections off the quay wall and non-linear mooring line forces. To be applicable in practice-oriented applications, improvements of the method are necessary, especially with respect to the robustness and computational speed. Nonetheless, the method has shown its added value in the presented application.","Triton; numerical simulation; wave propagation; low-frequency waves; Quaysim; Harberth; moored vessel; diffraction model; vessel simulation; vessel motions; Leixões; Leixoes; Portugal","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Hydraulic Engineering","","Ports and Waterways","",""
"uuid:aa67d759-fb8f-4a00-bf1e-7568154ead43","http://resolver.tudelft.nl/uuid:aa67d759-fb8f-4a00-bf1e-7568154ead43","Design of a Bi-Stable Compliant Grasper Using Bi-Stable Beams and Disc Springs","Lassooij, J.","Van der Helm, F.C.T. (mentor); Herder, J.L. (mentor)","2012","The Minimally Invasive Manipulator (MIM) copies the movements of the hands of the surgeon to the tip of the instrument inside the operating area. The movement is mechanically copied using cables and pulleys. When the surgeon grasps and holds an object, the friction inside the MIM increases and distorts the force feedback in the remaining degrees of freedom. The increased friction is the result of the reaction forces on the cables and pulleys due to the required pinch force to hold the object. The goal of this report is to present two designs for a bi-stable compliant grasper. The grasper will have two stable positions: open and closed. In those positions there is no need for an actuation force from the surgeon. When the grasper is closed, it will produce enough pinch force to hold an object. The first design is a compliant grasper combined with bi-stable beam. Both the grasper and bi-stable element will be a planer design. A large scale prototype is presented and evaluated. The prototype showed bi-stable behavior over a range of 8 mm. Using finite element modeling, dimensions for a bi-stable beam suitable for the MIM are found. The second design uses a disc spring as bi-stable element. This design is a 3D design, and is on the scale of the MIM. An ANSYS model and a database were validated. Using the model and database disc spring with suitable dimensions for the MIM scale was found. Two disc springs in parallel were needed to make a bi-stable compliant grasper. Both the bi-stable beam and the disc spring can be used in the design for a bi-stable grasper. The bi-stable beam is more effectively creating negative stiffness inside a circular space. As a result, it should be able to produce more force and/or stroke in the same volume as a disc spring. This makes the bi-stable beam more suitable for use in a bi-stable grasper than a disc spring.","","en","master thesis","","","","","","","","2012-10-07","Mechanical, Maritime and Materials Engineering","BioMechanical Engineering","","BMD","",""
"uuid:092cfddd-aa07-4e25-ac66-fd51faf33092","http://resolver.tudelft.nl/uuid:092cfddd-aa07-4e25-ac66-fd51faf33092","SmartLEGO: Enrich physical LEGO play","Voncken, R.","Pasman, G. (mentor); Aprile, W. (mentor)","2012","Smart devices have become more integrated in daily life over the past few years. Nowadays they are a fast growing market with rapidly changing technological developments. LEGO noticed that even young children aged between 4 and 6 years are playing with smart devices. To keep up with this new type of play, LEGO wants to explore the possibilities of integrating smart devices into a physical LEGO object. The aim of this study was to find out what children of this age are capable of doing with a smart device and to develop now concepts to enrich the physical LEGO play experience while keeping up to date with the new technical development. During this thesis an extensive literature study has been carried out to learn more about the development of children. Several user studies have been conducted to gather information about what children can do with a smartdevice and what is the essence of the LEGO play experience. The gathered information has been translated into design specifications and four design directions. The final design directions are: smart device becomes LEGO brick, combine physical and virtual play, analyse and enrich gameplay, create and support gameplay. Four concepts were developed based on the four design directions and from these four concepts the SmartLEGO concept was chosen to be further developed. The SmartLEGO concepts makes use of the technical features of a smartphone to create more realistic and inspiring LEGO gameplay. The gameplay encourages children to explore new possibilities by means of constructing and make-believe play. In order to fit different types of LEGO gameplay there was chosen to develop two concepts that use the same interaction but represent different types of LEGO objects. There is a deviation between static and mobile LEGO objects. The different types of objects stimulate different types of gameplay. Eventually a prototype was build to test the concept with the user during several user tests. These tests resulted in recommendations for additional research and improvement for the concept by LEGO. The validation showed that an external stimulus can stimulate creativity among children that are between 4 and 6 years old. The SmartLEGO concept provides children with an excellent external stimulus while it does not interfere with the originated LEGO gameplay.","LEGO; children; play; smartdevices; creativity","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Design for Interaction","",""
"uuid:53c804b1-6179-4bf1-bbf0-0f6f78e9d13a","http://resolver.tudelft.nl/uuid:53c804b1-6179-4bf1-bbf0-0f6f78e9d13a","The development of an in-hand-haptic-feedback device based on magnetorheological fluid","Elfering, T.C.","Rusak, Z. (mentor); Smit, A. (mentor)","2012","During this project, a mobile haptic feedback device, aimed at virtal object representation in virtual reality was developed. The device is capable of providing its users with passive force feedback between their thumb and index finger. The device consists of a magnetorheological fluid damper, suspended between the thumb and the index finger by means of a novel mounting mechanism. In the dampers OFF state, the user’ s movements can contract and extend this damper with relative ease. In the dampers ON state, an electromagnetic coil in the piston of the damper is activated, creating a magnetic field over the fluid in the damper This couses the affected fluid to solidify, significantly increasesing the damper’s resistance. The user’s fingers will sense this increase in resistance when they try to move them towards one another. In the right setting, this increase in resistance between the fingers may be experienced by the user as virtual object contact. By varying the intensity of the magnetic field over the dampers fluid, the damper is able to represent both rigid or ductile objects. The purpose of providing this type of feedback is twofold. It may allow people to experience virtual object contact, as they would in the real world. Previous research has indicated this type of haptic feedback could improve accuracy during virtual object grasping. The presence of this type of feedback may also enable people to disinguish the compliance of different virtual objects. A practical prototype evaluation was held to verify wheter or not the developed device was capable of providing the haptic sensations described above. In this evaluation, participants were asked to determine virtual object contact and to judge virtual object compliance. Due to the large internal resistance of the prototype, the difference between contact and no contact could not be determined for very ductile “objects”. Rigid object contact was detected far more easily. Participants were more adapt at sensing differences between different damper compliance values. The developed device was the result of a study into the field of haptic feedback. At the start of this study, the limitations of current haptic feedback devices were mapped. Simultaneously, a number of smart materials was studied to determine whether the application of one or more of these materials in a haptic feedback device could aid in overcoming some of the limitations found in existing devices. Out of the opportunities found, the creation of an in hand force feedback device aimed at simulating object contact was deemed most interesting. To provide the force feedback needed for this application, the descision was made to use magnetorheological fluid in a linear damper configuration. This choice was made based on the succesfull application of magnetorheological fluid in other haptic feedback devices, on the potentially high power density of magnetorheological dampers and on the relative simplicity of such a damper. Prior to the device’s development, the field of haptic feedback was studied. The purpose of this study with the purpose of identifying opportunities which are currently not or insufficiently fullfilled by existing haptic feedback devices. which could be fulfilled by the application of one or more smart material To come to the final design, a series of sketches was made, detailling potential methods to provide force feedback using a magnetorheological damper. Simultaneously, a calculation model was made and evaluated to determine the optimum geometry for a magnetorheological damper. At the end of this process, an optimised damper geometry was combined with a feasible method of mounting the damper to the hand, forming the final product.","design; haptic feedback; smart materials","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Master of Science Integrated Product Design","",""
"uuid:cd4b8546-d124-4c4c-9ee4-76f1ac5af49f","http://resolver.tudelft.nl/uuid:cd4b8546-d124-4c4c-9ee4-76f1ac5af49f","In-Situ Oil Combustion: An Experimental Study Impact of Reactions in the Processes Perpendicular to the Main Gas Flow Direction","Kartika Surjosantoso, M.","Rudolph, E.S.J. (mentor); Khoshnevis Gargar, N. (mentor); Bruining, J. (mentor)","2012","The objective of this thesis is to investigate experimentally the impact of gas phase reactions during a simple ISC process especially the role of heat and oxygen presence in the system. Heat plays an important role in both air and nitrogen injection experiments because the injected gas needs to be heated first to the set temperature before flushing the system. At a certain temperature, heat induces endothermic chemical reactions. Therefore it is also necessary to include precise descriptions of chemical reactions describing ISC process. However, the application of ISC method in the field is still an issue since it is hard to control the process. This can be related to the complexity observed in the experimental results. One of the difficulties encountering in this experiment is to acquire an evenly distributed heat within the reservoir. This needs further investigation in future work. In the work presented here the chemical reactions occurring during ISC are studied using a T-shaped reactor tube. The vertical part of the reactor was filled with an oil-saturated sand column; through the horizontal part of the reactor at top of the vertical part either nitrogen or air is flown. The experiments with air allow the study of the chemical reactions, which are thought to occur during ISC, while the experiments with nitrogen injection allow the study of the influence of heat on the reactions occurring during ISC. Thereby the focus is on the processes occurring perpendicular to the main gas (air or nitrogen) flow direction. The main results of the experiments are the effluent gas composition, the temperature profile within the vertical part of the reactor and the characterization of the sand and the liquid collected in the cooling trap after the experiment.","in situ oil combustion; experimental study","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","","",""
"uuid:391c0e28-4e76-42ef-8e57-25fb9b69760e","http://resolver.tudelft.nl/uuid:391c0e28-4e76-42ef-8e57-25fb9b69760e","Generic simulation metamodeling: Towards an experimental design environment","Kolenbrander, M.B.","Verbraeck, A. (mentor); Kortmann, L.J. (mentor); Cunningham, S.W. (mentor)","2012","Simulation models are used in many fields to experiment with real-world systems to gain insight into their behaviour. Experimenting with simulation models can be time consuming and costly. In order to save costs, experimenters reduce their scope of research or otherwise conduct less thorough investigations into the behaviour of a simulation model, increasing the risk of overlooking valuable information. A possible solution to this particular problem is metamodeling. Metamodeling is mentioned in literature as a way to reduce the number of required experiments. Only a reduced sample of experiments is run, after which the other results are estimated by certain interpolation techniques. While metamodeling is not new, it is mostly used in academic settings where metamodels are specifically tailored and designed for a specific simulation model or set of experiments. In commercial projects metamodeling has not been used often because of the lack of expertise that is required. A generic, automatic metamodeling tool or environment that allows simulation users to utilise the power of metamodeling can decrease the experimentation time for commercial projects as well as increase the quality of recommendations or decisions based on the results. The aim of this thesis is to find a metamodeling technique that allows this kind of generic use as well as investigating how this technique should work in practice. To achieve the latter, an experimental design environment, or tool, has been designed. By designing an experimental design environment with metamodeling capabilities, the setting in which metamodeling can benefit experimenters can be understood and more insight is given into the challenges surrounding the search for a generic metamodeling technique. The experimental design environment is designed focusing on the user’s pursuit for answers to questions about the system’s behaviour. This is done by focusing on three steps; selecting the input factors the user wants to vary with a certain range, setting up the simulation run (which behind the scenes uses metamodeling), and lastly viewing and comparing results. The way the experimental design environment is designed, allows the user to quickly understand the relationships between the input factors of a system and the results. The challenges that arise when choosing a metamodeling technique that can be used generically and automatically with any simulation model are finding the right metamodeling technique, using the right sampling technique that reduces the number of experiments, and using the right method to assess the quality of the final metamodel. When looking for a metamodeling technique that can be use generically and automatically with any simulation model, the techniques polynomial regression, spline, kriging and artificial neural networks were chosen based on literature. Based on a multi-criteria analysis two techniques were selected to experiment with: Polynomial regression metamodeling and Kriging. These two metamodeling techniques, both having different characteristics as well as using different sampling techniques for reducing the number of experiments, were tested for their accuracy in various situations. Both techniques were applied on eight sets of result data, using a reduced set of this data (using sampling) to create a metamodel in order to estimate the remainder of the data. By comparing the estimated data with the original data, the performance of both techniques was measured. Based qualitative and quantitative analyses it can be concluded that Kriging metamodeling is a suitable technique for generic use in a commercial simulation project. The strongest advantages of Kriging over other metamodeling techniques are the fact that it can be used without any prior knowledge of the behaviour of a simulation model, its overall accuracy and its ability to handle inherent erratic behaviour of discrete event simulation models. These characteristics make it possible to use Kriging as the single metamodeling technique to handle all kinds of simulation models, regardless of the expected behaviour of the responses, without the need for specific metamodeling or simulation expertise. Polynomial regression metamodeling has the drawback of requiring knowledge about the behaviour of the system it tries to estimate, in order to choose the right order for the polynomial it uses. Furthermore it was determined that it was less sufficient in handling inherent erratic behaviour of discrete event simulation models. While metamodeling does not always provide highly accurate results, it can be significantly valuable to experimenters and simulation users. Providing fast results, metamodeling can be used to initially scan a certain area of the design space before focusing on an area of interest. Requiring no metamodeling expertise, this can lead to a significantly reduced experimentation time for commercial simulation projects as well an increased quality of overall project results.","","en","master thesis","","","","","","","","2012-09-08","Technology, Policy and Management","Systems Engineering","","","",""
"uuid:75bc2112-59c6-4818-abfe-e601331cece3","http://resolver.tudelft.nl/uuid:75bc2112-59c6-4818-abfe-e601331cece3","Smart Motions: Reducing the effect of parameter uncertainties during feedforward control of a robotic manipulator","De Vries, M.","Van der Helm, F.C.T. (mentor); Wisse, M. (mentor); Plooij, M.C. (mentor)","2012","The performance of a feedforward controller depends on the accuracy of the internal model used for generating the control action. In this research we focus on the influence of parameter uncertainty on the performance of a feedforward controller. A simulation study is performed on a one and two D.O.F. planar robotic arm to improve the open-loop performance given an internal model with parameter uncertainty.","feedforward; model uncertainty; optimisation","en","master thesis","","","","","","","","2014-08-30","Mechanical, Maritime and Materials Engineering","BioMechanical Engineering","","BMD","",""
"uuid:44087018-fbe5-4614-beb2-df5ed4482a18","http://resolver.tudelft.nl/uuid:44087018-fbe5-4614-beb2-df5ed4482a18","Prediction of liking of functions based on the properties of features on social networking sites","Schüsler, O.M.","Houben, G.J.P.M. (mentor)","2012","When developing a website, feedback from the community is imperative. This is not different for Social Networking Sites (SNS). There is no way however to measure how well the functionality is liked. During this research, a new method- ology is developed that will be able to predict the liking of functions based on features of the site. This will hopefully enable the creators of SNSs to better their sites to increase the number of visitors. For this, first the functions have been de- fined for the 3 current leading SNSs - Facebook, Google+ and LinkedIn. For this list of functions, lists of features were generated by users. With a question- naire, a dataset is generated, from which the relation between the features and functions can be derived by machine learning. In the end, three achievements are gained: better understanding of functions, features and the relationship between each other, that are common to these three SNSs, predictors, which takes ratings from a questionnaire as input, that predict how much a user likes a function, and a dataset containing ratings from 125 users.","Social Networking Sites; Liking; Functions; Predictor","en","master thesis","","","","","","","","2012-07-31","Electrical Engineering, Mathematics and Computer Science","Computer Science","","Web Information Systems","",""
"uuid:003f5644-69f1-42da-b462-2184866c1080","http://resolver.tudelft.nl/uuid:003f5644-69f1-42da-b462-2184866c1080","Flash memory device: Electrical modeling and simulation","Klanderman, R.","Al-Ars, Z. (mentor)","2012","Flash memory, created in the early eighties and based upon EEPROM, has become a very popular non-volatile memory since the start of the millennium. A Flash memory cell consists of 1 MOS transistor with a floating gate. The floating gate (in between the channel and the control gate) is able to trap electrons due to writing mechanisms (e.g. Fowler Nordheim and Channel Hot Electron Injection) and hereby changing the threshold level of the transistor. Flash also has different cell array architectures that define its read and write speed, and geometrical size. The array architectures called NOR and NAND are currently most popular. NOR is advantageous for high speed read and writing, however the NAND architecture is more compact and therefore more suitable for mass data storage. By creating a functional model of a Flash memory device, design of an electrical Flash memory device and its simulation can be simplified. After studying Flash cell models in literature, a Flash cell model and complete memory device will be presented in this Thesis. This study has also led to distinction between ""Static"" and ""Dynamic"" Flash cell models. Static models need a voltage or current source to change the threshold voltage. This results in 2 models, one for writing and another for reading. Dynamic models can use equations as behavioral blocks to ensure a threshold voltage change at the transistor and have one model to represent both reading and writing. In order to show simulation results of a Flash memory device, a 2x2 bit NOR and 1x2 bit NAND will be presented for analysis. Both with a dynamic cell model. Fowler Nordheim and Channel Hot Electron Injection are also taken into account in the presented net lists. The simulations have been done in HSPICE, an industrial version of SPICE (Simulation Program with Integrated Circuit Emphasis).","flash modeling","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Computer Engineering","","","",""
"uuid:6cfbb3e6-8a2d-44fe-8c6c-7beb1cbd0f2a","http://resolver.tudelft.nl/uuid:6cfbb3e6-8a2d-44fe-8c6c-7beb1cbd0f2a","Integrating the online and physical apparel shopping experience","Huang, P.R.Y.S.","Christiaans, H.H.C.M. (mentor); Pasman, G.J. (mentor); Schiet, R. (mentor)","2012","The assignment was to study both the physical and the online shopping channel in order to design a concept integrating and thereby enhancing the physical and online shopping experience of Denim+ as a brand. The integrated solution must be intuitive in navigation and easy-to-use for the future customers of Denim+. Denim+ is a denim lifestyle brand store, set-up in 2010 and is located in Bussum. Denim+ sells jeans, basics and accessories. Next to the physical shop, the web shop was launched in November 2010, selling the same products. The report describes two major phases: the analysis phase and the synthesis phase. The analysis phase explores Denim+ internally and externally. The synthesis phase describes the process of idea generation, concept development and the final concept named PLUS. The internal analysis describes Denim+’ online and physical store marketing mix and branding. Both are evaluated and lead to strengths and weaknesses. Denim+’ most important strengths are the practical fashion and retail knowledge, large assortment with distinctive products and flexible and ambitious mentality. Denim+’ most important weaknesses are the lack of vision, objectives, strategy and differentiating features, slow online channel development and incompatible channel branding. The external analysis consists of three sections: consumer, competitors and environmental factors also known as trends. These sections issue various threats in the market, Denim+ should not ignore, and opportunities Denim+ could grasp. The media and technology opportunities show chances for Denim+ in the social and mobile media, enhanced by the use of intuitively operable screens and consumer data. The opportunities within the brand and product category show a retail environment based on engagement and interaction. This trend highlights that retailers should offer multiple brands and extend their assortment with non-core products. Mass-customization, self service and providing recommendations are shopping trends giving Denim+ concrete opportunities on how to serve the consumer. The fashion opportunities lie within facilitating consumers need to experiment with look and style, share and DIY fashion. The threats show changing ways of shopping online with high return rates and physical with changing store roles. The growing consumer power through technology shows threats for Denim+ which are: consumers’ ease to find substitute products and suppliers, short attention span and demand for ethically principled brand policies. In the synthesis phase I generated ideas based on search fields coming from the strengths, weaknesses, opportunities and threats. The ideas combined lead to six concepts of which the concept based on product scanning scored the best for integrating the online and physical apparel shopping experience. The final concept is named PLUS, which stands for Personally relevant, Look-based inspirator, User convenient Shopping experience. It clearly describes the goals of the concept. PLUS is based on a mobile application that can read product information. This aspect leads to five new features for the consumer: tangi ble POS material, fitting sessions, smart wish list, online clothing closet and online-only items available in the physical store. Roy Schiet (one of the owners of Denim+ and retail expert) says the concept will be appealing to consumers. This will emphasize that Denim+ is innovative, and creates awareness for the physical store, online and vice versa, which is what this assignment is about.","Multi channeling; Omni channeling; Online store; Physical store; Denim lifestyle; Fashion; Retail; Consumer experience; Shopping experience; Denim+","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Conceptualization & Communication","","","",""
"uuid:220b32e7-3961-462b-a670-d7e7a3b8f7dc","http://resolver.tudelft.nl/uuid:220b32e7-3961-462b-a670-d7e7a3b8f7dc","Improving Risk Management Through Knowledge and Experience Sharing","Jonsdottir, E.R.","Vrijling, J.K. (mentor); Leijten, M. (mentor); Verlaan, J.G. (mentor)","2012","","risk management; knowledge sharing","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Construction management and engineering","",""
"uuid:8fb70df1-8f5a-4ad8-b8e6-29bae0229f5f","http://resolver.tudelft.nl/uuid:8fb70df1-8f5a-4ad8-b8e6-29bae0229f5f","Enabling sustainable design at Designit: A case study and toolbox","Magerl, C.A.","Wever, R. (mentor); Calabretta, G. (mentor)","2012","The project investigates the design consultancy Designit to find ways which enable them to do more sustainable design. A research at Designit Denmark and a case study was performed to gain insights into the culture of Designit as well as practical aspects of sustainable design. The result is a toolbox, which can be implemented at the website of Designit. The toolbox has two parts, the Green Pool where inspiration about sustainable design can be browsed, and the Green Wheel where concepts can be evaluated. The toolbox is seen as a first realistic step upon which the toolbox can be further expanded - vertically into the entire organization and horizontally towards the client.","design consultancy; sustainability; toolbox","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Integrated Product Design","",""
"uuid:cf603e28-bd4f-42f6-b72b-32c603fe57b9","http://resolver.tudelft.nl/uuid:cf603e28-bd4f-42f6-b72b-32c603fe57b9","Service innovation for small fashion retail; analysis and design of an innovative service focused on retailers, provided by Philips Lighting","Kikkert, R.S.","Schoormans, J.P.L. (mentor); Calabretta, G. (mentor)","2012","The goal of this report is to present the process and concept design for an innovative service, which will be provided by Philips Lighting and is focused on the retail industry. For this purpose, a high potential target segment has been identified within the retail industry; the small fashion retailers. The service concept design creates easier accessibility to the products of Philips Lighting, provides insight in the effects of the products, product combinations and product solutions and finally it uses the retailer’s preferred channels to do so. In contrast with products, services make use of intangible elements to fulfil the need a consumer has. Using intangible elements brings various challenges, since they are only consumable at one time and often experienced differently per customer. A service always has at least one tangible element, which is the touchpoint. For the customer, the touchpoint are the evidence that the service exists, which makes these tangible elements very important in the design of any service. In reality the border between services and products is not a hard one. Products are often supported by several services, and services may use products. Philips Lighting, one of the three main sectors of Philips, is the provider of the service that is presented. With a turnover of over 7,5 billion euro’s, Philips Lighting is leading in the Lighting industry. The retail department creates a turnover of almost 800 million. Even though slowly more and more products are involving supported services and several services are arising, Philips Lighting is currently strongly product focused. A wide variety of services are already focusing on the retail industry. These services range from simple cleaning services, to total redesigns of the interior. All the services relate to a key activity of the retailer. To figure out the position of the retail in the future, a trend analysis has been executed. It has been identified that many digital channels see a quick rise. As a side effect, the connectivity between these various (digital) channels needs to be agile to be perceived positively by its user. Currently Philips Lighting focuses its sales on large chain retailers and consumers. The small retailers in between are not targeted, while this segment accounts for more than 50% of the retail market. Since the fashion segments is identified as most open to innovative services, it is the largest segment within the retail industry and it has a stable market size, this segment is chosen as a scope for the project. The scope focuses on the European market, based on the corresponding attitude and culture towards technology and services between the countries. The service design uses two process descriptions to ensure both the mental as the physical journey the retail goes through are covered. Initial attention is created by tradiational advertisment directed directly at the retailers or placed in retail related printings like the magazine of a branche association. Further attention and inspiration is created by displaying Philips Lighting products in action at locations that are frequently visited by the retailer. With the use of the internet, retailers can immediately get further informed about the products that are being displayed. An online tool automatically creates a range of light plans for the retailer, based on various effects that can be achieved with the lighting. The retailer only has to choose one, and optionally make the adjustments he wants. Subsequently the retailer can find other retailers in his surrounding that already have the specific or similar lighting products installed. It allows the retailer to not only see the product in real life, but also in environment similar to their own store. It is very likely that the retailer trusts and follows the advices that are given by his colleague. An online tool allows the retailer to further create his personal light plan. The products he has seen in real life are seamlessly added to his profile and easily added to his light plan. In a personal phone call or chat the details of the purchase are discussed and the retailer will be informed about the various supporting services like video workshops about the installment of the products, sharing his light plan online and optionally contact an installer if the retailer does not want to do it himself. The products that are purchased are prepared as if they were meant for consumers. This means they have simple manuals and are as close to plug and play as possible. The online tool allows him to comment on the products he has purchased and to re-order any products in a simple way. Finally the retailer can expect other retailers to visit his store to have a look at his lighting. This creates reassurance, since colleagues are interested in the lighting products the retailer has purchased. An estimated costs analysis shows that it is likely that the service will be profitable. In the expected scenario, the cumulative cash flow will turn positive in the fifth year, even though the analysis is based on the assumption that the first year will not generate a single sale. Both the best as worse case scenario show an IRR of above 10%. The service fits the target group perfectly, since it connects the retailers with its colleagues, the persons they trust the most. For Philips this connection also fits very good, since it dramatically decreases the effort needed from philips to keep the service running. As can be seen in the costs estimation and the blueprint, most elements of the service are preparation activities. Above all, the service provides a seamless journey through the various mental en physical stages of the purchasing process.","service design; retail; Philips Research","en","master thesis","","","","","","","Campus only","2013-08-30","Industrial Design Engineering","Product Innovation Management","","Strategic Product Design","",""
"uuid:145a3691-6c89-4d52-b3e8-e92f952b9cdc","http://resolver.tudelft.nl/uuid:145a3691-6c89-4d52-b3e8-e92f952b9cdc","Actuation of a 450 mm through Wall Wafer Stage","Boots, E.","Ostayen, R.A.J. (mentor)","2012","","Wall Wafer Stage","en","master thesis","","","","","","","","2013-08-30","Mechanical, Maritime and Materials Engineering","Precision and Microsystems Engineering","","","",""
"uuid:7a273a16-d472-4e1a-a5ce-72fbc5f081b5","http://resolver.tudelft.nl/uuid:7a273a16-d472-4e1a-a5ce-72fbc5f081b5","Towards a global implementation of Named Data Networking","Van Adrichem, N.L.M.","Kuipers, F.A. (mentor)","2012","The host-to-host IP model currently supporting the Internet does not suffice in supporting current-day content distribution in the form of content-sharing via peer-to-peer applications, real-time media streaming and social networks. Since the design of IP, the usage of the Internet has changed from a messaging and few-to-few information sharing system to a fewto-many content distribution system where many users request large amounts of overlapping information. Running a content distribution network over a host-to-host network appears to be very inefficient since every piece of content needs to travel the complete distribution-chain from generator to consumer every time it is requested. The result is that identical pieces of information will often redundantly travel the same links and routers. Information Centric Networking tries to solve this problem by proposing route-by-name instead of route-by-address mechanisms. This enables networks to be optimized for contentdistribution instead of connections and allows routers to cache often requested pieces of content in memory. In this thesis we will attempt to solve problems that arise at the introduction of a new globally routeable network, enabling clients and networks to be a full member (both consumer and generator) on a global Information Centric Network. The topics discussed vary from dynamic end-user configuration and generating globally unique names in order to share information on the Information Centric Network, via mapping techniques to decrease routing complexity, to proposing a transition mechanism that dynamically creates IP encapsulating tunnels between disconnected Information Centric Networks. In short, we discuss a multitude of problems which need to be addressed in order to assist the global implementation of an Information Centric Network.","Information Centric Networking; ICN; NDN; Named Data Networking; Named-Data Networking; Named-Data; dynamic configuration; name generation; transition; mapping; internet; global implementation","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Telecommunications","","Network Architectures and Services (NAS)","",""
"uuid:723c8277-f8a4-4f9a-a811-7c8d428ccecf","http://resolver.tudelft.nl/uuid:723c8277-f8a4-4f9a-a811-7c8d428ccecf","Approach to collect leading indicators in major accident areas","Van der Wielen, M.","Warnier, M.E. (mentor); Nijen Twilhaar, G.D. (mentor); Verbraeck, A. (mentor); Jagtman, H.M. (mentor)","2012","Major Accidents have the potential to endanger multiple lives, the environment but also the market position of even the biggest companies in the world. In the past we have seen various major accidents in the Oil & Gas Industry, one of the most recent and best known is the Macondo Blowout a.k.a. Deepwater Horizon Explosion that killed eleven workers and which was followed by an extensive oil leak in the Gulf of Mexico. Fortunately these accidents do not happen very often, but this also makes them difficult to predict. Based on the risk of these kinds of events, Royal Dutch Shell, one of the biggest public oil & gas companies in the world and sponsor of this research, wants to know whether it is possible to develop an approach to improve early detection of errors in the prevention of major accidents. As a result, this research project proposes an approach to detect ‘leading indicators’ for major accidents. This approach is developed and tested in a ‘field’ pilot. The main research question for the project is defined as: How can lead indicators about the state of major incident prevention be collected to gain more information about the state of incident prevention of major accidents? Early in the project it was decided to take an approach that enables everyone, including non?experts to use their smart phones to report on the state of barriers at a location or site where major accidents could occur. The tool that should enable this is called MoBaC, which stands for Monitoring of Barrier Conditions, and consists of predefined questions that focus on safety?critical barriers that should prevent major accident from happening. The major accident areas that are relevant for Shell are identified as:  Process Safety/Asset Integrity  Well integrity  Transport of people by helicopter, airplane, bus or over water  Transport of oil and gas overwater or over the road Due to the time?scope of this of the project it was not possible to look into all of these areas, therefore this research focuses only on ‘Process Safety/Asset Integrity' and 'Transportation of people by bus’. To streamline the identification process for suitable questions and ensure that the questions asked do not mainly focus on ‘personal safety’ a method is derived that can help with this process. This approach is used to derive the questions for the two major accident areas mentioned above and can be summarised as follows: METHOD IDENTIFYING QUESTIONS FOR MAJOR ACCIDENT AREAS: 1. Identify the main direct causes of major incidents within the selected area 2. Per direct cause: identify barriers that should prevent that cause 3. Per barrier: identify possible visible signs that can give an indication of the state of the barrier => this results in a list of potential questions 1. Next to all of the above, subject matter experts should be asked to assess the questions and see whether they ‘miss’ anything. In some cases the remaining questions can be assessed on a scale of 1?4 according to two aspects, visibility and usability/relevance. A pilot project was executed for the area of 'Transportation of people by bus' at the Pearl GTL site in Qatar. The target group consists of 800 people who are required to take the bus every workday. The pilot project was active for more than a month. In that time the questionnaire has been entered 89 times. The results of this questionnaire with respect to the barriers that are defined for this area are scientifically inconclusive; nonetheless the local road safety manager confirmed that he thinks the results have added value for safety at his location. Later a user?experience questionnaire was sent out to all known participants of the bus?transportation questionnaire, which was entered by 16 people. It was found that the majority of these 16 people have in general a positive attitude towards the project, but due to the small amount of participants no leading conclusion can be found for the entire target group. It can be argued that every compromised barrier that is being fixed due to the use of this tool does always decrease the risk of a major accident happening at a given location; nonetheless it is not possible to provide scientific proof that this approach to collect leading indicators can have a risk?reducing effect on major accidents. Overall this project has been a very interesting learning experience and it will be continued outside the scope of this report.","major accidents; lead indicator; leading indicator; barrier; IT tool; questionnaire","en","master thesis","","","","","","","","","Technology, Policy and Management","Systems Engineering","","","",""
"uuid:73758b4c-b29f-4c0c-9457-96993ac8d5b6","http://resolver.tudelft.nl/uuid:73758b4c-b29f-4c0c-9457-96993ac8d5b6","Scanning Ion Pipette with Integrated Piezoresistive Sensor: Design, Fabrication and Characterization","Stoute, R.","Staufer, U. (mentor)","2012","Not available because of confidentiallity.","ion pipette; piezoresistive sensor; piezo","en","master thesis","","","","","","","","2013-11-01","Mechanical, Maritime and Materials Engineering","Precision and Microsystems Engineering","","","",""
"uuid:9e1583fa-ad99-409c-9198-d265e9d85947","http://resolver.tudelft.nl/uuid:9e1583fa-ad99-409c-9198-d265e9d85947","Clothing Inspiration While Searching For Shoes","Bijkerk, B.","Boersema, T. (mentor); Wormgoor, R. (mentor)","2012","This final master thesis is about combining the online and physical shop experience in collaboration with the retail company Omoda Shoes in Zierikzee, the Netherlands. Nowadays, the overall retail market is changing. Especially the internet and mobile retail market are growing very fast and customers are using different type of shops for a purchase. While having both online and physical shops, a company could be able to stand out in this online market. But the problem is that both types of shops operate separately which does not encourage the use of the shops together. Looking into the future of retail, it can be expected that both online and physical channels will remain to exist, but each for different phases within the buying process. A customer focused approach was used during researching the problem. The goal of the research was to explore the customers shoe shopping journey, customers’ needs and influences. During this process customers were involved by an online questionnaire and interviews. During concept elaboration, customers were involved at the experimental method of trial-and-error that was used to judge different online and physical design trials. The results pointed out that customers were looking for clothing while searching for shoes. It became clear that inspiration (by clothing) was lacking in both online and physical shoe shops. A final cross-channel shop concept was created based on inspiration by clothing. This concept brings Omoda’s online and physical shops together by showing clothing to customers to give them inspiration and help them through the shoe shop journey. Customers are able to switch from type of shop whenever they want. The online shop shows inspiration pictures, inspires by showing clothing trends and offers a way of combining clothes with shoes. The mobile shop also shows inspiration pictures and the same trends while searching for shoes. Further, the physical shop contains also inspiration pictures and shows real fashion mannequins that offer the opportunity to compare shoes customers wear with those outfits in a mirror. With the completion of this thesis, eyes are opened to inspire customers in the shoe shops of Omoda. In this way Omoda can become unique in its retail branch. A bigger target group will be reached by implementing this concept.","cross-channel; retail; shopping behaviour","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Design for Interaction - Retail Design","",""
"uuid:fd90f76a-3771-442f-b0d5-31a698aa7008","http://resolver.tudelft.nl/uuid:fd90f76a-3771-442f-b0d5-31a698aa7008","Eigenvalue analysis of the Timoshenko beam theory with a damped boundary condition","Harrevelt, S.D.","Van Horssen, W.T. (mentor)","2012","In this report an attempt is made to analyse how a damped Timoshenko beam is affected by an external force.","Timoshenko beam theory damped","en","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Mathematical physics","","","",""
"uuid:fe63b125-ce24-427c-8493-fa9486438b4b","http://resolver.tudelft.nl/uuid:fe63b125-ce24-427c-8493-fa9486438b4b","Performance assessment of libswift","Schaap, T.M.","Pouwelse, J.A. (mentor)","2012","A performance comparison has been done between libswift and other P2P clients to assess whether libswift can be made the fastest P2P client currently available. A modular testing framework targeted at testing and measuring P2P clients has been developed and has been succesfully used to run several experiments with the clients and to debug and improve libswift. The results mainly compare libswift and libtorrent; uTorrent has been found unreliable under Linux and HTTPS was only used as a baseline measurement. libswift has also been compared to itself with different block sizes. Compared to libtorrent libswift performs quite well, but still suffers from two deficiencies: degrading download performance when many peers try and download the same swarm and large memory usage when confronted with very large files. libswift usually uses far fewer resources than libtorrent, though, while giving similar performance. Especially for use on mobile and other constrained devices or for joining large amounts of swarms libswift seems to be a good choice already. During the assessment several problems in libswift were identified and resolved. In particular a hard limit on the number of files libswift could handle was removed. Making libswift the fastest P2P client can certainly be done in the near future: only two deficiencies remain and libswift already shows several strong points.","P2P","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Parallel and Distributed Systems","","","",""
"uuid:cb7c2441-4d56-4390-b4dd-d56d94cec916","http://resolver.tudelft.nl/uuid:cb7c2441-4d56-4390-b4dd-d56d94cec916","Simulating Barrier Island Evolution: Coupling Process-Based Models","Den Bieman, J.P.","Stive, M.J.F. (mentor); Van Thiel de Vries, J.S.M. (mentor); Baart, F. (mentor); Van Dongeren, A.R. (mentor); Storms, J.E.A. (mentor)","2012","Barrier islands are important features in the coastal zone, among others because they shelter the mainland from waves and storm surge. Thus, the degradation of barrier islands can pose a threat to coastal safety. Hence, there is a societal demand for understanding and predicting barrier island evolution. High energy events, such as storms and hurricanes, play an important part in this evolution, with hydraulic sediment transport causing large and rapid changes in morphology. In the periods between storms, (partial) barrier island recovery takes place, largely driven by aeolian sediment transport on longer timescales. Hence, when predicting the morphological development of barrier islands, both hydraulic and aeolian transport need to be taken into account. Also, both the event timescale of hours to days, and the recovery timescale of weeks to months need to be resolved. Currently, no single numerical model exists that simulates both hydraulic and aeolian transport, though there are models that resolve either one separately. So, to resolve both simultaneously, two models will have to be coupled. The above leads to the two objectives of this thesis; firstly, constructing a coupling between a hydraulic and an aeolian sediment transport model, and analyze physical and numerical aspects of the model interaction. For this purpose the models XBeach and Dune are selected. The coupling is created using the Earth System Modelling Framework (ESMF). The second objective is confirmation of the predictive skill of the coupled model for the evolution of a real barrier island. Assateague Island (MD, USA) is selected, and a combination of model skill score and bias is used to represent the predictive capabilities of the coupled model. From a process point of view, undertow, long wave flow, and increased turbulence due to wave breaking have a significant effect on the sediment transport during storms, and all are represented within the XBeach model. Aeolian transport is less important during storms, because the sand supply is limited by submergence and moisture content. During recovery, aeolian transport does play an important role in transporting the sediment towards the beach and dunes, where it is often trapped by vegetation. The lower wave height during these periods allows for a relatively larger influence of short wave asymmetry, that can lead to hydraulic transport towards the shoreline, creating a sediment supply for beach and dune recovery. This makes the foreshore zone an interface between hydraulic and aeolian processes. The coupling between XBeach and Dune allows the models to exchange information after every communal timestep, thus facilitating dynamic interaction. This is only necessary when simulating recovery periods, for the influence of aeolian transport during storms is assumed negligible. The structure of the ESMF makes it possible to couple multiple models together, requiring only a few adaptations to the structure of the sub-model codes. This also provides the flexibility to add new or replace old models with relative ease. To confirm the predictive skill of this coupled model, a hindcast of six months of morphological development of Assateague Island will be performed. To this end, storms are distinguished from recovery periods, and are simulated in chronological order, the former with XBeach, the latter with the coupled model. The simulations lead to negative skill scores because of a significant overestimation of storm induced erosion. Even when using an overwash sediment transport limiter to reduce the erosion during storms, the skill scores remain negative. It can be concluded that the first objective has been fulfilled, since a coupling between XBeach and Dune has been constructed. Although a hindcast was performed, this could not confirm the predictive skill of the coupled model, so the second objective was not completed.","barrier islands; numerical modeling; model coupling; XBeach; dune","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Hydraulic Engineering","","Hydraulic Engineering","",""
"uuid:332e3fda-52ce-4aa9-9b77-3a0744f38792","http://resolver.tudelft.nl/uuid:332e3fda-52ce-4aa9-9b77-3a0744f38792","CEVA on its way to Purchasing Excellence: The implementation of a Vendor Rating Model","Van Gaalen, B.","Van Ham, J.C. (mentor); Tavasszy, L.A. (mentor); Veeke, H.P.M. (mentor); Van der Pijl, R. (mentor)","2012","","Contract Logistics; Tender design and evaluation; Consumer Distribution; Vendor Rating Model","en","master thesis","","","","","","","","2012-12-31","Delft University of Technology","Transport, Infrastructure & Logistics","","TIL","",""
"uuid:d441cb5f-9cb7-412c-9a6c-1e7f862625f0","http://resolver.tudelft.nl/uuid:d441cb5f-9cb7-412c-9a6c-1e7f862625f0","Interactive Design Studio: A spatial-computing framework fro non-IT specialists","Di Figlia, A.","Dulman, S. (mentor); Pruteanu, A. (mentor); Langendoen, K. (mentor)","2012","In recent years, application domains outside information technology such as architecture have shown an increasing interest in the capabilities of networked systems such as localized computation, reduced power-consumption, and distributed interaction. These capabilities incline the design of interactive environments towards the IT-domain. In particular the employment of large scale distributed systems in interactive designs bring along new challenges for architects/designer such as distributed algorithm design, programming skills, embedded platform knowledge. As a consequence of this new trend, adequate software tools to bridge the gap between the IT-world and the field of interactive design are scarce. In order to fill that gap we propose a framework called Interactive Design Studio(IDS) which aims to provide the necessary tools to hide the technological aspects from the end-user when designing interactive environments. To tackle the problem of handling large scale networks of embedded platforms we are convinced that spatial computing is a promising paradigm. The main reasons are the scalability(network size does not influence node behavior) and resiliency to network dynamics(network is hidden by space abstraction). Therefore we present a spatial computing framework for non-IT specialists. We provide a way to specify agent-level behavior and to generate the corresponding code for a specific embedded platform. In our case, we use the eLua VM enhanced with the necessary spatial computing capabilities. We show that spatial computing is a good methodology for Industrial Design and Architecture. Moreover, we show that spatial computing is possible using off-the-shelf virtual machines for embedded platforms. In conclusion, we demonstrate that IDS succeeds within a certain extent in abstracting or hiding the underlying technological aspects(spatial computing) from end-users.","spatial computing; interactive design","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Embedded Software","","Embedded Systems","",""
"uuid:4b44e2b8-7ab2-4415-8c16-ba774273e4ad","http://resolver.tudelft.nl/uuid:4b44e2b8-7ab2-4415-8c16-ba774273e4ad","Correlation of fracture patterns, lithology and tectonic position in Mesozoic carbonate rocks","Van Oosterhout, D.; Ravestein, T.; Nolte, H.","Bertotti, G. (mentor)","2012","Analyzing core data for fracture analysis is restricted by costs and gives limited information. Outcrop studies with the software DigiFract give a more complete set of information about fractures. The aim of this research is to find correlations between fractures patterns, lithology and tectonic position in the area around Coldigioco, Marche, Northern Apennines, Italy. In this area the current topography consists of two anticlinal structures with thrust origins. These thrusts originated during the Miocene as a result of the Corso-Sardinia-Calabria/Adria collision. The formations in this region consist of limestone and some chert/marl layers. To analyze the fracture patterns there are different ways of statistical processing, including determining fracture density, fracture orientation, fracture height and mechanical unit distributions. By correlating these statistics with lithology and tectonic location, the following can be concluded: The difference in fracture densities between the eastern and western flanks of the eastern anticline are caused by an active axial surface fold. The dense fractured western flank of the anticline is part of a deformed panel and the less dense fractured eastern flank is part of a undeformed panel of the fold. Furthermore one could conclude that the fracture pattern in the undeformed panel of the fold tends to be irregular due to the presence of an axial plane just above this panel. Parts of this panel have already been influenced by this upcoming change of bedding orientation or some parts have already passed this axial plane. The final conclusion related to tectonic position is that on the axial plane of a fold compressive stresses can cause stylolites perpendicular to the bedding. Two prominent influencing factors in lithology are the hardness of the rock and the presence of marl and chert layers. The formations of middle hardness are fractured regular. The opposite can be seen in the other, harder or softer formations. Finally one can conclude that marl and chert layers act as non-fractured or less fractured boundaries and cause bed confined fractures.","fracture pattern analysis; DigiFract software; fracture density; chert/marl layer influence; mechanical unit distribution","en","bachelor thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Section for Applied Geology","",""
"uuid:90934aec-41ca-41f7-a51b-17590bcdfce9","http://resolver.tudelft.nl/uuid:90934aec-41ca-41f7-a51b-17590bcdfce9","Design and development of a dust collecting system full indicator for hand sanders","Salvemini, E.","Hajian, M. (mentor); Van Breemen, E. (mentor)","2012","Skil costumers focus on the quality-price relation at the moment of deciding, which tool they are going to buy. Therefore, Skil products are feature centred. In the case of hand held sanders a dust box is a sign of quality. However, the efficiency of this kind of collector is much lower than the one of a common dust bag. Skil came with the idea ofhaving a dust bag inside a dust box concept. This new concept will keep the efficiency of the bag while giving the user the aesthetics of a dust box. Nonetheless, a new problem arose. The user does not realize when the dust box is full,as the inside of the collector cannot be seen. The assignment for this graduation was to design a mechanical system, which makes the user aware of when the dust collector is full and that can be integrated in a current dust box. This report shows the process followed to came up with the solution to the problem. First, an extensive analysis phase, trying to cover all aspects related with dust collectors, is presented. The market, the user, patents, information from the company, scientific studies, self-performed tests and much more information, was gathered to obtain the criteria for the new tool. Secondly, the Ideation and conceptualization phase. In this section; ideas, their working principles test and their evolution into concepts are presented. Furthermore, those concepts were evaluated and tested as well, in order to see which one fit the current Skil situation. Finally the embodiment phase presents a CAD model, of the chosen concept, and its performance as a final prototype. The outcome of this project was a mechanism, which not only solved the stated problem, but it was also applicable to any Skill sander. Recommendations are given to make the company aware, weather or not, the system should be applied.","full indicator; hand sanders","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product engineering","","IPD","",""
"uuid:a5dc5441-0fa1-4a4e-8da1-2048ba3334e9","http://resolver.tudelft.nl/uuid:a5dc5441-0fa1-4a4e-8da1-2048ba3334e9","The Influence of Tar on the Performance of Solid Oxide Fuel Cells","Van der Kleij, A.","Aravind, P.V. (mentor); Boersma, B.J. (mentor)","2012","""As fossil fuels are depleting, polluting and an increasing source for global conflicts it has become important to find alternatives. It is essential to develop conversion chains that are able to compete with the non-renewable energy sources both technically and economically. Biomass is an upcoming flexible energy source, and has a close to carbon neutral life cycle. In case of combined heat and power production, high system efficiencies can be attained when biomass gasifiers are connected with solid oxide fuel cells. Contaminants form however a thread to successful performance and long-term operation. Tars are one of the main harmful contaminants as they cause carbon deposition, but can be made harmless and converted into heat and electricity using an SOFC. It was chosen to use a model tar (toluene) in combination with synthesized mixtures. Dry operation was compared with wet. The main variables were the temperature (973, 1073 and 1173K) and compositions. Open and closed circuit measurements were performed to evaluate the catalytic and electro-catalytic reactions. Ni/GDC cells were chosen for their resistance towards carbon deposition and placed in a single cell setup. Electrochemical impedance spectroscopy was used to evaluate material changes and polarisation losses. I-V curves were taken to evaluate the performance and degradation. Gas chromatography was used to analyse the anode-off gases and to give an indication of the mechanisms at stake. Syngas as well as biogas were successfully operated under dry and wet conditions, the voltage oscillated but the average remained constant. Power production was found to be possible, although within a voltage bandwidth. Dry syngas performed slightly better than wet syngas. During dry reforming of CH4 it was found that the closer to equimolar conditions the higher the produced power. Carbon deposition was suspected for all syngas conditions at all temperature levels, but it did not influence the short time operation (45 minutes). No degradation was found during a long term (24 hour) tar and syngas operation at 1073K.","","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Process and Energy","","Energy Technology (SPE)","",""
"uuid:b7877dd3-3b11-4016-914f-488feec88bfc","http://resolver.tudelft.nl/uuid:b7877dd3-3b11-4016-914f-488feec88bfc","Numerical Investigations of Coherent Structures in Axial Flow in Single Rod-Channel Geometry","Gurunath, S.","Portela, L. (mentor); Rohde, M. (mentor)","2012","In order to ramp up the conversion ratios and burn-up of nuclear reactors, it is inevitable to go to tightly packed fuel rods in the reactor. These nuclear reactors with tightly packed rod-bundles are characterized by interesting flow patterns, different from the ones encountered in regular channel and pipe flows. The correct prediction and control of the flow distribution is essential for the reactor design and safety assessment, and has been an active area of research in reactor thermal-hydraulics. Apart from the axial flow of coolant parallel to the rod bundles, there exists cross-flow between the sub-channels. The cross-flow promotes homogeneous enthalpy distribution and enhanced mixing between the coolant flowing in the sub-channels. Turbulent mixing is an important phenomenon, which influences the flow and temperature patterns in the rod bundles. Large-scale coherent structures along with transverse flow pulsations have been identified in the rod-rod and rod-wall gap regions. This large-scale structure has a quasi-periodic behavior and is considered an important factor for high mixing-rate. The aim of this work is to get a better understanding of the flow in a rod-bundle. This is done by performing numerical investigations on a simplified rod-channel geometry. The Unsteady Reynolds Averaged Navier Stokes equations are solved using the Computational Fluid Dynamics software OpenFOAM. Extensive benchmark and validation studies were done in order to determine the simulation technique that offers a good balance between computational cost and accuracy. The flow dynamics and the transport and mixing of a passive scalar due to the coherent structures are studied. Different turbulence models were used to study their effect on flow dynamics, and no major differences were observed. Following this, the computationally cheaper k-epsilon turbulence model with wall functions was chosen for the simulations. The time required for flow development in this geometry was significantly higher than that in regular turbulent channel or pipe flow. This led to different results than the ones observed in the experiments and in previous simulation results published in the literature. It was concluded that the flow in the experiments was not fully developed and that probably not enough time was used to allow flow development in the previous simulations. Our results indicate that the shear-layer becomes thinner and the number of structures decreased with flow development, which would explain the higher number of structures found in previous simulations. High values of velocity fluctuations and the kinetic energy due to these fluctuations indicated the presence of structures in the near-gap region. Large-scale three-dimensional counter-rotating sledge-shaped structures were observed via the flow visualization of resolved velocity. These structures were not only restricted to the gap region, but encompassed the entire flow domain. The high periodicity and stability of these structures indicate that they are not turbulence structures. The effect of gap-size on the coherent structures was studied, and this study suggested that the presence of more than one mechanism for the formation of these structures. A critical gap-size was obtained, at which the intensity of the structures has a maximum value, and a cut-off gap size was identified, at which a transition takes place between the two mechanisms. The coherent structures were found to play a significant role in both the transport and mixing of the passive scalar. The contribution were similar to that of the turbulent diffusion. The simulations indicate that the effect of the coherent structures on the transport and mixing of a passive scalar is of the same order of magnitude of the effect of the turbulent diffusion.","turbulence; coherent structures; URANS; rod bundle; OpenFOAM; nuclear reactors","en","master thesis","","","","","","","","","Applied Sciences","Radiation, Radionuclides & Reactors","","Chemical Engineering","",""
"uuid:92f240dd-67ec-4f61-9210-4763d7b8a90a","http://resolver.tudelft.nl/uuid:92f240dd-67ec-4f61-9210-4763d7b8a90a","A low noise, low power dynamic amplifier with common mode detect and a low power, low noise comparator for pipelined SAR-ADC","Astgimath, S.P.","Long, J.R. (mentor); Bult, K. (mentor); Van der Goes, F.M.L. (mentor)","2012","This thesis presents a high gain, low noise and low power dynamic residue amplifier and a low power, low noise dynamic comparator designed in TSMC 28nm process for a two step Pipelined SAR-ADC. The cascoded integrator dynamic residue amplifier (CIDRA) achieves a gain of 30dB with THD of 47dB (11 mV pp input). The input referred noise across tem- perature and process corner is 55 µV and it operates at a frequency of 500MHz while the energy consumption is 390 fJ. The low power and low noise pseudo-latch preamp dynamic comparator (PLPDC) shows a delay of 250pSec for a differential input of 16 pV and consumes 91 fJ (current is 91 µA for 100 MHz clock) of energy. The input referred offset is 4 mV (?).","dynamic amplifier; dynamic comparator; pipelined SAR-ADC; noise analysis","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","","",""
"uuid:e5dcf5fd-564c-4c26-817c-da2d4cf21325","http://resolver.tudelft.nl/uuid:e5dcf5fd-564c-4c26-817c-da2d4cf21325","Greening Information Technology (IT) Infrastructures: Designing a green IT assessment methodology that supports IT decision-makers contribute to corporate responsibility strategy","Kalsheim, J.C.P.","Brazier, F. (mentor); Appelman, J. (mentor); Stougie, L. (mentor); Beulen, E. (mentor)","2012","Introduction There are several issues and opportunities with regard to information technology (IT). On the one hand, the IT industry is responsible for a large amount of global GHG emission, water pollution, depletion of scarce materials, growing volumes of e-waste and the largest release of hazardous waste worldwide. On the other hand, IT is an important source of cost efficiency and competitive advantage. Examples of economic opportunities of making IT greener are cost saving, risk reduction, innovation and prevention of resource restriction. Moreover, the social impact of the IT industry is immense. IT might be manufactured from minerals from military conflict zones or produced under derived working conditions. These examples of environmental, economic and social implications of IT illustrate that IT should constitute a significant part of an organisation’s sustainability policy and corporate responsibility (CR) strategy. But how can an IT decision-maker contribute to this? It is expected that a framework providing insights into the greenness of the hardware IT infrastructure of an organisation could support IT decision-makers contribute to the overall CR strategy of organisations. Consequently, the research question of this thesis project has been formulated as follows: What generic framework based upon environmental and economic life cycle assessment criteria could be developed to assess the relative greenness of the hardware IT infrastructure of an organization as a step towards a comprehensive corporate responsibility strategy? In essence this research addresses environmental and economic aspects of IT, often referred to as green IT. Emphasis is put on environmental sustainability and costs associated with the physical IT infrastructure supporting business applications through processing, transferring or storing computer programs or data. This is referred to as the greening the hardware IT infrastructure. The purpose of this research is to understand how an IT decision-maker can contribute to CR strategy by addressing several environmental issues efficiently. These environmental issues are related to water use, energy use and raw material use, greenhouse gas (GHG) emissions and generation of electronic and electrical waste (WEEE). Research methodology To structure and guide the explorative research of designing a new framework, the design science research by Hevner et al. (2004) is applied. The design science research is an outcome based research methodology that focuses on designing artefacts. Basically this methodology consists of three types of iterations; relevance, rigor and design. To establish rigor and relevance literature was reviewed from the knowledge base (rigor) and design requirements were analysed from stakeholder interviews (relevance). This information constitutes the academic and practical grounding of the new artefact. To design a new framework three design iterations were carried out; two formative validations by expert panels and one operational validation through a case study. Results The outcome of the design process was a new framework that can be used to assess the greenness of an organisation’s hardware IT infrastructure. The framework consists of several viable performance indicators related to energy use, water use, GHG emission and generation of raw material waste at organisational level (see Chapter 7). The operationalization of these can be found in the functional design in Chapter 8. The functional design describes how the performance indicator scores can be estimated and aggregated into assessment criteria scores and an index. The assessment criteria were defined as follows: 1. Water use over the life cycle of hardware IT (m3) 2. Energy use over the life cycle of hardware IT (MJ) 3. Generation of waste over the life cycle of hardware IT (kg) 4. Greenhouse gas emissions over the life cycle of hardware IT (ton CO2) 5. Costs over the life cycle of hardware IT (euro) The index is entitled the Hardware IT infrastructure Greenness (HITIG) index. The HITIG index can be determined by applying the weighted sum method. This requires normalization and weighing of assessment criteria. At the moment normalization is not possible as an unbiased reference score cannot be established. Evaluation, reflection and recommendations Although three design iterations were carried out to design the new framework, the framework design process and the artefact have several limitations. First, the expert panel reviews have several limitations. The panels were small and expert opinions about which design requirement constituted “core requirements” differed between the panels. Second, the case study research had several limitations. Data used to estimate some of the performance indicators in the case study was deprived. Moreover, the external validity of the framework is limited as only one case study was executed with a limited number of hardware IT infrastructure units. Third, a limited number of aspects related to sustainability have been incorporated in the new framework. Environmental issues have been limited resource usage (water, energy and raw materials), GHG emission and waste generation and economic aspects have been limited to costs. Social implications of sustainability have not been included at all. Fourth, measuring performance is challenging and using indicators to assess the greenness of hardware IT is a reductionist tool that possibly cannot encapsulate the complexity of sustainability and greenness of IT. Lastly, several experts from KPMG have been involved in the definition of design requirements and the expert panel reviews. This could have biased the framework, but this cannot be completely proven. To deal with the shortcomings of the new framework several things could be done. The external validity of the framework could be enhanced by carrying out additional case studies in which different units of analysis are investigated. The functional design could be improved by incorporating more accurate and up-to-date data. The framework could be further expanded to incorporate additional economic and environmental aspects and social implications of IT. Land use, hazardous waste, quality and working conditions are examples of four aspects that could be incorporated in the framework. Furthermore, the framework could be accompanied with a management process to ensure an organisations’ progress is measured over time. The management process could be based upon the plan-do-check-act (PDCA) cycle. Implementing a new management process or integrating the framework in an already existing environmental management process could require awareness of green and sustainable IT within an organisation as well as a clear governance structure. Conclusion and further research The new framework can be used to determine the greenness of the hardware IT infrastructure of an organisation as a step towards a comprehensive CR strategy when incorporated in a measurement process. The framework supports achieving the desired green IT assessment criteria scores. Organisations can use the outcome of periodical measurements from the framework to, if required, adjust their policies in order to achieve the CR goals as part of their CR strategy. The framework can be used to assess green IT progression related to energy use, water use, generation of raw material waste, GHG emission and costs over the life cycle of hardware IT. Assessing the relative greenness of the hardware IT infrastructure of an organisation would require implementing the framework in a continuous management process. Measuring the hardware IT infrastructure greenness with the purpose of benchmarking results, it is recommended organisations apply the same calculation methodology to ensure consistency and comparability of results. For further research it is recommended to investigate how social aspects can be incorporated in the framework to ensure a more balanced contribution to CR strategy. It is also recommended to improve the quality of certain data used in the functional design and to extend the scope of environmental and economic sustainability aspects in the framework. Furthermore, research should focus on improving the framework through additional refinement cycles. Particularly important are additional case studies to test the general applicability of the framework, further refine the functional design and evaluate the use of the framework over time as part of a continuous management process.","green IT; hardware IT infrastructures; corporate responsibility; IT decision-makers","en","master thesis","","","","","","","","","Technology, Policy and Management","Systems Engineering","","","",""
"uuid:912bdd63-4f18-49d3-83d0-e2307bddf232","http://resolver.tudelft.nl/uuid:912bdd63-4f18-49d3-83d0-e2307bddf232","A project management tool for multidisciplinary design teams","De Wit, P.","Mulder, I.J. (mentor); Aprile, W.A. (mentor)","2012","This thesis describes the design of a project management tool for multidisciplinary design teams. Background: Complex projects require multidisciplinary design teams, which are harder to manage than teams with people from one discipline. To control the resources within projects, an adequate software package is chosen for each issue. This kind of symptom management drives the introduction of resource management tools. This ad hoc behaviour results in different software packages that are not tailored to the people involved in the projects. The problem is that use of these tools requires extra effort and discipline from the people involved, with the consequence that some tools find only limited use or are not considered useful at all. Project managers and designers use a plethora of highly specialized software tools and can hardly be burdened to add another five just to check project progress; this is why integration of these systems is needed. A trend to take into account in designing an integrated solution is that people from the client side and the people involved in project management from the company side will use other devices than desktop PCs to stay involved in projects, such as smartphones and tablet computers. Goal: To improve project management in multidisciplinary design teams and prevent overspending of the resources of projects. Assignment: Design a tool that focuses on the core of the problem, with project management as a leading perspective and the people involved in the project management process as primary users. Method: The core of the problem is analysed through a short literature study on the general knowledge on project management, a survey and interviews on the internal context and people at the company and a short market study on available solutions. By being embedded in the target group, it was possible to follow an iterative process of ideation and evaluation with the target group. The design is evaluated through a presentation and a user test with a browsable prototype with actual project information. Research results: Project leaders are not motivated to use many software packages for project management, as they already have the different tools to do their work with. Because they only limitedly use the available tools and do not trust information, as it is not up-to-date, they are not conscious about the status of a project. This is the main cause of overspending of resources. To become conscious about the status of the project, the target group needs to reflect on relevant, up-to-date information. They need to be allowed and encouraged to input the most important information to be able to reflect on information. The following factors were identified as related to project management: money, time, activities, files, communication, decisions and general project-related information. Further in the report these will be called the resources of project management. Design: The design proposal focuses on the integration of the different resources of project management in a project-focused solution. It is built on two pillars: shown information depends 1) on the user and 2) on the level of detail. Showing only information that is relevant to the user reduces the amount of noise. Different levels in information, showing more detail when zooming in, prevent from information overkill for the user and enables the user to keep overview. Features like live tiles and semantic zoom known from Windows 8, speed up usage and fit the need for different levels of information. To ensure cross-device scalability, a web-based platform is proposed. The design provides a way of documenting important information on each topic of project management. Conclusions and recommendations: The target group thinks the tool will help prevent overspending but I advice a step by step introduction to let the user get used to the system and keep the costs limited and the advantages high. Due to the limited time frame and complexity of the project, testing the design with a real project was not possible yet. Furthermore optimization in the interactions of data entry should be made.","project management; multidisciplinary; design teams; tool; user interface; cross device","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Design for Interaction","",""
"uuid:97ee2e9e-9c0b-40f2-8865-b8f477ffa80a","http://resolver.tudelft.nl/uuid:97ee2e9e-9c0b-40f2-8865-b8f477ffa80a","Play like Messi; design of a product for making ball mastery exercises more fun.","Geerts, E.","Gielen, M.A. (mentor); Vegt, M.J.H. (mentor); Bartholomeus, E.J.C. (mentor); De Graaf, M. (mentor)","2012","Almost every youth football player dreams about being as good as very technical skilled football players, like Messi. Coaches often believe that these great players are simply gifted and that their skills are beyond the average player. Wiel Coerver, a Dutch football manager, analyzed these great players in slow motion video and came to the conclusion that many of their skills could be broken down and taught to most players, regardless of age or experience. Aiming to improve individual football skills and produce better attacking players and teams, Coerver developed a way to teach football. The foundation of the Coerver method is ball mastery. Ball mastery exercises are designed to get a feeling with the ball and to use all parts of the feet. His method is worldwide the most used skill teaching program and a lot of famous clubs like Arsenal, AC Milan and Real Madrid use his method in their academy programs. The philosophy behind the method is that a youth player can develop his technique only if he has come sufficiently enough in contact with the ball during his football education. But the amount of contacts with the ball during football matches and football practices doesn’t suffice. To become a better player they need to practice at home. At the most youth players train two hours a week and play one short match in the weekend. Naturally there are children who apart from this kick a ball now and then. But children nowadays have less free time and spend their time on other activities than sport, like watching television. Most young football players nowadays are not motivated to do ball mastery exercises on a regular base. Repeating the same exercise over and over again requires a lot of effort and is not fun. And fun is the single most important element in developing a football player. First the Coerver method was analyzed. The analysis showed what really was important about the exercises. The analysis showed what real ball control is and what it takes to become as skilled as Messi. Next a literature study of several motivational theories was performed. Children have different motivations for participating in sports. The study was performed in order to know how to motivate children to do ball mastery exercises. The analysis showed the different components of motivation and how theses can be applied in the project. The next phase was the idea generation phase. I came up with several ideas. The two best ideas were chosen to develop further into concepts. Two prototypes of the concepts were developed to test the concepts. Based on these tests a decission was made to develop one concept further into a detailed product design. The detailing phase embodies the final product design. The concept was optimalized and detailed. A prototype of the concept was developed to perform a user test. The last part of the project embodies the marketing strategy of the product. A business case was written in which the market is explained and how the product will be positioned within this market.","design; play; football","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Integrated Product Design","",""
"uuid:c9a3e9fd-ec74-490a-a15c-c7f14e528a24","http://resolver.tudelft.nl/uuid:c9a3e9fd-ec74-490a-a15c-c7f14e528a24","Maximal Flexibility and Optimal Decoupling in Task Scheduling Problems","Endhoven, L.A.M.","Aardal, K.I. (mentor); Witteveen, C. (mentor); Klos, T.B. (mentor)","2012","This thesis focuses on the properties of (multi-agent) task scheduling instances represented as Simple Temporal Problems (STP). By defining a subclass STP$_{\prec}$ of STPs that contain these task scheduling instances, existing algorithms for arbitrary STPs can be improved if applied to task scheduling STPs, allowing arbitrary schedules and temporal decouplings to be created more efficiently. With the introduction of a new flexibility metric in this thesis, a Linear Programming (LP) formulation as well as an alternative Maximum Flexibility Algorithm is given to create maximally flexible open schedules from which an optimal temporal decoupling can be derived. This thesis also contains a proof that in task scheduling instances, contrary to intuition, an optimal temporal decoupling does not reduce the flexibility of the system. In order to ensure fair decouplings or open schedules for either the tasks or the agents, three types of egalitarian flexibility problem formulations are presented including LP formulations to solve these problems.","scheduling; decoupling","en","master thesis","","","","","","","","2012-08-24","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","Optimization","",""
"uuid:7d2ae701-d670-4f9f-ba1f-92dcfb5fed79","http://resolver.tudelft.nl/uuid:7d2ae701-d670-4f9f-ba1f-92dcfb5fed79","Sedimentation-velocity in jet induced flow","Siteur, W.J.","Van Rhee, C. (mentor); Talmon, A.M. (mentor); Biesheuvel, M. (mentor); Van der Schrieck, G.L.M. (mentor)","2012","Embedding of subsea pipelines for protection purposes is usually done in a ‘Trench – Install – Backfill’ operation. The pipeline can also be embedded after it is installed on the seabed. This method is called post-trenching. When using a trailer suction hopper dredger for post-trenching, a large water jet erodes the soil underneath the pipe creating a temporarily trench in which the pipeline can sink. Large steel pipelines are inflexible and need a considerable free span to sink to the desired depth. The length of the trench is limited as the eroded sand that is brought in suspension starts to settle in the trench when the velocity of the suspension decreases. To be able to predict the length of the trench, the sedimentation velocity in jet induced flow is investigated in this research. The research describes the experiment series that is performed to investigate the behavior of a trench that is created by a vertical jet flow, trailing over a sand bed. The focus is on the sedimentation part of the trench. Concentrations and flow velocities are measured to determine the shape of the trench, the distribution profile and velocity profile. The experiments show a clear relation between the depth of the trench and the length that the trench is open. A deeper trench (due to a higher pressure or lower trail velocity) results in all experiments in a longer trench. The near bed concentration and the sedimentation velocity do not change a lot for different settings of the jet. To see if the theory on the sedimentation process can represent the post-trenching process, a calculation model is made that uses the theoretical concentration profile to calculate the sedimentation velocity. A good similarity was found between the model and the experiments. The experimental research on the sedimentation velocity in a trench that is created in a post-trenching process, indicates that sedimentation velocity is largely independent of the jet parameters. To make the trench longer, it has to be deeper to lengthen the path that the bed has to travel. A test with a second run over the bed proved highly effective due to the high porosity of the sand that settles in the first run, the maximum excavation depth is twice the depth of the first run. By implementing a pipeline in the experiment it is investigated if the pipeline has an influence on the flow conditions and sedimentation velocity.","post-trenching; TSHD; sedimentation; jets","en","master thesis","","","","","","","","2014-08-29","Civil Engineering and Geosciences","Hydraulic Engineering","","","",""
"uuid:2a9c3075-a679-4f61-89f4-24cf5a984398","http://resolver.tudelft.nl/uuid:2a9c3075-a679-4f61-89f4-24cf5a984398","Face Recognition System","Almuhamadi, A.","Rothkrantz, L.J.M. (mentor)","2012","In this thesis a research about a face recognition system is presented. The system uses a database of images to identify individuals. The starting point is a huge database of “known faces”, the FERET database. If a new face is presented the system has to decide whether this face is a member of the database or not. The matching of a face can be realized using the eigenfaces algorithm. Applying PCA (Principal Component Analysis) the database can be reduced to a finite number of eigenfaces, such that every face can be approximated by a weighted sum of eigenfaces. Every face can be represented by a column of elements and a distance measure is used to compute the distance between columns. In this thesis a face recognition system has been implemented and tests are performed. Two algorithms PCA (Principal Component Analysis) and ICA (Independent Component Analysis) have been implemented and the test results are compared with each other.","face recognition; pca; ica","en","master thesis","","","","","","","","2012-09-03","Electrical Engineering, Mathematics and Computer Science","Media and Knowledge Engineering","","Interactive Intelligence Group","",""
"uuid:84ff0f8e-ec0a-4b77-8fa9-9df7eaef6b60","http://resolver.tudelft.nl/uuid:84ff0f8e-ec0a-4b77-8fa9-9df7eaef6b60","Implementing and evaluating a simplified transistor model for timing analysis of integrated circuits","Zheng, X.Y.","Berkelaar, M. (mentor)","2012","Static Timing Analysis (STA) is one approach to verify the timing of a digital circuit. The currently used Gate Level Model (GLM) has limitations on performing STA for circuits when taking process variations into consideration. The transistor level model is developed taking the statistical factors into account. This thesis presents an implementation of the simplified transistor model in Verilog-AMS such that the model can be installed as a compiled model in existing commercial circuit simulators, such as Spectre. A direct comparison between the proposed transistor model and the sophisticated Berkeley Short-channel IGFET Model (BSIM) is presented. Furthermore, the transistor model is extended with process variations awareness for statistical timing analysis. The polynomial curve fitting scheme is proposed in this thesis to improve the model accuracy. The evaluation results indicate that the proposed method has approximately 70% improvement in terms of estimating one of the components i.e., drainsource current Ids for the statistical transistor model.","Static Timing Analysis; Verilog-AMS; transistor level model; spectre; polynomial curve fitting; statistical timing analysis","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Computer Engineering","","","",""
"uuid:770a3117-a069-43e7-9306-f4b5fb5f14e9","http://resolver.tudelft.nl/uuid:770a3117-a069-43e7-9306-f4b5fb5f14e9","Recognize sustained competitive advantage: A comparison in the automotive industry out of an investors’ perspective","Barnhoorn, J.W.","Den Hartigh, E. (mentor)","2012","How could the ability to sustain competitive advantage of a market leader in the automotive industry over its direct competitors be measured by using publicly accessible information? As is found in the research, it seems that a good individual factor performance is not a necessary and not a sufficient condition to maintain superior financial performance. Hence it is very hard to measure the ability to maintain superior performance by assessing a single factor. Instead, the combination of factors market share (growth), corporate reputation, R&D intensity and financial resources (health) seems to be a necessary but not sufficient condition to maintain superior performance. Therefore, the combination of factors provides stronger evidence for a firm’s ability to maintain superior financial performance. For that reason, it might be a better way to use the combination of factors to predict the ability of a market leader to maintain its consistent superior financial performance. It should be noted that a good performance in the combination of factors is not a panacea towards consistent superior financial performance as in the case of VAG. Additionally, major issues are still under consideration regarding this relationship. First, the assumption is made that the companies could be compared, while this might not be the case. Second, other competitive advantage factors not investigated in the study could have caused or contributed to the consistent superior financial performance of Toyota and many exogenous factors could have significantly affected that performance. Third, based on the evidence found in this research, it could very well be that the relationship of the combination of factors and performance is mutually dependent. Fourth, it is assumed that a company has one competitive strategy, while a firm might actually have different strategies that each target different rivals. Fifth, due to the illusiveness of the concept sustained competitive advantage it is assumed that consistent superior financial performance could be used instead, while they are actually two different constructs. That being said, predicting the ability of a market leader to sustain its consistent superior financial performance seems to be complex and is still not thoroughly understood. However, note that none of the below-average financial performers had a strong performance in the combination of factors. Based on that knowledge, the suggestion could be made that a strong performance in the four factors at least gives the long-term investor some indication of the ability to maintain that financial performance at most. In other words, a good performance in the four factors might increase the chances that the market leader is capable to maintain its consistent superior financial performance over time and therefore contribute to the assessment of the long-term investor.","sustained competitive advantage; competitive advantage; strategic management; automotive industry; consistent superior financial performance; superior performance","en","master thesis","","","","","","","","","Technology, Policy and Management","Technology, Strategy & Entrepreneurship","","Management of Technology","",""
"uuid:30745465-2c44-4b77-95be-1bdf251cd0a1","http://resolver.tudelft.nl/uuid:30745465-2c44-4b77-95be-1bdf251cd0a1","Economic feasibility of offshore service locations for maintenance of offshore wind farms on the Dutch part of the North Sea","De Regt, D.N.","Aardal, K.I. (mentor); Gijswijt, D.C. (mentor)","2012","The trend of highly energy-efficient, low carbon economies leads to high targets for renewable energy production in 2020, with main contributions by onshore wind, offshore wind and biomass. Many offshore wind farms have to be built to meet these targets. These wind turbines will be built farther and farther away from the coast. When a failure occurs, the maintenance crew has to travel farther and therefore needs a longer good weather window. Since these longer windows occur less often than small good weather windows, waiting times until a good weather window appears will probably be larger for these wind turbines. As long as the maintenance crew can not reach the failed turbine, this turbine cannot produce power and will thus not provide revenue. To reduce the downtime caused by these weather waiting times, a service island can be used. This is a fixed point at sea from where maintenance can take place, where engineers can stay and spare parts can be kept. To determine an optimal location for such a service island, the problem can be written as the Weber problem. The problem is to find the point for which the weighted sum of distances to given points is minimized. Using the wind farms or wind turbines as given points, and the ratio of weighted power as weights, this problem can be solved with the Weiszfeld algorithm. This algorithm finds a solution by using a converging sequence, based on the first-order necessary conditions for a point to be optimal. Since the objective function is strictly convex, the Weiszfeld algorithm finds the global minimum. In this solution all the maintenance for all wind turbines is done from this location, even of the ones that are closer to a port than to the service island. Because transportation time is to be minimized this might not be the best location for the purpose of a service island, and for this reason a generalization of the problem is considered. By adding more service locations, a port can be incorporated in the solution and each wind farm or wind turbine is assigned to one service location. The problem is to find the points for which the sum of distances to the given points, with the corresponding allocation, is minimized and is known as the unconstrained continuous location-allocation problem. The objective function of this problem is neither convex nor concave, which can cause a large number of local minima. If the number of new locations is unknown, the problem is NP-hard, but if the number of new locations is known, the problem is polynomial solvable. The problem can then be solved with the MALA algorithm. This algorithm allocates each wind farm to the closest service location and then solves the problem for each service location individually with the Weiszfeld algorithm. This procedure is repeated until no further reduction in total cost can be made. With the solutions of the MALA algorithm, the maintenance during the lifetime of the wind turbines is simulated. Hereto failure rates en repair time distributions are used to simulate failures and repairs. Four maintenance categories are considered for failures of different components of the wind turbine. It is assumed that there is only one maintenance crew available and that each maintenance category has its own vessel with its own weather specifications. Wind and wave heights of the period 2001 until 2010 are used to simulate the wind and wave pattern. This simulation gives insight into the availability of wind turbines and the influence of service islands. The presence of a service island increases the availability of the wind turbines and increases the number of repairs. A cost comparison is made to determine when a service island is profitable, considering the cost of an island, the kilowatt hour price and the losses caused by the downtime of turbines. The maximum investment budget increases when the kilowatt hour prices increases, but also the total cost involved increase. Therefore the profitability of a service islands depends on the (expected) kilowatt hour price.","Weber problem; location-allocation; wind turbine; maintenance","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Optimization","","","",""
"uuid:87477af2-2152-4d70-9831-c8ae3a754425","http://resolver.tudelft.nl/uuid:87477af2-2152-4d70-9831-c8ae3a754425","Step-by-Step Three-Dimensional Modeling and Visualization of an area in the southwestern part of France (in the French Subalpine Basin).","Schootstra, J.","Blom, J.C. (mentor)","2012","Detailed mapping and 3D structural modeling of the area around St. Nazaire le Desert, in the French Subalpine Basin, which structures had not been modeled previously, was performed in order to understand its structural evolution. The completed 1:25,000 scale mapping of the 52km2 area, reveals various structural domains based on regional structural elements. The dominant structures of the area are a thrust fault, stretching from the south to the north, which developed along the weak rocks of the Marnes Bleues formation and the Montange d’Angèle, which is the highest peak in the area. The model is built on the present-day structure of the basin and comprises 8 horizons within the Upper Jurassic to Middle Cretaceous rocks. The modeling consisted out of different parts: - Constructing multiple geological cross sections, which were checked for consistency and physical viability. - Creating a three dimensional model out of the sections and other field data such as maps. - Restoring and balancing of the three dimensional model, in order to determine its geological and physical viability. These steps resulted in a potential model for the area of interest, which ensures geological and physical viability. The restoration showed that the area had a 37,3% bigger area before deformation. As a final point it can be concluded that all structures originate from the collision of the Iberian Peninsula with the southern part of France, and the subsequent collision of the Apulian with Eurasian plates. Both dominant directions, respectively North-South and West-East, can be perceived.","3D structural modeling; 3D modeling; French Subalpine Basin; Three-dimensional modeling; Geology; Structural geology; Balancing; Restoring; Geological","en","bachelor thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","","",""
"uuid:ce462d85-c142-40c6-aa71-75dac8ca71a3","http://resolver.tudelft.nl/uuid:ce462d85-c142-40c6-aa71-75dac8ca71a3","The evaluation of two different PAC operations in combination with submerged ceramic MF membranes in surface water treatment","Cao, Y.","Rietveld, L.C. (mentor); Heijman, S.G.J. (mentor); Vrouwenvelder, H. (mentor); Lu, P. (mentor)","2012","Powdered Activated Carbon (PAC) has been successfully used in conjunction with membrane microfiltration (MF) to reduce taste, odour, colour and other concerns caused by organic material present in raw drinking water sources. PAC addition also significantly reduces the extent of fouling in membranes. And the operation of continuously dosed PAC before membrane filtration is widely applied in drinking water treatment while the operation of PAC precoated on the membrane is a new approach. This research, therefore, aims at evaluating the membrane fouling on these two different PAC operations. Water from the Schie canal in Delft was coagulated with Iron (?) Chloride and enhanced with PAC, then filtered through a ceramic membrane. The trans-membrane pressure was monitored during filtration. Samples of the raw water and the permeate water were collected and analysed for DOC and UV254, while LC-OCD tests were carried out on the collected samples as well. In addition, the the backwash water and chemical cleaning solutions after soaking membrane were analysed. The PAC in the continuous dosing channel was dosed before flocculation and the membrane was frequently backwashed every 19 minutes for 1minute. However, the PAC in the precoating channel was precoated on the membrane before the experiment and operated without frequent backwashes. The results show that the membrane fouling in the continuous channel was more severe than that in the precoating channel which was mainly concluded from the recovery of TMP. That is because the different PAC addition modes lead to a different cake structure on the membrane surface. The cake layer in the continuous channel was mostly non-backwashable while it was easy to be backwashed in precoating channel. Recovery in the precoating channel was quite good with a recovery of 99.2% while the continuous channel presented a normal recovery of 85.5%. The DOC and UV254 removal for these two operations was similar. Also, the LC-OCD results of the backwash water and the chemical cleaning solution reveal that, if ignoring the cake fouling, the total fouling for the two operations were not too much different while big difference existed in compositions of NOM. Specially, about 40% of the neutrals fraction and 35% of humic substances fraction were found in sodium hydroxide solution after the membrane had been soaked 24 hours in continuous channel. Whereas, the first two important foulants in precoating channel were humic substances and bio-polymers, with approximate 33% and 19% fraction, respectively.","pre-coat PAC; TMP; NOM; cake fouling","en","master thesis","","","","","","","","2012-09-10","Civil Engineering and Geosciences","Water Management","","Sanitary Engineering","",""
"uuid:c05b4760-04b5-4773-acea-b8cd496c5e23","http://resolver.tudelft.nl/uuid:c05b4760-04b5-4773-acea-b8cd496c5e23","Combining TestFrame with Web Services: An automated testing approach","Tjon Tsoe Jin, T.R.","Gross, H.G. (mentor)","2012","The software testing method currently used by the IT consultancy company Logica is the TestFrame method. This testing method is used for example on testing Web Services. Currently, the combination of the TestFrame method with Web Services is still in an infant stage. This thesis analyzes and models the current application of the TestFrame method on Web Services and defines a new method for Web Service testing in general. The new method, the Automatic Web Service Mapping (\awesome) method defines various forms of automation of the Web Service testing process. This new method is combined with the TestFrame method and Web Services, generating a new approach to applying the TestFrame method on Web Services. Part of implementing the new method is implementing a proof-of-concept application, called the \WSDLToTestFrame Application. A Case Study is performed in which the new approach compared to the original approach is evaluated. Evaluation is achieved by comparing the Test Results and the required manual intervention needed of both approaches. Based on the comparisons, the accuracy of both approaches could be measured against each other. The Case Study shows that the error-prone factor decreases and that in some areas development effort decreases linearly with the new approach compared to the old approach.","TestFrame method; Web Services; automated testing; AWeSoMe method; WSDL2TestFrame; case study","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Software Engineering","","","",""
"uuid:89986485-470b-45ab-879f-a38f6ab2d9bf","http://resolver.tudelft.nl/uuid:89986485-470b-45ab-879f-a38f6ab2d9bf","Phase unwrapping algorithm using edge detection and statistical cost functions","Soni, N.K.","Hooper, A.J. (mentor)","2012","Phase unwrapping algorithm for InSAR","InSAR; Phase unwrapping","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience and Remote Sensing","","","",""
"uuid:4f40a0f8-690e-4d20-8073-efa0a8b0b4cb","http://resolver.tudelft.nl/uuid:4f40a0f8-690e-4d20-8073-efa0a8b0b4cb","How to contribute to body awareness through physical interaction by design","Vosmaer, A.M.","Sonneveld, M. (mentor); Jepma, E. (mentor)","2012","This project starts with an analysis. Here, the design field will be explored by means of a literature study, user studies and a self-reflection study. The analysis aims to obtain a better insight in the subject. This is necessary in order to find out where the potential leads lie for design. Apart from that a good understanding of the subject is required, so a proper assessment can be made whether physical interaction (ph.i.) is an appropriate means to stimulate mindfulness (mf) and whether design can provide a contribition there. Subsequently I shall look how ph.i. and design can play a role in the stimulation of mindfulness. Based on the three types of study (literature study, user study and self-reflection study) a number of interesting leads for design have been identified, such as ‘finding your own path’, ‘train the body/mind shift’, ‘connection’, ‘grounding’, and ‘inner guidance’. Based on that framework I shall present a design goal and a vision, that will function as the starting point for the design. The goal of the design is to contribute to the self-awareness process by designing a product that stimulates advanced feelers to follow their own path in life. My vision is that this could be accomplished by increasing their sensitivity regarding their body. The product should aim at making the users more aware of their own bodies and to make them more sensitive to what is taking place within their bodies. By becoming more sensitive you come closer to your own feeling and you learn to feel what you want and what is good for you. You understand your body and your inner voice better and better. That way your life receives more direction from your own feelings instead of following a rational path. The product should aim to teach the user to take over the function of the product itself. The function of the product is to guide you to your inner world and to stimulate body awareness, resulting in awareness of your inner voice that can lead you on your own path. In the design explorations a description is presented of various methods that are used as an explorative ideation; whatsapp brainstorming, brainstorming concerning feet, ideation by means of personas and scenarios. Here a number of design paths are followed in parallel, in order to investigate what the design could contain for the various leads that appeared from the analysis, to contribute to the creation of the design goal and sharpening up the vision. These paths are about grounding, connection, your own path, your feet, respiration and balance. The explorations lead to a focus on a product that works, combined with respiration to come to the final concept. That development is described in the chapter on conceptualisation. An in-depth understanding of the experience process is obtained by designing with the use of scenarios. Three scenarios are presented. They contributed to the defining of the various interaction phases in user actions and product functions: sensing, approaching, communicating respiration, withdrawing, guiding the respiration and withdrawing altogether. These are illustrated in the concept idea storyboard, where the interactions are further defined. In the interaction character design, the various elements are explained that describe the character and the behaviour of the product-user interactions. This shows the way in which the product performs something. This will be done per interaction phase, also for a number of other interaction components that are of interest for the character design, like the development of the relationship over time of the product and the user. These interaction elements are described with the use of metaphors. From those a number of interaction qualities are derived: empathic, gentle, free, smooth, supportive and unobtrusive. These are used to translate the design concept to a more tangible level into tactual design elements. In the tactual design elements the physical interactions will be translated to tactility suggestions for design, whereby I aimed at translating the intended tactile experience and the interaction qualities to tactual properties and bodily sensations. This was done by means of an iterative design process, with the use of small evaluation experiments. These serve for direct evaluation of potential design options and provide suggestions how the intended interaction could be designed. The suggestions serve as explanations and inspiration for the designer who will continue with the design brief. This helps her/him to translate the design brief into a more clearly-defined product design. The final proposal acts as a design brief, where a definition of the concept is presented, followed by an overview of the features, character design and suggestions for the expression of the tactual experience. The storyboard concludes this chapter, illustrating the usage of the product in daily life. The reports is rounded off with an explanation how the findings are expressed in the design.","body awareness; mindfulness; physical interaction; design; respiration","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Design for Interaction","",""
"uuid:ed582f9d-2d93-48d1-8b81-3711fd22742c","http://resolver.tudelft.nl/uuid:ed582f9d-2d93-48d1-8b81-3711fd22742c","Computing the Spectrum of the Confined Hydrogen Atom","Kästner, K.","Van Gijzen, M.B. (mentor)","2012","This thesis is about the numerical approximation of the spectrum of the confined hydrogen atom. The energy levels and wave functions of the hydrogen atom are modelled by the corresponding eigenvalues and eigenvectors of the Schrödinger equation with Coulomb potential. At first different discretisation techniques for the hydrogenic Schrödinger equation are analysed. These include the finite difference method and the finite element method. Then appropriate methods for the solution of the discretised eigensystem are discussed. These include the Lanczos method, the implicitly restarted Arnoldi method and the Jacobi-Davidson method. A programme for the automatic computation of eigenspectra is implemented and numerical experiments are conducted to exemplify the theory. The programme is further on used to compute the spectrum of the hydrogen atom and several aspects of confinement are systematically investigated. These include the size and shape of the cavity as well as the position of the nucleus therein. It is shown that with increasing confinement all energy levels diverge towards positive infinity and that higher energy levels are affected first with decreasing domain size. Degeneracy is partially retained under confinement if the nucleus is positioned in the centre of the domain, but the spectrum becomes non-degenerate if the nucleus is shifted.","hydrogen atom; Schrödinger Equation; Coulomb Potential; singularity; energy level; spectral line; partition function; wave function; quantum confinement; finite element method; adaptive mesh refinement; large sparse eigenvalue problem; Lanczos Method; Implicitly Restarted Arnoldi Method; Jacobi-Davidson Method","en","master thesis","","","","","","","","2012-09-14","Electrical Engineering, Mathematics and Computer Science","Applied Mathematics","","COSSE Computer Simulation for Science and Engineering","",""
"uuid:d55b4e80-1a38-4979-a61f-603f9ad969b0","http://resolver.tudelft.nl/uuid:d55b4e80-1a38-4979-a61f-603f9ad969b0","Financial Sustainability of Rural Water Supplies in Western Kenya: Comparing technology types and management models","Adams, A.","Rietveld, L.C. (mentor)","2012","Introduction In order to improve people’s health worldwide, many efforts have been made in order to meet Millennium Development Goal 7c: reducing by half the proportion of people without sustainable access to safe drinking water and sanitation. Kenya is in the top ten of countries with the largest population without access to safe drinking water (UNICEF and WHO, 2012). Because most of these people live in rural areas, large investments are done in the Kenyan rural water supply. But recent studies show that many of the new water supplies stop functioning within a few years after implementation (MWI, 2007 and RWSN, 2007). Causes for this low ‘post-construction sustainability’ can be technical, institutional, financial, social or environmental. One of the most critical factors which is mentioned in literature is an adequate financing of operation and maintenance. This Master Thesis is about the post-construction sustainability of rural water supplies in Western Kenya, with a specific focus on the financial part of it (or financial sustainability). In the rural water supply practice in Western Kenya, several water supply technologies exist. Some of these technologies require hardly any operation and maintenance (O&M), like springs, surface water catchment, rain water catchment and a well without a pump. These technologies are not included in the current research. Remaining technologies are a handpump and a motorized pump, both used for groundwater pumping. Apart from the differences in technologies, several management models for rural water supply exist within Western Kenya: community management, government management, private management and institutional management. The latter one is not included in the current research because at these locations serving the community is in general not the main purpose. As the access to clean and safe water in adequate quantities is recognised as a human rights issue in Kenya (Constitution of Kenya, 2010), mechanisms for finding sustainable service delivery is a key national priority. As different management models are likely to result into different levels of sustainability, government of Kenya is in search of a most sustainable model for Kenyan context. Objective The objective of this study is to compare the financial sustainability of rural water supplies in Western Kenya. Within this comparison the aim is to compare different technology types, different management models and different combinations of these two. The final goal is that this comparison can be used by the Government of Kenya and other supporting entities in the development of policies and projects for the rural water supplies. Methodology Data for this study is collected during interviews with the responsible persons for the water supplies. Data is collected about service level, O&M, financial management, cost recovery and finances. Service level includes system functioning, water quantity, walking distances and water quality. O&M includes who is responsible for the daily operation and pump check and for the maintenance arrangements and the days it takes between a breakdown and a repair. Financial management includes: responsibility for the finances, water tariff, tariff structure, bank account, bookkeeping and service cut-off for non- payment. Cost recovery includes the practice of the payments, the extent in which the income covers the O&M costs and whether replacement is expected to be a problem on the long term. The finances include the yearly income, costs and costs per user. To all above mentioned factors scores are assigned depending on the output per criteria. The scores are also given a weighing factor. In this way, for every water supply a weighted score can be determined for all the four sustainability categories. In total 27 handpumps and 25 motorized pumps were evaluated. Conclusions and recommendations Out of all handpumps, the locations with community management and the locations with combined community and government management scored low. The communities were not able to collect enough money to keep the system functioning on the long term. The private managed handpumps scored good, especially in terms of cost recovery and quick response to breakdowns. The motorized pumps scored low at the locations with combined community and government management and at the locations with government management. At the combined managed motorized pumps the responsibilities for O&M and financial management were not clear. At the government managed motorized pumps the payments were not good enough to cover the costs. At the community managed motorized pumps, the committees were well organized but they did not manage to make all users pay. At the privately managed motorized pumps, the responsibilities for O&M and financial management were not clearly defined but the financial situation was good. There was enough money for the O&M and for replacement on the long term. Comparing the two technologies, the handpumps score higher on cost recovery and the motorized pumps score higher on O&M and financial management. At the handpumps it happens more often that the regular money collection is neglected. The responsible entities at the motorized pumps have more need to be organized because of the daily need for staff and money for e.g. fuel refilling. A negative side of the motorized pumps are the high costs per user per year, about nine times higher than at the handpumps. Comparing the four management models, the differences were not big. The community managed locations have difficulties with making people pay. At the combined managed systems the responsibilities for O&M and financial management are not clear. At the government systems the costs (including high salaries of government staff) are too high for the amount of users. The privately managed systems score slightly higher, especially in terms of cost recovery. Because of the fact that the water quantity is not sufficient at many locations and the walking distances are large, more water supplies are needed in the research area. It is recommended to focus more on handpumps than on motorized pumps for new water supplies. The reason for that are the high yearly costs at the motorized pumps. These costs make the motorized pumps less suitable for the rural areas of Western Kenya, where domestic income is low and people are not open to pay for their water. In some situations, with low water tables or high population density, a handpump is not feasible and than a motorized pump can be a good option for rural water supply. It is also recommended that action is taken in order to improve users’ willingness to pay. Four recommendations are: - Activities for economic development like job creation and microfinance projects. When people get to spend more, they become more open to pay for water. - Training in communities about the importance of clean water, which is not free. This includes basic insight in costs of water supply technologies. - Training for responsible entities about dealing with sanctions against non-payment and about making finances more transparent. In order to improve community management it is recommended that costs and responsibilities are shared within communities, local authorities and the central government. In the current situation, especially the tasks of the local authorities are not fully recognized: financing a part of major repairs of water supplies, monitoring the performance of individual facilities, conflict and problem resolution and retraining of mechanics and communities. For their monitoring task, the current study and other studies are used to constitute a basic half yearly performance monitoring. Since the private management model scores high on financial sustainability, it is recommended that the Government of Kenya and development partners pay more attention to this option. In order to create a situation where private management is a serious option, several aspects need to be considered: - The government need to contribute in investment costs. For e.g. the handpumps, they can contribute in the same way as in the current programmes with the community managed handpumps where the government pays 65% of the investment costs. - Community sensitization is required about the option of a private handpump. People need to know about this option. And they need insight in the costs and possible revenue. - Training is required for private owners of a water supply about water supply technologies, maintenance and dealing with financial management. - Formal recognition and regulation of such private investors is necessary as they will be running water systems as businesses.","rural water supply; sustainability; operation and maintenance; kenya; management models; handpumps","en","master thesis","","","","","","","","2012-09-11","Civil Engineering and Geosciences","Water Management","","Sanitary Engineering","",""
"uuid:cf4793ba-8232-4004-99f0-6db3d321d64e","http://resolver.tudelft.nl/uuid:cf4793ba-8232-4004-99f0-6db3d321d64e","A new sanitation system for slums in urban dense areas","Melgarejo Fuentes, M.A.","Crul, M. (mentor); Roscam Abbing, E. (mentor); Talsma, L. (mentor)","2012","Around 2.6 billion people in the world do not have access to proper sanitation solutions, leading to many social, economical and health related problems. This report elaborates on “Clean Alliance” a product-service-system based in the provision of adaptable toilet booth availability supported by a waste processing Mini Multi Product Plant (MMPP). This project is elaborated as part of the TU Delft chapter of the Reinvent the Toilet Challenge of the Bill & Melinda Gates Foundation. The main objective of the challenge is to incentivize the development of sanitation solutions based on new technologies at an affordable price. The TU Delft proposed to develop a Mini Multi Product Plant (MMPP) in which human excreta could be processed and transformed into valuable outcomes. The core technology in this system is plasma gasification by which human excreta can be destroyed and transformed into energy in a fast an efficient way. This report elaborates on the product-service system of this MMPP in the context of the urban slums in Delhi, India. People in these slums are forced to practice open defecation, affecting with this the entire urban environment. The final design it’s based on field research and expert interviews developed in this region of the world. The final solution comprises a flexible communal sanitation system based on the provision of adaptable toilet booth availability in slums depending on the hour of the day. The system proposes fixed and mobile communal facilities enabled by the energy and resources processed by the MMPP out of human excreta. An innovative service platform and business model based in mobile networks is proposed for enabling the system. A new brand, communication, payment and tracking system are elaborated as part of an integral sanitation solution. These innovations aim at changing the way sanitation is perceived in India and in the world. A technological roadmap and implementation strategy based on social, technological and business aspects is included and presented as a basis for further developments and application of this system in the future.","design; sanitation; toilet; india; product service system; plasma gasification","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Design for Sustainability","",""
"uuid:71aaa96d-358e-4945-91d9-1b1e4efe745f","http://resolver.tudelft.nl/uuid:71aaa96d-358e-4945-91d9-1b1e4efe745f","Examining the performance of integrated care pathways: On designing a method for healthcare performance quantification","Boon, M.","Cunningham, S. (mentor)","2012","","integrated care pathway; healthcare procurement; competition; performance quantification","en","master thesis","","","","","","","","2012-09-01","Technology, Policy and Management","Policy Analysis","","","",""
"uuid:870b099f-0fe1-4e02-a30d-a31f59f6f2b9","http://resolver.tudelft.nl/uuid:870b099f-0fe1-4e02-a30d-a31f59f6f2b9","Repositioning Happy People juice cocktail","Nijs, F.M.","Schoormans, J.P.L. (mentor); Bakker, S. (mentor)","2012","Healthy People is a small Dutch company founded in 2006 and located in The Hague. The company sells different types of fruit juices in the chilled juice section of most Dutch supermarkets and is mainly known for their super fruit juice range. These juices are made of fruits that contain a high amount of antioxidants, which contribute to better health. Since the company does not have its own production facilities, their products are produced in external factories in The Netherlands, Belgium, Germany and Finland. The company comes up with ideas for new products and purchases the fruit themselves in order to guarantee a high quality product. Recently, the company has introduced a new product: Happy People juice cocktail, a non-alcoholic cocktail in the flavors Mojito, Piña colada and Margarita. The product is sold in a 1 liter carton package at the ambient juice section of a few supermarkets in The Netherlands. This product differs from the company’s other products, as it has its focus on fun instead of healthiness. Therefore, the product is introduced with the new brand name “Happy People”. Since the company does not use consumer research they do not have clear information about the product perception by the consumer, the consumption moments of the product and the way of consuming the product. In order to gather this information nine semi-structured interviews are done with consumers of different ages, from which some are alcohol consumers and others not. During this interview respondents are asked questions about different types of beverages. Besides, they have to give their opinion about the product before tasting and after tasting. Several tasks are included in the interview in order to understand the perception of different types of beverages and different types of packaging. The results show that the flavors Mojito and Piña colada are evaluated as tasty. However, the packaging is perceived as being incongruent with the product that it contains. With the insights gained from the qualitative research three concepts are generated: Concept 1: the festive alternative for alcohol Concept 2 : the easy and convenient basis for mixing cocktails Concept 3: the current product Happy People juice cocktail The three concepts are described in a story that highlights the benefits of the concept. An online questionnaire is used to test the potential of the three concepts. A total of 93 respondents participated in the questionnaire, where every respondent had to answer a set of questions about one of the concepts. The results did not show a clear preference of the respondents for one of the concepts, but the research gives some other interesting insights. The respondents of 30 years and older, score higher on buying intention for all concepts compared to the younger respondents. Besides, to women it is a higher benefit that the product is non-alcoholic than to men. This shows that women in the age of 30 to 60 years old are a good target group for the product. Since non-alcoholic is an important benefit to them, concept 1 is chosen to continue with. The respondents indicated that a 275 milliliter glass bottle is the type of packaging that fits concept 1 the best. The production costs of this packaging are higher than the current carton packaging, but consumers are willing to pay a higher price for glass packaging, especially when they buy the product for a special occasion. To stimulate consumption in social settings and to make distribution more convenient the product will be sold in a multipack of four bottles. With the new type of packaging and a higher consumer price, Happy People juice cocktail fits better in the alcoholic beverage section of the supermarket. Since non-alcoholic cocktails are a new type of product in the Dutch supermarket, which do not fit existing categories, the company should create a new product category. The name for this new category will be party drinks. This new category and the brand Happy People have to be placed in the mind of the consumer by using public relations, product demonstrations, price promotions and advertisements in retailer magazines.","consumer research; positioning","en","master thesis","","","","","","","Campus only","2013-08-29","Industrial Design Engineering","Product Innovation Management","","Strategic Product Design","",""
"uuid:746edced-3c5f-4c96-99d0-5ee852ce6f3e","http://resolver.tudelft.nl/uuid:746edced-3c5f-4c96-99d0-5ee852ce6f3e","De supremumfout van de Grenander schatter","El Bouhaddani, S.","Lopuhaä, H.P. (mentor)","2012","In de toegepaste statistiek spelen dalende kansdichtheden een grote rol. Denk aan kansmodellen voor de levensduur van artikelen of risico's voor levensverzekeringen. Om deze risico's af te dekken is het cruciaal om over goede schattingsmethoden voor deze onbekende kansdichtheden te beschikken. Als de steekproefgrootte uit een dalende kansdichtheid naar oneindig gaat, convergeert onder een aantal voorwaarden de supremumafstand tussen deze dichtheid en zijn `beste' schatter, de Grenander schatter, naar een standaard Gumbel verdeling. Er wordt onderzocht in hoeverre de resultaten bruikbaar zijn voor eindige steekproefsgrootte. Ook worden een aantal interessante opmerkingen gemaakt die van belang zijn bij de praktische toepassing en verder onderzoek.","Grenander; Maximum likelihood; non-parametrisch schatten","nl","bachelor thesis","","","","","","","","2012-09-11","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","Statistics","",""
"uuid:c9fe7348-f2f6-4ac9-a775-b57c2691bdfe","http://resolver.tudelft.nl/uuid:c9fe7348-f2f6-4ac9-a775-b57c2691bdfe","Handbike simulator","Gulpers, J.","Molenbroek, J.F.M. (mentor); Vegt, N.J.H. (mentor)","2012","This report presents the design research, concept development, user test and final design for the handbike simulator. The handbike simulator is an addition for treadmills developed by ForceLink which allows handbikers to exercise on the treadmills with realistic opposing forces. Next to that it enhances the treadmill experience by offering different sensorial elements like wind, video and audio. Design research Through literature research on treadmills, interviews with handbikers and the development of theoretical model of the forces involved in handbiking, the initial problem of missing opposing forces was studied. With the theoretical model of forces involved in handbiking, a method was developed for analyzing how much wind friction force a handbiker experiences outside. With statistics from a handbiker about the average speed, average power and specifications of the handbike, an estimate can be given on the average amount of wind friction force, without the need of the wind tunnel. This model was verified with a test where the actual opposing forces of a recumbent were measured. During the literature research, several comparable studies on force simulation for treadmills were found. It was concluded that force simulation by means of mechanical tethers or slope has great potential, but that it is likely that slightly different forces have to be simulated than the actual forces experienced outside. This is due to difference in how the force is applied to a person. This meant that after developing a means for simulating force and calculating the force that has to be simulated, a test has to follow to study this effect and adjusting the actual force that has to be simulated for a satisfactory experience. From the interviews it was concluded that handbikers want a realistic and reliable training device. Independence and safety are also important issues. The most important quality of handbiking itself is the sensation of speed and should be a focus point for enhancing the treadmill experience. Concept development With the conclusions from the design research, the ideation phase started. Several brainstorms were done on two topics: simulating opposing forces and enhancing the treadmill experience. For simulating opposing force an idea was selected for further development which uses a fitness weight stack. For enhancing the treadmill experience, several ideas were selected on different sensorial fields. An idea with fans for actual wind was selected. Video projection of handbike environments were selected as well as LED strips for visual information about speed and performance. Finally the addition of sound was also selected. A prototype was built of all selected ideas for testing purposes. The prototype offered two forms of force simulation: a pulling force by means of a fitness weight stack and already built in slope function. The prototype also included a fan, video projection, LED strip and sound which were all programmed in to react to the speed of the treadmill. User test With the prototype a user test was setup. The first part of user test was to determine the how much force had to be simulated and which form of force simulation was preferred (slope force or pulling force). The second part of the user test was to evaluate the ideas for enhancing the treadmill experience. For the first part of the user test it was found that user had no preference towards pulling force or slope force. Also, users didn’t experience slope force as riding uphill, but just felt an opposing force. It was therefore concluded that slope force was the best solution for force simulation, since this didn’t require any changes to current treadmills. It was found that found that users required an average slope force of 22,6 Newton. For the second part of the user test it was found that the combination of wind from the fan and the modulated sound of wind greatly enhanced the experience. Users strongly related these two different sensorial inputs to each other, which made the treadmill experience more similar to handbiking outside. Next to that the wind created by the fan, also functions as a cooling mechanism for the handbiker. The video projections together with the LED strip were also a strong combination for enhancing the treadmill experience. With the video projection, users could imaging driving through the displayed environment. The LED strip was perceived as an extension of the video projection, with running lights passing by the user in their periphery. Objects by the side of the road on the video projection seemed to pass by them, while they were riding further on the displayed road. Final Design With the results from the user test the final design was made. A Harris profile was made for all the new elements on the treadmill to make sure none of the elements conflicted with each other and make find the most optimal overall solution. A final concept drawing was made for the handbike simulator. Finally a 3D model was created, which includes all the new parts and their measurements for the handbike simulator.","handbike; treadmill; simulator; wind friction force; enhancing xxperience","en","master thesis","","","","","","","Campus only","2013-08-29","Industrial Design Engineering","Industrial Design","","Master of Science Design for Interaction","",""
"uuid:df32d6be-c58c-4e69-b52d-23a10b29b19c","http://resolver.tudelft.nl/uuid:df32d6be-c58c-4e69-b52d-23a10b29b19c","Iterative solutions to sequences of Helmholtz equations","De Gier, J.M.","Van Gijzen, M.B. (mentor)","2012","We consider sequences of linear systems of equations that follow from the differential equations that describe the acoustics of a car, where the solution to a single linear system corresponds to the pressure perturbations that are caused by acoustic waves of a certain frequency. We consider several iterative numerical methods which belong to the class of Krylov subspace methods and that solve these linear systems. In addition we investigate a particular type of so-called preconditioning, which is a specific procedure that rewrites the system into a form that is more suitable for the numerical methods.","sequence; Helmholtz; IDR(s); IDR; shifted; Laplace; preconditioning","en","master thesis","","","","","","","","2012-08-29","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","Numerical linear algebra","",""
"uuid:9ea7cdf8-ae8b-4131-8647-c07794fe4a20","http://resolver.tudelft.nl/uuid:9ea7cdf8-ae8b-4131-8647-c07794fe4a20","Real-time Position and Attitude Determination of the Stratos II Sounding Rocket","Tong Minh, B.","De Mooij, E. (mentor)","2012","Currently, the student amateur rocket association Delft Aerospace Rocket Engineering (DARE), is designing a small sounding rocket to carry payloads to over 50 km, the Stratos II. Proper operation of this rocket will require an on-board position and attitude determination system. In this thesis, it will be researched how this position and attitude determination can be performed. In essence, the research can be divided into three main topics: simulation, measurement and estimation. Flight estimation is the main goal of the research, while simulation and measurements are prerequisites to estimation. A measurement system with low-cost sensors has been designed and built, and during calibration the performance of these sensors has been established. This measurement system has flown in an actual small sounding rocket, the Stratos II concept launcher, and acceleration, angular velocity and atmospheric pressure data have been acquired. Several estimators have been researched, from which the extended Kalman filter was selected as the most suitable to estimate the position and attitude. The accelerometer and gyroscope measurements are used to propagate the state, and the other measurement data to improve the state estimate, and to estimate various noise factors of the sensors. Measurements are generated from simulations of nominal and non-nominal flights, with nominal and non-nominal sensors, to verify the performance of the estimator. It was found that both the flight trajectory, as well as sensor noise factors such as bias and non-orthogonality strongly affect the estimation result. As only coarse requirements on the position and attitude determination system are available, it cannot be concluded with certainty that the developed measurement system and estimator are suitable for the Stratos II. However, preliminary analysis performed in this thesis, indicates that this is the case. Furthermore, in this thesis clear guidelines are established to improve the estimator performance, should the developed system not satisfy the final requirements.","stratos; navigation","en","master thesis","","","","","","","","","Aerospace Engineering","Astrodynamics and Space Missions","","","",""
"uuid:2a4b7b89-018f-4f60-bd85-dfbf21116e93","http://resolver.tudelft.nl/uuid:2a4b7b89-018f-4f60-bd85-dfbf21116e93","Strategy of Positioning DSM in Photovoltaic Industry","Xin, W.","Hultink, E. (mentor); Reinders, A. (mentor); Flipsen, B. (mentor)","2012","Photovoltaic (PV) technology has gained lot of attention these days, given the consideration of energy security and safety, as well as environmental pressure. As part of renewable energy technology, PV holds the potential to answer to the issues; like the increasing energy demand especially in urban environment and rural electrification. DSM as a sustainability-driven material innovator is trying to align its innovation to address food and energy security issues. PV industry gives DSM a good opportunity to serve solution(s) in tackling energy security. However, DSM has not yet established a clear and strong market proposition in the PV industry. That is why knowing the future of this industry and how DSM could contribute in such a development is crucial for DSM at this stage. The main purpose of this project is to identify the role/value proposition of DSM in the future of Photovoltaic industry. In order to answer this question, intensive investigation of current PV industry (external research) is the first step. What is the business ecosystem of this industry? Which are the key stakeholders and their visions of the industry? A future vision has been created based on external research and case study. This vision serves as a potential focus for the industry development in the future, indicating on which segment of the power market PV technology development should concentrate. According to the future development, DSM could better prepare itself and establish its own market place by delivering unique value propositions. In the future, there will be a great deal of energy mix and PV technology will certainly be part of it. As for PV technology, rather than building up power plants in the deserts (remote area), the development focus lies on providing power to building infrastructure (especially in urban environment). By identifying the trend/direction of future industry development, DSM could be proactive and generate solutions ahead of the market to challenge the key players in the industry and become the driving force and the enabler of innovation in PV industry. Based on the future development of PV industry, one solar module concept in DSM idea-pool has been identified during this project, which could be considered as potential stepping-stone for DSM to establish its role in the industry by fulfilling upcoming needs of industry development. A technology roadmap at the end of this document shows how DSM could capture the trend and fulfil needs step by step.","value proposition; photovoltaic industry; DSM; strategy","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product Innovation Management","","Master of Science Strategic Product Design","",""
"uuid:bb698b0c-3168-4322-b951-05bfa2f04e9b","http://resolver.tudelft.nl/uuid:bb698b0c-3168-4322-b951-05bfa2f04e9b","Technologies and Business Model Explorations for Risks and Performances Management in Dutch Commercial Buildings","Liu, Q.","Simonse, L. (mentor); Silvester, S. (mentor); Ray, N. (mentor); Fluks, P. (mentor)","2012","Priva is a Dutch company in the field of indoor control and automation. Its two main business segments are commercial building control and greenhouse control. In the commercial building segment, Priva’s business currently specializes in Heating, Ventilation and Air Conditioning (HVAC) control, floor control and energy management.However, although Priva’s products are energy saving and contribute to improving the indoor climate, some problems still exist. The pre-defined energy savings and comfort targets are not always met, and the hardware is not adjusted/ replaced until the end of its life-cycle period, which means the optimal time is missed. In a lot of cases, extra money is spent with no corresponding improvement in comfort, energy savings, health or hardware lifecycle index.This project proposes a way to solve the problems stated above by innovations from the viewpoints of both technology and business. In this case, the project objective is defined as: Technological-Oriented Business Model Design Based on Building Automation Technologies for Risks and Performancse Management in Dutch Commercial Buildings.","New Building Control and Management System; Service Business Model Development; Risk Management; Performance Management; Indoor Environment; Dutch Building Industry","en","master thesis","","","","","","","Campus only","2013-08-29","Industrial Design Engineering","Product Innovation Management","","Strategic Product Design","",""
"uuid:8f2867a1-1441-470c-be26-40be7df3f657","http://resolver.tudelft.nl/uuid:8f2867a1-1441-470c-be26-40be7df3f657","Finding Time-Optimal Trajectories for the Resonating Arm using the RRT* Algorithm","Loeve, J.W.","Van der Helm, F.C.T. (mentor); Wisse, M. (mentor)","2012","At the Delft Biorobotics Lab, a research project is started whereby it is the goal to create robotic arms that have the skills and the design to perform repetitive tasks in a natural dynamic manner. Within this project an energy efficient two degree-of-freedom robotic arm is designed, the so-called Resonating Arm. This thesis focuses on finding the time-optimal movements (around obstacles) for the Resonating Arm. These time-optimal trajectories are found with the RRT* algorithm, a novel asymptotic optimal motion planning algorithm.","RRT*; resonating arm; time-optimal","en","master thesis","","","","","","","","2012-09-28","Mechanical, Maritime and Materials Engineering","BioMechanical Engineering","","BMD","",""
"uuid:4e36121c-da15-46ab-953e-d6a87d1d4271","http://resolver.tudelft.nl/uuid:4e36121c-da15-46ab-953e-d6a87d1d4271","Performance Analysis of Middleware for Component Based Robot Control Software","Van der Hoorn, G.","Gross, H.G. (mentor); Wisse, M. (mentor)","2012","The design and implementation of robot control applications is complex: the enormous diversity in hardware, people and software leads to issues with productivity, maintainability and reusability. To cope with these challenges, robotics is adopting software engineering techniques, and in particular Component Based Software Engineering (CBSE). With the main rationale for this transition being CBSE's many advantages, the impact on the performance and efficiency of control applications has not received a similar amount of attention. In light of this, this study investigates the effects of componentisation on the performance of robot control applications, with particular attention to the influence on latency, jitter and throughput. The evaluation consists of two parts: first, synthetic benchmarks are used to assess the capabilities of two popular robotics middlewares -- the Robot Operating System (ROS) and the Open RObot COntrol System (OROCOS), selected for their support for the dataflow, publish-subscribe and remote procedure call interaction styles. The second part consists of a case-study, in which a monolithic AIS message decoder is componentised and implemented on both middlewares. Then, six variants of the resulting component system -- one for each of the interaction styles, plus two special configurations -- are benchmarked, and the effects on throughput, latency and jitter are analysed. Synthetic benchmark results indicate a strong correlation between message size and interaction latency, due to significant serialisation overhead in both middlewares. Case-study results show a significant negative influence on the performance metrics. Maximum system throughput is reduced by 99% in the worst-case and 94% in the best-case. Compared to the monolithic system, end-to-end latency increases between 7.5 and 1700 times at maximum throughput. Jitter increases from 0.1us to 24us for the OROCOS dataflow system, and to 980us for the ROS publish-subscribe system. Based on these results, componentisation of the system in the case-study cannot be recommended in contexts where performance is important.","middleware; performance; robotics; components","en","master thesis","","","","","","","","2012-08-31","Electrical Engineering, Mathematics and Computer Science","Software Engineering","","Computer Science","",""
"uuid:1e6c6190-ca4a-463d-9efb-b0027d312744","http://resolver.tudelft.nl/uuid:1e6c6190-ca4a-463d-9efb-b0027d312744","Cooperative Multi-Agent Path Planning","De Wilde, B.","Ter Mors, A.W. (mentor)","2012","Multi-Agent Path Planning is the problem of finding routes between pairs of start and destination vertices in a graph such that these routes are conflict-free in space and time. Application domains usually feature automated vehicles, for example in areas like warehouse management, aircraft taxiing and video games. Finding an optimal set of routes is an NP-hard problem; sub-optimal approaches usually decouple the problem into the problems of finding the individual routes sequentially, where each consecutive problem is constrained by previously determined routes. One of these approaches is the Push and Swap algorithm. The Push and Swap algorithm has been presented as complete for the class of problems in which at least two vertices in the graph do not contain an agent. We demonstrate, however, that there exist instances of this type in which a solution exists, but the Push and Swap algorithm fails to find one. By combining our analysis of the Push and Swap algorithm with results from the literature on the feasibility of finding solutions in the problem of moving `pebbles' over graphs, we present the Push and Rotate algorithm, which is complete for the class of problems in which at least two vertices are unoccupied. The algorithm runs in polynomial time and is presented with a proof of completeness. Furthermore, we present a revised version of an important post-processing operation that makes the algorithm practically usable on large instances.","","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Computer Science","","Algorithmics","",""
"uuid:98f9e876-5826-45bd-92ce-3f65e474582a","http://resolver.tudelft.nl/uuid:98f9e876-5826-45bd-92ce-3f65e474582a","A general RDE-based simulator for statistical timing analysis","Rodriguez Rodriguez de Guzman, J.","Berkelaar, M. (mentor); Tang, Q. (mentor)","2012","Accurate timing analysis of digital integrated circuits is becoming harder to achieve with current and future CMOS technologies. The shrinking feature sizes lead to increasingly important local process variations (PV), making existing methods like corner-based static timing analysis (STA) yield overly pessimistic results. While industry faces the uncertainty introduced by PV with time-consuming Monte Carlo (MC) simulations, this thesis presents a general purpose statistical circuit simulator for accurate timing analysis. This simulator uses a statistical simplified transistor model (SSTM) as its main building block, which allows the accurate modeling of both combinational and sequential circuits, and it is able to perform a fast statistical timing analysis of any input circuit by solving a system of random differential equations (RDE). Different experiments, ranging from simple cells to complex combinational circuits, were conducted to validate the simulator accuracy and performance for the 45nm CMOS technology. The obtained results show accurate results for both deterministic and statistical analysis of the circuit signals while effectively reducing the runtime when compared to MC simulations.","timing; simulation; statistical; RDE","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","MSc EE Microelectronics","",""
"uuid:e80e6742-4f34-473e-80ef-e3f297aee303","http://resolver.tudelft.nl/uuid:e80e6742-4f34-473e-80ef-e3f297aee303","Phosphorus removal by ceramic tight ultra-filtration (CTUF) membranes for RO pre-treatment","Zeng, Z.","Rietveld, L.C. (mentor); Heiman, S.G.J. (mentor); Shang, R. (mentor)","2012","gReverse Osmosis systems are wildly used for sea water desalination and water reclamation but they meet problems regarding bio-fouling. Bio-fouling increases their work pressure and operational costs and decreases their removal efficiencies. Phosphorus limitation is one strategy to control bio-fouling. This report focuses on phosphorus removal by ceramic tight ultra-filtration (CTUF) membranes (1kD and 3kD MWCO) as a pretreatment before RO. In this research we investigated different factors affecting phosphorus rejection by CTUF such as flux, cross flow velocity, ion strength, zeta potential and pH. The results show that increasing the flux, the cross flow velocity and the zeta potential increased the removal rate of phosphate. Increasing ion strength decreased the double layer thickness and decreased the removal rate of phosphate. All these results are in agreement with the theory of membrane filtration. The pH affected both the zeta potential of the membrane and the charge of the phosphate ion. Increasing pH increased the removal rate of phosphate but after pH 8.3, the removal rate of phosphate began to decrease. There is no explanation for this decrease in rejection at higher pH at this moment.","CTUF; phosphate removal; zeta potential; double layer thickness","en","master thesis","","","","","","","","2012-09-10","Civil Engineering and Geosciences","Water Management","","Sanitary Engineering","",""
"uuid:5722a0e7-e483-43f0-820b-f5f3ef8dd42e","http://resolver.tudelft.nl/uuid:5722a0e7-e483-43f0-820b-f5f3ef8dd42e","Look, who is talking?","Visee, C.E.","Visch, V.T. (mentor); Vermeeren, A.P.O.S. (mentor)","2012","Background and context Virtual Simulation Training increases in popularity for training of first responders in case of emergency situations. ‘XVR’ is virtual simulation training software used for this cause and is considered to be a Serious Game. Feeling immersed in a simulation is assumed to positively influence learning. Immersion is related to aspects like experiencing Presence and Involvement in the virtual environment. Realness of and interaction with the virtual environment can generate the feeling of Immersion. For a training of Fire Crew Commanders (FCC) the communication between the trainee and the instructor who is physically present, plays an important role. Trainees find themselves dividing their attention between the virtual and the real world. Objective The objective of this study is to research the influence of a different method of communication with the instructor on the experience of Immersion of a FCC during his training, by integrating the instructor’s role-play into the virtual environment (One World; virtual and real world aligned). Research Questions The primary research question of this thesis is: can the immersive experience of a Fire Crew Commander during simulation training with XVR be improved by integrating communication through role-play with the Virtual World to experience Immersion in One World? The secondary research question elaborates on this new manner of training with integrated communication: what are the effects of various ways of enriching communication between the Fire Crew Commander and the virtual characters in this newly created One World on the experience of Immersion of the Fire Crew Commander? Methods The immersive experience of a total of 27 Dutch Fire Crew Commanders was measured by a questionnaire and by post-experimental interviews. The current training situation and four situations with an instructor integrated in the virtual environment and manipulations of the communication were tested. The questionnaire measured the concepts of Communication, Spatial Presence, Involvement, Realness and Co-Presence. The interview gathered the Fire Crew Commanders’ experience of the different conditions. Results The immersive experience of Fire Crew Commanders was not influenced by the position the instructor had during role-play. An auditory cue (different voice) and a visual cue (speech balloon) were experienced to be beneficial for giving orders in the virtual environment. An effect of the cues on the feeling of Immersion in the virtual environment was not revealed. However, an ANOVA (statistical test) revealed that an instructor who is integrated in the virtual environment in combination with visual and auditory cues has a positive effect on experiencing giving orders in the virtual environment. Conclusions and Discussion For Serious Games, which train decisiveness and leadership abilities, the position of the instructor has no impact on the immersive experience of the trainee. This implies that the learning effect will be equal with or without an instructor who is physically present, assuming that Immersion influences learning. Visual and auditory cues can be supportive in creating a better understanding and control of the training scenario. For E-Semble this means that remote learning could be offered alongside the current training form. Also, integration of visual or auditory cues are supportive in understanding the scenario more easily; this sympathises with an XVR learning objective.","virtual simulation training; immersive experience","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Design for Interaction","",""
"uuid:5f9a68a8-42b5-4576-8815-15fd8f64dd18","http://resolver.tudelft.nl/uuid:5f9a68a8-42b5-4576-8815-15fd8f64dd18","An exploration on strategic tool developments in strategic design agencies","Cheung, C.Y.J.","Tassoul, M. (mentor); Calabretta, G. (mentor)","2012","This research project is an exploration on how strategic tools were developed in strategic design agencies. In conducting this paper, the author explored the strategic tool development in strategic design agencies of various age. With a grounded theory approach, this project conducted 10 interviews in 7 strategic design agencies in the Netherlands. The research project aims to capture a realistic view on the usage and development of tools in strategic design agencies. A visual map illustrating the relationships between findings is developed in the research. The findings are rich and presented in different layers under 5 interrelated themes. ""Preferred tool values"" indicates tool values that agencies are interested in. ""Tool innovation"" and ""re-creation & adaptation"" of tools describes the inspiration, drives and implementation of the tool development process. ""Knowledge management"" describes the management of personnel and tools within agencies. Last but not least, ""Tool selection process"" discuss the role of agencies in planning a project. This research project offers detailed insights into each theme and derive suggestions on how agencies can further create values, including ways to improve their organizational effectiveness and expanding their clientele base. This research is interesting for researchers on strategic design, tool developments, knowledge management and so on. Strategists and designers would also find this paper inspiring for reflecting their working module and gaining managerial implications.","strategic design tool; strategic design agencies; tool development; overview; strategic design","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Master of Science Strategic Product Design","",""
"uuid:804fb7d4-ff60-4d78-b12a-ebcdff3215e8","http://resolver.tudelft.nl/uuid:804fb7d4-ff60-4d78-b12a-ebcdff3215e8","Inferring Private Attributes in Online Social Networks","Shadravan, N.","Doerr, C. (mentor); Blenn, N. (mentor)","2012","Online social networks (OSNs) are playing an important role in current world and the way people communicate with each other. Despite the advantage of using online social networks, there are certain privacy risks that can affect users of such services. Since users provide a lot of personal information in OSNs, concerns about how data placed in online social networks may raise among the users. Social networking sites have responded to these concerns by introducing privacy filters to their site, allowing users to specify which aspects of their profile are visible to whom. Such privacy settings is not effectively used by half of the OSN users based on our analysis and we collect large number of public profile information from the well-known social network Hyves.nl in the Netherlands. We then show that public friendship links of a person can expose different attributes about him. Based on friendship links we are able to infer and predict some of the attributes of a user with good accuracy.","privacy; social network","en","master thesis","","","","","","","","2012-09-30","Electrical Engineering, Mathematics and Computer Science","Network Architectures and Services Group (NAS)","","","",""
"uuid:84f0e48c-a6f8-4708-92f6-047e849f565a","http://resolver.tudelft.nl/uuid:84f0e48c-a6f8-4708-92f6-047e849f565a","Asynchronous Logic as Counter Measure against Power Analysis Attacks","Tamerus, P.D.","Van Leuken, T.G.R.M. (mentor)","2012","Cryptographic devices are vulnerable to so-called Side Channel Attacks. As attackers become smarter, hardware designers and chip manufacturers need to keep up with the security demands against these Side Channel Attacks. Side Channel Attacks such as timing analysis, power consumption analysis or electromagnetic analysis, are based upon the principle that the attacker observes the behavior of the side channel (power, electromagnetic emission etc.) while a cryptographic device is performing its operations. The side channel reveals the attacker valuable information about the secret key which ultimately enables the attacker to derive the secret key. There are several counter measures that minimize the side channel information. This thesis analyzes the influence of using asynchronous logic as a practical countermeasure against Power Analysis attacks by implementing the AES Rijndael cryptographic algorithm in a FPGA device. A Power Analysis attack is a form of a Side Channel Attack where the attacker observes the behavior of the the power consumption during a cryptographic operation. A feasible asynchronous logic design style is chosen and implemented in a FPGA. In order to compare its effectiveness, a synchronous (clocked) hardware design is made in the same design structure of the AES algorithm. Power Analysis attacks are performed on both designs, and the results are compared.","Side Channel Attacks; Power Analysis Attacks; asynchronous logic; counter measures; AES","en","master thesis","","","","","","","","2012-08-29","Electrical Engineering, Mathematics and Computer Science","Circuits and Systems","","Computer Engineering","",""
"uuid:9170e10a-d07f-47ba-8605-95342128e194","http://resolver.tudelft.nl/uuid:9170e10a-d07f-47ba-8605-95342128e194","Online deployment of dependent tasks onto networked systems","Bernardo, G.","Dulman, S.O. (mentor); De Oliveira Filho, J. (mentor); Papp, Z. (mentor)","2012","The static deployment of tasks onto the components of a networked system is a design-time activity. Given a set of tasks it is desirable to distribute them across the network elements such that an intended system functionality is achieved while application specified criteria—such as power consumption or execution time—are optimized. However, it is common that assumptions taken for the satic deployment no longer apply during system operation or after the occurrence of unexpected events. The system functionality might be degraded or even halted. In this work, we discuss how to design networked systems that dynamically deploy tasks and therefore can adapt to unforeseen situations. The placement of tasks is decided by the system at runtime while taking in consideration actual operating conditions instead of design-time assumptions. We present a distributed algorithm for the online deployment of dependent tasks onto networked systems. The algorithm is able to handle a wide range of constraints and optimizes the task deployment according to an application defined quantitative criteria. Our method performs a full search in the space of possible deployments. We show that a full search contains a high degree of redundancy and we introduce a simplification that keeps the problem complexity within linear bounds for growing numbers of tasks and system components. In contrast with previous approaches, our method is not incremental and its model-based nature contributes for a wider applicability. We present experiments run on a network testbed composed of wireless nodes. The algorithm is shown to perform well for dependent sequential tasks and various network topologies. However it presents strong limitations in handling the deployment of tasks that are to be run in parallel in multiple system components. As a motivation we present also an application scenario in the logistics domain.","","en","master thesis","","","","","","","","2012-08-28","Electrical Engineering, Mathematics and Computer Science","Software Technology","","Embedded Software","",""
"uuid:ae201f3b-6470-458e-a988-f077484a6639","http://resolver.tudelft.nl/uuid:ae201f3b-6470-458e-a988-f077484a6639","Towards Bootstrapping Robotic Perception of Indoor Environments","Alagarsamybalasubramanian, A.C.","Jonker, P.P. (mentor); Rudinac, M. (mentor)","2012","Robots have been popular amongst us as Science fiction characters for a few decades now. The inability of the robots to robustly perceive and respond to the real world has been confining them to the laboratories for a long time. This can be attributed to the dynamic nature of the everyday environments where the prelearnt knowledge alone is not sufficient. The robots can be developed to work autonomously in these situations when they can obtain and update the knowledge of their surrounding on their own without external intervention. This process is termed as bootstrapping and it involves perceiving various aspects of the environment like faces, objects, sound, etc. This is a very elaborate task given the current level of sophistication. It is important for an intelligent robot to be able to comprehend unknown objects in the scene and this thesis focuses on handling unknown objects. A segmentation based on the 3 dimensional sensory data of the visual scene is implemented. The large planar structures in the scene are identified and the rest of the data is clustered to locate the probable objects in the scene. The appearance of the objects are chromatically and spatially described and are the basis on which they are recognized from the pre-learnt object models. A generic grasping technique based on the visual tracking feedback has been proposed and implemented to grasp any different object from various common locations.","robots; perception; object recognition","en","master thesis","","","","","","","","2013-08-28","Mechanical, Maritime and Materials Engineering","BioMechanical Engineering","","BMD","",""
"uuid:6128d78f-2b5d-455f-8bd9-0050a6413f72","http://resolver.tudelft.nl/uuid:6128d78f-2b5d-455f-8bd9-0050a6413f72","Touch-Based Organization of Patent Collections","Van Ee, A.M.","De Haan, G. (mentor)","2012","The number of patent applications has been growing rapidly: in 2010 the patent application requests increased with 11% at the European Patent Office. It is important that patent examiners can efficiently compare new applications with published patents. Patent examiners review the list of relevant patents, returned by a search query, one at a time using the current tools. There is no overview of the patents and time is wasted when the best document is the last in the list. An overview of the patent collection can provide insights into which patents can be skipped and which should be read in detail. This work proposes an Organization Viewer for reviewing a collection of patents. It is based on the research prototype TouchPat which uses multi-touch interaction and displays the patents in a static 2D grid. In the Organizational Viewer, the patents can be organized manually in a spatial layout using a new multi-touch gesture set and Stacks. In addition, this work examines how automatic organization using the Local Affine Multidimensional Projection (LAMP) technique can also support the user. These new organization techniques are evaluated with twelve patent examiners at the European Patent Office using the think-aloud protocol. The results of these evaluation show that an overview is a valuable addition to the work of patent examiners and that the value of an overview for patent examiners depends on personal preferences as well as their domain of expertise. The TouchPat prototype and the evaluation transcripts give insight into the features that can improve the process of reviewing relevant patents.","Local Affine Multidimensional Project; Touch-Based Interactions; ZUI; Patents; Multi-Touch; Visualization; Organization","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Intelligent Systems","","Computer Graphics and Visualization","",""
"uuid:351ed5e4-d1ee-4697-8403-10c0ce10769c","http://resolver.tudelft.nl/uuid:351ed5e4-d1ee-4697-8403-10c0ce10769c","Heritage Product for Future Living: A Strategic Approach Towards Sustainable Heritage Products in Vietnam","Suib, S.S.S.","Crul, M. (mentor); Tassoul, M. (mentor); Nguyen, H.L. (mentor)","2012","In order to innovate, we need creative ideas. This project focused on the use of ‘heritage product as a source for creative inspirations, thus a strategic approach was develop against the background of Vietnam’s handicraft industry. The project is about understanding the current development of heritage product and how it can potentially be develop towards sustainable living. A model towards this approach was devised based on three phases SEEK - IDENTIFY INNOVATE A strategic approach devised based on heritage innovation. It consists of a model and a process as a guidelines used during new product development project. In order to ensure its accessibility, the approach was transformed into a tangible toolkit which consists of three set of tools that act as a supporting material to mediate a session. A set of trend styles forecasted in 2013 are also included to help user with no design background or experience to kick-start their NPD project. This toolkit aims to be a catalyst for Vietnamese producers to innovate based on their heritage product. It also act as a platform to collaborate between designers and non-designers through step by step process that enable them to co-create using the same method. This potentially will increase design awareness and creative capabilities among local producers through experience and share knowledge with professional designers during the session. ‘Heritage Product for Future Living’ allow people to experience the process of developing new ideas from heritage product. The process nurture design capabilities while generating original ideas with story behind it. The story created an identity as well as build authenticity of the ideas, an outcome that can be used as part of the marketing strategy to promote the end products. The toolkit is design as a medium to facilitate creative session, it can potentially be used in two different scenarios; ‘fast and extensive’ or ‘deep dive experience’ which provide and options for users to used the tools according to their available time and resources.","heritage product; sustainable product innovation; strategic approach; design for sustainability","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Master of Science Strategic Product Design","",""
"uuid:2e3275f5-5db9-4ec0-a55a-30cc9f3e8ff5","http://resolver.tudelft.nl/uuid:2e3275f5-5db9-4ec0-a55a-30cc9f3e8ff5","Design of a Fast and Reliable Wireless Link for Kite Power Systems","Ramos Salido Maurer, Antonio (TU Delft Electrical Engineering, Mathematics and Computer Science)","Langendoen, Koen (mentor); Onur, Ertan (mentor); Schmehl, Roland (mentor); Fechner, Uwe (mentor); Delft University of Technology (degree granting institution)","2012","Kite Power Systems present technological advantages over traditional windmills. In this work, the design of a dual wireless link for kite applications requiring high reliability and low delays is presented. The link provides realtime data exchange between the system components that allows researchers to run closed-loop controllers, and to validate kite models. The proposed solution meets the quality of service requirements (delay and packet losses) and other requirements specific for airborne wind energy applications like small form factor, low weight, and power consumption. The most relevant design choices for frequencies, devices, and configuration are described. A pair of controllers for flying crosswind were tested under different QoS conditions with positive results. Performance measurements during flight were used to build statistical models. Such models were implemented in a simulator to better understand the effects of the network over autopilot controllers and to find the minimum communication performance requirement for the system.","","en","master thesis","","","","","","","","","","","","","",""
"uuid:b429e899-9955-4a23-9ceb-66ffb6210b30","http://resolver.tudelft.nl/uuid:b429e899-9955-4a23-9ceb-66ffb6210b30","Knowledge-based optimisation of three-dimensional city models for car navigation devices","Nedkov, S.B.","Ledoux, H. (mentor)","2012","Three-dimensional maps are deemed better for navigation purposes as they offer a larger number and more realistic navigation cues than two-dimensional maps. Improvements in two key technologies have opened the doors towards utilization of 3D maps for car navigation devices. Advances in data acquisition technologies and data processing methods have made creating photorealistic three-dimensional city models cheaper and to a large extent automatic, while advances in mobile technologies have made e.g. modern smartphones powerful enough to visualize photorealistic 3D graphics. Despite the latter improvements, making three-dimensional mobile maps remains a challenge due to the large amounts of data and the device’s limited amount of memory and pro- cessing power. These limitations can be overcome by intelligently reducing the amount of information that is handled and displayed by the device. This thesis presents an information reduction and prototyping framework that reduces the amount of information contained in city models so a to enable their loading and display on car navigation devices. The information reduction method consists of two steps. The first step selects buildings that are close to the driver’s route with the idea that these aid the driver in navigating. Buildings that are far from the route are discarded. In the second step, the selected buildings’ external representation is adapted to match their navigational value that is based on their thematic, semantic and cognitive properties. For instance, a building of type ’restaurant’ and ’brand’ McDonald’s offers more navigational cues than a block of gray, anonymous residential buildings. The latter are styled in generic textures whereas the former is styled in photorealistic textures. The relations between a building’s semantic and thematic properties and its external representation are captured in visualisation rules. A prototype is built that implements the designed information reduction methods and tests their effectivity. The selection step is performed using a spatial database while the visualisation rules are processed by an expert system. The reduced 3D scenes are displayed in a game engine that also performs performance measurements. The obtained results are conclusive: the performance of a visualisaion in terms of frame rate and used graphics memory is governed by the the amount of textures, much more so than the number of geometries. Effort should therefore be directed towards the reduction and/or simplification of textures rather than geometries.","3D; GIS; Geomatics; mobile; urban; rotterdam; city model; linked data; semantics; thematics; expert system; game engine; Panda3D","en","master thesis","","","","","","","","","OTB Research Institute for the Built Environment","GIS technology","","Geomatics","",""
"uuid:429d6df1-f988-41f0-abf7-c19196dd5ff4","http://resolver.tudelft.nl/uuid:429d6df1-f988-41f0-abf7-c19196dd5ff4","Design of a guidance device for minimally invasive hip prosthesis refixation","Ambrosi, M.","Dankelman, J. (mentor); Valstar, E. (mentor)","2012","All around the world countries’ populations are aging and with this increase of expected lifetimes there is additional need for medical interventions such as hip replacements. With many people outliving the lifetime of these implanted parts, revisions are sometimes necessary. In some hip prostheses, layers of fibrous tissue can grow and decrease the stability of the implant and cause a great deal of pain. Since open surgery is not an option for elderly patients, a minimally invasive approach is needed to remove the tissue and refixate the prosthesis. A guidance device was designed particularly for this procedure because removing the tissue before cementing is a novel approach to the current method of only cementing. Several concepts were created and evaluated resulting in an arc-shaped design being chosen. The designed guidance arc opens up the next step in hip refixation procedures. With the ability to guide new tools to remove the fibrous tissue and cement the area, the lifespan of the prosthesis and the quality of life of the patient will increase.","design; minimally invasive; hip prosthesis; refixation; fibrous tissue","en","master thesis","","","","","","","","2012-10-03","Mechanical, Maritime and Materials Engineering","BioMechanical Engineering","","BME","",""
"uuid:1736d513-e69f-4101-8995-4597c2a4df50","http://resolver.tudelft.nl/uuid:1736d513-e69f-4101-8995-4597c2a4df50","Extending Project Lombok to improve JUnit tests","Weijers, J.","Spilker, R. (mentor); Zaidman, A.E. (mentor)","2012","In this thesis, we look at unit and integration test suites and look for ways to improve the quality of the tests. The first step in this research is the development of the JUnitCategorizer tool to distinguish between unit tests and integration tests. JUnitCategorizer determines the actual class under test using a new heuristic and ultimately decides whether the test method is a unit or integration test. We show that JUnitCategorizer correctly determines the class under test with an accuracy of over 90%. Our analysis also shows an accuracy of 95.8% on correctly distinguishing unit and integration tests. We applied JUnitCategorizer on several open and closed source projects to obtain a classification of the test suites based on their ratio of integration tests. The second part of this research looks at applicable methods to increase the quality of the tests, for example elimination of boiler-plate code and detection (and possibly generation) of missing tests. Using the classification of test suites, we show that the aforementioned test problems occur in both unit as integration tests. We then propose a new tool called Java Test Assistant (JTA), which can generate boiler-plate tests and some hard tests. An experiment was conducted to assess JTA and showed promising results. Code coverage increased and several of our generated tests fail on the current code base because the implementations are not entirely correct.","java; unit testing; integration testing; developer testing; Project Lombok; JUnitCategorizer; JavaTestAssistant; test generation; JUnit","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Software Technology","","","",""
"uuid:728a23f2-8f91-49bf-9ba8-8ce796e85348","http://resolver.tudelft.nl/uuid:728a23f2-8f91-49bf-9ba8-8ce796e85348","Mineral Scaling in Geothermal Wells","Van den Ende, T.W.","Heimovaara, T.J. (mentor)","2012","","geothermal; DAP; mineral; scaling","en","bachelor thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Geo-engineering","",""
"uuid:fcb3cd7d-ed96-4541-bb8d-1be3a36e2aa8","http://resolver.tudelft.nl/uuid:fcb3cd7d-ed96-4541-bb8d-1be3a36e2aa8","Struvite Crystallization and Separation in Digested Sludge","De Buck, W.J.","Van Lier, J.B. (mentor); Rietveld, L.C. (mentor)","2012","Phosphorus depletion is an emerging and serious global environmental issue. At this moment, research and policy discussion on phosphorus scarcity is still limited. This research investigates the possibilities of phosphorus recovery by controlled precipitation of struvite from digested sludge. At Waternet’s wastewater treatment plant Amsterdam West, plans for a struvite reactor are scheduled. The advantage of phosphorous recovery through struvite precipitation from digested sludge is three-fold. First, struvite can be directly used as fertilizer. Second, undesirable struvite precipitation in the wastewater treatment plant is prevented by reducing the phosphorus concentration in the dewatering reject stream which is fed back to the inlet of the treatment plant. Third, sludge dewaterability improves due to the addition of MgCl2. This thesis investigates the influence of mixing speed, aeration rate, magnesium dosing method and crystal recycle method on struvite growth and phosphorus removal, as well as separation of struvite from sludge. For that purpose, experiments have been performed in a crystallization reactor and a counter-current washing column at lab scale at wastewater treatment plant Amsterdam West. MgCl2 was added under varying reactor conditions, struvite constituent concentrations were measured and struvite growth was assessed. First, it is demonstrated that struvite recovery is well possible in a stirred sludge environment at neutral pH commonly applied in sludge digesters (7.0 - 7.1). Phosphorous removal under these circumstances is at least 85%. More complete mixing by stirring at a higher speed further improves struvite recovery by keeping supersaturation low. Secondly, a significant difference in struvite recovery was observed between experiments in which MgCl2 is dosed instantly versus experiments in which MgCl2 is dosed gradually. Gradual MgCl2 dosage, and therefore rapid mixing, improves recovery compared to instant dosage. Mixing at a higher stirring speed further improves recovery. Thirdly, it is found that struvite recovery under given circumstances is poor in a combined aerated and stirred sludge environment. In such environment higher aeration rates deteriorate struvite recovery further, while struvite recovery improves with decreasing aeration rates at a higher stirring speed. Fourthly, struvite separation experiments have verified that separation is well possible in a counter-current washing set-up, separating 86% of detectable struvite within 15 minutes at an upflow velocity of 1.3 mm/s.","struvite; sludge; phosphorus; recovery; wastewater","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Water Management","","Sanitary Engineering","",""
"uuid:46da66df-0622-44a0-aeae-7616180f11b6","http://resolver.tudelft.nl/uuid:46da66df-0622-44a0-aeae-7616180f11b6","Dutch Electric Vehicle Innovation System","Suprata, F.","Van Beers, C.P. (mentor); Scholten, V. (mentor); Quist, J.N. (mentor); Willems, M. (mentor)","2012","","Innovation Systems; Strategic Niche Management; Entrepreneurship; Business Models; Dutch electric vehicle","en","master thesis","","","","","","","","2012-08-30","Technology, Policy and Management","Technology, Strategy and Entrepreneurship","","Management of Technology","",""
"uuid:6a4f1673-88b1-4823-b2ef-9d864c84ab11","http://resolver.tudelft.nl/uuid:6a4f1673-88b1-4823-b2ef-9d864c84ab11","A Hodographic-Shaping Method for Low-Thrust Trajectory Design","Gondelach, D.","Noomen, R. (mentor)","2012","The goal of this research was to develop an analytic low-thrust trajectory design method. The term low thrust stems form the fact that current electric propulsion systems can only produce low amounts of thrust. Nevertheless, these systems can deliver very high amounts of ?V using little propellant, which makes them very suitable for interplanetary flight. The orbital mechanics regarding low-thrust interplanetary flight were considered and it was found that for first-order design it is acceptable to neglect all perturbing forces with respect to the Sun's gravitational attraction and the (low) thrust force. In addition to that, a look was taken at the characteristics of electric propulsion and feasible thrust (acceleration) levels were obtained. Since only low thrust levels can be achieved by electric propulsion, long periods of thrusting are required to obtain sufficient change in velocity. This continuous thrusting feature of electrically-propelled spacecraft highly complicates the dynamics of such spacecraft. As a consequence, the design and optimization of low-thrust trajectories is very difficult, and therefore preliminary design of such trajectories is very important. Such first-order designs can give a fast overview of all feasible trajectories and can, moreover, be used as an initial guess for more refined trajectory optimization. For generating and optimizing first-order low-thrust trajectories, analytical methods are very suited, since they are very fast and exact. Several analytical low-thrust methods have been developed recently and most of them are shape-based; the trajectory is assumed to have a specific shape which satisfies the boundary conditions and subsequently the thrust profile can be obtained from the dynamics. These shape-based methods are popular for preliminary design, because of their simplicity and ability to obtain feasible trajectories. The currently known shape-based methods were investigated to obtain know-how about their functioning and to find their strengths and weaknesses. It was noticed that regarding the solving of boundary conditions improvements could be made and that most shaping methods lack flexibility. Inspired by the use of velocity hodographs for the computation of non-perturbed transfer orbits, a novel low-thrust trajectory design method was developed based on shaping the velocity of spacecraft during the transfer. For the shaping of the velocity components, velocity functions were used which consist of a sum of simple base functions. These base functions can be integrated analytically, such that the change in position can be obtained analytically. Since the velocity is shaped, the conditions on initial and final velocity can be solved very easily and exactly. In addition, the boundary conditions on position can be solved exactly without the need of iterative computations. Next to the parameters required to satisfy the boundary conditions, extra parameters can be added to make the design and optimization of trajectories more flexible. Two different methods have been developed; one which shapes the velocity as a function of time and another one which shapes as a function of the polar angle. For the computation of the required ?V , and for the computation of the polar angle in the time-driven method, numerical integration is required. Four simple integration methods were tested and an RK4 integrator was found to perform best based on accuracy and computation speed. Since the derivative of the ?V and the polar angle (the thrust acceleration and angular velocity, respectively) can be computed as a function of time or polar angle, their values can be computed prior to the integration. As a result, RK4 integration simplifies to Simpson's rule and the integration can be done much faster. Both hodographic-shaping methods have been verified by numerically propagating the initial spacecraft state vector using thrust profiles found by the shaping methods. Both the time-driven and polar-angle-driven method were found to function well, and the obtained trajectories and thrust profiles agreed almost exactly. In order to obtain minimum-?V trajectories, the free parameters in the velocity functions were optimized. Both a Nelder-Mead (NM) and Differential Evolution (DE) optimizer were tested for this purpose. NM was found to be equally robust, but much faster than DE, and therefore NM was used. In addition, initial guesses for the free parameters were used to speed up the optimization. Finally, the search for the optimal departure date and TOF was done by stepping through the flight window using a grid. Both hodographic-shaping methods were tested for missions to Mars, the near-Earth asteroid 1989ML, comet Tempel 1 and Mercury. For missions to Mars and 1989ML the two methods gave comparable results. The time-driven method found better trajectories to Tempel 1 (a far outer target), whereas the polar-angle-driven method found better ones to Mercury (an inner target). In comparison with the spherical and pseudo-equinoctial shaping methods and DITAN (the benchmark), the hodographic-shaping methods performed well, especially for mission to Mars and to asteroid 1989ML. The near-optimal results came at the cost of computational speed. The best results were found using 6 free parameters requiring require a computation time of 2 s per trajectory on average. The lowest-order solutions (0 DoF), on the other hand, required only 1.6 ms per trajectory on average. Finally, the lowest-order solutions were found to be unable to obtain near-optimal trajectories, however, they were able to indicate the correct regions of low ?V in the flight windows and to give a good indication of the required ?V and thrust acceleration.","shape-based method; low-thrust transfer; orbital mechanics","en","master thesis","","","","","","","","","Aerospace Engineering","Space Engineering","","Astrodynamics and Space Missions","",""
"uuid:688c208a-65d1-45ed-9efd-30210a8a907d","http://resolver.tudelft.nl/uuid:688c208a-65d1-45ed-9efd-30210a8a907d","The Effect of Online Adaptation on Conflicts in Haptic Shared Control for Free-Air Teleoperation Tasks","De Jonge, A.W.","Van der Helm, F.C.T. (mentor); Abbink, D.A. (mentor)","2012","Haptic shared control provides artificial guiding forces on a control interface that support operators to perform tasks. Research has shown that this can improve task performance and reduce control effort. However conflicts between the human operator and support system are often reported which deteriorate performance and increase control effort. Conflicts solutions have been proposed for unexpected avoidance of obstacle on the supported trajectory, but solving conflicts due to trajectory negotiation mismatches have not been proposed. One way of minimizing those conflicts is to base support on individual preferred trajectories. Another way propose in literature is by online adapting the supporting trajectory. The goal of this study is to provide evidence for the hypotheses that 1) an individualized support trajectory yields less conflict between operator and support system than convention general trajectory and 2) online adaptation of the supported trajectory will also reduce conflicts, regardless of the initially chosen support trajectory. In a human factors experiment, subjects (n=12) conducted a repetitive two degrees of freedom task in which they were provided with four different types of support. Both the recorded individual trajectories and the conventional centerline of the environment trajectory were provided both with and without adaptation. The results show no effect of adaptation or support path on performance. Adaptation reduces support forces and control activity. The individual recorded trajectory reduces control activity compared to conventional centerline of environment support. Those results provide evidence that recorded individual trajectory support reduces control effort for non-adaptive support, albeit only in control activity. The results furthermore provide evidence that adaptation of both types of initial support path reduce support forces and control effort. In conclusion, online adaptation of haptic shared control reduces trajectory negotiation conflicts and the associated increased forces. It adapts to subject-specific preferences in trajectory, regardless of initially chosen supported trajectories.","haptic shared control; adaptation; learning; virtual fixtures; task performance; control effort","en","master thesis","","","","","","","","2012-10-03","Mechanical, Maritime and Materials Engineering","BioMechanical Engineering","","BMD","",""
"uuid:2b238ade-cf76-4220-a407-4f3465d56dbc","http://resolver.tudelft.nl/uuid:2b238ade-cf76-4220-a407-4f3465d56dbc","Fault-Tolerant On-Board Computer Software for the Delfi-n3Xt Nanosatellite","Van den Berg, A.F.C.","Van Genderen, A.J. (mentor); Bouwmeester, J. (mentor)","2012","Fault-tolerant On-Board Computer (OBC) software for the Delfi-n3Xt nanosatellite is needed in order to minimize the risk of failures that may occur while the satellite is operating in space. Failures may be OBC specific, but failures that affect the state of the entire satellite and influence the health of the data bus may occur as well. Some failures that may occur on the I2C data bus can have a very large impact on the health of the satellite. The failure cases in which the I2C data line or I2C clock line is being pulled low for a longer period of time make communication over the I2C bus impossible. The I2C bus recovery mode that is implemented in the OBC, together with the I2C recovery mechanism that applies to the whole satellite, provides a way to resolve failure cases like these. The failure cases on the I2C bus with less disastrous impacts may result in data inconsistencies and time-outs and are handled by the OBC as well. The I2C data bus performance analysis for Delfi-n3Xt shows a bit error rate of at most 4E-9, which fulfills the requirement that specifies that the bit error rate must be 1E-6 or less. Apart from failures on the I2C data bus, failures may occur internally in the OBC hardware or software. Since the OBC controls the whole satellite, a permanent failure in the OBC hardware or software may result in a non-functional satellite. The OBC software is designed and implemented in such a way that it can not become in an undefined state for longer than 8 seconds. Besides that, the OBC assures that transfers over the I2C bus never take longer than 30ms. This improves reliablity and performance. Furthermore, clever routines that save flash memory erase cycles were designed and developed in order to increase the lifetime of the flash memory.","Delfi-n3Xt; On-Board Computer; Fault-Tolerance; Software; I2C; Satellite","en","master thesis","","","","","","","","2012-08-29","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","Computer Engineering","",""
"uuid:59d84718-b299-48f7-bdef-62c57377dfcf","http://resolver.tudelft.nl/uuid:59d84718-b299-48f7-bdef-62c57377dfcf","Pricing Methods in a LIBOR Market Model with Stochastic Volatility","Manzana, N.","Van der Weide, H. (mentor)","2012","","LIBOR market model; stochastic volatility","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","DIAM","","","",""
"uuid:60fdaad2-24a7-4245-a619-8d81728bcbdc","http://resolver.tudelft.nl/uuid:60fdaad2-24a7-4245-a619-8d81728bcbdc","Validation of Eddy Current Loss Models for Permanent Magnet Machines with Concentrated Windings","Liu, D.","Polinder, H. (mentor)","2012","","concentrated windings; eddy current losses; finite element modeling; permanent magnet machines","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Electrical Sustainable Energy","","Electrical Engineering (Track Electrical Power Engineering)","",""
"uuid:61fb78ea-dc3f-4e4c-ac72-ecf803961dec","http://resolver.tudelft.nl/uuid:61fb78ea-dc3f-4e4c-ac72-ecf803961dec","Charon: The Pluggable Filtering Framework for the Fox-IT DataDiode","Amesz, M.; Biemans, E.; Ruoff, J.; Van den Oever, J.","Erkin, Z. (mentor)","2012","Confidentiality This report contains detailed information about the design and implementation of Charon. The DataDiode, and by extension Charon, is used in many high security environments. They handle highly confidential data, and are used by clients ranging from major companies to governmental organizations. Because of this, the details about Charon disclosed in this report can not be made publicly available online. A physical copy of the full version of the report is kept by the Computer Science Bachelor Project Coordinator of the TU Delft. To access the full report, please contact the current coordinator. The Dutch IT security company Fox-IT created the DataDiode, a product that connects two networks with different security levels providing a one-way data path. A new appliance of the DataDiode is currently under development. As part of our BSc project, we were given de assignment to develop Charon, a pluggable filtering framework for the new DataDiode appliance. This thesis describes the complete process of the project and elaborates the choices we have made. In the introduction we explain what a Computer Science Bsc project is at Delft University of Technology and describe Fox-IT and the DataDiode. After this we give a detailed description of the assignment, define the requirements, explain the design methodology and why we consider Charon to be a suitable name for the project. In the next chapter we elaborate on the design choices we have made and illustrate these choices with UML-diagrams. The chapter that follows is about the implementation of the system; we describe the libraries, tools and system components. After this chapter we evaluate the implementation by comparing the implemented functionality with the requirements. We also explain in which way we tested our system to make sure it runs according to the specifications, about the Fox-IT challenge and the code evaluation. We reflect the process in the succeeding chapter where we compare the initial planning with the actual execution, and explain the collaboration between the group members. In the last chapter, we conclude the thesis and list several recommendations for Fox-IT. The appendices that are attached to this thesis contain a complete class diagram, several documents that are created during the orientation phase and a user manual.","","en","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Computer Science","","","",""
"uuid:edcd6144-38d7-4d65-b59a-038d1307a788","http://resolver.tudelft.nl/uuid:edcd6144-38d7-4d65-b59a-038d1307a788","Cooperative Networks: The Mobile Tethering Game","Constantinescu, M.M.","Onur, E. (mentor)","2012","The thesis aims at extending the capabilities of devices and enabling cooperation, i.e., data connection sharing, among users who may or may not necessarily be related to or know each other. To achieve this objective as well as to validate the results of our theoretical analysis, we developed a smart-phone application for data connection sharing. By means of data connection sharing, users may influence the pricing schemes of mobile network operators, increase spectrum utilization and build their own cooperative network. We define the mobile tethering game and investigate what makes the cooperation work and what are the economic requirements for building a cooperative network. The mobile tethering game may pave the way for a new business model where users not only get Internet connection service but also sell it in a mobile fashion. Using the results of the conjoint analysis integrated with the game theoretic model and the smart-phone application, the thesis will present a clear picture as to the interactions among players of the mobile tethering game and the influential preference factors. We are interested in figuring out whether people might be willing to share their connection for incentives (money or virtual currency) or whether they are just expecting to receive the same treatment (service) in a future interaction.","sharing data connection; game theory; conjoint analysis","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Wireless and Mobile Comunications","","Telecommunication Track","",""
"uuid:a52340c4-b453-441d-8721-59d1d6406dfe","http://resolver.tudelft.nl/uuid:a52340c4-b453-441d-8721-59d1d6406dfe","3D Geological Models of Submarine Lobes from Borehole Data, Permian Tanqua-Karoo Basin, South Africa","Lorenz, C.F.D.","Luthi, S.M. (mentor)","2012","The Permian Skoorsteenberg Formation in the Tanqua-Karoo basin in South Africa provides excellent exposure of submarine basin-floor fans. Because of this, the European Union sponsored various outcrop studies, drilling as well as the data acquisition of the research boreholes in the NOMAD project. It was a unique opportunity to study a submarine fan system by combining widely exposed outcrop and research borehole data. Because both data sets are available, this MSc. project aims to acquire bed thickness data from core and borehole image (Fullbore Formation Micro Imager) analysis and to extrapolate these data to 3D in a variety of methods based on the results of first objective. Analysis has been done on the turbidites of Fan 3 in wells NB-4, NB-3, NB-2, and NS-2. The cumulative distributions of turbidite bed thicknesses in the studied wells were found to follow a power law. Therefore, the cumulative bed thicknesses plot can be used for the following purposes: (i) to derive certain parameters for the bed geometries and distributions; (ii) to calculate turbidite volume connected to the well; (iii) to suggest accommodation space degree of confinement; and (iv) to derive qualitative information on the extent of erosion and bed amalgamation (thus, may suggest depositional setting). The change of slope (the change of exponent) in the cumulative bed thicknesses can be interpreted due to confinement or alternatively, due to the variation of the flow rheology. The clustering of data in the cumulative bed thicknesses plot may suggest the flow rheology affecting the turbidite deposition in particular time or location, which may represent a shift in the lobe depocenter. The turbidites volume connected to the wellbore can be calculated using three different methods, these are: using the mathematical model developed by Malinverno (1997) (volume is calculated from the bed thickness distribution); using the facies model developed utilizing Petrel 2010.1 software; and using the discrete convolution method (volume is calculated by relating the experimental data and the well data). The application of each method has to be done with care, taking into consideration the data availability and the limitation of each method. Moreover, information of the lobe internal geometries is needed in the volume calculation.","Tanqua-Karoo; Submarine lobes; Facies modeling; Power law; Turbidite","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Petroleum Engineering and Geosciences","",""
"uuid:db879ccf-3cb1-448f-adea-4d9e221be35f","http://resolver.tudelft.nl/uuid:db879ccf-3cb1-448f-adea-4d9e221be35f","The future of the Oosterschelde with a new inlet channel","De Bruijn, R.A.","Stive, M.J.F. (mentor); Wang, Z.B. (mentor); Van Prooijen, B.C. (mentor)","2012","After the storm surge of 1953, the Dutch Delta project was initiated in order to protect the southwestern part of The Netherlands. A storm surge barrier in front of the Oosterschelde and various dams at the back of the estuary were constructed. These interventions led to a large change of the hydrodynamics of the Oosterschelde: a large decrease in tidal volume and flow velocities. This decrease in flow velocities caused a decrease in sediment transport from the channels with about 75%. It is estimated that an amount of 400-600 million m3 of sediment is necessary to increase the flow velocities, restore the sediment transport from the channels and to obtain a new dynamic equilibrium (Kohsiek, 1987). This need for sand is called the ‘sand demand’. At present, the shoal height inside the estuary decreases by wave erosion. This decrease in shoal height mainly has a negative influence on the protected nature in the Oosterschelde. The Oosterschelde was ebb dominant and exporting sediment for centuries. All the events and interventions from 1530 up to the construction of Volkerakdam and Grevelingendam in 1969, caused an increase in tidal prism and export of sediment towards the ebb tidal delta. By the construction of the storm surge barrier, Philipsdam and Oesterdam in 1986, the situation changed, the tidal prism decreased and the ‘sand demand’ started. This research is aimed at finding a structural solution for the ‘sand demand’ by opening the storm surge barrier. The present situation of the Oosterschelde and a future situation with a new inlet channel at Neeltje Jans are analyzed in order to determine if a new inlet channel could influence the hydrodynamics and sediment transport in order to structurally solve the ‘sand demand’. A process based hydrodynamic and morphological model (Delft3D) is used to analyze the present and possible future situations with a new inlet channel. The new model and the methods of Van de Kreeke (1993) and Groen (1967) applied to the present situation of the basin, show that the Oosterschelde is still ebb dominant and would be exporting fine and coarse sediment if the inlet would not block the sediment transport. This ebb dominance follows from the large intertidal area and deep channels. Notwithstanding the ebb dominance, there is no sediment export possible through the inlet. The inlet blocks the sediment transport in both directions mainly because of a ‘tidal jet’, caused by the small inlet and large tidal prism. The tidal prism increases with a new inlet channel and thus increases the flow velocities in the channels. The increase in tidal prism and thus flow velocities brings the Oosterschelde closer to the old situation. The higher flow velocities increase the sediment transport from the channels and thus increase the shoal building. It is not known how much the shoal building is exactly restored. Some channels have such an increase in flow velocities that shoal building occurs again. However, parts of the basin are still not in equilibrium, which can be seen from comparing the old with the new flow velocities and by comparing the tidal prism and the cross-sectional areas of the channels with the empirical relations of Louters (1998) and Haring (1976). An important disadvantage of an increase in tidal prism is the enhancement of the ebb dominance that causes more sediment transport in ebb direction. However there is no export possible through the new inlet channel, because also the new inlet channel has a ‘tidal jet’ that blocks all sediment transport through the inlet. The large-scale effects of the Oosterschelde, like the ebb dominance and ‘sand demand’ cannot be structurally changed a new inlet channel. However the shoal degradation rate will probably be slowed down with an increase in tidal prism.","tidal asymmetry; sediment transport; Oosterschelde; Delft3D","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Hydraulic Engineering","","Hydraulic Engineering","",""
"uuid:06c4e1d1-bc49-4ac2-9296-e6fb35b74a86","http://resolver.tudelft.nl/uuid:06c4e1d1-bc49-4ac2-9296-e6fb35b74a86","Framework for Developing Innovation Systems in Small Island Developing States: Roadmap for turning Curaçao into the OTEC Centre of Excellence","Prochazka, T.","Ravesteijn, W. (mentor); Kamp, L.M. (mentor); Hartmann, L. (mentor); Blokker, R. (mentor)","2012","The objective of this thesis was to design a generically applicable framework for guiding the development of technological innovation systems in small island developing states (SIDS). Existing theories formed the bases of the framework but important changes were derived from a cross-case study of five island based innovation systems and an in-depth case study of Ocean Thermal Energy Conversion (OTEC) technology on the island of Curaçao. Two key factors were found to make the development of innovation systems in SIDS different. Firstly, only specific technologies should be targeted – high-margin or service sectors, and the ones that utilize strategic locations or specific natural resources of the islands. Secondly, due to the characteristics of SIDS the innovation systems’ integration into the landscape and regimes of the islands is essential – the links between the innovation systems and regimes and landscapes are much stronger in SIDS than in developed states. Therefore strong network of local partners should be established in order to guarantee sufficient support from the islands’ regimes. Also, due to the potential impacts on the islands’ landscapes, projects that are parts of the TIS should be of ‘moderate’ sizes so that they do not make the SIDS overly dependent on the success or failure of the technology. Furthermore, the innovation systems should be developed gradually in order not to disrupt the fragile economies of the islands. By following this set of rules, close relationships between the sectors and the islands’ regimes and landscapes can be established. This results into a win-win situation where the TIS can develop as it benefits from the island’s support (permits, policies, tax exemptions etc.) and the island itself reaps socio-economic benefits. Without this win-win situation, the TIS will struggle to develop.","SIDS; Innovation Systems; OTEC; Functions of Innovation Systems; Evolutionary Theory","en","master thesis","","","","","","","","2012-08-27","Technology, Policy and Management","Technology Dynamics and Sustainable Development","","Management of Technology","",""
"uuid:3c7e6d9d-5ee9-4fa3-8b64-954fb513976a","http://resolver.tudelft.nl/uuid:3c7e6d9d-5ee9-4fa3-8b64-954fb513976a","Problems in Modeling Orbital Soft Tissue with the Finite Element Method","Moerkerken, J.W.","Van Keulen, A. (mentor)","2012","The human eye is suspended in the orbit, a cavity in the skull that is largely filled with fat (adipose tissue). Fat is a gelatin like substance contained within fat cells surrounded by connective tissue membranes. Fat consists for 80 % of water, therefore it is almost incompressible. Fat supports the eye and eye muscles in the orbit, four rectus muscles pull the eye back on the fat. The eye slides and rotates in Tenon’s capsule, a sack that surrounds the backside of the eye. This sack is filled with synovial fluid, which can also be found in joints in the body. Besides sliding and rotating the eye may translate; eye rotation is not necessarily about a fixed point. This gives the eye six degrees of freedom, three translations and three rotations. The eye is able to rotate for about 50° in left and right gaze. Modeling such a complex three dimensional soft tissue structure gives more insight in functionality of anatomical structures. Such a model can be created with the finite element (FE) method. In the FE method a structure, for example a muscle is subdivided into little cubes. In case of the orbit, first the contours of anatomical structures are determined. These contours are filled with cubes (or elements) such a structure determined by cubes is called a mesh. Once the mesh is created, the elements are assigned material properties like elasticity. Then a simulation of movement of the structure is possible, for example caused by a contraction of an eye muscle. Such a FE model of orbital mechanics was built in 2001 in Delft. This model was able to rotate the eye for 15°, rotations for more than 15° were not possible in the model. It was not clear what caused this limited rotation. An investigation was needed to identify the problem of limited rotation. This study was done to identify problems in the model and seek for possible solutions. The goal was to simulate full eye rotations with the model.","orbital soft tissue; finite element method","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Precision and Microsystems Engineering","","","",""
"uuid:90575e43-bf89-497f-ba10-7a63433c309c","http://resolver.tudelft.nl/uuid:90575e43-bf89-497f-ba10-7a63433c309c","Wireless LAN Optimization of HQ audio conferencing system using application layer protocol","Elavarasu, P.P.","Venkatesha Prasad, R.R. (mentor); Rao, V. (mentor)","2012","The goal of this thesis was to optimize a audio conferencing system that communicate via the standard Wi-Fi network and to provide a maximum transmission delay of 5 ms (one way end to end delay of 10 ms) when coexisting with an interferer that use up to 50% of the channel bandwidth. First the QoS performance provided by the existing 5th generation Wi-Fi standard is analysed in detail. The performance provided by WMM feature in the standard did not satisfy the requirements of the audio conferencing system. This lead to designing a protocol at the application layer (WHAP) that provided scheduling and retransmission mechanism that made it possible to achieve the required performance. The WHAP based audio conferencing BSS was analysed under different interference scenarios both in theory and in simulated environment using network simulator OPNET. The results show the possibility to provide the required performance when coexisting with an interference of up to 50% as targeted. Finally, it can be concluded that the performance of the audio conferencing setup configured with WHAP enabled stations provide much better performance compared to the available state-of-art standard techniques.","","en","master thesis","","","","","","","","2012-08-29","Electrical Engineering, Mathematics and Computer Science","Telecommunications","","","",""
"uuid:36612f40-f875-4758-8153-5ff6cd480288","http://resolver.tudelft.nl/uuid:36612f40-f875-4758-8153-5ff6cd480288","Online swing leg trajectory optimization for a force controllable humanoid robot","Smith, J.P.","Van der Helm, F.C.T. (mentor); Wisse, M. (mentor)","2012","Humanoid robots are well suited to function in a world designed for humans. To function autonomously, it is important that the robot be robust against disturbances. Quick and accurate positioning of the swing foot allows the robot to recover from large disturbances. This thesis presents a novel controller that provides accurate foot positioning capability while reducing control effort com- pared to the existing swing leg controller. The presented controller uses model predictive control techniques to optimize the joint trajectories. Two cost functions are compared in a simulation study, the minimum of the sum of squared torques and the minimum sum of squared torque changes. The minimum torque change cost function has a 20% lower mechanical energy cost compared to the minimum torque cost function, but suffers from a significantly larger positioning error at the end of the step and reduced ground clearance. Compared to the existing controller, the proposed model predictive controller with a minimum torque cost function decreases the mechanical energy requirements by approximately 35% for a forward step while improving the accuracy. Negative work done by the actuator to decelerate the foot at the end of the swing is significantly reduced compared to the foot trajectory controller. The main disadvantage of the proposed model predictive controller is high computational cost. Therefore, a secondary controller is introduced, which plans joint trajectories using quintic splines trough a number of via-points. Mechanical energy consumption during the swing is comparable to the existing controller, but bandwidth requirements are reduced. In conclusion, the proposed model predictive controller with a minimum torque cost function is able to quickly and accurately position the foot, while reducing total energy consumption by exploiting the natural dynamics of the swing leg.","","en","master thesis","","","","","","","","2012-09-28","Mechanical, Maritime and Materials Engineering","BioMechanical Engineering","","BMD","",""
"uuid:150088d8-6349-49c7-b4c3-6c6e4a211bf8","http://resolver.tudelft.nl/uuid:150088d8-6349-49c7-b4c3-6c6e4a211bf8","Assessing the benefits of a field data management tool","Moran, M.S.","De Ridder, H.A.J. (mentor); Nederveen, S. (mentor); Koutamanis, A. (mentor)","2012","","data management","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Construction management and engineering","",""
"uuid:5bfd2866-1c16-4fc9-ab94-b6e4f4b164ba","http://resolver.tudelft.nl/uuid:5bfd2866-1c16-4fc9-ab94-b6e4f4b164ba","Large Scale Fracture Distribution on the Latemar Platform Based on Aerial Photograph and LiDAR Data","Nasution, A.","Bertotti, G. (mentor); Hardebol, N. (mentor)","2012","Fracture reservoirs have many inherent obstacles to proper analysis, due to their difficulties in prediction, evaluation, and characterization. Moreover, fractures not only increase reservoir permeability, but also fundamentally alter reservoir connectivity and heterogeneity. Several subsurface data can be used for fracture distribution and characterization of the reservoir with some limitations. Well data can only be used in the near wellbore region and are not always easy to extrapolate away from the well. On the other hand, most fractures are subseismic dimensions. Minimizing the uncertainty of modeling naturally fractured reservoirs could be achieved by outcrop studies that are lithological and historical analogues to the reservoir, which could be used to extrapolate fracture data outside the well control. This project is investigating large structures of the Latemar isolate carbonate platform in Northern Italy by using aerial photograph and LiDAR data (Light Detection and Ranging). From these data, tens of meters to kilometer fractures in Latemar can be identified with two main fracture sets which are perpendicular to each other in the NNW-SSE and ENE-WSW orientation, respectively. On the other hand, one of the shortcomings of the field work which can be covered by LiDAR is that this technology has the capability to efficiently capture inaccessible areas. Furthermore, LiDAR data can give direct insight to the 3D distribution (e. g. fracture intensity, P32).","fracture; LiDAR; Latemar","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Reservoir Geology","",""
"uuid:070476e2-102e-42f3-a636-da5e922ef6fd","http://resolver.tudelft.nl/uuid:070476e2-102e-42f3-a636-da5e922ef6fd","Injectivity in Non-Newtonian two-phase flow","Latooij, C.A.","Rossen, W.R. (mentor)","2012","A recent study [Rossen et al., 2011] developed a fractional-flow model (an extension of the Buckley-Leverett theory for a waterflood) for non-Newtonian two-phase flow (surfactant solution and gas) around a well. In this fractional-flow model two effects are represented: the decrease in water saturation Sw during gas injection in a SAG process and the non-Newtonian mobility with respect to radial position in the near-wellbore region, respectively. An important implication of this model is the relationship between these effects and injectivity. In this paper we create a model which determines injectivity as a function of time from data for water saturation and radial position, for shear thinning foam, modeled as a power-law fluid, in the near-wellbore region. We take the results generated by Rossen et al. and recast them in a form from which injectivity can be calculated. We compare the results, with both changing water saturation and non-Newtonian rheology, to two simpler cases: the effect of non-Newtonian rheology alone (effective viscosity changes with radial distance but Sw is assumed uniform) and the effect of water saturation alone (Sw varies with radial position but non-Newtonian effects are ignored) on injectivity. From these results we analyse whether or not it is essential to model both effects as in Rossen et al. We observe that the effects of non-Newtonian rheology on injectivity are far greater than those due to changing water saturation Sw in the near-wellbore region and that it is therefore not necessary to model both effects; one only needs to account for shear thinning. One limitation of this fractional flow model is that it disregards foam collapse. We found that this collapse of foam near the well has a much larger effect on injectivity than shear-thinning behavior. In order to determine how much the non-Newtonian rheology and nonuniform water saturation really affect injectivity, the foam model needs to be extended to include foam collapse. Furthermore, the factor (rw/re) in dimensionless position xD should not be disregarded in the MOC calculations, as it was in Rossen et al. [2011]. Doing so affects mobilities very close to the well and therefore affects injectivity. The model described in this paper focuses on non-Newtonian “strong” (shear thinning) foam flow; however, the approach could also be extended to polymer injection.","fractional flow; MOC; injectivity; two phase flow; shear thinning; changing water saturation","en","bachelor thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","","",""
"uuid:d01cc171-e691-4fb6-b258-5ef34952c697","http://resolver.tudelft.nl/uuid:d01cc171-e691-4fb6-b258-5ef34952c697","Developing a Winning Product Strategy","Peterson, R.K.","Smulders, E.H.M. (mentor)","2012","As a startup competing in a saturated market with large companies and established brands, Oto will need to effectively market itself to the targeted consumer. Part of Oto’s success will result from the brand’s product portfolio and design strategy. It is not only important for Oto products to be relevant to consumer tastes, but they will also need to appropriately represent the brand if Oto is to assert being a healthier and sustainable alternative to other enhanced water solutions. In addition to these drivers, products will also need to successfully distinguish themselves in the market and be feasible to produce from a technological and manufacturing standpoint, otherwise it may difficult to implement them.","bottle; water","en","master thesis","","","","","","","Campus only","2013-08-27","Industrial Design Engineering","Industrial Design","","Master of Science Strategic Product Design","",""
"uuid:88660d3f-76d3-4b98-abc4-c3db68b322fb","http://resolver.tudelft.nl/uuid:88660d3f-76d3-4b98-abc4-c3db68b322fb","Analysis of Grain Size Distribution for samples from the North Caspian Sea Basin","Lier, J.S.","Hoogendoorn, R.M. (mentor)","2012","The ultimate goal of this project is to identify the controls of the sedimentary systems of the North East Caspian Sea, in order to improve the capabilities for the assessment of the effects of the construction of future installations in the vicinity of Karain and Aktote islands on the coastal dynamics. Additionally, it is desirable to enable comparative analyses and the selection of more environmentally acceptable route of the future sealines/pipelines therefore assisting the planning of future production facilities such as artificial islands, platforms and pipelines. Grain size analysis is important in this context for several reasons. Not only is it a basic descriptive measure of the sediment, but it can also be characteristic of sediments deposited in certain environments. It may also yield information about additional properties such as the physical mechanisms acting during transportation and deposition or the permeability of the sediment. In order to obtain this information, cores from five separate boreholes were taken from the North Eastern Caspian Sea and analyzed. This was done using a Hiac Royco Model 3000, which employs the light blocking method of particle counting. This report discusses both the geology of the region and the various methods for particle size counting; and explain the choice for the light blocking method. Finally, the results of the analysis are presented and interpreted.","grain size distribution; Kazakhstan","en","bachelor thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Applied Earth Sciences / Applied Geology","",""
"uuid:fa7394c1-36ae-4b09-adca-d274d4dc12cb","http://resolver.tudelft.nl/uuid:fa7394c1-36ae-4b09-adca-d274d4dc12cb","Strategic Niche Management of Biogas technologies in the Netherlands","Roelse, B.","Quist, J. (mentor); Korevaar, G. (mentor)","2012","","natural gas; biogas; green gas; sustainable energy; transition management; strategic niche management","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Innovation Systems","","","",""
"uuid:593ba177-be25-437d-aa4e-58bfab7cbdaf","http://resolver.tudelft.nl/uuid:593ba177-be25-437d-aa4e-58bfab7cbdaf","Control Architecture and Utility Maximization for a Smart Grid based Energy Community","Abegaz, B.W.","Kuipers, F.A. (mentor); Negeri, E.O. (mentor); Kluin, M. (mentor); Verhoeff, S. (mentor)","2012","This thesis presents a control architecture and utility maximization mechanisms for a smart grid based energy community. The particular focus is upon a central server based, utility-oriented energy community which is composed of producer-consumer (prosumer) households each having a home gateway, an energy management system, smart meters, production units and appliances. To find out how such an energy community could be optimally managed from a central server, the type of intelligence required for the different nodes in the energy network has been identified. In addition, different control mechanisms that enable the energy community to make an optimal use of its energy resources are explored. Moreover, utility maximization mechanisms have been implemented on the aggregate energy profile of the energy community targeting three main objectives namely maximizing the aggregate greenness, minimizing the aggregate energy cost and maximizing the prosumers’ comfort. Maximizing the aggregate greenness aims to maximize the level of consumption of renewable energy resources using a novel mechanism that reduces the difference between the supply of and demand for renewable energy resources. Minimizing the aggregate energy cost aims to reduce the peak to average ratio of the aggregate energy profile of the energy community using direct mechanisms for energy cost minimization and a novel appliance based pricing scheme. Maximizing the prosumers’ comfort aims to preserve the schedule preference of prosumers. The mechanisms above are designed and implemented under a research setting of a renewable energy company that manages an energy community composed of central servers which control household, building and/or industrial prosumers.","Smart Grid; Control Architecture; Utility Maximization; Optimization Mechanisms; Greenness","en","master thesis","","","","","","","","2012-08-31","Electrical Engineering, Mathematics and Computer Science","Telecommunications","","Network Architectures and Services","",""
"uuid:19c9de73-7aaa-48db-85ce-78395a5b1309","http://resolver.tudelft.nl/uuid:19c9de73-7aaa-48db-85ce-78395a5b1309","Solvent enhanced waterflooding in fractured reservoirs","Zholdybayeva, A.","Bruining, J. (mentor); Farajzadeh, R. (mentor); Chahardowli, M. (mentor)","2012","Oil recovery in fractured reservoirs by water flooding critically depends on the wetting properties of the matrix blocks between the fractures. The recovery from oil-wet reservoirs is almost negligible. In incompletely oil-wet systems, the presence of initial water may change the wettability characteristics so that very slow imbibition and some oil recovery can occur. The hypothesis in this thesis is that water soluble solvents enhance the wettability change and lead to enhanced recovery. Another mechanisms is that the water soluble solvent dissolves in the oil and oil is recovered due to swelling. The solvent may also decrease the oil viscosity and the interfacial tension between the oleic and aqueous phases. This thesis comprises of an experimental study into the recovery enhancement by water soluble solvents (diethyl ether). We used an Amott imbibition cell studying oil saturated samples of various wettabilities, permeabilities using oil of different viscosities and two different solvent concentration in the aqueous phase. In the first stage of the experiment the water-wet core was exposed to brine without solvent. In a second stage the core was put in a new Amott cell, which was filled with solvent/ brine mixture. The additional recovery was small. We found that the oil recovery is faster when the oil viscosity is lower, but the ultimate recovery is about the same. The recovery with higher permeable samples is faster, but ultimate recoveries are close. Low permeable samples benefit from the presence of solvent, but the effect is rather small. For the oil-wet samples we also started with exposing the core into pure brine without solvent. In spite of being oil-wet, oil was recovered from these samples. In view of the large inverse Bond number it would appear unlikely that this a gravity drainage effect; however the produced oil droplets are coming from the top. Contrary to the water samples there was a significant increase in recovery rate when the sample is transferred to another Amott cell where it is exposed to a mixture of solvent and brine. Now oil drops come from all sides. Therefore it is concluded that wetting alteration is the main mechanism of water soluble solvent enhancement in partially oil-wet cores. The effect of solvent on completely water-wet cores is less but significant.","solvent; spontaneous imbibition; fracture","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Petroleum Engineering","",""
"uuid:31d7efee-8b65-4dbe-bde2-20c07bec933d","http://resolver.tudelft.nl/uuid:31d7efee-8b65-4dbe-bde2-20c07bec933d","Design and Implementation of a Novel Force and Brake Pressure based Anti-lock Braking System","Kerst, S.M.A.A.","Holweg, E.G.M. (mentor)","2012","","ABS; anti-lock braking system; hydrolic circuit modeling; force sensing baring; brake pressure control","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Precision and Microsystems Engineering","","","",""
"uuid:00a01596-3c53-4dbf-b47a-27c91985fd90","http://resolver.tudelft.nl/uuid:00a01596-3c53-4dbf-b47a-27c91985fd90","Data analytics at work","Meens, V.F.","Van den Berg, J. (mentor); Lukszo, Z. (mentor); Van Dijke, A. (mentor)","2012","Data mining promises to make life easier for business decision makers and analysts. Therefore data mining has a great history in the academic field and in the nowadays also in various other areas such as finance and retail there is a large amount of general data mining literature available. However, to be able to apply data mining to a business field where data mining is not used yet, like the purchasing and sales department, it is necessary to translate the business questions correctly to data mining tasks which is a difficult task. This research attempts to enable consultants to determine effective data analytics tasks for given business questions in order to answer those questions and be able to give companies advise. The result is a data mining process framework for consultants and advise on how this can be embedded in business.","data mining; process framework; business performance","en","master thesis","","","","","","","Campus only","2013-08-24","Technology, Policy and Management","Energy & Industry","","Systems Engineering, Policy Analysis and Management","",""
"uuid:acdd5013-19e3-4cc3-83e6-1e0736fbf46f","http://resolver.tudelft.nl/uuid:acdd5013-19e3-4cc3-83e6-1e0736fbf46f","Ultrafilters in de Combinatoriek","Smid, T.T.","Hart, K.P. (mentor); Coplakova, E. (mentor)","2012","Ultrafilters in de combinatoriek","","nl","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","","",""
"uuid:ecf0556d-d0e4-40f9-9f42-25228fb8688f","http://resolver.tudelft.nl/uuid:ecf0556d-d0e4-40f9-9f42-25228fb8688f","Improving the Algal Bloom Prediction on the North Sea by Dual Ensemble Kalman Filter in GEM Model","Zhang, D.","El Serafy, G.Y.H. (mentor)","2012","Increasingly, the phytoplankton blooms (algal blooms) become a public health concern and a worldwide ecological problem. The Generic ecological model (GEM) plays a very important role to assess ecological quality of the Dutch coastal waters and the southern North Sea. Algal blooms can also be predicted by the GEM model mainly through chlorophyll-a concentration. However, GEM contains large uncertainties caused by errors in both the model itself and the input. Data assimilation techniques are being used to reduce these uncertainties and improve the model forecast for chlorophyll-a concentration. In the meantime, data assimilation also provides an efficient approach to estimate the parameters. Several data assimilation schemes based on the dual Ensemble Kalman Filter will be compared with each other in this work. Based on the synthetic measurement, the superior scheme will be carried out to assess the data assimilation result for a longer period. The forecasting result from proposed data assimilation scheme will be compared with deterministic GEM forecasting output from different point of view. Based on the comparison result analysis, the proposed data assimilation scheme is proved to be successfully implemented and satisfactory results are achieved.","GEM Model; Data Assimilation; Ensemble Kalman Filter; Parameter Estimation; Chlorophyll-a Concentration","en","master thesis","","","","","","","","2012-08-21","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","","",""
"uuid:3c321045-2a4d-4fd9-984b-b60a6b0ff3bd","http://resolver.tudelft.nl/uuid:3c321045-2a4d-4fd9-984b-b60a6b0ff3bd","Computing the vertical density and seismic velocity profiles from multi-angle reflection data: Error analysis","Meijer, W.Y.","Slob, E.C. (mentor)","2012","Numerical models were used to recursively compute the density profile and the seismic velocity profile of three different artificial models of the underground from primary reflection images obtained from multi-angle incident plane wave reflection data. The aim is to investigate the effect of errors in the obtained primary reflection amplitudes on the recursive construction of the vertical density-velocity profiles. The reflection coefficients needed for the computations were obtained by solving the Marchenko equation for different angles of incidence. The recursive computation shows errors occur in every layer, but the error does not necessarily grow with each step. This implies the error does not propagate into the recursive scheme. Adding a random error to the reflection coefficients yielded results in a greater error in each individual layer with respect to the values obtained without an added error. Using a too large angle of incidence can result in too few primary events in the autofocused data, distorting the computed values.","autofocusing; error propagation","en","bachelor thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Applied Geophysics and Petrophysics","",""
"uuid:0ab476db-0ef3-4126-baec-bc59df800b9c","http://resolver.tudelft.nl/uuid:0ab476db-0ef3-4126-baec-bc59df800b9c","The effect of flocculant on the sedimentation and consolidation of fine tailings","Hijman, R.M.","Van Paassen, L. (mentor)","2012","Mixing fine mine tailings with flocculant is a method for water retention and accelerated sedimentation in the oil sand industry. One of the known effects of adding flocculants to soil is the resulting porous structure, which leads to fast dewatering but could possibly have a lower final compaction. The objective of this paper is to study the consolidation effect of adding the flocculant, compared with the natural tailings, too figure out the structural difference in final compaction state. In this paper, a river clay is studied instead of fine mine tailings, to avoid the effect of location distinct chemicals. Column studies were performed in which sedimentation and consolidation of the clay mixture, with and without flocculant were examined. CT-scans of the columns after 26 days of consolidation were carried out to evaluate the effects of the flocculant. The results lead to a consistent conclusion: final consolidation of the natural clay is significant lower volume, compared with flocculant mixture. Further (literature) research in the reliability and density relation of the CT-scans is recommended.","tailings; flocculant; consolidation","en","bachelor thesis","","","","","","","","2012-08-30","Civil Engineering and Geosciences","Geoscience & Engineering","","Geo-engineering","",""
"uuid:10fa2cde-9149-4ea1-b615-d2a4ace9890a","http://resolver.tudelft.nl/uuid:10fa2cde-9149-4ea1-b615-d2a4ace9890a","Terra Cotta in Transition: Connecting the traditional terra cotta craft village Thanh Hà to potential markets","De Koning, J.I.J.C.","Brezet, J.C. (mentor); Crul, M.R.M. (mentor)","2012","Thanh Hà is a traditional craft village in central Vietnam. For centuries the families in the village have been making terra cotta products from the local found clay. Traditionally Thanh Hà focused on making building materials for the houses of nearby H?i An, a city only two kilometers from Thanh Hà. For centuries the bricks, floor and roof tiles produced in Thanh Hà have been used to construct the houses and buildings in H?i An. Industrialization is getting up to speed in Vietnam and the manufacturing units in the traditional pottery villages Thanh Hà are small in scale, fragmented, with outdated technology, and the craftsmen of the village can not meet large orders from overseas. The production of tiles and bricks has been discontinued due to the environmental pollution it causes. This project formulates a strategy for the Vietnamese pottery craft village Thanh Hà in order to connect their products better to the new target markets: the tourists. The initiative to support the craftsmen in Thanh Hà comes from the Vietnamese architecture firm Nha Viet. Nha Viet identified the need for innovation of the pottery craft in Thanh Ha in order to preserve and promote the craft of making terra cotta products in the village. As an architecture firm they have taken the initiative to build a Terra Cotta Park that will host a museum, shop and innovation centre. This project is aimed at formulating an innovation strategy for the terra cotta village Thanh Ha that can be executed through the Terra Cotta Park that Nha Viet is building at the moment. In 2013 the Terra Cotta Park will be opening its doors and the first steps of the innovation strategy that is proposed in this project have already been taken. The foundation of the end result of this project, the innovation strategy, is summarized and visualized in a Strategic Road Map. Design guidelines support this strategy by stimulating a more user centered design process and personas of specific tourist groups will help understand the target market better. This strategy will be executed by Nha Viet through the Terra Cotta Park in Thanh Hà. The strategy must ensure that the core strengths of Thanh Ha are leveraged. The core strength of Thanh Ha is making hand crafted terra cotta products that are inspired by local culture. In order to ensure these two aspects of authenticity of the products, the TCP needs to educate the craftsmen well. Priorities for Nha Viet therefor lie with educating the craftsmen and teaching them to design products that fit the target market but are also true to their core strengths. The use of the design guidelines that focus on producing products that confirm to these strengths are important in the success of the outcome of the design process. Nha Viet must encourage the designers to document this process too and let a documented knowledge base grow almost automatically this way. Working together with craftsmen has proven to be more difficult than assumed in the beginning of this project. For other projects that also involve working together with craftsmen, it important to engage them in the process. Although they are used to get orders and execute them, empowering them to make their own decisions will stimulate innovation. It is more valuable to teach them how to make products than giving them a product. This is a process that takes time and devotion of the parties that work together with craftsmen. The strategic road map is the unification of all steps that need to be taken with regards to the different levels. The road map is a starting point for Nha Viet to execute and further define the strategy for the TCP. Other students have already applied some of the deliverables elsewhere and proven that they can be valuable for a broader public. The strategy and road map are divided in three phases: preparatory phase, first year of opening of the TCP and the future. (1) The first year of preparation, when the TCP is still being built, the focus of the strategy must be on creating a good relationship between the craftsmen and building an authentic product portfolio. This year is the year the basis is founded and the company that is the TCP is created. (2) The second year, the near future, is the year that the TCP is open for the first time. The foundation that is laid out in the preparatory year must be solid and ensure that the TCP can start producing turnover. Over the course of the year the focus must be on improving quality of the products and services offered. (3) The far future, when the TCP will be ope for a few years, the business must run smoothly. The basis is solid and an authentic and high quality portfolio has been established with satisfied customers. This is the time the TCP can start up scaling and widening their target markets. Diversification of products and markets will need to be investigated by then. This project has been executed in only seven months but defines the next five years of the future of the TCP. Therefore Nha Viet needs to be flexible towards changes that might occur. This project has unveiled the core strengths of Thanh Ha and it is important that the TCP keeps the craftsmen close to these core strengths and does not let them float into other directions, far away from their core strengths.","innovation; co-creation; road map; terra cotta; product strategy; clusters","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Master of Science Strategic Product Design","",""
"uuid:0290c0c2-c076-4605-ab01-e202aadc7336","http://resolver.tudelft.nl/uuid:0290c0c2-c076-4605-ab01-e202aadc7336","Multi Point IPR Uncertainty Quantification: novel approach for a next generation reservoir simulator","de Reus, Jasper (TU Delft Aerospace Engineering)","Bijl, Hester (mentor); Dwight, Richard (mentor); Delft University of Technology (degree granting institution)","2012","It is investigated if a Multi Point Inflow Performance Relationship (MIPR) using Uncer- tainty Quantification (UQ) can lead to a step change in completion design. The MIPR model consists of several Kuchuk IPR models coupled with a wellbore network, and is verified against a discretized model. It is found that the assumption of artificial no-flow boundaries for this model is limiting, which leads to an overprediction of the distributed productivity index. A calibration using Markov Chain Monte Carlo (MCMC) is pre- formed, which incorporates both epistemic and aleatory model parameters. In addition, a more efficient ‘partitioned MCMC’ is investigated, which shows promising results. The UQ MIPR model can predict the change in productivity index due to a uniform com- pletion skin profile, and can give an indication of results for a non-uniform change in completion skin. In conjunction with a discretized model, a MIPR model can lead to a step change in completion by providing information to a production technologists earlier on in field development.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:c830f7ed-ab32-4551-b0b9-f99c78c267b1","http://resolver.tudelft.nl/uuid:c830f7ed-ab32-4551-b0b9-f99c78c267b1","Design a Comfortable Laptop Bag for Fashion-conscious Professionals","Liu, Y.","Vink, P. (mentor); Ruiter, I. (mentor)","2012","The graduation project has three phases. The first phase is aimed to conduct market analysis and comfortableness criteria exploration in order to establish design objective and design criteria. The design objective is “Design a stylish, protective and two-year durable laptop bag for the target life style segment, which is also comfortable to use and easy to use, with realizable production and cost control.” So the design criteria contain five aspects in total, i.e. form giving, functional use, comfortableness, production and marketing. Before concept elaboration phase, design explorations have been conducted in three aspects, i.e. style design, functional uses as well as comfortable aspect. Afterwards, in the elaboration phase, one style has been chosen by Zomoy to integrate the exploration results of functional uses and comfortableness. Then the concept has been elaborated and made with prototypes at manufacturer. Afterwards, user tests have been conducted to test the functional uses and comfortableness. Conclusions and recommendations have been made according to test results. Later, production and market implementation have been elaborated in the end.","comfortable; ergonomic; fashion; laptop bag","en","master thesis","","","","","","","Campus only","2013-08-24","Industrial Design Engineering","Industrial Design Engineering -AED","","","",""
"uuid:96573fd5-3f7e-4b3d-9fd9-c10ea4fd44e5","http://resolver.tudelft.nl/uuid:96573fd5-3f7e-4b3d-9fd9-c10ea4fd44e5","Step location prediction for bipedal robots: Evaluating and improving Capture Point theory","Semeijns de Vries van Doesburgh, R.J.","Wisse, M. (mentor); Schwab, M. (mentor); Wang, S. (mentor)","2012","There are many good reason for the development of a robust bipedal walking robot. However, until recently this development was hampered by the lack of a disturbance rejecting locomotion algorithms. With the introduction of Capture Point theory by Pratt et al. [2006] this problem has been largely solved. Capture Point theory describes the point on the ground to which a biped must step to prevent a fall. This point is called the Instantaneous Capture Point (ICP). The ICP is updated every tick and in this way continuously indicates where to step to. The last location of the ICP before the foot touches the ground is called the Capture Point. To prevent the biped from falling the foot must touch the ground as close to the Capture Point as possible. It is important to have an accurate prediction of where this will be because the step location must be determined ahead of time. Thus, an accurate prediction of the ICP is required. The behaviour of the ICP is described using the Linear Inverted Pendulum Model (LIPM). This thesis focuses on establishing and improving the accuracy with which the LIPM predicts the ICP. First it is shown that the LIPM currently provides an inaccurate estimate of the ICP on the robot TUlip. After identifying and isolating a controller issue the improved situation indicates that the LIPM predicts the ICP trajectory to a standard deviation of 3.77%. The latter half of this thesis focusses on exploring the limits of this accuracy. By implementing a faster swing leg controller the accuracy of the LIPM is shown to decrease for increasing swing leg accelerations. An extension to the LIPM is then proposed that can account for this using external forces. This extension provides a marginal increase in accuracy. Finally, an analytic solution to the LIPM with external forces is found so that it can be applied in a real-time environment. At the conclusion of this thesis three things have been achieved. The first is that the LIPM has proven to be an accurate predictor of the ICP on our robot TUlip. The second is that the LIPM has been expanded to include external forces and that an analytic solution to this model was found. Finally, two issues with faulty controllers have been identified on TUlip and initial workarounds have been implemented.","biped; robot; TUlip; Capture Point; linear inverted pendulum; Instantaneous Capture Point","en","master thesis","","","","","","","","2012-09-28","Mechanical, Maritime and Materials Engineering","BioMechanical Engineering","","BMD","",""
"uuid:2f5d0dcd-dd5e-436e-a5e3-94a183b99beb","http://resolver.tudelft.nl/uuid:2f5d0dcd-dd5e-436e-a5e3-94a183b99beb","Limiting and shock detection for discontinuous Galerkin solutions using multiwavelets","Vuik, M.J.","Ryan, J.K. (mentor)","2012","Many areas such as climate modeling, shallow water equations, and computational fluid dynamics use nonlinear hyperbolic partial differential equations (PDE’s) to describe the behaviour of some unknown quantity. In general, the solutions of these equations contain shocks, or develop discontinuities. To solve these equations, various types of numerical methods can be used, such as finite difference, finite volume and finite element methods. In this master thesis, the discontinuous Galerkin method (DG) is used. To efficiently apply DG in case of discontinuous solutions, limiting techniques are used to reduce the spurious oscillations, that are developed in the discontinuous regions. Unfortunately, most of the limiters do not work well for higher order approximations, or multidimensional cases. Originally, the project focused on limiting DG solutions using multiwavelets. However, it is very hard to limit the solution using the multiwavelet decomposition. We did discover that the multiwavelet expansion is quite practical for shock detection. This report describes the pros and cons of multiwavelets as a limiter and shock detector for limiting DG.","discontinuous Galerkin; multiwavelets; limiting; shock detection","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Delft Institute of Applied Mathematics","","","",""
"uuid:2d568014-8acb-4e8e-9d39-91c76f499a46","http://resolver.tudelft.nl/uuid:2d568014-8acb-4e8e-9d39-91c76f499a46","Simulation of Geochemical Processes during Low Salinity Water Flooding by Coupling Multiphase Buckley-Leverett Flow to the Geochemical Package PHREEQC","De Bruin, W.J.","Zitha, P.L.J. (mentor)","2012","Simulations carried out for low salinity water flooding often do not include geochemical processes. Salt concentration, and thus the salinity, is modelled as a water tracer that does not react with the reservoir formation. The goal of this MSc thesis is to improve the understanding of the influence of geochemical processes on the mixing of formation water and injection water, during low salinity water flooding. The geochemical processes taken into consideration are CO2-buffering, ion exchange and mineral dissolution. An initial understanding of the geochemical processes was gained by performing numerous simulations with the U.S. Geological Survey geochemical package PHREEQC. A limitation of this simulator is that it only allows for single-phase aqueous flow. To overcome this limitation, a multiphase Buckley-Leverett simulator has been developed in MATLABR that couples oil-water flow to the geochemical package PHREEQC. Subsequently, the newly developed simulator was used to study the effects of geochemical processes on the increase in oil recovery. In addition, simulations were performed to study low salinity slug sizes and dispersion. Although the low salinity mechanisms are still subject of extensive research, it is assumed that increases in oil recovery due to low salinity water flooding can be modelled as a change in relative permeability, from oil- or mixed-wet to more water-wet. Simulation results showed that fully removing calcite (calcite content 0.97 Wt%) from the reservoir, requires an excessive amount of pore volumes of low salinity water to be flushed through the reservoir. Therefore, dissolution of all calcite seems a near injector well-bore effect only. In the majority of the case study field, the minimum salinity level reached will be around 910 ppm. Simulations also showed that, during the injection of low salinity water into the case study field, Na+ attached to the cation exchanger is replaced by Ca2+. This is a result of the preferential adsorption of double valence ions when lowering the ionic strength, and decreasing the Na+/Ca2+ ratio in the reservoir. In simulation runs where geochemical interactions were included, higher salinity levels were observed in the reservoir compared to passive salt tracer simulations. In addition to an increase of 160 ppm due to the initial calcite dissolution, a secondary increase due to calcite dissolution as a result of cation exchange was noted. Depending on the amount of exchange sites, significantly higher ion concentrations (?2000 ppm) were observed. As the low salinity effect is assumed to be triggered solely by the salinity level, including geochemical interactions can therefore lead to a lower low salinity EOR potential. The increase in oil production observed for a non-geochemical affected secondary low salinity injection scheme (1.0 pore volume formation water followed by 4.0 pore volumes low salinity water) is 5.8% of the originally oil in place (OOIP) compared to a high salinity injection scheme (5.0 pore volumes of formation water), for low salinity thresholds ranging from 1000-3000 ppm. By including geochemical effects, the amount of incremental oil was 0.5%, 3.2%, 5.7% or 5.8% of the OOIP for a salinity threshold of 1000 ppm, 1500 ppm, 2000 ppm, or 3000 ppm, respectively. This indicates that, especially for low values of the low salinity threshold, geochemical interactions may be of importance for the EOR potential. However, it is important to note that the amount of calcite and number of cation exchange sites have been calculated based on bulk rock data. In addition, it has been assumed that the aqueous phase is in contact with all calcite and clay. By doing so, the effects of the geochemical interactions are overestimated. Dispersion was found to be very important for the determination of minimum low salinity slug sizes. However, no accurate dispersion data were available for the case study field to verify the current model. Simulation results showed that frequent (2 days/month) injection of seawater slugs during low salinity flooding may increase salinity levels throughout the whole reservoir above the threshold values, effectively eliminating the increase in oil production. Injecting larger seawater slugs on a less regular interval (2 weeks/year) results in fractions of the reservoir having a higher salinity than the threshold value. However, the overall impact on the cumulative oil production was far less (-0.6% of the OOIP compared to no seawater slugs). An interesting continuation of this project would lie in a detailed study of the chemical composition of the rock surface. As the cation exchange sites are likely to be less, the impact of cation exchange induced calcite dissolution on the salinity is reduced. This will result in an increase of low salinity EOR potential.","low; salinity; water; injection; flooding; oil; eor; ior; phreeqc; geochemistry; geochemical; simulation; buckley; leverett; interactions","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","","",""
"uuid:dbe3f9b7-da12-4593-b5f1-0ddf5953ba65","http://resolver.tudelft.nl/uuid:dbe3f9b7-da12-4593-b5f1-0ddf5953ba65","Information Sharing in Global Containerised Trade: From Abstract Organizational Values to Concrete Systems","Olthof, K.L.","Aldewereld, H.M. (mentor)","2012","During the design of a new technology many design choices need to be made at a high level of detail. These detailed design decisions shape the nature of the resulting technology. The reasoning underlying each decision is ultimately based on abstract organizational values such as integrity, trust, security, or fairness. These values are, however, typically only implicitly involved in the design process. As a result, the technology may exhibit different characteristics than were foreseen because it is not in compliance with these abstract values. To ensure compliance, values should be systematically incorporated in the design. This study builds on recent advances in the area of Value Sensitive Design, which aims to take values explicitly into account from the design phase onwards as to achieve compliance by design.","Value Sensitive Design; Information Sharing; Containerised Trade; Service-Oriented Computing; CASSANDRA project","en","master thesis","","","","","","","","","Technology, Policy and Management","Infrastructure Systems & Services","","Information and Communication Technology (ICT)","",""
"uuid:a1ffdbad-0620-42ea-a02c-a807a2b932d8","http://resolver.tudelft.nl/uuid:a1ffdbad-0620-42ea-a02c-a807a2b932d8","DC/DC Converter For Helicopter Starter/Generator","Hailu, T.G.","De Haan, S.W.H. (mentor); Brink, E.A. (mentor)","2012","The use of power electronics DC/DC converters in aircraft has increased due to the state-of-art converters developments. However, the volume, efficiency and mass of such converters are critical issues. Each component of the DC/DC converters contributes to the total mass of the system. By designing each component, optimized to have small volume, high efficiency and small mass, the total system can have small volume, small mass and high efficiency. This master project explores design optimization of dual active bridge (DAB) DC/DC converter components: the capacitors, the cooling system and the transformer. Different types of capacitors are compared in terms of mass, volume and loss for the input and output capacitors. After selecting the types of capacitors, the number, volume and mass of the input and output filter capacitors are optimized by interleaving two and three dual active bridge DC/DC converters. The thermal resistance of external cooling system for the selected switches is optimized by a trade-off between the junction temperature of the switches and the losses induced. The transformer is optimized by an evolutionary algorithm, particle swarm optimization, for volume, power loss and required maximum allowable thermal resistance for cooling. The three interleaved DAB is found to be attractive in terms of less capacitor number which leads to a small volume and mass. It is also found to be attractive in terms of thermal management of the transformers designed using the particle swarm optimization. This decreases the volume of cooling systems needed for the transformer. Interleaved three DAB is selected as best in terms of volume, mass and thermal management.","Dual Active Bridge; Particle Swarm Optimization; Leakage Inductance","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Electrical Power Engineering","","Electrical Power Processing","",""
"uuid:f5cb2d1b-bdf3-46ab-9f9c-4a6836884720","http://resolver.tudelft.nl/uuid:f5cb2d1b-bdf3-46ab-9f9c-4a6836884720","Tidal power in the Klabat bay, Indonesia: An application of the SEPAM design methodology","De Groot, N.C.","Herder, P.M. (mentor); De Vries, L.J. (mentor); De Bruijne, M.L.C. (mentor); Tamboer, R. (mentor)","2012","The design of complex technological systems required an early outlook of institutional issues. The paper suggests a design methodology to combine institutional design and engineering design. The design methodology is applied to a case study of tidal power development in the Klabat bay, Indonesia. In the case study it is shown that there are interactions between institutional design and technological design. Ignoring the institutional environment the financial and economic performance of tidal power in the Klabat bay is poor for all options. Incorporation of institutional design allowed for creative thinking that could allow for the decision to continue feasibility research. The inclusion of institutional design therefore proved valuable. The design process did become more complex.","engineering design; tidal power; institutional design; tidal barrage; tidal stream","en","master thesis","","","","","","","","2012-08-24","Technology, Policy and Management","Energy and Industry","","","",""
"uuid:89c912d3-5cbc-4aa8-8c37-aafed89cea51","http://resolver.tudelft.nl/uuid:89c912d3-5cbc-4aa8-8c37-aafed89cea51","Wat is de invariante maat van de gegeneraliseerde kettingbreukafbeelding?","Langeveld, N.D.S.","Kraaikamp, C. (mentor)","2012","In deze scriptie word numeriek de invariante maat gegeven van de gegeneraliseerde kettingbreuk. Resultaten als constante van Khinchine worden vervolgens berekend voor de gegeneraliseerde kettingbreuk. Ook worden convergentie bewijzen gegeven voor zowel de reguliere kettingbreuk als de gegeneraliseerde kettingbreuk. Verdere eigenschappen over de gegenaliseerde kettingbreuk zijn er ook in te vinden. Zo ook een bewijs van existentie van de invariante maat van de gegeneraliseerde kettingbreuk.","gegeneraliseerde kettingbreuk; invariante maat","nl","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","Bachelor","",""
"uuid:2493b6bc-52c3-489a-a12f-3923e24efded","http://resolver.tudelft.nl/uuid:2493b6bc-52c3-489a-a12f-3923e24efded","A decision support system for balancing critical design issues in new service development for the TomTom Mapshop service platform","Van Leeuwen, J.P.","Bouwman, W.A.G.A. (mentor)","2012","A case study research in which a decision support system is designed for balancing critical design issues that stem from the technology part of a business case.","service platform; innovation funnel; critical design issues; decision support system","en","master thesis","","","","","","","","2013-08-24","Technology, Policy and Management","Infrastructure Systems & Services","","ICT","",""
"uuid:be19d28e-891f-4dd3-b7e0-118a175d1ded","http://resolver.tudelft.nl/uuid:be19d28e-891f-4dd3-b7e0-118a175d1ded","Electrical characterization of polymeric DC mini-cables by means of space charge and conduction current measurements","Tsekmes, I.A.","Morshuis, P.H.F. (mentor); Van der Born, D. (mentor)","2012","The world’s first commercial High Voltage Direct Current (HVDC) transmission link was built in 1954 between the Swedish mainland and the island of Gotland. At that time, it was proved that HVDC transmission is technically feasible. Since then, HVDC cable systems have been used worldwide in electrical energy transportation. Most HVDC installations in use around the world today, use paper-insulated, oil-filled type cables. Extruded dielectric cables with cross-linked polyethylene (XLPE) has long been the preferred solution in HVAC applications due to a combination of low material and processing costs, reliability and appropriate mechanical and electrical properties. However, polymeric HVDC cables suffer greatly from space charge accumulation during dc voltage application and from ‘low’ depletion rate of accumulated space charge when the external field is removed. As a result, considerable modifications of the electric field distribution with respect to the geometric Laplacian field occur, especially in case of voltage polarity inversion. This may cause insulation degradation and premature breakdown. Manufacturers are trying to tackle the problems related to space charge phenomena by introducing additives to the insulation or semicon layers. The development of new polymeric materials with improved performance under dc electrical stress requires a thorough investigation of the properties governing charge injection, transport and trapping. Particularly mobility and trap depth distribution are very useful to describe and compare the behavior of different materials from the view point of charge dynamics and field modification. In this thesis, different polymeric mini-cables are examined under DC stresses with regard to their space charge dynamics. Two different types of XLPE insulation and four types of semi-conductive layers compose eight different combinations of mini-cables. The specimens are subjected to space charge measurements and conduction current measurements in order for their electric field thresholds to be determined. The threshold for space charge trapping is an important parameter for the design of insulation systems subjected to dc electrical fields. If the applied electric field exceeds the threshold, charge injected from the electrodes can accumulate in traps located at the interface with electrodes and in the insulation bulk. Furthermore, depolarization characteristics obtained at high electric fields and temperatures, are used in order to further investigate the performance of the mini-cables with respect to their apparent trap-controlled mobilities and trap depths, including the space charge distribution along the trap levels. The main goal of this thesis is to evaluate how the composition of insulation and semi-conductive layers affects the space charge dynamics in polymeric mini-cables.","space charge accumulation; space charge measurements; PEA; pulsed electroacoustic method; DC mini-cables; conduction current measurements; electric field threshold; apparent trap-controlled mobility; trap depth; charge packets","en","master thesis","","","","","","","","2012-08-27","Electrical Engineering, Mathematics and Computer Science","High Voltage Technology and Management","","Electrical Power Engineering","",""
"uuid:09108de7-05ea-4e85-8212-b6506705da77","http://resolver.tudelft.nl/uuid:09108de7-05ea-4e85-8212-b6506705da77","Bilateral Collaborations in Sino-foreign Eco-cities: Lessons for Sino-Dutch Collaboration in Shenzhen International Low-carbon Town","Chen, X.","De Jong, M. (mentor); Van Bueren, E. (mentor); Ravesteijn, W. (mentor)","2012","The increasing concerns about global climate change and rising environmental pressures have prompted countries and cities to explore new sustainable development pattern. The concept of eco-city has been proposed as a potential sustainable urban solution. China as the most populous country in the world, is especially challenged by its rapid urbanization and environmental degradation, and has launched a number of eco-city initiatives in recent years. Among them many are eye-catching bilateral collaboration projects with the engagement of international partners. The growing trend of Sino-foreign eco-city initiatives give rise to the main research question of this study: “What is the role of bilateral collaborations in Chinese eco-city development?” This question is further divided into three sub-questions, among which the first sub-question intends to categorize previous Sino-foreign eco-city collaborations based on distinct features observed through an investigation on eight previous Sino-foreign eco-cities. The second sub-question focuses on the critical success factors influencing bilateral collaborations in Sino-foreign eco-cities at political/institutional, organizational, and individual levels. Finally based on the lesson drawings from previous experience, the study intends to answer the question of what a viable Sino-Dutch collaboration alternative could look like in Shenzhen International Low-carbon Town. Qualitative research methods including case study and comparison are used in the study. Case studies on eight selected Sino-foreign eco-cities present detailed empirical information and analysis systematically. Following the case studies, three types of bilateral collaborations in previous Sino-foreign eco-city projects were concluded: client-provider/designer type collaboration, intergovernmental agreement based collaboration, and JV-based collaboration under joint supervisory board. Based on the case studies, a framework of success factors influencing bilateral collaborations in Sino-foreign eco-cities is also established. With the lesson drawings from previous experience and specific analysis for Shenzhen International Low-carbon Town, two potentially viable Sino-Dutch collaboration alternatives including the cultivating and sufficing collaborations are proposed. Finally, some general findings across the cases are discussed and summarized in the paper. This study intends to fill in the literature gap in international bilateral collaborations in eco-city development by focusing on China’s experience. Besides, it also can contribute to the academic and professional community by making an inventory of existing Sino-foreign eco-city projects. The empirics and findings in this study can also shed light on the design of future bilateral collaborations in Chinese eco-city development with proper adaptations.","","en","master thesis","","","","","","","","2012-08-24","Technology, Policy and Management","Multi Actor Systems Department","","Management of Technology","",""
"uuid:a09c3aa1-3a05-4a83-873a-bb27add13df5","http://resolver.tudelft.nl/uuid:a09c3aa1-3a05-4a83-873a-bb27add13df5","Phasor Measurement Unit Testing","Thi Ai Nguyen, N.","Popov, M. (mentor); Rietveld, G. (mentor)","2012","Our power system nowadays operate as a huge complex machine that often operate close to their stability limit. This means that any disturbances or faults may cause power oscillations and lead to cascade outages. Many efforts, therefore, have been on the way to build new, smart grids. These will be the grids that use the most advance monitoring, controlling, networking, and measurement technologies. One of those technologies is a device known as Phasor Measurement Unit (PMU). PMUs are devices which produce synchronized phasor, frequency and rate of change of frequency estimates from voltage and/or current and a time synchronizing signal [1]. The key driver for PMU technology is the use of the precise time sources provided by GPS satellites to accurately measure the relative voltage and current phase angles at buses across interconnected grids [2]. This technology is capable of directly measuring the phase angles across an interconnected power grid, which is the main advantage that PMUs have over traditional SCADAs. In the thesis, PMU behavior and IEEE Synchrophasor standards have been studied through simulation and measurements. Simulation is done on a software platform whereas measurement is performed at a company, VSL, to test a PMU on its measurement quality.","Phasor Measurement Unit; PMU testing","en","master thesis","","","","","","","","2012-08-31","Electrical Engineering, Mathematics and Computer Science","Electrical Engineering","","Master of Science","",""
"uuid:6dba3b72-4e20-4db9-8f35-a8dbc844c80d","http://resolver.tudelft.nl/uuid:6dba3b72-4e20-4db9-8f35-a8dbc844c80d","Designing a new interactive exhibit","Meeldijk, M.","Gielen, M.A. (mentor); Van der Helm, A.J.C. (mentor)","2012","Design for Interaction graduation thesis describing the design and fabrication process of a new interactive exhibit, educating visitors of science centers on the subject of space and the solar system.","exhibit; space; education","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Design for Interaction","",""
"uuid:94f2cf81-3cba-476a-9e5d-a7a38d21ca65","http://resolver.tudelft.nl/uuid:94f2cf81-3cba-476a-9e5d-a7a38d21ca65","Influences on Project Portfolio Management Adoption","Haasnoot, H.","Van Beers, C.P. (mentor); Mooi, H.G. (mentor); Filippov, S. (mentor); De Reuver, G.A. (mentor); Boer, R. (mentor)","2012","Project Portfolio Management (PPM) has the potential to bring considerable benefits to organisations. Although PPM should improve project success, not all project management based working organisations have fully adopted PPM as part of their way of working. The question that arises here is ‘why?’. The concept of PPM Adoption has not received much academic attention so far. A positive link between PPM Adoption and portfolio success has been found by a few authors, but the circumstances under which PPM should be adopted is yet considered a research gap. This research aims to address this research gap by determining how PPM Adoption is influenced. This study aims to answer the research question ? How is the adoption by organisational bodies of Project Portfolio Management influenced? ? This question is split into three sub?questions focussing respectively on a deeper study into the process of PPM Adoption, the identification and validation of factors that influence PPM Adoption, and how and under which circumstances each of these factors influences PPM Adoption. This research project is divided into (1) an explorative phase, comprising literature study and 8 expert interviews, enabling the construction of a conceptual model, and (2) a validation phase following a multiple?case holistic design case study approach with 15 relatively small case studies with a 1,5 hour interview per case at their core, in various organisations in The Netherlands. The studied organisations can roughly be divided into one third (semi?) governmental, one third financial services and one third industry, technology and/or professional services. PPM is an ambiguous term. The definition used in this report stresses the aim of PPM for selecting and prioritising projects in the portfolio. Through literature study and explorative expert interviews it has been determined that PPM Adoption is not a choice between taking up and not taking up PPM. It rather is the movement along a spectrum between the extremes of intuitive and highly formalised project selection and prioritisation. Through study of literature on adoption of innovations and on PPM and its benefits, complemented by the explorative expert interviews, nine factors have been identified that influence PPM Adoption. These factors are categorised as conditions for and drivers of PPM Adoption. The conditions are Portfolio complexity; Organisational culture; PPM Gap size (inverse); and Relative resource scarcity. The drivers are Alternative organisational priorities (inverse); Desire for better information transparency; Need for better predictability of company results; Desire for project success rate improvement; and Desire for portfolio rationalisation. Based on mainly cross?case synthesis, considering multiple aspects of the collected data about these nine factors (conditions and drivers), conclusions have been derived about the influence of these nine factors on PPM Adoption. Besides the frequencies of these factors, also the phase of the interview in which the factor was mentioned and the additional comments by the interviewees have been included in the determination of an overall interviewee? and factor?specific judgement of the overall influence of this factor on each case’s PPM Adoption. Quantification of these judgements provides overall per?factor indications of their average influence on PPM Adoption and its standard deviation. Bringing all these components together, the following conclusions have been drawn about the individual factors. Of the four conditional factors, only ‘relative resource scarcity’ has been found to form an important condition for PPM Adoption. Of the driving factors, ‘desire for information transparency’ is an important driver for PPM Adoption, regardless of circumstances. Also ‘desire for portfolio rationalisation’ is frequently a driver, but often tacitly. This means that organisations are not aware of this desire, until they discover that this desire is fulfilled by PPM Adoption, which is then obviously driven by other factors. The influence of ‘need for better predictability of company results’ can be influential, but this is strongly dependent on circumstances, like how the organisational body hierarchically reports to another entity. The ‘desire for project success rate improvement’ can be a reason for adopting PPM, but conversely PPM is not always adopted to answer this desire. This study contributes to the extant body of literature by contributing to the bridging of the research gap in influences on PPM Adoption. Among its principal contributions are a conceptual model for researching the influences on PPM Adoption, a consideration of influencing factors that potentially provide wider application in the research on adoption of other organisational innovations, and ? more generally ? the contribution of empirical evidence to the extant body of literature on PPM through 15 case studies in organisational bodies that practice PPM. The managerial implications of this research comprise the perspective on PPM Adoption as movement along a continuum, rather than a one?shot action, and the understanding that PPM is often adopted reactively, in response to an emerging issue like a growing scarcity of resources, while proactive adoption of PPM allows enjoyment of many more benefits than solely the reduction of organisational pain.","Project Portfolio Management; PPM; PPM Adoption; Organisational Innovation; Innovation Adoption","en","master thesis","","","","","","","","","Technology, Policy and Management","Technology, Strategy and Entrepreneurship","","Management of Technology","",""
"uuid:03a72bda-ce65-4bb3-af56-ad33c810e029","http://resolver.tudelft.nl/uuid:03a72bda-ce65-4bb3-af56-ad33c810e029","Improving the User's Product Selection Experience by Designing a New Tool","Cho, E.J.","Keyson, D.V. (mentor); Van der Helm, A.J.C. (mentor)","2012","People from diverse professions and industries use professional lighting products. However, the descriptions of the professional lighting products are focusing on the technical information of each product which needs a certain level of the lighting design knowledge and experience to understand. Therefore, there are some people who cannot fully understand this type of description, and their product selection experience cannot be satisfactory. This graduation project was improving those people’s lighting product selection experience by designing a tool for those people, and in order to improve their lighting product selection experience, a new tool was developed. The studies and researches have been conducted during the project, in which the users’ needs and desires were unveiled and the problems of the current situation were found. To show the opportunity to improve and solve the current situation and problems, the concept of Lighting Effect Product Selector was developed. Through the concept evaluation, it was confirmed that the application is helpful in guiding the target users’ lighting product selection processes, and the application has the possibility to increase the target users’ lighting product selection experience. Therefore, the Lighting Effect Product Selector can be used as a starting point of developing more products and researches to increase the users’ better product selection experience.","interaction; user experience; user interface; product selection tool","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","ID  DCC; Design Context and Conceptualization","","","",""
"uuid:56b691b8-f6dd-470b-8d30-1e4202804e1c","http://resolver.tudelft.nl/uuid:56b691b8-f6dd-470b-8d30-1e4202804e1c","Ground-Penetrating Radar","Velds, C.B.","Slob, E.C. (mentor); Patriarca, C. (mentor)","2012","Measuring and analyzing ground penetrating radar data on different sand-clay soils as a function of water content","Ground-Penetrating Radar","en","bachelor thesis","","","","","","","","2012-08-24","Civil Engineering and Geosciences","Geoscience & Engineering","","Applied Geophysics and Petrophysics","",""
"uuid:12a93193-6bd4-436b-8578-a6593c161784","http://resolver.tudelft.nl/uuid:12a93193-6bd4-436b-8578-a6593c161784","Designing a Sustainability Support System for Product Designers: An explorative study to identify Design Criteria","Segers, M.P.A.D.","Van der Sanden, M.C.A. (mentor); Wever, R. (mentor); De Vries, M.J. (mentor)","2012","The Master’s programme Industrial Ecology is jointly organised by Leiden University and Delft University of Technology. In this research design criteria were formulated that can be used to develop support systems for product designers in the field of sustainable design. An extra focus lay on the product designer as a human being, which soft factors of product designers (sociological, psychological and emotional factors) are important to consider while designing a Sustainability Support System.","Sustainable Design; Sustainability Support Systems; Website; Industrial Ecology; Science Communication","en","master thesis","","","","","","","","2012-08-29","Applied Sciences","Industrial Ecology & Science Communication","","Industrial Ecology & Science Communication","",""
"uuid:2c23b4c3-8e68-43eb-b783-a180482e68b8","http://resolver.tudelft.nl/uuid:2c23b4c3-8e68-43eb-b783-a180482e68b8","Innovative design for lock gates - curved sliding gate; case study: IJmuiden Nieuwe Zeesluis","Zel taat, S.","Vrijling, J.K. (mentor); Van der Toorn, A. (mentor); Abspoel, R. (mentor); Langedijk, W.P.J. (mentor); Van der Tol, T.P.M. (mentor)","2012","Design of a lock gate for Nieuwe Zeesluis in IJmuiden becomes a challenge when the boundary conditions limit the choice for the conventional types of the gate. The available width of the lock does not allow a straight rolling gate to be considered as a possible alternative as it is in most similar cases. All the initial efforts of this study have been made in search of a new alternative to solve the space limit problem. After assessment of a number of feasible type of gates, finally, when the curved gate concept was introduced based on the concept of rolling gates and sliding gates, all the functional requirements of the design had to be met. This study investigates in three different structural alternatives for the curved gate in the concept development stage as well as three different operating systems and two different supporting systems. Based on certain design objectives, a final concept is chosen and is developed into a preliminary design. The design objective have been defined based a simple criteria of achieving the most benefit with the lowest investment possible. In this manner it is tried to increase the functionality of the design for gate structure. These objectives are basically: - Minimum use of movable devices - Minimum necessity of maintenance - Innovation - Simplicity The main challenge in the conceptual design is to find the optimum combination within the alternatives for the main compartments of the gate while every advantageous solution for a compartment, introduces a new problem in another. For making a better decision a framework is defined for the evaluation of the solutions and alternatives with the help of a score system which enables us to see which alternative is in line with the design objectives the most. Furthermore, the study presents a rather detailed design of certain compartments such as operational equipment, guidance devices, tracks, hydraulic bearings and sealing system. Structural and stability checks are done for the extreme load conditions, loads during the special combined movement and construction of the gate. This results in a preliminary design which is integrated and consistent in satisfying all the functional requirements of the design. The final and most important evaluation of the research study discusses the costs, safety, reliability and availability of the gate structure by means of a qualitative RAMS analysis accompanied by a cost comparison table. These two outcomes provide insight on applicability of the gate into the different situations but especially in this case study. This report will discuss the approach and steps in which the idea was developed and it answers the feasibility and applicability questions by the help of final results and evaluations. Report ends with presenting the conclusions of the work and giving a number of recommendations.","IJmuiden; lock gate; curved sliding gate; hydro-foot; feasibility study","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Hydraulic Engineering","","Hydraulic Structures","",""
"uuid:522e44b9-ecc4-4a3f-b835-02d88ed56231","http://resolver.tudelft.nl/uuid:522e44b9-ecc4-4a3f-b835-02d88ed56231","Reservoir characterization of the Upper Slochteren Sandstone by integration of core data","Knol, M.I.C.","Weltje, G.J. (mentor); Donselaar, M.E. (mentor)","2012","In this Bsc-thesis the thin-sections of the Uithuizermeeden-1A well are studied on mineral content and diagenetic changes with a Leica polarisation microscope and digital camera. Photo’s that have been taken are bundled together in a photo book which can be of use as study material. During Middle and Late Permian times the Netherlands became part of a large, complex, east-west trending sedimentary basin, with a large playa lake in the centre. The Variscan mountains in the south provided the siliciclastic sediments and early Permian volcanic deposits were the source of heavy minerals, volcanic rock fragments and mica’s. The Uithuizermeeden-1A well was located at the margin of the playa lake, which was characterized by a wetter and more cemented setting. Because of its deep-burial regimes the UHM-1A sediments have undergone several diagenetic processes, but stabilising, pore blocking cements didn’t allow mechanical compaction. At later time dissolution of these stabilising cements and unstable feldspars and rock fragments provided excellent reservoir conditions. With a Gas-Water-Contact on a depth of 2988 meter, minerals within the gas zone have been excluded of contact with formation waters for 200 million years, which inhibits further chemical diagenetic changes. Illitisation, the process of formation of pore-bridging, pore-filling or meshwork hairy illite, could only be seen within the Water Zone. Petrographic data also showed a reduction of K-feldspars from an average of 4%in the Gas Zone to an average 2% in the Water Zone. So gas charge arrests illitisation and diagenetic changes to unstable minerals.","reservoir characterization; microscopic research; Upper Slochteren Sandstone","en","bachelor thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Section of Applied Geology","",""
"uuid:1ed3d199-f73f-4569-9f5a-ae5236a38ee8","http://resolver.tudelft.nl/uuid:1ed3d199-f73f-4569-9f5a-ae5236a38ee8","Design of a new transformation device for a tip seat for multifunctional public transportation","Van Vliet, E.","Happee, R. (mentor); Van der Helm, F.C.T. (mentor); Plettenburg, D.H. (mentor)","2012","Tribus b.v. is a company in Utrecht that converts minibuses for multifunctional public transportation. This means that with the same bus both ambulant people and wheelchair occupants can be transported. The multifunctionality lies in the combination of a flexible floor layout and (tip) seats. The floor system is based on separate aluminium profiles that are assembled to form any desired floor layout. Tribus' tip seat FlexusPRO meets the highest quality and safety requirements. Because of its integrated three point safety belt, the seat can be positioned anywhere in the vehicle. A common seat layout is the 4x4 tip seats, where four FlexusPRO seats are positioned on the right side of the vehicle and four on the left. By folding the seat pan to the backrest and subsequently rotating the seat package to the side, a wheelchair environment is created without removing or repositioning the seat. This transformation from passenger seat (mode 1) to wheelchair space (mode 2) is an easy and fast operation that enables the transporter to do a combined transportation of ambulant people and wheelchair occupants with the same vehicle. Besides the benefits of Tribus' FlexusPRO, the tip seat also has some main drawbacks with respect to the production costs, weight, the available wheelchair space after seat transformation and the hindered view outside for the wheelchair occupant as a result of the seat dimensions in mode 2. The goal is to overcome these drawbacks, in order for Tribus to be able to launch a new tip seat that exceeds seats of competitors on price, weight, operation and functionality. The goal of this graduation project focuses on the improvements of the seat position in mode 2. This means an improvement of the transformation device, where the overall goal is to reduce the production costs and weight by at least 30% and increase the view outside for the wheelchair occupant by at least 20% in combination with an increased lateral wheelchair space of at least 10%. However, in order to obtain a good design, a complete concept of the new tip seat needs to be proposed, where every aspect of the seat is able to fulfil the design requirements. A morphological approach resulted in three tip seat concepts that are rated with respect to usage and manufacturing aspects. The final concept led to a tip seat with a rotation device and a tilting backrest, that increases the lateral wheelchair space in mode 2. The improvement of the lateral wheelchair space is however dependent on the entire seat design, where the base frame of the seat will be leading. Because the base frame of the seat is not part of this project, a specific percentage of the improvement is not yet known, but an improvement of at least 10% can be realized. The separate headrest of the seat is moved down during the transformation to mode 2, which improves the view outside for the wheelchair passenger. The entire seat design is also not part of this project, but research on commercial vehicles showed that a vertical adjustment of the headrest of 210 mm is possible, which would improve the view outside by approximately 33%. The new seat concept is used as a guideline for the design of the two mechanisms that are needed for the transformation from mode 1 to mode 2. The tilting motion of the backrest resulted in a mechanism that provides a simultaneous movement of both backrest and seat pan. The benefit is that the additional (tilting) functionality of the seat had no effect on the amount of operations needed for the transformation. The mechanism is based on the over-centre principle of a toggle clamp. The system uses four pivot points that connects the backrest to both seat pan and seat frame. This innovative solution resulted in the fact that no additional locking devices where necessary to prevent the angular movement of the backrest in mode 1. The loads on the three point belt in the backrest, as a result of a frontal impact, are transferred into the mechanism which is only locked by the geometry of the backrest and seat pan. This mechanism prevents additional costs and weight as a result of the additional tilting functionality. Finally a new rotation device is designed. The use of a morphological approach resulted in four concepts. The best concept is elaborated, resulting in a new steel swivel of 3 kg, which is a weight reduction of 38%. Because of the minimal amount of components, no welding operations and an easy and fast assembly, the cost price of the swivel is reduced by 47%. Both tilting mechanism and swivel have been prototyped and they underlined the benefits that are mentioned in this report. The swivel has even been tested by a physical pull test and passed this test successfully. The goal of reducing the production costs and weight by at least 30% has been exceeded on both aspects. The view outside for the wheelchair occupant could be improved by 33%, which also exceeds the required 20%. The required improvement of the lateral wheelchair space by 10% can still be realized and will exceed this 10% especially around the arms of the wheelchair occupant. The project has been a success and Tribus decided to continue the development of both mechanisms for series production.","","en","master thesis","","","","","","","","2017-08-24","Mechanical, Maritime and Materials Engineering","BioMechanical Engineering","","BME","",""
"uuid:1e8de397-ae1d-4bb5-8051-9319c8ef1982","http://resolver.tudelft.nl/uuid:1e8de397-ae1d-4bb5-8051-9319c8ef1982","dbQuery","Plak, R.S.","Gross, H.G. (mentor)","2012","Javascript framework voor databasecommunicatie, dat dynamisch klassen en objecten aanmaakt en bruikbaar maakt voor een javascript programmeur, aan de hand van interne databasestructuur.","javascript; mysql; database","nl","bachelor thesis","","","","","","","","2012-10-13","Electrical Engineering, Mathematics and Computer Science","Technische Informatica","","Technische Informatica","",""
"uuid:8fa09d2a-4436-445e-98db-02fb275a9815","http://resolver.tudelft.nl/uuid:8fa09d2a-4436-445e-98db-02fb275a9815","Repaper: Meaning and transferring quality of paper","Chao, P.Y.","Van Boeijen, A.G.C. (mentor); Wiegers, T. (mentor)","2012","The aim of this project is to explore the territory of paper based materials and interactions of sending postcards. The insights can help us to understand what are the reasons that trigger people to continue using postcards when they have instant messaging tools at hand and how paper materials support it. Furthermore, the results can reflect to the digital social media. This project includes three directions: I. Paper materials. II. Transfer quality from a source product to other target products. III. Reflections on the impact from digital social media. The initial idea of this project was that we were wondering why still many people like to use paper based communication when digital social media is more convenient. Papers and paper-based communication must have something unique and beautiful. Therefore, we started researching paper materials and found out some important factors that may influence how people perceive different types of paper. Then, we used those factors as a tool kit to define each paper property. We gave each paper a character and believed those can provide a reference for people and designers when they need to choose a paper material. Afterward, we focused on transferring characteristics and select postcards as a source product. Postcard is a unique communication tool today. It conveys many personal, emotional connections. Additionally, the slowness and simplicity make it stand out from other traditional communications and even digital social media cannot compete with it. In addition, the target product is calendar and the target group is Taiwanese young modern family. The reason for choosing it was that Taiwanese calendar market is decreasing rapidly because of technology, such as smart phone. Young generation rarely uses it. However, postcards are still popular among young people. Therefore, in this project we use Emotion Design Driven method to extract characteristics (personal connection, time, efforts, curiosity and expectation) from postcards. Hoping that by applying those to calendars will be able to bring calendars back to young generation’s market. As the result, the final concept is Bedtime Story Calendar for Taiwanese young family. It includes a small story with an origami for each day. Parents use the origami to perform the storytelling. The results showed that origami simulates parent-child relationship. The interaction is geared by children’s curiosity and expectation. However, due to lack of research in children storybooks domain, contents of the concept can be developed further. At the end of this project, we discussed the challenges of digital social media based on the researches of paper materials and postcards. We found that paper carries the characteristics of personal feeling, relaxing and creativity, however, digital social media is too tool-like in this sense. Moreover, because digital social media requires less efforts and time, people feel it is less personal than paper based communications. Those are the challenges for digital social media we found out from this project.","paper; postcard; calendar; ritual; DfI; transfer quality","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Design for Interaction","",""
"uuid:63a0a314-08c6-4bfb-b668-d6404bb2ed83","http://resolver.tudelft.nl/uuid:63a0a314-08c6-4bfb-b668-d6404bb2ed83","Getting the right information: Understanding client's needs in the context of software development","Ustohal, J.","Bouwman, W.A.G.A. (mentor); Ortt, J.R. (mentor)","2012","","business model; business model analysis; client's needs; Agile development; software development","en","master thesis","","","","","","","","2012-08-25","Technology, Policy and Management","Infrastructure Systems & Services","","Management of Technology","",""
"uuid:dda45cb7-e64d-4e23-b616-90457d01997a","http://resolver.tudelft.nl/uuid:dda45cb7-e64d-4e23-b616-90457d01997a","Geomechanical properties of a backfill material suitable for stabilising salt caverns in Twente","Drost, G.I.A.","Buxton, M.W.N. (mentor); Van Paassen, L.A. (mentor); Pinkse, T.M. (mentor)","2012","Potentially unstable salt caverns of AkzoNobel need to be stabilised with a suitable backfill material in order to prevent surface subsidence. These caverns are currently filled with Carbonate and Gypsum slurry, a residual product of the brine purification process, but a new backfill material is being developed for stabilisation purposes. At the bottom of the cavern, a layer with sump material could have an influence on the backfilling process. The aim of this study is to compare the geomechanical properties of the backfill material, the Carbonate and Gypsum slurry and the sump material by comparing the geomechanical properties and thereby contributing to AkzoNobel’s project Pilot Stabilisation Caverns Twente. It is hypothesised that the geomechanical properties of the new developed backfill material are better suited for stabilisation compared to the Carbonate and Gypsum slurry. However, it is expected that the Carbonate and Gypsum slurry is still suited for stabilising a potential unstable cavern. For the sump material, it is expected that the permeability of the material decreases during consolidation, which is advantageous for its barrier function. In order to evaluate the hypothesis, a numerical model was developed using bearing capacity calculations, to show to what extent the cavern potentially migrates when backfilling is carried out and what the applied load of the debris column would be. Secondly, the geomechanical properties of the Carbonate and Gypsum slurry and sump material were investigated by laboratory experiments, including the particle size distribution, mineral content and compressibility of the material. The third step was to compare the geomechanical properties in terms of total settlement and stiffness development of the Carbonate and Gypsum slurry and sump material with the new developed backfill material. A case study of Cavern 165 evaluates whether the Carbonate and Gypsum slurry is suited for stabilising an unstable cavern, based on the calculated and measured geomechanical properties. For the Carbonate and Gypsum slurry and sump material, the primary and secondary consolidation phases were indistinguishable. Even after two weeks of consolidation for a single load step, continuous settlement seemed to occur for the Carbonate and Gypsum slurry. This could be an indication that compaction creep occurs. This behaviour was also obtained for the backfill material. Compaction creep is a process that continues until the void ratio becomes zero. In terms of total settlement and stiffness development, the backfill material and Carbonate and Gypsum slurry showed comparable behaviour on the short term (i.e. after 10 days). However, when assuming compaction creep up to 1000 years, the backfill material is better suited in terms of total settlement and stiffness development on the long term. When it is assumed that compaction creep for the Carbonate and Gypsum slurry takes place for approximately 1000 years, the slurry is able to stabilise a potential unstable cavern when the cavern is filled for at least 81%. Since the void ratio of the Carbonate and Gypsum slurry was already low after 10 days of loading, the expected compaction creep would probably stop at an earlier stage. The total consolidation of the slurry should be taken into account when determining the fill volumes of the caverns. During backfilling, the Carbonate and Gypsum slurry or new developed backfill material penetrates through the voids of the sump rock at the bottom of the cavern. This results in consolidation of the fine sump fraction and a loss of backfill volume. Since the void ratio of the sump material decreased during consolidation, it is assumed that the permeability also decreased, but the order of magnitude is unknown. Hence, more research is required to investigate the decrease in permeability due to loading, in order to conclude whether the decrease is sufficient to be advantageous for the barrier function of the sump material. Furthermore, it is recommended to evaluate the time dependency of the consolidation of the backfill material, the Carbonate and Gypsum slurry and the sump material. Since consolidation of the materials continues in the worst case until the void ratio e becomes zero, it is likely that the assumed compaction creep already stops at an earlier stage, making 1000 years of compaction creep a very conservative assumption.","salt; caverns; backfill; stabilisation; mining","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Resource Engineering","",""
"uuid:b8fe573a-f4a2-489a-8b9e-b8617877f0d5","http://resolver.tudelft.nl/uuid:b8fe573a-f4a2-489a-8b9e-b8617877f0d5","Voorkeursroutes in Routenavigatie","Boutahar, H.","Van der Meer, K. (mentor)","2012","Een requirements analyse ten behoeve van een beoogd beslissingsondersteunend informatiesysteem voor routekeuze bij bestuurders van motorvoertuigen.","routenavigatie","nl","master thesis","","","","","","","","2012-08-17","Electrical Engineering, Mathematics and Computer Science","Informatie Systemen/Software Technology","","Computer Science","",""
"uuid:a07d4e8f-6250-4ace-b366-1c6cbc2285d2","http://resolver.tudelft.nl/uuid:a07d4e8f-6250-4ace-b366-1c6cbc2285d2","Seismic signatures of 2D fracture networks","Stallone, A.","Barnhoorn, A. (mentor); Thorbecke, J. (mentor)","2012","Fractures and faults play an important role in controlling the flow and transport properties in a reservoir and that is the main reason for which their characterization is very important in hydrocarbon exploration. In addition to this, the possibility of characterizing fractures can represent a great advantage in other fields, like geothermal exploration, hydrofracturing applications or volcanic risk evaluation. Seismic simulation by finite-difference modeling has been implemented as a tool to characterize fracture networks by testing their seismic signatures. The medium in which fractures are placed is represented by a squared model with the sides measuring 5000m; two receivers arrays, each including 1000 receivers, have been implemented: the first at the top of the model (to record the reflected wavefield), the second at a depth of 4000m (to record the transmitted wavefield). Fractures are randomly positioned in the center of the model, between 1250m and 3750m. In the case of a layered medium, only the middle layer, 1500m thick, contains random fractures. The sensitivity of seismic wave propagation to fractures has been analyzed by testing the influence of different fracture features: length, orientation, density (number of fractures). Even a single fracture affects the incident seismic signal, producing diffracted/scattered and transmitted waves. Moreover, its orientation significantly affects the reflected wavefield in the time domain in terms of amplitude and complexity of the response and in the frequency domain as well, where peak amplitude and peak frequency change depending on the fractures orientation. More than the orientation, the fracture length strongly affects the seismic signal in time and frequency domains. Considering a network of fractures, the imprint of the fracture orientation on the reflected wavefield is significant only in the frequency-wavenumber domain; on the other hand, it is much stronger for the transmitted wavefield in the frequency domain, where the peak amplitude and the peak frequency undergo high variation: in particular, the horizontal fractures produce the strongest frequencies attenuation and the lowest peak frequency. The fracture length variation produces the most interesting signature in the time domain for the reflected wavefield (an increase in the fracture length produces longer coda waves) and in the frequency domain for the transmitted field: in particular, the longest fractures produce the strongest frequencies attenuation and the lowest peak frequency. Significant is the signature of the fracture density, but it is particularly strong on the transmitted wavefield in the frequency domain: in particular, the highest number of fractures produce the same effect of the horizontal and longest fractures (strongest frequencies attenuation and lowest peak frequency). Eventually, the introduction of a fractured layer yields strong change in the incident signal, which is highly attenuated and disrupted. The results of the present work can have implications in all the fields where the detection and the characterization of fractures in the subsurface is vital, such as the geothermal exploration or the hydraulic fracturing applications. Despite of the complexity of a fractured systems, some recurrent trends and characteristic responses have been determined. However, it should kept in mind that fracture features are strictly related (they influence each other) and that different features can yield similar responses: this means that fracture characteristics can not be straightforward inferred from their seismic signatures.","modeling; seismic wave propagation; fracture signatures","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Applied Geophysics and Petrophysics","",""
"uuid:6762136d-5f8c-46a8-9ee5-18347c43fc0e","http://resolver.tudelft.nl/uuid:6762136d-5f8c-46a8-9ee5-18347c43fc0e","Preliminary multi-mission UAS design","Veerman, H.C.M.","Stoop, J. (mentor); Poppinga, G. (mentor); Hoogendoorn, S. (mentor)","2012","Unmanned vehicles are important when it comes to performing a desired task in a dangerous or inaccessible environment. Unmanned robots, have been successfully used for many years. More recently, a growing interest in Unmanned Aircraft Systems (UASs) has arisen. In the past few years the development of sensors, microprocessors and propulsion systems resulted in UASs that are smaller, lighter and more capable than ever before. This leads to endurance, efficiency and autonomy levels that exceed the capabilities of manned flight. A large number of successful designs have been created by several universities, commercial companies and research agencies. Due to the wide variety of applications, several configurational concepts have been developed. As a result, most UAS designs are optimized for a dedicated task. In order to perform different tasks, users need to have access to multiple UASs. This means that manufacturers and users have to maintain production and support lines for multiple UASs. The goal of this thesis was to create a preliminary design of a multi-mission UAS by using off-the-shelf systems. This UAS must be able to perform both low and high speed missions. To reach the stated goal a clear overview of all requirements had to be created first. This was followed by extensive market research in order to get an overview of the performance of current UAS designs. This market research was captured in a database. Based on the requirements in combination with the obtained database, all UAS classes and configurational options have been evaluated. The evaluation revealed that a new fixed wing electrical powered mini UAS design may be able to comply with the all UAS requirements. Based on the UAS database, weight estimation relationships for preliminary mini UAS design were derived. These relationships were used for the preliminary UAS performance and weight estimation. After investigating the technical and operational feasibility, the compliance with respect to the requirements was checked. This resulted in a new UAS design point. Subsequently, the UAS design was analyzed in more detail. Optimization of the wing was performed by using a quasi-3D optimizer. This was followed by a tail design that was based on UAS reference data and volume coefficients. The resulting wing and tail design were evaluated by investigating the wing-tail effects and the primary static \& dynamic stability derivatives. This was followed by an evaluation of the material options for the structure. During this evaluation a new manufacturing technique, 3D printing, was tested. Subsequently, the propulsion system design was performed by using a UAV Propulsion Development Kit (UPDK). This UPDK is able to estimate the performance of multiple engine-propeller combinations. Based on the evaluation of the top five combinations, a combination was selected. Finally, the additional UAS subsystems were selected. After the preliminary UAS design was completed, the effectiveness of the design was evaluated. Together with off-the-shelf systems it was possible to create a design that is able to comply with most requirements. The WER for the payload weight was found to be inaccurate. This was caused by the fact that current UASs are equipped with heavier or additional payloads. The WER for the empty weight slightly underestimated the structural weight of the UAS. Overall can be concluded that it is possible to create a preliminary mini UAS design capable of performing both low and high speed missions using off-the-shelf systems.","UAS; UAV; preliminary UAS design; preliminary UAV design","en","master thesis","","","","","","","","2012-09-08","Aerospace Engineering","Design, Integration & Operations of Aircraft and Rotorcraft","","","",""
"uuid:a0e03936-3fdf-4c94-a744-b02787b5a5f5","http://resolver.tudelft.nl/uuid:a0e03936-3fdf-4c94-a744-b02787b5a5f5","Rowing by numbers: A new foot strecher design to improve the usability and ergonomics of a competitive rowing boat","Hertog, M.","Jansen, A.J. (mentor); Van der Geer, S. (mentor)","2012","In the last decades major developments took place in the rowing world. In particular, the boat performance has been improved by reduced weight and increased stiffness. Both improvements have led to more efficient use of the rower’s power. However the way to optimize the rowers posture has hardly been hardly improved. During the analysis phase survey and observations were executed and they showed that lots of time and effort is needed to optimize the position of the foot stretcher for a particular rower. A foot stretcher is the component is the boat that connnects the rower with the boat (Figure 1). The time and effort demand of the foot stretcher can lead to a non-optimized foot stretcher, which eventually leads to less performance and a higher chance of injuries. After the analysis phase, the following design brief was stated: “The new foot stretcher must enhance the rower’s performance by enabling him to set-up the boat faster and simpler while maintaining the mechanical performance. The aesthetics should also match the boat’s looks and the rower’s expectation” The project is conducted in collaboration with the rowing boat manufacturer Hudson. Their foot stretcher is used as a case study. The Hudson foot stretcher has been designed 20 years ago as a good adjustable foot stretcher and has been iteratively developed into a relatively heavy weight foot stretcher compared to the other products in the market. More weight of the boat leads to less performance. The solution is a foot stretcher for which no tools are required to change and measure the feet’s position. Quick fasteners ensure efficient changes to the foot stretcher and numbers on the foot stretcher indicate the feet’s position. In the end this enables the rower to change settings faster and easier, which improves the set-up. A more optimal set-up leads to better performance.","rowing; foot stretcher; ergonomics; biomechanics; Hudson","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","","",""
"uuid:01feffe2-f1ca-43dc-8f86-47bd3c45a930","http://resolver.tudelft.nl/uuid:01feffe2-f1ca-43dc-8f86-47bd3c45a930","Test Circuit Design of DC/DC Converter for Helicopter Starter/Generator","Ren, Y.","De Haan, S.W.H. (mentor)","2012","A test circuit is designed for testing the DC/DC converter of Helicopter's Starter/ Generator, including topology selection, operation principle analysis, components selections, simulations and 3D model building.","DC/DC converter","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Electrical Power Engineering","","Electrical Power Processing","",""
"uuid:aec92d39-5262-4f91-9bce-65c6cf4c3c8f","http://resolver.tudelft.nl/uuid:aec92d39-5262-4f91-9bce-65c6cf4c3c8f","Arsenic Contamination: Deep wells as a solution for clean drinking water in Bihar, India","Deen, M.M.","Bruining, J. (mentor); Donselaar, M.E. (mentor); Wolff, K.H.A.A. (mentor); Slob, E.C. (mentor)","2012","The objective of thesis is to see at which rate and depth Arsenic (As) contaminated water flows into deep wells in the subsurface of a small region in Bihar, India. The method of investigation is interpretation of geological data and implementing this in a flow model built in Comsol Multiphysics 4.2a. Interpretation of the data is done by grain size analysis on two samples, using microscopy and sieve tests. The results show extensive differences in characteristic properties: The top layer (0-28m) has a permeability of 30.7 mD and a porosity of 20 %; the bottom layer(28-50m) has a permeability of 9.34*10^5 mD and a porosity of 36%. The flow model is based on the assumption of Darcy flow and transport of diluted species. The measured value of Arsenic concentration in the well in the model is 232 µg/L. The model assumes As release to happen only in the top layer by microbiological activity at low rates of dissolved oxygen. Contamination in the well is caused only by flow from the top layer, for there is assumed no in situ release of Arsenic in the bottom layer. The research question is: is it possible to subtract water from the second layer found in Bihar to produce clean drinking water? The findings are that if the well is at a depth of 42 m, the Arsenic concentration comes to an equilibrium for longer times and stays below the value of 10 µg/L measured at the well.","arsenic; Bihar; well; deep","en","bachelor thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","","",""
"uuid:c4a9b87f-906b-4dce-8069-d86aa6d96462","http://resolver.tudelft.nl/uuid:c4a9b87f-906b-4dce-8069-d86aa6d96462","Modeling and inversion of Scholte waves in shallow water for varying acquisition parameters","Diaferia, G.","Drijkoningen, G. (mentor); Kruiver, P. (mentor)","2012","On land, surface waves are extensively and successfully used for the determination of Shear velocity profile (MASW). From those, the stiffness of the subsurface within 20-30 m can be derived, useful especially for engineering purposes. This technique can be effectively applied also to shallow marine environments: surface waves ex- cited by air-gun and travelling along the sea-floor (Scholte waves) can recorded by a receivers cable towed behind a ship. Acquisition parameters and the local setting of the marine environment (mainly water depth) have a strong control on the gen- eration and detection of Scholte waves. In this work a finite-difference scheme has been used to model Scholte waves propagation for a simple 1D model, using several acquisition configurations. Based on inversion results and resolution of dispersion plots, the optimal acquisition parameters are derived. Moreover, the best strategy for acquisition in case of a laterally varying topography of the sea floor is defined. Since the strong 1D assumption for the inferring of Vs profile, more complex and laterally inhomogeneous models have then been implemented to test the effect of lateral variation on inversion results.","modeling; Scholte wave; inversion; shallow water environment","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Section of Applied Geophysics and Petrophysics","",""
"uuid:81e4f4f0-847c-4805-b9f4-24e045162485","http://resolver.tudelft.nl/uuid:81e4f4f0-847c-4805-b9f4-24e045162485","Can Wage Restraint Pull the Mediterranean Countries Out of the Sovereign-Debt Crisis? An Empirical Analysis of OECD Export Performance","Li, Y.","Kleinknecht, A. (mentor); Storm, S. (mentor); Molin, E. (mentor)","2012","On March 25th 2011, the European Council passed the Euro-plus Pact in order to enhance the competitiveness of European countries especially for the four Mediterranean countries which were trapped in a sovereign-debt crisis. One of the main focuses of the Pact was to restrain the growth rate of wages to make it below the growth rate of productivity. The introduction of this so-called ‘competitiveness pact’ aroused widely debate on the effectiveness of the wage restraint and some fairness issues within Euro system. This paper aims to figure out whether wage restraint can help the debt-trapped countries out of trouble. We first divided the European countries into two groups: North and South and then implemented the research by three main parts: facts overview, theoretical analysis and empirical analysis. In the facts part, plenty of macroeconomics indicators have been presented and compared between countries and over times to provide a clear view on the current crisis in Europe and differentiations in economic performance across countries. Great differences have been found in economic indicators like trade balance, export performance, government debt ratio, etc. in which the North shows better results than the South. There are also distinctions between countries in export patterns and commodity structures. The North focuses more on relative higher technology industries while the South more on the lower ones. For the theoretical part, the model of Fagerberg (1988) has been used combining with a Ricardian Model to describe the relation between export shares and possible impact factors such as labor costs, technology progress, technical change and other country specific factors. In the empirical part, quantitative relations are found within a panel dataset across 15 OECD countries and 24 industries (classified under ISIC Rev.3) over 12 years from 1995 to 2006. Compared to the Mediterranean countries, Germany has stronger cost competitiveness coming from its strongly increasing labor productivity rather than wage moderation. However, the labor productivity can also partially attribute to the technology competitiveness which in our analysis shows weak direct influence on export performance. Country specific factors play an important role in explaining the variations in export market shares but it is hard to find good indicators for them. Even though nominal wages in the South were rising significantly stronger than the North (represented by Germany), wages are not the core reason which deteriorates the cost competitiveness in the Mediterranean countries but the slow productivity growth. Structural competitiveness cannot be ignored due to its potential impact on policy making but needs further research.","Sovereign-Debt Crisis; RULC; International Competitiveness","en","master thesis","","","","","","","","2012-08-23","Technology, Policy and Management","Innovation Systems Department","","Economics of Innovation","",""
"uuid:f77e5e5f-2b08-47f0-b825-0637897154d6","http://resolver.tudelft.nl/uuid:f77e5e5f-2b08-47f0-b825-0637897154d6","Finite difference feasibility modelling of time-lapse seismic noise interferometry for CO2 monitoring","Boullenger, B.","Draganov, D.S. (mentor); Thorbecke, J.W. (mentor); Verdel, A.R. (mentor); Bosch, F. (mentor)","2012","Seismic Interferometry (SI) with ambient noise is a recently developed method for subsurface imaging that involves cross-correlating ambient noise from passive seismic data to reveal the earth’s reflection response. Based on this technique, TNO aims at developing a methodology for efficient monitoring of CO2 geological sequestration in Carbon Capture and Storage projects. In 2009, as a collaboration with the CO2SINK research project on CO2 sequestration taking place in Ketzin, Germany, TNO installed a permanent seismic array that has now already been recording passive data for 2 years during the CO2-injection. The correlation of the large real datasets requires a prior assessment on the feasibility of SI with ambient noise for time-lapse monitoring of the C02 storage process. Using a 1D layered acoustic velocity model of the Ketzin storage site as well as the layout of the TNO’s permanent array, we perform passive experiments that involve finite-difference modelling of passive wavefields from random noise sources and the cross-correlation of these passive synthetic data to retrieve reflection responses. By repeating the experiment for base and monitor velocity scenarios from CO2 saturation changes in the reservoir, we study the influence of various noise parameters (the number of sources, the sources’ duration, the spatial distribution) on the retrieved base and monitor reflection responses as well as their induced amplitude differences. We show that, for a sufficient number of sources with sufficient durations, the accuracy of the retrieved reflection responses from the CO2 reservoir are close enough to the reference responses from an active surface shot. More generally, the retrieved reflections are improved when more sources lie at or close to stationary points. In addition, when the sources characteristics are identical for both the base and the monitor passive experiments, the amplitude differences between the retrieved base and monitor reflection responses exhibit clear information on reflection changes from the reservoir. However we show that, when the sources’ characteristics, such as their spatial random distribution only, are not close enough for the base and the monitor passive experiments, the induced amplitude differences are difficult to interpret. Processing of the recorded body-wave noise prior to cross-correlation might be then necessary. We conclude that the repeatability of the passive noise is crucial for time-lapse interpretation. Finally, we choose an ideal noise configuration to enhance repeatability of the passive experiments when using different random distributions of the sources. In this special case, plotting picked amplitudes from the retrieved reflection responses for different velocity scenarios illustrates the potential of monitoring the velocity changes from SI with ambient noise.","seismic; interferometry; monitoring; gas sequestration","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","IDEA League joint master in Applied Geophysics","",""
"uuid:73c0ddc1-351c-43ae-b536-59829a0f9d07","http://resolver.tudelft.nl/uuid:73c0ddc1-351c-43ae-b536-59829a0f9d07","The Reconstruction of Missing Marine Seismic Data","Van Leeuwen, L.P.","Hegge, R.F. (mentor); Wapenaar, C.P.A. (mentor); Bosch, F. (mentor)","2012","To evaluate the subsurface, seismic surveys are carried out. A requirement for the processing of these data is that it is dense and regularly sampled and it should also include the near-offsets. Because these data cannot be acquired in practice for towed marine surveys, it should be obtained by inter- and extrapolation. The first objective of this report was to give an overview of the methods which already exist for the inter- and extrapolation of seismic data. Only the most important methods are described, because the total number of methods is too large. They are first explained and finally classified into the three main categories: Wave-equation based methods, Domain transform methods and Prediction-Error-Filter methods. The other objective of this thesis was to explain and test the Mixed domain reconstruction method. It is based on the Polya-Plancherel theorem, which states that band-limited data in one domain has infinite support in the other domain. This theorem makes it possible to reconstruct the missing seismic data. A conjugate gradient method is used in the optimization part of the implementation. The method was tested for its interpolating qualities and it was shown that it works very well. For extrapolation, the data should be transformed into a ‘split-spread’ configuration instead of the ‘end-on’ configuration which is typical for towed marine surveys. With this transformation, the near-offset gap is filled accurately. It was also shown that the error increases for larger gaps and that the method is limited by the offset and not by the number of traces. The method works in the frequency domain, but a time domain implementation of the algorithm was generated which gave promising results. Finally, the method can handle a wide variety of datasets: low quality data, conflicting dip data, dual-sensor data and real data. The conclusion of this report is that the Mixed domain reconstruction method works very well and can be applied to many types of seismic data. It was demonstrated that a dense and regularly sampled dataset can be obtained which contains also the near-offset.","seismic data reconstruction; extrapolation; interpolation; Mixed domain reconstruction method","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Section Applied Geophysics and Petrophysics","",""
"uuid:39c08d45-71cc-44fb-881d-7a8fa0fdf807","http://resolver.tudelft.nl/uuid:39c08d45-71cc-44fb-881d-7a8fa0fdf807","Feed-forward torque control for plantar flexion support","Huberty, L.","Van der Helm, F.C.T. (mentor); Van Dijk, W. (mentor); Wisse, M. (mentor)","2012","Recent studies suggest that a reduction of the plantar-flexion muscle EMG can improve the efficiency of human locomotion. In this study, an attempt is made to reduce the maximal EMG of the gastrocnemius medialis and soleus by providing a feed-forward torque support around the ankle. The strategy only requires the ankle kinematics to define the appropriate support torque. The maximal amount of support applied was equal to 30% of the total ankle torque of a human during steady state walking. Five untrained subjects walked on a treadmill at 4km/h and completed 3 test sessions of about 45 minutes each. The final EMG measurements showed a maximal reduction of 30% for the soleus and a slight increase of the gastrocnemius medialis EMG pattern for the case where 50% of the maximal support was applied. The tests showed a significant change in the ankle angle patterns when walking with maximal support. The findings suggest that the human prioritizes invariant ankle torque pattern over an invariant kinematic pattern. The results suggest that feed-forward torque control is capable to reduce the soleus muscle EMG and could possibly increase the walking efficiency of human locomotion.","Exoskeleton; EMG","en","master thesis","","","","","","","","2014-08-23","Mechanical, Maritime and Materials Engineering","BioMechanical Engineering","","BMD","",""
"uuid:b58445a9-5449-4909-acb1-e04f8134bb92","http://resolver.tudelft.nl/uuid:b58445a9-5449-4909-acb1-e04f8134bb92","Hartslagsensor voor 7 T MRI Cardiac Triggering","Spijkers, R.A.; Swager, I.S.","","2012","Voor het maken van scans van het cardiovasculair gebied is het noodzakelijk de MRI-scanner te synchroniseren met de hartslagcyclus. Dit wordt cardiac triggering genoemd. Door de hoge magnetische veldsterkte treden synchronisatiefouten op, waardoor de scans erg onduidelijk en daardoor onbruikbaar worden. Het doel van dit onderzoek was het verbeteren van de hartslagsensor die bij cardiac triggering wordt toegepast. De meettechnieken pulse oxymetrie, ECG-meting en akoestische meting zijn gedetailleerd uitgewerkt. Uiteindelijk is gekozen voor een akoestisch ontwerp. Voor dit ontwerp zijn twee technieken geanalyseerd. Het gebruik van een Elektromechanical Film (EMFi) en een MR-stethoscoop. De EMFi viel buiten het budget, dus is voor de MR-stethoscoop als implementatie gekozen. Het uiteindelijke prototype voldeed niet aan alle gestelde eisen. De akoestische meting van de hartslag is veelbelovend, maar een aantal verbeteringen op het gebied van de waveguide, microfoon en elektronica is benodigd om het tot een bruikbaar product te maken.","cardiac; triggering; hartslagsensor; MRI; akoestisch","nl","bachelor thesis","","","","","","","","2012-08-25","Electrical Engineering, Mathematics and Computer Science","Telecommunications","","Bachelorafstudeerthesis","",""
"uuid:6862427f-34c5-423c-8916-24564e55ec09","http://resolver.tudelft.nl/uuid:6862427f-34c5-423c-8916-24564e55ec09","Multiple attenuation by multi-dimensional deconvolution of dual sensor streamer data","Kareth, Z.V.","Frijlink, M. (mentor); Wapenaar, K. (mentor); Bosch, F. (mentor)","2012","A lot of algorithms for imaging seismic data assume that the recorded waves illuminate the reflectors in the subsurface only once, waves of this type are called primaries. But in marine environment the sea surface reflects most of the upcoming waves thus the recorded waves may have illuminate the reflectors more than once, waves of this type are called multiples. In seismic exploration for oil and gas, Surface-related multiple elimination (SRME) is the state of the art approach to eliminate multiples using adaptive substraction of predicted multiple energy. An alternative method is deconvolution of up- and downgoing wave fields. The up- and downgoing are obtained by decomposing pressure and vertical velocity fields. Unlike SRME, deconvolution requires the incident field or direct waves. The deconvolution method was applied previously to ocean-bottom cable (OBC) data. For OBC data the incident fields are routinely recorded at zero and near offsets, but for towed streamer data they are not. However, the incident fields can be modeled. For this thesis, it is assumed that the model and true incident field are related by a linear matching filter. In this thesis a method is proposed that solves for two unknowns, the multiple-free pressure and the matching filter. To investigate feasibility, sensitivity analysis is conducted to variations on the matching filter. Only horizontally layered media will be considered.","multiple attenuation; deconvolution of up and downgoing wave; conjugate gradient","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Section Applied Geophysics","",""
"uuid:e52379fb-4327-4d89-8b0a-381f49caff03","http://resolver.tudelft.nl/uuid:e52379fb-4327-4d89-8b0a-381f49caff03","The traffic safety effects of Connected Cruise Control","Van der Gulik, J.","Brookhuis, K.A. (mentor); Van der Pas, J.W.G.M. (mentor); Jagtman, H.M. (mentor); Weijermars, W.A.M. (mentor)","2012","The newly developed Connected Cruise Control-system aims to reduce the level of congestion at Dutch highways by the provision of real-time driving advices towards car drivers. The advices have the intention to let car drivers adapt their driving speed, headway or driving lane in order to create a more homogenous traffic flow that is less sensitive for disturbances that cause congestion. The CCC-system is currently in a premature developing phase, leading to uncertainty regarding the possible effects of the system on traffic safety. In this paper the traffic safety effects of the system are estimated with the help of a microscopic traffic simulation model. The results of the simulation study indicate that high penetration rates of the CCC-system result in a reduction of the level of congestion and in a reduction of potentially dangerous Time To Collision-conflicts. However, the simulation results also indicate that there is a slight increase in safety critical Time To Collision-conflicts; leading to the conclusion that the traffic safety effects of CCC should be investigated in more depth before the system gets market deployment.","Connected Cruise Control; ADAS; Traffic Safety; Microscopic Traffic Simulation; Time To Collision","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Transport and Logistics","","","",""
"uuid:c6406d8d-8e5f-4f8d-a2f8-49531aa4c9b8","http://resolver.tudelft.nl/uuid:c6406d8d-8e5f-4f8d-a2f8-49531aa4c9b8","Space-Based FMCW SAR Systems","Van den Oever, M.","Hoogeboom, P. (mentor); Bekers, D. (mentor)","2012","Monitoring critical structures such as oil pipe lines or dikes is essential for performing in-time and high-quality maintenance. Such structures cover a large area or are in abandoned places. Consequently, performing physical inspections by dedicated personnel is either impossible or very expensive. Alternatively such structures can be inspected by using satellite radar data. Synthetic Aperture Radar (SAR) data is already being used to create images of large areas. However, the current satellite SAR systems are big and require a lot of power, which makes their data expensive. In the TOFsat project the feasibility of a lightweight and low power FMCW SAR instrument for space is investigated. This work is part of the feasibility study. In the analysis of the power budget multiple feasible combinations for transmit power and antenna size where discussed, the preferred option is a option with 50~dBW transmit power and 6.25~m$^2$ antenna area. In our configuration of the radar ambiguities are present. The ambiguous projection of the ground directly under the satellite, called the nadir return, can distort the final image. However by carefully selecting the pulse repetition frequency the projection can be shifted outside the image of the area of interest. The utilization of FMCW on a SAR satellite introduces high demands on the isolation between the transmit chain and the receive chain. A single antenna solution on a single satellite with a circulator can not provide the required isolation. To avoid this problem a gating scheme was proposed. However a space based implementation of a gating scheme resulted in conflicting values of the gating frequency and pulse repetition frequency. Therefore gated FMCW did not resulted in a feasible solution. Having two separate antennas increases the isolation between the transmit chain and the receive chain. However from phase noise calculations it followed that still 100~dB of isolation was required. These high values of isolation are still difficult to obtain, together with the fact that two antennas on one satellite would have been required this led to a preference for a bi-static system. For a more accurate simulation of the system performance the far field antenna pattern was required. Multiple antenna options where considered, based on weight efficiency the slotted waveguide array was selected for this project. The available simulation tools within TNO did not take into account the mutual coupling of the slots of the array. To find the far field pattern first the slot voltages needed to be known. To compute the slot voltages a linear system of equations has been generated. After applying corrections to make the expressions convergent, a tool has been generated. With the obtained slot voltages the far field pattern can be generated. Resulting in a tool that is capable of simulating the far field pattern of a slotted waveguide array.","FMCW; SAR; space; small; satellite; radar","en","master thesis","","","","","","","","2012-09-12","Electrical Engineering, Mathematics and Computer Science","Telecommunications","","TC","",""
"uuid:51c94e10-3581-4c8b-8ec5-6c42a24f9238","http://resolver.tudelft.nl/uuid:51c94e10-3581-4c8b-8ec5-6c42a24f9238","Analysis of 2D homogeneous space solutions of the seismoelectric P-SV-TM mode for interferometric purposes","Hartstra, I.E.","Slob, E.C. (mentor); Grobbe, N. (mentor); Bosch, F. (mentor)","2012","Seismic and electromagnetic imaging methods both provide the geophysicist with different types of medium parameters. Seismic methods are sensitive to the elastic properties of the medium, while electromagnetic methods are sensitive to the electric properties. In porous-saturated media, these two wave fields occur as a coupled system, which is known as 'seismoelectrics'. This coupling is caused by physical interactions at the grain surface boundary and is a function of several medium parameters, such as dynamic permeability. This medium parameter is valuable to the oil and gas industry, as well to the field of hydrology. By conducting a seismoelectric survey it would theoretically be possible to provide an extra control on this medium parameter. However, both practice and theory have shown that this coupling mechanism also results in a low signal-to-noise ratio. A possible solution to this problem would be to apply interferometric Green's retrieval, which is a technique based on stacking of cross-correlated data. This approach has been proved successful for the SH-TE mode in 1D. The SH-TE mode forms together with the P-SV-TM mode, the total seismoelectric system. In this thesis the first steps are taken towards the proof that this technique could also work for the P-SV-TM mode of the system. This is supported by a modelling experiment of 2D homogeneous space solutions of the seismoelectric P-SV-TM mode for different configurations. This analysis turned out that the unwanted artefacts observed in the interferometric retrieval are generated by cross-correlations between P-waves and SV-waves.","seismoelectrics; interferometry; cross-correlation","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","IDEA League Joint Master's in Applied Geophysics","",""
"uuid:9a9b69e6-df74-4fd5-a6d0-e0a76b4c8e6c","http://resolver.tudelft.nl/uuid:9a9b69e6-df74-4fd5-a6d0-e0a76b4c8e6c","Testing and modeling of the Minimally Invasive Manipulator","De Vries, K.","Dankelman, J. (mentor); Jaspers, J.E.N. (mentor)","2012","Performing complex surgical procedures laparoscopically is hampered by the loss of dexterity for the surgeon. The MIM has been developed to overcome those problems. This MIM was never tested. This report describes user tests performed with this MIM. Users applied lower forces to the test pads, but used more time and made more errors during performing the tasks. A dynamic model was built in MSc ADAMS to explore the effect of mechanical parameters like friction and inertia. The imbalance of the system showed to be the biggest source for shortfall. To improve the prototype, the instrument tip should be redesigned and the range of motion should increase. For further development more effort should be put into bringing the system into static balance. More tests to the model should be developed and executed to give a clear view of the effect of mechanical parameters to the dynamical behavior.","laparoscopy; minimally invasive manipultor; user tests; dynamic model","en","master thesis","","","","","","","","2012-09-28","Mechanical, Maritime and Materials Engineering","BioMechanical Engineering","","BME","",""
"uuid:36db1824-ee18-44e5-9531-12077919d7aa","http://resolver.tudelft.nl/uuid:36db1824-ee18-44e5-9531-12077919d7aa","Ship Motion Compensation Platform for High Payloads; Dynamic Analysis and Control","De Zeeuw, W.A.","Rixen, D.J. (mentor)","2012","","ship motion compensation platform; dynamic analysis; control","en","master thesis","","","","","","","","2015-09-19","Mechanical, Maritime and Materials Engineering","Precision and Microsystems Engineering","","","",""
"uuid:c8235590-41f5-4194-acfb-a2e97f2fbc38","http://resolver.tudelft.nl/uuid:c8235590-41f5-4194-acfb-a2e97f2fbc38","Strategies for Transmission Network Investment under Deregulated Environment","Wang, R.","Liu, Z. (mentor); Papaefthymiou, G. (mentor); Sluis, L. (mentor)","2012","This thesis describes the transmission network investment strategy under deregulated environment; and aims at studying the worldwide and European electricity market and network investment situation, identifying individual players’ interests and EU collective roadmap and objectives, finding necessary adaptations and incentive that bring individual investment strategies in line with the overall roadmap, economically assessing the influence of different expansion schemes according to different scenarios to stakeholders’ interests, and finally providing a network expansion strategy that can satisfy the requirement of the deregulated environment. The whole report includes five chapters. The first chapter gives a general introduction on the necessity of the transmission investment, challenges under the deregulated environment, worldwide investment situation, three unbundling schemes (full ownership unbundling, ISO and ITO), and merchant transmission investment. The second chapter lists some important factors that have significant influence on the investment strategy, mainly including transmission tariff, congestion management and the influence on the investment regulation. The third chapter presents an economic assessment method to evaluate the influence of different expansion plans on different stakeholders and which one is preferred. The fourth chapter introduces a transmission expansion method aiming at maximizing the total network benefit as well as satisfying the unbundling electricity industries. Finally, I conclude my main thesis work and give the outlooks on future network development based on EU collective roadmap in 2050.","deregulated environment; unbundling schemes; economic assessment; network expansion","en","master thesis","","","","","","","","2012-10-16","Electrical Engineering, Mathematics and Computer Science","Electrical Power Engineering","","","",""
"uuid:ad238ce1-df51-44f0-a115-86e5a70a4921","http://resolver.tudelft.nl/uuid:ad238ce1-df51-44f0-a115-86e5a70a4921","The Next Sustainable Footwear","Lopez, J.","Koster, R.P. (mentor); Wever, R. (mentor)","2012","The development of a collection of footwear improving the end of life stage.","sustainability; footwear","en","master thesis","","","","","","","Campus only","2013-08-22","Industrial Design Engineering","Industrial Design","","","",""
"uuid:dec40ad3-a446-4cb9-a265-6092c35b1116","http://resolver.tudelft.nl/uuid:dec40ad3-a446-4cb9-a265-6092c35b1116","Semi-stochastische aanpak van migratie, sterfte en deling in geïnfecteerde celkolonies","Arkesteijn, E.C.M.M.","Vermolen, F.J. (mentor)","2012","","wondheling","nl","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","","",""
"uuid:3895c9ec-8932-44ec-a164-43b27a04ab19","http://resolver.tudelft.nl/uuid:3895c9ec-8932-44ec-a164-43b27a04ab19","Influence of wave climate schematisation on the simulated morphological development of the Western Scheldt entrance","Van Rijn, B.W.F.","Stive, M.J.F. (mentor)","2012","In the entrance of the estuary of the Western Scheldt (defined as the area between Vlissingen and Terneuzen), wave conditions are dominated by local wind conditions rather than by wave conditions at the North Sea. This is caused by the presence of the ebb tidal delta in front of the entrance. Waves influence the simulated morphology by eroding shoals edges, depositing sediment in the adjacent channels and by partly shifting patterns of erosion and sedimentation. Waves have the most influence at relative shallow areas where also tidal currents are present. These areas are in particular the shoals of Spijkerplaat and the shoals south of the Everingen flood channel. The way the wave climate is schematised influences the simulated local morphological development up to 20% to 25% (on the spatial scale of the channels and shoals and a time scale of one year). The amount of wind and wave classes within the climate schematisation has the most influence on the simulated morphology (up 20% to 25%). Other influences within the schematisation are subordinate to the influence of the amount of classes (in the order of 5%). Including a storm event within the wave climate schematisation, has limited influence on the considered time and spatial scale (order of 5%). On the time scale of one year, the influence of the storm is to a large extent redone by more occurring, moderate conditions. For the simulation of the morphological development in the entrance of the Western Scheldt it is recommended to apply a wave climate schematisation of five wind and wave classes at most. The schematisation should be based on the reproduction of the bottom changes in the estuary, seasonality and storm event don’t need to be taken into account.","waves; wave climate; morphology; Western Scheldt; schematisation","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Water Management","","Coastal engineering","",""
"uuid:ae0196e2-971a-4536-a5cc-b3e7061e65a8","http://resolver.tudelft.nl/uuid:ae0196e2-971a-4536-a5cc-b3e7061e65a8","The response of SV-HFO cells to Ti6Al7Nb surfaces modified by Plasma Electrolytic Oxidation","De Groot, N.","Fratila-Apachitei, L. (mentor); Duszczyk, J. (mentor); Van Leeuwen, J.P.T.M. (mentor)","2012","The aim of this study was to assess the response of preosteoblasts (SV-HFO), from adhesion to matrix mineralization, on Ti6Al7Nb surfaces modified by plasma electrolytic oxidation (PEO). Two different surfaces have been generated by changing the oxidation duration from 1 to 5 minutes. The resultant (PEO1 and PEO5) surfaces showed uniform porous topographies with pores mostly in the submicron range and a mixture of anatase and rutile TiO2 phases. However, the average surface roughness, maximum peak-to-valley height, pore size and Ca/P ratio increased with oxidation time whereas pore density and surface porosity decreased. On the PEO1 surface SV-HFO cells attached and spread easily using the pores as anchoring sites for their extensions and showing cell-cell contact after 48 hours. The larger pores protruding from the PEO5 surface suppressed cell adhesion. Deposition of extracellular matrix started earlier on the PEO1 surface and after 21 incubation days a net-like structure well integrated with the porous surface was visible. Matrix mineralization was evidenced on both surfaces after 21 days. However, more uniform mineralized areas were observed on the PEO1 surface whereas an accelerated mineralization was noticed after 14 days on the PEO5 surface. In conclusion, by varying only one PEO process condition, significant changes occurred on the surface of Ti6Al7Nb alloy, which influenced both the early and late response of SV-HFO cells. The observed surface-induced effects indicated that surfaces produced at shorter oxidation time may be more beneficial for early osteogenesis.","SV-HFO; Ti6Al7NB; PEO","en","master thesis","","","","","","","","2015-08-22","Mechanical, Maritime and Materials Engineering","BioMechanical Engineering","","BME","",""
"uuid:ddb7afcc-ed0f-4956-b689-6a2a7c7c927e","http://resolver.tudelft.nl/uuid:ddb7afcc-ed0f-4956-b689-6a2a7c7c927e","Sensor Fusion on a Humanoid Robot","Vissers, B.H.A.","Wisse, M. (mentor); Jonker, P.P. (mentor); De Vries, E.J.H. (mentor)","2012","When a humanoid robot is performing a certain task and is simultaneously maintaining balance, it is important that it can accurately measure its own state. The state is described by a number of variables, such as the center of mass (CoM) and the location of the feet. This information is used by the motion controllers to properly execute the task and control the posture. The accuracy of these measurements is crucial, since incorrect state information leads to an incorrect control action, which may harm the stability on the robot. With two experiments on the humanoid robot TUlip, problems with the current state estimation were identified. Firstly, in an experiment with a motion capture system, it was shown that due to backlash and a constant bias, errors of over 80 mm occur in the perception of the feet. Secondly, using a force plate it was found that the CoM position and velocity estimation also contain errors. Here an average error of 23 mm was observed for the CoM position. The average error in the CoM velocity was 2 mm/s but had a standard deviation of 21 mm/s. On TUlip, the prediction of the step location heavily relies on the the accuracy of the CoM. Thus, the error in the CoM results in an erroneous and unsteady step location prediction. The focus for this thesis therefore lies on improving the CoM estimation, and the main goal is improving the estimation of the center of mass position and velocity by applying sensor fusion on the humanoid robot TUlip. Subsequently, a new CoM estimator is designed. First, an analysis of the current CoM position and velocity calculations is made. The calculations are then improved since these serve as an input to the CoM estimator. The new estimator is based on the Kalman filter. It uses the Linear Inverted Pendulum Model to make a forward prediction of the CoM dynamics. For the state correction the Kalman filter uses the calculations of the CoM position and velocity, and the CoM velocity measured by the inertial measurement unit. Finally, the new estimator tested using a force plate. It was found that the CoM position estimation is not significant improved. This is caused by errors in the kinematic model. For the CoM velocity estimation however, a large improvement was observed. The average error is now 4 mm/s with a standard deviation of just 3 mm/s. This is makes the prediction of the step location more steady by a factor of 7. The CoM velocity estimation is now sufficiently accurate for a proper prediction of the step location.","humanoid robot; center of mass; sensor fusion; kalman filter","en","master thesis","","","","","","","","2012-09-28","Mechanical, Maritime and Materials Engineering","BioMechanical Engineering","","BMD","",""
"uuid:9b542aca-20fd-4bcf-a8f4-c0231e625404","http://resolver.tudelft.nl/uuid:9b542aca-20fd-4bcf-a8f4-c0231e625404","Automatic Discovery of Distributed Algorithms for Large-Scale Systems","Van Berkel, S.E.F.","Dulman, S.O. (mentor)","2012","In recent years, large-scale systems have become mainstream at a very high pace. Typical examples of large-scale systems are MANETs, Wireless Sensor Networks, Pervasive Computing, Swarm Robotics, etc. These systems distinguish them- selves by the large number of devices they embody, and emergent behaviors they exhibit: Behavior that is globally perceivable, but that is made up of only local interactions of the system elements. Because of the vast amount of devices that make up a large-scale system, it is infeasible to exhibit centralized control. As an alternative, we need to leverage distributed algorithms to create and control emergent behaviors for the global goal we want the system to exhibit. Since there is no linear mapping from local interactions to global behavior, we present a global-to-local compiler to automatically generate these distributed algorithms for large-scale systems. By using Genetic Programming to combine already known building blocks from other distributed algorithms, we provide a high-level, goal-driven framework for algorithm designers to design distributed algorithms. Evaluation shows that the framework we present is indeed a valuable tool for designing distributed algorithms for large-scale systems. Improving the develop- ment speed, allowing the designer to be agnostic to the underlying details, but nevertheless providing a flexible interface, to acquire the algorithm desired.","large-scale systems; global-to-local compiler; distributed systems; agent-based systems; netlogo; distributed algorithms; manet; pervasive computing; genetic programming; grammatical evolution; wireless sensor networks; swarm robotics","en","master thesis","","","","","","","","2012-08-22","Electrical Engineering, Mathematics and Computer Science","Embedded Software","","Computer Science","",""
"uuid:94c17f88-cc09-49a3-b15f-c2c69799b103","http://resolver.tudelft.nl/uuid:94c17f88-cc09-49a3-b15f-c2c69799b103","Design Principles for Engineering Information Security in Single-Windows","Jak, M.C.J.","Janssen, M. (mentor); Van der Voort, H. (mentor); Tan, Y.H. (mentor); Hulstijn, J. (mentor); Bharosa, N. (mentor)","2012","When designing a Single-Window in which multiple organizations, both governmental and businesses, are involved, security is a key aspect. Nevertheless agreeing on security measures is difficult as organizations might have different security policies, heterogeneous systems design and various levels of ambitions. Principles are heuristics that can help to make sure information security is maintained in these multi-actor networks. Yet there is no overview of such information security principles available in the literature. This thesis proposes principles to help engineering a secure end-to-end information system in a business to government (B2G) setting. There are already a lot of frameworks on the topic of security, but they do not cover all security aspects of an information sharing network with public-private parties instead of one organization. The principles presented consolidate insights from literature and a case study.","Single-Window; Information Sharing; Information Security; Principles; Business to Government","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","ICT","","","",""
"uuid:5d530142-f176-4b1a-82aa-175631daad52","http://resolver.tudelft.nl/uuid:5d530142-f176-4b1a-82aa-175631daad52","The promise of tailored health communication: ""Design of a decision aid based on patient's behavioural profile""","Geurts, P.M.","De Ridder, H. (mentor)","2012","This report describes the results of an Industrial Design (IPD) graduation project, that was carried out as part of the “Patient Centric Solutions for Participatory Health care” (PCS4PH) project, within the Human Interaction & Experience department of Philips Research. The PCS4PH project focuses on the decision-making part of the oncology care cycle (see figure), where this thesis focuses on prostate cancer patients. The user-centred design research resulted in a first framework to apply tailoring in the health care setting. To support prostate cancer patients in making their treatment decision, tailoring was identified as an interesting research focus. Tailoring means creating communications in which information about a given individual is used to alter message processing or behaviour relevant to the outcome goal. Since men respond to their diagnosis in different ways, tailoring could help men to better process information. To succesfully implement tailoring, understanding was needed on tailoring, the disease prostate cancer, prostate cancer patient behaviour and how this behaviour can be translated into design strategies for tailoring. Two types of tailoring were found in literature: content tailoring and style tailoring. A choice was made to focus on style tailoring, because creating valid content-tailored designs was not feasible within the time constraints of this thesis. Style tailoring also offered more design possibilities and has proven itself promising in current research. From user research and literature, the feeling of being in control, masculinity, coping style, information preference and opinions of others were important factors to take into account. Being widely used in social sciences, behavioural constructs were chosen as tool, since they offer the possibility to identify and assess men’s behaviour. Literature and user research at the “Prostaatcentrum Zuidwest Nederland” designated four key constructs relevant in the prostate cancer decision-making context: Health Literacy, Locus of Control, Coping Style and Need for cognition. From iterature, clear guidelines were extracted how to tailor for the chosen constructs. These guidelines were used to tailor the tool for each of the construct extremes. However, first ideation showed that these strategies did not suffice to create distinguishable tailored designs for each construct. The strategies were ambiguous and not actionable. To optimise design strategies, a quantitative study was performed among Dutch males to see which strategies could be merged or disregarded. Seventy seven males between the age of 45 and 85 participated in the quantitative study. Statiscial analyses were used to analyse the outcome. Since no illiterate participants were found in the sample, Health Literacy was dropped for further analysis. Two new behavioural components were found from the remaining constructs: “Trusting and accepting’ behaviour and “Autonomous and information seeking” behaviour. New strategies were created for these components and tested in a qualitative study. Strategies and tailored designs were created to test this first tailoring attempt. The evaluation interviews pointed out that the assessment of behaviour was accurate and that most of the design strategies matched the preference of the targeted group. Sometimes simplicity of the information or understanding what the information is about, was more important than the tailored aspects. Long-term goals like better perceived decision outcome are yet to be investigated. Although this thesis focused on prostate cancer decision-making, the principle of assessing someone’s behaviour and creating tailoring strategies accordingly, can also be applied to the general field of health care. This thesis can be seen as a first step towards the successful implementation of tailoring in health care.","prostate cancer; decision-aid; tailoring; behavioural constructs","en","master thesis","","","","","","","Campus only","2013-08-22","Industrial Design Engineering","Industrial Design","","Master of Science Integrated Product Design","",""
"uuid:a0b68f72-4e79-4d48-971c-9929b4de7a51","http://resolver.tudelft.nl/uuid:a0b68f72-4e79-4d48-971c-9929b4de7a51","Implementeren van een versnelling van de CONTACT-programmatuur met behulp van de Graphics Processing Unit","Meijers, O.L.","Vuik, C. (mentor); Vollebregt, E.A.H. (mentor)","2012","Het versnellen van CONTACT door het implementeren van Fast Fourier Transformaties op de GPU met de CUDA en de cuFFT bibliotheek. Met daarna onderzoek over wat de versnelling van de FFTs kan zijn.","CUDA; CONTACT; FFT","en","bachelor thesis","","","","","","","","2012-08-23","Electrical Engineering, Mathematics and Computer Science","Mathematics","","","",""
"uuid:6ed59a81-d6e2-4d90-8ea0-14082f4481fa","http://resolver.tudelft.nl/uuid:6ed59a81-d6e2-4d90-8ea0-14082f4481fa","Inner-city development for middle income households","Boerman, A.M.","Boumeester, H.J.F.M. (mentor); Elsinga, M.G. (mentor); Van Bueren, E.M. (mentor); Van der Heijden, H.M.H. (mentor)","2012","Cities within the most populated part of the Netherlands called the Randstad have to provide housing for a growing amount of households by building within the city. Because the housing market has changed from a supply driven market to a demand driven market, developers and municipalities cannot develop any type of housing they prefer but have to adapt their development plans to the current and expected demand of new houses. To stimulate development for the desired middle income households within the city that matches the current demand, financial, institutional and co-operational constraints need to be taken into account to realize successful inner-city development. The main question of this research therefore is: “which type of housing could the cities in the Randstad plan to develop to attract middle income households into the city and how should this inner-city development be stimulated while taking the institutional, financial and co-operational constraints into account?” To attract or preserve desired households cities within the Randstad could plan to develop affordable ownership apartments, rental apartments with less but larger rooms and affordable rental houses in green urban areas because the preferences of these households are currently not realized because of availability and affordability. To tackle the institutional and financial constraints the municipality should try to stimulate co-operation between the stakeholders and couple their powers and resources to increase the total investment capacity, improve the knowledge of specific demands (on a local and a project scale), increase the efficiency of the planning process and decrease the entry barriers of inner-city developments by risk sharing.","inner-city development; housing market; adapting to demands; housing production; financial feasibility","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Policy, Organisation, Law & Gaming","","","",""
"uuid:25f139c3-4893-49c7-a4e0-d4be20aab7d3","http://resolver.tudelft.nl/uuid:25f139c3-4893-49c7-a4e0-d4be20aab7d3","Realised capacity estimation with use of vertical queuing method: Improving the method of estimating the overall effect of traffic measures on the vehicle delay time at the Dutch national freeway network","Veenstra, M.J.","Hoogendoorn, S.P. (mentor); Meurs, H.J. (mentor); Taale, H. (mentor); Wiggenraad, P.B.L. (mentor)","2012","The topic at which this thesis is based on is the effect of traffic measures at the vehicle delay time, VDT. The research focused towards the capacity effect of traffic measures. The effectiveness of traffic management measures is determined by their effect on the VDT. However, the development of the VDT is not singular influenced by the installation of measures. The challenge within the main topic is to unravel the total change of VDT into the contributions of all influencing factors. Within this thesis, the vertical queuing model is used to estimate the realised capacity, i.e. the actual achieved throughput during a congestion period under the prevailing conditions. Regression analysis estimates the contribution of the different individual influencing factors, such as traffic management measures, on the realised capacity. The vertical queuing model uses the principle of first-in-first-out. Road sections are individually examined. The model is based on the count of the number of arriving and departing vehicles during the day. It is assumed that the total daily demand is served, i.e. eventually all traffic will pass the road section. All vehicles can pass without any delay as long as the demand does not exceed the capacity. A queue will build up in the model as soon as the demand does exceed the capacity. The arrivals are determined by the demand and can be deduced from the traffic flow. The departures are restricted by the number of arrivals or by the capacity. While the VDT is measured, the queue length and therefore the difference between the cumulative arrivals and departures can be calculated. The total number of departures and arrivals before the beginning of a congestion period as well as directly after the congestion period are based on the measured traffic flows. The estimated realised capacity is the average traffic flow during the congestion period. The estimated realised capacity should be explained by the prevailing conditions. Regression analysis based on many records can estimate the effects of all the influencing factors. So in essence, the capacity is the variable in the model that is estimated based on the measured VDT and the measured cumulative traffic volumes. The regression analysis estimates effects and these effects can be transferred to effects on the VDT. The main conclusion is that it is possible to implement the vertical queuing model and to estimate effects of influencing factors on the capacity. The calculation of the effect on VDT is also possible, only there is need for further research to improve the estimation of the effect of prevented congestion periods. There now is a direct relation between measured traffic data and the effect of traffic management measures. It is also possible to unravel the effects of other factors such as adverse weather conditions.","traffic; vertical queuing; VVU; delay time; measures; traffic management measures; capacity; estimation","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Transport & Planning","","","",""
"uuid:a8d3c05b-e44b-4bd5-8616-cbe4d14a5a8e","http://resolver.tudelft.nl/uuid:a8d3c05b-e44b-4bd5-8616-cbe4d14a5a8e","Prevention of pipeline floatation during dredge-based backfilling","Biemans, S.","Van Rhee, C. (mentor); Van Paassen, L.A. (mentor); Hendrickx, P.H.A. (mentor); De Jager, R.R. (mentor); Jacobs, W. (mentor)","2012","Underwater pipelines have become a vital part of modern civilisation. Transport by pipeline is relatively inflexible compared to other means of transport, however it consumes less energy. Most offshore pipelines carry oil or gas, but they can also transport water or other fluids. More and more oil and gas is produced from offshore fields. The product has to be carried onshore and that is usually done by pipeline. Pipelines can be laid uncovered on the seabed, or can be embedded in the seafloor when stabilisation or protection is required. Pipelines are primarily covered when they are located in shallow waters. The material used to refill an excavated trench is called backfill. The typical material used as artificial backfill is coarse granular soil (rock, gravel, or coarse sand). When there is no suitable backfill material available close to the pipeline route, then material has to be transported from another location. A subsea pipeline should remain stable during its entire lifetime. Normal engineering practice focuses on the operational phase, while the installation phase is almost neglected. However, this study focuses on the installation phase and particularly on dredge-based backfilling. Dredge-based backfilling means using the suction pipe of a Trailing Suction Hopper Dredger (TSHD) as discharge pipe. It is not always clear if a particular soil can be used as backfill material. In the past this lack of knowledge resulted a few times in pipeline floatation during the installation phase. This lack of knowledge can also result in the disposal of perfectly suitable backfill material. A pipeline can be lifted up from the bottom of the trench if the weight of the pipeline is lower than the weight of the liquefied backfill. Pipeline floatation occurs if a soil-water mixture remains liquefied over a too large distance. In general, coarse granular soils remain liquefied for only a short period of time. If the backfill is composed of fine material, it will take a relatively long period of time before the soil settles and develops structural density. G.C. Sills (1998) defines structural density as the density which marks the change from a fluid-supported suspension to a soil in which effective stresses exist. The subject of this study is prevention of pipeline floatation during dredge-based backfilling. It is therefore necessary to understand which characteristics cause pipeline floatation. Due to economic reasons, pipelines have become lighter than a typical soil-water mixture. This is a potential risk if the sedimentation time of a soil-water mixture is relatively long. Sedimentation time is the time required for soil particles to settle out of suspension. The sedimentation time and the backfilling process are analysed using the two dimensional (horizontal and vertical) sedimentation model (2DV model) developed by Van Rhee. The 2DV model is designed to simulate the sedimentation process inside a TSHD. However, in this thesis the model is used to simulate the backfilling of an offshore trench. To simulate this process correctly, it is necessary to implement a moving discharge point in the model. Loads due to waves and currents are not considered, since pipelines are usually installed during relatively calm weather. These considerations make it possible to use the 2DV model. The backfilling process is studied in three steps. First, the process is simulated as a one-dimensional sedimentation test. Secondly, the backfilling of a trench using a stationary TSHD is evaluated. Finally, the backfilling of a trench using a moving TSHD is simulated. The moving TSHD tests produce a distribution of the soil-water mixture density. This distribution is converted to a grid which is used as input for the beam-model (Matlab). The beam-model simulates pipeline displacement at a certain moment during the backfilling operation. The beam-model is based on the theory of the beam on elastic foundation. In this model only static loads are considered; the own weight of the pipeline and the buoyant force caused by the displaced fluid. The beam-model combined with the 2DV model provides an approach to model pipeline displacement during dredge-based backfilling. The 2DV sedimentation model is tested to its limits in this thesis. The simulation of the backfilling operation of a moving hopper requires a model area with a great length and a relatively small height. This results in a model composed of stretched grid cells (in longitudinal direction). The 2DV model is at his numerical boundaries due to these stretched grid cells. The results of the ‘moving hopper’ simulations are therefore questionable. The results of the static simulations can be considered as reliable, since in these simulations the 2DV model remains well within the boundaries.","","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Geo-engineering","",""
"uuid:23211b17-11ce-4cc5-8f84-35766f7a975f","http://resolver.tudelft.nl/uuid:23211b17-11ce-4cc5-8f84-35766f7a975f","Network-based bootloader for distributed embedded systems applications","De Roest, M.A.; Treep, H.J.","Dulman, S.O. (mentor)","2012","This thesis describes the design, implementation and deployment of a network-based bootloader for distributed embedded systems applications. The bootloader is based NXP's LPC1769 microcontroller containing the ARM Cortex-M3 processor. The CAN bus is used as the network's physical layer. Due to the modular design of the bootloader, easily switching to different technologies is possible. Up to the day of publishing of this thesis, flashing of 88 microcontrollers with a 180kB binary takes 1.5 minutes, while adding new microcontrollers does not add time.","bootloader; LPC1769; embedded systems; network-based bootloader; network bootloader; microcontroller; microprocessor; distributed embedded systems; embedded systems applications","en","bachelor thesis","","","","","","","","2012-08-23","Electrical Engineering, Mathematics and Computer Science","Software Technology","","Embedded Software","",""
"uuid:ae20405e-4291-4dce-87a5-60ff477c88f5","http://resolver.tudelft.nl/uuid:ae20405e-4291-4dce-87a5-60ff477c88f5","Model-Reduced Gradient Based Production Optimization: Computational Analysis of POD-Based Model-Order Reduction in the Context of Production Optimization","Sava, D.M.","Hanea, R.G. (mentor)","2012","Reduced-order modelling procedures, seen as an alternative to the classical gradient based approach, in which the adjoint of the tangent linear approximation of the forward model is replaced by the adjoint of a linear approximation of a reduced forward model. Proper orthogonal decomposition is used to compute the reduced model, by using the reduced adjoint, the gradient of the objective function can be approximated and the maximization problem can be solved in a reduced space. This work researches the viability of performing production optimization based on model-order reduction, by comparing several aspects of the implementation with similar aspects of Ensemble Optimization, a already well known way of solving the production optimization problem, that computes the gradient information from an ensemble of model realizations.","Production Optimization; Model-Order Reduction; Proper Orthogonal Decomposition; Ensemble Optimization; Data Assimilation","en","master thesis","","","","","","","","2012-08-14","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","Risk and environmental modelling","",""
"uuid:c213e59d-c1fc-47b8-8a52-e321c757c190","http://resolver.tudelft.nl/uuid:c213e59d-c1fc-47b8-8a52-e321c757c190","Development of heterogeneous slope reservoirs for different production mechanisms","Meijer, L.A.","Jansen, J.D. (mentor); Luthi, S.M. (mentor)","2012","Deep-marine slope and base-of-slope hydrocarbon reservoirs are difficult to model and produce because of their size and complex nature. The oil and gas industry focuses on easily producible reservoirs in channelized deposits, thereby leaving considerable volumes in the more heterogeneous external levees and lobes. This thesis is on how such systems can be modelled and produced as a whole and how variation of input parameters can affect the recovery factor in its reservoirs. A conceptual reservoir model consisting of different facies regions was created based on geometries found in literature, after which realistic petrophysical data from field analogues were implemented. Fifty-six simulation cases were defined to test the effect of using different upscaled grid sizes, production mechanisms, fluid types, well lay-out and rock properties on the recovery factor. Deep-marine slope and base-of-slope reservoirs can be modelled reasonably well by using object-based modelling for the channels and internal levees, truncated Gaussian simulation for the external levees and multi-point facies simulation for the fan region. Fluid flow simulations show that specially upscaling and application of different water saturation functions have a significant impact on the modelled recovery factor. Furthermore, reservoirs of this kind can be produced best by aiding the natural production mechanisms with water injection. Wells should be deviated, because they have a larger contact area with the reservoir sections than vertical wells, and horizontal wells are less effective due to the deposits’ inherent vertical heterogeneity. Well orientation should be perpendicular to the principal paleoflow direction. To increase oil production, the external levees can be produced with deviated injectors and producers oriented parallel to the channel belt.","slope reservoirs; recovery factor; conceptual model; deep-marine; heterogeneous; simulations; geology","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Petroleum Engineering & Geosciences","",""
"uuid:d3f9b17a-c52a-441a-bbcf-e33bd36d62dd","http://resolver.tudelft.nl/uuid:d3f9b17a-c52a-441a-bbcf-e33bd36d62dd","Design of a strategic framework for new business development in branded environments for UXUS","Singh, G.V.","Hultink, H.J. (mentor); Smulders, F.E.H.M. (mentor)","2012","UXUS has established itself as a design agency with a portfolio of award winning projects for clients in different market sectors. UXUS intends to establish itself as a strong player in the branded environments domain, which includes conceptualizing and designing different touch points in the customer’s journey of experiencing a brand. As an established firm, UXUS wants to utilise its experience in retail and interior design, it’s strength in conceiving unique and creative themes and narratives to grasp existing or emerging opportunities in this market sector. So, in order to gain market share in the presence of established global giants and competitors what should be UXUS’ strategy and what steps should be taken forward? How can UXUS differentiate itself and grow? After analysis of the external and internal environments and research into the aspects of growth, the main issues that could affect the growth of UXUS into branded environments are selected.A set of recommendations are proposed considering each of the issues mapped using the service blueprint technique. These recommendations would also trigger the formulations of action steps for UXUS in order to grow and establish itself in the branded environments discipline. Based on the strategic framework and recommendations, an action plan for marketing and management is formulated for honing up new business development methods and internal processes. The strategy of “Connect, Invest and Sustain” for the new brand environment domain is proposed and is visually documented in a roadmap.","branded environments; strategy; new business development; growth; marketing; organisation","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product Innovation Management","","Master of Science Strategic Product Design","",""
"uuid:26677059-5a6e-4bdf-abc9-92b6e41cef3a","http://resolver.tudelft.nl/uuid:26677059-5a6e-4bdf-abc9-92b6e41cef3a","Transmitter measurements and analysis of frame synchronization of an Impulse Radio Ultra-wideband system","Ramkumar, A.","Janssen, G.J.M. (mentor); Pflug, H. (mentor)","2012","Ultra-wideband (UWB) is a promising radio technology which is well suited to low power short-range wireless applications. At Holst Centre/imec, there is a research program on the design and implementation of ultra low power, Impulse Radio-UWB (IR-UWB) wireless systems suitable for audio streaming and real time localization systems. Some key technology challenges for IR-UWB systems are Direct Current (DC) power consumption, Link-budget and Quality of Service (QoS). The first part of this thesis focuses on measurement of DC power consumption; transmit output power and spectrum using the IR-UWB transmitter. As the hardware supports several modes, an automated measurement setup with programmable parameters has been created. In the second part, a mathematical model for the preamble and Start of Frame Delimiter (SFD) detection stages of the receiver operation is provided. This part of the receiver is a critical one and is challenging for IR-UWB type of signals due to the low transmit power. A method to estimate the signal to noise ratio (SNR) per pulse from the output of the preamble detection block is proposed. A theoretical approach for setting the threshold for SFD detection is described. It is shown through simulations that this method of threshold setting provides a significant improvement in receiver performance.","IR-UWB; low power; preamble detection; SFD detection; SNR","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Telecommunications","","Electrical Engineering","",""
"uuid:9ee4cf03-261e-48bf-a6b7-29a427aef575","http://resolver.tudelft.nl/uuid:9ee4cf03-261e-48bf-a6b7-29a427aef575","How contextual innovation management influences time to market: A case study in company X","Fuchs, M.","Van der Duin, P. (mentor)","2012","In the high-tech food industry the speed and rate at which organizations can introduce products into the market are critical for sustaining competitive advantage and market share. Therefore Company X wants to accelerate its time to market. Based on 7 case studies of recently finished innovation projects in COMPANY X, the relationship between time to market and contextual innovation management was investigated. Radicalness of innovation was identified as the main significant contextual factor. Subsequently a contextual framework was proposed including three customized processes (context 1: existing market & experience with technology, context 2: existing market & no experience with technology, context 3: new market). Using this framework innovation managers can administer the appropriate activities and therewith save time by minimizing the effort on factors that are not very important for the specific configuration of variables (i.e. context). Assessment of the contextual framework by an internal expert support the idea that contextual innovation management contributes to an acceleration of time to market, especially for innovations aiming at an existing market (i.e. the more incremental innovations). Research with regard to contextual innovation management is still exploratory and can be extended towards other areas of interest (e.g. innovation at lowest costs etc.).","contextual; innovation","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Technology, Strategy and Engineering","","","",""
"uuid:453c4f9b-1d9f-4f34-b0e2-a048c5f9a365","http://resolver.tudelft.nl/uuid:453c4f9b-1d9f-4f34-b0e2-a048c5f9a365","Designing a portable document reading device for the blind","Gudadhe, A.S.","Hajian, M. (mentor); Rusák, Z. (mentor)","2012","Situation: The World Health Organisation (WHO) estimates that worldwide, 285 million people are visually impaired due to various causes; 39 million of them are blind, a majority of them living in developing countries (WHO June 2012). This project stems from reflection into their lives. Literature forms one of the integral medium of acquiring knowledge and information for the blind. Currently, the system widely employed by blind people across the globe to read and write is the Braille standard. The difference in characteristics of this standard from the normal English language results in the need for literature to be reproduced in Braille; which is both time and resource-consuming. Hence, the number and diversity of Braille-translated books available is very limited; in-turn, limiting accessibility to information. Furthermore, the current braille literacy levels amongst the blind and visually impaired are very low, around 10% in USA (NFB 2009) and even lower in developing countries. Even today, despite the fast advance in technology, very few products in this category of reading aids exist in the market, which are especially designed and developed for the blind. Additionally, most of these products are either bulky, not portable, uncomfortable, expensive, partially useful or not designed/suitable for use by a blind person i.e. not user friendly. The high prices of such devices further render them unaffordable to a large section of the blind in developing nations, where the majority of blind reside; thus, catering only to a very small market of developed regions like US, Europe, etc. The project: The aim of this project is to enhance the daily life of the blind by developing a portable, affordable product utilising modern technology, which enables them to access everyday documents and books currently unavailable or difficult to obtain in Braille. Another aspect is to make the most of the expertise of the supervisory team in areas of electronics, image processing and user research, to develop a practical and functional test model. The project involved extensive rounds of interviews, modelling and testing with participants (user-centred and participatory design approach) along with a sound technical analysis. A typical reading device involves thee steps: image capture, processing (image correction algorithms and optical character recognition) and user interaction (buttons, text-to-speech audio output). Scanner is found to be a better image capture module in comparison to small camera found in smartphones, giving a clearer, sharper image and also easy to use. The proposed design comprises of two overlapping scanner heads. The scanned images from each of the scanners are matched, stitched together and then processed into an audio output using open-source Optical Character Recognition (OCR) and Text-to-Speech (TTS) algorithms. The various features and overall integrated design make the device portable (handheld), affordable (< 180 euros) and easy to use.","blind; reading device; portable; scanner","en","master thesis","","","","","","","Campus only","2014-08-21","Industrial Design Engineering","Design Engineering","","Master of Science Integrated Product Design","",""
"uuid:37ae1dfa-a0b7-480d-8060-3dbc702e7a59","http://resolver.tudelft.nl/uuid:37ae1dfa-a0b7-480d-8060-3dbc702e7a59","Incentives for deployment of electricity generation from renewable energy sources in Colombia","Ceballos Lopez, A.","Linares LLamas, P. (mentor)","2012","Colombia, despite having a well structuredlegal, regulatory and institutional framework, has not had a significant development of projects that take advantage of renewable resources for electricity generation, as RES-E technologies cannot compete with conventional technologies and there are no defined policies to incentivize them. This work inventories the available renewable energy resources and identifies the main motivations that would encourage Colombia to establish a renewable energy incentives policy. It also provides an analysis of different alternatives to promote the use of renewable energy sources, and proposes an auction for the construction of wind farms, as the main incentive mechanism, because it is identified as the most suitable taking into account the characteristics of the Colombian market. Additionally, this document proposes the most important changes required in Colombian law to meet the challenges introduced by an increase in the penetration of highly intermittent generation.","Renewable energy sources; Colombian electricity market; Economic incentives","en","master thesis","","","","","","","Campus only","2012-12-06","Technology, Policy and Management","Management","","EMIN Master on economics and management of network industries","",""
"uuid:9aa938da-35d1-457c-a2f5-9215cd068c9b","http://resolver.tudelft.nl/uuid:9aa938da-35d1-457c-a2f5-9215cd068c9b","The design of a global shutter CMOS image sensor in 110nm technology","Ge, X.","Theuwissen, A.J.P. (mentor)","2012","The goal of this work described in this thesis is to design a CMOS image sensor chip, implementing pixels with a 4.8?m pitch with a peripheral readout circuitry in a 110nm CMOS process. The architecture of the CMOS image sensor is presented, with a functional illustration for every block. The 8T global shutter pixel noise, circuit and layout are described and analyzed in the thesis. The simulation results of the pixel readout speed and the output swing are presented and some other performances are shown. The Analog Front-End (AFE) circuit design of a switched capacitor amplifier and a sample and hold stage are also presented. The layout of the AFE circuit for the important blocks is done and the practical concerns of the amplifier design are discussed. The Low Voltage Differential Signaling (LVDS) driver also is implemented in this thesis, the power efficiency and common mode feedback stability issues of it are tackled as well. The simulation results of the LVDS driver with extraction of parasitics are presented and the performance summary is given.","CMOS image sensor; global shutter pixel; AFE; LVDS","en","master thesis","","","","","","","","2012-08-31","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","Microelectronics","",""
"uuid:02374125-d46f-4ef2-9d0d-c9f193af005b","http://resolver.tudelft.nl/uuid:02374125-d46f-4ef2-9d0d-c9f193af005b","Assessment of sustainability in product design at BK cookware","Zapata Mejía, J.E.","Wever, R. (mentor); Dehli, S.R. (mentor)","2012","BK (Berk Kampen) is a Dutch company part of the Royal Delft Group, which in the past 160 years has grown into a cookware brand that combines high quality with ease of use and prize-winning design. BK wants to deliver both convenience and inspiration for cooking through good products, specially developed for the needs of users through requirements that vary from cooking techniques and design to energy consumption and ease of use. In order to fulfil such goals, BK has a range of about 29 product lines of pots and pans, 7 lines of cooking tools and 3 lines of cooking knifes. BK’s product portfolio includes a wide range of processes and materials such as Tri-ply stainless steel, silicones, aluminium, and anti-adhesive coatings. These characteristics allow the company to offer a wide range of products for the Dutch and German markets and most of the production happens around Eastern Europe and Asia. The Corporate Social Responsibility (CSR) policy of BK has brought to the company a desire to find out about the environmental impact of their production processes, therefore there are a series of efforts in more sustainable practices inside the company. From the Corporate Social Responsibility (CSR) Policy of BK, there is an increasing interest to provide solutions in terms of environmental impact of products and processes. Although the company is established in the Netherlands, most of the production happens in Western Germany and Far East, which represents a challenge in the total control of the practices that the suppliers carry on during the different production processes. In order to contribute to the current CSR policies, BK wants to implement and assure more sustainable practices inside the company and within its stakeholders; therefore from the product design process it has to be considered multiple factors that will have an environmental impact in the future production process and the whole supply chain.","eco design; fryware; cookware; sustainability; sustainable development","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design Engineering","","Integrated Product Design","",""
"uuid:672a9aa7-6a77-4dbc-a135-03d3f5fa25f3","http://resolver.tudelft.nl/uuid:672a9aa7-6a77-4dbc-a135-03d3f5fa25f3","Impacts of Distributed Generation on remuneration of the Electricity Distribution Company in Spanish Electric System","Petrusic, A.","Domingo, C.M. (mentor)","2012","The contribution of Distributed generation (DG) to Electric Power Systems is evident, as it contributes to all major drivers of System´s sustainability (open market, security of supply and environment) propagated by EU directives. However, it is still not clear what impacts DG has on the Distribution System Operator´s (DSO) operations, which is in charge of providing a safe environment and technical conditions for their consumers and to DG as a newcomer in the system. This thesis addresses the issues related to Technical and Economic impacts of DG on remuneration of DSO. Using a Reference Network Model (RNM), an impact assessment is performed by analyzing changes in the grid´s operation through grid reinforcement costs, energy losses, and quality of service indices, under different scenarios of DG penetration in the Distribution network. Based on the obtained results recommendations have been made for alteration of DSO´s remuneration scheme for the case of a DSO in Spanish regulatory framework.","distribution; distributed generation; impact assessmen; Reference Network Model","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Multi Actor Systems","","Erasmus Mundus Joint Master Programme in Economics and Management of Network Industries (EMIN): Engineering in Policy Analysis (TPM, TU Delft, Netherlands)","",""
"uuid:476aa816-4fe8-4b61-adf7-a8d25ade944b","http://resolver.tudelft.nl/uuid:476aa816-4fe8-4b61-adf7-a8d25ade944b","The Effect of Network Structure and Signal Settings on the Macroscopic Fundamental Diagram","De Jong, D.","Hoogendoorn, S.P. (mentor); Knoop, V.L. (mentor); Van Lint, J.W.C. (mentor); Taale, H. (mentor); Wiggenraad, P.B.L. (mentor); Schreuder, M. (mentor); Reijneveld, A. (mentor)","2012","Recently it has been proposed that the performance of a complete network can be represented graphically using only aggregated data for flow and density. The resulting graph is the macroscopic fundamental diagram (MFD), which relates the average flow (performance) to the number of vehicles in the network (accumulation). The resulting shape is often concave, meaning that the performance can be maximised if a fixed number of vehicles is maintained in the network (optimal accumulation). One of the most promising methods to achieve this, is by adapting signal timings. The objective of this thesis is to investigate if (1) a relationship between the shape of the MFD and the structure of the underlying network exists and on which factors this depends and (2) if the shape of the MFD of a subnetwork (neighbourhood) and its perimeter (ring of higher level roads (with signalised intersections) around a subnetwork) are affected by different signal timings and how this does affect the applicability of the MFD for control strategies. To assess the effect of the structure on the network, a tool has been developed to automatically generate fictitious networks with different structures, in which the amount of infrastructure and signal timings are matched dynamically to a randomly generated OD-matrix. The resulting networks are used as a base for the simulations, which are done in the microscopic traffic simulator VISSIM. Using various signal timings for signals located on the perimeter, the flow from the subnetwork to the perimeter is restricted and vice-versa, in order to assess how the MFD of both react to these changes. Regarding the relation between the shape of the MFD and the network structure, it is concluded that the structure of a network in itself does not have a strong influence on the shape of the MFD. Differences between MFDs are not caused by topological differences, but by the different characteristics of the roads (length, speed, capacity) and the amount and type of intersections in the underlying network. The different factors influencing the shape of the MFD could not be quantified – in order to construct MFDs based only on knowledge of the network and without the use of simulations - as the shape of the MFD is found to differ strongly, even for similar networks. As such it is concluded that the stochastic and dynamic nature of traffic has a strong influence on the shape of the MFD. Especially the accumulation is highly sensitive to differences in the distribution of traffic over the network, making the optimal accumulation particularly hard to predict. Regarding the effect of signal settings on the shape of the MFD of a subnetwork and its perimeter and its applicability for control strategies, it is concluded that a strong relation between the MFD of the subnetwork and its perimeter does exist, in which both react in the same way to changes in traffic demand and signal timings. The ratio between the performance of the subnetwork and perimeter is highly consistent and not strongly affected by changes in the signal settings, implying that signal timings exist, which optimise the performance of both the subnetwork and its perimeter. The optimal accumulation of the perimeter is found to be highly sensitive to changes in the signal timings. As a consequence it is concluded that the MFD is difficult to use for control strategies aiming to adapt signal timings to maintain the optimal accumulation in a part of the network, because these changed signal timings result in a different optimal accumulation.","MFD; Macroscopic Fundamental Diagram; signal settings; network structure","en","master thesis","","","","","","","","2012-08-28","Civil Engineering and Geosciences","Transport & Planning","","Transport and Planning","",""
"uuid:3d4832fb-53f3-4997-84b5-5c5d6bd265b9","http://resolver.tudelft.nl/uuid:3d4832fb-53f3-4997-84b5-5c5d6bd265b9","The Desigh of a High Dynamic Range CMOS Image Sensor in 110nm Technology","Liu, Y.","Theuwissen, A.J.P. (mentor)","2012","This thesis presents the design of a dual-transfer-gate high dynamic range CMOS image sensor. Several methods that can be applied to extend the dynamic range have been developed. However, all of these solutions have undesired problems, such as nonlinearity response, higher dark current shot noise and discontinues signal-to-noise ratio. In this thesis, a dual-transfer-gate pixel which can achieve 84.5dB dynamic range is implemented in a 110nm CMOS image sensor technology. The sensor provides 76fps speed in 12-bit digital format. The equivalent input noise is as low as 3.1e- by introducing correlated-double-sampling (CDS) technology.","High dynamic range; Image sensors; Ramp geneato; Column ADC; Bandgap; Multiplexer","en","master thesis","","","","","","","","2012-08-27","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","Electronic Instrumentation Laboraoy","",""
"uuid:362367a2-d043-47b0-b10c-745faecf07ea","http://resolver.tudelft.nl/uuid:362367a2-d043-47b0-b10c-745faecf07ea","A multi-actor analysis approach in decision making: A framework to complement ISA-95 guidelines within manufacturing companies","Osorio, F.A.","Hermans, L.M. (mentor)","2012","Decision making in manufacturing activities is an everyday business. Manufacturing activities involve the interaction of different actors (i.e. departments) to provide information or activities that will serve as an input for decision making. The situation of dependency, network and cooperation in these activities calls in to question the suitability of today´s decision making processes, which more than enough do not actively and effectively include the several involved actors. A framework of a decision making process based on a multi-actor analysis approach was created and tested in manufacturing companies. This framework process proved with quicker and more effective decisions and suggests to have the potential to have great added value and more benefits to the companies using it. The thesis suggests that indeed, including the involved and affected actors at all stages of decision making, increases the chances to have succesful decisions and improves the support and better implementation of those decisions. The framework can be improved in several areas, most notably, by more empirical tests and research in different manufacturing companies among different regions.","decision making; multi-actor analysis; ISA-95","en","master thesis","","","","","","","","","Technology, Policy and Management","Policy Analysis","","Engineering and Policy Analysis","",""
"uuid:68c8e36e-5d0a-4ed1-ba01-283bf73d95d2","http://resolver.tudelft.nl/uuid:68c8e36e-5d0a-4ed1-ba01-283bf73d95d2","The Influence of Retention Basins on Tidal Dynamics in Estuaries","Lugt, D.","Schuttelaars, H.M. (mentor)","2012","The Ems estuary suffers from high concentrations of suspended sediment, which is harmful for the life in the river. Sediment import occurs because of tidal asymmetry, a difference between the velocity of the current during high tide and low tide. The use of retention basins are a possible measure to reduce the tidal asymmetry. An analytic model, using partial differential equations derived from the Shallow Water equations and Navier-Stokes equations, was used to investigate the influence of retention basins on the tidal dynamics and sediment transport in estuaries in general and the Ems estuary specifically. For these investigations, this analytic model is useful because system conditions can easily be changed. Results show that the locations of retention basins are of great importance for their performance. In the Ems estuary the location minimizing the sediment import is at the end of the estuary, near the weir. Enlarging the retention basin is better than placing a second basin at a different location in the estuary.","tidal dynamics; estuaries; Navier-Stokes; Shallow Water equations; retention basins; sediment","en","bachelor thesis","","","","","","","","2015-03-01","Electrical Engineering, Mathematics and Computer Science","Applied Mathematical Analysis","","","",""
"uuid:bfd3169e-4e69-4c69-96cd-9d43566e67a7","http://resolver.tudelft.nl/uuid:bfd3169e-4e69-4c69-96cd-9d43566e67a7","Towards smart integrative planning to avoid last-minute deliveries in construction projects from a supply chain perspective: The case of an electrical material supplier Legrand B.V.","Fan, Y.","Tavasszy, L.A. (mentor); Ludema, M.W. (mentor); Ravesteijn, W. (mentor); Broos, J.P. (mentor)","2012","This summary provides a brief account of the background, approach, analysis and conclusions of this thesis. Construction is characterized as a high hazard industry which contains a wide range of activities including construction, alteration and/or repair (Michaels, 2010). The organizations involved in construction projects are project owner, designer, contractor/sub-contractors, suppliers. According to Benton&McHenry (2010), the material-delivery system is an important success factor for a construction project, which involves many companies such as professionals and suppliers. However, suppliers, which have limited control on a construction project, are an important organization involved in a material-delivery system of construction projects. Thus improvements on the performance of suppliers can contribute to an effective and efficient material-delivery system of a construction project. In a construction project, last-minute deliveries are one of the problems suppliers have encountered. Therefore, this research is based on the notion that reducing the influences exerted by last-minute deliveries on construction supply chain can improve suppliers’ performance, which in turn contributes to an effective and efficient material-delivery system of a construction project. It aims to explore how the construction supply chain should be in order to have less last-minute deliveries. The main research questions stem from these ideas and are defined as follows: How can the planning process be organized for suppliers from a supply chain perspective in order to lead to a better process with less last minute deliveries to construction sites? To answer this main research question, first a literature review is conducted to explore what is already known about how to improve the performance of material-delivery system of construction projects. Prior work on the improvement of material-delivery system was found to address some issues on two aspects: 1) Construction project management Increase the material-delivery system of construction projects from a project management perspective 2) Construction supply chain Increase the material-delivery system of construction projects from a supply chain perspective But improving the performance of construction supply chain from a supplier’s perspective by reducing the number of last-minute deliveries is not explored. To answer the main research questions, seven research sub-questions are formulated. The process of answering the sub questions are divided into two phases: analysis phase and design phase. The analysis phase is focusing on clarifying the current problem situation and the reasons for higher number of last-minute deliveries to construction sites. While the design phase aims to identifying best practices concerning construction supply chain and applying these practices to the supply chain of one construction projects supplier --- Legrand B.V.. The seven research sub-questions are listed below: Analysis Phase 1) What is the current situation related to the construction organization, supply chain process and the problem of last minute-deliveries 2) What is the current situation related to the planning process for construction supply chain? 3) What are the reasons for a higher number of last-minute deliveries in construction projects? Design Phase 4) What are the best practices concerning the planning process in construction projects from a supply chain perspective so far? 5) What can be learned by evaluating the best practices in the current situation in order to make recommendations on how the redesigned planning process should be? 6) What is the recommendation on how the planning process can be organized in construction projects from a supply chain perspective? 7) What are the benefits of the recommended solutions for both Legrand and related stakeholders? In this thesis, a multi-method strategy including interview, document review and literature review is used for data collection in order to increase the credibility and validity of the results (K.Yin, 2003). Additionally, root-cause analysis is also used to find the root cause of higher number of last-minute deliveries to construction sites. The first two research sub-questions are about identifying the current situations with respect to construction organization structure, construction supply chain, problem scale of last minute deliveries and the current planning process in construction projects from a supply chain perspective, thus related data are needed to collect to visualize these current situations. In this research, literature review and document review are conducted to identify the current situations. Additionally, eight interviews in related construction organizations also contribute to the identification of the current situations. Thus, the credibility and validity of the current situation are increased by employing these three kinds of data collection methods. In chapter 4 which is for answering research sub-question 3, root-cause analysis is used to identify the root causes for higher number of last-minute deliveries to construction sites. Root cause is the most basic reason for an undesirable condition or problem which, if eliminated or decreased, would have prevented or mitigated it from occurring (Paulf, Dell, & Anderson, 1993). In this research, one of the technic for root cause analysis ----- events and causal factors analysis is chosen as a tool for analyzing, because the construction organization is complex and also there are surrounding conditions (Paulf, Dell, & Anderson, 1993). For research sub-question 4 which is focusing on finding the best practices concerning the planning process in the construction projects from a supply chain perspective, literature review is considered as a method. According to Yin (2003), one approach which can be considered as an analytic strategy is to use analytic technique such as creating some requirements and showing if some evidence satisfies those requirements. Thus in this research, sub question 5 and 6 are answered by displaying all the alternative solutions identified in Chapter 4 and evaluating them in the current situation by means of balanced scorecard. According to the interviews and related document, literatures, it derives that there are three controllable root causes for the higher number of last-minute deliveries to construction sites: ? Viable demand from client ? Imperfect design ? Lack of communication among construction contractors In order to reduce the number of last-minute deliveries to construction sites caused by the three controllable root causes, five recommendations have been made for the suppliers involved in construction projects. The five recommendations have different priorities. The most promising strategies are Partnership development, and building information modeling. Firstly, by participating into the design phase of a construction project and simulating the whole construction process, not only the number of rush orders caused by imperfect design and lack of communication among the whole construction organization can be reduced, but also this strategy can benefit the whole construction organizations. On the other hand, agile supply chain, logistics centers are also two strategies which can improve supplier’s construction supply chain performance by quickly responding customers’ needs, therefore mitigating the influences exerted by rush orders. Thirdly, postponement by means of modularization, standardization is also a promising strategy, although most of the electrical materials for construction projects are already standardized. It indicates that the standardization can be improved to a more detailed level, which makes the assembly on sites more flexible, so urgent demands from customers can be satisfied more quickly. This thesis contributes to both theory and management in the following ways: With respect to the academic contribution of this research, it can be found on the integration of expertise and research efforts aiming to result in the advancement of knowledge on the field of construction supply chain management and logistics. It may resolve theoretical questions such as whether the number of last-minute deliveries in construction projects can be reduced by redesign the construction supply chain. Bridging this scientific gap can lead in substantial conclusions and valuable practical applications. In addition, the managerial contribution of this research can be seen on the number of managerial terms intervening in this endeavor. Since several years ago, most of the manufacturing companies recognized that supply chain management can be a new way of doing business. The implementation of this new approach was a consequence of various changes in manufacturing environments. All these indicate that construction logistics is an interesting area for construction suppliers to make higher profit. Also, for construction project managers, construction logistics can help them understand the projects and the planning procedure better.","construction supply chain; last-minute deliveries; supply chain management","en","master thesis","","","","","","","Campus only","2013-08-20","Technology, Policy and Management","Transport and Logistics Organization","","Management of Technology","",""
"uuid:3e371583-7f8e-41a2-8953-f9c5402e5c99","http://resolver.tudelft.nl/uuid:3e371583-7f8e-41a2-8953-f9c5402e5c99","Simulation of oil down-coning in a single well scenario using finite element analysis","Slangen, G.L.J.","Bruining, J. (mentor)","2012","When an oil reservoir is underlain by an aquifer, oil production draws the water from the aquifer upward, forming a water cone, which under adverse conditions enters in the production well leading to high water cuts. An alternative option is to produce above the critical rate from the aquifer, i.e., at such a rate that the oil cone is drawn into the well. Analytical models, such as derived by Muskat et al. allow to determine the critical rate in terms of simple expressions for interface models that thus ignore relative permeability and capillary pressure effects. Including these effects requires numerical modeling. The numerical modeling of this process is a challenge, because of the occurrence of steep water-oil fronts in the flow direction and the small width of the cone near the production well, which coincides with high production rates. This thesis investigates the possibility of using finite elements for the simulation of oil down-coning. The advantage of finite elements is that it allows grid refinement in regions where large variations occur. A diffusion coefficient is introduced in the saturation equation to smoothen the numerical solution, hereby decreasing the occurrence of flow singularities and allowing larger element sizes, thus decreasing the computation time. The computer model is then used to simulate coning of the oil-water interface, towards a single production well situated at the bottom of a reservoir. The considered reservoir geometry is radially symmetric, so that calculations can be done for a two-dimensional section. The model includes relative permeabilities, capillary pressure and gravity effects. To avoid infinite capillary pressure at connate water saturation, we use a fractal model for continuation of the capillary pressure below a defined critical water saturation. The height of the oil-water interface is not kept constant at the external radius, so that all oil is free to move through the reservoir. Simulations are done for scenarios with different fluid parameters, and variating drawdown rates. For certain drawdown rates, a stationary profile of the interface occurs. If this does, the height of the cone is within the range of values given by the interface model. However, critical rates provided by the derived interface model is not satisfied in the numerical model, since breakthrough does occur in simulations with rates below this critical rate. This is due to the neglecting of capillary force and relative permeabilities in the interface model. The numerical model in this study represents a reservoir where the initial oil cap is of limited radial extend, because the height of the oil column at the external radius decreases and is not kept fixed at a certain height, and is therefore not representative for a reservoir with larger interface size.","coning; geothermal; reservoir simulation","en","bachelor thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Section Petroleum Engineering","",""
"uuid:e9a0ed78-1624-4610-8d96-3977c3116b20","http://resolver.tudelft.nl/uuid:e9a0ed78-1624-4610-8d96-3977c3116b20","An application of Real Options to the valuation of an investment in electrical network","Moriakov, N.","","2012","In the thesis it is shown how Real Options can be applied to the valuation of an investment in electrical network. The approach developed is also compared to more classical tools from decision analysis. It is also shown how the valuation algorithm based on real option analysis can be implemented in a practical and usable way.","Real Options; riks; investment valuation","en","master thesis","","","","","","","","2013-08-20","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","Risk and Environmental Modelling","",""
"uuid:0d135444-9b3e-4768-90e9-b0c247b1f58f","http://resolver.tudelft.nl/uuid:0d135444-9b3e-4768-90e9-b0c247b1f58f","Sustainable BATA footwear","Van der Helm, R.M.","Vogtländer, J.G. (mentor); Gattol, V. (mentor)","2012","BATA has a heritage of being a responsible company since its founding, but has not yet institutionalized and measured their social and environmental accomplishments. This study starts measuring the environmental impact of 4 current BATA shoes by means of life cycle calculations. Thereafter, the effects of different communication strategies are researched by means of an experiment. Finally, a concept for the sustainable BATA shoe of tomorrow is developed. In the first section of this study, the life cycles of the following 4 existing BATA shoes are analyzed: (1) a pair of SAXA ESD S2 shoes (security shoe, BATA Industrials, Netherlands), (2) a pair of pure PVC shoes (BATA Indonesia), (3) a pair of pure EVA shoes (BATA Bangladesh) and (4) a pair of leather shoes (BATA Italy). For these 4 shoes, the Eco-costs and CO2-equivalent for each pair are calculated. The Eco-costs and CO2 equivalents for each pair are further divided over so called life cycle phases: material production phase, processing phase, transport phase and end-of-life phase. The Eco-costs and CO2 equivalents of each life cycle phase are, in turn, divided over materials, factories and forms of transport. It appears that the material production phase (especially the materials PU, PVC and EVA) is responsible for the largest part of the Eco-costs and CO2 equivalents (50% up to 80 %) a pair. It is concluded that BATA can lower the Eco-costs and CO2 equivalents of the 4 analyzed shoes by introducing (more) BATA recycling plants and/or by replacing PU, PVC and EVA. Besides, BATA is advised to encourage local production, to introduce (more) recycled packaging material and to lower the energy consumption during production. Finally, 4 general design guidelines for sustainable footwear are formulated: (1)design light weight, (2)extend service life, (3)replace materials and (4)design for disassembly. To further institutionalize environmental accomplishments, BATA is advised to create their own digital tool that links product specifications and LCI values. With this tool, BATA designers can check the Eco-costs or CO2 equivalent of their design within 10 minutes. BATA management can use the tool to measure environmental progress. In the second section of this study is tested which graphical and textual elements of a sustainable BATA shoe advertisement result in an optimal consumer evaluation of the BATA brand and the sustainable BATA products. The following elements are chosen as independent variables: (1)layout: a green layout versus a red layout, (2)benefit: emphasizing a personal benefit versus an environmental benefit and (3)heritage: emphasizing BATA’s local heritage versus BATA’s global heritage. The independent variables are translated into 8 simple advertisements. The experiment is carried out by means of an online questionnaire which is completed by 200 respondents, mainly second year Industrial Design Engineering students from the Delft University of Technology. The respondents were almost evenly divided over the 8 different advertisements. The results show that the green layout in combination with the personal benefit “foot health” has a positive impact on the buying intention. However, the green layout results in a lower perception of brand’s quality image and has no effect on the perception of brand’s and product’s sustainability. Emphasizing the personal benefit ‘foot health’ also leads to a more positive evaluation of the product’s healthiness, durability and fashion image. Finally, emphasizing the personal benefit “foot health” leads to a more positive perception of brand’s social responsibility. Advised is to focus the BATA communication on a benefit for the individual consumer and link that to a benefit for the environment. Consequently, the design of sustainable BATA products is advised to contain one or more (additional) benefits for the individual consumer. It is also recommended to use the colour green in a very basic way in sustainable BATA advertisements, only for recognition and/or comprehension, and preferably in combination with ‘foot health’ as personal benefit. In the last section of this study, earlier formulated guidelines for the design and communication of sustainable footwear are translated into concrete ideas and concepts. Primarily ideas are generated as broad as possible, and vary from statement shoes (e.g shoes that are visibly made from used car tires) to technological shoes (e.g. shoes that consist of air). In order to narrow the design scope, one category of shoes is chosen as focus area: women dress shoes. Two concepts are developed. Concept 1 (Transparent & Traditional) primarily focuses on the use of environmentally preferred materials combined with the consumer benefit “foot health”. The concept makes use of the materials leather, bamboo, natural rubber, cork and wood. The construction and production of the concept are conventional. The matching communication strategy includes 3 phases: (1)Attract the customer by means of a transparent (PLA) shoe box, (2) surprise the customer by a barcode on the packaging and (3) inform the customer by means of a smartphone application. Concept 2 (Create & Recycle) primarily focuses on design for disassembly combined with the consumer benefits “customizing” and “repairing”. The construction of concept 2 is based on the principle that biodegradable and recyclable parts can easily be separated: the upper is made of biodegradable (breathable and deformable) materials while the outsole is made of recyclable (durable) materials. The matching communication strategy makes use of a “BATA recycling wall” in BATA shops. Customers can choose the parts they like and derive them from different drawers in the BATA recycling wall before assembling their own shoe. Besides, customers can dispose the used shoes in separate recycling bins that are also a part of the BATA recycling wall. In doing so, customers are able to (1) customize their shoe and (2) repair their shoe. The Eco-costs of both concepts are less than half as much as the Eco-costs of a conventional women dress shoe. Concept 2 is chosen for further development because this concept allows more design freedom and is more suitable for communicating a sustainable design vision. With concept 2, BATA can show that they are thinking about the shoe of tomorrow, a shoe which parts are no longer owned but rented by customers and returned to BATA after usage. Since concept 2 requires customer involvement, customers will very consciously notice the sustainable characteristics of the BATA footwear and will consequently associate the BATA brand with sustainability.","Bata; sustainability; footwear; life cycle analysis","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design for sustainability","","","",""
"uuid:68771b79-3b91-4ea1-815b-c76ccc5494b3","http://resolver.tudelft.nl/uuid:68771b79-3b91-4ea1-815b-c76ccc5494b3","Separating convection from diffusion in a model of dispersion in fluid injection in forward flow","Bouman, L.S.","Rossen, W.R. (mentor)","2012","Recent research (John et al., 2008) has shown that the usual way of measuring dispersion in flow through permeable layers doesn’t distinguish between dispersion caused by convective spreading and mixing. Dispersion is used to mean both the variation of arrival times of material at a well and the molecular mixing of components in a reservoir. John et al used flow reversal to distinguish between the two, and quantified dispersion using particle-tracking. To make it more clear, in this thesis the case with convection and diffusion is called “diffusion”, and the case with convective-flow only is called “convective-flow”. Comparing results of forward movement with the results of flow-reversing allows one to distinguish the effects of convection alone from convection and diffusion. John et al. came to the conclusion that the difference can be seen only in flow-reversal. They compared the positions of “diffusion” particles and the mean of the positions of the “convective-flow” particles. This is possible in a computer simulation, where diffusion can be excluded from the process. Part of the difficulty in distinguishing between convection and diffusion arises because convection alone gives rise to a variation of particle positions that on the large scale looks scattered and random. On the small scale the convection particles trace a surface that is deterministic, based on the distribution of permeability in the medium. We test whether it is possible to distinguish convection from diffusion if one compares the positions of ""diffusion"" particles to the surface of “convective-flow” particles rather than the mean position of the convective-flow particles. If such a difference could be found it would give more insight in the movement of particles during forward movement. To achieve this, one would have to interpolate the convection surface between the “convective-flow” particles. This was done in Matlab and the features of this surface were closely examined. I conclude that the amount of data (number of particles) was not sufficient to give an accurate representation of the features of this surface. Unfortunately I conclude that, with this amount of data, one cannot distinguish quantitatively between convection and diffusion in forward flow, because more data are needed to make a representative surface for the convection particles. The idea of plotting a surface to give a more accurate difference between diffusion and convection might in principle still work. To find out if it would really work, a larger amount of particles is needed to represent the convection surface.","dispersion; flow reversal; convection; diffusion","en","bachelor thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Section Petroleum Engineering","",""
"uuid:6e3785f7-ebca-4e9f-afcf-f2d044058d48","http://resolver.tudelft.nl/uuid:6e3785f7-ebca-4e9f-afcf-f2d044058d48","Modulation of Contra-lateral Wrist Joint Impedance","Jain, N.","Van der Helm, F.C.T. (mentor); De Vlugt, E. (mentor)","2012","This study sought to find evidence of bimanual coordination in human wrist joint movements, by exploring a phenomenon known as motor irradiation. Subjects were made to perform a force task with their right hand, while the left hand was kept dormant. Torque and position data was collected from both hands, and used to find interlimb coupling during the force task.","bimanual coordination; motor irradiation; neuromuscular control; biomechanics","en","master thesis","","","","","","","","2012-10-03","Mechanical, Maritime and Materials Engineering","BioMechanical Engineering","","BMD","",""
"uuid:56f1aef6-f337-4224-a44e-8314e9efbe83","http://resolver.tudelft.nl/uuid:56f1aef6-f337-4224-a44e-8314e9efbe83","Development and validation of a real time pumping kite model","Ruppert, M.B.","Ockels, W.J. (mentor); Schmehl, R. (mentor); Bierbooms, W.A.A.M. (mentor); van der Vlugt, R. (mentor)","2012","A pumping kite system is a new innovative way to generate sustainable energy. A large kite is used to generate a pulling force which is transmitted to the ground by a tether. The tether is reeled off a drum that is connected to a generator. When the tether is completely unwound the kite is controlled in such a way it hovers down like a parachute, with almost no traction force, and the tether is reeled-in. This results in a cycle which produces a net amount of energy. Currently multiple institutes and companies are investigating and developing such pumping kite systems, including the ASSET institute at the TU Delft. A simple, realistic and fast kite model is essential during the development of these systems. Such a model could be used for: estimation of the power production, structural optimization, trajectory optimization and for example autopilot development. This thesis describes the development of a realistic real time capable pumping kite model. Initially a literature study gives an overview of the current models available in literature. It explains the advantages and shortcomings of the different approaches. Main shortcoming of most kite models is their limited validation. As a result their accuracy is unknown. Secondary, the measurement data of a 20kW prototype, which has been developed by the ASSET kite group, is used in an extensive data analysis and system identification. The general dynamics are described and multiple relevant phenomena are found. Especially the rotation of the kite has been studied. An useful relation is found which couples the rotation of the kite to the steer input and the side slip angle (or gravitational vector). This relation originates from a moment study of the kite on a quasi-static basis and corresponds with measurement data. Further the sagging of the tether due to tether drag and pod dynamics has been studied. Relatively small sag angles of 0-150 are found during regular flights and a characteristic pattern indicates that especially the pod dynamics play a role in the flight dynamics. Finally the aerodynamic forces acting on the kite have been studied and coefficients needed for an aerodynamic force model have been fitted to the measurement data. It is concluded, based on the literature study and data analysis, that a semi-rigid body modelling approach is most suited. The semi-rigid body model simulated the kite as a point mass with one additional degree of freedom, namely the rotation of the kite around the tether (yawing of the kite). The pitch angle of the kite, which is adjustable in the real system, is incorporated in the model by a variable constrain instead of an additional degree of freedom. The semi-rigid body kite model proves to be a simple and computer efficient model. The kite model is connected to two different tether models. A single spring-damper tether model which simulates the tether as straight and a discretised point mass model which is able to simulate the dynamics of the tether and pod. The kite model with both tether models have been validated by comparing the models to measurement data. Both models seem to realistically simulate the current kite system. The model with a straight spring damper tether model runs approximately 7x real time1 and correctly simulates all variables except the sag of the tether. The discretised tether model simulates these effect correctly but at the cost of simulation speed. Currently it runs approximately 0.5x real time. The discretised model additionally shows more realistic behaviour during non-normal flight conditions.","","en","master thesis","","","","","","","","","Aerospace Engineering","Aerodynamics & Wind Energy","","","",""
"uuid:bf12bb63-9b88-4f8d-b971-af34b62b6015","http://resolver.tudelft.nl/uuid:bf12bb63-9b88-4f8d-b971-af34b62b6015","Fostering the reuse of knowledge in project based organizations","Anninos, P.","Verbraeck, A. (mentor); Lukosch, S. (mentor); Groenleer, M. (mentor); Pegels, V. (mentor); Buttler, T. (mentor)","2012","In the contemporary business world, more and more organizations especially in the engineering domain structure their working processes around projects. These organizations are called project-based-organizations (PBOs) and have established distinct work processes to successfully execute the projects that they undertake. The working processes in the early phases of a project are quite important in adding value to the project, and are called Front End Development (FED) of projects. Knowledge Management is a practice that adds value in FED of projects, since knowledge is an important resource that provides PBOs with competitive advantage to survive in harsh competition. A knowledge management strategy to achieve learning across projects, is codification; converting tacit knowledge from people’s minds, to explicit knowledge in documents. In a strife to increase value in their projects, PBOs are looking for ways to improve reuse of explicit knowledge in the FED of their projects: a practical problem. From a scientific point of view, a clear scientific mapping of the factors that support or hinder explicit knowledge reuse in the FED of projects, and what such a mapping entails for a strategy to foster reuse of explicit knowledge in PBOs in the engineering domain is not present yet. Therefore the main research question for this research is: What factors support or hinder explicit knowledge reuse in the front end development of projects, and how can project based organizations in the engineering domain exploit them aiming to improve value in projects during their front end development? The selected approach in this research for improving reuse of explicit knowledge, is the identification and categorization of the factors that support or hinder reuse of explicit knowledge, and their respective exploitation. The design science research framework is used to guide this research approach: exploration of the environment, development & evaluation of the designed artifact, and contribution to the knowledge base. The environment of the present research is the Technology department of Heerema Marine Contractors. To manage the research process, the principles of process management are adopted; create an open and safe decision making process during the research.","knowledge reuse; knowledge management; project based organizations; Front End Development of projects; Heerema Marine Contractors","en","master thesis","","","","","","","","","Technology, Policy and Management","Systems Engineering","","Management of Technology","",""
"uuid:a0c38255-7287-4a50-8970-58c943422fbc","http://resolver.tudelft.nl/uuid:a0c38255-7287-4a50-8970-58c943422fbc","System Identification of the Brake Setup in the TU Delft Vehicle Test Lab","Busselaar, J.P.","De Vries, E.J.H. (mentor)","2012","Testing facilities such as the TU Delft Vehicle Test Lab (VTL) are needed to provide necessary experimental data to validate and to compare the performance of several ABS controllers like the Feed-Forward Braking controller. Before testing ABS controllers with the VTL measurement system, it needs to be improved first. Earlier measurements reported in [11] showed a lack of developed braking torque due to decreased bandwidth of the measurement setup. This problem could be within the hydraulic brake line of the VTL measurement setup. Pressure dynamics results of the original situation show a significant decrease when increasing the actuating frequency. Differences in pressure dynamics are examined by replacing the original brake hose with a stainless steel braided brake hose. Sinus wave excitation measurements show a relative small increase of the maximal reaching brake pressure with the design improvements situation. Random noise excitation measurements show increased bandwidth, compared to the frequency results reported in [4] and [11]. Improvements in brake pressure dynamics are realized by using a stainless steel braided brake hose in addition with relative low varying amplitudes.","ABS","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Precision and Microsystems Engineering","","","",""
"uuid:1ad323b5-da4c-48b7-8566-4434ab044dce","http://resolver.tudelft.nl/uuid:1ad323b5-da4c-48b7-8566-4434ab044dce","Capturing Transient Effects in Turbulent Flows with Passive Scalars over Urban Areas with Hybrid LES/T-RANS Approaches","De Wildt, S.","Kenjeres, S. (mentor)","2012","","","en","master thesis","","","","","","","","","Applied Sciences","Kramers Laboratorium voor Fysische Technologie","","","",""
"uuid:c79da8ce-f885-4241-b745-4d81d7850049","http://resolver.tudelft.nl/uuid:c79da8ce-f885-4241-b745-4d81d7850049","Analysis of Switching Transient Overvoltage in the Power System of Floating Production Storage and Offloading Vessel","Xue, H.","Popov, M. (mentor)","2012","Large transient overvoltages can be caused by the switching operation of vacuum circuit breakers of induction motors. In order to analyze the switching transient overvoltage and use an appropriate protective method in the power system of floating production storage and offloading (FPSO) vessel, the accurate models of electrical equipments are necessary. In this study, vacuum circuit breakers, generators, cables, busbars, surge arresters and induction motors are modeled in Alternative Transient Program-Electromagnetic Transients Program (ATP-EMTP) software. The switching transient overvoltages of four typical induction motors under the starting, the full load and the light load working conditions in the power system of the selected FPSO vessel are analyzed. A suitable protection against the switching transient overvoltage is included in this study.","switching transient overvoltage; ATP-EMTP; FPSO; VCB; cable; induction motors; surge arrester; protection","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Electrical Sustainable Energy","","Electrical Power Engineering","",""
"uuid:93e4298f-0ccd-45b1-978a-1dc81a8b94ab","http://resolver.tudelft.nl/uuid:93e4298f-0ccd-45b1-978a-1dc81a8b94ab","How to Preserve Historic Districts in Harbin: A Study in Transplanting European Experiences","Liu, X.","De Jong, M. (mentor); Ravesteijn, W. (mentor); Mi, J. (mentor)","2012","Historic preservation is always a hot topic in contemporary city development. The heritage witnessed how human life evolved and how the city developed. The high historical value assembles the city’s spirit and it brings to the human a sense of belonging. However, with urbanization and modernization, the heritages are easily under the risks of being damaged. Since 1980s, China started to pay attention on heritage preservation. The historic buildings, sites and historic cities are continuously added into the preservation objectives. Harbin city is a Chinese city with influences of western culture in its architecture due to its history. The government took actions to preserve these heritages since late 1980s. But facing countless historic remaining, the process of historic preservation planning has many problems which lead to a dissatisfaction of Harbin city. So far, there are 22 legally listed historic cultural districts. Based on their functions, they are divided into 5 types. The three districts having the most problems regarding preservation are covered in this research while the other two with better conditions are left for further study. The main difficulties in historic preservation are stated to provide sufficient knowledge on what is happening in Harbin, namely the decay of historic cultural value, the extensive influence of the government and commercial developers over other actors, and the lack of funding on preservation projects. In order to improve the historic preservation planning system for Harbin, the research deeps into the current situation of Harbin and analyzes two European cases in order to draw lessons. Three main parts in the body of the analysis are inspiration phase, learning phase and the transplantation phase. The inspiration phase contains the current situation and the case introductions, the learning phase contains the case analysis and the transplantation phase is focusing on transferring the merits from cases to Harbin. Five aspects are found to be essential in historic preservation. These are guidance of operation, public participation, supervision in process, coordination with other organizations and money source. The activities of these aspects are discussed in the case studies. And in order to improve the historic preservation planning system in Harbin, together with the local situation and resources, this research recommends five mechanisms. According to Richard Rose’s theories on the alternatives of treating lessons learning, they are adapted to increase the suitability and effectiveness: The research suggests that the experts should come up with a clear and detailed operating guidance for the operators in real work. The public’s involvement and other organizations should be encouraged and stimulated to coordinate in the preserving process. The funding problem can be solved by getting support from central government and the society including rich groups and donations. The mass media should monitor the process in order to ensure the fairness of the process.","historic preservation; lesson-drawing","en","master thesis","","","","","","","","2012-08-17","Technology, Policy and Management","Multi Actor Systems","","Policy, Organisation, Law and Gaming","",""
"uuid:b0e662d2-ee02-47f7-bb06-7cb93d361836","http://resolver.tudelft.nl/uuid:b0e662d2-ee02-47f7-bb06-7cb93d361836","Barriers to commercialize nanotechnology product innovation and the strategies to overcome the barriers","Sharma, J.","Ortt, R. (mentor); Cunningham, S. (mentor)","2012","Nanotechnology has drawn a substantial amount of attention from policy makers and companies all across the globe. This research-intensive field is relatively in its early stages of commercialization. A plethora of large corporations and small-medium enterprises (SMEs) exists in different industries which harness nanotechnology to develop innovative products. A vast sum of money continues to be invested by governments all across the globe to accelerate the commercialization efforts for bringing innovative nanotechnology products to the market. However, the commercialization of such products is hindered by a variety of barriers. This research takes a closer look at product innovation springing from the SMEs in the field of nanotechnology. In this research, following central questions have been investigated: 1. What barriers are faced by SMEs during the commercialization of nanotechnology product innovation? 2. And, how do SMEs overcome the barriers? Qualitative research is adopted to answer these questions. Multiple case study method is used to investigate the topic. Literature study on barriers to innovation, desk research on the cases and semi-structured interviews have been conducted to fully answer the questions. The research contributes to the existing body of literature in barriers by finding out new barriers in the cases. Further, empirical based strategies devised in the research holds managerial implications both for the companies and policy makers. A new framework is built for the categorisation of barriers based on a simplified market model of a firm. Four broad categories of barriers namely technology-related, firm-related, environmental, and market characteristics have been defined. These categories are further sub-divided into several ones. The framework is further used to categorise the barriers found in the cases. This categorisation further helped in formulating strategies to deal with these barriers. Concerning the barriers, the research reveals that the cases are heavily hit by firm-related barriers. It is followed by technology related-barriers, environmental barriers and market-characteristic barriers. The strategies adopted by the companies to overcome the barriers were influenced by the context in which the product innovation was commercialised. Generic strategies that came out of the research can be broadly seen as that of either improving or circumventing the barrier, or leaving the barrier unaddressed.","barriers; commercialisation; nanotechnology; SME; product innovation","en","master thesis","","","","","","","","2013-12-31","Technology, Policy and Management","Innovation Systems","","Management of Technology","",""
"uuid:46217f6e-20f2-47fa-a622-42f7a9b79759","http://resolver.tudelft.nl/uuid:46217f6e-20f2-47fa-a622-42f7a9b79759","Bayesian network applications in traffic prediction and traffic load in bridges in the Netherlands","Si, L.","Napoles Oswaldo, M. (mentor)","2012","Traffic loads is an important factor in assessing the reliability of infrastructures. The gravity causes the pressure to the bridge deck when traffic pass by, which further leads to a hidden danger to bridge safety. Besides the prediction of traffic situation is valuable not only for bridge safety valuation, but also for travelers, since it can help drivers to arrange the route and road managers to execute traffic controls. Therefore, an accurate model for measuring and prediction is necessary. In this thesis, Continuous Non-parametric Bayesian Networks (CNBNs) are employed to investigate the dependence relations and the predictability of target variables. Two case studies are conducted on the basis of simulated data for “Traffic Loads in Bridges” project. The BN structure is learned from data. Three copula testing methods are applied to evaluate the Gaussian copula assumption. The BN model with mixed Normal margins is able to predict better than the model with Normal margins when conditionalizing on out of sample values. We propose three models for traffic prediction purpose. The Naive model turns out to predict the best with prediction time horizon below 20 minutes. When the prediction time horizon falls in [20, 40] minutes, the BN model presents an approximate accuracy of 90%-95%. The Historical model is a good choice for longer prediction time horizon prediction. The results of traffic loads project can be used for bridge safety assessment. And the traffic speed prediction can provide information to travel time prediction for dynamic routing.","Bayesian network; Copula","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","Risk and Environmental Modelling","",""
"uuid:43c18f6c-8c8b-45b9-b9fd-80d10a69f6fd","http://resolver.tudelft.nl/uuid:43c18f6c-8c8b-45b9-b9fd-80d10a69f6fd","Growing with the grower: Developing a mid segment solution for Priva's horticulture business","Van Dijk, J.","Buijs, J.A. (mentor); Dehli, S.R. (mentor); Ray, N.P. (mentor)","2012","Within horticulture, Priva is serving the top of the market with high quality, reliable, but also expensive solutions for process automation. Below this top of the pyramid, there is a big market that has a lot of potential. It is called the mid segment and requires cheaper and more basic solutions for automation. It has a lot of opportunities but also challenges for Priva. The purpose of this project was to explore this market, and develop a concept for a suitable product-service combination. First, a theoretical framework was made based on a literature review. After an internal analysis of Priva and an external analysis of the market context, a new solution for the mid segment was developed in the synthesis phase. The solution that was developed is called Grow, which is based on the concept of growing with the grower. This product-service combination provides sustainable competitive advantage for Priva. It takes care of the entire customer experience, and creates a new meaning of the product. The system uses wireless technology to connect the modules in the field. The Grow station is ‘plug-and-play’, making it easy to install and maintain. Using the product, growers can save valuable resources which become increasingly scarce. They can optimize the quality and quantity of their yields, and generate income to invest into Grow again. The modular system allows a flexible solution for a nonhomogeneous market, at a competing price. The mid segment requires a radically different approach than the high segment. The old ways of working cannot simply be copied, because the market is really different. Furthermore Priva’s current business model of software distribution will expire in the coming years. Grow takes a first step in creating a new business model, where hardware and software sales are separated. Software modules can be downloaded like apps, and the interoperable hardware modules can be installed by dealers and installers with basic technical knowledge. For them Grow allows easy, remote, service and offers opportunities to grow their business. Because of the online service, there is more direct contact between Priva and the end user, creating customer loyalty. Revenue will be created by a higher volume of smaller transactions. When developing an innovative product-service combination like this, there is a lot to explore. Stakeholders should be involved early in the development process. Development partners should be attracted to co-create with. There is further research needed into the market and the technology. This concept is a first, but absolutely necessary step towards horticultural automation of the future, with cloud technology and wireless networks. Priva has to invest now in creating this for the mid segment, to build competencies that help to create sustainable strategic advantages in the high segment of the future.","strategic product design; horticulture; visualisation; market analysis; company analysis; innovation strategy","en","master thesis","","","","","","","Campus only","2013-08-17","Industrial Design Engineering","Product Innovation Management","","Strategic Product Design","",""
"uuid:22b1f465-87f1-4748-9c8e-0ef8e9bd9751","http://resolver.tudelft.nl/uuid:22b1f465-87f1-4748-9c8e-0ef8e9bd9751","Human Resource Capacity Planning in a Multi-Program Environment: A case study in the German automotive manufacturing industry","Nieling, V.I.","Van Beers, C. (mentor); Mooi, H. (mentor); Filippov, S. (mentor); Kolfschoten, G. (mentor)","2012","","HR capacity; capacity planning; multi-program; process master plan","en","master thesis","","","","","","","","2015-08-17","Technology, Policy and Management","Technology, Strategy and Entrepreneurship","","Management of Technology","",""
"uuid:e4f09167-a76d-4f36-b042-2b0b13fd336b","http://resolver.tudelft.nl/uuid:e4f09167-a76d-4f36-b042-2b0b13fd336b","A Future Workstation environment concept","Minkes, R.","Vink, P. (mentor); Moor, P. (mentor); Lensvelt, H. (mentor)","2012","Lensvelt the company has always been progressive in its market. It aims to produce products that have great aesthetic value and work well. Its products are made by well-known and established designers. On the market Lensvelt is in, however, a lot of copying and stealing takes place, and successful, original products do not stay original for long. To make a product of the future, it seems obvious to use a method of the future to design it. By using next-generation designing tools, it is easier to produce products which strife to be next-generation. One of this next generation design method is generative modelling. Generative models have great potential to make a product more user specific. It can be used for customized designs, and has easily understandable inputs to control aesthetics and dimensions. To produce a lot of different physical models, in a short amount of time, requires a fluent integration with the rest of the production process. The future workstation environment concept fulfils the criteria of a future workstation. The Rise table and Tube table for 4 are developed further than the other parts of the total concept, mainly because these are of the greatest interest for the company, and there is the budget to develop them further. The Rise table is made as a prototype. For the others, the developments to create prototypes are started.","office; furniture; workstation; environment; concept","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Master of Science Integrated Product Design","",""
"uuid:ee35f437-5c5f-4df3-b363-ca87c4e2f782","http://resolver.tudelft.nl/uuid:ee35f437-5c5f-4df3-b363-ca87c4e2f782","Physical model tests of the notional permeability on breakwaters","Kluwen, J.G.M.","Van den Bos, J.P. (mentor); Verhagen, H.J. (mentor); Uijttewaal, W.S.J. (mentor); Van der Meer, J.W. (mentor); Maertens, J. (mentor)","2012","Breakwaters are important objects to protect coastal- and harbour areas. To minimalize the probability of failure of breakwaters, a lot of research has been conducted concerning the stability of breakwaters. After Iribarren and Hudson, an influential research is conducted by Van der Meer. The literature research of this report will provide more background information concerning their researches on the stability of breakwaters. Van der Meer tested three sorts of breakwater constructions. The first breakwater structure contained a homogeneous construction (P=0.6) The second and third structure consisted of respectively a construction with impermeable core (P=0.1) and a structure with a filter layer and a permeable core (P=0.5). These variants of breakwaters were constructed with different slopes angles to require as much information possible concerning the stability of breakwaters. Van der Meer discovered two formulas for the stability of breakwaters. The first formula is used for plunging waves while the second formula is used for surging waves.Within these formulas, important factors as damage, wave height and notional permeability are included. The most important parameter of the formulas of Van der Meer is the notional permeability factor P. Van der Meer conducted his research on three different constructions and has designed a fourth construction based on the stability curves. This fourth construction has a value of permeability of 0.4. This value is estimated based on curve fitting. Following the research done by Van der Meer, Kik has subsequently researched the notional permeability of three breakwater constructions. Firstly, Kik repeated the test with a construction of impermeable core (model 1/P=0.08) and the test with the construction of filter layer and permeable core (model 2/ P=0.05) of Van der Meer. Lastly, Kik did a third test existing of a variant of the design of the fourth construction of Van der Meer (model 3 / P=0.35). Concluding from his research, Kik stated that the ‘Root mean square equation’ is a reliable method to determine the notional permeability P. During this research the influence of the thickness of the filter layer on the notional permeability P is studied. This research will also try to answer the question whether other relevant aspects might influence the notional permeability as well. The elaboration of this research is performed in a practical way in a wave flume in the water laboratory of the faculty of civil engineering of the TU Delft. Scale models of the breakwaters were constructed to test the notional permeability of the breakwaters. In the water laboratory three models were tested. Firstly, model 3 of Kik is repeated as model 3A, with a calculated value of notional permeability P 0.38. The construction of model 3A is build with a top layer, filter layer 1, filter layer 2 and a impermeable core. Second, another variant of model 3 of Kik is designed and tested (model 4). However, the measured damage figures were too low and therefore they could not be used to calculate a value for the notional permeability P. The construction of model four is build with a top layer, filter layer 1, filter layer 2 which is thicker as model 3A and an impermeable core. Finally, model 5 is tested with a calculated value of notional permeability of P 0.45. This model is designed from the fourth construction of Van der Meer. The construction of model 5 is build with a top layer, filter layer 1 and a permeable core with the same material of filter layer 2 of model 3A and model 4. The results of this research show that the influences of the notional permeability P exists of the ratio of the armour layer thickness and the thickness of the second filter layer. If the layer thicknesses are equal the value for notional permeability P is 0.38, which follows from model 3A. If the second layer has an infinite thickness (permeable core), the value for notional permeability P is 0.45, which follows from model 5. The value of the notional permeability P of model 5 corresponds to the design calculations of the computer model HADEER. Van der Meer discovered using this computer model that the ratio of dn50a/ dn50f = 5 has a value on the notional permeability P of 0.43 –0.44. During this research, while using two different methods, a value of the notional permeability P of 0.45 was calculated.","breakwaters; notional permeability P; Van der Meer","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Hydraulic Engineering","","coastal engineering","",""
"uuid:eb7045ea-152f-40c0-a24a-5a5a37724f11","http://resolver.tudelft.nl/uuid:eb7045ea-152f-40c0-a24a-5a5a37724f11","Improving exterior customization in super yacht design at AMELS Holland B.V.","Roes, J.A.","Tempelman, E. (mentor); Grondelle, E. (mentor)","2012","This master thesis concentrated on the process of designing an exterior customization concept for standardized super yachts. It was executed for the Dutch yard AMELS Holland B.V Currently AMELS builds semi-custom yachts, which is a compromise compared to custom yacht building. In custom yacht building the client can decide about design, layout and technical requirements. In semi-custom super yachts, the exterior is standard and the interior can be customized by a yacht architect, based on a standardized layout. The exterior design is already defined when a client is not involved in the project yet. In the future of large yacht building it is expected that more customization is asked. The AMELS portfolio shows a large visual overlap between the yachts and is expanding towards larger yachts. Therefore the largest yacht from their fleet was chosen for customization. To be able to assess which items determine yacht exteriors, an evaluation model was developed. It is an adapted version of the automotive form hierarchy model (Grondelle and Van Dijk, 2004) and was used to qualitatively evaluate yacht exteriors. It resulted in a set of styling items which had impact on exterior aesthetics. Technical analysis on the building process and on the current AMELS 242 showed interferences between shaping components, technical systems and construction. Therefore an upgraded platform was developed. In the platform the shaping components were separated from the technical systems and construction. Next to the grey items, it is now possible to customize the form language layer (green items). When AMELS maintains the delivery time and competitive pricing, and there is no reason to assume they will not, a great advantage is created. Built on the core values of the company and the proven quality of the platform, clients are now able to involve their own designers in order to create a custom interior and exterior.","yacht design; industrial design; aesthetics","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Master specialisation Automotive","",""
"uuid:610a8924-46b3-4c53-9fec-53463b28a9ff","http://resolver.tudelft.nl/uuid:610a8924-46b3-4c53-9fec-53463b28a9ff","Evaluating the Quality of Opponent Models in Automated Bilateral Negotiations","Hendrikx, M.J.C.","Baarslag, T. (mentor); Hindriks, K.V. (mentor); Jonker, C.M. (mentor)","2012","Automated negotiation agents are agents that interact in an environment for the settlement of a mutual concern. An important factor influencing the performance of a negotiation agent is how it takes the opponent into account. The main challenge in this aspect, is that opponents typically hide private information to avoid exploitation. In such a setting, an opponent model can help by estimating the opponent's strategy or preference profile. This work contains the first recent survey of opponent models in automated negotiation. One of the main conclusions of this survey, is that currently there is no fair method to evaluate and compare the quality of a set of opponent models. Insight in the quality of an opponent model could lead to the development of a better model. In this work we focus on a specific type of opponent models which model the opponent's preferences. Based on a detailed analysis of the factors influencing the quality of this type of opponent model, we introduce and apply two fair measurement methods to quantify the performance gain relative to not using an opponent model and the accuracy of the model. Our contribution to the field of automated negotiation is threefold; first, we provide a comprehensive survey of opponent models; second, we introduce a method to isolate the components of a negotiation strategy; finally, we construct and apply two fair evaluation methods to quantify the quality of a set of opponent models which model the opponent's preferences. Taken together, this work structures the field of opponent models and provides insight in how to improve existing models.","negotiation; software agents; opponent models; opponent modeling; machine learning","en","master thesis","","","","","","","","2012-08-17","Electrical Engineering, Mathematics and Computer Science","Computer science","","Media knowledge engineering","",""
"uuid:fd3bedc7-b724-432e-b633-dee4e15a4c68","http://resolver.tudelft.nl/uuid:fd3bedc7-b724-432e-b633-dee4e15a4c68","Relative Density Differences of a Sand Fill","Vessies, W.C.N.","Van Rhee, C. (mentor); Van der Schrieck, G.L.M. (mentor); Van Gelder, P.H.A.J.M. (mentor)","2012","The Maasvlakte II project is a joint venture between Boskalis and Van Oord. During the construction, they have measured the relative density for different kind of work methods, by making cone penetration tests. The result of those measurement is, that the measured relative density for the Maasvlakte II project is higher than the values that can be found in literature for the different kind of work methods. Thus the objective of this MSc-thesis is to understand the influencing and determining processes for the relative density of dumped or sprayed sand underwater. This MSc-thesis can be divided in four parts. The first part describes the characteristics of sand and the relation between the density and the relative density. Laboratory testing is executed to determine the relevant parameters of the sand, such as the minimum and maximum density and the particle size distribution. The second part describes the used work methods, such as dumping, rainbowing, back filling through the suction pipe and spraying with a spray pontoon, that are used by the construction of the Maasvlakte II project. The third part describes the analysis of the CPT data. The CPT data is linked to the work methods and the relative density based on the correlations of Baldi and Lunne and Christoffersen. Also, a statistical analysis is made. The statistical analysis is based upon different kinds of statistical tests, such as Kruskal-Wallis and Wilcoxon Rank Sum Test. The last part consist of physical hypotheses that explain the potential influencing and determining processes for the relative density of dumped and sprayed sand underwater. The work methods used for the hydraulic placement, the discharge conditions, the layer thickness, the water depth and the soil properties of the borrow area are all important in the achieved relative densities. From statistical testing, with the Kruskal-Wallis and Wilcoxon Rank Sum Test, the used work method has an influence on the achieved relative density.","dredging; sand fill; hydraulic reclamation; cone penetration test; relative density; sand; shear stress; shields parameter; Kruskal-Wallis Test; Wilcoxon Rank Sum Test","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Hydraulic Engineering","","","",""
"uuid:463c73bd-2b68-47a9-b99e-cef662946bce","http://resolver.tudelft.nl/uuid:463c73bd-2b68-47a9-b99e-cef662946bce","Improved static data-flow model for TDM scheduler","Butala, K.R.","Cotofana, S.D. (mentor); Molnos, A.M. (mentor)","2012","A streaming application like software defined radio (SDR) executed on a heterogeneous multi-processor system on chip (MPSoC) consists of various transceiver jobs that have to be scheduled on different processors concurrently. The hard real time performance requirements of these jobs can be guaranteed on the multi-processor system on chip (MPSoC) using a Time Division Multiplexing (TDM) scheduler for each processor. The TDM scheduler allocates a fixed amount of time slot for each job and removes the timing inter-dependence between the concurrently executing jobs. In order to guarantee that a job scheduled using a TDM scheduler would meet its deadlines, temporal analysis can be performed by modelling an application as a data-flow graph, called as an application graph. Scheduling framework maps nodes of the data-flow graph, called actors, on to the processors. It generates a schedule or an order in which actors of an application can execute on a processor. This order is called a static order. Data-flow model for a TDM scheduler is a timed data-flow graph which uses the TDM scheduler settings to predict worst case finish times of a job scheduled on a TDM scheduler. Using this mapping information and a data-flow model, an analysis graph is obtained from the application graph by replacing each application actor by a data-flow model and is analysed for its temporal behaviour. Various such data-flow models, e.g., the latency rate model, are proposed in the literature, but they over-estimate the worst case finish time of an application. This over-estimation causes over-allocation of resources on the processor. In this thesis, we propose a data-flow model based on multi-rate data flow (MRDF) graph, called as a multi-rate model, that is conservative and more accurate than the existing models. We provide a detailed analysis of the multi-rate model and prove that the model is conservative. We also show that the multi-rate model provides worst case finish times that are more accurate than existing models like the latency rate model. We implemented the multi-rate model, simulation of the TDM behaviour and techniques to reduce the utilizations of the processors on an existing data-flow analysis tool developed at ST Ericsson. We used our implementation to study the impact of improved accuracy in the estimation of the finish times of the application tasks due to the multi-rate model. The reductions in the processor utilization obtained using the multi-rate model were found to be better than the latency rate model and in some cases, better than the simulation technique. The experimental results show that the improved modelling accuracy helped us to achieve up to 40\% reduction in the utilization of a processor, over the latency rate model based method for a WLAN application. Thus, the multi-rate model is a more accurate model for the analysis of the TDM scheduler arbitration as compared to the state-of-the-art.","real-time; multi-processor; scheduler; time division multiplexed (TDM); data-flow graphs","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","Embedded Systems","",""
"uuid:005bcd14-474c-4a70-9691-a63ce1207ac5","http://resolver.tudelft.nl/uuid:005bcd14-474c-4a70-9691-a63ce1207ac5","From Necessity to Fun: Implementing User Centered Design and Brand Driven Innovation at a business to business software provider","Sosinowska, A.","Buijs, J.A. (mentor); Van der Meer, J.D. (mentor)","2012","For almost all companies it is very obvious that in order to survive and grow they need to innovate, whether the innovation concerns their product, market or the way they do things. The paradox of innovation is that on one hand the companies want to innovate (since they know it is necessary) on the other they want to do things they are used to do and naturally prefer to relay on the safe recipes that worked in the past. Since the innovation process significantly differs from regular business it requires different mindset of the whole organization. Regular business is all about developing and selling one (or more) unique idea(s) and avoiding all kinds of risks, while innovation is all about out-of-the-box thinking, breaking the rules, risk taking and above of all producing ideas and throwing most of them away. The last is in general in contradiction to operational effectiveness; it is seems simply throwing money and effort away. Innovation is also stepping out of the comfort zone, what is usually associated with a painful and stressful situation since it is an unknown territory that is to been entered and it is difficult to predict what is to be expected. Organizations that are to innovate are also stepping out of their comfort zone of known routines and working recipes, often observed reaction is resistance and falling back on known routines. The innovation process should however be a fun and rewarding process in order for it to be successful. The reward should be not only in the profit the company makes or a prospect of domination on the market but also the learning process that the organization and its employees go through. For my graduation project I have chosen to introduce the approach that changed the innovation from a painful and necessary business to a fun and rewarding process at software provider for the business-to-business market. In this report of my graduation project the process of introducing different techniques of user research and creative problem solving to the company can be found. Further a proposal of a User Centered Design Toolkit meant to help the company to be able to do user research that results in gaining of a deep knowledge of the use needs as well as help the company employees to work together is shown.","Design; User Centered Design; Innovation; Brand Driven Innovation; Business to Business; Software","en","master thesis","","","","","","","Campus only","2013-08-16","Industrial Design Engineering","Industrial Design","","Master of Science Strategic Product Design","",""
"uuid:4bf469bf-4284-4610-8c81-a2641a7a8df4","http://resolver.tudelft.nl/uuid:4bf469bf-4284-4610-8c81-a2641a7a8df4","The influence of the wave height distribution on the stability of single layer concrete armour units","Zwanenburg, S.A.A.","Uijttewaal, W.S.J. (mentor); Van Vledder, G.P. (mentor); Verhagen, H.J. (mentor); Ten Oever, E. (mentor)","2012","The dimensions of single layer concrete armour units (interlocking armour units) are calculated with a similar stability relation as the stability relation for quarry stone. In these design formulas an 'average/significant' wave load is used (Hs). Since quarry stone gains its stability only from gravity, this type of armour unit is constructed in a double layer and therefore some damage development is allowed. Interlocking armour units are constructed in a single layer and the design should be based on zero damage. This research investigates whether this different approach to damage leads to a different characteristic design wave load which will increase the accuracy of the design method for interlocking armour units. It is focussed on the influence of the wave height distribution on the stability of single layer concrete armour units in general and Xbloc in particular. For Xbloc, zero damage is defined as a criterion for rocking of the armour units: during design conditions ""not more than 2% of the units are allowed to move during more than 2% of the waves"". To find a stability relation based on this criterion, the stability of Xbloc is investigated according to rocking of armour units contrary to the conventionally approach to stability based on the number of displaced units from the armour layer. To find the relation between waves and rocking, physical model tests are performed. In these tests a model breakwater is loaded by wave series with different wave height distributions, wave steepness and groupiness. It resulted that every wave has a certain probability of causing rocking of an armour unit. This probability of rocking is mainly dependent on the height of individual waves and to a lesser extent on the groupiness of the wave series. The steepness of the waves appeared to have a negligible small influence. When the found rocking probability relation is combined with the criterion for rocking, it appears that H2% is mathematically a better fitting parameter for a stability relation according to rocking. A new stability relation for Xbloc is derived based on H2%. Additionally, it is found that very extreme wave heights can dislodge an armour unit in such a way that this armour unit does not interlock anymore. Because it is undesirable that armour units do not interlock anymore, dislodgement of armour units should be accounted for in the stability calculations. Therefore, also a stability relation based on dislodgement of units is provided.","breakwater; Xbloc; armour unit; rocking; wave height distribution; wave load","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Hydraulic Engineering","","","",""
"uuid:25770055-cb5f-41d7-9a84-5a89288dae7b","http://resolver.tudelft.nl/uuid:25770055-cb5f-41d7-9a84-5a89288dae7b","Evaluation of hazard classification systems of water source, sanitation facility, and hygiene behaviour in determining drinking water safety: Systematic classification of hazard components coupled with microbial water quality analysis at sources and points of consumption in two rural sites in Thailand and Laos","Novalia, W.","Medema, G. (mentor); Van Lier, J.B. (mentor); Bakker, M. (mentor); Stenström, T.A. (mentor)","2012","Introduction: The research was performed in two rural sites in Thailand and Laos. The Diarrhea and Dengue (DIADEN) group from the Norwegian University of Life Sciences facilitated the fieldwork. In the Thai site, rainwater was the main drinking water source, whereas in Lao site, unprotected dug well was predominant in dry season and was replaced by rainwater in wet season. Drinking water was largely consumed untreated. Combined with varying sanitation service and hygiene behavior, it was assumed that the safety of drinking water might be compromised. Problem definition: The global monitoring of the MDG target to halve the population without safe drinking water access is performed by the Joint Monitoring Programme (JMP). The JMP uses technological classification (improved or unimproved sources) as monitoring indicator for water safety. This has been criticized for being inadequate in representing the actual conditions in water provision. The core argument is that drinking water quality at improved sources might not necessarily be free from pathogens. In addition, drinking water that is safe at the sources might as well be recontaminated through various water handling practices, particularly where manual collection, transport and storage are common. Thus, in this study it is proposed that the technological classification is refined through the use of a semi-quantitative hazard classification system. Research: In the first part, the research was focused on the identification and classification of the hazards found at the various water sources and the hazards related to sanitation facility and hygiene behavior. This was achieved through sanitary inspection, household questionnaire and spot observation carried out in about two weeks time. In the second part, water samples were collected twice at selected sources and household drinking containers. Samples were tested for E. coli as faecal indicator organisms, using the standard Colisure/Ouanti-tray 2000 method from IDEXX. The water quality data were then used to validate the hazard classification systems. Simultaneously, a new E. coli enumeration method, the Compartment Bag Test (CBT) by University of North Carolina, was used in parallel to investigate the comparability of the two tests. Results: 1. The first investigation found that the hazards in Laos were more severe than in Thailand. 2. Water quality of the rainwater source (improved) was variably contaminated. The unprotected dug well (unimproved) was grossly contaminated. 3. Water quality at the household containers was also variable. Overall, there was significant deterioration of water quality from sources to households that can be attributed to household water handling practices (e.g. extraction methods, cleanliness, treatment). 4. The hazard classification system for water sources in Laos was moderately correlated with water quality data and was not significantly correlated for Thailand. The sanitation and hygiene hazards were not significantly correlated in both sites. 5. The CBT data was significantly different from the Colisure/Quanti-tray 2000 data. Conclusions and recommendations: The JMP indicator overestimates water safety both at sources and at households. The hazard classification system, if refined further with weighted-scoring and long-term water quality data, might enable a more accurate representation of the actual conditions. Correlations with health impacts are also recommended. Furthermore, manual water handling practices compromises water quality and it is thus advised to eliminate hand-water contact as much as possible.","safe drinking water; indicator; hazard classification; water sources; recontamination; household containers","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Water Management","","Sanitary Engineering","",""
"uuid:c3e20dc5-b5e3-42e5-bf6e-8456babc9cb3","http://resolver.tudelft.nl/uuid:c3e20dc5-b5e3-42e5-bf6e-8456babc9cb3","Cost Model for Manufacturing of a Girder for a Wind Turbine Blade","Mehesh, D.S.V.","Boerman, A. (mentor); Bersee, H.E.N. (mentor)","2012","Wind energy has a longstanding reputation in making daily activities possible for mankind. Whereas in the past wind was used for propelling ships or for milling grain using wind mills, nowadays its market is growing towards the application of wind turbines, generating electricity in a sustainable manner. The growth in the wind energy market is more and more directed towards offshore wind. The trend here is installation of wind turbines with large rated power, leading to future turbines with rated power >5MW. For these turbines longer blades are required. Most blades are produced using glass fiber-epoxy. However, glass fiber has its limitations related to its stiffness. As the blades become larger, so does the tip deflection. In order to comply with the mechanical requirements of the blades, the usage of glass fiber is stretched to its limits and economically the usage might become less costefficient. To be still able to manufacture the larger blades, the focus is now set on a different reinforcement material: carbon fiber. Carbon fiber has better mechanical properties compared to glass fiber, but on the downside carbon fiber is more expensive. Therefore, for the switch from glass fiber to carbon fiber the economic picture should also be drawn. This is the focus of this thesis. This thesis focuses on the manufacturing cost of a girder that is manufactured using any of the three methods: vacuum infusion of glass fiber, vacuum infusion of carbon fiber and the prepreg process using carbon fiber as reinforcement material. The process of vacuum infusion of glass fiber is used as a reference in order to estimate the cost of the other two methods. This is done, as this process is used by Suzlon Energy in manufacturing wind turbine blades. The vacuum infusion of carbon fiber is the next method that will be assessed as this method can be seen as the next logical step. Simply said, this method can be applied by only changing the reinforcement material in the vacuum infusion process, so the change in the usage of reinforcement material is in this case the smallest as the manufacturing process remains the same. The choice for the prepreg method is that this method is thought to be a good alternative for manufacturing the blade instead of the vacuum infusion process. In a way it completes the picture of material switch. The aim of this thesis is twofold. On the one hand a cost model for the manufacturing of a girder using any of the three mentioned methods, i.e. vacuum infusion of glass fiber, vacuum infusion of carbon fiber and the prepreg process using carbon fiber as reinforcement material, is developed. On the other hand this model is used to determine which process, from an economical point of view, is favorable. The comparison of the three cost models is based on two criteria: manufacturing cost and manufacturing time. It is observed that the prepreg process is both more expensive and manufacturing takes longer compared to the vacuum infusion process of either glass fiber or carbon fiber. Focusing on the infusion process it is observed that there is a small difference in cost for infusion of glass fiber or infusion of carbon fiber. The trend shows is that for small blade lengths infusion of carbon fiber is slightly more expensive than infusion of glass fiber, however for larger blades the opposite becomes the case. Focusing on the manufacturing time it is observed that glass fiber infusion takes significantly more time compared to carbon fiber infusion. Therefore, it is concluded that the switch from glass fiber to carbon fiber is economically justified. However, this is only the case when the manufacturing process used is vacuum infusion of carbon fiber, rather than the use of carbon fiber in the prepreg process.","Windenergy","en","master thesis","","","","","","","","","Applied Sciences","","","Sustainable Energy Technology","",""
"uuid:26a5ae1a-e3cc-46bc-9049-fc87548d0f7d","http://resolver.tudelft.nl/uuid:26a5ae1a-e3cc-46bc-9049-fc87548d0f7d","Developing an Impact Evaluation Framework for Product Designers Inspired by the Capability Approach: A Case Study on the Philips Chulha","Van der Marel, F.","Keyson, D.V. (mentor); Mink, A. (mentor); Isik, F. (mentor)","2012","Within the field of Product Design is an increasing interest in designing with emerging markets. Considering how long people have already been concerned with increasing global living standards it is surprising how little has been achieved. This suggests our current methods are insufficient. The Capability Approach (CA) by Amartya Sen offers a new way of assessing inequality and poverty, focusing on what people have reason to value to be or do. Products can be means to achieve these beings and doings. An evaluation framework inspired by this philosophy was developed. The framework was tested in a case study. The sociological impact was evaluated of the Philips Chulha, a subsidized cooking stove implemented in tribal India. The impact in terms of the CA was identified and explained using Kleine's Choice Framework and Bourdieu's concept of habitus. The framework was successful in engaging into deep dialogues with the target users. The interpreter appeared to be highly influential on the way the study was executed. Since the research was conducted in one region, no firm statements could be made based on this single case study. The framework needs further testing and developed in order to increase the collaboration between the interviewer and the interviewee. Eventually product designers can use the improved evaluation framework as a prospective framework to uncover design opportunities for developmental purposes.","evaluation framework; Capability Approach; emerging markets; product impact; Philips Chulha","en","master thesis","","","","","","","Campus only","2013-08-15","Industrial Design Engineering","Industrial Design","","Design Research for Interaction","",""
"uuid:80b6b987-488d-4210-9c93-10b425545fc0","http://resolver.tudelft.nl/uuid:80b6b987-488d-4210-9c93-10b425545fc0","Exploring and Implementing Pleasant Touch in the Interface of Products for Design Purposes: The Case of a Bang & Olufsen TV Remote Control","Fennis, T.J.M.","Sonneveld, M.H. (mentor); Sener-Pedgley, B. (mentor); Rozendaal, M.C. (mentor)","2012","This thesis proposes a design strategy for pleasant touch. Literature is reviewed on the importance of pleasant touch, existing implementations in products and design for tactility. A lack of competence is found on how to design for pleasant touch in the interface of products: functional pleasant tactility. Therefore, a design vision is created by the author as a designer, on how to design functional pleasant tactility. The envisioned design strategy is then implemented through a case study of a Bang & Olufsen TV remote control. The case study includes 3 sequential phases: exploring, designing and evaluating functional pleasant tactility in the given context. Exploring was done through workshops where design students were asked to touch objects with various material properties. Pleasant movements were performed with the objects, and matching functions were imagined, resulting in ‘actions’. Those actions were analyzed to discover three underlying themes of inviting, mastery and logic. In the designing phase those themes were translated into three corresponding design concepts, and worked out into prototypes. In the evaluating phase those prototypes were tested with that target group, and the results were used to create a final design concept. As a researcher, the author then concludes with a design strategy that is expected to work for the broader context of industrial design, and recommends further research with this strategy for different products and companies.","Pleasant Touch; Functional Pleasant Tactility; Design Strategy; Case Study; Bang & Olufsen","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design for Interaction","","TULIP program (double degree Master with METU)","",""
"uuid:bde2dae3-ac32-46df-9a39-330d613d3f57","http://resolver.tudelft.nl/uuid:bde2dae3-ac32-46df-9a39-330d613d3f57","Entity Information System","Mol, A.W.; Cheung, L.","De Haan, G. (mentor); Krijnen, R. (mentor)","2012","","","nl","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Technische Informatica","","","",""
"uuid:35943d13-7812-41a1-9a44-c9a8f94ee1cc","http://resolver.tudelft.nl/uuid:35943d13-7812-41a1-9a44-c9a8f94ee1cc","Uncertainty Quantification and Calibration of the k − ǫ turbulence model","Yildizturan, Haci (TU Delft Aerospace Engineering)","Bijl, Hester (mentor); Dwight, Richard (mentor); Hulshoff, Steven (mentor); de Baar, Jouke (mentor); Delft University of Technology (degree granting institution)","2012","Nowadays, the numerical errors are decreased to an acceptable level in the sense that the variability of the model parameters is becoming more important for obtaining results with higher reliability. Therefore, the focus of this thesis is on the quantification of the uncertainties of the turbulent closure model k −ǫ. The k −ǫ model is tuned to free shear flows and used for wall-bounded flows in combination with wall functions. To increase the reliability of the k − ǫ model for predictions of turbulent flows the uncertainty quantification (UQ) methodology is applied in this thesis. As a test case the external flow over the airfoil DU96-W-180 is considered.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:97469901-4724-4c0b-851e-0eefb100adc8","http://resolver.tudelft.nl/uuid:97469901-4724-4c0b-851e-0eefb100adc8","Non-Parametric Bayesian Networks (NPBNs) versus Ensemble Kalman Filter (EnKF) in Reservoir Simulation with non-Gaussian Measurement Noise","Zilko, A.A.","Hanea, A. (mentor)","2012","Lately, the objective of reservoir engineering is to optimize hydrocarbon recovery from a reservoir. To achieve that goal, a good knowledge of the subsurface properties is crucial. The author is concerned with estimating one of the properties of the field: the permeability of a reservoir. To characterize the fluid flow, a two phase (oil-water) 2D model represented as a system of coupled nonlinear partial differential equations which is unsolvable analytically is used. Ensemble Kalman Filter (EnKF) is the most common tool used to deal with this situation. However, it is not the only way. Recently, a research on a more general approach based on a dynamic Bayesian network using the Non-Parametric Bayesian Networks (NPBNs) has been initiated. This research, which uses twin experiment, indicates that the NPBN approach appears to be a promising alternative to EnKF. However, a number of open questions emerge from this initial research. The first one is the normality assumption for the noise used in the measurements generation in the twin experiment. Even though Gaussian noise for measurements is sensible in the sense that the knowledge about the noise is unavailable, it does not mean that other noise from different distributions cannot be applied. The second one is the exclusion of saturation in the NPBN approach performed in the previous research. This may result in the loss of valuable information. Further, the previous research discovers that NPBN approach seems to work well in recovering only part of the reservoir. The entire permeability field may be approximated by means of interpolation between several approximated parts of the field. Hence, the third question relates to an interpolation method that may be used in recovering the permeability of the entire reservoir. This project aims to experiment on these three key points of interest. A fourth objective, however, is surfaced during the analysis, which is to use an alternative measure of performance to the well-known Root Mean Square Error (RMSE). Along the way, the performance of both EnKF and NPBN are going to be observed and compared one more time.","Ensemble Kalman Filter; Non-Parametric Bayesian Networks; Parameter Estimation; Reservoir Engineering; Reservoir Simulation; Bayesian Networks","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","","",""
"uuid:92034300-4071-4d94-9223-7c2f15d401ba","http://resolver.tudelft.nl/uuid:92034300-4071-4d94-9223-7c2f15d401ba","Analyzing and applying agent oriented programming methods for teaching purposes","Dekker, M.","Hindriks, K.V. (mentor); Van Riemsdijk, M.B. (mentor)","2012","In this thesis we discuss ways to improve teaching methods for agent oriented programming. The research approach consists of several steps. First data is gathered from groups of students participating in a first year agent programming project that uses the Unreal Tournament 2004 environment. The stronger and weaker groups are analyzed in a qualitative way to establish differences in programming styles between the stronger groups and weaker groups. The focus of the analysis is on software quality and code constructs. This analysis establishes what the key success factors of the stronger groups are. The results of this analysis are applied while developing the HactarV2 agent system for the Multi-Agent Programming Contest together with other students. During the Unreal Tournament project we found that stronger groups spend more time and energy on testing than weaker groups. It was also established that they pay more attention to documentation, software quality factors and the style of their code. Finally a code pattern similar to the Strategy design pattern showed up much more often with the stronger groups than with the weaker groups. When these methods were applied during the Multi-Agent Programming Contest project it was established that some of the documentation methods do not work as intended and that code style sometimes has to be sacrificed for the sake of efficiency. On the other hand the use of testing was proven again and the use of the code pattern turned out to work better than expected. The fact that the HactarV2 team won the Programming Contest is a clear indication that these methods work. The conjecture of this thesis is that the quality of an agent system can be improved by the right approach to testing and documentation during the development and by applying code patterns that make behavioral control easier. Teaching these approaches and patterns to students will improve their skill level of agent-based programming.","Agent Oriented Programing; GOAL; Multi-Agent Programming Contest; Artificial Intelligence; Design Patterns","en","master thesis","","","","","","","","2012-08-15","Electrical Engineering, Mathematics and Computer Science","Intelligent Systems","","Interactive Intelligence","",""
"uuid:830611e8-104d-4b56-aede-8515e45be90f","http://resolver.tudelft.nl/uuid:830611e8-104d-4b56-aede-8515e45be90f","Mimetic Mesh Refinement: A mortar element approach","Kuystermans, Peter (TU Delft Aerospace Engineering)","Gerritsma, Marc (mentor); Dwight, Richard (mentor); Kreeft, Jasper (mentor); Pinto Rebelo, Pedro (mentor); Delft University of Technology (degree granting institution)","2012","This thesis aims to introduce mesh refinement into the Mimetic Spectral Element Method (MSEM). The concept of mimetic discretizations is to mimic the properties of continuous Partial Differential Equations (PDEs) discretely. In many discretization methods information is lost in the actual discretization step which is detrimental to the physical fidelity of the approximated solution. Mimetic methods try to prevent this, a feat achieved by combining the fields of differential geometry and algebraic topology. Where differential geometry describes the continuous problem, algebraic topology functions as its discrete equivalent. By accounting for the spatial and temporal geometric objects each physical quantity is associated with, mimetic methods preserve as much as possible of the continuous structure.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering | Aerodynamics and Wind Energy","",""
"uuid:cf5c137e-1135-45c6-9eeb-5456bfdcbbe8","http://resolver.tudelft.nl/uuid:cf5c137e-1135-45c6-9eeb-5456bfdcbbe8","Motivations for Knowledge Sharing in Professional Services Firms: A Case Study","Orjuela Alvarez, L.A.","Rook, L. (mentor)","2012","Starting with the research question -Why are individuals at professional services firms motivated or inhibited to share knowledge? This case study gives an elaborate picture of the knowledge sharing behaviors and the motivations of a group of technology consultants. The insights obtained from this research reveal valuable lessons to increase the propensity of these individuals to share their knowledge. Businesses such as management consultancy and technology consultancy are recognized for their heavy investment in human capital while minimizing the use of tools and machinery. It is in this setting where managing knowledge has become critical to performance and the process of sharing knowledge has been identified as a key source of competitive advantage. Although much theory is available in this area, organizations often experience difficulties taking knowledge management into practice. Among other problems, it has been observed that there is a poor understanding of the employees who carry the knowledge and what their perceptions are. One approach drawn from social sciences has addressed this situation by focusing on the motivations of the individuals to engage in knowledge sharing. It brings attention to the personalized, diffuse nature of knowledge and that transferring knowledge is an effort-insensitive activity, thus requiring certain degree of motivation. A relevant development in this direction is the Alignment Model of Motivational Focus, which stresses that the decision on an individual to share knowledge is not only affected by personal motivations, but also by the alignment, or association, to the groups it belongs to. While this model is recent and has not been tested, its original approach and its focus on knowledge-intensive firms provide a suitable foundation to prolong the research on knowledge sharing. In line with the theoretical and practical implications of focusing on professional services firms, this research aimed to explore the knowledge sharing behaviors in this industry and to identify the motivations of the individuals to engage in the process. Once reached a conclusion on the most relevant forces steering the individuals, the author sought to draw corresponding management practices that would increase the propensity of the workforce to share its knowledge. The research was structured in the form of a case study on an IT-consulting unit within a large professional services firm in the Netherlands. It made use of in-depth interviews with the consultants and direct observations of their behaviors, while the Alignment Model of Motivational Focus was implemented as main conceptual model to structure the data. Given the strict qualitative nature of the study, specialized software was utilized to code and analyze the data. The analysis focused on evaluating the frequency of key concepts and establishing relationships among them. It was found that the individuals are mainly driven by personal motivations, but also by the alignment to their team, the alignment to the organization and the alignment to their professional discipline. Eight motivational forces seem to have a major impact in stimulating knowledge sharing behaviors. Their ranking in order of importance is:  Most important: Reciprocity  Personal success  Expectations from the team  Team success  Perceived value of knowledge by others  Availability of resources  Personal Status  Least important: Contribution to project practices This list is the result of proposing a modified version of the Alignment Model of Motivational Focus specific to professional services. The new model excluded the motivations of gaining financial rewards and of gaining personal influence, as they do not seem to correspond to the work in this industry. In addition, reciprocity was a motivation not contemplated in the original model but here it was found to have a central role. These disparities appear to be related to the distinctive features associated with the professional services industry, such as the importance of networking and the heavy weight given to the individual achievements. Furthermore, it was found that there are a various barriers inhibiting the individuals to share knowledge. The most significant ones are the perception that there is not enough time to invest in sharing, and that the management does not provide enough support for this process. The results of the case study provide the groundwork to design improvement measures to increase the likelihood that knowledge will be shared among the employees of professional services firms. A set of seven managerial practices were identified that may effectively stimulate knowledge sharing in line with the perceptions and ambitions of the individuals. In no particular order: 1. Strengthen networking skills 2. Make knowledge contributions publicly visible 3. Have formal procedures to record and share lessons learned 4. Integrate knowledge sharing into the performance appraisal 5. Offer explicit, non-financial rewards 6. Develop a knowledge sharing culture 7. Exhibit leadership Incorporating these practices in the knowledge management strategies of professional services firms and keeping sight of the behavioral responses of the workforce will offer valuable insight to gain an enhanced organizational performance.","knowledge management; motivation; knowledge sharing; professional services; IT consulting","en","master thesis","","","","","","","","","Technology, Policy and Management","Technology, Strategy and Entrepreneurship","","Management of Technology","",""
"uuid:246cd36d-cded-4ab8-a882-7663a631e0ac","http://resolver.tudelft.nl/uuid:246cd36d-cded-4ab8-a882-7663a631e0ac","Stevin Outlet Sluices: Wave impact under a beam","Hofste, G.M.","Vrijling, J.K. (mentor); Uijttewaal, W.S.J. (mentor); Labeur, R.J. (mentor); Molenaar, W.F. (mentor); Vos, J.P. (mentor); Wellens, P. (mentor)","2012","The Dutch department of Public Works had a problem regarding wave impacts on a beam in the Stevin outlet sluices, located in the Afsluitdijk. Wave impacts on this beam could also cause a peak pressure on the barrier gate, just behind the beam. The numerical program ComFLOW and physical scale experiments were used to predict the wave impacts for different hydraulic conditions (i.e. wave height, wave period and water level). The research questions were: 1. How is the wave load on the northern gates depending on the presence of the military beam? 2. How large is a wave impact load on the bottom of the military beam in the Stevin outlet sluices? 3. How well can the numerical model ComFLOW and physical modelling be used to determine the wave impact on the bottom of the military beam in the Stevin outlet sluices? 2D scaled experiments were performed making use of a model with the (simplified) geometry of the Stevin outlet sluices and regular waves. It was found that the largest wave impacts occurred for water levels equal to the bottom plane of the beam or slightly under it. This happened for the shortest waves in the test domain. The largest pressure measured on the beam was approximately 50 kPa or 35H, with H representing the incident wave height in front of the model. It was also found that the spread in the peak pressures for one single experiment was large. The results of the measured impulse per peak showed far less spread. The effect of wave impacts under the beam was also found on the vertical wall under the beam. The actual pressures however were less and they were decreasing with increasing depth. Besides physical wave impact testing, a few experiments were performed with the beam removed from the model. This resulted in wave simply running up the vertical wall of the model. They did not cause a wave impact. The measurements of both type of experiments, with and without a beam, were compared. This revealed that the total wave impulse on the gate was not affected by the presence of the beam. However the distribution of the pressure within a single wave period was significantly different. In case of a beam, a large impact peak was observed, whereas the other wave only showed a small hump caused by the deflected flow against the vertical wall. When the calculated and measured wave impact results were compared it became clear that ComFLOW underestimated the peak pressures by a factor 2 to 20 for the pressures on the impact plane. The same was done for the peak impulse. This showed that the impulse of the peak on the impact plane were underestimated by a factor 2 at most. These results confirmed that the used grid was too coarse for the program to model the physics correctly. The main conclusions to the research questions were: 1. The presence of the military beam causes a different distribution of the force on the gate within a wave period. The total amount of impulse is more or less the same as for the situation without a beam. With the military beam, a wave impact results in a peak force on the gate. Without the beam, there will be no peak force. 2. The largest measured wave impact pressure is 35H. 3. Both ComFLOW and physical modelling can be used to predict wave impacts for the geometry of Stevin outlet sluices. Much care should be taken when modelling and much attention should go to the input parameters of the program.","impact; slamming; beam; horizontal; wave; waves","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Hydraulic Engineering","","Hydraulic Structures","",""
"uuid:b8ed91da-8999-45a4-8e29-0ae0fa79f420","http://resolver.tudelft.nl/uuid:b8ed91da-8999-45a4-8e29-0ae0fa79f420","Separated sequences in Banach spaces","Van Heijst, W.N.","Van Neerven, J.M.A.M. (mentor)","2012","","banach space; separated sequences","en","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Mathematics","","Technische Wiskunde","",""
"uuid:b6f6eb6a-5277-41c6-858f-69bf2846a273","http://resolver.tudelft.nl/uuid:b6f6eb6a-5277-41c6-858f-69bf2846a273","AR.Drone autonomous control and position determination","Van der Spek, I.T.; Voorsluys, M.H.","Verhoeven, C.J.M. (mentor)","2012","In this thesis first a study is conducted on which position determination method should be used in a UAV and especially in the Parrot AR.Drone. Then an autonomous control for the AR.Drone is designed. The best position determination method in this case appeared to be a combination of a GPS sensor and a barometer. The autonomous control is designed with a three layer model. The four control parameters of the Parrot AR.Drone are controlled by this control model.","AR.Drone; parrot; UAV; GPS; autonomous","en","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Electrical Engineering","","","",""
"uuid:c7b566fb-387d-4f3a-9553-d59bddc6771d","http://resolver.tudelft.nl/uuid:c7b566fb-387d-4f3a-9553-d59bddc6771d","Minimally Unsatisfiable Subformulae","Mijnders, S.","Heule, M.J.H. (mentor)","2012","Minimal unsatis?ability is a topic in the ?eld of satis?ability (SAT). Minimally unsatis?able subformulae (MUSes) are minimal subsets of an unsatis?able formula that are unsatis?able. They can therefore be seen as causes of unsatis?ability. With recent improvements in SAT solving, extracting MUSes has also become faster. Lately increasingly more effort has been put in getting MUS extraction to industrial strength. This thesis tries to speed up MUS extraction by applying preprocessing techniques from the ?eld of SAT solving. Application is not always straightforward. Some techniques have to be modi?ed and some are not applicable at all. For each of the discussed techniques, this thesis describes how they affect MUSes and what has been done to apply them.","MUS; satisfiability; SAT; minimal unsatisfiability; MUS extraction; preprocessing; clause elimination; BCP; SCCE; minimally unsatisfiable subformula; heuristics; self-subsumption; minisat; muser","en","master thesis","","","","","","","","2012-08-15","Electrical Engineering, Mathematics and Computer Science","Software Technology","","Algorithmics","",""
"uuid:67036896-928d-4e0a-8fa6-1c42a74acd5c","http://resolver.tudelft.nl/uuid:67036896-928d-4e0a-8fa6-1c42a74acd5c","Prediction of Market Value of Used Commercial Aircraft","Feng, Q.","Kurowicka, D. (mentor); Redig, F.H.J. (mentor)","2012","Aviation financers are interested in the current/future market value of used commercial aircraft, as this information is precious knowledge for them to support collateral position in the aircraft loan. In this paper, variables from general economy, airline industry and aviation fleet are explored to find out the factors predictive for used aircraft market. Two statistical methods- principal component regression and copula-are applied for building the prediction model of an aircraft.","Market value of Aircraft; Used aircraft market; regression; principal component analysis; copula","en","master thesis","","","","","","","","2013-08-13","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","Risk and Environmental Modeling group","",""
"uuid:3d75e8be-a02f-4368-953f-da26030c065c","http://resolver.tudelft.nl/uuid:3d75e8be-a02f-4368-953f-da26030c065c","Optimization of a 2D Forebody for Sonic Boom Minimization","Ahmadi, Faramarz (TU Delft Aerospace Engineering)","Bakker-Jager, Peter (mentor); Delft University of Technology (degree granting institution)","2012","When an object moves near sonic speed a shock wave will be formed and all disturbances and discontinuities remain localized in an area downstream of the shock wave. The impact of sonic boom is both of psychosomatic and structural damage. The sonic boom is unacceptable to the human ears due to the fact that it appears without warning and it produces structural damage. The sonic boom is unavoidable for an airplane which has lift, so the effort should be made to minimize the unacceptability degree on the part of the people.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:5d2c8dd1-53f3-48a5-9742-6edbaf3faf51","http://resolver.tudelft.nl/uuid:5d2c8dd1-53f3-48a5-9742-6edbaf3faf51","Notion of the North","Van der Vorm, R.J.","Van den Heuvel, D. (mentor); Hrsak, L. (mentor); Cuperus, Y. (mentor)","2012","‘At the moment Amsterdam, including the north, is undergoing big changes...’ ‘... the city is suffering from the crisis and is looking for new ways to house people. This also concerns the district of Amsterdam Noord. How will these changes and conditions effect the character of this part of Amsterdam. Will ‘Noord’ in twenty years still be ‘Noord’? ‘The last one hundred years Amsterdam Noord developed into a district where living, industry and working can exist next to each other. Amsterdam Noord is informal, ‘not tidy’, it is indifferent, in one hand traditional but also ‘easy’. Pockets of working class housing and areas with small industry and businesses are imbedded in a spacious, divers, maybe even fragmented urban patchwork. Moreover, the district is bordered by the river IJ in the South, and by a rural hinterland in the North which generate a lot of opportunities. Being part of a vibrant, important metropolis, Amsterdam Noord has its own personality, it is part of the collective memory of the city.’ How can a housing project implement these aspects to keep and even enhance this ‘personality’ of Amsterdam Noord? What kind of program and configuration, concerning the design site, is needed when dealing with this notion of the North?","Dwelling; Architecture; Amsterdam Noord","en","master thesis","","","","","","","","2012-11-24","Architecture","Dwelling","","At Home in the City","",""
"uuid:20f991b9-d731-4139-b938-7636a52eeb76","http://resolver.tudelft.nl/uuid:20f991b9-d731-4139-b938-7636a52eeb76","Novel Simulator for Wireline Mini-Fracture Testing","Sintra Magalhaes, B.M.","Zitha, P.L.J. (mentor); Barnhoorn, A. (mentor); Subbiah, S.K. (mentor)","2012","Wireline Mini-Fracture testing jobs consist of a short duration, small volume fracturing operation inside an open-hole borehole, where a certain amount of fluid is injected into the formation at constant rate using a Wireline Modular conveyed tool as a source of hydraulic power to pressurize the wellbore. The tool is configured with an inflatable straddle packer and an internal pump, which inflate/deflates the packers and supplies pressure to the formation until a hydraulic fracture is induced. This procedure is used to determine in–situ formation breakdown and closure pressure also known as minimum horizontal closure pressure. This provides vital information regarding hydraulic fracture design, water and gas injection management, fault re-activation, wellbore stability, sand production, rock mechanical properties, casing string design, cap and base rock integrity and gas storage design. Geomechanical and operational parameters such as, elastic properties, poro-elasticity, rock strength, formation pore pressure, far field horizontal stress, permeability/porosity distributions, borehole fluid properties among others, influences the performance of the Mini-Frac Jobs. In many cases poor understanding of the reservoir response to the fracture process, caused that the hydraulic fracture did not propagate deep into the formation. In other cases the pressure applied to the formation might be insufficient to break down the formation, leading to unsatisfactory application of the Mini-Fracture technique in the process. The objective of this thesis is to develop a Mini-Facture application simulator that uses the geomechanical and operational parameters that control the performance of a Mini-Fracture job and estimate the possibility of the occurrence of a tensile failure in the formation. The simulator is then validated by comparing its output with the results of stress test done in the field. With this simulator petrotechnical professionals and field engineers will have a platform that simulates the pressure responses and fracture initialization during Mini-Frac treatments, incorporating all the variables affecting a Wireline Mini-Fracture job, helping the design engineer to make key decisions about the ultimate or required fracture plan. Furthermore the simulator will reduce the uncertainties that limit the reliability of the Wireline Mini-Fracture treatment by allowing the selection of appropriate tool configuration based on the job objectives and the geological environmental conditions. Finally this project demonstrates that combining the appropriate constitutive relations that reflect the coupling among the tool operational performance with wellbore flow, reservoir and geomechanics modelling a Mini-Fracture simulator can be developed.","mini-frac","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Petroleum Engineering","",""
"uuid:7349d2c4-8d76-4862-b233-efd3ffe2ab0b","http://resolver.tudelft.nl/uuid:7349d2c4-8d76-4862-b233-efd3ffe2ab0b","Design of an unobtrusive customized luminaire for the fashion retail","Aarts, C.J.M.","Christiaans, H.H.C.M. (mentor); Doubrovski, E.L. (mentor)","2012","Lighting is one of the most important inventions ever. It makes us see in the dark! These days it is also a key value add in spaces like retail. The right lighting in the right situation makes us buy more. Light nowadays is much more than the source itself. It is about the luminaires, the integration in architecture, matching level with shopping expectations and total design. Before you lies my final report of my graduation project. At the start of my graduation I formulated a research question: “How can we create relevant and meaningful customized lighting solutions for the fashion retail business using rapid manufacturing techniques” The research question is a result of a personal interest in lighting and rapid manufacturing techniques and Philips’ aim to research new values spaces in the area of customization, lighting solutions and emerging technologies like rapid manufacturing. As an interesting market the fashion retail business was selected due to their demanding character on renovation cycles, flexibility of product offerings and customer expectations. In the beginning of this project the research question was technology driven. Soon it became clear that without knowing the relevance and meaning of lighting solutions in the fashion retail the technology is irrelevant. Therefore the research itself was soon watered down to finding the relevance and meaning of lighting solutions and how this can be translated into a design. This means the area of rapid manufacturing was soon considered just a evaluation aspect at the final recommendations. Entering the market of fashion retail design is complex. The retail space exist of many different aspects that together create a retail experience. Lighting being one of those aspects which is considered important because it brings the focus on the merchandise by illuminating this in the best possible way. Lighting also contributes to the total consumer shopping experience, both by the presence of the luminaires at the ceilings and the source itself. After studying the different domains of fashion retail, its lighting solutions and the relevance and meaning of these in the retail space, it became clear that light quality, unobtrusiveness of the luminaire, differentiation and flexibility of the luminaire are the most import aspects for a lighting product in the fashion retail. Translating this into a luminaire should create a relevant and meaningful lighting solutions for the retailer. This resulted into the challenge to design an unobtrusive customized luminaire that provides flexibility to change its look&feel as well as re-adjusting its spotlights. To answer the research question a concept luminaire has been developed from design to a working prototype. Key features were the slim platform providing general and spot light and the 360 degrees flexible spot with differentiable add-ons. (for the sharp reader, it is actually 358 degrees due to the electrical connection;-) The concept itself has been found valuable on multiple aspects like unobtrusiveness through small dimensions, use of transparent materials and integrating accent and general lighting in one luminaire. The innovative way of re-adjusting and aiming the spotlight are also evaluated as being very valuable. In the area of customization there is still a lot to win. The proposed solutions of customization will not generate sufficient differentiation for the retailer. The ease of use and the flexibility in the concept does provide a valuable feature to the concept and can be a starting point for further development. Most interestingly a design was found to reduce chaos at ceilings. This is a potential value space for Philips. Further research into unobtrusiveness through ambient colour lighting, variable ceiling application and easily changeable customization possibilities are indicated as key recommendations for Philips.","fashion retail; customization; lighting; rapid manufacturing; unobtrusive","en","master thesis","","","","","","","Campus only","2013-08-09","Industrial Design Engineering","IDE","","Master of Science Integrated Product Design","",""
"uuid:d88573f4-9c70-4c58-bcd8-f573d96f2785","http://resolver.tudelft.nl/uuid:d88573f4-9c70-4c58-bcd8-f573d96f2785","A Study on Geometric and Material Properties of the Mangrove Root System in Singapore","Bo, J.","Cheong, H.F. (mentor); Chua, V. (mentor); Verhagen, H.J. (mentor)","2012","Although the effect of wave attenuation by mangrove has been widely observed and studied, the problem pertaining to how to accurately describe the geometrical properties is still remaining unresolved. Also, the material properties of mangrove root have not been comprehensively studied before. This is study is dedicated for the survey on geometric and material properties of mangrove in Singapore for future modeling work. In this study, two types of mangrove are surveyed, as Sonneratia alba and Rhizophora, for the two survey types of mangroves are mostly abundant in Singapore and Johor River region. Photogrammetry technique has been extensively practiced for capturing the geometrical properties of the mangrove root. Lab testing has been carried out to obtain the material properties of mangrove root. The geometrical properties studied are mainly root density, root distribution and root height. The material properties studied are the mass density, moisture content and modulus of elasticity of the mangrove roots.","mangrove; resistance; root system; flow","en","student report","","","","","","","","","Civil Engineering and Geosciences","Hydraulic Engineering","","TUD-NUS","",""
"uuid:726c4d37-e9c3-48f7-a2c2-55511e52f1c9","http://resolver.tudelft.nl/uuid:726c4d37-e9c3-48f7-a2c2-55511e52f1c9","The Oval Fuselage: A New Structural Design Concept for Blended Wing Body Cabins","Hoogreef, M.F.M.","Vos, R. (mentor); Veldhuis, L.L.M. (mentor); La Rocca, G. (mentor); Geuskens, F.J.J.M.M. (mentor)","2012","Faced with the decreasing fossil fuel reserves and the need to decrease its environmental footprint, the aviation industry is searching for alternative fuels and more fuel efficient engines and aircraft. With the current designs reaching their limits, the industry has turned its attention to the family of all lifting bodies. Particularly blended wing body aircraft have received much interest, a combination of a lifting fuselage and a flying wing. It is commonly believed that this design has a high aerodynamic efficiency and lower structural weight fraction, which both contribute to a higher fuel efficiency. Though the concept has been around since World War II, no flying full-scale aircraft with a pressurized cabin currently exists. Additionally, the pressure cabins have so far been dictated by the aerodynamic design of the centre body. This thesis presents an alternative approach in blended wing body design, which has its roots in the design of conventional aircraft. For current aircraft a method called the `inside-out approach' is used, where the design of the fuselage is dictated by the requirements for the passenger and cargo compartment. Following this approach a blended wing body cabin consisting of four tangentially connected arcs, forming an oval fuselage cross-section with no need for an aerodynamic outer surface is designed. The arcs are supported by vertical and horizontal members, doubling as walls, floors and ceiling for the cabin. The research presented in this thesis describes the geometry determination and weight estimation for this new design, for pressurization, wing bending loads and longitudinal fuselage stresses. The weight estimation method that has been developed determines the thicknesses of the structural members per oval fuselage cross section, described by the four arcs and horizontal and vertical members, for a certain cabin geometry and the aforementioned loads. An imposed airfoil shape over the centre line of the cabin restricts the height of each oval cross-section. By placing these oval cross-sections in sequence, and interpolating between two neighbouring sections, a three-dimensional fuselage can be created that follows the airfoil shape. This airfoil-shaped fuselage is combined with outer wing sections, vertical tail planes, engines and landing gears to generate a complete blended wing body model. This model is analyzed by means of a Matlab optimization tool, which was adapted from a pre-existing blended wing body design tool. In this tool, the developed fuselage weight estimation is combined with a wing-weight estimation and an operative empty weight estimation to calculate the total operative empty weight. Three different conceptual design studies of blended wing body configurations, for 200, 400 and 800 passengers, have been optimized and assessed to investigate the feasibility of the new structural cabin design. These designs have been compared to another blended wing body cabin design and to conventional aircraft. In comparison to other blended wing bodies a lower fuel consumption, lower operative empty weight and longer range were found for the same maximum take-off weight and the same payload. A 400 passenger `oval-fuselage' blended wing body showed the most promising results with a 13% lower empty weight, a 6% better fuel consumption and almost 29% longer range. In comparison to the conventional airliners, this particular blended wing body showed a fuel consumption per transported kilogram that was 10% lower than that of the best performing conventional aircraft, the Boeing 777-200LR.","Blended Wing Body; Aircraft Weight Estimation; Conceptual Design; Fuselage Concept; Aircraft Cabin","en","master thesis","","","","","","","","","Aerospace Engineering","Flight Performance and Propulsion","","","",""
"uuid:7f88255d-31d3-4bc9-a078-744a8f564d38","http://resolver.tudelft.nl/uuid:7f88255d-31d3-4bc9-a078-744a8f564d38","Node Selection Technique for Distributed Beamforming in Green Cognitive Radio Networks","Tessema, N.M.","Nikookar, H. (mentor); Lian, X. (mentor)","2012","The wide deployment of wireless sensor nodes for varieties of applications calls the need for distributed beamforming as a cooperative scheme to efficiently use spectrum, to improve communication range and to save precious battery power during transmission. Given that there are a large set of cooperative cognitive radio users, ensuring the minimal energy is consumed while keeping the interference received by primary users below a given regulatory limit is crucial to maintain the green aspect of Cognitive Radio Sensor Network. The major research question is how to develop an efficient node selection method that allows to keep the energy consumption at the minimum and while keeping the interference regulations of primary users. In this thesis, an efficient node selection method which allows maintaining the Green aspect of the network is proposed. The node selection method is used to save significant amount of energy per single transmission. Furthermore, the impact of ambiguous location information in distributed beamforming is investigated. The statistical characterization of the phase error at the beamforming nodes is studied. A simple solution that leads to minimize the degradative impact of location ambiguity is given.","green; cognitive radio; node selection; beamforming","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Telecommunications","","Telecommunications","",""
"uuid:75eb6925-dad1-4680-9dad-d554b23fe44e","http://resolver.tudelft.nl/uuid:75eb6925-dad1-4680-9dad-d554b23fe44e","Iris - A strategic & integrated mobile application for KLM's cabin crew","Gaykema, R.W.A.","Van der Meer, J.D. (mentor); Molenbroek, J.F.M. (mentor)","2012","This MSc. thesis is about the development of an integral user-centered and lean mobile application for KLM's cabin crew. In approximately 12 months the author has executed many deep internal analysis on KLM's inflight services operations, its organization and processes, the cabin attendants and its external environment. And in addition to all prior analysis a case study was performed on, KLM's 'iPad on Board' pilot.The analysis have resulted in many important insights, opportunities and fundamental flaws. The main goal for this thesis was to develop an application that contributes to an efficient, enriching, premium and crew supportive operation.All conclusions from the analysis were integrated in an integral and strong mobile strategy, which includes a fully developed application-concept 'iris' and an implementation plan.","mobile; application; strategy; implementation; iPad; KLM; user-centered-design","en","master thesis","","","","","","","Campus only","2013-08-08","Industrial Design Engineering","Industrial Design","","Master of Science Strategic Product Design","",""
"uuid:81f376a3-2c9a-4d24-b547-6b384dc0aef6","http://resolver.tudelft.nl/uuid:81f376a3-2c9a-4d24-b547-6b384dc0aef6","Visualize local neighborhood for supporting debugging","Cobben, N.R.","Pinzger, M. (mentor)","2012","Developing software is complex, debugging even more. In this thesis an approach is presented to reduce the debugger’s burden by introducing visual support for debugging. This is accomplished by using multiple supporting debugging concepts which are implemented in the tool: the Visual Debugger. The Visual Debugger supports debugging by visualizing the local neighborhood at runtime when debugging with a specialized hierarchical graph. The visualization provides the user easy access to an overview and details of the dependencies surrounding the executing method. The concept of visualizing local neighborhood to support debugging is tested in a pre-post test user experiment in which participants solve debug tasks with the Visual Debugger and answer questions about their debug habits. The questions involve how participants experience the tool and how they use a debugger. The results show that the capability of the Visual Debugger to support debugging by visualizing the local neighborhood is useful but more optimization and research is required to relate this result to improved program understanding.","visualization; debugging; program understanding","en","master thesis","","","","","","","","2012-08-08","Electrical Engineering, Mathematics and Computer Science","Software Engineering","","Computer Science","",""
"uuid:f5819979-5874-497d-9ec5-8645916b9c9a","http://resolver.tudelft.nl/uuid:f5819979-5874-497d-9ec5-8645916b9c9a","Maximum Likelihood Estimation of Linear Time-Varying Pilot-Vehicle System Parameters","Kers, M.","Mulder, M. (mentor); Pool, D.M. (mentor); Van Paassen, M.M. (mentor); Chu, Q.P. (mentor)","2012","","Maximum Likelihood Estimation; Human-Machine Interaction; HMI; aerospace; system identification; parameter estimation; Gauss-Newton; Boltzmann Sigmoid; control; simulation; modeling; LTV; Linear Time-Varying; MLE","en","master thesis","","","","","","","","2016-06-01","Aerospace Engineering","Control & Operations","","Human-Machine Interaction","",""
"uuid:9a6694d7-aa65-4902-bd07-b3cf6fd79213","http://resolver.tudelft.nl/uuid:9a6694d7-aa65-4902-bd07-b3cf6fd79213","Philips oral health care: Analysis of growth drivers","Lignarolo, U.","Hultink, E.J. (mentor); Cankurtaran, P. (mentor)","2012","Philips Oral Health Care product category, embodied in the brand Sonicare, has seen seven consecutive quarters of solid growth in the period from January 2010 to September 2011. The Category delivered significant growth in key markets throughout the last two years, with strong revenue growth of over 10% in both years. Such revenue increase largely came from growth of the total market, which was driven by Sonicare in markets where Philips holds a leading position. In 2011, the brand has seen its shares growing more dramatically in key markets, with a stronger contribution to its sales growth. The objective of this study is to identify and provide understanding of the key drivers of success in the oral health care market, by capturing and quantify the impact of different factors on the business, allowing Philips Sonicare sharpen its strategies and to continue on its path of accelerated growth.","marketing mix; innovation management; business drivers analysis; strategic design","en","master thesis","","","","","","","Campus only","2013-08-03","Industrial Design Engineering","Product Innovation Management","","","",""
"uuid:3b11ac81-3d99-47cb-a8a1-2a8bf91f270d","http://resolver.tudelft.nl/uuid:3b11ac81-3d99-47cb-a8a1-2a8bf91f270d","A Geometric Approach Towards Momentum Conservation: Using design tools based on finite difference and integral methods","Toshniwal, Deepesh (TU Delft Mechanical, Maritime and Materials Engineering)","Huijsmans, Rene (mentor); Gerritsma, Marc (mentor); Delft University of Technology (degree granting institution)","2012","The equations governing fluid-flow are a set of partial differential equations, as is the case for a host of other continuous field problems. Analytical solutions to these problems are not always available and computers are unable to handle continuous representations of variables. This makes a finite-dimensional projection mandatory for all variables and this may result in a loss of information. At the same time, invoking the inherent association between physical field variables and geometric quantities, as seen in [1, 2, 3], it is known that stable discretisation schemes can be constructed. In this spirit, mimetic discretization strategies are based on minimizing the loss of information in going from a continuous to a discrete setting by making a clear distinction between exact/topological and approximate/constitutive relations in a physical law, and then focussing on an exact representation of the former and a suitable approximation of the latter. For further reading, please see [4, 5, 6, 7].","","en","master thesis","","","","","","","","","","","","Mechanical Engineering","",""
"uuid:3b1c6432-cfbf-4fec-894b-9f6b870015f5","http://resolver.tudelft.nl/uuid:3b1c6432-cfbf-4fec-894b-9f6b870015f5","Wing Shape Multidisciplinary Design Optimization","Mariens, J.","Elham, A. (mentor)","2012","Multidisciplinary design optimizations have shown great benefits for aerospace applications in the past. Especially in the last decades with the advent of high speed computing. Still computational time limits the desire for models with high level of fidelity cannot be always fulfilled. As a conse- quence, fidelity is often sacrificed in order to keep the computing time of the optimization within limits. There is always a compromise required to select proper tools for an optimization problem. In this final thesis work, the differences between existing weight modeling techniques are investi- gated. Secondly, the results of using different weight modeling techniques in multidisciplinary design optimization of aircraft wings is compared. The aircraft maximum take-off weight was selected as the objective function. The wing configuration of a generic turboprop and turbofan passenger aircraft were considered for these optimizations. This should aid future studies of wing shapes in early design stages to select a proper weight prediction technique for a given case. A quasi-three- dimensional aerodynamic solver was developed to calculate the wing aerodynamic characteristics. Various statistical prediction methods (low level of fidelity) and a quasi-analytical method (medium level of fidelity) are used to estimate the structural wing weight. Furthermore, the optimal wing shape was found using a local optimization algorithm and is compared to the results found using a novel optimization algorithm to find the global optimum. The quasi-three-dimensional aerodynamic solver was validated using experimental data and other available aerodynamic tools. Compared to the results generated by other tools, the developed solver has a wider range of validity. Most important of all, it is up to 10 times faster and the results show good agreement with other data. Several test cases were used to prove the robustness and effectiveness of the global optimization algorithm. A comparison of the different weight estimation methods indicated that the lower level fidelity methods are insensitive for some wing parameters. The results of the optimizations showed that the optimum wing shape is affected by the used weight modeling technique. Use of different weight prediction methods strongly affects the computational times and the convergence history. The global optimization algorithm was able to find the global solution for the wing shape optimization. However, the search for the global optimum comes at a cost: the computational time is significantly larger.","wing; shape; optimization; quasi-3D; multidisciplinary; MDO; locsmooth; wing weight prediction; EMWET","en","master thesis","","","","","","","","2012-08-31","Aerospace Engineering","Flight Performance and Propulsion","","Aircraft Design","",""
"uuid:35f5b670-eb0d-4a25-a4ab-ec96841bff23","http://resolver.tudelft.nl/uuid:35f5b670-eb0d-4a25-a4ab-ec96841bff23","Aerodynamic and Structural Analyses of the 5 MW Wind Turbine Using BEM and Lifting Line Theories","Gupta, V.","van Bussel, G.J.W. (mentor); Bierbooms, W.A.A.M. (mentor)","2012","Uncertainty in aerodynamic load prediction is an important parameter driving the price of wind energy and thus the wind turbine community is in need of more sophisticated tools for evaluating aerodynamic blade loading. Blade Element Momentum (BEM) theory is the current standard for estimating the wind forces in load case calculations. The predictive capability of BEM falls short for e.g. yawed flow and dynamic in flow cases and also has shortcomings in its assumptions. A physically more correct approach to model the rotor aerodynamics is presented by a lifting line method with a free vortex wake. This approach includes more physics, however the resulting computations are more time consuming. The thesis is attributed to find significant differences in predic- tion of aerodynamic performance and loads using BEM theory and lifting line theory. For this purpose ECN has modelled a state of art software, ECN AEROMODULE. The software has both BEM and lifting line (AWSM) modules. To underline the differences between BEM and lifting line (AWSM) implementation, two load cases are selected from the IEC standard and two test load cases are formulated. For all the load cases, both aerodynamic and structural analysis is done and the results are validated with FOCUS software results. FOCUS software is well developed software and is being used in wind energy industry for many years, it is based on BEM theory. Frequency analysis of the ART wind turbine is done at rated wind speed during normal operating condition to check whether the natural frequencies of blades and tower coincide with the impor- tant excitation frequencies. Aerodynamic phenomena like dynamic in flow and tower presence are studied for both the theories and the contributions of both phenomena on loading of wind turbine are also discussed.","Windenergy","en","master thesis","","","","","","","","","Aerospace Engineering","","","Sustainable Energy Technology","",""
"uuid:406c0599-bbe4-4a56-8f9f-b450a1709bd6","http://resolver.tudelft.nl/uuid:406c0599-bbe4-4a56-8f9f-b450a1709bd6","An Assessment Framework for the Speed Policy on Dutch Motorways","Kuijvenhoven, J.","Hoogendoorn, S.P. (mentor); Schreiter, T. (mentor); Taale, H. (mentor); Ludeking, M. (mentor); Annema, J.A. (mentor); Wiggenraad, P.B.L. (mentor)","2012","Today the Dutch cabinet provides in implementing a maximum speed limit of 130 km/h on Dutch motorways as much as possible. As a consequence, research is needed to the circumstances where and when higher speed limits (or maybe a dynamic speed limit) will be acceptable. In other words, what speed limit is the most optimal for a road section taking the traffic flow, the environmental targets and the safety issues into mind? In order to do the research, an assessment framework for a new speed policy is developed. With an assessment framework, the speed limit on a road section can be assessed. A more optimal speed limit can be determined, either permanent or dynamic for that road section. After finishing the research, it can be concluded in general that the road authority desires lower speed limits than currently applied and that the road user desires higher speed limits, but it is the question whether or not 130 km/h is the optimal speed limit for the road user.","optimal speed limit; variable speed limit; Rijkswaterstaat; 130 km/h","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Transport & Planning","","Transport and Planning","",""
"uuid:7c10ef88-4a73-479f-b27f-631905f4f54f","http://resolver.tudelft.nl/uuid:7c10ef88-4a73-479f-b27f-631905f4f54f","Flow Separation Control over a Wing-Flap Model: Analysis of flap leading edge applications","el Haddar, Jaouad (TU Delft Aerospace Engineering)","Scarano, Fulvio (mentor); Veldhuis, Leo (mentor); Vos, Roelof (mentor); Kotsonis, Marios (mentor); Delft University of Technology (degree granting institution)","2012","Nowadays, the development of multi-element airfoils show a progression towards a “circular arc” to attain a maximum lift force. The improvement of the high lift performance of specifically a wing-flap combination is an ongoing research at Delft University of Technology. Generally, a higher lift force can be created by deflecting the flap to higher angles. The higher this angle, the larger the curvature the flow has to follow. Consequently the flap becomes dominated by separated flow and a big part of the lift force will be lost. To overcome this lift loss due to flow separation additional flow control techniques become essential. Hence, within the scope of lift improvement, the effect of flap leading edge applications is investigated for a wing-flap model at critical flight conditions i.e. high flap deflection angle of 45◦ and Re = 1.7 · 106 (42m/s).","","en","master thesis","","","","","","","","","","","","Aerospace Engineering | Aerodynamics and Wind Energy","",""
"uuid:26809f76-fe8e-4486-b992-d6ea0f08963b","http://resolver.tudelft.nl/uuid:26809f76-fe8e-4486-b992-d6ea0f08963b","Passive Flow Separation Control on an Airfoil-Flap Model: The Effect of Cylinders and Vortex Generators","Jansen, Daniel (TU Delft Aerospace Engineering)","Bijl, Hester (mentor); Veldhuis, Leo (mentor); Delft University of Technology (degree granting institution)","2012","In the on-going search for improvements in high lift device performance, the field of flow separation control has seen explosive growth in recent years. This is due to a continuously improved understanding of fluid mechanics, the development in experimental and computational techniques and the variety of flow control mechanisms existing today. These multiple mechanisms can be differentiated into active and passive flow control techniques. In this research two passive flow separation control methods are tested on their ability to postpone flow separation on an airfoil with trailing edge flap model of the Extra EA-400. The two methods are the application of vortex generators on the airfoil and the positioning of vortex producing cylinders in the slot of the airfoil flap system.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering | Aerodynamics and Wind Energy","",""
