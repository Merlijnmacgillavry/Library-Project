"uuid","repository link","title","author","contributor","publication year","abstract","subject topic","language","publication type","publisher","isbn","issn","patent","patent status","bibliographic note","access restriction","embargo date","faculty","department","research group","programme","project","coordinates"
"uuid:f502d39b-af19-46bf-a850-dd597437dbc3","http://resolver.tudelft.nl/uuid:f502d39b-af19-46bf-a850-dd597437dbc3","Basalt to replace steel in concrete quay wall aprons: Evaluation of minibars and basalt reinforced polymer rebars to replace steel as reinforcement in quay wall aprons to reduce environmental impact.","Slegers, Ron (TU Delft Civil Engineering & Geosciences)","Jonkers, H.M. (mentor); Hendriks, M.A.N. (graduation committee); van der Ham, H.W.M. (mentor); Delft University of Technology (degree granting institution)","2022","An experimental research into the use of basalt as reinforcement in concrete to reduce the ECI value of a concrete quay wall apron. In this research experiments with basalt minibars and basalt reinforced polymer rebars are performed to compare directly to steel fibres and steel rebars. With the test results 4 designs are produced resulting in material requirements per type of reinforcement. By using these amounts of material an ECI value is determined showing that in this research basalt is an option to reduce the environmental impact. The ECI value presented in this research are in euros/year lifespan, meaning that for a different lifespan the material shows different values. Here the pros of basalt come out as the material is resistant to corrosion as it is a stone like material. Therefore in this research with a product that is placed in water, the lifespan of a steel reinforced apron could only reach 50 years where the apron with basalt reinforcement reached 100 years.","basalt; minibars; experimental research; basalt fibre reinforced polymer rebars; ReforceTech; Rutte Groep; Fibre Reinforced Concrete; fibre reinforced concrete calculations; dramix 5d steel fibres; ECI; environmental impact assessment","en","master thesis","","","","","","","","","","","","Civil Engineering | Structural Engineering | Concrete Structures","Singel, Amsterdam",""
"uuid:3c415721-9744-46ac-ab5f-b7c76922ad19","http://resolver.tudelft.nl/uuid:3c415721-9744-46ac-ab5f-b7c76922ad19","Spatial variability of leachate flow and distribution in a landfill stabilized by leachate recirculation","Feenstra, Merel (TU Delft Civil Engineering & Geosciences)","Gebert, J. (mentor); Heimovaara, T.J. (graduation committee); Bogaard, T.A. (graduation committee); Rees-White, T.C (graduation committee); Delft University of Technology (degree granting institution)","2022","Recirculation and infiltration of leachate in landfills are performed to accelerate the process of stabilizing organic matter in waste. At landfill De Kragge (Bergen op Zoom, the Netherlands), leachate recirculation and infiltration measures started in March 2018. This research aims to provide insight related to leachate flow throughout the landfill. Knowledge about the leachate flow is essential for evaluating the success of the stabilization measures. In this research, uniform and point borehole dilution tests were conducted to investigate the horizontal and vertical flow velocities. In addition, measured leachate levels throughout the landfill were analyzed. <br/><br/>The leachate levels indicated perched leachate zones: above the basal drainage system and below the injection drains at the top. Leachate injected through the infiltration drains cannot efficiently infiltrate the waste body, and the effects of the infiltration events were not picked up in the wells and piezometers throughout the landfill, implying little hydraulic connectivity. <br/><br/>The results of the dilution tests indicated horizontal and vertical flow within the landfill. Vertical velocities measured in the wells were estimated to be considerably higher (77 - 225 m/d) than the average horizontal velocities (0.02 - 1.0 m/d). The wells provide a path for vertical flow. Apart from the highest horizontal velocities measured in deeper sections of the landfill (15-18 m below ground level), velocities varied without a clear relation to landfill depth, indicating preferential flow paths. Uniform dilution tests performed with the infiltration drains turned off suggested that leachate infiltration does not increase the horizontal velocities. This research suggests that waste stabilization through recirculation is not optimal at De Kragge. <br/><br/>\noindent Due to an overall lack of understanding about the well and filter pack installation and the high spatial heterogeneity of the waste, the calculated velocities are uncertain. Further research into possible error sources (e.g., the borehole correction factor) is recommended. Additional tracer tests, including tests on the neighboring compartment without stabilization measures, are recommended to further assess the effectiveness of the recirculation system.","Landfill; Leachate flow; Leachate distribution; Leachate recirculation","en","master thesis","","","","","","","","","","","","Geo-Engineering","",""
"uuid:fe97ff6e-4080-4afe-81a6-7607fb5ade5b","http://resolver.tudelft.nl/uuid:fe97ff6e-4080-4afe-81a6-7607fb5ade5b","Quantifying sensitivity of aerosol-cloud interactions to atmospheric state through cluster analysis","Kroese, Willem (TU Delft Civil Engineering & Geosciences)","van Diedenhoven, B. (mentor); Glassmeier, F. (mentor); Hasekamp, O. (graduation committee); Schleiss, M.A. (graduation committee); Delft University of Technology (degree granting institution)","2022","Cloud droplet number concentrations change due to perturbations in aerosol concentrations. The strength of this correlation covaries with meteorology. Using polarimetric aerosol estimates and MODIS-2 cloud retrievals we compute the interaction strength per meteorological regime, which we determined using clustering techniques on MERRA-2 reanalysis data. The clusters that were found are similar to other clustering studies. The clusters are however not well-separated. The resulting interaction strengths are slightly higher compared to previous satellite studies. The clusters which show large scale vertical movement, generally have higher interaction strengths.","Aerosol-Cloud Interactions; Clustering; Atmosphere; Radiative Forcing","en","student report","","","","","","","","","","","","Geoscience and Remote Sensing","Additional Master Thesis",""
"uuid:03ddcd90-1b89-44b2-8a5d-ca4bc8a32d5e","http://resolver.tudelft.nl/uuid:03ddcd90-1b89-44b2-8a5d-ca4bc8a32d5e","Non-Modal Growth Induced by Discrete Roughness Elements in a Swept Wing Boundary Layer: Modelling and Diagnostics","Sequeira, Aaron (TU Delft Aerospace Engineering)","Kotsonis, M. (mentor); Zoppini, G. (graduation committee); Westerbeek, S.H.J. (graduation committee); Delft University of Technology (degree granting institution)","2022","Laminar-to-turbulent boundary layer transition on the wings and stabilizers of aircraft leads to a large increase in the skin-friction drag they experience during flight. This has motivated prolific research into understanding and delaying the transition process, in an effort to improve the economic and ecological impact of air travel. The swept wing poses a particular challenge to this, as the transition scenario in flight is typically governed by the growth and breakdown of stationary crossflow instabilities (CFI). These are destabilized by flow conditions that would suppress instabilities on straight wings, such as Tollmien–Schlichting waves, complicating the use of laminar flow control techniques. Previous research has shown stationary CFI to be highly receptive to surface roughness, with the use of discrete roughness elements (DRE) having emerged as a forcing/control strategy. However, the mechanisms behind which DRE condition the onset of CFI in a swept wing boundary layer are still a topic of ongoing investigations. <br/><br/>The research presented in this Master thesis aims to further characterize the relation between the DRE forcing configuration and the onset of swept wing boundary layer instabilities, through an investigation of its wake flowfield. The DRE wake has previously been observed to be highly non-modal in nature, limiting the use of modal linear stability theory in predicting stationary disturbance evolution in the element vicinity. To address this, a linear, non-modal, parabolized stability framework is derived, capable of simulating transient growth within the DRE wake region. The numerical framework is initialized with experimental DRE wake data from a previous study, for a DRE array of critical forcing height. The predicted stability characteristics qualitatively agree with experiment, with the numerical solver successfully evolving the stationary DRE wake structure into stationary CFI downstream of the array. However, a quantitative match with experiment could not be attained. The results were also noted to be sensitive to the choice of initial conditions, as well as to the numerical discretization. <br/><br/>In addition to the stationary numerical simulations, hot-wire anemometry measurements are conducted at the TU Delft low turbulence wind tunnel, providing a first-time experimental characterization of the evolution of unsteady disturbances in the DRE wake for a swept wing boundary layer. Regions of high fluctuation intensity are observed to be localized around the top and sides of each element in the DRE array, with their spectral characteristics associated to circular cylinder shedding. For a critical DRE forcing, the evolution of the wake flow is largely governed by the stationary structures, although unsteady disturbance energy is observed to undergo a brief period of transient energy amplification. A super-critical DRE forcing introduces strongly tonal fluctuations into the DRE wake, whose amplification is enhanced by interaction between the stationary structures. The high fluctuation levels are sustained and grow to non-linear amplitudes, inhibiting the relaxation of steady disturbance energy. This leads to rapid, local turbulent breakdown in the vicinity of the elements.","Non-modal; Swept Wing; Discrete Roughness; Boundary Layer Transition; Crossflow Instability; Numerical Modelling; Experimental Characterization","en","master thesis","","","","","","","","","","","","Aerospace Engineering | Aerodynamics","",""
"uuid:0c029dd0-9bbf-479a-8891-ed2e1d6ab731","http://resolver.tudelft.nl/uuid:0c029dd0-9bbf-479a-8891-ed2e1d6ab731","Towards Proactive Integration of Sustainability in Projects: A framework for integrating sustainability at the operational level of EPC contracting organization","Navandar, Aditya (TU Delft Civil Engineering & Geosciences)","Straub, A. (graduation committee); Molaei, M. (mentor); Houwing, E.J. (graduation committee); Hollestelle, Pieter (mentor); Delft University of Technology (degree granting institution)","2022","In recent years, the concept of sustainability has grown in popularity and has become a critical strategic component for businesses (Garza, 2013). Corporate organizations, as the industry's productive drivers, play a crucial role in attaining sustainable development. Thus, the problems have shifted from ""WHY"" to ""HOW"" to integrate sustainability into management decisions at all organizational levels (Epstein &amp; Buhovac, 2014). Corporate entities, such as EPC contractors, tend to realize their strategic goals and produce value for their shareholders through projects. However, for sustainability to be evident in all organizational practices, these methods must be well adapted at the operational level. Organizations are increasingly struggling to translate their strategic goals into project-specific activities (Marcelino-Sádaba et al., 2015; Engert &amp; Baumgartner, 2015). In practice, there is a significant gap between strategy formulation and project implementation (Økland, 2015). The problem addressed by this study is the gap between the formulation of strategic level objectives and its implementation at the operational level. According to researchers, integrated ways to putting sustainability into action are inadequate, and there is no systematic approach to effectively incorporating sustainability into projects (Silvius et al., 2012; Sabini et al., 2019; Epstein &amp; Buhovac, 2014). As a result, sustainability goals often remain confined at the strategic level. <br/><br/>The purpose of this research is to provide solutions to the EPC contractor to overcome the barriers to enhance the integration of sustainability in projects and bridge the implementation gap. The results will provide a structured approach in connecting high-level sustainability objectives to more concrete and tangible solutions for the project. This research is an attempt to respond to the lack of empirical studies on the implementation of organizational sustainability strategies and helps reveals how organizations can move towards translating strategy into action and overcome the barriers to sustainability implementation. <br/><br/>To achieve this objective, the research is divided into three main phases. In phase one, literature review and document review was conducted. Through literature review five elements essential for implementing sustainability strategies were identified i.e., organizational decision-making, lifecycle thinking, balancing the triple bottom line, stakeholder engagement, and proactive approach. Through document review the gap between strategic and operational level was highlighted. In the second phase, semi-structured interviews were conducted with people in the top management and project managers to identify the barriers to sustainability implementation resulting in the gap between strategic and operational level. In total 20 barriers were identified. The interviews also included understanding the application of elements identified from literature review in practice. The third and the final phase, synthesised all the findings from phase one and two, and proposed solution to the EPC company to integrate sustainability in projects. This was done by providing mitigating actions to overcome the identified barriers and proposing a framework to translate strategy into action, thus bridging the implementation gap. Using the suggested framework to make the strategy explicit has the following benefits: it encourages communication and strategy execution, allows for strategy discussion within the organization, and tracks progress toward long-term goals to determine whether the strategy is clear or needs improvement. <br","sustainability integration; project management; framework; EPC; Decision Making; sustainability strategy; operational decision-making; implementation","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:fb3380a5-710b-472b-8e39-6d3dff925e8d","http://resolver.tudelft.nl/uuid:fb3380a5-710b-472b-8e39-6d3dff925e8d","Health Care System Change Via Data Analytics To Enable Collaboration: The case of decentralised assisted living in the Netherlands","Ruijs, Luca (TU Delft Technology, Policy and Management)","Hinrichs-Krapels, S. (mentor); Slinger, J (graduation committee); Annema, J.A. (graduation committee); van den Broek, T. (graduation committee); Delft University of Technology (degree granting institution)","2022","The gap between planning and budgeting is a problem for improving health systems. In decentralisation health care services, authority, resources, and responsibilities are moved from central actors (i.e. national government) to peripheral actors (i.e. municipalities). Adding the risk of creating silos within sub-national governments, creating the need for collaboration in some form. Data analytical forecasting, like prognosis tools, may facilitate planning for health care service implementation. When operating on the interface between actors, as a boundary object, they may mitigate the risk of fragmentation and isolation associated to decentralisation, by enabling collaboration. <br/><br/>In the case of decentralised Assisted Living in the Netherlands (""Beschermd Wonen"") citizens dealing with psycho-social problems, receive guidance to participate in society. Newly responsible sub-regions have limited facilities and funds for their own citizens. <br/><br/>Newly responsible sub-regions having limited facilities and funds, may face incurring costs and inaccessible care when citizens seek to other areas due to uncoordinated implementation and elimination of facilities. To plan these, a prognosis tool was designed and developed for the three sub-regions. <br/><br/>A literature review was conducted on decentralisation of health care services globally. The prognosis tool’s technical design and development, and observations during, were studied. Analysed Interviews with actors involved in the prognosis tool, assessed if and how collaborating was enabled. <br/><br/>Lack of research on the implementation of decentralisation for health services, the use of prognosis tools for this purpose, the risk fragmentation resulting from independent processes and lack of system focus and the need for collaboration were highlighted in the literature, justifying building and testing a tool. <br/><br/>The design of the tool was therefore intentional: colour codes stimulated usability, the three sub-regions sub-files were stored in one place promoting transparency, and standardisation was stimulated by representing all sub-regions’ demands and resources into a general fitting categorisation and identical calculations from input to results for all sub-regions. <br/><br/>The tool and outcome is usable for agreements with care suppliers (procurement) or housing and enables organisation through agreements between sub-regions. <br/><br/>The meta-analysis of the interviews revealed that from the prognosis tool’s design and development, shared understanding emerged through shared language and extensive problem demarcation. <br/>An independent expert mediated the needs of sub-regions, staying close to the task. This combined with the factual outcome led to insight and clarity in the content of subregions’ own and other’s task. <br/><br/>Inducing trust and confidence in the relation and in achieving own and shared goals. Leading to tranquility and comfort, setting the atmosphere for collaboration. By clarifying the uncertainties and interdependencies, where or why collaboration is needed (the identified risk) has stimulated collaborative action.<br/><br/>This prognosis tool has enabled collaboration for decentralised health services by addressing both socio-technical aspects. The latter integrate the effected sub-systems, ensuring the outcome can be used for organising future steps (such as procurement). The former, extensive problem demarcation and shared language emerged a shared understanding of the system. In combination with the factual outcome (prognosis), insight and clarity was created into the actual need and to enable trust and comfort, enabling collaboration.","Decantralisation; Prognosis Tool; Collaboration; Assisted Living; Boundary object","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:1f5f60d8-ba5b-47f5-96eb-b61664bdd743","http://resolver.tudelft.nl/uuid:1f5f60d8-ba5b-47f5-96eb-b61664bdd743","An Indoor Localization System for Nursing Homes Based on RSSI","Boringa, Marijn (TU Delft Electrical Engineering, Mathematics and Computer Science); van Erp, Job (TU Delft Electrical Engineering, Mathematics and Computer Science); Ploumen, Corné (TU Delft Electrical Engineering, Mathematics and Computer Science)","French, P.J. (mentor); Lager, I.E. (graduation committee); Bastemeijer, J. (graduation committee); Eldering, D. (graduation committee); van Rijn, J.M.S. (graduation committee); Delft University of Technology (degree granting institution)","2022","Over the years, care givers in nursing homes have seen their workload gradually increase. With no end of this trend in sight, the need for smart support systems increases. Especially systems which decrease the time spent on menial tasks are valued highly, because this frees more time for high quality and personal care.<br/>To achieve this, Momo Medical is expanding on its nurse support system. This is a network of integrated smart solutions aiming at supporting care givers in nursing homes to provide better, faster and more personal care. The backbone of this nurse support system consists of the BedSenses, sensors which are placed under mattresses of each resident and can measure a variety of things.<br/>This thesis describes the process of designing and creating a localization algorithm for this nurse support system. This algorithm can find residents by tracking the panic buttons they wear, so that in case of an emer- gency or whenever a care giver wants to know where a resident is located, they do not need to undertake a time consuming search in order to find them. These panic buttons send out an alive signal once every minute as well as a signal whenever the button is pressed. These signals are received by any nearby BedSenses. The algorithm looks at the signal strength with which each BedSense receives these signals and uses this to per- form localization.","RSSI; localization; nursing home","en","bachelor thesis","","","","","","","","2023-12-23","","","","Electrical Engineering","Bachelor Graduation Project",""
"uuid:1f4b3824-0ecf-4086-94cb-bab3417f0dd9","http://resolver.tudelft.nl/uuid:1f4b3824-0ecf-4086-94cb-bab3417f0dd9","Access Control System Based on UHF RFID Technology","Bennebroek, Arthur (TU Delft Electrical Engineering, Mathematics and Computer Science); Ramezani, Shayan (TU Delft Electrical Engineering, Mathematics and Computer Science)","French, P.J. (mentor); Eldering, D. (mentor); van Rijn, J.M.S. (mentor); Lager, I.E. (graduation committee); Bastemeijer, J. (graduation committee); Delft University of Technology (degree granting institution)","2022","To make open door policies easier in nursing homes, it is important to have a smart system that can check whether access is allowed for the person trying to enter some place or not. This thesis documents how an access control system has been built, for Momo Medical, to be used at a nursing home. It sheds light on hardware considerations made and the software written for the final product. All the knowledge gathered and the time spent has led to a final product that with minor tweaks can be used in the existing infrastructure of Momo Medical but also without the presence of it. There are however still improvements left to be made for the final product to be commercially appealing.","","en","bachelor thesis","","","","","","","","2025-01-01","","","","Electrical Engineering","",""
"uuid:fa37352d-e960-4ec4-acbd-de490ebc211b","http://resolver.tudelft.nl/uuid:fa37352d-e960-4ec4-acbd-de490ebc211b","Combined Effects of The Electromagnetic Suspension and Frequency-Velocity Dependent Reaction Force of The Guideway on The Hyperloop Instability","WANG, Rui (TU Delft Civil Engineering & Geosciences; TU Delft Steel & Composite Structures; TU Delft Dynamics of Structures)","van Dalen, K.N. (mentor); Metrikine, A. (graduation committee); Faragau, A.B. (graduation committee); Delft University of Technology (degree granting institution)","2022","The stability analysis of electromagnetic suspension system applied to Hyperloop in simplified two degrees of freedom system has been studied deeply where the track-beam is regarded as a point mass and the effects of velocity and beam are neglected. However, there is little reference on the study of the interaction between electromagnetic suspension system and wave effects.<br/><br/>The main aim of this thesis is to investigate the dynamic behavior of the EMS vehicle-beam coupled system using the one-dimensional model, and illustrate the combined effects of the EMS and guideway on the vehicle instability at different horizontal velocity by comparing with results of EMS system in simplified model and mechanical system in one-dimensional model.<br/><br/>Along these lines, the tube is modelled as an infinite long Euler-Bernoulli beam resting on a homogenous viscoelastic foundation and the vehicle is modelled as a point mass. The response of the system is obtained both numerically and analytically. The values of control gains are determined based on the equivalent simplified two degrees of freedom EMS system. A representative mechanical system is designed to show the anomalous Doppler waves effects. It is found that for inappropriate values of control gains which will cause instability of vehicle at static state, the one-dimensional guideway has positive effects which can stabilize the vehicle at certain range of subcritical velocity, whereas for appropriate values of control gains the EMS system can counteract the wave-induced instability and keeps the vehicle stable at even supercritical velocity. Finally, a method to linearize the system is presented which allows eigenvalue analysis.<br","Hyperloop; Electromagnetic suspension; one-dimensional modelling; Instability","en","master thesis","","","","","","","","","","","","Civil Engineering","",""
"uuid:ee441703-cbff-46f8-8387-0abd1a4308a7","http://resolver.tudelft.nl/uuid:ee441703-cbff-46f8-8387-0abd1a4308a7","Towards Effective Planning and Control of Complex EPC Construction Projects","Ning, Jinghua (TU Delft Civil Engineering & Geosciences)","Bakker, H.L.M. (mentor); Jalali Sohi, A. (graduation committee); Heintz, John L. (graduation committee); Goodall, Duncan (graduation committee); Delft University of Technology (degree granting institution)","2022","Effective planning and control are crucial for the successful delivery of engineering, procurement, and construction (EPC) projects, which are characterized by complex organizational structures, interdependent activities, overlapping phases, and a large number of disciplines and participants. However, project uncertainty, including the lack of complete information and frequent changes, can lead to delays and cost overruns if not effectively managed. In this research, an integrated planning and control approach for EPC projects that addresses these challenges by combining the Last Planner System of Lean Construction and the Scrum framework of Agile Management is developed. Through a literature review and a case study of an EPC industrial construction project, six requirements for effective planning and control and mechanisms for their implementation are identified. The approach is evaluated through interviews with industry experts. The results highlight the importance of both structured planning and control for identifiable and predictable uncertainties, and flexibility and agility for unforeseen uncertainties, in managing project uncertainty in EPC projects.","Planning and control; EPC construction project; Last Planner System; Uncertainty; Complexity; Scrum","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:aa2c4b1d-7829-4030-8ce0-d2605240fd27","http://resolver.tudelft.nl/uuid:aa2c4b1d-7829-4030-8ce0-d2605240fd27","Multiplexed thermal-diffusivity-based temperature sensors","Tansel, Öykü (TU Delft Electrical Engineering, Mathematics and Computer Science)","Makinwa, K.A.A. (mentor); Muratore, D.G. (graduation committee); Delft University of Technology (degree granting institution)","2022","Due to the precise lithography and highly pure silicon used in IC technology, thermal-diffusivity (TD) temperature sensors can achieve high accuracy without the need for trimming. TD sensors employ electrothermal filters (ETFs) to measure the thermal diffusivity of silicon, i.e. the rate at which heat diffuses through silicon, which is a well-defined function of temperature. This thesis presents two approaches to improve the accuracy and resolution of TD sensors. The first approach investigates the effect of variations in ETF geometry on sensor resolution and proposes a multiplexing scheme to utilize a single readout circuit for reading out multiple ETFs. The second approach aims to investigate the effect of improvements in CMOS technology on sensor accuracy by scaling two ETFs to the 65nm process from the 180nm process. A first-order phase-domain delta-sigma modulator is designed for the readout of the ETFs in the 65nm process, and the previously designed multiplexing scheme is used for cost and time-efficient tape-out. Based on the estimated lithographic error of the 65nm process, the two ETFs are expected to achieve untrimmed inaccuracies of 0.18℃(3&#x1d70e;) and 0.36℃(3&#x1d70e;), respectively.","Electrothermal Filters; Temperature Sensor; Thermal diffusivity","en","master thesis","","","","","","","","","","","","Electrical Engineering","",""
"uuid:c8dce4a7-769b-4711-a72c-4ebbb921065c","http://resolver.tudelft.nl/uuid:c8dce4a7-769b-4711-a72c-4ebbb921065c","Development and validation of a bone quality measurement method integrated into the freehand drilling process","Roosens, Victor (TU Delft Mechanical, Maritime and Materials Engineering)","Dankelman, J. (mentor); Wei, J.C. (mentor); Schornagel, J. B. L. (mentor); Delft University of Technology (degree granting institution)","2022","b>Background:</b> Low bone quality associated with osteoporosis is an increasing health issue. The reduction in bone quality increases the risk of bone fractures and implant failure in osteosynthesis. Implant failure can be avoided by adapting the surgical procedure and postoperative care to the bone quality. This requires knowledge of the local bone quality at the implant site. Currently, surgeons can only assess bone quality based on their experience. Therefore, a routinely available and objective bone quality method is needed.<br/>This thesis aims to develop and validate a bone quality measurement method integrated into the freehand drilling process. A new bone quality score was proposed, normalised work (&#x1d45b;&#x1d44a;&#x1d45c;&#x1d45f;&#x1d458;), which can be measured during freehand drilling with a sensor module placed between the drill bit and the drilling machine.<br/><b>Methods:</b> The relationship between &#x1d45b;&#x1d44a;&#x1d45c;&#x1d45f;&#x1d458; and bone quality and the effect of drill diameter on &#x1d45b;&#x1d44a;&#x1d45c;&#x1d45f;&#x1d458; was analysed in an in vitro experiment and in an <i>in situ</i> pilot experiment. Drilling was done with a handheld surgical drilling machine and double fluted surgical twist drill bits. A sensor module was placed between the drill bit and the drilling machine to measure the axial drilling force, drilling torque, and drill position.<br/>In an <i>in vitro</i> experiment, freehand drilling was performed in synthetic bone models. Low, medium and high-density bone models were used to simulate bone quality. In addition, three drill bit diameters were used to evaluate the effect of drill diameter on the proposed quality score.<br/>In an<i> in situ</i> pilot experiment, an experienced trauma surgeon performed freehand drilling in a human cadaver’s femoral shaft and tibial plateau. The femoral shaft (cortical bone) and tibial plateau (cancellous bone) were used to simulate high and low-quality bone, respectively.<br/><b>Results:</b> The bone quality score, &#x1d45b;&#x1d44a;&#x1d45c;&#x1d45f;&#x1d458;, was calculated from the measured axial drilling force, drilling torque, and drill position.<i> In vitro</i>, &#x1d45b;&#x1d44a;&#x1d45c;&#x1d45f;&#x1d458; differed significantly between the bone model densities for all drill diameters. Furthermore, the &#x1d45b;&#x1d44a;&#x1d45c;&#x1d45f;&#x1d458; differed between drill diameters. <i>In situ</i>, &#x1d45b;&#x1d44a;&#x1d45c;&#x1d45f;&#x1d458; was significantly different between the femoral shaft and tibial plateau. &#x1d45b;&#x1d44a;&#x1d45c;&#x1d45f;&#x1d458; in the tibial plateau and femoral shaft compared well with &#x1d45b;&#x1d44a;&#x1d45c;&#x1d45f;&#x1d458; in the medium and high-density bone model, respectively.<br/><b>Conclusion:</b> The <i>in vitro </i>experiment and in situ pilot experiment showed that normalised work (&#x1d45b;&#x1d44a;&#x1d45c;&#x1d45f;&#x1d458;) is related to bone quality. This suggests that &#x1d45b;&#x1d44a;&#x1d45c;&#x1d45f;&#x1d458; can be used to detect low bone quality and develop a new bone quality scoring system. &#x1d45b;&#x1d44a;&#x1d45c;&#x1d45f;&#x1d458;, however, differed between drill bits. Future work should focus on establishing threshold values and making the bone quality score independent of the drill bit geometry. Additionally, the presented method should be evaluated in a multi-user study. Ultimately, the proposed method could routinely provide bone quality measurements to guide surgeons in surgical fracture treatment and postoperative care protocols.","Bone Drilling; Bone Quality; Orthopedic Surgery; Osteoporosis","en","master thesis","","","","","","","","2024-12-22","","","","Mechanical Engineering","",""
"uuid:ff57dc4f-5350-4ee3-ba29-42a15421cfb1","http://resolver.tudelft.nl/uuid:ff57dc4f-5350-4ee3-ba29-42a15421cfb1","Improving last-mile transport planning by nudging customer delivery windows based on a dynamic spatial customer grouping: Simulating nudging of customer delivery windows at order creation","van Mil, Jelle (TU Delft Mechanical, Maritime and Materials Engineering)","Duinkerken, M.B. (mentor); van Dooijeweert, J. (mentor); Negenborn, R.R. (graduation committee); van der Drift, M.J.G. (graduation committee); Delft University of Technology (degree granting institution)","2022","With routing algorithms approaching optimization limits, other approaches are required to further improve the last-mile delivery of goods. In this paper, an analysis is made of the effectiveness of nudging customer delivery windows at order creation dependent on a dynamic spatial grouping to improve last-mile routing performance. During this research, the focus is placed on the development of a grouping model to spatially group customers at order creation. Next to the development of a grouping model a simulation is created to analyse different customer behaviours with the use of historic order data. The grouped order data is then planned in an existing planning tool and compared to an ungrouped benchmark. The results of the tests show that nudging customer delivery windows dependent on spatial grouping improve last-mile routing performance. A grouping model which uses travel distance grouping with a grouping distance of 1000 meters currently generates the best results, but further research into customer behaviour and improving the proximity metric used could improve this performance gain even further.","Nudge; Last-mile planning; Grouping methods; Delivery windows","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Multi-Machine Engineering","",""
"uuid:f692ab5f-e4b9-4bf9-a327-3fd41aaa8740","http://resolver.tudelft.nl/uuid:f692ab5f-e4b9-4bf9-a327-3fd41aaa8740","Improving the stability of the B-spline Material Point Method: Using Extended and Truncated Hierarchical B-splines","Ruiter, Stijn (TU Delft Electrical Engineering, Mathematics and Computer Science)","Toshniwal, D. (mentor); Möller, M. (mentor); Delft University of Technology (degree granting institution)","2022","br/>The Material Point Method (MPM) is a numerical method primarily used in the simulation of large deforming or multi-phase materials. An example of such a problem is a landslide or snow simulation. The MPM uses Lagrangian particles (material points) to store the interested physical quantities. These particles can move freely in the spatial domain. Each time step, these physical quantities are projected on a background grid, which is necessary to evaluate these quantities at a future time step. Once all necessary properties are projected, the acceleration on this grid can be updated using the conservation of linear momentum. At last, this updated acceleration can be projected to the particles to compute their updated velocity, position and other quantities.<br/><br/>The main problem addressed in this thesis arises in the projection of the particles to the background grid. The use of linear basis functions in the classical MPM causes instabilities, which can be resolved by using higher order B-splines. However, another problem arises when particles move between the background cells. Since these particles move freely through the spatial domain, it is possible for some cells to by \textit{nearly-empty}. In this thesis, the use of Extended B-splines is explored to increase the stability in these areas by deactivating unstable B-splines and \textit{extending} stable ones.<br/><br/>Furthermore, higher dimensional B-splines are constructed by a tensor product of one dimensional B-splines. The scalability can be a problem, as these B-splines cannot be refined locally. Therefore, Truncated Hierarchical B-splines are introduced to locally refine a geometry. The effectiveness of this technique in combination with the EB-splines is investigated. <br/><br/>The thesis shows that the use of EB-splines in the context of MPM increases the stability in the case of nearly-empty cells, and can also improve the quality of the solution near the boundary. Furthermore, in the neighborhood of high stress concentrations, the THB-splines have a similar accuracy as the regular B-splines, while drastically reducing the computational costs. In combination with EB-splines, THB-splines can be used to accurately refine a geometry in the presence of nearly-empty cells.","MPM; B-splines; THB-splines; EB-splines","en","master thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:15a6b29c-9d2e-4e34-bc45-5dd6dd330801","http://resolver.tudelft.nl/uuid:15a6b29c-9d2e-4e34-bc45-5dd6dd330801","From Data to Prediction: Vision-Based UAV Fault Detection and Diagnosis","de Alvear Cardenas, Jose Ignacio (TU Delft Aerospace Engineering)","de Visser, C.C. (mentor); Delft University of Technology (degree granting institution)","2022","Despite the camera being ubiquitous to unmanned aerial vehicles (UAVs), it has not been used for fault detection and diagnosis (FDD) due to the nonexistence of UAV multi-sensor datasets that include actuator failure scenarios. This thesis proposes a knowledge-based FDD framework based on a lightweight Long-Short Term Memory network that fuses camera and Inertial Measurement Unit (IMU) information. Camera data is pre-processed by extracting features from its optical flow. Short-Time Fourier Transform is applied on the IMU data for obtaining its time-frequency information. For training and assessing the proposed framework, UUFOSim was developed: an Unreal Engine-based simulator built on AirSim that allows the collection of high-fidelity photo-realistic camera and sensor information with the possibility of injecting in-flight actuator failures. To simulate blade damage, a Blade Element Theory (BET) model is introduced as plug-in which enables any level of blade damage simulation without costly experimental data. The BET model was validated with static test stand wrench measurements obtained at 3 levels of blade damage (0%, 10%, 25%) from a dedicated wind tunnel experimental campaign in the Open Jet Facility of TU Delft with velocities up to 12 m/s. In the presence of blade damage, at high propeller rotational speeds the BET model shows a relative error between 5% and 24%. At low propeller rotational speeds, the relative error oscillates between 15% and 75%. Results of the FDD framework trained on 5,000 simulated flights demonstrate the added value of the camera and the complementary nature of both sensors with failure detection and diagnosis accuracies of 99.98% and 98.86%, respectively.","UAV Fault Detection and Diagnosis; Sensor Fusion; Optical Flow; Short-Time Fourier Transform; Long Short-Term Memory Network; Blade Element Theory; Photo-Realistic Simulator; Unreal Engine 4; AirSim","en","master thesis","","","","","","","","2025-12-22","","","","Aerospace Engineering","",""
"uuid:88639dbd-c0c3-44a9-a4fd-f92548e79bd0","http://resolver.tudelft.nl/uuid:88639dbd-c0c3-44a9-a4fd-f92548e79bd0","Learning from Few Demonstrations with Frame-Weighted Motion Generation","Sun, Jianyong (TU Delft Mechanical, Maritime and Materials Engineering)","Kober, J. (mentor); Zhu, J. (mentor); Gienger, Michael (mentor); Peternel, L. (graduation committee); Stienen, A.H.A. (graduation committee); Delft University of Technology (degree granting institution)","2022","Learning from Demonstration (LfD) aims to learn versatile skills from human demonstrations. The field has been gaining popularity since it facilitates transferring knowledge to robots without requiring much expert knowledge. During task executions, the robot motion is usually influenced by constraints imposed by environments. In light of this, task-parameterized (TP) learning encodes relevant contextual information in reference frames, enabling better skill generalization to new situations. However, most TP learning algorithms require multiple demonstrations in various environment conditions to ensure sufficient statistics for a meaningful model. It is not a trivial task for robot users to create different situations and perform demonstrations under all of them. Therefore, this paper presents a novel concept to learn motion policy from few demonstrations through explicitly solving reference frame weights along the task trajectory. Experimental results in both simulation and real robotic environments validate our approach.","Learning from Demonstration; Few Demonstrations; Frame Weights; Data Augmentation","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Vehicle Engineering | Cognitive Robotics","",""
"uuid:06fbdb78-bcb0-47be-976a-8b39cd0f1ee8","http://resolver.tudelft.nl/uuid:06fbdb78-bcb0-47be-976a-8b39cd0f1ee8","Vibrational Analysis and Modelling of the Toyota Kinetic Seat","Gregoire, Pepijn (TU Delft Mechanical, Maritime and Materials Engineering)","Happee, R. (mentor); Desai, R.R. (graduation committee); Cvetković, M. (graduation committee); Delft University of Technology (degree granting institution)","2022","","Vibration; Comfort; Kinetic Seat; Modelling; Posture; Automotive","en","master thesis","","","","","","","","2027-12-22","","","","","",""
"uuid:d5208c75-ea0f-4a17-9f75-96a72246204a","http://resolver.tudelft.nl/uuid:d5208c75-ea0f-4a17-9f75-96a72246204a","The Lagrangian Mimetic Spectral Element Method: Solving (non-)Linear Advection Problems with a Mimetic Method","Dekker, Joey (TU Delft Aerospace Engineering)","Gerritsma, M.I. (mentor); Delft University of Technology (degree granting institution)","2022","Advection is at the heart of fluid dynamics and is responsible for many interesting phenomena. Unfortunately, it is also the source of the non-linearity of fluid dynamics. As such, its numerical treatment is challenging and often suboptimal. One way to more effectively deal with advection is by using a Lagrangian formulation instead of the conventional Eulerian view.<br/><br/>This work aims to show that the Lagrangian formulation, and its underlying geometric and physical character, are fundamental in overcoming the challenges posed by (non-)linear advection. The Mimetic Spectral Element Method ensures that this geometric and physical character is kept when the equations are discretised. The advection term can then be dealt with exactly. The method is put to the test by solving the inviscid Burgers and isentropic Euler equations in one spatial dimension. The results confirm the exactness of the advection term and good overall accuracy.","Mimetic discretisation; Mimetic Spectral Element Methods; Lagrangian advection; Lagrangian Mimetic Spectral Element Method; Space-time method; Euler equations; Burgers' equation","en","master thesis","","","","","","","","","","","","Aerospace Engineering | Aerodynamics","",""
"uuid:ad243b4c-7362-41bb-abd7-e554d7b739e5","http://resolver.tudelft.nl/uuid:ad243b4c-7362-41bb-abd7-e554d7b739e5","Biological Bromate Reduction in the O3 -STEP Filter: Mechanism and Relationship with Denitrification","Deng, Tianyi (TU Delft Civil Engineering & Geosciences)","van der Hoek, J.P. (mentor); van Halem, D. (graduation committee); de Kreuk, M.K. (graduation committee); Spit, T.P.M. (graduation committee); Luimstra, V.M (graduation committee); Delft University of Technology (degree granting institution)","2022","Bromate is a possible human carcinogen that does not naturally exist in surface or groundwater bodies. Its formation mostly results from ozonating bromide-containing water during wastewater treatment or drinking water production. Bromate is difficult to remove from water due to its high solubility and low reactivity in the aqueous environment; however, some bacteria showed the ability to reduce bromate to bromide, but the mechanism is unknown. Previous studies postulated a cometabolic pathway of biological bromate reduction, a side reaction of denitrification using the same enzymes. This study investigates the biological bromate reduction mechanism with a focus on its relationship with the denitrification process.<br/><br/>Wastewater and biologically active granular activated carbon (BAC) from a methanolsupplemented pilot filter called O3 -STEP in the wastewater treatment plant (WWTP) Horstermeer, the Netherlands, were used for research. This study first measured the crucial water quality parameters at eight different heights in the filter to investigate the redox condition’s influence on biological bromate removal. After that, batch experiments were conducted to validate the findings. The filter showed the ability to remove bromate as it lowered the bromate concentration from 2.7 to 0.9 µg/L. Bromate reduction happened at all depths including the supernatant, although the redox conditions significantly changed. Decreasing nitrate and dissolved oxygen (DO) concentrations did not change the bromate reduction rate in the filter. The batch experiments confirmed that nitrate did not affect bromate reduction. However, a DO concentration of 8 mg/L led to a 50% reduced bromate reduction rate compared to anoxic conditions. Experiments with varying chemical oxygen demand (COD, in the form of methanol) concentrations showed an extensive accelerating effect on bromate reduction. This explained why the bromate reduction rate was not lower at high DO levels in the filter, as the high COD concentration promoted bromate reduction. Nitrate reduction was found to have a high positive correlation with bromate reduction in both filter and batch experiments, indicating similarities in their mechanisms. Nitrate reduction happened under highly oxic conditions. The intensive mixing of the granules in the filter may have provided alternating aeration and anoxic conditions for the enrichment of aerobic denitrifiers.<br/><br/>This study is the first study to observe simultaneous nitrate and bromate reduction under oxic conditions. Taken together, biological bromate reduction is likely to be a synergetic cometabolic process of aerobic denitrification. The robustness of the biological bromate reduction under high DO and nitrate conditions enables the O3 -STEP ® filter to steadily produce bromate-free effluents under more extreme influent conditions.","graular activated carbon filter; bromate; biological bromate removal; disinfection byproduct; denitrification; waste water treatment","en","master thesis","","","","","","","","","","","","Civil Engineering","",""
"uuid:d99451c0-fcd3-4a9a-abe4-dd870a6323cf","http://resolver.tudelft.nl/uuid:d99451c0-fcd3-4a9a-abe4-dd870a6323cf","Stability of four-body kite central configurations","Stasevičius, Simonas (TU Delft Aerospace Engineering)","Noomen, R. (mentor); van Horssen, W.T. (graduation committee); Delft University of Technology (degree granting institution)","2022","Central configurations provide the only closed-form analytical solutions of the n-body problem. All possible central configurations of three bodies have been extensively studied along with the stability of the associated periodic orbits. Stable cases have been found for the Lagrangian triangle configuration, which we see occurring with the Trojan asteroids. However, the knowledge about four-body central configurations remains limited. An explicit parameterization of a family of kite shaped four-body central configurations has recently been published. The present research investigates the stability of periodic solutions provided by these central configurations. An analytical treatment of linear stability is carried out and the eigenvalues for circular periodic orbits are calculated. This is complemented with a numerical estimation of Floquet multipliers to determine the linear stability of eccentric periodic orbits. While most of the kite configurations are found to be unstable, regions of linearly stable cases are discovered for both circular and eccentric orbits. Further, numerical simulations of the non-linear system are performed as an independent approach to validate the linear stability results. Perfect agreement with the linear analysis is found, suggesting that stable kites may be observed in the universe.","Central configurations; celestial mechanics; four body problem; Kite; Stability; Linear stability theory; Hamiltonian mechanics; many-body system; Periodic Orbits; Floquet theory","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:105abeee-6430-4eb7-b3fd-eda35add900d","http://resolver.tudelft.nl/uuid:105abeee-6430-4eb7-b3fd-eda35add900d","Designing AI projects using a reactive digital canvas","Dekker, Ruben (TU Delft Industrial Design Engineering)","Bozzon, A. (mentor); van Allen, P.A. (mentor); Delft University of Technology (degree granting institution)","2022","Supporting designers working with AI is important, yet the tools they have at their disposal are in many ways not satisfactory. The aim of this project was to design a digital canvas tool which lets designers explore AI and ML, adopt the affordances that AI and ML as a design material give, and which can be used to map out and design integrated products, services and systems (iPSSs) by not just guiding the design process but by becoming an integral part of it.","Design; Canvas; AI","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:9cf8a17f-716c-4142-a067-0b6df3a66f7c","http://resolver.tudelft.nl/uuid:9cf8a17f-716c-4142-a067-0b6df3a66f7c","Fault Damage Zone Fracture Network Connectivity: A graph theory approach towards the assessment of fault damage zone leakage risk using DFN and outcrop studies","Spaa, Hidde (TU Delft Civil Engineering & Geosciences)","Bertotti, G. (mentor); Delft University of Technology (degree granting institution)","2022","Capturing CO2 directly at industrial complexes and safely storing it in the subsurface is one of the proposed mitigation measures of climate change. One of these challenges is identifying suitable reservoirs that ensure the safe and permanent storage of CO2. Therefore, detailed integrity assessments should be performed on the caprock to accurately determine and manage the risks involved in the permanent storage of CO2 (Kaldi et al., 2013). This should include leakage risk quantification of (sub-seismic) fault zones in the primary seal (Zappone et al., 2021). This thesis aims to understand and predict the probability of caprock leakage through a fault-related fracture network. It specifically focuses on the network organisation of fault damage zone (FDZ) fracture networks and the impact of their topology on the connectivity of the fracture network. Topology, in the form of fracture node classification, has been used to determine the connectivity of fracture networks (Sævik and Nixon, 2017). However, this research points out that the connectivity of a fracture network cannot be solely determined by a linear relationship between the fracture node ratio and the connectivity. This methodology does not effectively succeed in capturing connectivity differences of different fracture networks. To research these differences, a measure of connectivity is introduced based on the graph theory concept of the giant component. In this concept, networks are connected by a certain amount depending on their  node type. By using the total length of the giant component we find the largest component ratio (LCR). This measure of connectivity and its relationship with percolation was tested using a DFN simulator. The concept of the giant component allows us to study the connectivity of various fracture networks. This is done by developing an algorithm that is based on the concept of robustness that removes fracture segments from a fracture network, which in turn enables us to find a relationship between the topology and the connectivity of the network and assess its uncertainty. From the DFN simulations and the robustness algorithm, it is found that the relationship between connectivity and topology is unique for different fracture networks. However, it was concluded that in general a fracture network significantly starts to increase in its connectivity when the average node has 1.6 edges connected to it (k). It also showed that the highest uncertainity of fracture network connectivity is present at 1.9&lt;k&lt;2.2.<br","","en","master thesis","","","","","","","","","","","","Applied Earth Sciences","",""
"uuid:52b6bd77-7e15-44ec-bcb3-ce0eda8d04a6","http://resolver.tudelft.nl/uuid:52b6bd77-7e15-44ec-bcb3-ce0eda8d04a6","Multi-parametric assessment of a scraped slow sand filter during the ripening period","Kannan, Thanisha (TU Delft Civil Engineering & Geosciences)","van Halem, D. (mentor); van der Hoek, J.P. (graduation committee); de Kreuk, M.K. (mentor); Delft University of Technology (degree granting institution)","2022","Being one of the oldest water treatment systems in the world, slow sand filters (SSFs) have played a big role in the water treatment sector due to their reliability and their effective physico-chemical and biological purification capabilities. They are still widely used as a disinfection step in many countries, especially those that do not use chlorine for disinfection. SSFs are gaining popularity in recent times, especially due to their ability to deactivate pathogens like Giardia lamblia and Cryptosordidium parvum, which have been posing significant challenges to the public drinking water systems for years.<br/>Over time, researchers have mainly focused on understanding the importance of the schmutzdecke layer of the SSFs, as it is understood that the schmutzdecke is essential for their functioning. This has limited the research done in the deeper layers of the sand bed, resulting in a lack of understanding of the activities here.<br/>The aim of this study is to investigate the physico-chemical and biological functions happening in the deeper layers of the SSF, and to determine whether parameters like nitrate, turbidity, DOC, FEEM, ATP and particle cell counts can evaluate the ripening of a scraped bed. Furthermore, the ability of these parameters to sufficiently indicate biological stability of the sand bed is to be assessed. <br/>In order to determine this, two full scale filters were sampled and analysed. One was a scraped bed and the other was a mature bed. They were also compared to judge how differently they behaved throughout the ripening phase.<br/>The results of the tests showed that nitrate, turbidity and ATP are good indicators of ripening. ATP and particle cell counts, when used in parallel, are good assessors of biological stability. FEEM also serves as a useful method to determine why the DOC concentrations in the water samples were similar for both the filter beds. ATP tests conducted on the schmutzdecke sand samples provide evidence of ripening over time for the scraped bed. Further research using parameters like iron, manganese, ammonia and oxygen is required to strengthen the understanding of the workings of the deeper layers of the sand bed and the various physico-chemical and biological mechanisms happening within.","","en","master thesis","","","","","","","","","","","","Civil Engineering | Environmental Engineering","",""
"uuid:08e19ab4-a89e-4bf9-80ab-663135a132de","http://resolver.tudelft.nl/uuid:08e19ab4-a89e-4bf9-80ab-663135a132de","Accelerating the growth of start-ups in the Smart City Entrepreneurial Ecosystem: an empirical analysis of the Brainport Smart District (BSD) in Helmond, the Netherlands","DAI, Yuxin (TU Delft Civil Engineering & Geosciences)","Hoppe, T. (mentor); Noori, F. (Negar) (graduation committee); Schraven, D.F.J. (graduation committee); Delft University of Technology (degree granting institution)","2022","Smart City has become one of the most popular topics in recent years due to the emergence of innovative digital technologies. Start-ups have been active in an innovation system defined as Smart City Entrepreneurial Ecosystem (SCEE) in this study, where stakeholders in the Smart City industry are involved and interact with each other, including start-ups, government, industry players, knowledge institutions, citizens, etc. It is observed that start-ups have encountered the “valley of death” problem in their early development stage with limited commercial resources such as funding, unstable customers, brandings, etc. Hence, it is imperative to research the SCEE and figure out how to help start-ups address these problems by strengthening favourable interactions with other actors in the ecosystem. Since little research has been done on the development and analysis of SCEE, this study aims to develop a theoretical framework of SCEE with the systematic literature review and apply it to analyse the case of Brainport Smart District (BSD) by using Social Network Analysis. The developed theoretical framework consists of sixteen groups of actors under four main categories (i.e., government, academia, industry, and society) and ten types of interactions. As for the social network results, the social network of SCEE is relatively condensed; its diameter is 3, the average clustering coefficient is 0.622, and the average path length is 1.697. Start-ups/SMEs, the local management team of BSD, users &amp; consumers, and software &amp; hardware infrastructure providers are the key players with high values in terms of degree centrality, betweenness centrality, closeness centrality, and eigenvector centrality. When it comes to interactions, most interactions happened between start-ups and actors in the government and industry. And there is also a self-loop in the social network of the SCEE in BSD, which means that start-ups are interacting with other start-ups in the ecosystem. Identifying key actors will be helpful for policymakers or other actors to make strategic decisions to improve the SCEE and create a better environment for start-ups to thrive and grow. The analysis of interactions provides guidance on how to improve the current interactions between start-ups and other actors and points out what interactions are lacking in the ecosystem. This study not only fills in the knowledge gap in the development and analysis of SCEE and benefits scholars interested in this field but also can be adopted by policymakers and practitioners to improve the whole ecosystem and stimulate entrepreneurship and innovation in smart cities.","Smart City; Entrepreneurial Ecosystem; innovation; Entrepreneurship; Startup; Social Network Analysis","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:a86873fd-a440-4c2b-b7d8-00febbe52d20","http://resolver.tudelft.nl/uuid:a86873fd-a440-4c2b-b7d8-00febbe52d20","Do signals interact? A machine learning approach to study the multi -signal environment of Initial Coin Offerings","Wever, Job (TU Delft Technology, Policy and Management)","Roosenboom-Kwee, Z. (mentor); Ralcheva, Aleksandrina (graduation committee); van Cranenburgh, S. (graduation committee); Delft University of Technology (degree granting institution)","2022","","Initial Coin Offerings; Machine Learning; Entrepreneurial finance; Signaling Theory","en","master thesis","","","","","","","","2024-02-01","","","","Management of Technology (MoT)","",""
"uuid:0693b238-a933-4a4a-83a3-9b36b81af12f","http://resolver.tudelft.nl/uuid:0693b238-a933-4a4a-83a3-9b36b81af12f","5G Deployment: Initial Startup and Long-term Migration Plan","Ye, Chang (TU Delft Electrical Engineering, Mathematics and Computer Science)","Van Mieghem, P.F.A. (mentor); Noldus, R.A.C.J. (mentor); Delft University of Technology (degree granting institution)","2022","Since the first introduction of 4G in the early 2010s, mobile data traffic has increased significantly, mainly because 4G networks can support more devices, services and applications, as well as greater cellular network coverage. With the advent of the 5G era, the mobile communication system will be further developed. Today, most countries and regions are already implementing their own 5G plans. Compared with China, South Korea and the United States, the three leading countries in the 5G market, the EU’s 5G plans are relatively slow.<br/><br/>The focus of this thesis is to explore various 5G deployment and migration options, as well as the current 5G status in different countries and regions. We start with current network technologies, compare and analyze various 5G deployment and migration options. Then we compare the 5G status of the EU with China, South Korea and the United States, and analyze the internal and external factors faced by the EU in the development of 5G. In these two analysis, we will consider several communication services that are currently used in the mobile network, including, but not limited to, voice/video calling and messaging, for both home usage and roaming usage. Finally, based on the above two analysis, suggestions for EU operators in 5G deployment and development are provided, along with recommendations for future research.","5G; deployment option; migration path; 5G service","en","master thesis","","","","","","","","","","","","Electrical Engineering | Wireless Communication and Sensing","",""
"uuid:4290dd28-bbde-4707-9780-46441a04e2b7","http://resolver.tudelft.nl/uuid:4290dd28-bbde-4707-9780-46441a04e2b7","Behind the Botnet: Evaluating Avalanche's security controls using a reconstruction of its anatomy from forensic evidence","Miedema, Fieke (TU Delft Electrical Engineering, Mathematics and Computer Science)","van Wegberg, R.S. (mentor); van Eeten, M.J.G. (graduation committee); Smaragdakis, G. (graduation committee); Delft University of Technology (degree granting institution)","2022","How did Avalanche, a botnet with an active lifetime of 8 years while serving 20+ malware families, ensure a smooth operation of business? Avalanche had the attention of security researchers and law enforcement, yet it managed to persevere for a long period of time.<br/>In this work, we answer this question by analyzing Avalanche’s security controls and its business model based on longitudinal ground truth data from its criminal investigation by German law enforcement. We first analyzed previous botnet research and identified five research challenges: (1) the botnet phenomenon keeps evolving, so continuous research is required, (2) there is not yet a framework to categorize or interpret botnet evasion techniques, (3) botnet research is challenging due to the lack of large real-world datasets, (4) botnet takedowns are challenging and costly, so other avenues for intervening in botnets should be explored, and (5) more research is being done into botnet economics, but it is mostly based on case studies methodologies without access to ground truth data.<br/>We defined the adversarial context of botnets and showed how their responses – evasion techniques – can be interpreted as security controls according to deviant security theory. We created a framework for categorizing these security controls, based on security control types and the type of threat. Turning to our data, we performed an exploratory analysis in which we processed, validated and interpreted the available data based on their different types: server images, network data and databases. Based on the insights from this analysis, we applied the business model canvas and described Avalanche’s business model. We describe how Avalanche provides it customers with proxying and domain registration services, generating on aver- age $7,500 of revenue per month from 59 customers. We identified seven security controls, three technical controls and four administrative controls, that were applied to evade detection, to increase resilience against takedowns and to conceal the ownership by the botnet operators.<br/>Our findings show that Avalanche configured itself to adequately respond to the threats in its adversarial context. Its business model – through using different key partners and many replaceable resources – and its application of security controls – such as backups, bot monitoring and proxy architecture – created redun- dancy in Avalanche’s operation, allowing it to detect and resolve threats quickly.","botnet; Deviant Security; Business Model Canvas","en","master thesis","","","","","","","","","","","","Computer Science | Data Science and Technology","",""
"uuid:851aa0e5-be8a-4aa6-ac91-7eb4720b8257","http://resolver.tudelft.nl/uuid:851aa0e5-be8a-4aa6-ac91-7eb4720b8257","Design for reducing the food waste of the TUDelft banquet service","Yang, xiaonan (TU Delft Industrial Design Engineering)","Schifferstein, Hendrik N.J. (mentor); Cankurtaran, P. (mentor); Delft University of Technology (degree granting institution)","2022","In the past decade, food waste has accepted intensive attention from society. It is increasingly acknowledged that approximately one-quarter of the food for human consumption is wasted throughout the food supply chain (Papargyropoulou , 2014). At the Delft University of Technology, It organizes a vast meeting every day in different facilities. The banquet service with the company of Cirfood would be the food supplier to provide the lunch for the guests during the meeting. Typically, the orderer needs to book the food from the “Banque” website, the official and only platform that merely offers the food for the Delft University of Technology.<br/>In contrast, it must go through a long journey from booking the food to disposing of the food with conference organizers, the secretariat who is also the orderer, and the Cirfood caterer in a different stage. The project figures out the workflow of the banquet service and understands the problems of different stakeholders that meet during the process that cause food waste. The design solution achieved the vision: I envision a seamless banquet service aiming to help the organizers, orderers and audience collaborate to reduce food waste. The project ends with the holistic banquet service concept, which integrates with the website, APP, and packages to apply numerous design interventions for multiple stakeholders to meet their value towards collaborating to reduce food waste. In addition, validation has proven that the new service concept could achieve the goal of the design vision.<br","Food Design; Service design; User experience design; Sustainability; Seamless; Food & Eating Design Lab","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:821aa502-5e1b-467b-a772-9c334a26f98a","http://resolver.tudelft.nl/uuid:821aa502-5e1b-467b-a772-9c334a26f98a","Wrinkle direction detection and its application on robotic cloth wrinkle removal","Qiu, Yulei (TU Delft Mechanical, Maritime and Materials Engineering)","Zhu, J. (mentor); Kober, J. (mentor); Gienger, M. (mentor); Wiertlewski, M. (graduation committee); Delft University of Technology (degree granting institution)","2022","Deformable Object Manipulation (DOM) is an important field of research as it contributes to practical tasks such as cloth handling, cable routing, surgical operation etc. The sensing in DOM is now considered as one of the major challenges in robotics due to the complex dynamics and high degree of freedom of deformable objects. One challenge is to find a suitable representation with low dimensionality and reliable accuracy. The aim of this thesis to develop an algorithm to represent the state of the deformable objects like cloth in low-dimensional vectors, together with a framework based on visual servoing to flatten cloth-like objects. We present a novel pipeline for cloth flattening, which determines a stretching direction (in 2D vector) and an operation point for the robot to removes the wrinkles. The performance of the perception algorithm is validated in simulation and real-world experiment. The whole framework is evaluated in the real-world experiment, which is compared with a human operator. The results show that our framework efficiently determines the direction of wrinkles on the cloth in the simulation as well as the real robot experiment. Besides, the proposed framework has a good performance close to that of a human operator in terms of cloth flattening tasks.","Deformable object manipulation; Cloth manipulation; Visual Servoing","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Vehicle Engineering | Cognitive Robotics","",""
"uuid:8da01924-920a-42ce-826c-30df9b5c770c","http://resolver.tudelft.nl/uuid:8da01924-920a-42ce-826c-30df9b5c770c","Damping Analysis of Reset Control Systems: an Analytical Approach","Vanderbroeck, Mees (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Precision and Microsystems Engineering; TU Delft Mechatronic Systems Design)","Karbasizadeh, Nima (mentor); Hassan HosseinNia, S. (graduation committee); Boskos, D. (graduation committee); Delft University of Technology (degree granting institution)","2022","The high-tech industry continuously pushes the boundaries of controller performance to achieve faster and more precise machines. Currently, linear control is the standard in the industry. These controllers suffer from the waterbed effect and Bode's phase/gain relation, which impose inherent limitations on the precision and robustness of the system. Reset control is a popular strategy to get around these limitations and improve performance. The damping in reset control systems is not only determined by the phase margin of the system but is also dependent on the exact controller element sequence. Currently, finding the optimal controller sequence is done through simulation of the step response. However, this fails to provide insight into the underlying cause of the additional damping achieved by specific controller configurations. This thesis proposes an analytical approach to analyze the damping of the transient response reset control systems. The analytical analysis provides a better understanding of sequence-dependent damping and assists in controller design. First, the analytical expressions of the step response and states of the system are derived, which are used to define the system's energy. The step response and energy equations are used to characterize the damping in a reset control system. To show the value of the proposed method, the damping in a reset control system is assessed as an illustrative example. It is found that when a lead is in front of a reset element, the reset controller can provide more damping because it reduces the oscillatory content in the step response.","Reset control; Transient response; Nonlinear control; Damping","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Mechatronic System Design (MSD)","",""
"uuid:6750d185-c52c-4ad0-9fd2-0eb32f374ce7","http://resolver.tudelft.nl/uuid:6750d185-c52c-4ad0-9fd2-0eb32f374ce7","Potential of the E-Pusher as Transport Mode in the Dutch Carbon Capture and Storage System","Blom, Maikel (TU Delft Civil Engineering & Geosciences)","Schott, D.L. (graduation committee); Vleugel, J (mentor); Beelaerts van Blokland, W.W.A. (graduation committee); Garg, V. (mentor); Everts, P.C.N. (graduation committee); Delft University of Technology (degree granting institution)","2022","Carbon Capture and Storage (CCS) is considered an essential solution to reaching climate goals. The two main identified transport modes in CCS, pipelines and ships, are widely compared to each other in the literature. This research contributes to the literature about the evaluation of transportation modes in CCS chains, by determining to what extent electrified ships can play a role in CCS. This is not studied before. This research is executed by following the Systems Engineering approach, in particular the SIMIE process. In a proposed point-to-point network for onshore transportation, mainly general diesel-propelled barges would perform with the lowest costs per ton, whereby the distance ranges from 25 km up to 250 km. As longer the distances, more Tank-to-Wheel (TTW) emissions savings could be obtained if barge transport is electrified. Identifying the most accurate emissions reporting method and performing operational validation for modelling the transport modes and trajectories could provide the obtained results with more scientific and practical robustness.","carbon capture and storage; Systems Engineering; TTW emissions; Transportation","en","master thesis","","","","","","","","2023-06-22","","","","Transport, Infrastructure and Logistics","",""
"uuid:be10b0a2-2826-4b2d-8865-6519cf628776","http://resolver.tudelft.nl/uuid:be10b0a2-2826-4b2d-8865-6519cf628776","To Err Is AI! Debugging as an Intervention to Facilitate Appropriate Reliance on AI Systems","Bharos, Abri (TU Delft Electrical Engineering, Mathematics and Computer Science)","Gadiraju, Ujwal (mentor); He, G. (graduation committee); Houben, G.J.P.M. (graduation committee); Cavalcante Siebert, L. (graduation committee); Delft University of Technology (degree granting institution)","2022","Powerful predictive AI systems have demonstrated great potential in augmenting human decision-making. Recent empirical work has argued that the vision for optimal human-AI collaboration requires ‘appropriate reliance’ of humans on AI systems. However, accurately estimating the trustworthiness of AI advice at the instance level is quite challenging, especially in the absence of performance feedback pertaining to the AI system. In practice, the performance disparity of machine learning models on out-of-distribution data makes the dataset-specific performance feedback unreliable in human-AI collaboration. Inspired by existing literature on critical thinking and explanation-based human debugging, we propose the use of debugging an AI system as an intervention to foster appropriate reliance. In this paper, we explore whether a critical evaluation of AI performance within a debugging setting can better calibrate users’ assessment of an AI system and lead to more appropriate reliance. Through a quantitative empirical study (N = 234), we found that our proposed debugging intervention does not work as expected in facilitating appropriate reliance. Instead, we observe a decrease in reliance on the AI system after the intervention — potentially resulting from early exposure to the AI system’s weakness. We explored the dynamics of user confidence to help explain how inappropriate reliance patterns occur and found that human confidence is not independent of AI advice, which is potentially dangerous when trying to achieve appropriate reliance. Our findings have important implications for designing effective interventions to facilitate appropriate reliance and better human-AI collaboration","explanation-based human debugging; appropriate reliance; human-ai collaboration; crowd computing","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:80b3460c-8c87-497f-8868-a9fa579c2f4b","http://resolver.tudelft.nl/uuid:80b3460c-8c87-497f-8868-a9fa579c2f4b","Guidelines for the process design of operational concepts for railway innovation: A case study for NS","van Wijk, Christine (TU Delft Technology, Policy and Management)","Annema, J.A. (mentor); de Bruijne, M.L.C. (mentor); Delft University of Technology (degree granting institution)","2022","Technological developments in the field of digitalisation, automation and sustainability are moving fast in road transport. Without innovative developments in the railway sector, the competitive position of the sector will deteriorate. For this reason, the rail sector must innovate at a faster pace to remain competitive. Also, it is expected more rail capacity will be needed in The Netherlands to meet the expected increase in passenger demand. However, expansion of rail infrastructure is often geographically impossible, costly and realisation is time-consuming. Solutions based on new technical possibilities are necessary to innovate on the current rail network. In order to respond to the need for development, Nederlandse Spoorwegen (NS) started the a research programme in 2019. Also, looking at literature, the need of having operational concepts is already emphasised, but there is a scarcity in literature regarding the development process for operational concepts for railway innovations.<br/>Following the case-study approach, this research aims to learn from two railway innovation projects in practice and to improve the lack of understanding and tools available on the topic of operational concept development for multi-actor railway innovations. This is done by designing a conceptual framework that captures the key elements to include in the process to develop operational concepts. This results in the following main research question: <br/><br/>What are key elements to consider with regard to the process design of an operational concept for technical operational transformation railway innovations? <br/><br/>The current state of knowledge regarding the design of operational concepts for railway innovations is first determined through a literature review. As a result, the need and added value of an operational concept as a tool for large-scale multi-actor innovations is made clear. Developing operational concepts for railway innovation projects adds value in three dimensions. First, by creating a shared vision of the project between all stakeholders to prevent a diversity in expectations. Second, by reaching alignment between the innovation and its environment to ensure effective implementation of the operations strategy within the innovation environment. Third, by reducing future risks. By developing operational concepts, striving to identify and define concept elements early on can help to avoid costly mistakes and future hurdles. <br/>To add empirical knowledge about operational concept development to the theoretical foundation from literature, two case-studies are conducted. The case data is compared and confronted to literature. Based on this comparison and theories from literature, a conceptual framework is developed. By abstracting the key elements included, the framework relates the research findings to broader fields of knowledge than the specific cases selected for this research. To make the framework useful for future innovation projects, guidelines for the process design of operational concepts for technical operational railway innovations are generated. The set of guidelines are:<br/>1. Develop a strategy that captures when and how project awareness is created. <br/>2. At some point, offer the possibility for commitment for stakeholders that have an interest in <br/>decision-making. <br/>3. Honour crucial company bodies and work from their perspective on the concept from the <br/>beginning of the project programme. <br/>4. Go through the framework elements in parallel for progression. <br/>5. Work towards intermediate goals. <br/>Taking in account the set of guidelines may help in achieving openness, protection of stakeholder core values, progress and substance in the process management for the development of operational concepts. The research provides an approach to get a grip on the complex development process of operational concepts for technical operational transformation projects in the railway sector.<br","Innovation; Railway; Operational concept; Process Design","en","master thesis","","","","","","","","2028-01-28","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:fbdd94fd-ff8d-4c44-a979-16f9c5ba99e0","http://resolver.tudelft.nl/uuid:fbdd94fd-ff8d-4c44-a979-16f9c5ba99e0","Machine learning study on performance prediction of asphalt mixtures under Dutch conditions","Mota Lontra, Bernardo (TU Delft Civil Engineering & Geosciences)","Anupam, K. (mentor); Erkens, S. (graduation committee); Nunez, Alfredo (graduation committee); Moenielal, Mahesh (graduation committee); Delft University of Technology (degree granting institution)","2022","The Netherlands is a northwestern European country. The location makes the Netherlands an important entry for trade to the European continent resulting in high traffic intensities [1]. The Netherlands has one of the densest road networks in the world, having over 139.000km of roadways [2, 3]. The understanding of the link between the functional properties and the behavior of the road is crucial [4]. However, predicting such properties is still challenging, and expectations differ from the results found in the field [5, 4]. Data-driven approaches have been part of pavement engineering for decades and have shown to be a powerful tool for performance prediction [6]. This thesis aims to develop a machine learning framework for predicting stiffness, fatigue resistance, resistance to permanent deformation, and water sensitivity. Along with sensitivity analysis to understand the deviations from expectation. The objective is to develop a framework to understand the applicability of machine learning tools and the impacts of the composition parameters into the mix. The models developed applied three different machine learning tools for regression: Support Vector Machine, Random Forests, and Gradient Boosting. The models were compared to a statistical model to validate the work. The statistical approach was a Multiple Linear Regression. All developed models used the database from the NL-LAB project. The machine learning models were compared, and the best-performing proceeded to a sensitivity analysis. The sensitivity analysis used SHAP values, which derive from the Games Theory and have shown to be powerful tools for complex model interpretability [7]. The models had good accuracy prediction. For most properties, machine learning had a higher performance than the statistical model. Gradient Boosting performed the best from the machine learning tools and was selected to finalize the research. The sensitivity analysis had good results, confirming some of the expectations and setting a precedent for researching others.","Machine learning; pavement engineering; performance prediction; statistical analysis; gradient boosting","en","master thesis","","","","","","","","","","","","Civil Engineering | Structural Engineering","NL-Lab",""
"uuid:ceccbcdc-90e6-4bfd-ab9f-9b5b05d7f539","http://resolver.tudelft.nl/uuid:ceccbcdc-90e6-4bfd-ab9f-9b5b05d7f539","Addressing The Potential of Alternative Configurations for CO2ER Supply Chains","Yska, Stijn (TU Delft Technology, Policy and Management; TU Delft Energie and Industrie)","Ramirez, Andrea (graduation committee); Pérez-Fortes, Mar (mentor); Maknoon, M.Y. (graduation committee); Delft University of Technology (degree granting institution)","2022","As global climate change concerns intensify, the search for renewable-based alternatives to products and processes that rely on fossil fuels becomes ever more important. A process that has been championed is the co-electrolysis of carbon dioxide and water, under the supply of renewable energy, via high-temperature solid oxide electrolyser systems. The technological combination can produce syngas directly. This syngas is a renewable-based alternative to fossil-based syngas, which has a widely established market and can directly be used for the generation of energy in power plants, or as a precursor for the production of carbon-based chemicals and fuels. Although many technology-specific improvements have been made in recent years that contributed to the creation of a promising outlook and an increasing number of demonstration projects, the feasibility and implications of implementing the process on an industrial scale remain largely unaddressed. Since many technologies fail in the transition from benchtop to industrial scale, a deeper understanding of the requirements that are opposed at an industrial scale should be obtained, to this end, this work applies an exploratory research approach to investigate the feasibility and opportunities of the supply chain that supports the production of syngas via co-electrolysis. To delineate the feasibility of the supply chain, this work considers two perspectives of feasibility; (i) the feasibility of the horizontal supply chain which encompasses the requirements and availability of feedstocks, technology and process scales, and market potential, and (ii) the feasibility of the vertical supply chain which encompasses the availability of materials required for the operation of solid oxide electrolyser systems. To investigate the opportunities of the supply chain, this work considers decentralised and centralised supply chain configurations. To initiate the research the individual supply chain units that are required for the process to be operatable at industrial scales were assessed. The requirements and scales of the individual units are matched with the current and expected future scales of technologies, feedstocks and markets. From this scale match, it can be concluded that based on feedstock availability and syngas market size, it is technically feasible to completely replace fossil-based syngas with renewable-based syngas produced by solid oxide electrolyser technology. However, several aspects such as the renewable energy requirements and the number of high-temperature solid oxide electrolyser systems that are required, impose practical limitations on the large-scale rollout. The influence of these practical limitations is aggravated after an assessment of the opportunities of decentralised and centralised supply chains, as both possibilities require capital investments on the scale of 1 Billion Euros and no positive return. A smaller implementation scale was also considered, and the limitations opposed to such a scale, seem much easier to overcome, highlighting potential future research directions. To delineate the feasibility from the vertical supply chain perspective, the material requirements of solid oxide electrolyser systems and the corresponding material availability were investigated. From this investigation, it can be concluded that from a global point of view, only Gadolinium opposes feasibility limitations. However, from a European point of view, the limitations seem much more severe. Based on the findings of this work, future research should focus on detailed analyses of the potential of solid oxide electrolyser supply chains at smaller scales, as there exist many opportunities that could improve overall supply chain performance, and smaller scales oppose less severe problems.","CO2 electrolysis; Exploratory research; Supply Chain; Solid Oxide Electrolysis; Syngas","en","master thesis","","","","","","","","2023-12-21","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:a7361455-6b67-4a4e-bd84-da689e82db30","http://resolver.tudelft.nl/uuid:a7361455-6b67-4a4e-bd84-da689e82db30","Stimulating learning behaviour in integrated multidisciplinary collaborations at the TU Delft","Bennink Bolt, Sarah (TU Delft Applied Sciences)","Flipse, S.M. (mentor); Wehrmann, C. (graduation committee); de Vos, Marina (graduation committee); Delft University of Technology (degree granting institution)","2022","A shift in academia is taking place, from individual excellence towards more collaboration. Where autonomy and individuality are highly valued by scientists and the systems in which they operate, a push towards more collaboration in the scientific field in the Netherlands is inevitable. Scientific issues are becoming increasingly complex and demand a wide range of expertise and methodology in order to be solved. This necessitates not only collaboration, it requires far-reaching integration and leads to inevitable interdependency within the collaboration. To be successful, one needs to combine the knowledge available within multiple disciplines to create a solution together. In these collaborations, team learning behaviour becomes a necessary collaborative effort in order to work together effectively. <br/>In this research, team learning behaviour in multidisciplinary academic teams at the TU Delft is investigated. It focusses on integrated multidisciplinary collaborations, which include inter- or transdisciplinary collaborations and everything in between. The goal of this research is to come up with an idea that could help stimulate team learning behaviour.<br/>Through a non-systematic literature review, an extensive overview of factors that have an influence on team learning behaviour and their underlying relations is made. The factors are categorised as learning boosters and learning drainers. A diagram is used to show the complexity and interconnectedness of the influence factors on team learning behaviour. From this overview, a section was chosen to focus on, the antecedent factors. This is the section with which the TU Delft could most effectively influence the team learning behaviour of its academic integrated multidisciplinary collaborations.<br/>Through semi-structured interviews, issues were identified with the current team learning behaviour within these collaborations. These issues turned out to be spread out over three different levels. Some issues can be addressed within collaborations. Some issues are broader than a collaboration and can only be solvable within the organisation, in the TU Delft. A few issues present themself more in the whole academic field. These issues might not be solvable by the TU Delft, but they might be able to contribute. <br/>Three main themes were identified to be in the way of the collaborative effort of learning behaviour: <br/>• Low prioritisation of collaborative work due to the pull to individualistic work. This issue presented itself within the collaboration, the organisation, and the academic field.<br/>• Non-efficient collaboration activities. Within the collaboration, this is partly due to implicit communication. This results in scientists often having to spend their personal time on collaboration efforts, which could be tackled on the organisation level.<br/>• Few integrated multidisciplinary collaboration opportunities. In the organisation this is mainly visible in job and education opportunities given by inherently monodisciplinary faculties. In the wider academic field, this shows itself in fewer publication opportunities.<br/>As the result of this research, a toolset has been developed to help stimulate learning behaviour. The tools facilitates a session with people who can influence either a collaboration, the organisation or the academic field to find solutions to issues raised. The output of this session are concrete goals and action points to carry out.<br","Learning behaviour; TU Delft; Transdisciplinary learning; transdisciplinarity; transdisciplinary collaboration","en","master thesis","","","","","","","","","","","","Applied Sciences | Science Education and Communication","",""
"uuid:53b46ab2-d81a-4fa5-8497-992bccefeb5b","http://resolver.tudelft.nl/uuid:53b46ab2-d81a-4fa5-8497-992bccefeb5b","Dune vegetation classification using UAV-LiDAR point clouds","Labaar, Anna Lisa (TU Delft Civil Engineering & Geosciences; TU Delft Geoscience and Remote Sensing)","Lindenbergh, R.C. (graduation committee); Zandbergen, S.A. (graduation committee); de Vries, S. (mentor); Delft University of Technology (degree granting institution)","2022","For European Union member states, it is mandatory to assign Natura 2000 areas and regularly monitor them. Currently, vegetation mapping is done mainly manually, which is a time-consuming and expensive practise. Unmanned Aerial Vehicles (UAVs or drones), manoeuvrable vehicles with which high-resolution measurements can be done, could increase automation in this process.<br/>Combining RGB imaging from drones with Machine Learning has already shown promising results. However, RGB imaging has limitations; there should be sufficient daylight, and only the upper layer of vegetation can be monitored. The use of LiDAR could complement the use of RGB imaging due to its ability to penetrate through different layers of vegetation and due to the fact that it does not depend on light conditions. This thesis investigates the contribution that LiDAR point clouds could have in mapping vegetation in typical Dutch Natura 2000 areas, which are typically in coastal dunes.<br/><br/>In this thesis, a method is proposed to classify vegetation into herbaceous, shrub, deciduous and coniferous vegetation classes. First, a method is developed to obtain the height of the vegetation. <br/>Using the height of the vegetation, the vegetation is divided into two classes: high vegetation (coniferous and deciduous trees) and low vegetation (herbaceous vegetation and shrubs). In this way, different layers of vegetation can be classified. For the classification of high vegetation, the points from the top of a raster cell to 5 metres below the top are considered. For the classification of the low vegetation, the points in the lower 2 meters of the vegetation are considered. Features are designed that summarise the vertical distribution of points in different ways. These features are used as input to a random forest classifier.<br/><br/>Using this classification method an accuracy of 85% could be reached to classify the higher vegetation into deciduous and coniferous trees. Using the method, spatial patterns in deciduous and coniferous trees are clearly visible; however, when looking at individual tree levels, still improvements can be made. For the lower vegetation, an accuracy of 73% could be reached to divide the vegetation into classes of shrubs, herbaceous vegetation and bare ground. The method generally performed well for the shrubs, but herbaceous vegetation and bare ground still was mixed at some points by the model. For both classification algorithms, the results and behaviour of the model showed high sensitivity to the training data.<br/><br/>This study has shown the potential of the use of LiDAR in the field of vegetation monitoring, especially in areas where cameras cannot reach, where LiDAR could have added value in vegetation monitoring.","Point Cloud; LiDAR; Random Forest; UAV","en","master thesis","","","","","","","","","","","","Geoscience and Remote Sensing","","52.42005837082298, 4.605582666101285"
"uuid:017e26b5-710e-4ad1-b0ea-11628de40272","http://resolver.tudelft.nl/uuid:017e26b5-710e-4ad1-b0ea-11628de40272","Research on Ride-hailing Pricing Strategies","Cui, Kairui (TU Delft Civil Engineering & Geosciences)","Cats, O. (mentor); de Ruijter, A.J.F. (graduation committee); Delft University of Technology (degree granting institution)","2022","Compared to traditional public transport, ride-hailing makes it possible for people to get a more comfortable and faster riding experience with a higher fare. Ride-sharing fall in between the two, offering a discount at the price level of ride-hailing, yet operates with more detours and less comfortable experience. In this study, with different price levels for ride-hailing and discount rates for ride-sharing, we would like to examine the system performance of co-existence of ride-hailing, ride-sharing and public transport services. We would also like to search for an optimal solution for the ride-hailing &amp; ride-sharing company to maximize its profit. We apply ExMAS, an open-source agent-based model for ride-sharing simulation, to simulate passengers' and vehicles' behavior on a microscopic level, and acquire numbers of results. Based on our model, in the case of Amsterdam, when price level is 1.1 euro/km and discount rate is 0.4, the company could enjoy maximum profit and market share. It is also found that, when price level gets higher more people opt for the competitive mode instead, resulting in the overall profit falling significantly.","ride-sharing; ride-hailing; Agent-based model; On demand mobility","en","student report","","","","","","","","","","","","Civil Engineering | Transport and Planning","CIE5050-09 Additional Graduation Work, Research Project",""
"uuid:708fdbc7-f96a-4336-a758-692630721de8","http://resolver.tudelft.nl/uuid:708fdbc7-f96a-4336-a758-692630721de8","Assessing the viability of implementing significantly oversized holes in high strength friction grip bolted connections: Towards the increased modularity of bridge decks and ease of their replacement","Barelts, Eric (TU Delft Civil Engineering & Geosciences)","Christoforidou, A. (mentor); Pavlovic, M. (graduation committee); Kavoura, Dr. Florentia (graduation committee); Cabboi, A. (graduation committee); Delft University of Technology (degree granting institution)","2022","The development towards a circular economy has many hurdles to overcome. For the construction sector an important step in this process is the transition towards reusing structural elements. Prefabrication of elements is a significant step towards achieving this concept. However, a case where both prefabrication and reuse are limited is the replacement of bridge decks. Headed bolts are welded to the steel supporting elements and encased in grout to connect them to the concrete deck elements. This method prevents reuse of the deck elements and hinders reuse of the steel supporting elements.<br/><br/>Research and literature exists on a number of alternative shear connectors that increase the modularity of these elements. The best alternatives have a single limitation in common: the allowed deviation for the placement of the shear connectors and bolt holes is smaller than is feasibly possible. The variances of element placement during construction add up to make it incredibly hard for these low tolerance connections to be made. The bolt hole diameter can be increased to increase the deviation tolerances. The large nominal hole clearance this results in needs to be considered. This can be done by using either resin injected bolts or High Strength Friction Grip (HSFG) bolted connections. Using HSFG bolted connections is preferred due to the shorter time spent on site and minimal waste, but research on the subject is sparse.<br/><br/>A proposed HSFG bolted connection that implements significantly oversized holes, defined as bolt holes with a nominal hole clearance roughly equal to the bolt diameter, and cover plates was designed together with both a control and regular connection to compare its behaviour with. The control connection is identical to the proposed connection with the exception of its holes which are normal sized. The regular connection has normal holes and does not include cover plates. Finite Element Models (FEM) were made of these connections that were subjected to static loading in a Finite Element Analysis (FEA). Test specimens of these connections were made and subjected to fatigue loading.<br/><br/>The numerical results of the static FEA showed that the use of cover plates reduced the stiffness and slip load of the connection. The second observation was the small impact that the hole size had on the slip load when using cover plates. This small impact becomes negligible at design preload.<br/><br/>The experimental results showed that the impact of larger bolt holes increased the loss of preload by roughly 1% during both short term relaxation and fatigue loading. The effect of the bolt hole size on the slip after fatigue loading was also concluded to be negligible, but the effect of the cover plates was concluded to be detrimental.<br/><br/>It was overall concluded that the use of significantly oversized holes in HSFG bolted connections with cover plates is viable. The negative effects caused by the cover plates and required longer bolt make it preferrable for large disc springs to be used instead of thick cover plates. The viability of the concept allows for further research on the subject.<br","Bolted connection; Friction; Fatigue Loads; Steel structures","en","master thesis","","","","","","","","","","","","Civil Engineering","",""
"uuid:d26c676f-b4ed-47a5-8ed2-91adcac2fafd","http://resolver.tudelft.nl/uuid:d26c676f-b4ed-47a5-8ed2-91adcac2fafd","Design with data: Practising exploratory inquiring on data visualisation","Balakrishnan, Vignesh Balakrishnan (TU Delft Industrial Design Engineering)","Gonçalves, M. (mentor); Chandrasegaran, R.S.K. (graduation committee); Eikelenberg, Nicole (graduation committee); Delft University of Technology (degree granting institution)","2022","Intending to implement a data-enabled design approach to use this data in their creative design process, Ford established a research collaboration with the faculty of Industrial Design Engineering at the Delft University of Technology. As part of the collaboration, several lines of research were carried out, like data strategy, data visualisation, and early prototyping in the form of graduation projects. In one such work, Mellado Cruz (2021) identified that exploratory inquiring as a means to derive insights from data visualisations has great potential in supporting the creative design process. With her empirical studies, she could generate theoretical knowledge about this process; however, bridging work was needed to convert this knowledge into a practical and actionable outcome.<br/>In this project, I address the research question, ""How can exploratory inquiring on data visualisation be operationalised in the Ford design team to support their creative design process? "". I begin the process with a phase of immersion into theory and context- using published literature about exploratory data analysis,<br/>data visualisation, creativity, and design theory to obtain theoretical understanding and the thesis reports of past graduation projects. At the end of this phase, I identify three potential opportunities that can aid in implementing exploratory inquiring in Ford design teams. One of the opportunities- to conceptualise exploratory inquiring as a collaborative design method- was identified as the most feasible in terms of the scope of the project, practical and desirable for the Ford design teams. A preliminary concept method was developed based on the learnings from the literature in line with this direction. This was iteratively prototyped, tested and refined for three cycles in the design iterations phase. The version at the end of the third cycle was used to create the final deliverable- a toolkit consisting of an information booklet that helps in circulating the procedural knowledge of the method within the team to create awareness and canvasses that support the execution of the method. In the last parts of this report, I provide recommendations for future studies to tackle the limitations I faced in this project and possibly inspire new works in the area of data-enabled design.","Design methods; data visualisation; Creativity; data-enabled design","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:0ff7b5ce-c5b4-45d4-8812-57904e49b5dc","http://resolver.tudelft.nl/uuid:0ff7b5ce-c5b4-45d4-8812-57904e49b5dc","Linear State-Space System Identification for Automatic Greenhouse Climate Control","van der Lely, Lars (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Cognitive Robotics; TU Delft Team Manuel Mazo Jr)","Mazo, M. (mentor); Kober, J. (mentor); Keviczky, T. (graduation committee); Laurenti, L. (graduation committee); Delft University of Technology (degree granting institution)","2022","Over nine billion people will have to be fed fresh and healthy food in 2050 according to United Nations. This puts pressure on the horticulture sector, responsible for a large portion of the world’s food production. The literature has shown that automatic optimal control algorithms are able to make better use of resources and can even outperform growers in terms of resource efficiency.<br/><br/>While applications of automatic optimal control methods show promising results, few are made adaptive to the greenhouse-crop system, assuming the system to be time-invariant. That is, the prediction models or techniques used in the controllers are not updated to adapt better to the evolving greenhouse-crop system. This thesis sets a first step towards this on-line system adaptation: it investigates the possibility to use a linear state-space model to estimate the non-linear greenhouse-crop systems dynamics around an operating point, for the purpose of automatic optimal climate control. In this work, a linear state-space model is identified and is implemented in an automatic optimal controller based on Model Predictive Control (MPC). Moreover, a greenhouse-crop simulation is built from state-of-the-art models based on first-principles. This ground-truth simulation is used to generate data and test the proposed control method.","Greenhouse; Climate Control; Tomatoes; System Identification; MPC","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Vehicle Engineering | Cognitive Robotics","",""
"uuid:26bf5248-9efa-4f97-9db0-e79d61932ce1","http://resolver.tudelft.nl/uuid:26bf5248-9efa-4f97-9db0-e79d61932ce1","Characteristics of BioMEMS thin-film polymers: A study towards the biocompatibility","van der Voort, Silvana (TU Delft Mechanical, Maritime and Materials Engineering)","Dekker, R. (mentor); Delft University of Technology (degree granting institution)","2022","Biomedical micro-electromechanical systems or BioMEMS are microdevices with actuation or sensory function in biomedical applications. In this process, polymers are widely used as material layers. Polymers have significant advantages for applications in BioMEMS, such as low cost and ease of fabrication.<br/>The problem at the moment is the lack of information needed to compare polymers with each other in order to identify their characteristics and properties. These characteristics are particularly important for the biocompatibility of the BioMEMS. Therefore, the optical characteristics, surface characteristics, adhesion etching, and cytotoxicity are investigated. For the optical characteristics, the polymers were examined for fluorescence and transmission of light. For the surface characteristics, hermeticity (non-permeable) and wettability (hydrophilic or hydrophobic surfaces) were examined. Furthermore, adhesion and etching were studied for their (chemical) resistance. Finally, the polymers were examined for their toxicity to cells (cytotoxic).<br/>Through these tests, more information about the polymers and their characteristics has been obtained through these tests.<br/>The results of these different tests cannot be combined into a single polymer showing the best results from all tests. The fluorescence test showed that the layers of the final device are important as they can be responsible for different intensities of fluorescence. Furthermore, it was found that perminex is the most hydrophilic but may fracture in saline solution.<br/>It was noteworthy that the polymers, which are already widely used in BioMEMS applications (SU-8 and parylene-C), appeared to be the only ones to exhibit negative effects on cells (toxicity and cell growth inhibition). The other polymers tended to do significantly better there. Even though a number of properties that are important for biocompatibility were evaluated here, to ensure that the polymers and BioMEMS devices are fully compliant, testing will be required to meet the ISO standard 10993.","Polymers; BioMEMS; Fluorescence; Cytotoxicity; Hermeticity","en","master thesis","","","","","","","","","","","","Biomedical Engineering","",""
"uuid:bcc7b9b1-3c38-44cf-a14e-7c623f285475","http://resolver.tudelft.nl/uuid:bcc7b9b1-3c38-44cf-a14e-7c623f285475","A GO/PO tool for synthesizing shaped multi-surface dielectric lens antennas","Gottmer, Leila (TU Delft Electrical Engineering, Mathematics and Computer Science)","Llombart, Nuria (mentor); Dabironezare, Shahab Oddin (mentor); Neto, A. (graduation committee); Jellema, Willem (graduation committee); Delft University of Technology (degree granting institution)","2022","In this thesis, an efficient optimization method is described for synthesizing lens antennas fabricated in low permittivity plastic materials to achieve wide scanning performances. The method is based on an antenna in reception representation. The optimized parameters are the location and orientation of the antenna feeder, lens angular region and its shape by adding Zernike polynomials to standard ellipsoidal shape. The synthesized lens antennas achieve scan losses lower than 3dB while scanning up to 60°. The presented theoretical results are validated using full wave simulations. Furthermore, an efficient analysis method based on Geometrical Optics and ray tracing is developed. This method is applied to the study of multi lens Quasi-Optical structures. The presented theoretical results are validated by multi surface Physical-Optics approach.","Quasi optical systems; Lens antenna; Geometrical Optics; Ray tracing; Shaped lenses; Multi surface lens","en","master thesis","","","","","","","","","","","","Electrical Engineering | Wireless Communication and Sensing","",""
"uuid:b4cff558-72d8-4d16-a7f9-ff26a86bba22","http://resolver.tudelft.nl/uuid:b4cff558-72d8-4d16-a7f9-ff26a86bba22","Digital Distraction Barrier Design: Using Lean startup to develop an app that creates intentional friction to create conscious phone usage","Smits, Tim (TU Delft Industrial Design Engineering)","Lomas, J.D. (mentor); Keller, A.I. (graduation committee); Delft University of Technology (degree granting institution)","2022","Smartphones have revolutionized the way we live, giving us instant access to countless tools and apps (replacing dozens of single-function products), and this has made us more and more dependent on them. But there is another side, they are taking a heavy toll on our time and attention. Unpluq is a startup that aims to help people reclaim their time and attention from their smartphones and improve people's digital wellbeing. It was started by Jorn Rigter and Tim Smits (author of this graduation project). Unpluq’s first product is a physical key that users need to plug into their phone to access distracting apps. This physical distraction barrier changes using distracting apps from a mindless habit into a conscious choice. While the key acts as a successful hardware-based barrier, it is also a limiting factor in the growth of Unpluq, because of distribution and scaling. To overcome these problems this graduation project explores the development of a new software-only version of Unpluq as this opens up easy online distribution.<br/><br/>Smartphones have taken over control of our time and attention. It details how social media is hacking our primal brain because the business model behind the attention economy is driven to optimize for engagement, their advanced algorithms are designed to keep users scrolling. The reality is that the majority of the population has become addicted to their smartphone, with screen time reaching a 6-hour average each day in 2022. This leads to negative side effects like decreased mental wellbeing, attention span, self-reported life satisfaction, sleep quality, personal connection, productivity and more.<br/><br/>The project then shows the consumers' need for digital wellbeing and how this<br/>need can be addressed through the use of tools that leverage behavioural change theories through interaction design. It explores how through the “rational override” behavioural theory it is possible to break the normal flow of smartphone usage, prompting the user to reflect and take conscious action.<br/>Although 82% of people aspire to reduce their screen time, they’re struggling to do so. The built-in screen time features are too easy to circumvent, don’t change habits and miss a balance between giving up and having control.<br/>From all the gathered quantitive and qualitative research, the graduation project establishes a list of principles of “interaction design for digital wellbeing”. The principles aim to guide interaction designers on designing for healthy digital behaviour by making users conscious, providing tools, setting intentions and finding the right balance between restoration and access to digital distractions. The design process is further guided by the insights from the research phase and follows an iterative process called the “Lean startup method” in which the designer goes through 7 Build /Measure / Learn cycles.<br/><br/>The main concept of the app is based on 6 distraction barriers (shaking your phone, tapping buttons and more), which have been carefully designed to find a balance between blocking access to digital distractions, while still allowing access with the right amount of conscious effort. The barriers work in combination with schedules, which let users select what apps are distracting at what time. To access the app within this time frame the user has to go through the “distraction barrier”. The distraction barrier acts as the rational override and helps the user to make a conscious choice: “Is this time well spent?”. The distraction barriers integrate the<br/>principles of interaction design for digital wellbeing. It helps the user to make a conscious decision, balances restricting access and control and nudging towards healthier digital behaviour. The app also will include other features that are based on the principles like setting intentions, showing average screen time, time saved by unpluq, nudging notifications and suggested distracting apps.<br/>In this graduation project, it has been established that digital wellbeing tools are necessary for overall human wellbeing as we increasingly spend our time in digital environments. Products like Unpluq can help people to improve their digital wellbeing and feel in control of their devices, making sure their time is well spent. This trend will continue to grow over the coming years, when the next major personal computer innovations like VR and AR become mainstream the necessity for digital well-being will only grow.","lean startup; digital distraction; Smartphones","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:0ca35fcb-21f2-44fb-ae78-c2fe73feb894","http://resolver.tudelft.nl/uuid:0ca35fcb-21f2-44fb-ae78-c2fe73feb894","A framework for climate change adaptation strategies acknowledging transboundary governance complexity: A case study in the Geul basin","van der Steen, Jan (TU Delft Civil Engineering & Geosciences; TU Delft Water Resources; TU Delft Water Management)","Rutten, M.M. (mentor); Mostert, E. (mentor); Hrachowitz, M. (mentor); Slager, Kymo (graduation committee); Delft University of Technology (degree granting institution)","2022","On the 13th and 14th of July 2021 a cold pit caused extreme precipitation along with record discharges in tributaries of the Meuse. These discharges caused floods in Belgium, Germany and the Netherlands.<br/><br/>Extreme precipitation occurrence and its intensity are expected to increase in the area due to climate change, increasing flood risk. Flood risk is the product of hazard, exposure and vulnerability. Research indicates all three are equally important drivers.<br/><br/>Planning of adaptation measures has been done with Decision Making in Deep Uncertainty (DMDU) methods to account for deep uncertainty. These methods lack natural and institutional context. Literature suggests both the natural system and the system governing it are complex. Therefore there is a need for a method providing climate change adaptation strategies with regard for the context and the notion that these systems are complex.<br/><br/>To address the research gap, a Framework is developed that combines natural and institutional aspects of climate change adaptation. A systems approach is used to find leverage points for wider systemic change. This can be used to spark autonomous adaptation, thereby also targeting exposure and vulnerability. The Framework provides a solution space of possible adaptation combinations and maps of spatial cooperation difficulty. By combining these possible combinations and locations are proposed. Systemic leverage points determine preferential strategies and additional policies. The Framework is tested in a case study in the Geul, Methods used are expert judgment, literature review, social network analysis and using open-source information.<br/><br/>The adaptive capacity is roughly 20 millimeters equivalent (6,680,000 m3) upstream of Valkenburg and 23.6 millimeters equivalent (7,882,400 m3) in the city itself. Thousands of combinations are possible. Depending on preference, this number is severely reduced.<br/><br/>The network governing flood risk is dense and polycentric. Cooperation quality is likely not sufficient between many actors to implement very intrusive adaptation measures that would be needed according to the solution space. When a certain cooperation is required, Flanders and the Netherlands are central players in the network. Germany and France are isolated in the network, causing the national governments of those nations to hold brokerage positions. Cooperation is the hardest in transboundary subcatchments especially when multiple nations are involved.<br/><br/>Depending on the preferences in the network, several adaptation strategies are possible in the Geul. In terms of cooperation difficulty, downstream solutions located in the Netherlands are preferential. Natural solutions would be preferable to harness self-organizational capacities of nature. Strategies that would cause secondary effects by intervening deeper into the systems should be highly visible. In addition, adaptation strategies should be accompanied by policies aimed at restoring the flow of information to citizens, restore or create financial incentives for autonomous adaptation of inhabitants and alter the paradigm of manageability of nature. Delays in planned adaptation response could be shortened by network interventions such as creating a central operational role in the network, implementing binding adaptation goals using the common European legislation or improving regional cooperation.<br","climate adaptation planning; Governance; Transboundary basins; Climate strategy; Adaptive capacity; Water Resources Management; Meuse","en","master thesis","","","","","","","","","","","","Civil Engineering","Delta Futures Lab","50.86444440"
"uuid:69d2bd6e-c428-4cab-8f6d-64838a01b528","http://resolver.tudelft.nl/uuid:69d2bd6e-c428-4cab-8f6d-64838a01b528","Designing optimal investment trajectories for the energy transition of industrial clusters in the Netherlands","van Dullemen, Stijn (TU Delft Technology, Policy and Management)","Stikkelman, R.M. (mentor); Bots, P.W.G. (graduation committee); Delft University of Technology (degree granting institution)","2022","Because of the climate crisis the world is facing, all sectors must move towards a more sustainable future. In the Netherlands, the industry sector emits large amounts of CO2 because of the heavy reliance on fossil-fuels and large electricity demand. The Paris agreement and the Green Deal forces the industry sector to rapidly transition towards more sustainable practices, which can be achieved if the correct synergies are established. The multi-actor nature and the technical and operational dependencies that industrial clusters have, makes optimal decision-making extremely important in working towards that net zero future. Innovations that re- duce the emissions are limited, but they exist and provide (intermediary) solutions to adhere with the imposed regulations. Furthermore, the industrial clusters are subject to numerous different factors that influences the behaviour of actors within the cluster. The issue faced is to understand how the transition of an industrial cluster is influenced by exogenous factors and how actors in such an integrated environment should invest, while keeping in mind that both the industrial clusters and the individual actors have to remain profitable and have differing investment behaviour. Current studies fall short in identifying, analysing and understanding how multi-actors in an institutional en- vironment relate to the technical options and the exogenous factors engaging with that system in an industrial setting. Identifying an optimal investment trajectory that such an industrial cluster should follow to adhere with the regulations whilst staying profitable with a multi-actor configuration requires different integrated methods and other tools. This thesis will address that problem through the following main research question: What is the effect of multiple exogenous factors on the optimal investment trajectories of indus- trial clusters in the Netherlands with multiple investment options? This question has been answered through exploratory research combined with a modelling approach. The first step in the exploratory research required attaining insights in what the current state of is multi-actor invest- ments. This in combination with looking at how they are structured contractually has been the main foundation for the literature review. A case study analysis has been conducted of an industrial cluster located in Geleen, called Chemelot. This allowed for analysing decarbonizing investment options and looking at what exogenous factors influence the industrial cluster. The investment options attempt to move Chemelot away from fossil-fuels as energy source and move towards lower emitting sources such as electricity. The information gathered served as an input to put together a methodology which captured the exogenous factors, interactions in the industrial cluster and the sustainable investment options in an optimization model. Using this, the optimization model was constructed using Linny-R, a Mixed Integer Linear Programming op- timization software developed by Dr. P.W.G. Bots. The model produced quantifiable results as well as serve as a proof of concept for the methodology that is presented to incorporate exogenous factors and sustainable investment options in the energy transition. The model also gives insights in what effect the exogenous factors have on the investment behaviour of actors within industrial clusters by showing cash flows, both individually and collectively and through an investment curve for the cluster. The economic performance is considered to be the leading metric in this research. Finally, using the results, the implications of implementing exogenous factors and sustainable investment options in an optimization model are discussed. The research outcomes show that CCS and electrification are favourable investments for Chemelot to remain profitable and cope with increasing prices of commodities and CO2. The model results has provided insights in the effect that exogenous factors have on the energy transition of an industrial cluster. More specifically, it showed that a cap on CO2 and increasing the price of CO2 emitted really accelerates the rate at which actors make investments in sustainable options. Added to that, increasing the price of other commodities such as natural gas and naphtha also forces actors to move away from those commodities and look for alternatives that provide the same product or energy without having to compensate the CO2 emissions related to them. Other factors such as limited infrastructure restrict industrial clusters in the amount of products they can produce and restrict them from innovating towards less emitting processes. Electrification of certain processes is possible, but increases the electricity demand with enormous amounts. With limited electricity infrastructure to provide those amounts, the innovation cannot be realized and therefore, halting the transition for an industrial cluster. The findings suggest that because of these exogenous factors, the actors will move towards electricity demanding innovations that do not make use of fossil-fuels and invest in CCS options. However, the methodology presented should be used as directing future research in looking at how industrial clusters should engage in the energy transition. The dependencies existing between actors in an industrial clusters and how different investments II may adjust these dependencies are identifiable using the methodology presented in this research. Ending with a general conclusion, the investment behaviour of industrial cluster changes because of multiple exogenous factors that influence the system. The increase in commodity prices combined with CO2 capping reg- ulations cause actors to invest more quickly into sustainable investment options to adhere with the regulations, but it also causes them to compromise their production levels in some scenarios to remain profitable. Actors downstream are dependent on the investments made by actors upstream since they rely on the output of those upstream actors to develop the final products that they sale. This combination generates valuable insights from a systems perspective but also from a multi-actor perspective.","MILP; Chemelot; Energy; Linny-R; Investment behaviour","en","master thesis","","","","","","","","","","","","Complex Systems Engineering and Management (CoSEM)","",""
"uuid:a90d8bee-0b76-4b78-92c7-72207ecbadd8","http://resolver.tudelft.nl/uuid:a90d8bee-0b76-4b78-92c7-72207ecbadd8","The Future of the Dutch Environmental Testing Market","Lu, Simona (TU Delft Technology, Policy and Management)","Dolkens, T.L. (mentor); Scholten, V.E. (graduation committee); Correljé, A. (graduation committee); Delft University of Technology (degree granting institution)","2022","The environment is an important part of the life for most organisms, including humans. Since its quality is integral for social welfare, ensuring and maintaining a high environmental quality is essential. The environmental testing market is dedicated to the testing of the three main components of environment: soil, water, and air. Since the origin of the environmental testing market in the Netherlands, a rapid growth in the market, especially its soil and water markets, has been witnessed. Multiple consolidation waves has reduced the market players to a few, and the markets have become saturated and growth is stagnating. Furthermore, the Dutch environmental market is facing a two-sided challenge that could potentially disrupts its current form. The first challenge is that the high pricing and cost reduction strategies, that have been adopted because of the high competitive nature of the market, have resulted in profit margins that are not longer feasible in the current economy. Secondly, the market is at the forefront of potential disruptive change from different factors like emerging technologies, regulation &amp; policy, or the emergence of alarming substances that are potentially harmful to the environmental. These types of challenges in the Dutch environmental testing market point to a reevaluation of the business strategies of firms operating in this target market. This study was dedicated to multiple sided analysis approach of the developments in the Dutch environmental testing market. The objectives were to determine the most suited business strategy for firms in the Dutch environmental testing market to remain competitively relevant in regards to the future developments in the market, and the internal circumstances needed to support this strategy.","environmental testing market; market analysis; resource-based view; competitive advantage; regulation theory","en","master thesis","","","","","","","","2024-12-21","","","","Management of Technology (MoT)","",""
"uuid:c99017db-46d9-419d-91b0-ff4d86cb4acc","http://resolver.tudelft.nl/uuid:c99017db-46d9-419d-91b0-ff4d86cb4acc","Metasurface Antenna for Space-Based SAR","Falckenheiner Soria, Sebastian (TU Delft Aerospace Engineering)","Kuiper, J.M. (mentor); Gerini, Giampiero (mentor); Cervone, A. (graduation committee); Loicq, J.J.D. (graduation committee); Delft University of Technology (degree granting institution)","2022","Synthetic Aperture Radars (SAR) have demonstrated to be great instruments for space-based Earth observation in the microwave frequency. Metasurface antennas, on the other side, are a new type of planar antennas with a great potential for space applications, as they are compact and easy to produce. Several methods have been developed in the past years addressing one or many parts of the design and applications of these antennas, which rely in more or less measure in locally developed tools. However, some parts of these methods can take a great amount of time to implement, making this process more difficult than it should especially if the user has commercial electromagnetic simulation tools available that could accelerate this process. In this work, different procedures have been adapted to the design of a high-gain SAR anisotropic metasurface antenna for a multi-static Earth observation mission, showing that the proposed methodology produces accurate results.","SAR; Metasurface; Earth Observation; Radio frequency; Metamaterials","en","master thesis","","","","","","","","2024-12-21","","","","Aerospace Engineering","",""
"uuid:0a463a28-aefd-45b8-9990-e0d9032ef4a3","http://resolver.tudelft.nl/uuid:0a463a28-aefd-45b8-9990-e0d9032ef4a3","Design and performance of a novel concept vacuum insulation panel with a honeycomb plate-foil core","Tjeerdsma, Michiel (TU Delft Mechanical, Maritime and Materials Engineering)","Langelaar, M. (mentor); van Keulen, A. (mentor); Delft University of Technology (degree granting institution)","2022","Reducing greenhouse emissions can be achieved by better insulating buildings. However, wall thickness increases significantly if conventional insulation materials are used. Conventional vacuum insulation panels (VIPs) offer a solution to this problem. VIPs have potential, but can not compete with conventional insulation materials due to their high pricing. A new concept vacuum insulation panel is introduced by the start-up company IQ-Bizz. To what extent this concept panel is a feasible alternative to conventional VIPs is the main research question of this thesis. The concept panel consists of two honeycomb plates, an intermediate foil and an MF2 panel envelope. The panel's geometry is chosen such that heat transfer through the panel is minimal and failure of the panel does not occur. Finite element models, verified by analytical calculations, have been used for evaluating the concept panel's structural and thermal performance. A thermal performance (R-value) of 6.23 m^2K/W is evaluated for a one-centimetre thick square panel with sides of one metre. Conventional VIPs of equal size have an R-value of 2.5 m^2K/W. The global warming potential of the concept is roughly 9 kg compared to 15 kg for conventional VIPs. A conventional VIP's price of roughly 21 euros is compared to the material costs of the concept panel of 8 euros. All performance parameters of the concept panel are higher compared to conventional VIPs. However, the concept panel's thermal performance is expected to be lower, and its environmental impact and price higher. Further research is required for a better evaluation of these performance parameters. Nevertheless, this thesis shows that the vacuum insulation panel concept has promising potential.","Vacuum insulation; Thermal comfort; Insulation; Insulation performance; Feasibility assessment; Concept design","en","master thesis","","","","","","","","2024-12-01","","","","Mechanical Engineering | Mechatronic System Design (MSD)","",""
"uuid:b8ade9b6-addc-462e-9d44-94c9e5fa887e","http://resolver.tudelft.nl/uuid:b8ade9b6-addc-462e-9d44-94c9e5fa887e","Introduction to structure learning for gaussian and pair copula bayesian networks","Villar Guardia, Amadeo (TU Delft Electrical Engineering, Mathematics and Computer Science)","Kurowicka, D. (mentor); Delft University of Technology (degree granting institution)","2022","Due to technological breakthrough in recent decades and the rapid increase in the availability of multidimensional data, data science has become one of the most important areas of research. Within this field, modeling dependence of random variables is gaining great interest. To cope with this task, the use of graphical models is often advocated. In this dissertation, we study Bayesian Networks (BNs), a particular type of graphical models. Concretely, structure learning algorithms for two types of continuous BNs: Gaussian Bayesian Networks (GBNs) and Pair Copula Bayesian Network (PCBNs) are investigated.<br/><br/>We present an overview of these two types of BNs, illustrating its properties and differences. An outline of the different existing structure learning algorithms is provided, showing their efficiency for the Gaussian case and limitations for the copula based. The problems of structure learning for PCBNs are then addressed. We investigate the performance of Gaussian structure learning algorithms for PCBNs. Based on a simulation study, we show that these procedures are not completely efficient, but prove beneficial. Second, a new approximation of the score based on logLikelihood of PCBNs is explored. We propose to solve the computational inefficiency of the exact logLikelihood by estimating the necessary copulas from data such that the copula terms in the PCBNs decomposition can be computed without need of integration. A simulation study suggests that this logLikelihood approximation yields better results than the approximation used<br/>by Pircalabelu et al. (2017). Finally, an algorithm to learn the structure of PCBNs is proposed, based on the 2 previous procedures.","Bayesian Networks; Copulas; Structure Learning; Graphical Models; Graphical Lasso; Hill Climbing algorithm; PC algorithm","en","master thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:e60af234-efa1-4b7a-b17c-9dd910d15ef2","http://resolver.tudelft.nl/uuid:e60af234-efa1-4b7a-b17c-9dd910d15ef2","Examining possible improvements to non-invasively measure mitochondrial oxygen tension in a clinical device","van der Graaf, Marijn (TU Delft Mechanical, Maritime and Materials Engineering)","Mik, E.G. (mentor); Harms, F.A. (mentor); van den Dobbelsteen, J.J. (graduation committee); Delft University of Technology (degree granting institution)","2022","Background and objectives: Mitochondria require oxygen to generate energy for essential cellular processes. An in-vivo non-invasive technique to monitor mitochondrial oxygen tension (mitoPO2) is the protoporphyrin IX-triplet state lifetime technique. Protoporphyrin IX (PpIX), one of the key components of heme, is naturally present in the mitochondria. Topical administration of 5-aminolevulinic acid hydrochloride (ALA) increases PpIX concentration in the skin. After excitation with a laser pulse, PpIX emits red light with an oxygen-dependent delayed fluorescence lifetime. This signal is detected by a photomultiplier and the mitoPO2 can be derived from this. A clinical device has been developed using this technique. Although this device has been proven feasible, improvements in reliability and practicality are needed. This work aims to investigate possible improvements to the components of this device for better application in a clinical setting. The main areas of improvement are the excitation wavelength, the detection of the signal, and the light source.<br/>Excitation wavelength: First, wavelengths from 415 nm to 695 nm are explored as possible excitation wavelengths. Second, four excitation wavelengths that exhibit low noise are investigated in more detail. For a better comparison, the pulse energy per wavelength is equated. The excitation wavelengths 415 nm and 515 nm showed low noise, no oversaturation, and accurate fits. These two excitation wavelengths are then validated on three test subjects with skin types II, IV, and V on the Fitzpatrick scale. Oxygen-dependent lifetimes are obtained in all test subjects with an excitation wavelength of 415 nm.<br/>Detection: A new detector is explored to replace the large and expensive photomultiplier. The detector is tested in a fluorescent solution and on human skin. The first experiments resulted in oversaturation of the detector. To prevent this, several combinations of band-pass, long-pass, and absorption filters are tested. Even with these filters, the detector was oversaturated by the light pulse from the laser. <br/>Light source: Two light sources are investigated as possible replacements for the currently used laser. These were first tested in a 10 μM PpIX solution. No delayed fluorescence was observed because the light sources and detector could not be placed close enough to each other. Therefore, for the measurements in human skin, the light source was coupled into a fiber. Both light sources showed oxygen-dependent lifetimes, suggesting that they are suitable for this application. As a final step, related parameters were optimized to reduce oversaturation and noise. These are described in the Confidential Appendix.<br/>Conclusion: The potential of 415 nm as an excitation wavelength is demonstrated, but these results should be validated in more test subjects. The light sources showed the potential to replace the current laser, which could reduce maintenance and increase reliability. The next step should be to combine the 415 nm excitation wavelength, light source, and detector into a prototype to explore their combined potential.","Mitochondrial oxygen tension; Clinical device; Non-invasive; Protoporphyrin IX","en","master thesis","","","","","","","","","","","","Technical Medicine | Sensing and Stimulation","",""
"uuid:8d4b2b0c-0021-46f0-babe-5f228dee5395","http://resolver.tudelft.nl/uuid:8d4b2b0c-0021-46f0-babe-5f228dee5395","Proof of concept design of a black water disinfection system for on board use on recreational vessels and yachts","Veel, Lucas (TU Delft Civil Engineering and Geosciences)","van Lier, J.B. (mentor); Rietveld, L.C. (graduation committee); Lindeboom, R.E.F. (graduation committee); Delft University of Technology (degree granting institution)","2022","There are more than 160,000 recreational crafts in the Netherlands with a toilet on board. It is forbidden to discharge blackwater into the environment from these crafts. Stricter enforcement of the law by the sealing of the valves of the external drain, leaves the owners of these crafts with a major problem. It is allowed, however, to treat the blackwater on board and then discharge it if the following two boundary conditions for fecal indicators are met: a maximum concentration of 330 cfu per100 ml of Intestinal enterococci and a maximum concentration of 900 cfu per 100 ml of E. coli. The overall objective of this research was to find and test a proof-of-concept (PoC) method to reach these boundary conditions. The method consisted of a series of conventional wastewater techniques: first a coagulation and flocculation step, then the filtration and subsequent dewatering of the TSS and lastly the filtrate was disinfected using UV-C irradiation. Bench scale experimental setups were used to get the data for this research. Results demonstrated that TSS was most efficiently removed by a combination of polyaluminnium chloride and a cationic polyacrylamide copolymer with a low charge density. Furthermore, polyaluminium chloride demonstrated to be highly effective at removing the fecal indicators. Dewatering experiments proved that increasing the polymer dosage did not affect the total dry solid content of the final sludge cake. Also, under the most ideal circumstances a dry solid content of the filter cake of 30% was achieved. Lastly, UV-C experiments were conducted on the filtrates of two different samples, with values for UV254 absorbance of 1.34 cm−1 and 11.85 cm−1 respectively. The first of which was sufficiently disinfected after a total irradiated UV-C dose of 180 mJ/cm2, of which the effective dose was 54.9 mJ/cm2. The fecal indicators in the second sample were not sufficiently removed after a total UV-C dose of 1100 mJ/cm2. The absorbance of UV254 of the filtrate was so large that the effective dose was only 40.0 mJ/cm2. The PoC method showed to have potential for implementation, but adjustments need to be made to make it more sufficient and viable for use of on board disinfection of black-water. Preliminary screening can extract most of the fecal material, which is already high in dry solid content, before homogenising with the liquid fraction. The quantity of conditioning agents need to be adapted to the specific blackwater, and if necessary the pH will need to be adjusted to ensure the right coagulation mechanism for efficient TSS removal. Finally, humic matter in the filtrate will have to be reduced for UV-disinfection to be an effective treatment method. This could possibly be achieved by mechanisms such as adsorptive coagulation or by implementing an intermediate ozonation step after filtration of the TSS, which would also help in the removal of fecal indicators.","","en","master thesis","","","","","","","","2024-01-01","","","","Civil Engineering | Environmental Engineering","",""
"uuid:0ebe58d6-68e7-4a64-b64c-88328be31f40","http://resolver.tudelft.nl/uuid:0ebe58d6-68e7-4a64-b64c-88328be31f40","Using the Random-Cluster Model for Ising Model Simulations","Delboo, Maxime (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Applied Sciences)","Thijssen, J.M. (mentor); Pulvirenti, E. (mentor); van der Sar, T. (graduation committee); Dubbeldam, J.L.A. (graduation committee); Delft University of Technology (degree granting institution)","2022","This thesis contains a rigorous derivation of the path integral formulation of the Isingmodel with multiple original proofs. Besides that, thesis also contains various resultsof simulations of the 2D square lattice Ising Model with nearest-neighbour interactionsusing the Swendsen-Wang algorithm. Using finite size scaling to find critical exponentγ, we reported a value of γ = 1.748 ± 0.004. After calculating the relaxation times τ forvarious thermodynamic variables, we found the value for the dynamic critical exponentz to be in the range of z = 0.180 ± 0.004 and z = 0.282 ± 0.005.","Ising Model; Swendsen-Wang Algorithm; Random-Cluster Model","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics | Applied Physics","",""
"uuid:3fdfdf01-45f9-4cb9-ac54-ad98edae408c","http://resolver.tudelft.nl/uuid:3fdfdf01-45f9-4cb9-ac54-ad98edae408c","Optimizing machine learning inference queries for multiple objectives","Schönfeld, Mariette (TU Delft Electrical Engineering, Mathematics and Computer Science)","Houben, G.J.P.M. (mentor); Katsifodimos, A (graduation committee); Hai, R. (graduation committee); Delft University of Technology (degree granting institution)","2022","Machine learning inference queries are a type of database query for databases where a model pipeline is needed to evaluate its boolean predicates. Using a model zoo it is possible to select a variety of models to execute in a sequence rather than using a highly specialized model to answer every query predicate. Machine learning models can have multiple measurements for gauging performance however, and the quality of a query plan therefore is not only dependent on the time needed to compute it. Selecting a query plan of models that balances multiple objectives is not a trivial feat however. This work builds upon existing methods that utilize MIPs for model selection and ordering for machine learning inference queries by extending them with multi-objective optimizing capabilities. The opportunity for adding a third objective, namely memory footprint, to that of accuracy and execution cost is explored. Several methods are then considered and compared on their suitability, and the final chosen method, the Archimedean goal method, can generate Pareto optimal query plans that provide gains over naive, greedy methods. In addition, several methods of cutting down runtime on the original optimizer are explored, leading to a program than can generate higher quality solutions in less time.","Query optimization; Machine learning; Multi Objective Optimisation","en","master thesis","","","","","","","","","","","","","",""
"uuid:61f4e969-8bd1-4687-9942-b70024b216dc","http://resolver.tudelft.nl/uuid:61f4e969-8bd1-4687-9942-b70024b216dc","Optimal Skateboard Geometry for Maximizing Ollie Height: a Multi-Phase Direct Collocation Optimization Study","Heinen, Jan (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Biomechanical Engineering)","Moore, J.K. (mentor); van der Kruk, E. (graduation committee); ten Broek, Raymund (graduation committee); van der Helm, F.C.T. (graduation committee); Delft University of Technology (degree granting institution)","2022","Skateboarding involves a human controlling a four wheeled vehicle that is steered by tilting the standing surface. The riding mechanics of skateboarding have been well reported [2, 3]. The sport also includes aerial maneuvers such as jumping of stairs, flying off ramps and flipping and rotating the skateboard. The most basic aerial trick is called the ollie. The athlete jumps up while pushing down on the back end of the skateboard’s tail, causing a rotation about the back axle. The upward acceleration due to the rotation together with the tail-ground impact cause the skateboard to go airborne. Midair the athlete drags the skateboard up through frictional contact and levels it out to land the trick. The most concrete performance measure of the ollie is height according to the Olympic judging criteria [4]. To reach maximum height the dynamics such as impact, dynamic response, and torque production are dependent on shape, inertia and mass, which gives reason to assume an optimal shape exists. This leads to the research question: What are the optimal geometric and inertial parameters of a skateboard for an Olympic athlete to reach maximal ollie height. The skateboard geometry is optimized through multiphase direct collocation with the objective of maximal ollie height. A parameterized model is created with scaling mass and inertia properties such that the geometry of the skateboard. Modelling the dynamics of the ollie including impact and friction are done with a point mass human controller that is kineticly and kinematicly mapped to a counter movement jump. A simplistic contact implicit impact scheme is made for a higher order optimization. The ollie height is improved by changing the mass and inertia properties of the skateboard. Multiple optimal board shapes are generated for example a skateboard with a smaller wheelbase can reach higher ollie height compared to an industry standard skateboard.","Trajectory Optimization; Direct collocation; Skateboarding; Ollie; Parameter Optimization; Constraint friction model; Human jumper model","en","master thesis","","","","","","https://github.com/mechmotum/ollie-optimization Github repository with code and data https://www.youtube.com/watch?v=jw5DmNnvD7c Video made of found optimization trajectories","","","","","","Biomedical Engineering","","52.00360,4.221259"
"uuid:eeed7784-9632-4ecb-932e-74f49d5aea99","http://resolver.tudelft.nl/uuid:eeed7784-9632-4ecb-932e-74f49d5aea99","Construction schedule optimisation: Optimisation of BIM-based, component-level construction schedule for building structural and MEP systems considering parallel working zones","Jiang, Xinzhi (TU Delft Civil Engineering & Geosciences)","Wamelink, J.W.F. (mentor); Nogal Macho, M. (graduation committee); Kammouh, O. (graduation committee); Shang, Y. (graduation committee); Arts, D. (graduation committee); Delft University of Technology (degree granting institution)","2022","Construction schedule optimisation problems have been explored extensively, including activity sequencing rules and work packaging. Yet knowledge is still lacking in the sequencing of mechanical, electrical and plumbing (MEP) components with geometric complexity, and how to handle conflicting precedence between MEP work packages arising from the geometric complexity. Another concept of interest is working zones, which are spaces a building may be divided into to enable parallel working: they have the potential to reduce idle working space and project duration, but its integration with the scheduling of MEP systems and effect on schedule optimisation are under-investigated. This work studies the optimisation of construction schedules for building structural and MEP systems considering working zones. First, a conceptual framework is developed, on: (1) activity sequencing rules, featuring preferences on spatial proximity and component size for MEP components; (2) clustering and cluster-splitting method, to resolve the conflicts among MEP packages; and (3) mathematical formulation of schedule optimisation problems as mixed-integer linear programming (MILP) problems. Next, a software tool consisting of an Excel add-in, a MATLAB executable programme and an Excel macro is developed to implement the framework. Two case studies are carried out. The results of case studies and further analysis demonstrate the large potential of zones in reducing project duration, the effect of the amount of resource available, and strategies for future scheduling practices. Applicability to general construction projects, limitations and future directions are also discussed.","Construction scheduling; Optimisation; BIM; Mixed integer linear programming; Work packaging; Mechanical, electrical and plumbing (MEP)","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:58198af7-6be8-4f48-b6ea-f047c07d4e2e","http://resolver.tudelft.nl/uuid:58198af7-6be8-4f48-b6ea-f047c07d4e2e","Multi-Agent Pickup and Delivery Problems in Uncertain Environments: Automation of hospital workplaces using autonomous transportation robots","Brouwer, Lucas (TU Delft Mechanical, Maritime and Materials Engineering)","Alonso Mora, J. (mentor); Wilde, N. (graduation committee); Delft University of Technology (degree granting institution)","2022","The aging of society, population growth and chronic under-investments in education of healthcare workers have all led to a major imbalance between the demand for healthcare and the supply of healthcare. Autonomous robots can be used to relieve overqualified healthcare workers of their repetitive transportation tasks, allowing them to spend more time on actual patient care, hence reducing this imbalance. One of the greatest challenges that must be overcome is the dynamic changes in the environment, which affects the traversability of corridors and thus travel times. This challenge also arises in other human-centric and urban areas where constantly arriving delivery tasks have to be completed such as autonomous mobility-on-demand systems, autonomous warehouses and same-day delivery services. In the hospital environment these dynamic changes occur naturally and can only be observed on-site, which makes them difficult to model. This thesis attempts to fill this gap in literature and therefore studies the online Multi-Agent Pickup and Delivery (MAPD) problem with binary, recoverable and stochastic blockages. The task is twofold in that both the tasks have to be assigned to the agents and the shortest paths for each agent have to be found. The stochastic, binary blockages result in parts of the environment becoming untraversable for a random amount of time. First, an observation model is created that records the blockages and uses the input parameters of the blockage model to estimate the current expected travel times of the edges affected by a blockage. These estimates are then incorporated into the graph used to compute the agents' routes, and an online centralized MAPD algorithm is derived. A waiting state is introduced that allows agents to wait at blockages instead of replanning their paths, and it is demonstrated why replanning is necessary after each observation. This thesis presents numerous experiments on different maps with various blockage parameter configurations to show that the proposed algorithm is more effective than naive algorithms even with noisy blockage parameter estimates. Furthermore, if the initial blockage model parameters are unknown we show that the maximum likelihood estimates can be used as inputs of the blockage model and still outperform the naive methods.","Multi-Agent Pickup and Delivery; Multi-Agent; Multi-Agent Path Finding; Task Allocation; Uncertain Environment","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Vehicle Engineering | Cognitive Robotics","",""
"uuid:54eec5b0-e9b1-413b-a333-500e97e4050b","http://resolver.tudelft.nl/uuid:54eec5b0-e9b1-413b-a333-500e97e4050b","Energy efficiency and treatment performance of BPM-ED for ammonium recovery from ammonium sulphate and ammonium citrate scrubbing effluents","Başli, Elif (TU Delft Civil Engineering & Geosciences)","van Lier, J.B. (mentor); Spanjers, H. (graduation committee); Narayen, D. (mentor); Vermaas, D.A. (graduation committee); Delft University of Technology (degree granting institution)","2022","Excess nitrogen disposal into the environment increased with the discovery of an artificial way of nitrogen gas conversion to ammonia, and its implementation to industrial scale. The excess wasted fixed nitrogen ended up in rivers, lakes, oceans which resulted in degrading air, water and soil due to exceedance of the amount of nitrogen that can be absorbed by soil and plants. Currently, the global wastewater treatment objective has been adapting sustainable solutions by shifting from contaminant removal to resource recovery. Nutrients that were once considered as waste are now being considered as resources. Bipolar membrane electrodialysis (BPM-ED) in combination with stripper/scrubber is one of the combined technologies that aim at contaminant removal and resource recovery. <br/><br/>This study looks into energy efficiency and treatment performance from ammonium sulphate and ammonium citrate scrubber effluents by BPM-ED technology. A three-compartment BPM-ED was used to investigate the use of salt mixture in the feed solution and factors affecting ammonium yield. <br/><br/>Salt mixture of ammonium sulphate and tri-ammonium citrate were used. It was found that use of a salt mixture of ammonium sulphate and tri-ammonium citrate decreased the energy consumption and increased the current efficiency for both of the salts. Use of a mixture of ammonium sulphate and tri-ammonium citrate resulted in better energy performance than either of the salts when they were used alone. Ammonium recovery performance was higher when tri-ammonium citrate concentration was higher in the initial feed solution. This was due to increase in buffer capacity and basic pH in feed solution due to OH- leakages from base compartment. Sulphate ions were favored over citrate ions in their transfer through anion exchange membranes due to higher mobility of sulphate ions. As a further investigation a BPM-ED stack with different combinations, perhaps a two-compartment stack, can be tested to get a deeper understanding to optimize the operation. <br/><br/>Factors affecting ammonium yield that were investigated were H+ leakages and ammonia diffusion. It was found that H+ leakages were same for ammonium sulphate and potassium sulphate feed solutions and H+ leakages were not affected by ammonia diffusion. Ammonia diffusion resulted in higher energy consumption and loss of ammonium recovery potential. Ammonia diffusion increased even with experimental time of 60 minutes. Ammonia diffusion rates also increased through experimental time of 60 minutes. Ammonium and potassium transfer rates from diluate compartment did not follow a specific trend within the first 30 minutes. Clear reasoning behind this was unknown and the results were not completely satisfactory. In current study, it was assumed that ion cross-over and back diffusion were identical for ammonium and potassium. Investigating ion cross-over and back diffusion of the ions in BPM-ED could bring a deeper understanding to the energy efficiency and treatment performance.<br","BPM-ED; Ammonium recovery; Ammonium sulphate; Ammonium citrate","en","master thesis","","","","","","","","2025-12-22","","","","Civil Engineering | Environmental Engineering","",""
"uuid:92d57871-46fa-47af-a24b-b2b2776713a9","http://resolver.tudelft.nl/uuid:92d57871-46fa-47af-a24b-b2b2776713a9","The Bricoleur — Architect: Healing 1960s and 70s Concrete Buildings","Wiedenhöver, Laura (TU Delft Architecture and the Built Environment)","Snijders, A. (mentor); Koskamp, G. (graduation committee); Jennen, P.H.M. (graduation committee); Delft University of Technology (degree granting institution)","2022","This graduation project argues for an alternative circular and healthy construction approach that can be applied to renovate other existing 1960s and 70s concrete buildings in the Netherlands. It integrates historic techniques such as press-fit timber connections, and uses natural and local harvested materials to provide the Hugo R. Kruytgebouw a material conscious and environmentally friendly second-life.","timber; press-fit joints; second-life; concrete; 1960s and 70s buildings; healing","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences | Architectural Engineering","",""
"uuid:ea3d5172-eebb-4708-aaab-a32f97a98956","http://resolver.tudelft.nl/uuid:ea3d5172-eebb-4708-aaab-a32f97a98956","An integrated sensor and process fault diagnosis framework for marine vessels","Pantela, Patroclos (TU Delft Mechanical, Maritime and Materials Engineering)","Reppa, V. (mentor); Kougiatsos, N. (mentor); Jiang, X. (graduation committee); Delft University of Technology (degree granting institution)","2022","This research work tries to provide a model-based, distributed Fault Diagnosis (FD) framework that will eventually act as an early warning system for online monitoring of the marine propulsion process, in order to avoid future failures and accidents. Furthermore, the introduction of adaptive thresholds in the monitoring modules of the monitoring agents helps minimize false alarms and reduces the conservativeness in decision-making. Finally, this work comes to provide an integrated sensor and process FD framework that can be adopted on-board marine vessels in the future, and narrow down the gap, regarding FD for marine vessels which is closely linked with maritime safety and maintenance decision-making.","fault detection and isolation; sensor and process faults; nonlinear interconnected systems; distributed fault diagnosis","en","master thesis","","","","","","","","","","","","Marine Technology | Transport Engineering and Logistics","",""
"uuid:8f3cc921-a898-4fa4-9d2b-6e694a051d95","http://resolver.tudelft.nl/uuid:8f3cc921-a898-4fa4-9d2b-6e694a051d95","Exploring the feasibility of placing a wind turbine on top of an FPSO","Öhlschläger, Youri (TU Delft Mechanical, Maritime and Materials Engineering)","van der Male, P. (mentor); Simanjuntak, T.A. (graduation committee); Delft University of Technology (degree granting institution)","2022","Changing the way of power production on a Floating, Production, Storage, and Offloading (FPSO)<br/>system by using renewable power can contribute to reducing an FPSO’s carbon footprint while operating. Bluewater Energy Services is interested in the use of a wind turbine placed on top of an<br/>FPSO, to power the FPSO’s internal electricity grid. This suggested configuration of a wind turbine and FPSO results in many different challenges that are new to the offshore industry. Therefore, this thesis considers the following research question: ‘To what extent is placing a 5 MW wind turbine on top of an FPSO feasible?’<br/><br/>To answer this question this research is split into two parts. The first part consists of a literature<br/>research, in which two reference FPSOs, Bleo Holm and Haewene Brim, are introduced, and the decision of considering a 5 MW horizontal axis wind turbine is made. A wind turbine with this capacity can deliver approximately 75% of the FPSO’s required power during its normal operations. This information is used as input for a hazard identification (HAZID), in which a group of experts was challenged to brainstorm on possible hazards concerning the topic. The second part introduces the first design concept and focuses on the assessment of feasibility. Both technical feasibility and non-technical feasibility are evaluated. For technical feasibility, topics such as vessel stability, vessel strength, vibrations, the system’s motions, and wind turbine use during operational events on the FPSO are considered. From the non-technical feasibility, additional focus is put on the health, safety, and environmental (HSE) aspects of the project, and the project’s business case. <br/><br/>From the technical evaluation of the chosen design configuration a motion analysis, which consists of a diffraction analysis in HydroStar and a time domain simulation in OrcaFlex, identified a limitation in the wind turbine’s nacelle acceleration. This motion analysis was limited by the unavailability of a wind turbine model consisting of a yaw control system. In operations, the limit for nacelle acceleration is exceeded, which can be mitigated by performing more frequent wind turbine shutdowns. In extreme conditions for the vessel’s fully loaded condition, this mitigation is not an option. Recommended is an improvement of the design, to reduce the nacelle’s acceleration, with options such as reducing the wind turbine tower height or increasing the tower’s bending stiffness. Also, the found result is linked to the location of the Haewene Brim in the central North Sea, which is generally considered a site with rough environmental conditions. A different location with calmer waters is likely to still facilitate this concept. The considerable HSE-related risks that have been identified are related to the risk of a wind turbine’s dropped objects onto the FPSO, which can occur from different causes such as fire, structural failure, or lightning. This risk comes with a low probability, while its impact can be high. The business case of the project shows the potential of saving 250,000 tonnes of CO2 emissions during a typical wind turbine’s lifetime of 20 years. Also, it is estimated that a positive return on investment can be made in case the capital expenditures are less than €64.3 million. However, this result is sensitive to changes in, among other parameters, the wind turbine’s power production.<br/><br/>Based on the findings described above the conclusion to the question: ‘To what extent is placing a<br/>5 MW wind turbine on an FPSO feasible?’ is that it can be considered feasible in case a design concept is found for which the nacelle acceleration is no longer an issue. However, future research is recommended on comparing this concept to other renewable power alternatives for the FPSO, based on their risks and financials, to see if the safety risks are worth the financial gain. On top of that, the development of a wind turbine yaw-controlled model is suggested to capture the interaction between weathervaning FPSO and yaw-operating wind turbine. In addition, research can be done on the installation method for a wind turbine on an FPSO.<br","FPSO; Wind Turbine; Technical; Non-technical; HSE; Finance; Motion analysis; Strength & stability; Power; Design; HAZID; Diffraction analysis","en","master thesis","","","","","","","","2024-12-20","","","","Offshore and Dredging Engineering","",""
"uuid:47e186ee-3f82-45bf-b7a6-90c9e0dd7d55","http://resolver.tudelft.nl/uuid:47e186ee-3f82-45bf-b7a6-90c9e0dd7d55","Global identification and characterization of drivers of shoreline evolution: A novel method using Satellite Derived Shorelines and spatiotemporal characteristics","van der Heijden, Dante (TU Delft Civil Engineering & Geosciences)","Luijendijk, A.P. (mentor); Kras, Etienne (mentor); Aarninkhof, S.G.J. (graduation committee); Storms, J.E.A. (graduation committee); Delft University of Technology (degree granting institution)","2022","Since early history, humans have been attracted to coastal areas. This can be related to the economic benefits of these areas due to access of ocean navigation, coastal fisheries, tourism and recreation (Seas and Plans, 2011). Around 40% of the world’s population lives within 100 km of the coast (Seas and Plans, 2011). People are drawn to sandy beaches in particular because of its aesthetics and value for specific economic amenities (Luijendijk et al., 2018). Nevertheless, as these beaches are dynamic both in time and space, proper coastal management is required to prevent loss of land and secure future coastal life. <br/><br/>Up till now, studies into coastal erosion have been conducted locally, resulting in site specific observations. However, the promising results of using satellite imagery in the field of coastal engineering allowed studies to be performed at larger spatial scales. This can lead to the identification of areas with similar characteristics, resulting in methodological standardization of approaching a specific problem. A first step toward this new approach of studying shoreline evolution was taken by Luijendijk et al. (2018) who presented a global dataset of annual shoreline positions for sandy beaches over the period 1984-2016 using satellite derived shorelines<br/>(SDS). However, the drivers (causes) of shoreline evolution on a global scale were still unknown, making it only suitable for identifying areas of structural shoreline change, but less suitable for deriving coastal management solutions. Therefore, the research objective in this study is to identify and characterize drivers of shoreline evolution on a global scale using SDS. <br/><br/>This study focused on dynamic sandy beaches, or hotspots, extracted using a method developed by Kras (2019). In this method, using a 2.5-kilometer moving window, transects showing structural shoreline changes and similar characteristics both in space and time were grouped. The small size of the moving window led to locally created hotspots, 95% of which had a spatial extent of less than 10 kilometers, allowing to study shoreline drivers with small to moderate spatial scales (∼10 kilometer). Therefore, the main focus in this study lies on seasonality as a natural driver of shoreline evolution and three anthropogenic drivers: reclamations, nourishments and littoral drift barriers. As seasonality shows inter-annual variability, the temporal resolution of the SDS is increased from annual to monthly.<br/>Using time series decomposition methods, different parameters are extracted that can be used to link the drivers to the SDS. Besides temporal parameters, also parameters related to spatial characteristics are considered. These parameters can be split into identification parameters, used for identifying a driver, and informative parameters, providing knowledge on the behavior of the driver. These parameters were developed and tested using local case studies. Results from these local case studies showed that the identification parameters showed similar behavior along the case studies. This implies that the identification parameters correctly reflect a driver’s behavior. Next, identification of the drivers was verified on a larger scale, all transects within hotspots on West-European coastlines. Verification was done on hundreds of samples using literature or manual inspection of satellite images. Using precision scores, the fraction of true positives to the total identified cases, optimal settings were derived for identification of the drivers. These settings resulted in a pattern of driver identification and characterization along the West-European coastline that is supported by literature. <br/><br/>With the optimal settings for identification determined, the methods were deployed on a global scale. The global dataset consisted out of 3033 prograding and 2121 retreating hotspots containing over 58 thousand transects in total. For these hotspots, SDS were generated over the period 1984-2021 with a monthly temporal resolution. This resulted in a global dataset of more than 26 million monthly shoreline positions. Two other processes, in addition to a seasonal change in wave height, were found to be able to generate seasonal variations in coastline positions from this global dataset. At the Red Sea, even though the wave climate is low in energy (Langodan et al., 2017), the coast is characterized by seasonal behavior. However, in this basin, seasonal variations in water levels rather than the wave climate best described this pattern. In addition to varying wave height and water level, seasonal beach morphology can also be caused by a shift in wave direction. This was observed in southern and western parts of Australia. Furthermore, non-seasonal beaches were primarily seen in low-energetic wave regions where neither of these other two processes occurred, as is the case in the Mediterranean. In regions where seasonal shoreline fluctuations are caused by differences in wave energy, minimum shoreline positions were found at the start of the summer. However, the period in which minimal shoreline positions are observed may be observed at a different time of the year in regions where seasonal shoreline behavior is driven by water level variations or a shift in wave direction. The identification of reclamations pointed out that this driver was especially linked to shoreline evolution in the Middle East and East-Asia. Furthermore, while the amount of constructions of reclamations remained<br/>constant on a global level over the period 1987-2017, in these two areas an increase was observed. Opposite behavior was found by the identification of nourishments, as this driver was identified more often in the period 2007-2017 compared to the two decades before that. Moreover, nourishments were mostly observed in Western countries, for example the USA and the Netherlands. Nevertheless, also in Non-Western countries, an increment over time in the amount of nourishments could be detected. This indicates that throughout the entire world the use of nourishments as a measure to prevent coastal erosion is increasing. Shoreline evolution linked to littoral drift barriers was mostly observed in North-America, Europe and Africa. Downdrift (erosive) hotspots were mostly observed in Africa while in North-America and Europe mostly updrift (accreting) hotspots were linked to littoral drift barriers. On a global level, a combination of an updrift and downdrift hotspots (a pair) was observed in only 2% of all hotspots.<br/><br/>The outcomes above can support local-scale studies by identifying the drivers of shoreline evolution, describing their characteristics and even create standardization by analyzing areas with similar behavior. Hence, it can be concluded that spatiotemporal parameters describing the behavior of a driver can be used to identify and characterize drivers on a global scale using SDS. Nevertheless, not all drivers of shoreline evolution were included in this study. Therefore, to include drivers with larger spatial scales, hotspots should be extracted by using a larger moving spatial window. Furthermore, by increasing the spatiotemporal resolution on which this extraction is based, accuracy of the spatial extent of the hotspots is expected to increase. The small proportion of pairs identified for littoral drift barriers can be partly explained by the erroneous spatial extent of some hotspots. Finally, drivers are identified independently from each other neglecting their interactions. Even though interactions might be complex, drivers should not be identified independently as this will rather<br/>require local studies than support them. Still, even though refinement and further development of the methods is required, this research has shown that identifying the drivers of shoreline development on a global scale using SDS has great potential for sustainable coastal management in the face of future challenges<br","Global dataset; Big data; Coastal engineering; Satellite imagery; Sandy coasts; Shoreline evolution; Python; Timeseries decomposition; Classification; Identification; Characterisation","en","master thesis","","","","","","","","","","","","Civil Engineering | Hydraulic Engineering","",""
"uuid:54ccef80-0805-4c09-9f41-2e8fb34fab3f","http://resolver.tudelft.nl/uuid:54ccef80-0805-4c09-9f41-2e8fb34fab3f","Modeling ray angles in deep learning based dose calculation algorithms","van der Valk Bouman, Jim (TU Delft Electrical Engineering, Mathematics and Computer Science)","Postek, K.S. (mentor); Breedveld, Sebastiaan (graduation committee); Delft University of Technology (degree granting institution)","2022","A fundamental tool in radiotherapy treatment planning is the dose calculation algorithm, which models the dose that will be distributed for given beam parameters and patient geometry. Various available algorithms include Monte Carlo simulations (MC) and pencil beam algorithms (PBA), with the former being computationally expensive but offering high precision and the latter sacrificing precision for speed. A recent study presents the deep-learning based Dose Transformer Algorithm (DoTA) which provides MC accuracy at speeds 33 times faster than PBA. However, as currently implemented, DoTA dose computations assume that each ray enters the patient geometry perpendicularly, while clinical treatment plans consist of many diverging rays with angles of entry up to 5°. <br/><br/>In this project, we extend the current model to include angular dependency. The resulting models DoTA-A and DoTA-S improve on DoTA by including angle of entry as an additional input on top of the beam energy and patient geometry. DoTA-A includes the actual angle values as input, while for DoTA-S an expected beam shape is precalculated with a trajectory based on the angle of entry. A training dataset of more than 30.000 samples with MC baseline dose is generated from a public patient dataset, using a 2 mm resolution. The architecture of the models is similar to that of DoTA, with convolutional layers extracting important spatial features from the input geometry and a transformer layer using a self-attention mechanism to weigh token inter-dependence.<br/><br/>The models DoTA-A and DoTA-S are evaluated and compared on different test sets with MC baseline doses. Both models are shown to be more accurate than PBA, with DoTA-S having the best performance by most metrics. We demonstrate the relevance of ray angles in dose calculations by comparing DoTA-A and DoTA-S to perpendicular MC predictions, which were considered ground-truth for DoTA. The models DoTA-A and DoTA-S compute dose distributions at an average speed of 10 ms to 15 ms per dose, with the predictions achieving an average relative error of 1% across various test sets. The average relative error of the perpendicular MC predictions lies around 3%, demonstrating the importance of angle of entry as an input variable in dose calculation algorithms. The gamma pass rates (for δ=1%, Δ=3mm) of a full treatment plan with dose distributions predicted by our models are 97.60% for DoTA-A and 95.74% for DoTA-S, indicating that there is no strictly better model between the two.","Dose Calculation; Deep Learning; Radiotherapy","en","master thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:94d16d94-e4c7-4a54-a26a-af114db02dd7","http://resolver.tudelft.nl/uuid:94d16d94-e4c7-4a54-a26a-af114db02dd7","The Application of RDMA over Converged Ethernet Data Transport for Radio-Astronomy Systems","de Laat, Willem (TU Delft Electrical Engineering, Mathematics and Computer Science)","van der Vlugt, Steven (mentor); Al-Ars, Z. (mentor); Venkatesha Prasad, Ranga Rao (graduation committee); Hoozemans, Joost (graduation committee); Delft University of Technology (degree granting institution)","2022","The need to receive and process higher data rates in computer clusters is an ever-increasing trend. This also applies to radio-astronomic systems, which have become more distributed over the past decades, increasing data traffic between antennas and processing facilities. At the antenna, Field Programmable Gate Arrays (FPGAs) digitise the radio signals and often perform the first stage of signal processing at the antenna. Hereafter, the data is sent from the FPGAs to computer clusters, where further processing is accomplished on CPUs and GPUs. Currently used protocols for data transport between FPGAs and CPUs, such as UDP, are insufficiently scalable for higher data rates since these heavily load the receiving CPU. <br/>Remote Direct Memory Access (RDMA) over Converged Ethernet (RoCE) was developed to overcome the disadvantages of the standard UDP and TCP protocols by using the CPU to orchestrate data transfers and not engaging the CPU in the data path. With this, the data bypasses the CPU, lowering the CPU workload and enabling throughput and latency improvements. However, the data transport methods for applications in radio-telescopes must meet specific characteristics of this application area, such as public Ethernet routing, high sustained data rates, real-time processing and implementable on FPGAs. <br/><br/>This work examines whether RoCE can reduce system load and increase throughput in sending and receiving antenna data. For this purpose, we characterise the data transport, derive the best RoCE configuration for the intended application and asses whether RoCE can achieve the required performance. The protocol analysis concluded that an unreliable connection transport service with RDMA WRITE with immediate data is best suited for the application in radio telescope systems. <br/>This thesis defines a methodology to examine the impact of RoCE settings and RoCEs scalability on a representative cluster setup with CPU-CPU and CPU-GPU data transport. To conduct these tests, an application is developed with abstractions such that it can be easily reused. First, standard tooling demonstrated that RoCE achieves ∼2x higher goodput and 3x lower CPU utilisation compared to UDP, indicating the possible scale of performance improvement of RoCE. Further performance studies are accomplished through the custom-developed application to explore various settings and network topologies (1-1, 1-N and N-1). For example, we found that using a shared receive queue can reduce CPU utilisation by 50%, and the use of solicited events can yield reductions of up to 70%, with no negative impact on resources and goodput. Direct memory access from the RoCE-enabled NIC to GPU memory is also evaluated, for which comparable performance was achieved to standard main memory in an N-1 setup. We found that RoCE can transport data from multiple transmitters over a total of 2000 QPs with a 16kiB message size to a single receiver at 90Gbps and a CPU load of 40% for one core in the receiver. <br/>The feasibility and performance of transporting data between FPGA and RNIC are also investigated. The implementation could not transport the data from the FPGA into the CPU memory because of an incorrect checksum implementation. Nevertheless, we were able to confirm that it is possible to implement RoCE on an FPGA for use in radio astronomical data transport.","RoCE; RDMA; FPGA; GPU; networking; 100Gbps; radio astronomy; astronomy; DMA","en","master thesis","","","","","","","","","","","","Computer Engineering","",""
"uuid:6119a9c8-c6e0-4ac7-8d24-349278eaa550","http://resolver.tudelft.nl/uuid:6119a9c8-c6e0-4ac7-8d24-349278eaa550","The Design of a ’Water Droplet’-Based UFP Mitigation System at Airports: A Case Study at Amsterdam Airport Schiphol","Jebbink, Rinke (TU Delft Civil Engineering & Geosciences)","van Wee, G.P. (graduation committee); Annema, J.A. (mentor); Vleugel, J (graduation committee); Zekveld, Jan (mentor); Enting, Yannick (graduation committee); Delft University of Technology (degree granting institution)","2022","This research explored potential designs of an innovative mitigation strategy to combat the aircraft-produced ultrafine particle (UFP) concentrations at Amsterdam Airport Schiphol (AMS). This technique is based on the principle that fine water droplets are able to encapsulate dust and fine particles, which clump together and eventually descent to the ground. The reduction of airborne particle concentrations is expected to have a significant effect on the health of (platform) employees, which makes it an interesting strategy to further investigate. A wide variety of stakeholders, from both the aviation industry and the academic world, were interviewed about the important design components that need to be incorporated in a potential mitigation system, as well as essential requirements that the system needs to comply with. A system that integrated the cold start of the aircraft engines as the most suitable moment and the introduction of remote starting positions as the most optimal location for the implementation of UFP mitigation strategies, contributed to the proposed conceptual design for AMS. A system alternative in which the water droplets are directed into the jet engine outlets by spraying cannons was discussed for a close-up mitigation strategy, while an alternative in which a screen of water droplets is created to absorb the jet blast with emissions was established for the mitigation strategy at a further distance. The assessment of the conceptual system design, on its feasibility, viability and desirability, showed that the UFP mitigation system could have a desirable impact on Schiphol’s environment on the short-term. However, the possibilities of implementing remote starting positions at AMS and the impact that the system has on the starting capacity and the turnaround time should be further investigated to increase the system’s feasibility and viability.","Aviation; System Design; Aircraft emissions; Sustainability; Innovative technology","en","master thesis","","","","","","","","","","","","Transport, Infrastructure and Logistics","",""
"uuid:e009cc92-ccda-4458-a7ba-5ce014e7526e","http://resolver.tudelft.nl/uuid:e009cc92-ccda-4458-a7ba-5ce014e7526e","Fabrication Technologies of 3-Dimesional Electrodes for a Heart-on-Chip Application","R KANNAN, Shirley (TU Delft Mechanical, Maritime and Materials Engineering)","Dekker, R. (mentor); French, P.J. (graduation committee); Gaio, N. (graduation committee); Delft University of Technology (degree granting institution)","2022","Organs-on-Chips (OoCs) are micro-engineered devices in which small samples of human-organ tissue are cultured on the substrate. A chip is designed in such a way that it can emulate the in-vivo physiological environment for disease modeling and drug screening. OoC technology can be incorporated into the drug development process from early drug discovery to pre-clinical drug screening. This cutting-edge technology can reduce the use of laboratory animals as animal models do not accurately recapitulate the in-vivo physiology and pathology of the human body. Current microfabrication techniques integrate features like microfluidics and micropumps into OoC devices to provide the necessary perfusion. Additionally, it is possible to monitor the behavior of cells or tissue by incorporating sensors into the platform.<br/>Cardiovascular diseases are a leading cause of death worldwide, which calls for an ideal in-vitro screening model for cardiotoxicity. The MUSbit™ device, an OoC developed by Bi/ond, incorporates a 3D muscle microtissue anchored to two pillars designed to align the tissue. The device consists of a microfluidic channel to offer the necessary perfusion to mimic the blood flow through the heart. Bi/ond aims to electrically pace the cardiovascular bundle via the two pillars and record the electrical activity of the cardiac cells. This is achieved by combining an electrode and the pillar. Thus, a 3D electrode in integrated into the platform. Compared to 2-D microelectrode arrays (MEAs), 3D electrodes have a larger surface area, lowering the electrode impedance and increasing the signal-to-noise ratio (SNR). <br/>The existing method of Bi/ond incorporates the electrode underneath the pillar via a cavity ( also known as the basement) in silicon fabricated using Deep Reactive Ion Etching (DRIE). This thesis focused on combining the electrode underneath the pillar by optimizing the critical steps in the fabrication process. The basement provides a form of adhesion for the pillars towards the later stages of the process. Due to the limitations concerning the step coverage of the different layers deposited over the current profile of the cavity, the design was modified. In this project, two main goals were defined and achieved. Firstly, the basement design was optimized by wet etching the silicon using potassium hydroxide (KOH) to obtain a cavity with a slanted sidewall. The photolithography on the layers and the step coverage of the deposited layers on the cavity were investigated. Experiments were performed to observe the effect of the modified basement design on the pillars (without the electrode). Secondly, the feasibility of integrating the electrode underneath the pillar without a basement was assessed. The photomask of the essential layers (except the metal) was designed accordingly. Finally, the influence of the alternative designs on the pillars was tested to verify their viability. Both approaches showed that it is practical to implement the techniques which can be compatible with the process of Bi/ond. The several microfabrication tests presented in this work set a foundation to incorporate the electrodes into the platform, making ground for future studies.<br","Heart-on-Chip; 3D electrode integration; Photolithography; Etching; Silicon nitride insulation; TiN","en","master thesis","","","","","","","","2027-12-29","","","","Biomedical Engineering","",""
"uuid:044b1f53-806b-47d4-868e-dc9d2bdd115a","http://resolver.tudelft.nl/uuid:044b1f53-806b-47d4-868e-dc9d2bdd115a","Architecture of Occupation","van de Wijgert, Rik (TU Delft Architecture and the Built Environment; TU Delft Urban Architecture (OLD))","Vermeulen, P.E.L.J.C. (mentor); Reinders, L.G.A.J. (mentor); van Deudekom, A.B.J. (mentor); Delft University of Technology (degree granting institution)","2022","","","en","master thesis","","","","","","","","","","","","Architecture, Urbanism and Building Sciences","",""
"uuid:5cbaf29a-bd03-4922-b25a-4fc60a1ffb13","http://resolver.tudelft.nl/uuid:5cbaf29a-bd03-4922-b25a-4fc60a1ffb13","Prototyping a domain-task ontology for facilitating strategic decisions of asset managers of public sewerage systems","Barekas, Apostolis (TU Delft Civil Engineering & Geosciences)","Wamelink, J.W.F. (graduation committee); van Nederveen, G.A. (mentor); Bektas, K.E. (graduation committee); van den Berg, Marijn (graduation committee); Raghavendra Rao, Shreenidhi (graduation committee); Delft University of Technology (degree granting institution)","2022","The current research stems from the motivation of reducing the information loss that asset managers face in the operation &amp; maintenance phase of the project. Most of the public infrastructure assets’ condition nowadays deteriorate due to ageing and municipalities confront challenges to manage their portfolios effectively by adopting proactive management strategies. To succeed the highest possible value from assets, asset management is being adopted as an industry practice in the Dutch construction sector. Successfully managing assets requires managers at the handover stage to acquire accurate, explicit, and complete information from the earlier stages (Design and Construction phase). Only with reliable information they can make the right decisions about costs, performance, and risks which are the pillars of asset management theory. However, the information in the operations stage is incomplete or invalid and dispersed in various sources. This is an obstacle to reuse knowledge as asset managers have to identify information from various sources leading to secondary costs. Significant barriers are the asset managers' limited involvement from the project's beginning. That makes their needs less explicit for contractors and reduces the level of understanding of what information they have to deliver. This thesis works towards providing a more reusable and flexible method in the construction industry for capturing and structuring the strategic information needs of asset managers in a machine and human-understandable way. Linked data and semantic web technologies were used to capture and structure the information and create an ontology. In conclusion, the research demonstrated a way of identifying, capturing and structuring asset information needs with which users can communicate effectively using a common language. The ontology aggregates and stores information from diverse sources and enhance the communication between parties by providing them a common understanding given the specific scope. In this way, the information needs of asset managers can be explicitly defined from the beginning of a project, resulting to complete and reusable information. Now the understanding of what information has to be transferred to asset managers is more straightforward, reusable and unambiguous, resulting in reduced time retrieval of information and secondary costs (e.g. looking for information).","Asset management; Public Sewerage Systems; Information Technology; Knowledge Management","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:71d23197-e244-4572-9f5a-957a7ecf049f","http://resolver.tudelft.nl/uuid:71d23197-e244-4572-9f5a-957a7ecf049f","Modifying a path into the shortest path","Duan, Xiaowei (TU Delft Electrical Engineering, Mathematics and Computer Science)","Van Mieghem, P.F.A. (mentor); Qiu, Z. (graduation committee); Delft University of Technology (degree granting institution)","2022","The inverse shortest path problem (ISPP) is a problem based on graph theory, that is to design link weights in a graph to satisfy that given paths are the shortest between the corresponding node pairs. It can be used in networks of complex systems to solve practical problems such as re-routing in transportation systems and reallocating resources in IP networks. This thesis proposes two new methods based on the simplex algorithm, the split path method (Sp) and the limit constraints method (Lc), to solve the inverse shortest path problem with one predefined path (ISPP-S). The different approaches used to find the constraints in these two methods affect the obtained optimal solution and running time. By analyzing the simulation results (running time, adjustment of link weight as well as the relationship between path length and running time) of these two algorithms in graphs with various structures, we can evaluate the efficiency of Sp and Lc and summarize their applicable networks. After modification, these two methods can be utilized to solve the extended inverse shortest path problem with multiple target paths (ISPP-M) and with target paths in a spanning tree (ISPP-T). In addition, the applicability of these two algorithms is also extended from directed graphs to undirected graphs. The application of Sp and Lc algorithms in a variety of empirical networks is also discussed. Through the analysis of the above problems and the experimental results, we discover that Sp is more suitable to solve ISPP with relatively few constraints (ISPP-S or ISPP in small-sized networks); Lc performs better when solving ISPP with relatively more constraints (ISPP-M or ISPP in large-sized networks).","The inverse shortest path problem; Network; Graph theory; Mathematical optimization; Simplex algorithm","en","master thesis","","","","","","","","","","","","Electrical Engineering","",""
"uuid:e7e2029c-c2e5-42b8-ba9b-f625fdb2af4e","http://resolver.tudelft.nl/uuid:e7e2029c-c2e5-42b8-ba9b-f625fdb2af4e","Intravascular Ultrasound and Photoacoustic Image Reconstruction: For Improved Lipid Imaging in Atherosclerotic Coronary Arteries","Bekkers, Amerens (TU Delft Mechanical, Maritime and Materials Engineering)","Daeichin, V. (mentor); Vos, H.J. (graduation committee); van Soest, Gijs (graduation committee); Delft University of Technology (degree granting institution)","2022","Introduction: Coronary atherosclerosis can form large lipid-rich plaques inside the arteries, which are prone to rupture. Rupture can lead to thrombus formation and subsequent obstruction of the blood flow, which is the most common cause of acute coronary events like myocardial infarction. Current imaging modalities lack the ability to image important factors in the diagnosis of these vulnerable plaques or have a limited image quality. A novel imaging modality, intravascular ultrasound (IVUS) combined with intravascular photoacoustics (IVPA), is a good candidate for accurate lipid imaging in atherosclerotic coronary arteries. IVPA enables specific lipid imaging alongside the artery morphology image provided by IVUS. Kaminari Medical is developing the first rotating IVUS and IVPA catheter for this purpose. Objective: The objective of this research project is to develop an image reconstruction method with improved lateral resolution (LR) and Signal-to-Noise Ratio (SNR) compared to the conventional image reconstruction method. Methods and Materials: A literature review was executed to find the state-of-the-art image reconstruction method for IVUS and IVPA. A virtual source synthetic aperture (VSSA) beamforming method with Coherence Factor Weighting (CFW) was selected and implemented to achieve the desired image quality improvement. The principle of the VSSA is that the signals captured at adjacent transducer positions are delayed and summed to use all available image information. The delays are calculated with respect to the virtual sources, which are placed at the natural focus of the beams under the assumption that this yields the best alignment after delaying the signals. A pixel-based implementation of VSSA with CFW was developed on IVUS data which directly reconstructs the image pixel values. Subsequently, the algorithm is optimized to achieve the best image quality for IVUS and IVPA data acquired by the Kaminari Medical catheter. Results: The implementation of the algorithm based on the literature did not show the image quality as expected, most likely due to the invalid assumption that the virtual source should lie at the natural focus of the ultrasound beam. Therefore, the virtual source depth and the opening angle of the beam are optimized to find the parameter combination that achieves the best image quality. For both IVUS and IVPA, narrow beam shapes and a virtual source behind the transducer, thus using diverging beam shapes, should be used to obtain the best LR and SNR. The optimized VSSA leads to an increased SNR by 20.3% and 77.7% for IVUS and IVPA, respectively. The LR is increased by 7% for IVPA but shows a LR reduction for the IVUS data. Conclusion: The optimized VSSA meets the objective of improving the LR and SNR to a large extent. However, it is recommended to focus future work on developing a substitutional weighting method for the CFW to also improve the LR for the IVUS data","Image Reconstruction; Intravascular Ultrasound; Intravascular Photoacoustics","en","master thesis","","","","","","","","2024-12-09","","","","","",""
"uuid:68d3bb28-9a88-4398-8ed0-ab99873cb224","http://resolver.tudelft.nl/uuid:68d3bb28-9a88-4398-8ed0-ab99873cb224","Orbital evolution of levitated regolith particles in the 65803 Didymos binary system","Fiuk, Aleksander (TU Delft Aerospace Engineering; TU Delft Astrodynamics & Space Missions)","Heiligers, M.J. (mentor); Soldini, Stefania (graduation committee); Delft University of Technology (degree granting institution)","2022","Operating spacecraft in a perturbed environment of a binary asteroid system is a challenging task. In light of the near-future exploration of the 65803 Didymos system by the Hera probe and the lack of study of orbital evolution of naturally-levitated regolith particles in this system, a method is here proposed to identify regions of high risk of collision with the levitated regolith grains. Regions of regolith levitation are identified, periodic orbits and regions of stable motion are computed through a grid search method, and the distance between trajectories leading from the off-surface levitation of the grains from the primary body and the trajectories of bounded motion is then assessed to determine the occurrence of temporary capture. A qualitative evaluation of the expected patterns of motion of regolith particles is presented together with a discussion of the key conclusions in the context of in situ operations planning for the Hera probe.","Regolith; Astrodynamics; Binary asteroids; Hera; Levitation","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:fcafaade-316f-4794-9c1c-aacf6d5e9b80","http://resolver.tudelft.nl/uuid:fcafaade-316f-4794-9c1c-aacf6d5e9b80","To determine the effects of propeller ducts on quadrotors in longitudinal forward flight, using flight data and stepwise regression","Koster, Max (TU Delft Aerospace Engineering)","de Visser, C.C. (mentor); van Beers, J.J. (mentor); Delft University of Technology (degree granting institution)","2022","In order to gain more insight into the effects of propeller ducts on quadrotors in forward flight, this research analyses flight data obtained from free flight tests, performed in the Cyberzoo and the Open Jet Facility of the TU Delft. Using a quadrotor platform with detachable propeller ducts, both trimmed forward flight tests and flights exciting the F<sub>x</sub>, F<sub>z</sub> forces and the M<sub>y</sub> moment, using both ducted and unducted configurations. From the analysis of the steady flight data, the ducted configuration flies at a significantly higher pitch angle compared to the unducted configuration. However, for the power consumption and the rotor speeds, a crossover point is present around an airspeed of 6 ms<sup>-1</sup>. Before this crossover point the power consumption and total rotor speeds of the ducted configuration are lower than its unducted counterpart. The flights containing the excitations of the forces and the moment are used to identify an aerodynamic model of the quadrotor using stepwise regression. Using this technique a model of the ducts themselves is identified which can be added onto the unducted model in order to predict the response of the ducted quadrotor. The regressors of this model were also used to gain extra insight into the terms at play in the effects of the ducts.","Quadrotor; System identification; Propeller ducts; Flight Data Analysis; Modelling; stepwise regression","en","master thesis","","","","","","","","2024-12-20","","","","Aerospace Engineering","",""
"uuid:545a229c-0511-43be-a93c-96caf95a0486","http://resolver.tudelft.nl/uuid:545a229c-0511-43be-a93c-96caf95a0486","BigTech Mobile Payment Adoption in the Netherlands: Performance over Trust?","Pieter, Levi (TU Delft Technology, Policy and Management)","Scholten, V.E. (graduation committee); Roosenboom-Kwee, Z. (mentor); Ralcheva, Aleksandrina (graduation committee); Delft University of Technology (degree granting institution)","2022","The broad goal of this thesis is to explore what is currently motivating consumers to adopt BigTech mobile payment services in the Netherlands. The term BigTech refers to a collection of the largest and most dominant companies in the IT industry, including Google, Apple, Meta, and Amazon, among others. The BigTechs have been leveraging their core competencies in order to enter the financial industry by offering contactless mobile payment services, such as Apple Pay and Google Pay. Further involvement of BigTechs in the financial industry could lead to increased systemic risk, as well as power concentration risks due to their already large influential market power. The Dutch central bank (DNB) and the Dutch competitive authority (ACM) have released reports in which they acknowledge these risks. They state that the competitive balance between BigTech and the financial incumbents will moreover depend on the relative distrust the consumer currently has towards the BigTechs as provider of financial services compared to incumbent financial institutions. Both authorities indicate that the direction which this competitive balance is taking remains unclear, yet the adoption of contactless mobile payment services in the Netherlands, the majority of which is provided by BigTechs Apple and Google, has seen increasing growth. Therefore, this thesis aims to evaluate whether this distrust still wields this influential balancing power in the Netherlands, or if there are other motives that are more strongly influencing this trend instead. <br/>Reviewing the relevant past literature found moderating and mediating effects between constructs examined in mobile payment studies to often be excluded from analysis. As a result, this thesis also aims to address this research gap. A suitable starting research framework was selected after reviewing eleven prominent research models and a conceptual model was designed based on these reviews. Data was subsequently collected using an online survey questionnaire. The 217 collected responses were subjected to data analysis of which the results indicate that the Dutch consumer is mainly driven by three functional motives regarding respectively: how well the technology is expected to perform, how well the technology is perceivably supported, and to which extent the consumer has habits that are similar to using mobile payment services. <br/>Perceptions of involved risk and feelings of distrust towards providers of mobile payment services only reduced the incentive to adopt the technology among respondents within the age group of 25-34, and solely weakened the performance-based motive. It was furthermore found that the habit-based motive reduced both risk perception and distrust of the users. No motivational differences were found between users of BigTech services or those offered by financial incumbents, or between users and non-users. <br/>The Dutch relevant authorities may induce from this research that the competitive balance in the Dutch financial sector is likely tipping in favour of BigTech as consumers are driven mainly by utilitarian needs to which BigTech can more easily cater than financial incumbents. Dutch financial incumbents may therefore require additional support to reduce the potential for harmful levels of competitive pressure in the financial sector and limit the sector’s exposure to concentration risk, which the involvement of BigTech can bring about. Dutch financial incumbents may induce from this research that the contemporary Dutch consumer mainly prefers improved functional capabilities. According to the results, performance, wide-spread support, and fit with consumers’ existing habits, should serve as key focus areas for improvement in order to compete efficiently. The theoretical contribution that this research made regards the discovered mediating and moderating effects of the evaluated constructs in mobile payment adoption research. The obtained results thereby implore future research in this field to similarly evaluate such effects in order to increase the explanatory power of the employed research model and potentially derive additional and crucial insights.","BigTech; Mobile Payments; Technology Adoption; UTAUT2; Consumer Trust; Digitalisation; M-Payments; PLS-SEM","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:1d878b1b-09e0-4e07-b1ab-f15eb3c4b85c","http://resolver.tudelft.nl/uuid:1d878b1b-09e0-4e07-b1ab-f15eb3c4b85c","The aerodynamic effects of the location of baseball seams: An experimental study by PIV","Knepper, Jorian (TU Delft Aerospace Engineering)","Sciacchitano, A. (mentor); Delft University of Technology (degree granting institution)","2022","The aerodynamic behaviour of a pitched baseball depends on the combination of the translational velocity, the rotational velocity in combination with the rotation axis and the seam positions. For small spin parameters the effect of seam positions dominates the Magnus effect. This study focusses on a visual understanding of the seam position by 2D planar PIV (Particle Image Velocimetry) in the windtunnel. This has as main advantage a high repetition rate and statistical convergence of the flow fields. This is done for baseballs with small spin parameters for the two most common pitch configurations: the 2-seam and the 4-seam. The goal of this research is to understand the effect of the location of the seams of a slow or non-rotating baseball (spin factor &lt; 0.2) on the wake.","2D Planar PIV; Baseball; Seams; 2-seam; 4-seam; aerodynamics; Wind Tunnel Experiment; Spin","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:98fda42e-1cf4-448c-991d-82afdda04c05","http://resolver.tudelft.nl/uuid:98fda42e-1cf4-448c-991d-82afdda04c05","Quantum Inspired Factoring","Elgar, Peter (TU Delft Electrical Engineering, Mathematics and Computer Science)","Verwer, S.E. (mentor); Feld, S. (graduation committee); Delft University of Technology (degree granting institution)","2022","RSA encryption standard is a vital component of everyday internet communication. It is currently seen as being unbreakable as the problem that it is based on, semiprime factorisation, is an NP problem. Therefore, to try and break RSA using the current state of the art factoring method will take thousands of years. However, thanks to the advent of quantum computers we do know that RSA can theoretically be broken in seconds in two main ways. Firstly, by using Shor’s algorithm. Secondly, by formulating it as a binary optimisation problem and solving the formation with the quantum approximate optimization algorithm or solving the formulation by using quantum annealing. Unfortunately, there does not exist a quantum computer today that is accurate nor large enough to be able to break RSA encryption any time soon. For example, the largest semiprime number that has been factored by a quantum computer was a 41-bit number, as opposed to 2048-bit numbers that get used for RSA encryption. Fortunately, what is possible is to split the binary optimisation problem formulisation up into sub- problems, solve them individually and combine the solutions to get the answer, as shown in Wang et al. . Unfortunately, how the Wang et al. approach splits the problem up is not scalable, as when the problem gets larger so do the subproblems. Therefore, in the end the subproblems will expand to such a size that even they cannot be solved. The problem of ever expanding subproblems is the main focus of this thesis. We present a new approach that splits the problem into subproblems that are of constant size. Consequently, no matter how large the problem gets, all components can still be solved. Using our new method, we have been able to vastly outperform previous records set by quantum computers. However, our approach does not outperform current state of the art classical factoring methods. However, we also show that our new approach has limits. The increase in the amount of subprob- lems means an exponential increase in the spatial complexity when combining the solutions. Fortunately, we also present ways in which we can reduce the spatial complexity. These methods have a mixed success. However, they have meant that we can factor numbers that have more than triple the bit length than if we were not to use them. Finally, our techniques in reducing the spatial complexity have led us to discover a new weakness in RSA encryption. Therefore, potentially wreaking havoc on the security of the internet.","Factoring; RSA; QUBO; Quantum; prime number theorem","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:01ae0d69-cab9-475e-8c0b-ebe3750e4708","http://resolver.tudelft.nl/uuid:01ae0d69-cab9-475e-8c0b-ebe3750e4708","Seismic Performance of Glazed Curtain Walls. Connections: Experimental Testing and Finite Element Modelling","Nuñez Enriquez, Daniel (TU Delft Civil Engineering & Geosciences)","Bianchi, S. (mentor); Louter, P.C. (graduation committee); Schipper, H.R. (graduation committee); Messali, F. (graduation committee); Lori, G. (graduation committee); Delft University of Technology (degree granting institution)","2022","Seismic events have shown the hazardous and expensive consequences resulting from seismic damage of non-structural elements. For this reason, the concern regarding the seismic performance of glazed curtain walls has acquired more relevance in the building industry; however, there is still a gap of information in the literature about this topic. To contribute with a broader panorama about the seismic performance of CW, this thesis project is focused on the seismic of the connections within a curtain wall.<br/>This thesis intends to evaluate the performance of the connections that contribute to the seismic response of a glazed curtain wall with finite element models and experimental tests. To achieve this objective, several important points were taken into account. First, a literature study to understand what is a CW, and which are the components that may have influence in seismic design. Second, the two case-studies considered in this research are presented; in this section information about the specimens tested and types of tests performed is provided. Third, elaborate finite element models of the connections corresponding to each case study describing the criteria used. Finally, a comparison between the experimental and numerical results is elaborated to determine if the modelling approach is correct.<br/>The experimental tests were carried out with the collaboration of Permasteelisa Group, and the numerical models were elaborated with DIANA FEA software. Five connections were analysed in this research: mullion to mullion, transom to starter sill, top aluminium bracket and hook, starter sill- bottom steel bracket, and silicone by a non-linear analysis with incremental displacements. At the end of this analysis it was observed a good agreement in the behaviour of the frame to frame connections with a minimal over estimation of the stiffness of certain frame to frame connections. Regarding the connections involving brackets, it was observed that the behaviour in the in-plane horizontal direction can be affected by the rotation of this elements because bolted connections shall be modelled as rotational springs. Finally about silicone it was observed that there exists a good match between the experimental results and the numerical models. <br/>In conclusion, the modelling procedure was validated with experimental tests with relatively optimal results. Nonetheless, there are still limitations in the development of this topic that will be described in the recommendations but much more openness is expected in the future in terms of research on this topic.<br","Curtain Wall; Finite Element Modeling; Seismic Performance; Connections; Facade","en","master thesis","","","","","","","","","","","","Civil Engineering | Building Engineering - Structural Design","",""
"uuid:74d6e200-17dc-48be-bb12-971b697a2ffe","http://resolver.tudelft.nl/uuid:74d6e200-17dc-48be-bb12-971b697a2ffe","Investigation of the microstructural distribution in a trailing arm made of silicon-containing spring steel","Tzelepi, Angeliki (TU Delft Mechanical, Maritime and Materials Engineering)","Santofimia, Maria Jesus (mentor); Zhao, L. (graduation committee); Delft University of Technology (degree granting institution)","2022","The presence of bainite and retained austenite in advanced high-strength steels (AHSS) has grown a great interest in the automotive industry as simultaneously provides strength and the transformation-induced plasticity (TRIP) effect. This type of microstructure is present in modern trailing arms. A trailing arm is part of the air suspension system in heavy vehicles. In spring steels, such as the ones used to produce trailing arms, this combination of bainite and retained austenite is obtained by a heat treatment named austempering.<br/><br/>In this work, the microstructural distribution of a silicon spring steel (Fe-0.6C-1.63Si- 0.97Mn-0.48Cr) was investigated after austempering for 1 hour at 300o C. Microstruc- tural heterogeneity was investigated at different scales using optical microscopy, scan- ning electron microscopy (SEM), electron probe micro analysis (EPMA), X-ray diffraction (XRD), and hardness measurements. Observed heterogeneities were related to the pres- ence of thermal gradient, chemical segregation, and carbon gradient.<br/><br/>The results gave insights into the effect of the processing route on the microstruc- ture. After austempering, bainitic ferrite, martensite-austenite islands, and carbide par- ticles were observed. The thermal gradient was confirmed by the identification of auto- tempered M-A islands due to the slower cooling rate in the bulk of the material. More- over, chemical segregation of Si, Mn, and Cr parallel to the rolling direction was observed and confirmed from optical microscopy, SEM, and EPMA results. In regions with high concentrations of substitutional elements, the Bs temperature was locally reduced and the bainitic ferrite formation kinetics was slow. Carbon gradient in M-A islands was ob- served as carbide precipitation occurred at the center of the island indicating that the carbon content was lower compared to at the edges of the constituent. Furthermore, in areas of the trailing arm with lower fractions of retained austenite (≺ 8%), bainite forma- tion was ceased based on the To curve (austenite reached a specific carbon content over which growth of bainite based on the diffusionless theory is not possible). These results indicate that bainitic ferrite advances non-uniformly through the trailing arm.<br/><br/>Based on these indications, the carbon gradient had a more significant effect on the bainitic ferrite formation in the spring steel during austempering compared to the ther-mal gradient and chemical segregation.<br","","en","master thesis","","","","","","","","","","","","Materials Science and Engineering","",""
"uuid:515b4427-dd16-4096-9f47-a9b870d92d9f","http://resolver.tudelft.nl/uuid:515b4427-dd16-4096-9f47-a9b870d92d9f","Fighting Malaria Using Gene Drives: Worthy Tool or Waste of Time?: A Safe-by-Design Assessment for Gene Drive Organisms","Cohen, Hod (TU Delft Applied Sciences)","Asveld, L. (mentor); Bouchaut, B.F.H.J. (graduation committee); Delft University of Technology (degree granting institution)","2022","Malaria is both an economically and medically burdensome disease taunting people worldwide. Treatments for the disease – transmitted by malarial Aedes and Anopheles mosquitoes infected with Plasmodium – are either temporary or in developmental stages, while rising insecticidal resistance and mosquitoes’ behavioral changes call for a lasting solution to responsibly fight malaria. The application of gene drive (GD) technology – biasedly propagating genetic material into a population using CRISPR/Cas9 – has been suggested. By introducing a sex ratio bias into malarial mosquito populations, or by targeting the mosquito’s interaction with the Plasmodium-parasite, malaria could be eradicated. The design, testing and implementation phases of GDs must, however, be approached with caution, due to the invasive nature of and controversy around the technology. To prevent harmful consequences, the risk management strategy of Safe-by-Design (SbD) was used to compose a set of guidelines for selected SbD Risk Categories. Academic literature and scientist interviews were used to obtain insights of possible risks and to find balance between medical progress and technological threats. Stakeholder involvement was found to be an important part of the GD design process, with a multidisciplinary team of experts, appointed and enforced by international organizations. The team must be held co-responsible for compliance with the guidelines of all four SbD Risk Categories, covering (i) unintended effects on non-target organisms and ecosystems, (ii) horizontal gene transfer (HGT), (iii) pathogenicity and toxicity, and (iv) run-off risk and reversibility. Key findings include previously proposed models, including an inhibitory rock–paper–scissors and a confining split-drive model for GD regulation. After carefully considering the available knowledge and the guidelines necessary for responsible research, I concluded that further research into mosquitoes’ ecosystems, target-specificity, HGT prevention and the theoretical GD models is required.","gene drive; malaria; Safe-by-Design","en","bachelor thesis","","","","","","","","","","","","Life Science and Technology (LST)","",""
"uuid:4e35fe88-bb7d-4379-ae98-8ca1444093e1","http://resolver.tudelft.nl/uuid:4e35fe88-bb7d-4379-ae98-8ca1444093e1","Optimising storage assignment, order picker routing, and order batching for an e-grocery fulfilment centre: An exact and heuristic approach","Sterk, Merel (TU Delft Aerospace Engineering)","Gerritsma, M.I. (graduation committee); Roling, P.C. (graduation committee); Bombelli, A. (mentor); Delft University of Technology (degree granting institution)","2022","With (e-)grocery retailers striving to increase their efficiency and subsequently reduce their costs, the opportunities that lie in optimising the order picking process of the supply chain is of key importance. The complex nature of assigning articles to an optimal storage location, having efficient routing of order pickers, and optimised grouping of orders calls for an integral approach to these problems. The objective of the research is to reduce the travelled distance of order pickers and subsequently the costs of the order picking process. Next to the integral approach, a new method of Multiple Storage Locations (MSL) is introduced. Historic order data of an e-grocery retailer is used, together with information on stock keeping units (SKUs), to implement SKU allocation with MSL possibility, routing, and batching into models. This ensures that the cost saving effects of these measures can be quantified. A benchmark Mixed Integer Linear Programming model (MILP) is developed and compared to a meta-heuristic Adaptive Large Neighbourhood Search model (ALNS) to determine how much travelled distance would be saved. The ALNS has multiple destroy- and repair heuristics, some of which are novel, that are specific to the problem at hand. The ALNS is able to handle bigger instances than the MILP, whilst ensuring quality of the solution. The MILP model outperforms the ALNS for small instances, however for large instances (instances of 400 orders or more) the ALNS performs, on average, 12.5% better whilst reducing computational time by 14.8%. Finally, areas of improvement are suggested in the ALNS model as well as other effects that should be studied when introducing MSL.","Routing; MILP; ALNS; Batching; Storage assignment; e-groceries","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:8805870c-aa1f-4bdb-92af-e9458773806d","http://resolver.tudelft.nl/uuid:8805870c-aa1f-4bdb-92af-e9458773806d","Development of a Pullback Device for Intravascular Ultrasound and Photoacoustic Catheter Imaging","Tesselaar, Izaka (TU Delft Mechanical, Maritime and Materials Engineering)","French, P.J. (mentor); van Soest, Gijs (graduation committee); Delft University of Technology (degree granting institution)","2022","Introduction – Cardiovascular diseases are the leading cause of death in the world with one in three succumbing to the disease. The most common cardiovascular disease is coronary artery disease, caused by atherosclerosis resulting in a build-up of plaque within the arteries. This plaque can progress into a vulnerable plaque, which has been linked to an increase in major adverse cardiac events. Identification of a vulnerable plaque can lead to more precise treatment, better patient outcomes, and fewer reinterventions. A technique currently in development is intravascular photoacoustic catheter imaging combined with intravascular ultrasound, which can detect both the composition and the structure of a plaque. Current pullback devices – a device for driving the catheter – don’t exist for a clinical setting for this application and are used for research purposes only. This project is a design study looking into the different aspects that go into the development of such a product with the aim of usability, divided into two goals: Exploring the catheter connection to the pullback device that is suitable for users of the product, and the redesign of the pullback device.<br/>Methods and Materials – The first part concerns the design of the catheter connection to the pullback device for users of the product. The users are interventional cardiologists and anyone who interacts with the device in a clinical setting. Catheter connector designs are prototyped and central to a short user experience study. The design space for current catheter connector devices is explored and four connectors are designed. A user experience study is made with the aim of obtaining feedback on different design aspects and what this user group prefers in catheter connector devices. The second part concerns the redesign of the system. A system design is proposed within the set requirements.<br/>Results – Catheter connector designs are designed and 3D printed, assembled and placed in mock-up pullback devices as prototypes. These have been shown to users of the product during a user experience study. This study has shown that users (n=5) have clear preference for some design aspects, such as a twisting connection, relatively small connection devices, automatic signal connection parts, among others. A redesign of the system is performed within the set requirements, where design aspects and their consequences are considered. This is done through an iterative design process to enquire feedback from technicians, until a satisfactory system is proposed. This includes the signal transfer to the catheter and back, the rotation of the catheter, the pullback of the catheter, and its housing. <br/>Discussion – Catheter connection design aspects have been explored after which a system redesign is proposed. This redesign lacks the connection between the signal connectors of the catheter and the pullback device. This connection is highly dependent on the disconnection method, which is non-trivial and infeasible to explore in this user experience study. The catheter connector could encompass a project in itself. The system redesign originally was aimed at the manufacture of the device, but was deemed infeasible for this project. Instead the project was aimed to be a design study of the development of such a device. As it stand, the current device is larger than preferred by users, which could be scaled down in collaboration with parts manufacturers. This can also downscale the motor for rotation, which is implemented to work at the devices maximum expected power requirements.<br/>Conclusion – This thesis focused on the design study of a pullback device for intravascular photoacoustic and ultrasound catheter imaging for users of such a device. Catheter connection design aspects have been explored after which a system redesign is proposed considering the many different aspects that go into such a design. All designs have been handed over to Kaminari Medical","Intravascular Photoacoustics; Intravascular Ultrasound; User experience design; Medical device design","en","master thesis","","","","","","","","2022-12-19","","","","Biomedical Engineering","",""
"uuid:487352e2-fcae-419e-81ec-23efbf263700","http://resolver.tudelft.nl/uuid:487352e2-fcae-419e-81ec-23efbf263700","Solving a flexible resource-constrained project scheduling problem for an e-grocery fulfilment centre: a meta-heuristic approach: Master thesis Aerospace Engineering","van Teeffelen, Jop (TU Delft Aerospace Engineering)","Bombelli, A. (mentor); Pavel, M.D. (mentor); Lourenço Baptista, M. (mentor); Boekema, F. (graduation committee); Delft University of Technology (degree granting institution)","2022","class=""MsoNormal"">The demand for online shopping has grown tremendously in the last couple of years. Picnic, a major player in the online grocery industry, is struggling to achieve long-term growth within its current operations. Scheduling and planning are key drivers for maintaining operational efficiency. The Fulfilment Centre (FC) and Distribution Centre (DC) costs heavily depend on efficient operations. This research focuses on improving the scheduling process in an e-grocery FC and DC. The main objective of the model is to maximise the quality of the schedule, which is achieved through two lexicographical objectives. First, the make span is minimised to improve efficiency and to calculate the number of employees required to fulfil the workload. The make span of a schedule is defined as the time between the first scheduled activity i and the last activity j in a schedule s. Next, the number of switches between activities is reduced. The second objective is to increase overall productivity since switching moments cause slack in the operations. Two solution methods are proposed to solve the Flexible Resource Constrained Project Scheduling Problem (FRCPSP). The first solution method is a Mixed Integer Linear Programming (MILP) formulation that is solved with a Branch &amp; Cut (B&amp;C) algorithm. Next, a meta-heuristic is proposed named Variable Neighbourhood Search (VNS). The initial solution is computed by solving the MILP for one objective, minimising the make span. Next, the VNS uses nested neighbourhoods to modify the answer resulting in fewer switches per schedule. For small instances, the exact formulation outperforms the meta-heuristic in most cases. Conversely, the meta- heuristic features a higher efficacy and efficiency when tackling more significant instances, being the only solution method capable of yielding feasible solutions for real-world scheduling problems. Despite the effectiveness of the proposed meta-heuristic, some operational adjustments are still required before implementing the proposed decision-making tool.","Project scheduling; Job Shop Scheduling Problem; E-groceries; Flexible Resource Constrained Project Scheduling Problem; meta-heuristic; Variable neighbourhood search","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:8c25833a-1f07-4786-aae2-36d0464e6040","http://resolver.tudelft.nl/uuid:8c25833a-1f07-4786-aae2-36d0464e6040","Optimization of Curved Introducer Device's Dimensions and Insertion Path in Safe Neurostimulation Against Pain (SNAP)","Li, Zhixin (TU Delft Mechanical, Maritime and Materials Engineering)","Dankelman, J. (mentor); Horeman, T. (graduation committee); Konings, Maurits (graduation committee); Delft University of Technology (degree granting institution)","2022","","","en","master thesis","","","","","","","","2024-12-19","","","","Biomedical Engineering","",""
"uuid:807f305b-320f-4762-a697-debf9324fca8","http://resolver.tudelft.nl/uuid:807f305b-320f-4762-a697-debf9324fca8","Kiosk Strategic Demand Forecasting with Scenario Planning: A case study at SITA","LIU, JIshan (TU Delft Civil Engineering & Geosciences)","Rezaei, J. (graduation committee); Pel, A.J. (mentor); Maknoon, M.Y. (graduation committee); Delft University of Technology (degree granting institution)","2022","SITA is the world’s leading specialist in air transport communications and information technology which works with around 400 air transport members and has 2800 customers in 190 countries. TS6 kiosk is the newest generation of its kiosk family and is facing a complicated situation now. Usually, the production of a kiosk is using make-to-order methods. However, if this method is adopted, the customers of SITA can not receive their productions within the expected periods of time. Besides this, SITA also can not get the procurement discount from the suppliers if they only purchase a low volume and do not make changes. In order to solve this problem, demand forecasting is conducted using the historical sales data of the TS6 kiosk. Through the literature review, suitable qualitative forecasting methods and quantitative forecasting methods which were mainly used in the FMCG industry are got together and combined to increase the forecast accuracy in this research to come out with the final forecast result of the TS6 kiosk. This research also explores the possibility of demand forecasting for the slow-moving consuming industry. By successfully conducting the final forecast, the result can help SITA to shorten procurement lead time so as to meet customers’ expectations as well as save total costs.<br/>KeyWords: Demand Forecasting, Quantitative Forecasting Methods, Qualitative Forecasting Methods, ARIMA, SARIMA, Residual Analysis.","Demand Forecasting; Quantitative Forecasting Methods; Qualitative Forecasting Methods; ARIMA; SARIMA; Residual Analysis","en","master thesis","","","","","","","","2024-12-12","","","","Civil Engineering | Transport and Planning","",""
"uuid:7de1d918-1316-48b3-9345-1982af9b0b91","http://resolver.tudelft.nl/uuid:7de1d918-1316-48b3-9345-1982af9b0b91","The Sustainability Transitions Platform: A digital innovation platform that serves as a tool for development of sustainability transitions research and as a bridge between theory and practice","Blom, Peter (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Technology, Policy and Management; TU Delft Energie and Industrie)","Kamp, L.M. (mentor); Ortt, J.R. (graduation committee); Delft University of Technology (degree granting institution)","2022","Sustainability transitions is a complex multi-dimensional research field. In this field, different frameworks exist that have grown as separate strands while they actually contain many similarities and in some cases can even complement each other. In general, these frameworks try to present and clarify the processes related to transitions of socio-technical systems and the emergence, diffusion and utilization of technological innovations. To do so, researchers carry out historical event analyses for specific cases. This means that they gather, process and analyse data about events that have happened in the past to build a narrative of how an innovation has developed or a transition took place over time. Although there are guidelines in literature on how this should be done for each framework, the case results as presented in academic papers are often varied and the clarification behind the results and the used data can be unclear.<br/>In this research an attempt has been made to reduce this variance and unclarity by building a tool in which the data gathering, categorizing and processing of sustainability transitions research cases is done structurally and the data itself is systemically presented through visualisations. This tool is a software based digital platform, referred to as the Sustainability Transitions Platform (STP). In the first draft of the platform functionalities have been limited and the sustainability transitions theory has been focused on the Multi-Level Perspective and Technological Innovation Systems. These are two of the most frequently used frameworks in the field and a combination of both is already being experimented with taking advantage of their commonalities and complementarities. <br/>The combined framework contains three elements that are deemed important to build the system of the case. These are i) the environment in which the technological innovation system resides; ii) the actors, networks and institutions of the system; iii) the functions analysis tool to determine how the parts of the system are functioning. <br/>These elements have been translated to the platform as three separate visualization tools, which are:<br/>1. Technology environment, which presents the technology being analysed within a graph together with other technologies relevant for the analysis as comparison and landscape factors that influence the system.<br/>2. Structural components, which presents all the actors, in a structured way through predefined groups, and their networks in the same graph and also present the relevant institutions in an adjacent table.<br/>3. TIS functions analysis, which presents how the system is functioning in a radar chart based on a set of functions and their corresponding indicators.<br/>These visualization tools are intended to present the case data in a structured way in order to help users of the platform better understand the system development process and make it comparable between cases.<br/>The platform template has been tested through a case for offshore wind energy technology in Brazil.<br/>From this case we have seen that i) the data does indeed need to be implemented structurally; ii) the visualization tools in the platform present the system through the three required elements of the framework; and iii) the platform user is able to determine possible bottlenecks for further development of the system. Another advantage gained by carrying out the case in a platform instead of how they currently are in journals, is that the digital aspects of the platform allow users to interact with the visualization tools and the underlying data which can help clarify the reasoning behind the conclusions of analysis. From the case we have also learned that in the current version of the platform i) inputting the data can be very time consuming and should in the future be automated; and ii) some essential aspects of the case are still not presented in the visualization tools, for example, the power or influence specific actors have in a system, which should be taken into account in future versions.<br/>The STP appears to have a positive effect on sustainability transitions case implementation and would be recommended to be further developed. Given its dynamic nature it should also be used as an experimentational tool to merge the strengths of other frameworks in sustainability transitions research to eventually generate a single more complete framework and act as a bridge between theory and practice.","Sustainability transitions; Platform; Multi-Level Perspective; Technological Innovation Systems","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:a64b3239-6ad8-4fea-aec9-346d0da18d13","http://resolver.tudelft.nl/uuid:a64b3239-6ad8-4fea-aec9-346d0da18d13","Translating Automata: Comparing Automata Based on Intrinsic Characteristics","Houtman, Marco (TU Delft Electrical Engineering, Mathematics and Computer Science)","Verwer, S.E. (mentor); Tax, D.M.J. (graduation committee); Delft University of Technology (degree granting institution)","2022","Established research that is done on finding similarities between two finite automata, or finite state machines, is based on matching symbols that are shared between the two automata. In our research, we define a scenario in which the shared alphabet is either partially or completely obscured due to translations. We emulate a scenario where 2 probabilistic deterministic finite automata (PDFA) are created based on the same process, but with different definitions for each step of the process. We introduce three methods that make use of different properties in the automata to establish a translation between the two PDFA that have mismatched alphabets. The first two methods: Total frequency distribution, and depth frequency distribution match symbols based on their relative similarities. Our third method, state frequency comparison, calculates a similarity between two states based on their inherent structure and matches symbol translations based on the established state similarities. In our results we show that when comparing automata to itself where a number of symbols are translated, all three methods score high on accuracy, returning similarity scores over 80% when 50% of the symbols are translated. The addition of random traces reduces the similarity scores of all three methods, indicating that the robustness of the methods can be improved. In a set of 90 comparisons, 7 comparisons were chosen as the most similar automata pairs. Each of the proposed methods manages to determine 5 of the most similar automata within their top 10 approximations. Finally, a number of clusterings of 10 automata were created with help of a relative similarity table containing 100 comparisons. For one of the datasets the method state frequency comparison manages to create a similarity table that generates clusters that are identical to the original clusters for cluster sizes 2,3 and 4, returning a rand index of 0.88 for cluster size 5.","Finite Automaton; Automaton Comparison; PDFA","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:d0cca0af-8df0-44c8-8aae-beead7e1d702","http://resolver.tudelft.nl/uuid:d0cca0af-8df0-44c8-8aae-beead7e1d702","Shifting perspectives: Applying systemic design to strategise long-term impact for parents of children with special needs","van Loon, Carine (TU Delft Industrial Design Engineering; TU Delft Design, Organisation and Strategy)","van der Bijl-Brouwer, M. (mentor); Gonçalves, M. (graduation committee); Schot, M. (graduation committee); Delft University of Technology (degree granting institution)","2022","This graduation project was in cooperation with Ontzorghuis, a Dutch charity that is focused on supporting the parents of children with special needs (CSN). It is crucial that CSN parents receive extra support, especially in the early stages when the child's diagnosis is still unclear. Parents of a CSN have extra responsibilities and care, which can easily overwhelm them and lead to burnout. In fact, 78% of CSN parents started working less after getting their child, and 60% ended up overworked and burned out (Okma, Naads, Vergeer &amp; Berns, 2014) . Their extra care can also lead to an escalation: if the parents' well being is declined too much, the CSN has to be placed out of home. However, currently the Dutch care system is focused and structured around the child with special needs, not on the parents. Parents of special needs children are currently not seen as informal carers, giving them no right to extra support (Ross, 2020). This leaves the parents in a vulnerable position. The goal of this project is to use systemic design to develop a strategy for Ontzorghuis, to have a long-term impact on these parents.<br/><br/>After researching the context, several key actors in the system around CSN parents were identified: the national government, municipal councils, the care domain, charities and network. Ontzorghuis is part of the charity actor. For each of the actors, one or more interviews were conducted with someone working in this domain, 12 in total. The insights of the interviews were combined with those from literature research, to analyse the interactions between the actors. This forms the basis of the system map. The map consists of 25 points, representing the challenges actors have to face together. This system map was then used to investigate the possibilities for systemic impact for CSN parents. Leverage points were identified, and used to map out future interventions. The insights were converted into an actionable strategy for Ontzorghuis. <br/><br/>The first step of the strategy is to make CSN parents visible within society. The graduation design therefore had the goal of helping actors reflect on their role in the system around CSN parents. Storytelling was chosen as the mechanism to convey the system, as ""storytelling allows for thorough understanding of complex systems with limited time investment and without requiring expertise on systems design"" (Talgorn &amp; Hendriks, 2021, p. 50). Using storytelling also allowed room for the empathy needed for this vulnerable but inspiring target group. The end result is a children's book for any actors of the system, using a metaphor to tell the story of a CSN parent interacting with the system, and inviting readers to reflect.<br","systemic design; CSN parents; system map","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:eb283676-b5a7-42fe-bdda-c3ca3fae708b","http://resolver.tudelft.nl/uuid:eb283676-b5a7-42fe-bdda-c3ca3fae708b","Time-domain investigation of the ro-vibrational CH<sub>4</sub> v<sub>2</sub> Raman spectrum via fs/ps CRS for combustion diagnostics","Thornquist, Ona (TU Delft Aerospace Engineering)","Bohlin, G.A. (mentor); Mazza, F. (graduation committee); Delft University of Technology (degree granting institution)","2022","With the onset of climate change it is crucial to eliminate emissions, particularly for aviation reliant on gas turbine combustion. Computational models aid combustor improvement, but experimental data needed for validation is difficult to obtain. Fortunately, laser diagnostics can now achieve non-intrusive, high-resolution combustion measurements, especially with hybrid femtosecond/picosecond (fs/ps) coherent Raman scattering (CRS). In this thesis, the goal was to develop hybrid fs/ps CRS spectroscopy for the CH<sub>4</sub> ν<sub>2</sub> vibrational mode. Methane merits investigation as a climate forcer alongside potential use in carbon-neutral hydrogen production. Time-resolved CRS was performed for collision-independent, collisional dephasing, and laminar CH<sub>4</sub>-air flame measurements. A time-domain model well-reproduced experiments, along with extracting molecule-specific ν<sub>2</sub> Q-branch dephasing linewidth parameters. Additionally, fundamental physio-chemical processes were observed in a spectral molecular fingerprint region across the CH<sub>4</sub>-air flame: CH<sub>4</sub> dissociation, H<sub>2</sub> synthesis and consumption, mass diffusion, and fuel/oxidizer mixing.","Laser diagnostics; Spectroscopy; Coherent anti-Stokes Raman scattering (CARS); Methane; Combustion","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:e72a05ef-df32-4c08-aa1d-95d8c5828a2a","http://resolver.tudelft.nl/uuid:e72a05ef-df32-4c08-aa1d-95d8c5828a2a","Exploring Copula-Based Models for the Stochastic Simulation of Information Retrieval Evaluation Data","Theodorakopoulos, Dimitris (TU Delft Electrical Engineering, Mathematics and Computer Science)","Urbano, Julián (mentor); Delft University of Technology (degree granting institution)","2022","In the field of Information Retrieval (IR), the reliable evaluation of systems is a key component in order to progress the state-of-the-art. Much of IR research focuses on optimizing the various aspects of evaluation. Stochastic simulation is one technique that can be used to assist this kind of research. It allows researchers to overcome certain limitations associated with IR data, such as limited size, and lack of control. Recently, there have been two parallel lines of work that use stochastic simulation to study the question of ""which statistical significance test is optimal for IR evaluation data?"". Surprisingly, the authors reach different conclusions, despite the fact that both use stochastic simulation. One line of work, lead by Urbano et al., simulates scores for a fixed set of systems on new random topics, and concluded that the t-test is optimal. Another line of work, lead by Parapar et al., simulates new random retrieval runs for a fixed set of topics, and concluded that the Wilcoxon test is optimal. Interestingly these two tests are the most popular in IR literature. In an attempt to shed some light on this disagreement between the two conclusions, we made a first attempt at providing some empirical evidence regarding the quality of the simulation approach that was used by Urbano et al. Our main findings is that the quality of the simulation is moderately good, and also discovered some opportunities to refine it. In addition, we proposed a new model selection criterion, that showed some promising results, and in many cases managed to select models more optimally than other, more established criteria, such as AIC.","Information Retrieval; Evaluation; Copula; Simulation","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:6c1da590-3ea8-43d5-aba4-90da1c941c48","http://resolver.tudelft.nl/uuid:6c1da590-3ea8-43d5-aba4-90da1c941c48","PINNs for parametrized problems","van Ruiten, Frank (TU Delft Electrical Engineering, Mathematics and Computer Science)","Möller, M. (mentor); Toshniwal, D. (graduation committee); Delft University of Technology (degree granting institution)","2022","Physics Informed Neural Networks are a relatively new subject of study in the area of numerical mathematics. In this thesis, we take a look at part of the work that has been done in this area up until now, with the ultimate goal to develop a new type of PINN that improves upon the old concept. We introduce the concept of parameterized PINNs, which allow a single trained network to solve multiple partial differential equations for multiple boundary conditions and geometries by parametrizing these variables as an input for the network. Two methods are tested: one using global basis functions, and one using B-splines. The proposed methods are tested for Laplace’s equation and Poisson’s equation in multiple dimensions, most of which show that these methods are viable alternatives for the current style of collocation-based PINNs.","PINNs; Neural Networks","en","master thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:8d7c17f3-0812-4ad2-afcf-7ea7cb000449","http://resolver.tudelft.nl/uuid:8d7c17f3-0812-4ad2-afcf-7ea7cb000449","Automated Guide-Path Map Generation for Automated Guided Vehicle Systems: An Algorithmic Framework","Endlich, Luuk (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Cognitive Robotics)","de Winter, J.C.F. (mentor); van Rhee, Erik (mentor); van Eekelen, Joost (mentor); Eisma, Y.B. (graduation committee); Delft University of Technology (degree granting institution)","2022","The design of a guide-path map is a well-known problem in various industries, such as automated guided vehicle (AGV) systems, road networks, and train track design. Nowadays, designing a path map is a manual, time-consuming, and expensive process. The solutions often turn out to be far from optimal. Several approaches are known to generate path maps automatically. The main challenges are computation efficiency due to large solution spaces and the lack of feasibility of solutions for application to real-world layouts. Little research focuses on the importance of computational efficiency to keep up with the pace of dynamic user requirements and constraints.<br/><br/>The goal is to design a framework that balances computational efficiency with feasibility in automated path map generation. A feasible path map can continuously distribute requested flow targets and is practically useable without many manual changes. It is expected that less optimal but still feasible solutions can be generated more efficiently by using a smaller solution space.<br/><br/>The framework consists of four stages: a practical problem, a mathematical model, a mathematical solution, and a practical solution. All solutions are theoretically validated on two aspects: capacity and performance.<br/><br/>The framework is tested using three layouts: low complexity and small-scale, complex and large scale, and one in between. The exploratory model outperforms in the complex large-scale layout while the goal-oriented models outperform in the other layouts.<br/><br/>Path maps are generated in a reasonable and controllable time. The settings allow a trade-off between the efficiency and feasibility of solutions. Due to its efficient computation, the model has the potential to generate path maps that are directly usable in real applications, if several realistic implementations are included to improve the feasibility of solutions.<br","path generation; AGVs; Path Finding; Linear programming","en","master thesis","","","","","","","","2025-12-19","","","","Mechanical Engineering | Vehicle Engineering | Cognitive Robotics","",""
"uuid:d2322bfd-248e-411c-8e75-c8ef295de9a5","http://resolver.tudelft.nl/uuid:d2322bfd-248e-411c-8e75-c8ef295de9a5","The Connectivity of the Long-distance Rail and Air Transport Networks in Europe","Bruno, Francesco (TU Delft Civil Engineering & Geosciences; TU Delft Transport and Planning)","van Wee, G.P. (mentor); Cats, O. (graduation committee); Bombelli, A. (graduation committee); Delft University of Technology (degree granting institution)","2022","Demand for long-distance transport has been steadily increasing over the last years, worsening the environmental impact of the transport sector. Despite European governmental bodies and policy-makers directed considerable efforts towards the substitution of short-haul flights with greener rail alternatives, the desired results do not appear to have materialised yet. This study contributes to the literature by providing a broad overview of the current state of rail and air service supply in the European market and identifying the most significant nodes and links within the network. Furthermore, the connectivity index proposed by this research allows to compare the performances and the attractiveness of the two modes. Overall, this study shows that air efficiently connects most major European cities, whilst, in the rail network, considerable inequalities in terms of performances across different geographical locations are still present. From this picture, derive two main conclusions. First, the rail network has substantial limitations and constraints on longer distances, and second, the sector is more fragmented and less cohesive than air. To minimise the environmental impact of long-distance transport, it appears beneficial to focus on capturing the demand for connections shorter than 500 km by fostering inter-modality and air-rail integration, enhancing rail performances and opening new competitive direct routes on OD distances longer than 500 km. Currently, rail appears to be more complementary to air, rather than competing with, as the inter-modal competition is limited to shorter routes. However, the results suggest that rail has the potential to be competitive with air also on longer routes, either by offering more direct services, improving schedule coordination, or increasing the supply of high-speed and night train services. In this regard, it is worth noting that more attention should be devoted to analysing the specific infrastructural gaps and the optimal directions for investments. Finally, this paper identifies the main bottlenecks hindering the capacity of rail to compete and substitute air, suggesting that these barriers are not limited but go beyond the network performances and service supply perspectives.","Connectivity; Long-distance travel; Air to rail modal shift; European transport network; Substitutability; Competitiveness","en","master thesis","","","","","","","","","","","","Transport, Infrastructure and Logistics","",""
"uuid:8863838d-5ee1-4fee-ad82-46cf5a972ff5","http://resolver.tudelft.nl/uuid:8863838d-5ee1-4fee-ad82-46cf5a972ff5","Computing multiphase flow induced forces by multiphase CO2 in pipelines using OpenFOAM","Mohammed Rajiv, Adila (TU Delft Mechanical, Maritime and Materials Engineering)","Pourquie, M.J.B.M. (mentor); Twerda, Aris (mentor); Delft University of Technology (degree granting institution)","2022","The need to curb CO2 emissions has led to an increase in the utilization of CCS systems. These systems use pipelines for the transport of CO2. It is preferred that CO2 be transported in it’s dense form. But, this is not always the case as the phase in which CO2 exists is based on the operating conditions. In some cases, multiphase CO2 is observed in pipelines. These multiphase systems tend to vibrate due to the dynamic nature of multiphase flows in pipelines. These vibrations can lead to fatigue in these systems. In such a situation it is important to understand the multiphase flow induced forces caused by mutliphase CO2. TNO has conducted experiments on MEG-gas systems as well as multiphase CO2 systems which act as the reference research work for the thesis. In this thesis, the multiphase CO2 system is simulated and is compared with the MEG-gas system. The simulation results helped in understanding how the difference in properties of fluids affects the multiphase flow induced forces. The CFD results of multiphase CO2 show a similarity of 70% of the RMS forces. From the simulations, we can see that the lower density difference, liquid viscosity, and surface tension of multiphase CO2 as compared to MEG-gas results in dispersed flow as compared to stratified wavy flow in MEG-gas. The influence of inlet length is also discussed which showed that there is indeed a difference in the way fluid behaves when the inlet length is increased. The different numerical parameters like timestep, mesh resolution, wall treatment, and solvers are also explored here. This work shows that even though the expected flow regime is accurately simulated, there is a discrepancy when it comes to calculating the flow induced forces using OpenFOAM.","Multiphase CO2; Flow induced forces; OpenFOAM; compressibleInterFoam; CCS; Flow regimes; Bends","en","master thesis","","","","","","","","","","","","","",""
"uuid:b18ffc16-28f1-4957-9bf7-2175ca6a641d","http://resolver.tudelft.nl/uuid:b18ffc16-28f1-4957-9bf7-2175ca6a641d","Hydropower Potential in Indonesia: Assessment of theoretical, technical and economic potential of hydropower","Permata, Citra Septa (TU Delft Civil Engineering & Geosciences)","Uijlenhoet, R. (mentor); Hoes, O.A.C. (mentor); Farid, Mohammad (graduation committee); Langer, J.K.A. (graduation committee); Delft University of Technology (degree granting institution)","2022","Indonesia has a severe problem of fossil fuel dependency, making it become one the world’s larger carbon emission contributor. At the same time, the growing population will increase the energy demand in the future. Thus, in order to meet the energy demand and decrease the carbon emission, the government together with PLN as the state electricity company will committed to implement carbon neutral targets by 2060. Additional of 413 GW installed power capacity will be necessary in which 308 GW generated from renewable energy. Indonesia has many renewable energy alternatives that can be utilized such as solar, wind, biomass, and hydropower. Among various renewable energy alternatives, hydropower has emerged as one of the means to achieve the aforementioned targets. Indonesia has a hydropower potential of around 75 GW from large hydropower and 19.4 GW from small hydropower, meanwhile, due to a number of barriers, hydropower contributed only 7% from installed large-scale hydropower and 2% from installed small-scale power plants.<br/><br/>In order to reach the government’s goals, further study is needed to better understand the hydropower potential in Indonesia. Hence, the aim of this research is to quantify the potential of hydropower for Indonesia to find the possible location based on the economic consideration and to understand the positive influence of hydropower application. The analyses will be done using GIS-based modelling approach based on three DEM sources with 3 different resolutions, namely DEMNAS (0.27 arcseconds), USGS (1 arcsecond) and MERIT (3 arcseconds). The gross theoretical potential will be calculated based on the river discharge and the head of every pixel of the DEM. Further, the technical potential could be obtained by eliminating the output of theoretical potential with contraints area. Subsequently, the cost components (e.g investment and operational cost) will be added to the model to quantify the levelized cost of electricity (LCOE). The potential location that has LCOE lower the cost of power generation.<br/><br/>Based on the analysis, the theoretical potential in Indonesia ranges for approximately 159 GW to 182 GW, or in annual energy production amounts to 1400 TWh to 1600 TWh. Subsequently, the technical potential after eliminating the constraints area decreased to around 550 TWh (63 GW) – 700 TWh (80 GW). On the other hand, based on the technical potential results, the LCOE ranges from 1 to 69 cent USD/kWh. However, only around 45% of the total technical potential is economically feasible. Thus, the hydropower potential lowered to 240 TWh (10 GW) – 690 TWh (38 GW). According the results, hydropower could cover 9% to 25% of the total required additional capacity planned by PLN and could reduce the carbon emission around 90% compared to the carbon emission of fossil fuels. Since this study used three different DEM resolutions, the output of the analyses varies depending on the DEM used. Based on the results, higher resolution DEM could delineate river shape better and thus the location of estimated hydropower potential location could be more accurate. However, DEM with larger pixel size could detect better the medium and large hydropower potential","Hydropower; GIS; Theoretical potential; Techno-economic potential; Indonesia","en","master thesis","","","","","","","","","","","","Water Management","",""
"uuid:38ff5352-6d56-46e8-a5ce-b65e703cda2f","http://resolver.tudelft.nl/uuid:38ff5352-6d56-46e8-a5ce-b65e703cda2f","Assessing meditation through electroencephalographic data: a dynamical systems approach","van Engen, Femke (TU Delft Mechanical, Maritime and Materials Engineering)","Gonçalves Melo Pequito, S.D. (mentor); Brouwer, Anne-Marie (mentor); Van de Plas, Raf (graduation committee); Vardar, Y. (graduation committee); Delft University of Technology (degree granting institution)","2022","Meditation is a contemplative practice that is believed to entail attentional and emotional regulation. One of the biggest challenges in developing personalized, accessible healthcare options with meditation is finding understandable features that signify whether someone is meditating. Specifically, there is no consensus on a feature resulting from the electroencephalogram (EEG) in the current body of literature on meditation.<br/><br/>In this thesis, I propose a dynamic systems analysis on EEG data to obtain a dynamic feature capable of distinguishing meditation from an eyes-closed resting baseline. I gathered the EEG data at TNO (Dutch Organisation for Applied Scientific Research) from twenty-two participants during a sixteen-minute loving-kindness meditation and two two-minute baselines. The proposed methodology characterizes temporal and spatial characteristics of the EEG simultaneously by approximating the EEG dynamics with a linear model on short time windows. I assess changes among three features: the frequency and magnitude of the oscillatory dynamics and the corresponding active electrodes.<br/><br/>The analysis can identify changes in EEG dynamics for each individual. Across all participants, regions associated with vision and language processing were active throughout the experiment. Notably, attention-related regions were more involved during meditation than rest. Moreover, the results show a shift in active regions throughout the meditation and the baselines for several participants.<br/><br/>Moreover, the thesis investigates the sensitivity of the analytical approach to changes in the electrode subset used for the analysis. For each participant, I constructed a subset of electrodes that were most involved in the changing EEG dynamics. The personalized subset was most sensitive to changes between meditation and rest, compared to other subsets based on commercial wearable EEG headsets. Finally, I compare the findings of the dynamic systems approach to a conventional analytical approach, and the participants’ emotional ratings inquired in subjective questionnaires. Unfortunately, from the current data, there appears to be no relationship between the proposed features and the conventional measures or the subjective questionnaires.","EEG; dynamic systems; eigenvalue-eigenvector decomposition; meditation","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:785f8735-6a25-4314-9daf-50c3bac299a9","http://resolver.tudelft.nl/uuid:785f8735-6a25-4314-9daf-50c3bac299a9","The Value of System Dynamics for Healthcare Resource Modelling","Lukács, Márk (TU Delft Technology, Policy and Management)","Hinrichs-Krapels, S. (mentor); Auping, W.L. (mentor); Delft University of Technology (degree granting institution)","2022","class=""MsoNormal"">It is no secret to hospital and public health managers thatresource shortages worsen pandemics. The importance of preparedness has longbeen recognized within the European Union. One of the current H2020 innovationprojects in this domain is PANDEM-2, aiming to improve pandemic preparednessfrom the side of resource management and sharing by creating cutting-edgedigital tools. As part of these tools, a system dynamics (SD) healthcareresource model is being developed, with the ultimate goal of embedding it in adashboard accessible to pandemic managers. This is done in order to supportmanagers in rapidly making evidence-based assessments and decisions, or as inthis thesis shortened, to provide situational awareness. In short, the specificproblem we were tackling was the exploration of how can pandemic preparedness canbe achieved via current healthcare resource models and how a specific resourcemodel (developed by a previous intern) can be used. First, to gain a generalunderstanding of the state-of-the-art models, we looked into the scientificliterature from two directions: We looked at how existing resource models work,are validated, and are used via literature review. For another perspective, welooked at scientific frameworks describing modelling and validation to informour methodology. Therefore, this thesis seeks to answer the question: <i>How tosupport healthcare resource managers in acquiring situational awareness via anSD model?</i> To gain a better understanding, we did a literature review first tounderstand how others approach the topic of healthcare resource modelling.</p><p class=""MsoNormal""> </p><p class=""MsoNormal"">We first analyzed the existing scientific literature by apreliminary search, which was also used to construct a more detailed andrefined second search. In this second search, we used the PubMed database tosearch for articles containing the keywords <i>hospital and healthcareresource</i>, <i>pandemic</i>, <i>model</i>, <i>validation</i>, andsynonyms. Then the returned articles were screened for relevancy, resulting ina total of 25 healthcare resource models analyzed. Within these analyzed models(and articles), we found that the most common approach is using SD models, andthe second most common approach is using regression models. Roughly two-thirdsof the models fall into these two categories. Furthermore, we found that there isa stronger focus on hospital resources than public health resources and that nocommon approach is used for model validation. We also found that the articlesdemonstrating that the model is used to support real-life decision-making wereusually not about SD models; therefore, examining how to use SD healthcareresource models for decision support is not mainstream. We also found that themodel used in our research is novel in the sense that it encompasses resourceson a more detailed level than existing published models.</p><p class=""MsoNormal""> </p><p class=""MsoNormal"">To further our understanding, we decided to answer ourresearch question by holding a workshop, where we examine how to communicatemodel outputs. While examining the relevant modelling methodologicalframeworks, we defined the tasks that need to be done in this thesis throughthe lens of the modelling cycle. We need to perform the tasks of verification,validation, and holding a workshop, which partly encompasses evaluation. Thenexamining the literature about verification and validation, we encountered theimplication of a well-known philosophical problem of scientific theories' formodelling: It cannot be demonstrated whether the model (or the theory) is atruthful description of the phenomenon.</p><p class=""MsoNormal""> </p><p class=""MsoNormal"">To overcome this problem, in modelling, validation refers tobuilding confidence that the model is fit for its purpose. In this study, thepurpose of the model changed from describing the different mechanisms foundimportant to generate semi-realistic outputs to be used in the workshop;therefore, it had to be revalidated. This was addressed by performing aparticular set of relevant validation tests. The model passed verification andthen the validation for this purpose, so we continued with the workshop. Wedecided that in the workshop, we would use a presentation to communicateintervention opportunities for the pandemic based on the model outputs. Thenafter each intervention, the participants were asked to evaluate the easinessof understanding the output and to talk about what actions the presentedinformation inspire. </p><p class=""MsoNormal""> </p><p class=""MsoNormal"">By holding the workshops, we found several relevant facts:First, it was found that the goal participants were searching for was to getrid of the perceived gap. This also meant they were searching for insights thatcould be used for operational planning purposes. Furthermore, the analysis doesnot need to stop at visualizing outputs. One of the participants indicated thatfurther analyzing the graphs is not as easy for them as for an analyst workingwith the model. We have also seen that participants tend to augment thepresented data with their experiences, which (unless explicitly presented)leads to assumptions about how the model works. Some participants also pointedout that the contact tracing part of the model is already outdated (in lessthan a year). We have identified some practical ways to avoid ambiguity whilecommunicating about healthcare resource models. First, we found that despitethe insights we gained by analyzing model outputs were not novel, thediscovered scenarios were still good discussion starters in the workshop. Thisis likely the mechanism of the scenarios acting as a reminder for passiveknowledge, which participants subsequently shared. Furthermore, extra careshould be taken to explain the context of how the data got generated, especiallyconcerning the model. As the presented data left some space for interpretation,participants sometimes had different assumptions than the ones coded into themodel. While these could be resolved in the workshop to some extent, this willnot be the case for the dashboard. Given some familiarity with the audience, itis possible to expect some questions and misunderstandings, which could beproactively addressed in a description or in a `frequently asked questions'. Wealso identified two presentation types that were easier to process thanpresenting key model outputs: The first option is to analyze key model outputsfurther than graphing and present the key insights (such as peak resourcedemand) in a tabular format. Alternatively, the second option is to build allvisualization on the same template and explain that template on the firstoccurrence in detail. In subsequent occurrences, it should be enough to pointout only the interesting parts and give participants time to process theinformation.</p><p class=""MsoNormal""> </p><p class=""MsoNormal""/><p class=""MsoNormal"">From another perspective, participants expressed a need fordata that can be used for planning purposes. However, given the uncertaintyabout the system, these, as we call consolidative models, cannot be constructedyet. While exploratory modelling is an alternative SD technique for addressingdeep uncertainty, it does not attempt to produce numerically accuratepredictions. However, from a novel perspective, the consolidative andexploratory approaches can be viewed as two ranges on the spectrum ofuncertainty about the modelled system. Viewed from this perspective, validationmeans reducing uncertainty about the system. Nevertheless, to achieve theconsolidative models, datasets about resource usage are needed, but as far aswe know, no such dataset exists. As data to create such datasets is probablyalready being collected for operational purposes, it is likely that thecollection and aggregation of these data are not happening. However, creatingsuch datasets comes with some challenges. There is a value trade-off betweenprivacy and preparedness through data collection, and the current datacollection techniques are unlikely to be unified. Overcoming these challengeswould need quite a significant upfront investment. To answer our originalquestion of how to support healthcare resource managers in acquiringsituational awareness, this thesis argues that, by far, the biggest utilitycould be achieved by strengthening data collection and aggregation, as itenables the possibility to develop surrogate models. However, as this requiresa significant upfront investment, question-driven exploratory models remain analternative way to address these uncertainties.","Healthcare; Resource; System Dynamics","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:58402751-d2ea-4184-bf2b-9830b38b59f2","http://resolver.tudelft.nl/uuid:58402751-d2ea-4184-bf2b-9830b38b59f2","Toward an inclusive work environment in the construction industry using digital tools","LEE, Jeongeun (TU Delft Civil Engineering & Geosciences)","Chan, P.W.C. (graduation committee); Heintz, John L. (mentor); Bosch-Rekveldt, M.G.C. (graduation committee); Delft University of Technology (degree granting institution)","2022","Women in construction are marginalised, and gendered work culture results in a higher turnover rate of early female professionals. On the other hand, after the COVID-19 pandemic, construction organisations have understood the need for digitisation to derive benefits from digital tools. Besides, it was presented that using digital devices may impact work &amp; employment and employees’ behaviour and organisational culture. In this context, the study aims to explore how the usage of digital tools at work influences the gendered work culture and how it can improve the early career experience of female employees in the construction sector.<br/><br/>This research employed two data collection methods: (1) a review of previous studies and (2) a series of semi-structured interviews. Reviewing previous studies aims to understand the trend and phenomena of the research topic to build a research framework. Career development challenges for female early career professionals: family-work balance; pay; stress; recruitment and selection; training; allocation of tasks and positions; work climate and condition; network; and career opportunity. Then, a series of semi-structured interviews were conducted. <br/><br/>This research suggests that using digital tools in communication results in misunderstanding, fewer opportunities for bonding and relationship building with colleagues and exclusion. Moreover, the usage of digital tools enables female employees to gain respect and be heard because the results of the digital tools support their opinion. Furthermore, the data-driven perspective promotes removing bias and subconscious bias in decision-making. On the other hand, hierarchy and pressure on budget and schedule hamper the implementation of digital tools at work practice. Besides, it was identified that these changes affect the experience of early female employees in the sector. The digital-related skillsets provided them with more job opportunities, breaking gender-stereotypical norms. A remote working environment enabled by digital communication made female employees balance work and life more manageable, and promotion decisions can be based on a data-driven perspective. Regretfully, digital communication disturbs the accommodation of new employees and socialising opportunities between colleagues. <br/><br/>It is recommended to facilitate training programmes for digital tools to improve and promote the benefits of using digital tools. In addition, more flexible network practices can also be provided to encourage socialisation, and fair and accurate data analysis programmes for promotion can be developed.","Diversity and inclusion; Women in construction; construction industry; Work environment; Work culture; Digitisation; Gender","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:38b66e00-9418-487e-8dba-bccdfcb3b0e6","http://resolver.tudelft.nl/uuid:38b66e00-9418-487e-8dba-bccdfcb3b0e6","Development of a motion guidance device for 4D CT scans of the wrist","Crezee, Wilrik (TU Delft Mechanical, Maritime and Materials Engineering)","Tümer, N. (mentor); Kraan, Gerald A. (mentor); Delft University of Technology (degree granting institution)","2022","","","en","master thesis","","","","","","","","","","","","Biomedical Engineering","",""
"uuid:55ae75b0-a1b3-4bee-8d08-4d26867928de","http://resolver.tudelft.nl/uuid:55ae75b0-a1b3-4bee-8d08-4d26867928de","Numerical Investigation of Stationary Crossflow Instability Evolution in a Rapidly Deformed Base Flow","Sen, Srijit (TU Delft Aerospace Engineering)","Kotsonis, M. (mentor); Hickel, S. (graduation committee); Casacuberta Puig, J. (graduation committee); Delft University of Technology (degree granting institution)","2022","The flow of air over a swept wing initially starts in a smooth laminar state (referred to as base flow) and entrains disturbances which subsequently grow and transition the flow to a chaotic, turbulent state. Active efforts have been made to study and control these disturbances, which manifest as stationary crossflow modes. Excrescences in the form of a forward-facing step (FFS) impose a base flow deformation in the form of a rapid near-wall pressure change, flow separation, and strong upwash. This modifies the behaviour of stationary crossflow instability and subsequently leads to an upstream or downstream shift of transition location depending on FFS height. The mechanisms responsible for the above behavioural modification are unknown, motivating the current thesis. The evolution of primary stationary crossflow instability, in its linear growth phase, is studied through a spanwise invariant, synthetic, and idealized rapid base flow deformation imposed by changing the near-wall pressure distribution of a clean swept flat plate (possessing a favourable pressure gradient) via Gaussian-like pressure variations. An energy balance framework is developed that identifies the production term's behaviour as the differentiator between regions of perturbation growth and decay. The behaviour of the production term is described by two competing mechanisms, the first controlled by wall-tangential base flow shear and the second controlled by wall-tangential base flow acceleration or deceleration. The balance of these mechanisms shows that perturbations grow faster than the clean case in regions of wall-tangential base flow deceleration and slower than the clean case in regions of wall-tangential base flow acceleration. Perturbations are even found to attenuate in some cases when a region of wall-tangential base flow acceleration follows a region of wall-tangential base flow deceleration. The modification of energy transfer mechanisms brings into question whether the initial modal stationary crossflow mode deviates from modal character on interacting with the base flow deformation. The Orr mechanism is shown to identify differences in perturbation behaviour from local modal character. However, criteria from the literature hint towards an absence of any non-modal effects. Finally, the extent to which a synthetic idealized base flow deformation mimics the effects of an FFS on deforming the base flow and changing trends of stationary crossflow instability evolution is tested to show the applicability of methods developed in the thesis to instances of natural base flow deformation. The progress in understanding mechanisms by which a deformed base flow affects the linear phase of primary stationary crossflow instability growth leads to suggestions on devices that can be tested to delay this phase of instability growth. These devices could potentially also delay subsequent stages of instability growth and hopefully lead to the development of novel transition delay techniques.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:add7b22f-6020-4b0c-be1d-e83705430c80","http://resolver.tudelft.nl/uuid:add7b22f-6020-4b0c-be1d-e83705430c80","'Underwater' Real Estate: Exploring housing market dynamics under severe flooding in Rotterdam","Lee Sherman, Sherman (TU Delft Technology, Policy and Management)","Nikolic, I. (graduation committee); Filatova, T. (mentor); Taberna, A. (graduation committee); van Ginkel, Kees (graduation committee); Delft University of Technology (degree granting institution)","2022","Climate change will lead to more extreme climate and weather phenomena, and this includes the increased risk and severity of flooding. Flooding is one of the most destructive and common natural hazards globally, and rising sea levels and extreme precipitation mean that many human settlements will be situated in climate-sensitive areas. <br/><br/>However, the increased threat of floods in coastal cities is not currently sufficiently represented in the housing markets. Contemporary property prices are shaped by the locational advantages of coastal cities, and have a tendency to underestimate or ignore flood risk, even after experiencing a flood themselves. This increases the possibility of structural shifts in housing markets when the flood risk is realised by the public, leading to a depreciation of real-estate property values, and may cause cascading effects in other aspects of the economy, such as the collapse of the regional housing market and reduced economic attractiveness to the region. The Netherlands, for example, is arguably the best-protected delta in the world from flooding. Still, it is vulnerable to the ""safe development paradox"", where public flood protection measures motivate the continued investment and expansion of flood-risky areas. While Dutch safety standards are very high, they cannot guarantee absolute protection from floods; the country is still at risk from rare-but-severe flooding, or the occasional minor flood, both of which can influence the Dutch housing markets.<br/><br/>The deep uncertainty of future flood risk means that empirical research alone cannot sufficently describe possible responses to housing market shocks from flooding. Therefore, modelling and simulation is useful in testing potential variants of a housing market system, such as testing different dynamics of housing market actors and potential policy levers in various flood scenarios. This is further supported by an increase in publicly-available rich datasets, that allow for spatial and empirical representation of the housing market and climate-induced flood scenarios.<br/><br/>\noindent In this thesis, the city of Rotterdam is used as a case study, to explore the usage of empirical data and to model a housing market shocked by various plausible flood scenarios. This is done in two steps: firstly via a data exploration effort in publically-available datasets for the Netherlands, and then consolidating the data into a stylised agent-based model, simulating the transactions of the housing market while several districts experience flooding shocks from different flood scenarios. <br/><br/>Firstly, I have conducted the data exploration aspect using Dutch open data for flood scenarios, housing, local demographics, and empirically-estimated flood discounts. The data was judged on the suitability of the datasets to be incorporated into an empirical model, and on the presence of data gaps while linking between different data. The exploration highlights the potential of modelling the housing market using empirical demographic data based on income level, but only missing certain data to characterise how homebuyers would acquire mortgage financing. Additionally, on the flood damages side, I show the possibility of characterising flood discounts as a function of flood depth, and the depth-damage relation for the Netherlands.<br/><br/>In the modelling part of the thesis study, I have consolidated the data into an agent-based model with a stylised set of relationships for the housing market. The model was designed based on the empirical stylised trends regarding housing markets dynamics, like declining flood risk discounts in property prices over time. In short, the model simulates the purchase transactions of homebuyers, who are discouraged from flood-affected properties, thus leading to a growing demand and price premium for flood-safe properties. This model was then tested with a simple series of experiments, for single flooding and multiple flooding scenarios, based on empirically-grounded severe flood scenarios on Rotterdam. While the model results are limited in terms of prediction for policy purposes directly, the modelling process as a whole illustrates the value of exploratory modelling to refine the understanding of a system. Via this exploration, it was highlighted that there is a need to further characterise flood discounting behaviour around the action of housing market actors.","Flood risk; flooding; scenario analysis; agent based model; exploratory modeling","en","master thesis","","","","","","Citation for Mutlu et al. (2022) is classified as a manuscript awaiting publishing. https://github.com/FishOuttaWotah/epa-rdam-housing-under-floods/tree/master Repository link GitHub link to model code","","","","","","Engineering and Policy Analysis","",""
"uuid:cb9c9a43-2691-47d3-95cf-ae7877b2b6c8","http://resolver.tudelft.nl/uuid:cb9c9a43-2691-47d3-95cf-ae7877b2b6c8","Modelling a Simulation Environment to analyse Race Strategy in Formula E","Bartl, Frederik (TU Delft Electrical Engineering, Mathematics and Computer Science)","Scali, Vincenzo (mentor); Bierkens, G.N.J.C. (mentor); Fokkink, R.J. (graduation committee); Delft University of Technology (degree granting institution)","2022","In this report, I investigate strategic decision making in the Formula E racing series for Porsche. Formula E is an electric car circuit racing series, where the main tasks of race strategy are allocating energy consumption across the race and timing mandatory ""attack mode"" activations (similar to small-scale pitstops). I work on a flawed existing tool that simulates Formula E races with the goal of identifying optimal strategies. By learning from Porsche's experience and comparing the tool against related literature, I investigate how to model a Formula E race.<br/><br/>To do this, I outline a method to measure the realism of our simulated races. By defining a race as a set of stochastic processes approximated with empirical data, I find a dissimilarity metric for the underlying probability distributions of two collections of races. My dissimilarity metric is based on Kantorovich's formulation of the optimal transport problem as applied to probability measures. The cost function used within this dissimilarity metric is based on how differently two drivers' individual races evolve from start to end, using gaps between times of arrival.<br/><br/>I introduce various alterations to the race model, based on experience and related literature. Through applying my metric to different versions of my race model, I evaluate these alterations and find improvements. Doing so shows measurable gains in the race model were achieved; this is also checked by measuring the prediction error of simulations versus the true observed race.<br/><br/>My approach yields a scalar metric that allows fast and straightforward tuning of any race model. It uses a high degree of aggregation to successfully compare otherwise not trivially comparable data. While already delivering a significantly improved model, my dissimilarity metric in conjunction with the prediction error-based metrics can help to find further improvements in the future. This is also independent of the used simulation method or format, since my metric only requires realisations of true and simulated races as input.","Motorsport; Simulation modelling; Tuning metric; Optimal transport","en","master thesis","","","","","","","","2027-12-11","","","","Applied Mathematics | Stochastics","",""
"uuid:d272e763-9026-464e-b12d-9902b5d7eaf8","http://resolver.tudelft.nl/uuid:d272e763-9026-464e-b12d-9902b5d7eaf8","Prediction of Aircraft Trip Fuel Deviations for Fuel Loading Decisions with a Deep Time Series Approach","Lampe, Reinoud (TU Delft Aerospace Engineering)","Li, L. (mentor); Santos, Bruno F. (mentor); Delft University of Technology (degree granting institution)","2022","Reducing fuel consumption is an increasingly important topic within aviation. One approach to accomplish this goal is reducing excess fuel weight being loaded on aircraft. Flight dispatchers and pilots load extra fuel to account for uncertainties present in trip fuel consumption, which is currently computed by the flight planning system (FPS). In this paper, a time-series-based model is proposed that predicts deviations in trip fuel consumption of commercial flights. The aim is to assist dispatchers with fuel loading decisions, using the proposed model. A 2-layered time series is proposed, able to capture temporal patterns present in deviations of trip fuel consumption. The first layer is a fixed time interval time series, grouping flights per time interval, to estimate average trip fuel deviation for the coming time intervals. The output of this layer is used for the second layer, which is a sequential time series model, modelling each flight individually, able to capture patterns present in the individual flight information. To estimate the trip fuel deviations for coming flights, input features from the operational flight flan, weather descriptive features from terminal area forecasts and historical flight descriptive input features from the flight data recorder are used. The new prediction model is able to reduce the root mean squared error (RMSE) of trip fuel predictions of the FPS by 26% and reduces the RMSE compared to the baseline gradient boosting model by 5.4%. Using a fixed-buffer loading strategy, 0.12 - 0.39% of fuel consumption could be reduced, depending on the desired safety key performance indicators, which leads to yearly savings of up to $1.5 million and 4,792 tonnes of CO<sub>2</sub>.","Fuel; prediction; airline; time series; deep learning","en","master thesis","","","","","","","","","","","","Aerospace Engineering | Air Transport and Operations","",""
"uuid:4e47e122-4e8e-4534-8f98-88d3b1eae8fb","http://resolver.tudelft.nl/uuid:4e47e122-4e8e-4534-8f98-88d3b1eae8fb","Flying in the face of climate change: the role of information to induce voluntary behavioural change","Meijneke, Sanne (TU Delft Civil Engineering & Geosciences)","Kroesen, M. (mentor); Cats, O. (mentor); Annema, J.A. (graduation committee); Delft University of Technology (degree granting institution)","2022","The Ministry of Infrastructure and Water Management looks into the possibility of raising the awareness of Dutch citizens as policy measure to encourage travellers to travel in a more conscious and more climate-friendly manner. Scientific literature, however, shows contradictory results on the effectiveness of this measure. An ongoing academic discussion is present on the extent to which awareness about the consequences of behaviour results in a desirable change of that behaviour. This study applies structural equation modelling on Dutch Mobility Panel data to examine if and via which causal pathway of socio-psychological factors information and awareness about the relative impact of flying on climate change run to the intention to fly. We find that raising awareness of Dutch citizens about the relative impact of flying on climate change is not enough to change people’s intended flying behaviour. The current awareness only changes people’s attitudes and reasons used to justify their flying behaviour, not the intention to fly. Further research, however, is necessary to find out if raising awareness on other consequences or other alternatives result in the same findings. Only then it could be recommended to look into other measures to encourage travellers to travel in a more conscious and more climate-friendly manner.","Air travel behaviour; Structural Equation Modelling(SEM); Survey; Pro-environmental behaviour; climate change mitigation","en","master thesis","","","","","","","","","","","","Civil Engineering","",""
"uuid:9547f270-88ca-4c60-9ee3-0c797e449e14","http://resolver.tudelft.nl/uuid:9547f270-88ca-4c60-9ee3-0c797e449e14","Sensitivity of a coupled modelling workflow to knee marker displacement: Determining the sensitivity of a coupled modelling workflow to variations in marker data retrieved from gait analysis","Wildöer, David (TU Delft Mechanical, Maritime and Materials Engineering)","Tümer, N. (mentor); Harlaar, J. (graduation committee); Seth, A. (graduation committee); Wesseling, M.G.H. (mentor); Delft University of Technology (degree granting institution)","2022","To better understand and predict osteoarthritis, researchers are developing so-called coupled modelling workflows. Coupled workflows convert data from gait analysis studies to subject-specific tissue mechanical response estimations through the use of musculoskeletal and finite element models. The tissue mechanical response inside the joint is thought to play an integral role in the onset and progression of osteoarthritis. To study this, the design of coupled workflow was proposed. This design contained subject-specific gait data which was processed by a musculoskeletal model with a single degree of freedom knee joint. Musculoskeletal output was transferred through an adjusted generic finite element model of the knee to calculate maximum principal stress and shear strain values in the tibial cartilage of the knee. Proper marker placement is crucial for making an accurate assessment of the patient’s function in gait analysis studies. It has been claimed that marker misplacement is the main cause of measurement variability in gait analysis studies. It however remains unclear how potential marker misplacement propagates to the coupled modelling workflow results. To investigate this, in addition to the design of a coupled workflow, a sensitivity analysis was performed. With this sensitivity analysis we tried to answer the following question: How does marker placement of knee joint markers in gait analysis influence the tissue mechanical response calculated by a coupled workflow? For the sensitivity analysis, knee joint marker placements were virtually perturbed along anterior-posterior, proximal-distal and medial-lateral direction, to mimic marker misplacement. Corresponding knee biomechanics were estimated from the perturbed input data in the coupled workflow. Peak maximum principal stress values varied by up to 0.60MPa and peak shear strain varied by up to 0.08% as a result of perturbed knee marker placement. For cumulative stress levels, broader relative ranges were found. Moreover, the results showed that marker placement along the anterior-posterior direction had the greatest influence on corresponding tissue mechanical response estimations. In future studies a standard error of measurement margin is proposed in the assessment of coupled modelling worfklow results. In conclusion, the proposed workfow was relatively easy to build and provided similar tissue mechanical response result to those as reported by more complex models which were more computationally intensive. This implies that in the future, coupled modelling processes may very well be incorporated into the clinical decision-making process for musculoskeletal disorders like osteoarthritis.","Biocomputational modelling; Knee osteoarthritis; Gait Analysis","en","master thesis","","","","","","","","","","","","BioMedical Engineering","",""
"uuid:368252f2-0045-4532-a3c7-9bc28cdb167f","http://resolver.tudelft.nl/uuid:368252f2-0045-4532-a3c7-9bc28cdb167f","Crashworthiness Analysis of An Aircraft Subfloor Structure using Artificial Neural Networks","Waaijer, Joost (TU Delft Aerospace Engineering)","Bisagni, C. (mentor); Delft University of Technology (degree granting institution)","2022","The goal of this thesis is to build an artificial neural network(ANN) surrogate model, that predicts the crashworthiness performance of a structure. The structure used in this research is a thermoplastic fibre-reinforced composite aircraft subfloor section which is part of the SmarT multifUNctioNal and INteGrated thermoplastic fuselage (STUNNING) fuselage demonstrator section. The structure will be analysed numerically, by making use of the finite element software LS-Dyna by Ansys. Within this research, a surrogate model is defined as a model that has been fed data from a computationally expensive model, yet is computationally considerably more inexpensive to run to obtain similar results as the expensive model. The main methodology to do so in this research is to build a two-dimensional design space, which is sampled using optimal latin hypercube sampling. By using an existing model for the STUNNING fuselage subfloor section and by automatic generation of geometry changes of the structure through a Python script, input files can be created according to the sampled design space. The simulations are then run on a high performance cluster. Once the simulations are run the results can be fed to an artificial neural network that uses this data to predict crashworthiness performance of the structure within the design space.<br/><br/>To build towards the goal of the thesis, a small comparative study has been performed on material models MAT054, MAT058, and MAT 261 in LS-Dyna. These material models are based on different failure criteria, and thus have different performance in coupon simulations. Using these simulations as a basis, a simple design space was created, sampled, and modelled so that a first ANN surrogate model could be built that could predict the failure displacement and the ultimate load of a composite coupon in tension. It was found that for a small dataset (&lt;10 samples), the neural network could easily fit to the data, and could predict accurately on samples within the design space that were withheld from the network during training.<br/><br/>Then, the STUNNING subfloor section model was introduced and a number of models that section this structure are investigated. The main purpose of this investigation is to find out if the model can be reduced in size without changing the resulting failure mode. When a satisfactory reduced model was found, the research carried on by doing a sensitivity analysis on a proposed two-dimensional design space, and similarly a sensitivity analysis on the parallelization settings. From this study, a second failure mode of the model was discovered and the effect of the parallelization settings was quantified. From here the limits of the design space could be formed and sampled. Finally, different variations of ANN surrogate models were defined, trained, and tested. In the end, a root mean square discrepancy of around 10\% was achieved during testing of the network. This means that the methodology could prove useful in design applications, depending on the design stage and needed accuracy.","Artifical Intelligence; Artificial Neural Networks; Crashworthiness; Aircraft; Structural Engineering; Composite structure","en","master thesis","","","","","","","","","","","","Aerospace Engineering | Structures and Materials","Clean Sky 2",""
"uuid:41173ad6-ceb0-4d7f-b305-0fe319688ab8","http://resolver.tudelft.nl/uuid:41173ad6-ceb0-4d7f-b305-0fe319688ab8","Straight line propagation in radio occultation measurements at Mars: A feasibility study for an alternative calculation of refractivity profiles","Cini, Daniele (TU Delft Aerospace Engineering)","Svedhem, L.H. (mentor); Vermeersen, L.L.A. (mentor); Delft University of Technology (degree granting institution)","2022","Since the first radio occultation measurements were performed to study planetary atmospheres, the calculations returning refractivity profiles always adopted the so-called ""spherical symmetry assumption"". This hypothesis imposes a null horizontal gradient of the atmospheric parameters within the region sampled during the occultation: a scenario that can be quite unrealistic for regions in proximity of the terminator line. This study suggests that another way of calculating refractivity profiles is doable, dropping the spherical symmetry assumption and assuming a straight line propagation of the radio signal through the atmospheric medium (which, according to the laws of refraction, should travel in a curved line, corresponding to the fastest trajectory according to Fermat's law). The study proved that the theoretical difference between the two methods is negligible (within 1%) and that numerical methods can be developed to account for the asymmetric regions within the atmosphere.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:ebf0a2a5-549e-4107-bfc4-cb3d33fd696e","http://resolver.tudelft.nl/uuid:ebf0a2a5-549e-4107-bfc4-cb3d33fd696e","Creating Monsters: crafting gender ambiguous child toys through reflexive designer-AI interactions","Arzberger, Anne (TU Delft Industrial Design Engineering; TU Delft Human-Centered Design)","Lupetti, M.L. (mentor); Giaccardi, Elisa (graduation committee); Rebaudengo, Simone (mentor); Delft University of Technology (degree granting institution)","2022","Growing up, social constructs like roles, norms and values are being internalised and naturalised. Despite offering a sense of stability, such constructs also prohibit equality, justice and diversity, by pushing people into categories, roles and norms they do not represent. However, once internalised, social constructs fall under the surface of awareness, making their mitigation and re-framing a complex task. This also poses a great challenge for designers, who often aim to create fair and inclusive futures for those marginalised and discriminated against.<br/><br/>Attempts are made to mitigate bias by introducing artificial intelligence (AI). Technology however, often acts as a double-edged sword, having the abilities to both identify and mitigate bias, or amplify inequality, reinforce existing stereotypes and increase injustice. <br/><br/>Recognising both the potential but also the limitations of AI, this thesis explores the idea of reflexive designer-AI interactions, as a new form of human-machine collaboration towards more reflective design practitioners who are able to surface and dismantle and rethink personal and collective imaginings. Seeing a key role in reflection, often criticised behaviour of AI, like inconsistency, unpredictability and confrontation, are being explored as potentially meaningful for triggering critical and self-reflective thinking and decision making in design. <br/><br/>Following a speculative and introspective research through design approach, this thesis explores such reflexive interactions in the context of gender representation in child toys. The hypothesis is that the introduction of reflection and a change in mindset when engaging with AI, can be productive in terms of mitigating gender bias in child toys. In order to envision the situated designer-AI interactions, a speculative vision of the first gender fluid child toy company is introduced. This vision serves as a tool for presenting queer future AI-design practices, but also as a critique of current gender stereotypes in the design of children's toys. <br/><br/>Technological exploration insights are translated into four design tactics, resulting in designer reflection and bias awareness. Those tactics are applied and explored in practice, by designing three gender-ambiguous child toys. Each toy represents a new reflexive design-AI workflow. Each workflow differently illustrates human and non-human collaboration that surfaces, de-familiarizes and dismantles personal and collective imaginings of gender in toys. Additionally, these speculative practices also challenge the status quo in design, raising awareness about design and AI issues that need to be addressed further in the future.<br/><br/>Taking into account the insights from the experiments, as well as prototype testing with children and evaluating expert interviews, this project concludes that reflexive interactions – as proposed alternative to traditional human-AI interactions and in addition to the current design practice – are potentially productive to surface, dismantle and re-familiarize personal bias and collective imaginings. Furthermore, does this thesis suggest that AI’s often negatively described behaviour like confusion and inconsistency, also carry the power to trigger reflective practices that help surfacing and challenge bias. However potentially limiting factors like ecological, economical and social cost as well as ethical concerns are discussed.<br","Human-Machine Interaction; Artifical Intelligence; Challenging Bias; Reflexive interaction; Speculative Design","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:bf7d6479-97d8-41f5-9bee-ccda508373a0","http://resolver.tudelft.nl/uuid:bf7d6479-97d8-41f5-9bee-ccda508373a0","Design of Balancing Converter for Bipolar DC Grids Using Series Connected MOSFET Switches","Sinha, Pooja (TU Delft Electrical Engineering, Mathematics and Computer Science)","Qin, Z. (mentor); Bauer, P. (graduation committee); Santbergen, R. (graduation committee); Yadav, S. (mentor); Delft University of Technology (degree granting institution)","2022","Global electricity usage has been increasing exponentially over the last 40 years and with the current pace of population and economic growth, the same trend will continue in the coming years. However, the current electricity generation is predominantly fossil fuels based, which makes the overall process unsustainable and polluting, and is contributing directly to the menace of global warming. The need of the hour is to transition to renewable and sustainable sources of electricity generation such as solar, wind etc.<br/><br/>However, the major bottleneck in the large-scale implementation of RESs is the intermittent availability and their integration into existing AC grids as the RESs are predominantly DC sources. In order to tackle the issue of intermittency various energy storage solutions are being developed. Further, as a solution to the issue of integrating RESs into the current electricity distribution system, DC distribution grids are being developed. <br/><br/>The DC distribution architecture is of two types, Unipolar and Bipolar distribution systems characterized by the number of wires used for power transmission; 2 wires for unipolar and 3 wires for Bipolar. Out of the two, Bipolar systems have inherent advantages of flexibility, stability and efficiency over unipolar systems. <br/><br/>Current thesis focuses on series connected switch configuration of voltage balancing converter for bipolar DC power distribution systems. <br/><br/>For this thesis, various topologies of voltage balancers for bipolar dc distribution systems were studied and a buck boost-based series switch-connected voltage balancer topology was chosen for the final design. For this topology, using MATLAB the parameterization and optimization of magnetic components of the converter were performed. The optimized configuration was then modeled and simulated using LTSpice.<br/><br/>Post this, a comparison between different methods adopted to account for the unbalanced voltage sharing across the series-connected switch configuration of the balancing converter owing to the non-linearities present in the circuit was done. Based on this study, the most prominent of the methods is then integrated to the LTSpice model.","Bipolar DC Grid; Voltage Balancer; Buck-Boost converter; Series MOSFET; RC Snubber","en","master thesis","","","","","","","","2023-12-16","","","","Electrical Engineering","",""
"uuid:a3f39f23-26d6-46dd-b9c3-32baeea03d5c","http://resolver.tudelft.nl/uuid:a3f39f23-26d6-46dd-b9c3-32baeea03d5c","Design, Production and Characterisation of an LPCVD-Based Poly-Silicon Carbide Pressure Sensor for Extreme Environments","Salden, Tom (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Else Kooi Laboratory)","Zhang, Kouchi (mentor); el Mansouri, B. (mentor); van Driel, W.D. (graduation committee); Bossche, A. (graduation committee); Delft University of Technology (degree granting institution)","2022","Sensors are extremely valuable to this world. Without sensors, we would not be able to live as we do in this data-driven environment. Therefore, finding new ways to measure the matter around us is a continuous process. In this work, an addition to the new sensors is attempted, using materials that can withstand the most extreme circumstances. This work describes the process of designing, simulating, producing, measuring and validating a pressure sensor based on LPCVD Silicon Carbide.<br/>The created sensor should be modular and back-end-of-line compatible. In addition, the sensor should measure pressures from 80Pa up to 1MPa at temperatures from room temperature to 600°C. Because of a favourable reaction to high temperatures, a capacitive sensor type that uses a sealed membrane for absolute pressure measurements is chosen.<br/>Due to the large pressure range, the design has been split into three distinct parts, each with its specialised pressure range. A low-range for 80Pa to 100kPa, a mid-range sensor for 100kPa to 300kPa and a high-range sensor for 300kPa to 1MPa. To compensate for the nonlinearity in the device, two approaches are taken. One method splits the bottom electrodes, generating a more linear output with the correct division. This approach is used for low-and-mid-pressure devices. The other approach uses touch mode to decrease nonlinearity. After the membrane touches the bottom contact, a linear range is found. This approach is taken for the high-pressure device.<br/>A flowchart has been developed based on the necessary layers to create the sensors. Using this flowchart, masks have been designed. During production, the process was adjusted, as delamination of the dielectric layer was observed. In addition, because of difficulty with sealing, the membrane is thicker than the original design.<br/>During production, buckling of the membranes was observed. This causes the sensors to behave differently compared to the simulations. One effect the buckling may have caused is the reaction to temperature. This is opposite to the simulations. In addition, subjecting the sensors to a vacuum also causes behaviour opposite to what was intended. When high pressure is applied, the sensors do work as intended. Due to the design alterations and buckling effect, the sensors are less sensitive to pressure than intended. The best sensor has a sensitivity of 0.025 f F/100Pa compared to the designed 0.3 f F/100Pa. However, the output of the sensor is linear without needing the designed compensation techniques.","Pressure Sensor; Silicon Carbide; Membrane; Capacitive Sensor; Harsh Environments","en","master thesis","","","","","","","","2024-12-16","","","","Electrical Engineering","",""
"uuid:88bb6ff2-5e56-4b7c-a8ef-545eebc63fd3","http://resolver.tudelft.nl/uuid:88bb6ff2-5e56-4b7c-a8ef-545eebc63fd3","3D woven denim jacket: Exploration and development of 3D weaving as a more sustainable way to produce a denim jacket","Vroom, Barbara (TU Delft Industrial Design Engineering)","McQuillan, H.L. (graduation committee); Soerjo, E.A.A. (mentor); Delft University of Technology (degree granting institution)","2022","The clothing industry is one of the most polluting industries worldwide (Ellen MacArthur Foundation, 2017). The current industry for producing garments is built on the overproduction of cut-and-sewn textile products, which are produced as fast as possible for as little money as possible. The denim industry is a major contributor, producing over four billion denim garments every year (Toepel, 2018). Over the last 150 years, the aesthetics of a pair of jeans and a denim jacket has barely changed, which is a result of this cut-and-sew fast fashion industry that still exists. A way to reduce the global impact of denim garment manufacturing would be to reduce the number of production steps. <br/><br/>This research aimed to investigate 3D weaving to rethink the production process for a denim jacket. 3D weaving combines woven textile design and garment design in multi-layer textile forms. With 3D weaving, the number of production steps after weaving and the resulting cutting waste can be reduced by weaving parts of the garment as already connected pieces. <br/><br/>This project is executed in a sustainable context of limiting pre-consumer waste and reducing the number of parts to assemble the denim jacket. A change in the manufacturing process of a denim jacket will raise the question if the 3D woven denim jacket can and also has to look the same as a denim jacket produced with the regular cut-and-sew method. The 3D woven denim jacket versions in this report show how and to what extent this is possible. These concepts also show how this new production method affects the aesthetic outcome of denim jackets.<br/><br/>This report starts with setting the context of denim jackets, the industry and its polluting side. After introducing 3D weaving and setting the criteria the process of experiments is explained and visualised. Research through design has been the basis of this research. This iterative research led to three 3D woven versions of a chosen concept. These prototypes were developed at Diamond Denim during a visit to their factory in Pakistan through many weave cycles. One of the outcomes is a zero-waste 3D woven jacket. <br/>The aesthetic of the 3D woven jackets was found to fit the description of a denim jacket but was different due to the fabric density, texture and raw fraying seams. <br/>Change is inevitable. Let’s wear the change!","Denim; 3D weaving; Textile; Textile-form; Zero waste; Sustainability; Denim jacket","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:6c606bf1-4ebe-4bb7-9139-5e5e686ecd3f","http://resolver.tudelft.nl/uuid:6c606bf1-4ebe-4bb7-9139-5e5e686ecd3f","Spatial temperature measurements and turbulence analysis using DTS in the LIAISE field campaign","Vis, Gijs (TU Delft Civil Engineering & Geosciences)","Coenders-Gerrits, Miriam (mentor); Hartogensis, Oscar (graduation committee); ten Veldhuis, Marie-claire (graduation committee); Delft University of Technology (degree granting institution); Wageningen University & Research (degree granting institution)","2022","Experiments using fiber-optical set-ups for distributed temperature sensing (DTS) were conducted in the LIAISE (Land surface Interactions with the Atmosphere over the Iberian Semi-arid Environment) field campaign during 15-30 July 2021 in the north-east of Spain. Three DTS set-ups were installed to measure temperature profiles along varying vertical scales; 1.6 - 40 m in the atmosphere, 0 - 1 m into the rapidly-growing alfalfa canopy and -0.5 - 0 m in the soil. Measurements were conducted at 5 s and 25.4 cm resolutions using a 1.6 mm Kevlar-reinforced fiber. The preliminary data of these three set-ups are described in the first part of this thesis, which display the potential of using DTS in a land surface campaign to capture vertical temperature structure in great detail.<br/>A fourth fiber-optic set-up was installed with a horizontal extent of 70 m, measuring at four heights between 0.40 m and 2.05 m height. A thinner 0.5 mm cable was used here in an effort to obtain the fastest possible time response in order to measure temperature turbulence parameters using DTS. Measurements were made at 1 Hz and 12.7 cm resolution, however the actual sampling frequency appeared to be 0.15 Hz in the temperature spectrum, likely because of the long response time of the cable.<br/>Despite the limited 0.15 Hz sampling rate it was possible to obtain turbulence information through the use of the structure parameter of temperature, C2T<br/>. This parameter indicates the intensity of temperature fluctuations and was calculated over time, as is conventional. In a novel approach, it was also calculated over space, using the spatio-temporal dataset as obtained by DTS. Both the definition of C2T and the inertial range of the temperature spectrum were used to determine C2T. The spatial C2T obtained through<br/>the definition method was found to have the best correlation with a sonic anemometer reference, with an R2 of 0.88. The temporal C2T lack the structure that is shown in the spatial C2T, which is likely due to 30-min averaged data for horizontal wind speed from the sonic anemometer or to Taylor’s frozen turbulence hypothesis not being a suitable assumption within the dimensions of this research. Determining C2T through the turbulent spectrum was successful for limited data points for the time series, and is currently inconclusive for the spatial series.<br/>Recommendations for further research for using DTS in turbulence analysis are to investigate the effect of instrument noise and the limited sampling rate. Also a critical look into the current DTS calibration routines for atmospheric is recommended. This work provides a first step towards using DTS in capturing<br/>turbulent information along spatial temperature series.","Distributed Temperature Sensing; Structure Parameter; Turbulence analysis; LIAISE","en","master thesis","","","","","","","","","","","","Civil Engineering | Environmental Engineering","LIAISE","41.69336,0.92841"
"uuid:6e91cd0c-fc51-4b85-a897-70dac35c8c88","http://resolver.tudelft.nl/uuid:6e91cd0c-fc51-4b85-a897-70dac35c8c88","Preference and Performance Based Design &amp; Decision Systems in Offshore &amp; Dredging Engineering: A multi-objective design/decision optimisation approach based on sound mathematical modelling of both preference and physical design performance functions","van Heukelum, Harold (TU Delft Civil Engineering & Geosciences; TU Delft Mechanical, Maritime and Materials Engineering)","Wolfert, A.R.M. (graduation committee); Binnekamp, R. (graduation committee); Colomes, Oriol (graduation committee); Steenbrink, A.C. (graduation committee); Delft University of Technology (degree granting institution)","2022","Why do engineers often design what people don't want? And why do people often want solutions that are not feasible? This is because the current design and decision support optimisation methodologies are one-sided and ignore or fail to capture the dynamic interaction between people's preferences (desirability) and technical assets' performance (feasibility). Furthermore, most methodologies contain fundamental problems and often cannot achieve a single best design solution. Moreover, the offshore &amp; dredging engineering (ODE) industry can significantly benefit from multi-objective design/decision optimisation as projects become larger, more stakeholders are involved in concurrent design/decision-making, and new technologies emerge.<br/><br/>To solve the shortcomings given the current momentum within the ODE industry, a truly integrative Open Systems Design (Odesys) methodology is proposed in this thesis. For this purpose, a new multi-objective optimisation method IMAP is introduced which is operationalised in a Python-based software tool called Preferendus, including a new inter-generational Genetic Algorithm (GA) solver.<br/><br/>The application and added value of the Preferendus/IMAP are validated for two demonstrators within the maritime contractor Boskalis.<br/><br/>The first validation case concerns planning and design optimisation in the development of offshore floating wind farms, focusing on scheduling and mooring design. For this purpose, an integration was made with the wind turbine simulation tool OpenFAST. The new Preferendus/IMAP significantly improved the overall tender performance by: 1) providing initial design approaches within a few hours, where currently tender teams spend days working on design alternatives that, in hindsight, were suboptimal; 2) removing tender team bias from the design process and finding design solutions that were otherwise unfairly disregarded; 3) open glass-box modelling support for concurrent design between the asset owner and the contractor.<br/><br/>The second validation case is a decision support optimisation application of a dredging production in which multiple vessels jointly execute a dredging project. Due to different types of disturbances, these vessels often have to wait for each other, reducing the overall efficiency of the project. Current expert-based optimisation approaches are limited in their ability to adjust best-for-project. The new Preferendus/IMAP shows a clear improvement and finds solutions that significantly reduce waiting time while simultaneously achieving high production levels. Moreover, the Preferendus/IMAP outperforms single-sided optimisation on production alone by achieving similar high production levels while also improving other objectives such as CO2 emissions and vessel efficiency.<br/><br/>Steps for further development include: 1) improving OpenFAST integration and modelling; 2) addition of fatigue loading in the anchor design; 3) improving discrete event simulation scheduling modelling; 4) improving runtime by exploring other algorithms and/or programming improvements.<br","Multi-objective design optimisation; Preference function modelling; Design and planning systems; Preference-based decision-making; Systems Engineering; Physical object and human preference behaviour; Inter-generational solver","en","master thesis","","","","","","Double degree in Offshore and Dredging Engineering and Civil Engineering | Construction Management and Engineering https://github.com/TUDelft-Odesys/Preferendus Link to GitHub repository containing the Preferendus which was developed during this thesis.","","2024-12-16","","","","Offshore and Dredging Engineering","",""
"uuid:c6bfe155-e126-48eb-9c5c-c5115d05494f","http://resolver.tudelft.nl/uuid:c6bfe155-e126-48eb-9c5c-c5115d05494f","Additive Manufacturing of Kirigami Metasurfaces","Amin, Shashank (TU Delft Aerospace Engineering)","Masania, K. (mentor); Damodaran, V. (graduation committee); Delft University of Technology (degree granting institution)","2022","Kirigami- the Japanese art of paper cutting – is used extensively as a design philosophy for stretchable and morphable structures. An array of cuts on a thin planar sheet creates a structure that can morph into a 3D pattern on applying an in-plane uniaxial load. This type of structure is called a kirigami metasurface. A subset of this type of structure is a buckling-induced kirigami metasurface that displays an in-plane and out-of-plane deformation response when an in-plane tensile load is applied. This metasurface type is multistable and displays a snap-through behaviour. The angles at which the cuts are made are one of the main influences behind the proportions of these in-plane and out-of-plane deformations.<br/><br/>Cut patterns for these kirigami metasurfaces are specified with respect to the loading direction. For example, linear cut patterns contain periodically spaced linear cuts perpendicular to the loading direction, and angular cut patterns contain periodically spaced angular cuts in the form of the legs of an isosceles triangle, with its median parallel to the loading direction.<br/>Traditionally, stiff materials with low operating strain ranges are used to manufacture angled cut pattern kirigami metasurfaces. This work incorporates the use of high-toughness thermoplastic elastomer and fused filament fabrication (FFF) to manufacture metasurfaces with higher operating strain ranges. The influence of varying the cut pattern's geometric parameters on the metasurface's overall mechanical response is studied. Digital Image Correlation is used to quantify this out-of-plane mechanical response, and the effects of manufacturing using FFF on the bistability of the kirigami metasurface are analysed.<br/><br/>The results showed that the 30-degree angled cut design gave the highest out-of-plane displacement relative to the size of its spikes. This angled cut design gave also gave the highest projected area amongst the other angled cut design types. The maximum projected area of this 30-degree angled cut design is 2.9 times greater than a similarly sized linear cut sample. <br/><br/>An outcome of this work is to be the starting point for the use of FFF additive manufacturing and its design and material deposition freedom to tailor the response of the unit cells of an angled-cut kirigami metasurface. It also highlights the potential for using the angled cut design over the linear cut design for aerodynamics applications where local drag generation is favourable.","Kirigami; Additive Manufacturing; Digital Image Correlation; Metamaterials; 3D Printing","en","master thesis","","","","","","","","","","","","Aerospace Engineering | Structures and Materials","",""
"uuid:e665b12f-3bb4-4ff8-b095-4388a8d0ba59","http://resolver.tudelft.nl/uuid:e665b12f-3bb4-4ff8-b095-4388a8d0ba59","Towards a Circular ICU: How to implement reusable video laryngoscopes at the ICU","Koot, Veerle (TU Delft Industrial Design Engineering)","Diehl, J.C. (mentor); Kleinsmann, M.S. (mentor); Hunfeld, Nicole (mentor); Delft University of Technology (degree granting institution)","2022","The healthcare sector uses a lot of on single use medical products, causing large amounts of CO₂ emissions and excessive amounts of waste. This project contributes to a circular Intensive Care Unit (ICU) by investigating the barriers and possible solutions for a transition from single use video laryngoscopes (VL) to (partly) reusable ones, in order to develop guidelines and best practice for the transition of other single use medical products to reusables.<br/><br/>To produce single-use products, raw materials are extracted, products are manufactured, used, and disposed of after using the product just one time. This is known as the linear economy or the ‘take-make-waste’ system, having a devastating effect on the environment. However, reusing medical products comes with organisational challenges. Concerns with patient safety, liability, the costs, and complexity of developing and maintaining in-house reprocessing infrastructure and logistics have left hospitals with a complex organisational challenge.<br/><br/>The research question for this project is: How can the ICU become more sustainable through overcoming organisational challenges hindering the implementation of reusable video laryngoscopes? With the sub-questions: 1. What are the barriers and enablers for implementing the reuse of video laryngoscopes in the ICU? 2. How can the reuse of video laryngoscopes be implemented at the Erasmus MC? 3. What could be the next step in transitioning similar products (to the video laryngoscope) from single use to reusable?<br/>This design project was structured through three phases: Exploration, Analysis and Conceptualisation phase. Three product journeys were analysed: a single use VL, semi-reusable VL and a completely reusable VL. This project concludes, contrary to the original hypothesis, that barriers to for the implementation of reusable VL’s are minimal. The semi-reusable VL seems to require the least change from the organisation, but the fully reusable VL contributes better to the end goal of a fully circular ICU in 2030, notwithstanding its higher up-front cost.<br/>For the implementation of the reusable VL it is essential to spark the actual implementation of the reusable VL and communicate with and facilitate stakeholders. The implementation processes need to be kickstarted through the set-up of a tender, followed by a pilot, pilot evaluation and expansion of the pilot in order to ensure proper implementation. After implementing the VL three other medical devices were identified to follow in the footsteps of the reusable VL: Laryngoscope blades, bronchoscopes, and scissors. Laryngoscope blades and bronchoscopes can be collected in the same place since the use-case of them is very similar to the VL. Scissors will require further research but follow a similar journey to and from the CSD. <br/><br/>This report brings value to the ICU of the Erasmus MC through identifying that the Erasmus MC has the resources and capabilities to implement the reusable VL’s, as well as presenting recommendations for the implementation process. <br","Sustainability; Healthcare; intensive care; Reuse; Circularity; video laryngoscopes","en","master thesis","","","","","","","","","","","","Strategic Product Design","",""
"uuid:e62d62af-d536-4383-b126-36462e344f57","http://resolver.tudelft.nl/uuid:e62d62af-d536-4383-b126-36462e344f57","Dynamic Transport Model for Nautical Recreational Activities","Litjens, Thomas (TU Delft Civil Engineering & Geosciences)","Daamen, W. (mentor); Pel, A.J. (graduation committee); Duinkerken, M.B. (graduation committee); Zantema, Kobus (graduation committee); Delft University of Technology (degree granting institution)","2022","The aim of this research is to develop a transport model that is able to identify potential conflicts and bottlenecks for nautical recreational activities in the IJburgbaai, an open-space water area in the eastern part of Amsterdam.","Dynamic model; Transport model; Recreational activity; Nautical activity","en","master thesis","","","","","","","","","","","","Civil Engineering | Transport and Planning","","52.35891658129552, 5.000406269573893"
"uuid:b567e131-d49f-4a72-8ad4-4af2f4ed375f","http://resolver.tudelft.nl/uuid:b567e131-d49f-4a72-8ad4-4af2f4ed375f","Dynamic Programming based basicity control of an experimental smelting furnace prototype","Vitanov, George (TU Delft Mechanical, Maritime and Materials Engineering)","Keviczky, T. (mentor); Mohajerin Esfahani, P. (graduation committee); Max, G.F. (graduation committee); Feenstra, E. (graduation committee); Delft University of Technology (degree granting institution)","2022","This thesis discusses the chemical composition (basicity) control problem of HIsarna, an experimental iron furnace which operates with 30% less CO2 emissions than its traditional blast furnace counterparts. The control challenge is keeping the basicity of the plant in a narrow operating region. A mass balance model of the plant was constructed - as it is common practice in the literature for traditional blast furnaces - which we combined with a parameter search method to find the most optimal model parameters from data. Next a stochastic system model of the plant was derived using the prediction errors of the plant on a new dataset. The novelty of our work is the chosen dynamic programming controller approach that we used for controller synthesis that enables optimal control of the plant with respect to the known model error distribution. A continuous Markov Decision Process based infinite horizon controller was devised by using Value Iteration to find a fixed point in our value function space with respect to the Bellman operator: our static value function. We used multilinear interpolation and a state and inputs grid to define our value function for our continuous state space. The controller map was derived from the static value function and we used multilinear interpolation again in order to obtain a continuous controller. We validate our controller by simulating the controller performance on our stochastic system model and evaluating it versus the recorded operator runs according to our running cost function defined in the Value Iteration. In summary the resulting controller outperforms the operator on average and in the worst case has comparable performance to the operator from 1000 simulation runs. Improving the controller performance further would be possible by using a more accurate system model or using a different grid parameterization than the one we used for computational efficiency reasons.","Dynamic Programming; Value Iteration; Optimization; Chemical composition control; Markov Decision Process; Bellman operator","en","master thesis","","","","","","","","2024-12-16","","","","Mechanical Engineering | Systems and Control","",""
"uuid:e76b2ad8-224b-4043-8bfb-4fcf82777c36","http://resolver.tudelft.nl/uuid:e76b2ad8-224b-4043-8bfb-4fcf82777c36","Joint human motion recognition and breathing frequency estimation for indoor healthcare applications","CORTES PERALTA, Max (TU Delft Electrical Engineering, Mathematics and Computer Science)","Fioranelli, F. (mentor); Guendel, Ronny (mentor); Hunyadi, Borbala (graduation committee); Delft University of Technology (degree granting institution)","2022","The challenge of dealing with patients suffering from chronic diseases and an aging population requires evolving from traditional hospital-based healthcare systems into a person-centered approach, where patients can be monitored remotely via modern technologies by cost-effective and reliable solutions based on emerging technologies in the healthcare domain. <br/><br/>Due to its contactless capabilities, radio-frequency technologies can lead to proactive monitoring of conditions directly related to health statuses. These technologies can include the tracking and monitoring of vital signs or the identification of abnormalities and critical life-threatening events, such as strokes or falls, in order to react before more complex scenarios and non-treatable conditions can appear over time. <br/><br/>This thesis project explores developing, evaluating, and verifying a processing pipeline based on radar sensing technology, jointly exploring human activity recognition and breathing frequency estimation, two of the most immediate capabilities to detect and monitor the general health conditions of a human being. <br/><br/>Through Doppler-Time and Range-Time data domains, the differentiation between translational and in-place activities, namely walking and sitting, is addressed, aiming to successfully identify and locate the segments where the test subject is not moving. This then triggers a proposed pipeline for the continuous estimation of the breathing frequency for the in-place scenario based on a sequential estimator, specifically the extended Kalman filter.","Human Activity Recognition; Breathing Frequency Estimation; Extended Kalman Filter","en","master thesis","","","","","","","","","","","","Electrical Engineering | Wireless Communication and Sensing","",""
"uuid:95cb8bcc-79f2-4063-9845-bc844284a484","http://resolver.tudelft.nl/uuid:95cb8bcc-79f2-4063-9845-bc844284a484","Rod bending accuracy improvement for spinal fusion in adolescent idiopathic scoliosis patients: An exploratory finite element analysis","Smedema, Jette (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Biomechanical Engineering)","Weinans, H.H. (mentor); Pahlavani, H. (graduation committee); Tümer, N. (graduation committee); Delft University of Technology (degree granting institution)","2022","b>Background</b><br/>Adolescent idiopathic scoliosis (AIS) with a Cobb angle larger than 45° is a spinal deformity that needs surgical treatment to stop progression and reduce pain. Spinal fusion is a surgical procedure where rods are attached to the spine through screws to diminish the Cobb angle.<br/><b>Objective</b><br/>The metal rods are pre-bent to correct the spinal deformity as much as possible. This rod shape is currently based on experience of the orthopedic surgeon. The aim of this thesis is to use Fi-nite element analysis (FEA) to predict a suitable rod shape for AIS patients that need to un-dergo surgery.  <br/><b>Method</b><br/>An FE model of an AIS spine was created based on high quality CT images. Rotation of ver-tebrae led to the optimal shape of the spine in the coronal plane. Vertebral bodies in this model were one by one rotated to a new position from top to bottom, to bring the spine to a new state and align it as much as possible to a normal physiological shape. However, alignment of the spine is an iterative process and rotation of every subsequent vertebra affects the shape of the entire spine. For each vertebral rotation, the reaction moments to maintain the new position is determined in the FE spine model. The acquired reaction moments are transferred to an FE rod model to provide the pre-bending of a rod that can bring the spine in its new state.<br/><b>Results</b><br/>The FE spine model was corrected to reduce the Cobb angle as much as possible. The highest stresses were found at the spinal apex. The reaction moments were transferred to a rod that became deformed in such a manner that straightened the spine model and corrected the Cobb angle to its pre-determined position with 33% reduction.<br/><b>Discussion</b><br/>This is an exploratory study that examines the possibility to predict ideal rod shapes pre-operatively to reduce surgical duration and improve the quality of the procedure. An accessory rod shape was accomplished but could not be validated due to lack of comparable studies. Improved FE spine models will lead to higher reliability of FE pre-bent rod models. This can be accomplished by, for example, inclusion of ligaments, muscles and other structures in the FE model and use of time-dependent material properties. The current model did not lead to a perfect aligned physiological spine and optimization algorithms should be developed in future models to further improve pre-bending of the rods.<br/><b>Conclusion</b><br/>Pre-operative prediction can improve the quality and reduce the time of spinal fusion. Im-provements to the FE spine- and rod model, such as automation, generalization, inclusion of more structures, and optimization algorithms will lead to optimal pre-bending of rods and bet-ter and quicker surgical outcome.<br","FEM analysis; Scoliosis; Adolescent Idiopathic Scoliosis; Spinal fusion surgery; FEA Simulation; ABAQUS","en","master thesis","","","","","","","","","","","","Biomedical Engineering","",""
"uuid:eaf3a964-45b8-4ef2-89c1-96dc70022a90","http://resolver.tudelft.nl/uuid:eaf3a964-45b8-4ef2-89c1-96dc70022a90","Increasing Children’s Influence on Living with Hemophilia","Kerimoğlu, Ekin (TU Delft Industrial Design Engineering)","Melles, M. (mentor); Gielen, M.A. (graduation committee); Van Hoorn, E.S. (graduation committee); Delft University of Technology (degree granting institution)","2022","For hemophilia patients, a simple fall or injury can cause excessive bleeding, which if not handled properly can cause major disabilities and in extreme situations even death. Due to the insufficient blood coagulation factors in their system, a fun day can easily end in the emergency room. Children, by nature, are still learning how to move and navigate the world. Where an adult may know the consequences of their actions, a child may not be able to see that, and therefore are an especially vulnerable group. With many challenges in their daily life, children with hemophilia have a complex experience with the disease. In collaboration with Partitura and the Sophia Childrens Hospital, the goal of the project is to analyze the experience of severe hemophilia patients aged 0 to 8, visualize this in the form of a patient journey built from their perspective and find opportunities and patterns in the experience to eventually create a proposal for an intervention to improve quality of life.<br/><br/>A patient journey was created, in order to visualize this complex experience. The journey showed that there were definitely opportunities for improvement, giving an overview of the different touchpoints the patient goes through in the 3 main phases, (1) diagnosis, (2) treatment and (3) living with hemophilia.<br/><br/>The patient journey, as well as various methods of research including a literature review, observations in the outpatient clinic and interviews with healthcare professionals, parents and patients showed that children want to feel more in control of their disease, and have more structure/predicability in their experience with hemophilia. Especially the 3 main contact areas of the patient, (1) home, (2) the outpatient clinic and (3) the emergency room, provided room for these needs to be met.<br/><br/>Based on the research outcomes, a design goal was formulated for the creation of an intervention: To design an intervention for children with severe hemophilia aged within the range of 0-8 years, that helps empower them and help them better comprehend their journey with the disease, by providing structure, consistency and control. 3 concepts were created, all serving the different contact areas of the patient, with the overarching purpose of helping the child be more involved and active in his healthcare. The concepts were designed as seperate interventions, which can be combined and used together to strengthen each other by improving the patient experience in the different areas of the child’s life. The evaluation sessions, carried out with parents and healthcare professionals showed that the concepts had a lot of potential, and was met with great enthousiasm. This project concludes with recommendations for the next steps, for the implementation of the interventions and also further research opportunities in the experience of children with hemophilia. The next steps for the project will be to prepare for implementation, with interest to implement nationally, and eventually to aid in improving the patient experience of children with severe hemophilia, not only in the context of the Sophia Children’s Hospital but all patients of the Netherlands.","Patient Journey; Pediatric Hemophilia; Healthcare; Patient Experience","en","master thesis","","","","","","","","","","","","Design for Interaction | Medisign","",""
"uuid:34aa6b4c-7b5c-4e93-be9d-e88a8598bf6f","http://resolver.tudelft.nl/uuid:34aa6b4c-7b5c-4e93-be9d-e88a8598bf6f","Pressure monitoring inside the nozzle of a fused filament fabrication (FFF) 3D printer","de Vries, Sietse (TU Delft Mechanical, Maritime and Materials Engineering)","Ayas, C. (mentor); Fanzio, P. (graduation committee); Accardo, A. (graduation committee); Delft University of Technology (degree granting institution)","2022","Fused filament fabrication (FFF) is the most used additive manufacturing technique that uses a heated nozzle to melt a polymer and a feeder to extrude it on a buildplate. The dependencies of temperature, shear-rate, viscosity and pressure of the melt create complex dynamics within the nozzle, which causes inconsistent extrusion. To improve extrusion control, a better understanding of the dynamics within the nozzle is required. The greatest knowledge gap comes from a lack of experimental data on the pressure inside the nozzle, due to the challenging environment for sensors. This study presents a novel way of monitoring the pressure inside the nozzle of an FFF 3D printer. A pin that is in direct contact with the melt transfers the force applied by the melt through a hole in the nozzle to an externally mounted load cell. The set-up has proven to provide reliable, repeatable pressure data in steady-state, static extrusion. The experimental data on different nozzle geometries and materials, with different flows and temperatures, has been compared to theoretical pressure calculations to identify non-linearities that influence the pressure such as entrance effects, temperature non-uniformity and viscoelastic behaviour of the melt. The proposed design can be used to gain more knowledge on the extrusion process to further develop extrusion control.","Pressure; 3D printing; Fused filament fabrication; Nozzle; Monitoring","en","master thesis","","","","","","","","","","","","Mechanical Engineering | High-Tech Engineering","",""
"uuid:c911b76e-6774-4afb-9674-e229d19236c6","http://resolver.tudelft.nl/uuid:c911b76e-6774-4afb-9674-e229d19236c6","Uplift behavior of offshore shallow foundations during retrieval: An experimental study on the pressure differences that occur during uplift of mud-mats of pre-piling templates","Rietema, Bertie (TU Delft Civil Engineering & Geosciences)","Gavin, Kenneth (mentor); van der Male, P. (mentor); Kementzetzidis, E. (graduation committee); Delft University of Technology (degree granting institution)","2022","Offshore structures are often founded on mud-mat foundations which prevent the structure from settling excessively. Pressure differences are generated under mud-mats during removal from the seabed. These differences lead to a force that resists the uplift. A literature study on breakout resulted in a hypothesized distinction of four mechanisms that occur during the uplift of offshore shallow foundations. An experimental program was designed to study these mechanisms. Small-scale tests on clay and sand were executed. The effectiveness of selected mitigation measures was studied, as well as the influence of the measures on the mechanisms. Existing calculation methods that model suction or quantify the breakout force were evaluated. It is believed that the results from the experimental program led to a comprehensive list of parameters that should be included in a design method to model the total resisting force to uplift, taking the mechanisms into account.","","en","master thesis","","","","","","","","","","","","Civil Engineering","",""
"uuid:64e17e2a-a5ff-42ed-900f-aaa2e7799f59","http://resolver.tudelft.nl/uuid:64e17e2a-a5ff-42ed-900f-aaa2e7799f59","A digital workflow for 3D printed full-colour ocular prosthetics","Calis, Ilse (TU Delft Industrial Design Engineering; TU Delft Sustainable Design Engineering)","Elkhuizen, W.S. (mentor); Doubrovski, E.L. (mentor); Delft University of Technology (degree granting institution)","2022","Fabricating custom-made ocular prostheses is currently a highly-skilled, labour-intense and non-reproducible process performed by an ocularist. Custom-fit prostheses are made from acrylic using a plaster mould, the iris is hand-painted, and veins are mimicked by adding red embroidery threads. Digital production techniques provide opportunities to improve and automate this process. Therefore, this graduation project aims to research a possible digital workflow, including data capturing and calibration, modelling and 3D printing, for producing 3D-printed full-colour ocular prosthetics. The workflow should capture and reproduce the eye’s appearance to create a life-like ocular prosthesis that resembles the patient’s facial appearance as closely as possible.<br/><br/>Research into manual and digital production techniques results in a proposed digital workflow showing how a prosthesis can be produced. The workflow consists of five phases: collect, design, produce, post-process and finalise and shows how the patient and the ocularist are involved.<br/><br/>Data capturing and calibration<br/>The patient’s eye colour data needs to be captured and calibrated to ensure accurate colour reproduction of the eye. The images can be calibrated by applying a colour profile made from a colour target to correct the camera error. The capturing research showed that photographing is a suitable technique to collect colour data for accurate colour reproduction if the eye and the colour target are shot under a controlled light condition. Multiple calibrated iris images were printed and compared to the participant’s eye to review the capturing and calibration process.<br/><br/>Modelling<br/>The modelling research showed that a parametric model based on a computational design template is a suitable solution for adjusting the prosthesis model to a personalised shape.<br/>The template should automatically model the inner parts of the prosthesis based on the outer shape and important parameters, such as the iris and pupil diameter. The first steps towards creating this computational design template are shown in this report by modelling a parametric iris disk.<br/><br/>3D Printing<br/>The full-colour 3D printing technology's capabilities were exploited to reproduce best the various features of a human eye, such as the sclera, blood vessels, pupil, cornea and iris. This investigation showed that mapping an eye image to the model does not always give the desired result and that different printing techniques are suitable for different eye parts. Alternative approaches, like contoning, sclera generator and ‘dotting’ and ‘varying line deepness’ techniques, are exploited and show promising results. However, a voxel-based printing technique is needed to combine and control these approaches, and current software lacks these possibilities.<br/><br/>Two experts and five users validated prostheses produced following the proposed digital workflow through an interview and by photographing them next to their eyes. All participants were impressed by the prosthesis and rated the total prosthesis as ‘sufficient’ or ‘good’. Nonetheless, it remains a challenge to reproduce the exact iris colour, structure and veins. A voxel-based printing technique is recommended to have more control over these various aspects. More research is needed to explore the possibilities for controlling colour on a voxel level and to model a complete voxel-based prosthesis. The comparison between the manual and digital workflow showed that 3D printing results in significant time savings since over four hours of manual work could be replaced by 3D printing. 3D printing ocular prostheses make the workflow reproducible and faster, which leads to more accessible and affordable prostheses in the future.","Ocular prosthetics; 3D printing; Digital workflow; Material jetting; Colour reproduction","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:973e0119-36cc-4dd4-9521-d283485fa23f","http://resolver.tudelft.nl/uuid:973e0119-36cc-4dd4-9521-d283485fa23f","Magnetoencephalography to characterize cortical effects of conditioned pain modulation in patients treated with spinal cord stimulation","Reinders, Laurien (TU Delft Mechanical, Maritime and Materials Engineering)","de Vos, C.C. (mentor); Schouten, A.C. (mentor); Frankema, S.P.G. (mentor); Forbes, P. (graduation committee); van Velzen, M. (graduation committee); Delft University of Technology (degree granting institution); Erasmus Universiteit Rotterdam (degree granting institution); Universiteit Leiden (degree granting institution)","2022","b>Introduction</b>: Spinal Cord Stimulation (SCS) is a successful last-resort treatment for chronic pain patients, although its exact mechanisms of action (MOAs) still need to be unraveled. The MOAs of SCS partly rely on spinal mechanisms (gate control theory) and supraspinal mechanisms likely play a role as well. Pain processing involves a complex network of cortical structures and can be modulated. Conditioned pain modulation (CPM) is a measure to describe the modulation of pain perception. CPM relies on the 'pain inhibits pain' theory, where a nociceptive test stimulus (TS) is modulated by applying a nociceptive conditioning stimulus (CS). CPM is often less efficient in chronic pain patients, but this might be improved by effective SCS.<br/><b>Objective: </b>The aim of this thesis is to assess how effective SCS affects the supraspinal mechanisms of pain modulation in chronic pain patients. The supraspinal mechanisms are evaluated using magnetoencephalography (MEG) to assess the cortical response to TS <i>before, during</i> and <i>after </i>CPM in chronic pain patients treated with SCS.<br/><br/><b>Methods: </b>Chronic pain patients treated with SCS underwent MEG sessions after receiving tonic and burst SCS for one week. Each session consisted of three CPM blocks: <i>before</i>, <i>during </i>and <i>after </i>CPM. During each CPM block 22 TS were administered accompanied by CS <i>during </i>CPM, after each block the subject reported a subjective pain rating of TS (and CS). The cortical response to TS, measured using MEG, was analyzed in the time and time-frequency (TF) domain using <i>Brainstorm </i>and <i>Matlab </i>software. TF decomposition was computed in several pain related regions of interest using complex Morlet wavelets. We examined how CPM affected event related spectral perturbations, induced by TS, in the alpha (8-12 Hz) and beta (13-30 Hz) frequency ranges. The average cortical response during tonic and burst SCS was evaluated in all subjects, and separately in the five clearest SCS responders (effective) and the five clearest SCS non-responders (non-effective).<b><br/></b><b>Results: </b>17 subjects were included. On average a decrease in subjective pain ratings of TS was observed <i>during</i> CPM. In the time domain, TS evoked activity in areas related to the sensory-discriminative aspect of pain. In the TF domain, TS induced event related desynchronization (ERD) followed by event related synchronization (ERS) in the alpha and beta frequency ranges in the bilateral sensorimotor cortices. <i>During </i>CPM the power of beta ERS was significantly decreased during burst SCS. A trend was observed towards a decrease in power of beta ERS for the effective burst SCS group, whereas no decrease was observed for the non-effective burst, effective tonic and non-effective tonic SCS groups.<b><br/></b><b>Conclusion:</b> The results suggest that on average, effective burst SCS decreases the power of beta ERS <i>during </i>CPM, this decrease indicates successful modulation of pain. Therefore, I suggest that effective burst SCS is capable of improving the supraspinal mechanisms of pain modulation, whereas effective tonic SCS is not capable of doing so. This suggestion indicates a partially different MOA for tonic and burst SCS. Future studies containing larger group sizes should validate these findings.","Magnetoencephalography; Spinal cord stimulation; Chronic pain","en","master thesis","","","","","","","","","","","","Technical Medicine | Sensing and Stimulation","",""
"uuid:6b42047d-5f0b-49bc-ba2c-48b04d8b32bd","http://resolver.tudelft.nl/uuid:6b42047d-5f0b-49bc-ba2c-48b04d8b32bd","Robotic Skill Mutation when Propagating a Physical Collaborative Task from Robot-to-Robot","Maessen, Rosa (TU Delft Mechanical, Maritime and Materials Engineering)","Peternel, L. (mentor); Delft University of Technology (degree granting institution)","2022","In this research, we examined the occurrence of skill mutation when propagating a collaborative sawing task from robot-to-robot. We conducted this research, to gain insight into this mutation to understand the generation of potentially beneficial or dangerous skills.<br/>Thirty propagation steps in simulation were conducted per experiment, each consisting of one expert robot teaching a novice (learner) robot. To explore what influences mutation, different external factors were changed, such as the maximum stiffness of the robots, the base position of the robots, the friction coefficient of the object and saw, and the period span of one sawing movement. The robots were controlled using a hybrid force/impedance controller, with the impedance part responsible for the sawing movement. The goal of the skill propagation was to teach the novice robot the impedance controller inputs (desired trajectory and stiffness), which is implemented through a three-staged learning process. In stage one, the desired trajectory was learned by encoding the measured trajectory using DMP and LWR, in stage two the stiffness was learned by encoding the computed stiffness, and in stage three the novice robot became an expert, able to collaboratively execute the task. <br/>The results showed that the skill varied over the different propagation step, therefore proven the existence of skill mutation. It was found that the biggest mutations were caused by a phase lag, overshoot on the desired trajectory, differences in joint states, and reaching torque limits. It was also found that environmental boundaries limited the mutations. By comparing the results of the different propagation steps of both different and the same conditions, it was that the mutations were not reproducible. This is a result of not being able to fix all external factors. We also identified the benefits (skill useful for different settings or different tasks, and energy efficiency) and dangers/drawbacks (high forces and skill becoming useless for initial task) of the mutation. <br/><br","Robotic Skill Mutation; Skill Propagation; Collaborative Task; Robot-to-Robot learning; Periodic DMP and LWR; KUKA LBR","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Vehicle Engineering | Cognitive Robotics","",""
"uuid:6f093c02-6405-47bc-832d-d74fd2c8714f","http://resolver.tudelft.nl/uuid:6f093c02-6405-47bc-832d-d74fd2c8714f","Creating ocular prosthetics using parametric modelling: Developing an new workflow for the parametric 3D-modelling of ultra-personalized ocular prosthetics","Mulder, Jelmer (TU Delft Industrial Design Engineering)","van Eijk, D.J. (mentor); van Dam, J.J.F. (graduation committee); Delft University of Technology (degree granting institution)","2022","In the Netherlands roughly 20.000 people wear an ocular prosthetic as a consequence of losing their eye due to an accident or disease. An ocular prosthetic is a type of facial prosthesis that replaces an absent natural eye. The main goal of an ocular prosthetic is to provide an aesthetic replacement of a real eye. It does not restore the ability to see. During surgery the eye is removed and a empty socket is left. An ocular prosthetic is custom made to fit that socket. <br/><br/>These prosthetic eyes are made by highly-skilled professionals who are called ocularists. They do this through a labour-intensive manual production process. This process consists of several steps such as obtaining the shape of the empty socket, consulting with patients and painting a realistic iris, sclera and pupil by hand. Traditionally these prosthetics are made with an acrylate called PMMA using a series of plaster moulds. <br/><br/>However the industry is moving towards digital production. The starting point for this thesis was an article written in 2021 by a research team from the Amsterdam Medical Centre consisting of Annabel L.W. Groot, Jelmer S. Remmers, and Dyonne T. Hartong. This article featured a proof-of-concept of a fully coloured 3D-printed ocular prosthetic. This showed that creating an realistic prosthetic using 3D-printing is possible. The next steps are integrating this knowledge into the daily work of an ocularist.<br/><br/>The goal of this thesis was to develop a new workflow for an ocularist in order to create an ocular prosthetic suited for 3D-printing by using computer aided design. To increase the efficiency of production and to help the ocularist with digitalization a custom tool was developed in the form of a parametric model. This parametric model is able to automatically generate 3D-geometry of an ocular prosthetic using 3D-scans of ocular impressions or digital reference models. By inputting manual measurements, photographs and parameters the ocularist is able to create eyes which offer a personalized fit for every patient. Five ocular prosthetics have been made using the new workflow and parametric model. These were then validated by comparing the results with prosthetics who are made using the same input but with the traditional method. The 3D-prints showed great promise for a new fully digital way of creating ocular prosthetics having low surface deviations with the original prosthetics . <br/><br/>The next steps are testing with real patients and further developing the parametric model into a dedicated software tool for ocularists. <br/><br/>Most ocularists seem to be far away from producing fully 3D-printed prosthetics for customers but this thesis is a good first step in the digitalization of the ocularist practice.<br/><br","Prosthetic eye; Parametric Design; Ocular prosthetics; 3d-scanning; 3d-printing; Workflow; Prosthetics; Design for Manufacturing","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:892b97a2-7038-4381-ab18-c931c6e73320","http://resolver.tudelft.nl/uuid:892b97a2-7038-4381-ab18-c931c6e73320","From least-weight to least-environmental-impacting truss structures: A method to minimize the total environmental cost with the Ground Structure Method for the welding, coating and construction material","van Rhijn, Bart (TU Delft Civil Engineering & Geosciences)","Hendriks, M.A.N. (mentor); Langedijk, Walter (mentor); Rots, J.G. (graduation committee); Mehrotra, A.A. (graduation committee); Delft University of Technology (degree granting institution)","2022","Climate change is changing the world. Where previously efficient use of materials was mainly applied to realize cost savings, this can also help to reduce the footprint of a construction. There is a rather direct and obvious relationship between the amount of material required in a construction and its environmental impact. Of course, the environmental impact is not solely dependent on this metric, but minimizing the weight of the structure is a great starting point. This thesis focusses on minimizing the environmental impact of a welded truss bridge. In addition to the required volume of construction material, the environmental costs for the welding and conservation are also taken into account. A case study is performed on a bicycle bridge crossing a highway that is built in the Netherlands.<br/><br/>The thesis starts with a review of multiple methods that minimize the weight of a structure. Within the field of structural optimization, The Ground Structure Method (GSM) appears to be the most suitable method for large structures that consist of slender structural elements. Making utterly high refinements in the GSM-model will result in a structure with definitely the lowest volume possible. However, this structure will have lots of smaller and shorter elements that will require in total more welding and conservation. This will not lead to a least-environmental-impacting structure. Thus the main question arises: <br/><br/>Will, within the ground structure method, minimizing on the environmental impact result in a significantly different structure than a minimization on weight?<br/><br/>The objective function for the environmental impact consists of the three considered contributing factors: the construction material, welding and the conservation. The environmental impact for the three factors is determined with a Life Cycle Assessment (LCA). Finally, every contributing factor is unified into a single indicator value through the Environmental Cost Indicator (ECI) method. <br/>The objective function also consists of three variables which represent: the volume of construction material, the welding volume and the surface of the structure. The volume is already known, since it is the regular GSM minimization. The welding volume can be determined through the joint-cost method, which is adding an artificial length to each member. The surface area of the structure is harder to determine. The relation of the volume of a construction element and its surface area is generally speaking non-linear. Multiple implementations were investigated. The aim is to perform the optimization on a fully connected ground structure, and so the assumption is made to make the relation between the volume and surface area linear. A circular hollow cross section with a variable radius and a constant wall thickness is implemented into the optimization method. The final objective function to minimize the ECI costs is a mixed-integer linear programming problem (MILP). <br/><br/>This method is tested on the established benchmark for a cantilever structure and on a case study for a bicycle bridge. The shape of the optimal structure is dependent on the amount of nodes within the design domain. The results for the cantilever structure does clearly reflect this. Depending on the amount of nodes in the design domain, the minimization of the environmental impact is decreased between 0 and 37%, while the weight is at most 2.5% higher. The difference of the environmental impact between the least-weight and least-environmental-impacting structure keeps increasing as the node density increases. <br/>The bicycle bridge is optimized in a 2D and 3D design domain. The design domain of the bicycle bridge appeared to be too big to be solved by the MILP formulation optimization, thus the domain is reduced to a single span of the bridge. Furthermore, the amount of nodes in the design domain is limited to improve the computability of the problem. In both the 2D and 3D variant the regular minimization on weight requires only a fraction of the time to solve the problem successfully. For the 2D case there is a difference between the minimization of the weight and ECI. The number of members in the least-environmental-impacting structure is reduced by 40%, which results in a 1% lower environmental impact. The MILP could not converge properly in 4 hours in the 3D design domain. This is mainly because the model size did increase a lot compared to the 2D design domain. Going from 2D to 3D adds a third axis, which increases the amount of constraints by 50%. Likewise, the number of nodes in a 3D domain increase more rapidly than in a 2D domain. <br/><br/>All in all, the method is implemented successfully and validated with the cantilever structure. The proposed method will result in a structure with an equal or lower environmental impact compared to the regular least-weight minimization. However the minimization of the environmental cost with the proposed optimization method is able to solve problems with around 5,000 variables. To solve larger models successfully it is advised to either reduce the connectivity of the ground structure or to apply the joint-cost method with an LP. <br","Ground Structure Method; Environmental impact; Environmental cost indicator; least-weight structure","en","master thesis","","","","","","","","","","","","Civil Engineering | Structural Engineering | Structural Mechanics","",""
"uuid:4a345862-7d71-4fec-b4b9-87322a332787","http://resolver.tudelft.nl/uuid:4a345862-7d71-4fec-b4b9-87322a332787","Application of Deep Neural Networks to the Operator Space of Nonlinear PDE for Physics-based Proxy Modeling","Hadjisotiriou, George (TU Delft Civil Engineering & Geosciences)","Voskov, D.V. (mentor); Rongier, G. (graduation committee); Mansour Pour, K. (graduation committee); Groenenboom, Jeroen (graduation committee); Fadili, Ali (graduation committee); Delft University of Technology (degree granting institution)","2022","Compositional simulation is computationally intensive for high-fidelity models due to thermodynamic equilibrium relations and the coupling of flow, transport and mass transfer. In this report, two methods for accelerated compositional simulation are outlined and demonstrated for a gas vaporization problem. The first method uses a proxy model that reduces the number of components and the second method reduces the number of grid blocks (i.e. upscaling). Both methods are implemented within the operator-based linearization framework of the Delft Advanced Research Terra Simulator.<br/><br/>Lebesgue integration is applied in the loss function of a neural network allowing the neural network to discover the operator space of the reference model in reduced dimensions. Training is carried out for a one-dimensional homogeneous reservoir and minimizes the misfit of the leading and trailing shocks of a compressible pseudo-binary model with respect to observations of the reference model. The operator space of the pseudo-binary model is initially approximated with the method of multiscale reconstruction of physics, a numerical representation of the method of characteristics. Training is carried out in a two-stage transfer learning scheme to increase computational efficiency. In the first stage, neural networks are trained to approximate the analytical reconstruction. In the second stage, a solver is embedded in the loss function of the neural network and the forward solution is used to calculate the Lebesgue integral. The transfer training scheme minimizes the misfit of the leading and trailing shocks for 10 discrete time steps in a one-dimensional homogeneous reservoir. The misfit of the trained model shows a significant improvement in the location of the trailing shock and a modest improvement in the estimation of the leading shock. The trained proxy is applied to the top and bottom 15 layers of the SPE10 model and the estimation of the first and last breakthrough is assessed in conjunction with the error of the phase-state classification. The phase-state classification is significantly improved through time which is also expressed in improvements of the estimation of breakthrough times. The average difference in breakthrough time for the trained and untrained models with respect to the reference model is 293days versus 570days for the trailing shocks and 15days versus 16days for the leading shock. The established training framework enables the development of proxies with increased complexity. <br/><br/>Rigorous upscaling defines the upscaled operator space with dynamic and non-equilibrium thermodynamic upscaling functions. These functions combined, define the upscaled operator space for the three-dimensional compositional space and are inferred from data points gathered from a limited, characteristic portion of the full-size model. Gathered data points are interpreted with an interpolation function or neural networks to construct structured OBL meshes for implementation within DARTS. This upscaled operator space can effectively be used for different boundary conditions without reevaluating the upscaling functions.","machine learning; partial differential equations; nonlinear dynamics; compositional simulation; physics-informed neural networks","en","master thesis","","","","","","","","","","","","Geo-Engineering","",""
"uuid:07ad0f20-9f31-4f40-94a5-7c80638b04b3","http://resolver.tudelft.nl/uuid:07ad0f20-9f31-4f40-94a5-7c80638b04b3","Multi-Renewable European Power System: Wave Energy Integration","Delgado Elizundia, Felix (TU Delft Technology, Policy and Management)","Lavidas, G. (mentor); Blok, K. (graduation committee); Delft University of Technology (degree granting institution); Universiteit Leiden (degree granting institution)","2022","Multi-renewable energy systems, which must consider emerging technologies that exploit other available renewable energy resources, have the potential to reduce the variability of current mature renewable technologies such as solar and wind, increase power availability, diversify the electricity supply, and ultimately accelerate the substitution of fossil fuels. Ocean energy technologies can represent an important part of these multi-renewable generation low-carbon energy systems, given their vast and yet untapped source of renewable energy medium. They are increasingly being perceived as an important piece of future energy systems, given they are characterized by stable generation profiles, predictability, and high energy density. Among the different ocean energy technologies, wave energy shows strong potential to support carbon reduction targets and meet expected increases in electricity demand. It is considered one of the most dense, predictable, and persistent energy sources, with multiple regions exposed to the wave energy resource.<br/>This researched performed an exploratory investigation of the impacts and interactions of wave energy in a wider context under future cost-optimal and multi-renewable configurations of the European transmission network. This was achieved, first, by expanding the renewable energy capabilities of the existing open-source PyPSA-Eur, energy system model and dataset of the European power system at the transmission level covering the full ENTSO-E area, to include the wave energy resource. And second, by simulating a set of future, cost-optimal, and multi-renewable European power systems at 2030, 2040, and 2050 horizons employing a greenfield optimization approach and considering cost-reduction potentials of wave energy and other generating technologies. <br","Industrial Ecology; Wave energy; power system modelling; European power system; ENTSO-e; PyPSA-Eur; Atlite","en","master thesis","","","","","","","","","","","","Industrial Ecology","",""
"uuid:65cbbdf3-3627-4829-bd69-208fffc8eba9","http://resolver.tudelft.nl/uuid:65cbbdf3-3627-4829-bd69-208fffc8eba9","Preliminary sizing methodologies for regional aircraft with liquid hydrogen fuel and SOFC-GT-Battery hybrid-electric powertrains","Garcia Gonzalez, Pedro (TU Delft Aerospace Engineering)","de Servi, C.M. (mentor); Mourao, Carlos (mentor); Delft University of Technology (degree granting institution)","2022","Solid Oxide Fuel Cell (SOFC) systems for aviation applications have been considered for their use as APUs or powertrains, as standalone systems or in combination with gas turbines, and both fueled by reformed Jet-A or by hydrogen. Most existing studies focus on powertrain performance modelling. In this work, traditional tube-and-wing regional aircraft sizing methodologies are modified to account for liquid hydrogen fuel and SOFC-GT-Battery hybrid electric powertrains. Methodologies for powertrain modelling, power sizing, energy sizing, weight calculation and system integration have been derived, implemented, verified, validated when possible, and used to assess several study cases. Considering state-of-the-art metal-supported planar ITSOFC technology installed in a 50-seat regional aircraft as test case, it is concluded that current SOFC system power density is not sufficient to achieve MTOW values similar to conventional kerosene-powered regional aircraft. This work serves as a baseline for the integration of sizing methodologies for SOFC-GT-Battery powertrains into aircraft conceptual-to-preliminary design tools.","Liquid Hydrogen; Fuel Cell Aircraft; SOFC-GT; Solid oxide fuel cell; hybrid electric propulsion; Aircraft Design; Weight Estimation; system integration; Turboprop; Power sizing; Energy sizing","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:fe28e8a3-4bc8-4ddd-a5b4-892608e9cf3f","http://resolver.tudelft.nl/uuid:fe28e8a3-4bc8-4ddd-a5b4-892608e9cf3f","Decarbonisation in PyRICE: Decomposing the Emission Output Ratio to Better Understand the Drivers Behind Low Carbon Futures","El Malki, Marya (TU Delft Technology, Policy and Management)","Kwakkel, J.H. (mentor); Pfenninger, Stefan (graduation committee); Biswas, P. (graduation committee); Delft University of Technology (degree granting institution)","2022","Climate Change continues to pose a considerable threat to the well-being of people and economies. Today, to avoid catastrophic and irreversible damage, decision-makers and policy advisers need to explore possible scenarios and enact mitigation and adaptation policies to curb the rise of global temperatures within the thresholds set by the Paris Agreement. However, avoiding a 1.5-degree warming seems already out of hand, and the last Conference of Parties in Glasgow (COP26) sparked a contentious debate surrounding the role of coal. Representatives rely on climate reports and models to understand the problem, including integrated assessment models that aim to encompass the whole process straightforwardly and transparently. One example is the RICE-2010 model developed by the 2018 Nobel Prize winner in economics William Nordhaus, used by the IPCC and known for its simplicity. However, the model does not include an explicit formulation of energy. This renders it hard to explore scenarios and policy questions directly tied to the diversification of the energy mix, a topic that has gained considerable attention with the Energy Crisis sparked by the Russian Invasion of Ukraine. Therefore, this thesis attempts to introduce energy intensity and carbon intensity to the model by decomposing the Emission Output Ratio. These parameters will allow the user to explore the drivers behind decarbonisation, whether it is related to an improvement in the energy efficiency of processes or a greener energy mix. The selected approach yielded surprising insights, such as the poor documentation and data quality of the RICE model, the over-simplistic design choices behind emissions and decarbonisation, and the under-representation of carbon intensity. These outcomes have highlighted potential, underestimations of future temperature rise, limited policy testing potential and a lack of transparency in data, methodology, and reproducibility.","RICE Model; Decarbonisation","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:b54afe4a-c6e5-4c21-8ed3-acfbd4466c40","http://resolver.tudelft.nl/uuid:b54afe4a-c6e5-4c21-8ed3-acfbd4466c40","Analysing the Waste Potential of Solar PV In India","Thomas, John (TU Delft Technology, Policy and Management)","Fishman, Tomer (mentor); Kamp, L.M. (graduation committee); Delft University of Technology (degree granting institution); Universiteit Leiden (degree granting institution)","2022","With growing demand for energy and the shift towards renewable energy, countries like India are targeting energy mixture with alternate sources like solar, wind and water. With the current growth of solar energy use in India, it is predicted that high amounts of Solar Photovoltaic (PV) waste would be generated in the near future which left improperly managed would lead high amount of useful and expensive material ending up in landfills. This research focuses on the potential material generated from the growth of solar PV stock in India.<br/>This research studied the growth of solar PV industry and the spread of Solar PV growth in India. The stock growth of solar PV till 2030 based on India’s renewable energy goal of 280 GW solar energy is taken. Further study on End of Life (EOL) management of Solar PV was studied and the best practice scenarios from around the globe for handling Solar PV waste was studied. The circular economy approach for the Solar PV industry was also reviewed. 3 scenarios were created to determine how the waste from these Solar PV would be managed based on the current state in India, using best-case scenario from around the world and circular economy practices. These scenarios were simulated using dynamic material flow analysis to determine the waste inflow and outflow of material based on the defined scenario.<br/>It was determined that more than 21 million tonnes of waste would end up in landfill by 2060 if India does not increase its recycling capabilities. Also, by adapting Germany’s WEEE regulation for solar PV waste management, 2 other scenarios are created, which uses extended producer responsibility and would provide India with the capability to handle future Solar PV waste. A comparison of these 2 scenarios showed higher recovery of material in one (423 thousand tonnes) while generating 21 times more waste to landfill than the other (16 thousand tonnes).<br/>It is found that the outflow of tonnes of material is same in all 3 of the scenarios and the highest amount of waste produced by the 280GW target of 2030 would be in 2055 at over 1.6 million tonnes. It is predicted that landfill can end by 2033 or 2044 in the defined scenarios but shows variation in the amount of recovered material would differ between them. Achieving the scenarios put forward would involve coordination between Government agencies, producers of solar PV and the actual users of PVs. A shift to a formal waste management sector would be required and a successful implementation of policies and targets would lead to improvement in multiple Sustainable Development Goals (SDG) for India.","Material Flow Analysis; Circular economy (CE); Solar PV; India; End of life","en","master thesis","","","","","","","","","","","","Industrial Ecology","",""
"uuid:2594342a-90b6-443b-9430-36e2ca21be0f","http://resolver.tudelft.nl/uuid:2594342a-90b6-443b-9430-36e2ca21be0f","No Gas All Local: Developing a renewable-based and decentralised energy system for the historic centre of Amsterdam","Ayaz, Melih (TU Delft Architecture and the Built Environment; TU Delft Amsterdam Institute for Advanced Metropolitan Solutions)","Bokel, R.M.J. (mentor); Chen, H.C. (graduation committee); Peters, K.B.M. (graduation committee); Delft University of Technology (degree granting institution)","2022","Urban energy systems are the key elements of combating the climate crisis as the energy transition is crucial to curb greenhouse gas emissions in urban areas, one of the main drivers of climate change. As such, there is a great effort in Amsterdam to phase out natural gas use by 2040, and to become carbon neutral by 2050. It is a great challenge since the existing centralised energy systems are specifically built on the transportation and use of large amounts of fossil fuels while renewable energy has many limitations due to the volatility of its sources, lack of capacity for energy load and storage. Yet, since renewable energy sources are locally available everywhere, the establishment of decentralised renewable energy infrastructures based on local sources can help overcome these limitations. On this basis, this research explores the possibility of developing such systems through a case study in the historic centre of Amsterdam where many local challenges like urban monumentality pose risks for the energy transition. The research is structured around the use of Smart Urban Isle approach as a methodological tool to reveal local potentials for energy reduction, reuse and production, and to design energy concepts based on these potentials to reduce the reliance on external energy input. The results of the case study show that it is possible to cover the heat and cold demand with local sources and to cut almost half of the external energy input into the site without bringing any significant pressure onto the power grid. This outcome is highly promising as it proves that such local interventions can make great contributions to the energy transition process by significantly reducing the tension on the regional and national energy systems for the replacement of fossil fuels. As for the field of architecture and urban planning, the results implicate that the bioclimatic design principles, mixed-use of buildings and urban spaces, and small-scale and decentralised urban infrastructures based on the circular economy and self-sufficiency principles are crucial to achieve higher energy efficiencies and more local energy inputs.","Energy transition; Decentralised energy system; Renewable energy; Smart Urban Isle; Heat transition; Amsterdam","en","master thesis","","","","","","","","","","","","Metropolitan Analysis, Design and Engineering (MADE)","","52.37537080532721, 4.89590580815472"
"uuid:8d9f0d07-8294-4c3d-b33e-ed09042fb5bd","http://resolver.tudelft.nl/uuid:8d9f0d07-8294-4c3d-b33e-ed09042fb5bd","Planning support systems for implementing blue-green infrastructure: Multi-functional spatial planning strategies in Amsterdam","Keijzer, Nout (TU Delft Architecture and the Built Environment)","Gaete Cruz, M. (graduation committee); Alves Beloqui, A. (mentor); Delft University of Technology (degree granting institution)","2022","Cities are facing more extreme climates and weather events. This requires changes in the way cities are planned and designed. Blue-Green Infrastructure (BGI) is increasingly recognized to guide the transition to climate resilient cities. BGI is founded in urban water management but has emerged as a complementary type of infrastructure because it can provide multiple benefits. To advance the integration of BGI in the urban landscape, Planning Support Systems (PSS) have proven their merit. PSS are any kind of digital tool for support in planning processes. However, PSS are not used much in urban planning. This could have multiple reasons, but it referred to the implementation gap. The gap suggests a mismatch between PSS supply and demand. The demand is set by the practitioners of PSSs, the urban planners. Most effort in closing the gap is with research on improving the technical specifications of PSS. The challenges urban planners are facing in implementing BGI hasn’t been carefully studied. To improve the uptake of PSS for BGI implementation, this thesis evaluated a prototype PSS, studied on the case of the municipality of Amsterdam. Next to the conceptualization of BGI and PSS, the objectives were: to understand urban planning processes; to determine the challenges for BGI implementation; and to find opportunities for PSS to address these challenges. This thesis conceptualizes BGI and PSS in the perspective socio-technical solutions in the transition to sustainable urban development. The planning processes and related challenges are studied by means of semi-structured in-depth interviews with 9 urban planners of the municipality of Amsterdam. Five of them participated in a focus group in which the prototype PSS was evaluated. Amsterdam constructed four main planning processes with which it aims to apply an integrated approach to the implementation of BGI. The main challenges urban planners are struggling with multi-objective planning required in the increasingly complex urban landscape; translating abstract and contradictory policy into practice without classification and standardized BGI measures; and collaborating to obtain the integrated approach. During the focus group, the participants listed multi-objective planning and supporting collaborative processes as most appropriate opportunities for the protype PSS. The use of PSS is highly dependent on the balance of technical and supportive functions. This thesis provides insights for PSS-developers on how to meet the demand of urban planners. With more useful PSS the transition for sustainable urban development can be accelerated.","Blue-green infrastructure; Planning Support System (PSS); Planning tool; Urban planing","en","master thesis","","","","","","","","","","","","Metropolitan Analysis, Design and Engineering (MADE)","",""
"uuid:8f75af88-fda1-4c2a-b8f9-94fa29a20e71","http://resolver.tudelft.nl/uuid:8f75af88-fda1-4c2a-b8f9-94fa29a20e71","Spectral Calibration of Time-inhomogeneous Exponential Lévy Models: with Asymptotic Normality, Confidence Intervals, Simulations, and Empirical Results","Koorevaar, Loek (TU Delft Electrical Engineering, Mathematics and Computer Science)","Söhl, J. (mentor); Papapantoleon, A. (graduation committee); Delft University of Technology (degree granting institution)","2022","The problem of calibrating time-inhomogeneous exponential Lévy models with finite jump activity based on market prices of plain vanilla options is studied. Belomestny and Reiß introduced an estimation procedure for calibration in the homogeneous case with one maturity. The open-ended question that will be addressed is if we can extend this model to use all listed plain vanilla options with multiple maturities. This opens a way to use all available data to create a time-inhomogeneous model with time-dependent Lévy triplets between subsequent intervals based on the maturities. <br/><br/>We establish via an adapted Lévy-Khintchine representation an estimation procedure on the explicit inversion of the option price formulas in the spectral domain with a cut-off scheme for the regularisation of high frequencies. The estimation procedure will be shown to be well-defined and the parameters to be normally distributed asymptotically. <br/><br/>Practical implications imply that using the asymptotic variances of the normal distributions leads to insufficient confidence intervals for non-asymptotical cases. We, therefore, construct confidence intervals using an approximated finite sample variance. <br/><br/>Monte Carlo simulations are implemented in the computational software R to evaluate the stability and accuracy of the estimation procedure. Furthermore, the finite sample confidence intervals are assessed with coverage probabilities. <br/><br/>In the end, the estimation procedure is evaluated by calibrating to market data of plain vanilla S\&amp;P500 options, which contain numerous maturities. The estimated parameters with confidence intervals between maturities support time-dependency and the constructed time-inhomogeneous exponential L{\'e}vy models appear favorable in contrast to the time-homogeneous model.<br","Exponential Lévy Process; Spectral Calibration; Time-Inhomogeneous; Asymptotic Normality; Simulations; Confidence Intervals; non parametric; Empirical Results","en","master thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:58eb0f8b-0e02-434e-b11b-f88200b12e07","http://resolver.tudelft.nl/uuid:58eb0f8b-0e02-434e-b11b-f88200b12e07","Exploring opportunities to decrease the future healthcare burden of cardiovascular diseases","de Schipper, Lisette (TU Delft Technology, Policy and Management)","Hinrichs-Krapels, S. (mentor); Kist, Janet (mentor); Ghorbani, A. (graduation committee); Kwakkel, J.H. (graduation committee); Delft University of Technology (degree granting institution)","2022","In the Netherlands, a substantial burden of morbidity and mortality persists for cardiovascular diseases in women. Despite this, the reduction of cardiovascular diseases in women has plateaued. This is against the backdrop of an ageing population and the prevalence of sedentary and unhealthy lifestyles.<br/>This research presents a novel model to explore the problem space. A multi-disciplined microsimulation model is presented that incorporates theories and data aggregated from individual health data, population studies, social network studies, and behaviour studies. To our knowledge, it is the first model of its kind. We used the city of The Hague as our case study, as we were able to use a treasure trove of individual health data to inform the model, and thus inform the answer to the research question. The model was developed to answer the research question:<br/>How can behavioural interventions decrease the healthcare burden of cardiovascular diseases among women in The Hague?<br/><br/>Our methodology consisted of multiple phases. First, we conducted a literature study to identify<br/>cardiovascular risk factors and entry points for interventions. Second, we developed health data models to be integrated into the microsimulation model. Third, we designed and implemented a microsimulation model and explored a plausible future cardiovascular health burden. Fourth, we looked at the impact of certain interventions applied to the entry points. The chosen interventions are based on the hypothesis that was derived from the literature read during the first phase. The hypothesis was as follows: <br/><br/>How can recurring interventions targeting diet, exercise or smoking behaviours decrease the healthcare burden of cardiovascular diseases among women in The Hague?<br/><br/>During the literature study we conducted, we made multiple findings. First, current studies seem to omit relevant risk factors for women, such as pregnancy complications. So far, studies primarily focus on men, even though that cardiovascular diseases are the leading cause of morbidity and mortality for women in the world. Second, studies that examine risk factors oversimplify the nature of the problem and neglect cultural, social and even biological context. The problem is complex and multi-faceted. Thus, it warrants a fitting approach, such as the one presented in this research. Third, there is too little evidence on the efficacy of interventions targeting behaviours that lead to an increased risk of cardiovascular diseases.<br/>During the development of the data models, we found that the cardiovascular risk of a young female is significantly higher if she has multiple risk factors – something that is currently not mentioned in the cardiovascular guidelines. We also found that smoking is the most dominant modifiable risk factor. However, since, in the model we developed, exercise and diet behaviour affect a woman’s blood pressure, total cholesterol and blood sugar, indirectly, BMI may be just as, if not more, important. Our data model and our literature study thus confirm that these are important entry points that need to be exploited by interventions.<br/>The simulation runs made the staggering revelation that, unless we do something about it, the future for women with regard to CVD looks bleak. The health issue is obstinate, and much of the prevention potential seems to be lost. The effects of many temperate interventions, such as education in schools, are negated, due to the oversaturation of unhealthy lifestyle behaviours. We also found that the effect of repeating interventions is more sustainable and long-term. However, our experiments implied that true progress can be made if extreme interventions are introduced repeatedly. Due to the intensity, it is unlikely the population of The Hague and additional stakeholders would approve of these interventions. We nuance the findings by the fact that the model is a simplified representation of the real world.<br/>Choices were made during the design, and certain elements of human behaviour and of cardiovascular pathophysiology were omitted from the model. In some aspects, there simply was not enough data, such as on the effect of policies on a woman, but also how a woman is exactly influenced by her network and by external influences. These were some of the unknowns that could be addressed in future research.<br/>This research concludes that there is an urgent need to introduce interventions that realise a sustainable, lasting change in the behaviours of women in The Hague. Three potential entry points are food intake, exercise, and smoking. Promoting healthier lifestyles is however only possible if we also address the social and cultural context. This model shows it is less effective to just change the behaviours of one woman, as social pressures may persuade her to fall back to her previous behaviours. We can set up women for success by involving her social network and as such decrease the barrier for her to permanently adopt a healthier lifestyle.<br","Cardiovascular disease; Policy analysis; Agent-based model; Fine and Gray Model; GLMs; women; Healthcare burden","en","master thesis","","","","","","https://github.com/Lischip/pulse_ultra Github repo","","","","","","Engineering and Policy Analysis","Hart voor vrouwen","52.078754545735016, 4.3191270656160965"
"uuid:129d05b0-87f5-44e1-8878-b03a2c0ee845","http://resolver.tudelft.nl/uuid:129d05b0-87f5-44e1-8878-b03a2c0ee845","Building a building block: A realistic, ready-to-couple, one-dimensional model of systemic lymph flow.","Pomari, Antoine (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Mathematical Physics)","Dubbeldam, J.L.A. (mentor); Vuik, Cornelis (graduation committee); Delft University of Technology (degree granting institution)","2022","Coupled mathematical models are used successfully to represent systemic blood flow with different degrees of precision: for example, 3D representations in zones of particular interest (e.g., the aortic bifurcation) are embedded into 1D models who account for systemic blood circulation. When it comes to the lymphatic system, various 1D models for systemic lymph flow have been developed, however it is not clear whether they can be readily used in the context of a coupled mathematical model. In this work, we give an overview of the lymphatic system and its components in order to justify the interest for a 1D model of systemic lymph flow which can be coupled with 3D representations of specific zones. Then, we develop a one-dimensional model for lymph flow with exactly this property. In particular, we propose a formulation for the compliance of the walls of lymphatic vessels and of the sinuses of lymph nodes, as well as a novel formulation to mimic the phase contractions of lymphatic endothelial cells. Moreover, we give details and insight on the eigenvalues and characteristics of our proposed system for one-dimensional lymph flow, in order to highlight why and how coupling with 3D representations is possible. Finally, we perform a set of numerical experiments to study the applicability of our model.","Coupled numerical model; Lymphatic system; lymph flow","en","master thesis","","","","","","","","","","","","Applied Mathematics | Computational Science and Engineering","",""
"uuid:ed3e282a-35cd-4c15-b346-a26950b47472","http://resolver.tudelft.nl/uuid:ed3e282a-35cd-4c15-b346-a26950b47472","Tangential load and trim behaviour: Analysis of the Maeslant Barrier under seaward flow","van der Weijden, Hans (TU Delft Civil Engineering & Geosciences)","Jonkman, Sebastiaan N. (mentor); van der Male, P. (graduation committee); Bakker, A.M.R. (graduation committee); de Jong, M.P.C. (graduation committee); H., Nederend (graduation committee); Delft University of Technology (degree granting institution)","2022","This investigation considers the two floating gates of the Maeslant barrier, which is a storm surge barrier in the Rotterdam area. During the end of each closure operation of the Maeslant barrier, the flow at the barrier may be in seaward direction. Three different effects have been observed in the situation with a flow in seaward direction. The following three effects are considered in this report:<br/><br/>1. A force in the connection between the gate and guide tower<br/>2. A quasi-constant change of the gate orientation<br/>3. A periodic oscillation of the gate orientation<br/><br/>In this report, these three effects are described, and data on these effects and relevant hydraulic conditions is collected. These data are obtained from yearly test closures in the period 2007-2021. Based on the collected data, the three effects and hydraulic conditions are quantified. From a statistical analysis based on the data, a relation with the local discharge is found for each of the three effects. <br/><br/>To further explain the effects, simple conceptual models are derived for each of the effects. The conceptual models yield the most relevant results for the observed force, which is appropriately modelled based on a momentum balance over the barrier. For the other two effects, the conceptual models presented in this report do not adequately model the gate behaviour, however suggestions are provided for further improved models. <br/><br/>Lastly, based on the most relevant statistical and conceptual models, an extrapolation of the three effects is performed to assess the magnitude of the three effects in extreme situations. <br","Maeslant barrier; Storm surge barrier; hydraulic structures; stormvloedkering; Nieuwe Waterweg","en","master thesis","","","","","","","","","","","","Civil Engineering | Hydraulic Engineering","","51.955278,4.163889"
"uuid:87ca0e26-a920-4bea-9516-8293294b1ebe","http://resolver.tudelft.nl/uuid:87ca0e26-a920-4bea-9516-8293294b1ebe","The role of data visibility in the control and automation of modern Supply Chains: A Model Predictive Control case study in Ferrari","Dell'Orto, Federico (TU Delft Mechanical, Maritime and Materials Engineering)","Beelaerts van Blokland, W.W.A. (mentor); Patuelli, Nicola (mentor); Delft University of Technology (degree granting institution)","2022","Nowadays many companies still conceive their logistic operations as a simple material replenishment of the production plants and do not invest money and time in projects to structure their Supply Chain and bring more eciency to the production process. In addition, the high complexity of the automotive industry and the emerging uncertainties that are characterizing a more globalized, dynamic and interconnected world give companies a huge incentive to research and innovate the management of their supplier network. Over the last years, businesses have experienced several issues along their logistic flows. Unexpected events such as the pandemic and the semiconductor crisis have put companies in research for solutions that look to improve and strengthen the partnership with their suppliers.<br/>Digitization represents one of the most innovative and disruptive challenges in today’s Supply Chains. Indeed, the increasing amount of data retrievable from logistic and production processes today is yet not exploited enough in comparison with its potential benefits. Companies still work by silos and prefer to hide their information rather than sharing them with their partners.<br/>In this research paper, the role of data visibility is put under attention, in order to demonstrate its practical benefits in a complex automotive Supply Chain. By collaborating with Ferrari on a Supplier Relationship Management (SRM) project, this research presents the design of a Supply Chain control tower through Model Predictive Control. By simulating a MPC optimization model on a small part of Ferrari’s supplier network, the coordination, eciency and sustainability of the Supply Chain are assessed through a comparison with the current state and by evaluating the network’s performances in di↵erent logistic scenarios. Although this solution is presented as a decision-support tool, it is thought as a key technology for the future development of autonomous Supply Chain operations.","Big Data; Supply Chain integration; Model Predictive Control; Supplier Relationship Management; Supply Chain control tower; Centralized autonomous agents","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Multi-Machine Engineering","",""
"uuid:de8eb6c2-020f-4c7d-a49a-f139940a28e7","http://resolver.tudelft.nl/uuid:de8eb6c2-020f-4c7d-a49a-f139940a28e7","Unsteady SpaRTA: Data-driven turbulence modelling for unsteady applications","Miori, Nicolò (TU Delft Aerospace Engineering)","Doan, Nguyen Anh Khoa (mentor); Dwight, R.P. (mentor); Kotsonis, M. (graduation committee); Langella, I. (graduation committee); Delft University of Technology (degree granting institution)","2022","Recent years have seen an increase in studies focusing on data-driven techniques to enhance modelling approaches like the two-equation turbulence models of Reynolds-averaged Navier-Stokes (RANS). Different techniques have been implemented to improve the results from these simulations. In particular, the main focus has been on overcoming the limitations implied by the Boussinesq assumption. This has been approached by using machine learning techniques as a way of discovering new formulations that could overperform when compared to traditional models.<br/>Despite promising results for steady RANS simulations, little has yet been investigated in URANS applications. In this dissertation, this lack of research will be addressed. The main ideas are then, first, to see how the available information in URANS simulations can be used to improve the anisotropic Reynolds stress tensor prediction, and second if and how this can be done by using a sparse regression technique, whose framework is known as SpaRTA. A procedure involving the triple decomposition of High-Fidelity velocity fields is applied, aiming at finding a model exclusively for the stochastic component of the anisotropy. The test case which is considered is the flow around a cylinder at Re=3900. The High-Fidelity data was collected by running Large Eddy Simulations in OpenFOAM, after which the velocity was split into its different components through Proper Orthogonal Decomposition.<br/>A priori results have shown good performance of the trained models, outperforming the Boussinesq assumption both in the prediction of turbulence componentiality and also on the values of the single anisotropy components.","Data-Driven turbulence modelling; POD; SpaRTA","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:8d7b8bf6-4831-40aa-acc0-3b72501543ab","http://resolver.tudelft.nl/uuid:8d7b8bf6-4831-40aa-acc0-3b72501543ab","Application of the IUCN Global Standard for Nature-based Solutions to river restoration projects","Berg, Maikel (TU Delft Civil Engineering & Geosciences; TU Delft Hydraulic Engineering; Rijkswaterstaat - WVL)","Schielen, R.M.J. (mentor); Blom, A. (graduation committee); Spray, Chris J. (graduation committee); Stancanelli, L.M. (graduation committee); Slinger, J (graduation committee); Snoek, Yvo (graduation committee); Delft University of Technology (degree granting institution)","2022","Implemented in river landscapes, Nature-based Solutions (NbS) have the potential to reduce flood risk, while also playing an important role in restoring many of the ecosystem services that are lost as result of human interventions and global warming. A barrier to succesfull implementation of NbS is the lack of a global and common framework with guidelines for its implementation and evaluation. In response, the IUCN Global Standard for NbS was published. Even though the IUCN Standard has been designed to be applicable to NbS in all sectors and over the entire globe, knowledge on its applicability and usefulness for specific sectors remains limited at present. Therefore, this study aims to identify the challenges that occur in ex-post application of the IUCN Standard to river restoration projects with a focus on flood risk mitigation, and the added value that this application may provide.<br/><br/>At first, a literature study is conducted in which the content of the IUCN Standard is related to twenty-two other assessment frameworks for NbS and compared in-depth to the three most relevant frameworks. These comparisons indicate that that the IUCN Standard has a broad scope of application, provides limited flexibility in assessment to its users and is descriptive. Furthermore, the comparisons reveal that the IUCN Standard can be used as a tool to evaluate the extent to which the essential processes of a NbS, established by the IUCN, have been incorporated in the project (i.e., process-oriented framework). The standard can, however, not be used to evaluate project results, including biophysical and social results.<br/><br/>In the next part of the research, the IUCN Standard is applied to three case studies of river restoration projects with a focus on flood risk mitigation, of which at least two differ significantly in the surface area, position in the catchment, kinetic energy of the river, data accessibility, resources and the type of riverine NbS measures that were implemented. The selected case studies are the Eddleston Water Project, the “Room for the River” Deventer Project and the Missouri River Levee Setback Project. Despite facing challenges in the interpretation of indicators, data accessibility, a relatively coarse scale for evaluation, and tensions between the project objectives and the use of the IUCN Standard, the standard is successfully applied to all case studies. The case study results consist of (1) a total percentage match to the IUCN Standard and a statement on being in adherence to the standard, which may provide credibility to the project processes, (2) the strenghts and weaknesses of a project, which may be used to guide projects and strengthen (future) projects, and (3) a radar chart, which may provide possibilities to compare to and learn from other projects. Based on these results, it can be concluded that, despite of a few challenges, the IUCN Standard is applicable to river restoration projects with a focus on flood risk mitigation, and that application of the standard may provide added value in various ways, although restricted by the limited evaluation of flood risk mitigation.<br","Nature-based Solutions; IUCN Global Standard for NbS; river restoration; flood risk mitigation; Case Study Research","en","master thesis","","","","","","","","","","","","Civil Engineering | Hydraulic Engineering","",""
"uuid:1a517f2d-edd3-4c63-968a-7ca9c60426dd","http://resolver.tudelft.nl/uuid:1a517f2d-edd3-4c63-968a-7ca9c60426dd","Fleet Design for Last-Mile OnDemand Logistics","Claij, Cilia (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Cognitive Robotics)","Kronmüller, M. (mentor); Alonso Mora, J. (mentor); Hernández, Carlos (graduation committee); Sharif Azadeh, S. (graduation committee); Fielbaum, Andres (graduation committee); Delft University of Technology (degree granting institution)","2022","The simultaneous rapidly increasing demand for home delivery of goods and on-demand expectancy of customers over the past years leaves a tough challenge for the logistical branch. They have to keep up with this increasing demand and simultaneously they are obliged to satisfy consumer service level demands to preserve their customers. On the other hand, as economic goals drive these businesses, they are prompted to operate cost-effectively. As a result, the fleet, deployed to execute the last-mile delivery, should meet both the requirement of cost-efficiency as well as the requirement for meeting consumer service level demands. This raises the question of how to efficiently design a fleet for last-mile on-demand logistics. For a fleet to be able to operate cost-efficiently, the fleet design decisions are required to take both fixed and variable costs into account. As such, the fleet design decisions need to include the consideration of the size of the fleet as well as the distance the vehicles travel on daily basis. Therefore, the goal of this thesis is to develop a novel method for fleet design for last-mile on-demand logistics. This work contributes by being the first to investigate methods for doing fleet design specifically for last-mile on-demand logistics considering multiple depots and variable pick-up locations. The purpose of the method is to determine the operational plans of the individual vehicles, the number of vehicles needed throughout a certain time period, the pick-up locations for all orders and the total distance travelled by the full fleet of vehicles. The proposed method builds upon established fleet design methods for ride-sharing taxi problems. The optimization method is adapted for last-mile on-demand logistics, yielding the required number of vehicles and their individual operational plans. The input of the system is a set of trips, which represent a path of a single vehicle to deliver one or multiple orders from a depot. Connecting two trips, which is called chaining, has the benefit of reducing the number of vehicles used, as chained trips are served by a single vehicle. Additionally, from multiple available depots where orders can be picked up, the method determines the best depot per order. This part of the method is called depot re-assignment. Furthermore, the fleet design problem is modelled as a multi-objective optimisation problem to find the trade-off between fleet size and the total distance the vehicles travel. Three different modelled datasets, each containing 10.000 order requests in the city centre of Amsterdam, are used to prove the value of the given method. A comparison between the method with and without depot re-assignment is made, to prove the value of the given addition of depot re-assignment. It is proven that depot re-assignment is valuable as it decreases or retains the fleet size for all test cases. The experiments conducted show that a significant decrease of the required fleet size can be established by a minor increase in total travelled distance. Furthermore, the optimal trade-off between the fleet size and the total distance travelled can be determined for a specific operation with the knowledge of operational costs for that operation.","Fleet; On-demand logistics; Multi-depot VRP; Same day delivery; Flash deliveries; Dynamic Vehicle Routing Problem; Pre-empty depot returns; Grocery delivery","en","master thesis","","","","","","","","2023-12-15","","","","Mechanical Engineering | Vehicle Engineering | Cognitive Robotics","",""
"uuid:ce98c4e3-6ca1-4966-a5cf-2120f2fa44bf","http://resolver.tudelft.nl/uuid:ce98c4e3-6ca1-4966-a5cf-2120f2fa44bf","Identifying high Alpine geomorphological processes using permanent laser scanning time series","Frantzen, Paco (TU Delft Civil Engineering & Geosciences)","Lindenbergh, R.C. (mentor); Rutzinger, M. (graduation committee); Kuschnerus, M. (graduation committee); Voordendag, A. (graduation committee); Wouters, B. (graduation committee); Delft University of Technology (degree granting institution)","2022","Global climate change affects mountain regions such as the European Alps. Consequently, glacier extents decrease, and proglacial areas, the areas that recently lost their ice cover, increase in size. These proglacial areas are subject to a high frequency and magnitude of geomorphological activity and act as a sediment source for downstream fluvial systems, extending the influence of their activity beyond proglacial margins. Therefore, a good understanding of the geomorphological activity in these regions is important and subject to numerous studies. Challenges to access Alpine proglacial areas complicate collection of data with high spatial and temporal coverage. A permanently installed terrestrial laser scanner (TLS) overlooking the Hintereisferner glacier in the Ötztaler Alps (Austria) provides daily ranging observations of a proglacial area. The aim of this study is to assess the potential of this permanent laser scanning system for identifying geomorphological processes in proglacial areas. Point clouds of this TLS system were rasterised into range images. An automated registration method is developed to ensure alignment of large quantities of range images in the event of scanner movement. Scans of the 2020 and 2022 summer were combined into two 4D spatiotemporal datasets, allowing analysis of range change time series for each raster cell. A principal component analysis (PCA) of the 4D spatiotemporal datasets is used to explore spatial and temporal patterns of change in the observed proglacial area. The range image registration procedure performed slightly worse than conventional registration methods, but allowed for automated registration of large quantities of scans. Based on the patterns found in the PCA, as well as in the range time series and precipitation data, different geomorphological processes are identified in the observed proglacial area at daily time scales, with magnitudes of several meters. Among these processes are debris flows in gullies, and slumps on lateral moraines. These results demonstrate that characteristic patterns of topographical change can be distinguished using PCA, and PCA is a promising method to be used in other studies exploiting 4D spatiotemporal datasets. The identification of different geomorphological processes indicates that the permanent TLS system could be of use for further research on geomorphological activity in proglacial areas, such as reworking of lateral moraines, while the developed methodology could be used in other studies exploring 4D spatiotemporal datasets as well.","permanent laser scanning; LiDAR; geomorphological processes; range image; registration; principal component analysis; terrestrial laser scanning; Hintereisferner; paraglacial","en","master thesis","","","","","","","","","","","","Geoscience and Remote Sensing","","46.8088, 10.773"
"uuid:f2424334-caeb-410e-a3d6-4ed642288fa7","http://resolver.tudelft.nl/uuid:f2424334-caeb-410e-a3d6-4ed642288fa7","Surrogate Model Based Diagnostics for the GEnx-1B Turbofan Engine","de Bruin, Bram (TU Delft Aerospace Engineering)","Colonna, Piero (mentor); Visser, W.P.J. (mentor); Roling, P.C. (graduation committee); Rootliep, T. O. (graduation committee); Delft University of Technology (degree granting institution)","2022","Over the years, aero engines have evolved into the efficient turbofans present on commercial airliners today. Although these engines are very reliable, they still experience degradations in performance and reductions in component health. The degradation affects the operation of the engine, which can be measured using the pressure, temperature, and rotational speed sensors. Using accurate engine models together with engine sensor measurements, the condition of individual components can be determined. Surrogate models of a non-linear Gas Path Analysis model have been developed for the GEnx-1B turbofan in the form of High Dimensional Model Representations. It is determined that the surrogate models developed are able to determine component conditions with a high accuracy and low computational complexity. The models are able to properly identify the effects of water-washes and turbine failures when applied to real-world on-wing data. Due to the low computational complexity of the models, they provide the possibility for fleet-wide continuous engine diagnostics.","Surrogate Model; Turbofan; GEnx-1B; Engine Modelling; Engine Diagnostics; Condition Based Maintenance; HDMR","en","master thesis","","","","","","","","2027-12-15","","","","Aerospace Engineering","",""
"uuid:108f1838-20bc-4af4-90d0-6d473120633a","http://resolver.tudelft.nl/uuid:108f1838-20bc-4af4-90d0-6d473120633a","Forecasting Mortgage Prepayments in Changing Interest Rate Regimes: A Hybrid Economic-Engineering Model with EMPC","Krabbenborg, Britt (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Delft Center for Systems and Control)","Mendel, M.B. (mentor); Mazo, M. (graduation committee); Hutters, C. (graduation committee); van Zwol, Pieter (graduation committee); Delft University of Technology (degree granting institution)","2022","Banks such as Rabobank depend on multi-year mortgage prepayment forecasts in order to make provisions for the associated prepayment risks. The econometric models they use are fitted to historical data, and as a consequence their models are fitted to a decreasing interest rate regime. Given the current economic climate of increasing interest rates, Rabobank has ascertained that their models are underperforming. They expressed the need for an alternative modeling approach that performs better in changing interest rate regimes.<br/><br/>This thesis takes a systems and control approach motivated by this need. We split the development into two parts; a dynamical system for modeling mortgage payments and prepayments, and a controller for simulating mortgagor behavior.<br/><br/>We model the dynamical system by following the principles of economic engineering. Economic engineering is based on the method of analogs, and we develop specific analogies applicable to the mortgage market. We first derive a continuous model describing the mortgage payment and partial prepayment dynamics. This model is then extended towards a hybrid model to include the dynamics of full prepayment. The parameters of this economic engineering model can be identified with historical data and are relatively constant. The resulting model is not affected by the variation of interest rates and performs well in any interest rate regime.<br/><br/>We design an Economic Model Predictive Controller (EMPC) to simulate mortgagor behavior that minimizes an objective function of its costs. This controller minimizes an economic objective which is needed to simulate the behavior of mortgagors in changing interest rate regimes. For different interest rate scenarios, we forecast prepayments with the model by simulating this minimizing behavior. We perform simulations for different kinds of mortgagors by varying the model parameters and the objective function. Based on these simulations, we describe for each mortgagor both the exact cause and dynamics behind the mortgage prepayments supplied.","Interest rates; Hybrid modeling; Economic model predictive control; Forecasting; Mortgage prepayments","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:4e649218-ac7b-4f78-b57e-5d1e4ed4fbcd","http://resolver.tudelft.nl/uuid:4e649218-ac7b-4f78-b57e-5d1e4ed4fbcd","Analysing visual biases in coral imagery for bleaching detection","Vlekke, Jimmy (TU Delft Electrical Engineering, Mathematics and Computer Science)","Reinders, M.J.T. (mentor); Pintea, S. (graduation committee); Delft University of Technology (degree granting institution)","2022","Global warming causes coral bleaching which threatens the health and existence of coral reefs and therefore also the future of a lot of species, including human beings. Efforts to automate coral reef monitoring using annotated coral images to detect coral bleaching are hindered by the lack of a complete dataset that specifies the health and bleaching status of corals. We propose to combine publicly available data into a dataset and train a CNN for coral bleaching detection. This model performs surprisingly well. However, combining data from different sources gives rise to dataset biases which helps classifiers perform better and make them unreliable for unseen data. We try to detect such biases and document themsing several bias detection methods.","Bias Detection; Dataset bias; coral bleaching; Coral bleaching detection; CNN; Deep Learning","en","master thesis","","","","","","","","","","","","","",""
"uuid:d2a8d675-2c8e-4db5-b935-fb81569a990b","http://resolver.tudelft.nl/uuid:d2a8d675-2c8e-4db5-b935-fb81569a990b","Performance Assessment of Industrial-scale n-Caproate Production utilizing CO2 as Feedstock: A comparitive study between different n-caproate production pathways at the Port of Rotterdam","Nieuwesteeg, Arlette (TU Delft Applied Sciences; TU Delft Technology, Policy and Management)","Ramirez, Andrea (mentor); Lieu, J. (graduation committee); Virla Alvarado, L.D. (graduation committee); Luo, J. (graduation committee); Delft University of Technology (degree granting institution)","2022","The Port of Rotterdam is one of the largest CO2 emitters of the Netherlands. One method to reduce its emissions is by implementing carbon capture and utilization (CCU) technologies. In this research two different CCU routes for industrial-scale n-caproate production are compared. The first route utilizes microbial electrosynthesis (direct route). The second route uses syngas formation via electro-reduction combined with syngas fermentation (indirect route). <br/><br/>Based on the European Union's technology readiness level, the maturity of both routes is ranked as 3 to 4. This indicates that both routes are in the demonstration phase. In this phase scientists play an important role, as the focus is on researching the technology's overall feasibility. It is also the phase in which financial barriers are the most pressing. Early-stage investors can help overcome these barriers, by allocating (financial) resources. Nonetheless, an assessment method taking both scientists' as well as early-stage investors' perspectives into account is missing. This research contributes to filling this knowledge gap.<br/><br/>The methodology applied is bricolage, using a mixture of literature research, simulation data and interviews. Data of the direct route is retrieved from literature research. To obtain data of the indirect route, a simulation is made in Aspen Plus v12. An overview of important assessment parameters are acquired via the conducted interviews. <br/><br/>In total 15 participants are interviewed, of which; 8 scientists working on CCU technologies, 5 early-stage investors, 1 governmental policy executing party and 1 NGO. These interviews, combined with metrics found in literature research, led to an overview of parameters to be assessed for a performance analysis. <br/><br/>Overall, 10 metrics are selected and used for the performance assessment. These include technical, economic, environmental and strategic metrics. The technical assessment showed that the indirect route has a significantly higher energy consumption compared to the direct route (0.35 GJ/kg caproate compared to 0.1 GJ/kg caproate). However, the indirect route has a higher production selectivity towards n-caproate. The economic performance assessment resulted in a lower CAPEX and OPEX for the direct route. Still, for both routes, the minimum n-caproate selling price is below the current n-caproate market price. The net carbon footprint of the indirect route is 7.3 kg CO2 per kg caproate, indicating that a significant amount of CO2 is being emitted during its production. <br/><br/>While an analysis at this maturity stage of the production routes comes with uncertainties, it gives a first sound indication of its performance and bottlenecks. For the indirect route, the energy consumption is dominated by the two electrolyzers used and the downstream processing. This energy consumption is also the main contributor to the OPEX (47%) and the carbon footprint (79%). Another factor largely responsible for the carbon footprint are the emissions during fermentation (19%). The main cost item of the equipment cost is the water alkaline electrolyzer (42% of total cost). <br/><br/>To conclude, the indirect route shows the potential of industrial-scale n-caproate production with a high selectivity. Nonetheless, it is key to reduce its energy consumption and implement more efficient off-gas recycling to improve its techno-economic and environmental performance.","","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:ece9a3bc-be4e-4163-91cb-0d6419d3500a","http://resolver.tudelft.nl/uuid:ece9a3bc-be4e-4163-91cb-0d6419d3500a","Influence of Initial Mesh Topology on the Optimal Structural Design of Steel Space Frame Structures","Salitrežić, Juraj (TU Delft Civil Engineering & Geosciences)","Schipper, H.R. (mentor); Popescu, M.A. (graduation committee); Kavoura, Dr. Florentia (graduation committee); Hoogenboom, P.C.J. (graduation committee); Delft University of Technology (degree granting institution)","2022","Space frame structures today are a common choice of load bearing system for achieving long spans with minimal interruptions of the floor plan beneath. On top of that, the versatility of space frame structures to conform to any shape makes them particularly interesting today, especially in the context of free-form geometry which is becoming ever more common. In structural design, and especially for space frame design, the creation of a structural model is quite a labour-intensive process, and it is highly beneficial to automate the structural model generation. Furthermore, the design of such structures can benefit from an exhaustive preliminary design space investigation. Thus, this MSc thesis deals with the parametric design, engineering and optimization of space frame structure typologies based on different initial surface discretization of the input free-form surface geometry, and different topological relations of space frame top and bottom layers. These topological relations are based on Conway operators most relevant for the structural patterns occurring in space frame structures specifically, dual, kis and ambo. These operators are always applied on an initial or seed meshing of the desired free-form surface, to create different space frame layouts for them to be compared by their structural performance, primarily in terms of mass. The scope of initial meshing options is kept to tri, quad, and skeleton-based quad meshing. These three different types of mesh options, combined with the three possible Conway operator options, constitute the main nine combinations for each case study example.<br/>In essence, every space frame design, due to the linear and geometric nature of the structural elements (nodes and bars seen as points and lines), can be considered as a literal structural translation of the final desired free-form shape. This free-form shape is always tessellated or discretized in certain configurations. The aim was to gain more insight into how the initial tessellation affects the behaviour of space frame structures as well as how the process of optimization of such structures is influenced regarding the initial tessellation. To gain insight into this influence qualitatively and quantitatively a parametric tool was developed to conduct case studies. The tool allows for the generation and cross-section optimization of various space frame structures based on an input surface. This parametric tool was developed using Rhino, Grasshopper, and karamba3D structural analysis plugins for grasshopper.<br","Parametric Design; Space Frame; Optimization; Conway Operators; Mesh topology; Topological skeleton","en","master thesis","","","","","","","","","","","","Civil Engineering | Building Engineering","",""
"uuid:b0022e82-0e47-477b-87da-e7e4fbe40639","http://resolver.tudelft.nl/uuid:b0022e82-0e47-477b-87da-e7e4fbe40639","3-D Target Classification in Short Range Radar Applications","Arun Vijayaraghavan, Arun (TU Delft Electrical Engineering, Mathematics and Computer Science)","Yarovoy, Alexander (mentor); Uysal, Faruk (graduation committee); Heusdens, R. (graduation committee); Koppelaar, Arie (graduation committee); Delft University of Technology (degree granting institution)","2022","Over the years in the automotive industry, the use of radar sensors in advanced driver assistant systems (ADAS) has been increasing, shining a light on various safety and security concerns to be dealt, that come along with it. The performances of existing sensor technologies such as camera, LIDAR and GPS can be very well complemented by the use of millimeter-wave radar due to its robust performance in various conditions. In assisted or autonomous driving tasks, localization of targets and their height information is important to be determined. Since height information is lacking from automotive radar systems without elevation measurements capabilities, this remains a challenge to be worked on. In the application discussed in this thesis, using the radar specifications providing a high range and velocity resolution, the multi-paths can be resolved in the range-Doppler domain and be used for height estimation techniques. The automotive applications for which short and ultra-short range radar systems are used, require a high range and velocity resolution. In this thesis, a low complexity and fast target height classification algorithm is presented using a FMCW radar.<br/><br/>In the process of having a quick response automotive radar system, low latency DoA estimation technique was employed. To estimate the height properly, knowledge of the ego-velocity is needed. A histogram method can be used to roughly estimate the ego-velocity. The ego-velocity estimate can be refined using an Extended Kalman filter that tracks targets that are supposed to be annotated with height information. Using the vertical doppler beam sharpening technique, the improved ego-motion estimate helps in estimating the elevation angles of the targets and therefore, their corresponding height. An overview of the height estimation process is explained to provide a real time mapping of the target in 3-Dimensions, showcasing the improvement in ego-motion estimation leading to an elevation angle estimation. Simulations and experiments are carried out to validate and verify the algorithm. The results show promising results and also reveal potential improvements and the need for more simulations and experiments to mature the concept further.","DBS; FMCW Automotive Radar; Height Classification; Tracking; MIMO radar; Ego Motion; DOA","en","master thesis","","","","","","","","","","","","Electrical Engineering | Signals and Systems","",""
"uuid:abf7b54e-f4bb-4e16-9fea-14fb368624f5","http://resolver.tudelft.nl/uuid:abf7b54e-f4bb-4e16-9fea-14fb368624f5","Redesign of the Centring Unit in the Wafer Handler","de Sonnaville, Rudolf (TU Delft Mechanical, Maritime and Materials Engineering)","Herder, J.L. (mentor); Delft University of Technology (degree granting institution)","2022","Background<br/>One of VDL most complex products is the Wafer Handler a machine with the function of thermal conditioning, centering and aligning wafers for the subsequent photolithography processes. The function of centering a wafer is performed by a submodule of the WH, the Centring Unit (cu) Currently the CU has two main limitations which make it unfit for the next generation WH, it is dependent on the subfunction of an otherwise redundant module, and its performance it not optimal. The goal of the research is to develop a future-proof solution for the CU, which is compatible with the next generation WH. The specific objectives of the research are threefold: 1) to develop and identify innovative concept directions for the CU which address its current issues and provide better overall performance, 2) to select the most promising concept for detailed development and 3) to prove the feasibility of the most promising concept.<br/>Method<br/>First the origin of the problem of the CU was analysed to identify the functional requirements and design criteria for concept development. Subsequently, a long list of concept directions was developed and a selection was made to identify the best concept to perform the function of the CU. This concept was experimentally validated to demonstrate the feasibility of the selected concept. <br/>Results<br/>The concept design and selection phases resulted in the development of 6 acceptable concepts of which two concepts were selected for further development. Of these two concepts, the Photo Measurement System was selected as the best concept to perform the function of the CU. The PMS is a measurement system that measures the position error of a wafer when it enters the WH, this enables the subsequent modules to correct the position error. The feasibility of the PMS has been proven via experimental validation, as the measurement uncertainty (38.1 µm) falls within the defined requirement for uncertainty (functional requirement of the position measurement is 55µm).<br/>Conclusion<br/>In this study an innovative concept has been developed to perform the function of CU in next generation WH. The PMS allows the subsequent module to the CU to correct the position error of an incoming wafer, making the current CU redundant. This research allows for future-proof centering in the next generation WH.<br","VDL ETG; Centring Unit; Position module; Measurement system; Computer Vision; Concept Development; Design","en","master thesis","","","","","","","","","","","","","",""
"uuid:d3da32cb-1ee4-40c7-a9fb-c46d2dec0528","http://resolver.tudelft.nl/uuid:d3da32cb-1ee4-40c7-a9fb-c46d2dec0528","Multiple Markov properties for fractional parabolic SPDEs","Titulaer, Björn (TU Delft Electrical Engineering, Mathematics and Computer Science)","Kirchner, K. (mentor); van Neerven, J.M.A.M. (graduation committee); Kraaij, R.C. (graduation committee); Delft University of Technology (degree granting institution)","2022","Spatiotemporal stochastic processes have applications in various fields, but they can be difficult to numerically approximate in a reasonable time, in particular, in the context of statistical inference for large datasets. <br/>Recently, a new approach for efficient spatiotemporal statistical modeling has been proposed, where the space-time stochastic processes are constructed as solutions to a certain class of fractional-order parabolic stochastic partial differential equations. Until now, the solution concepts, that have been formulated for these stochastic equations, either assume zero initial conditions for the process itself and (if existent) for all of its (mean-square temporal) derivatives, or set all (existing) higher-order derivatives at the starting time to zero. The aim of this thesis is twofold: Firstly, we generalize this class of stochastic processes in such a way that non-zero initial conditions (for the process and its temporal derivatives) can be meaningfully incorporated. Secondly, we show that for certain (integer) values of the parameter corresponding to the fractional power of the parabolic operator, the solutions satisfy certain Markov properties. <br/>To this end, we first generalize the integration domain of stochastic Hilbert-space-valued Itô integrals to the whole real line. Afterwards, we present the modified spatiotemporal stochastic processes that facilitate incorporating nonzero initial conditions for the process and its derivatives at a given initial time. Lastly, we show that this proposed process satisfies a so-called multiple Markov property under certain conditions. Markov properties are desirable in numerical applications, because a Markov process allows for a much faster numerical approximation of its covariance operator. <br","Stochastic partial differential equations; Multiple Markov; Semigroups; Sobolev space; Bochner space; Spatiotemporal statistics","en","master thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:bff2c00f-3a78-440b-a419-e202edb68dfd","http://resolver.tudelft.nl/uuid:bff2c00f-3a78-440b-a419-e202edb68dfd","Recovery of magnesium from RO concentrate for struvite production","Mehta, Divvay (TU Delft Civil Engineering & Geosciences; TU Delft Water Management; TU Delft Sanitary Engineering)","van der Hoek, J.P. (mentor); Heijman, Sebastiaan (graduation committee); Lindeboom, R.E.F. (graduation committee); Tee, Synco (graduation committee); Delft University of Technology (degree granting institution)","2022","Magnesium is one of the most critical natural resources and 96% of magnesium used in Europe is imported. The present study investigated possible ways of implementing circularity in the magnesium cycle within the borders of Waternet, a water utility in the Netherlands. The wastewater treatment plant at Amsterdam-West produces struvite from anaerobic digestate. The production of struvite requires 4400 tons of 32% MgCl2 annually. At the same time, a reverse osmosis (R.O.) process treating brackish groundwater for drinking water production produces a concentrate rich in magnesium ions. This R.O. concentrate, after being treated by aeration and filtration to remove iron and ammonium, is considered for use in the wastewater struvite recovery process. Technologies for recovering magnesium from this R.O. concentrate were investigated in this study. After analyzing the constraints of the magnesium dosing system, the struvite reactor, and the R.O. concentrate composition, two technologies were selected for the study of Mg2+ recovery: Nano-filtration (N.F.) and Ion exchange. The present study investigated both these processes via software simulations and laboratory experiments. The study revealed that while the N.F. process is not viable, the cation exchange using a weak chelating resin AmberLite IRC747 in Na+ form (regeneration with H2SO4 and NaOH) is possible when the resin is saturated with divalent cations. The regenerant stream (produced via acid regeneration) is a sodium-free stream having gypsum precipitates. After gypsum separation, the process created an Mg2+ dose with a concentration of 4.45 g/l. This study developed a 1 step process for extracting Mg2+ from RO concentrate.","Magnesium; Struvite; Resource recovery; RO concentrate; Ion Exchange","en","master thesis","","","","","","","","","","","","Civil Engineering | Environmental Engineering","",""
"uuid:e944ddac-51ae-4575-80b1-21da6088ddae","http://resolver.tudelft.nl/uuid:e944ddac-51ae-4575-80b1-21da6088ddae","Exploring governance mechanisms for inter-organizational collaboration in Dutch infrastructure programmes","Gomez Chica, Tatiana (TU Delft Civil Engineering & Geosciences)","Molaei, M. (mentor); Straub, A. (graduation committee); Houwing, E.J. (graduation committee); Delft University of Technology (degree granting institution)","2022","Programmes in the Dutch infrastructure sector can contribute to overcoming the industry’s lagging performance and the increasing amount of renovation of work it is currently facing. Additionally, they have the potential to integrate the fragmented supply chain while facilitating better coordination of the projects being executed more effectively and efficiently. However, they also introduce chaos to the collaboration that can be detrimental effect on the programme’s outcome. Although there is extensive literature on inter-organizational collaboration in projects, little attention has been paid to the programme context. It is still unknown how governance should be organized to facilitate inter-organisational collaboration in programmes Therefore, this study responds to the call for research. Two Dutch infrastructure programmes were studied to understand the governance approach used and how it facilitated inter-organizational collaboration. The results from the case studies showed that inter-organizational collaboration in the early phases of infrastructure programmes is facilitated by an interplay of relational and contractual mechanisms corresponding to the six dimensions of governance: goal-setting, capability building, rewarding, roles &amp; decision-making, coordination and monitoring. This governance mechanisms are established by the programme level and the contracting authorities’. They intend to provide a framework for organizational processes, decision-making, and coordination in the programme, while integrating the different levels of the programme. Additionally, this research provides a model that aims to provide a structural way to organize future programme governance while allowing public clients to analyze their choices better","programme management; inter-organizational collaboration; governance; Infrastructure","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:284ba1d4-2196-4ed7-84b7-d02c6a5d06ab","http://resolver.tudelft.nl/uuid:284ba1d4-2196-4ed7-84b7-d02c6a5d06ab","Sampling-Based MPC with Learning-Based Trajectory Predictions for Interaction-Aware Motion Planning: Autonomous navigation in urban canals","Jansma, Walter (TU Delft Mechanical, Maritime and Materials Engineering)","Trevisan, E. (mentor); Serra Gomez, A. (mentor); Alonso Mora, J. (mentor); Delft University of Technology (degree granting institution)","2022","With the world’s population recently surpassing the 8 billion mark, population growth poses significant challenges on the planet. This growth is particularly evident in urban areas, and as a consequence, cities must find innovative ways to accommodate the increasing pressure on the current road infrastructure. In Amsterdam, a city with an extensive network of urban canals, Autonomous Surface Vessels (ASV) could play an important role in alleviating the pressure on the road by transporting goods and people through the canals. However, autonomous navigation in narrow and unstructured canals amongst human-operated vessels is still a great challenge. Recently, a sampling-based Interaction-Aware Model Predictive Path Integral (IA-MPPI) control framework was proposed for this purpose. The method pro- vides trajectories for all agents in a local multi-agent system based on their current state and estimated local goals. This thesis builds upon this framework by integrating a learning-based trajectory prediction model to provide better estimates of the local goals of interacting agents. We adapt a state-of-the-art trajectory prediction model and train it on simulated vessel data to predict vessel trajectories. We then provide heuristics to extract local goals from these predictions and integrate them into the IA-MPPI framework. With extensive experiments in simulated environments of Amsterdam’s canals, we show that our proposed method outperforms the baseline in high-interaction scenarios and achieves similar performance to the method with communication capabilities. Furthermore, we provide insights into the benefits of interaction-aware planning over planning with fixed trajectory predictions for other agents’ motion. In additional experiments, we provide heuristics to use the trajectory predictions to improve the sampling distribution of the IA-MPPI. Preliminary results of this method provide insights into the potential benefits of this approach and we suggest directions for future research in this area.","Trajectory Prediction; Motion Planning; Multi-agent systems; Deep Learning; Model Predictive Path Integral Control","en","master thesis","","","","","","","","","","","","","",""
"uuid:c55ee599-238c-40a6-a0be-33fca35f9c51","http://resolver.tudelft.nl/uuid:c55ee599-238c-40a6-a0be-33fca35f9c51","Brand identity of business-to-business start-ups and its association with brand relevance: Graduation project MSc Management of Technology","van der Zalm, Anne-Lokke (TU Delft Technology, Policy and Management)","Dolkens, T.L. (mentor); Scholten, V.E. (graduation committee); Rook, L. (graduation committee); Delft University of Technology (degree granting institution)","2022","One of the biggest challenges start-ups encounter is establishing themselves within the market. A widely recognized contributing factor to increasing chances of outrunning competition, is the implementation of a branding strategy with the purpose of creating a strong brand identity. Whether investing in developing a brand identity is profitable, depends on the brand relevance of a company. Brand relevance is the level of the overall role of brands in customers’ decision-making. Business-to-business start-ups have access to limited resources, hence it is important to them to only invest in creating a brand identity, when their level of brand relevance shows that this would be profitable.<br/><br/>The current exploratory research combined a desk research and a qualitative panel study to gain insight into the presence of an association between the two, as well as which factors are considerd to be of influence to the perceived brand identity.<br/>Using a desk research, the level of brand relevance for a total of 30 start-ups related to the Delft Technical University was determined. Next, a focus group was hosted to gain insight into which factors are considered to be important to the perceived brand identity of B2B start-ups. Four overarching aspects were indicated: brand personality, corporate visual identity, clarity of the product/service and its relevance, and clarity of the competitive advantage. Furthermore, the current research aimed to investigate whether an association between the level of brand relevance of B2B technology-based start-ups and perceived brand identity was present. The results of the focus group were used to test whether this association was present. In the scope of this research however, no association was found.<br/><br/>The research provides start-up entrepreneurs with hands-on tips on which factors influence their perceived brand identity which makes it managerial relevant. The academical relevance can mainly be found in recommendation for future research, since this should show whether the absence of an indicated association between brand relevance and brand identity, can be explained by the absence of awareness among B2B technology-based start-ups.","Brand identity; Start-up branding; Business-to-Business; Brand relevance","en","master thesis","","","","","","","","","","","","Management of Technology (MoT)","",""
"uuid:f6bf1b27-322b-4f2c-9d15-d96604a2e946","http://resolver.tudelft.nl/uuid:f6bf1b27-322b-4f2c-9d15-d96604a2e946","Robustness of Modular Timber Buildings: An investigation into alternative load paths in volumetric timber post and beam modules","Knuppe, Joep (TU Delft Civil Engineering & Geosciences; Pieters Bouwtechniek)","Ravenshorst, G.J.P. (mentor); Messali, F. (graduation committee); Felicita, M.P. (graduation committee); Bosveld, C. (graduation committee); Delft University of Technology (degree granting institution)","2022","Increasing housing demand in Europe and the need to be more sustainable are asking the construction industry to leave the traditional pathways and innovate. An emerging construction method with volumetric timber modules potentially offers the solution. However little is known about the robustness of this new innovation. Therefore, this thesis aims to advance the current research regarding collapse resistance in volumetric modular timber buildings. To achieve that goal, first, in this thesis, a literature study into robustness and modular buildings was performed. The study identified the importance of redundancy, proper connection design, ductility, and tying in modular structures for robustness. Secondly a case study was performed. The case study provided the structural design concept of a newly developed volumetric timber post and beam module by Lister Buildings, structurally designed by Pieters Bouwtechniek. The modules consist of glued laminated beams and columns with cross-laminated floor and ceiling slabs. With the modules, a hypothetical residential building of 5 storeys was created, which consecutively was decomposed into equivalent two-dimensional frame structures suited for 2D finite element analysis. To account for the mechanical behaviour of the connections in the models, nonlinear springs were used. To establish the springs, the component method was adopted. The spring behaviour was determined from the elastic, plastic and failure performance of the individual components of a connection in translational and rotational degrees of freedom. Then based on a notional element removal concept, multiple possible loss events of load bearing elements were analysed in the finite element software of Abaqus to examine the existence and development of alternative load paths. To do that, both nonlinear static and nonlinear dynamic analyses were performed. The results of this study indicate that the new design concept performs quite well on robustness. Several alternative load paths were identified, among which cantilever action, bridging action, and catenary action, depending on the removal event and scenario. In addition this thesis investigated the dynamic amplification factor (DAF) of the modular system. The results of this research imply that for alternative load path analysis of timber structures, a DAF of 2.0 should be applied in a (non)linear static analysis. More research will be necessary to examine whether a lower value than 2.0 can be used.","Robustness; Finite Element Analysis; Dynamic Amplification Factor; Timber; Modular Construction; Nonlinear Analyses","en","master thesis","","","","","","","","","","","","Civil Engineering | Building Engineering","",""
"uuid:f63ece3a-02b9-46df-b4bf-27f8c65bef7d","http://resolver.tudelft.nl/uuid:f63ece3a-02b9-46df-b4bf-27f8c65bef7d","Level localisation for lumbar surgery using ultrasound","Sluijter, Judith (TU Delft Mechanical, Maritime and Materials Engineering)","van Walsum, Theo (mentor); Leenstra, Sieger (mentor); Delft University of Technology (degree granting institution); Erasmus Universiteit Rotterdam (degree granting institution); Universiteit Leiden (degree granting institution)","2022","Wrong-level spine surgery (WLS) is a medical error with severe consequences for the patient and medical staff. The current golden standard to prevent WLS during spinal surgery is fluoroscopy images acquired by a C-arm. However, this approach uses ionising radiation and interrupts the standard surgical workflow. To overcome these disadvantages, ultrasound-based navigation may provide an alternative to prevent WLS during spinal surgery. Baka et al. developed the Lumbar Localiser for ultrasound-based level localisation; however, this has not yet been applied in clinical practice. This project aims to improve and evaluate this level localisation approach in clinical practice. <br/>Chapter 1 highlights the social relevance of ultrasound-based level localisation. Chapter 2 shows in a literature review that navigated ultrasound-based guidance is not yet implemented in clinical practice. Identified recommendations for further research were optimising ease of use, workflow integration, registration accuracy and computation time. Chapter 3 describes a prospective multi-centre study (n=34) which evaluated the accuracy of the level localisation approach and the added value of intraoperative ultrasound acquisition. The accuracy of the improved level localisation approach was too low (53%) to recommend implementation in clinical practice. We showed that pre- and intraoperative ultrasound acquisitions could be integrated efficiently into the operation room (OR) workflow, with clinically negligible time differences compared to the current approach for level localisation. Intraoperative ultrasound acquisition added valuable information, enabling a re-check of the level localisation without the attenuating subcutaneous fat layer between the SP and ultrasound transducer. Chapter 4 describes the development of an automated contour segmentation approach based on magnetic resonance imaging (MRI) using deep learning. A nnU-Net was trained to segment the lumbar spinous process automatically. Subsequently, the posterior contours were extracted based on these segmentations and imported into the Lumbar Localiser. The automatic contours showed a successful matching in all 16 test cases. Chapter 5 provides an overall conclusion and discussion.<br/>In this master’s thesis, the technical aspects and clinical workflow of the Lumbar Localiser were improved to get closer to the clinical application of ultrasound-based level localisation for lumbar surgery. Implemented improvements include adding intraoperative ultrasound acquisition, extension to MRI as a preoperative modality and automatisation of the contour annotation. In conclusion, this approach cannot be applied yet in clinical practice, as an accuracy of around 100% should be achieved to minimise the risk of WLS and thereby prevent irreversible damage to the patient.","Image-guided surgery; Ultrasound; Lumbar surgery; Medical segmentation; nnU-Net","en","master thesis","","","","","","","","","","","","Technical Medicine | Imaging and Intervention","",""
"uuid:6aa1208d-4bd9-4580-86ec-871849bc95d4","http://resolver.tudelft.nl/uuid:6aa1208d-4bd9-4580-86ec-871849bc95d4","Predicting the stability of distal radius fractures with a small dataset and machine learning","Wilbers, Julia (TU Delft Mechanical, Maritime and Materials Engineering)","Vos, F.M. (mentor); Su, Ruisheng (mentor); van Walsum, Theo (mentor); Benmahdjoub, Mohamed (mentor); Cohan, Abi (mentor); Colaris, Joost (mentor); Delft University of Technology (degree granting institution)","2022","Purpose. Distal radius fractures are common fractures of the wrist. These fractures are often displaced and need reduction, after adequate reduction, the patients will have follow-up X-rays to check if the fracture stays stable. This is important because surgery might be required if the fracture becomes unstable. This can lead to delayed surgery which can worsen the treatment outcome.<br/>Therefore, it would be valuable to predict which distal radius fractures are likely to become unstable. Machine learning could help predict the stability of distal radius fractures based on CT. In addition, because there is only a small dataset available, this research also studies the effect of different machine learning methods.<br/>Method. Two different methods were evaluated for the stability prediction of distal radius fractures: traditional machine learning (radiomics method) and a residual network with and without transfer learning (deep learning method). For the radiomics method, a python package called WORC was used, which automatically extracts radiomic features and optimizes machine learning models. For the deep learning method, the backbone of a residual network called Med3D with added layers for classification was used.<br/>Results. The radiomics method combined with augmentation, gave the best results (AUC: 0.64± 0.01). Also, it was found that using an augmented data set in the radiomics method resulted in improved performance. This gives a slight indication that the radiomic method can learn to predict DRF when there would be more data available.<br/>Conclusion. The radiomic method is the most promising method for predicting the stability of distal radius fractures, despite the small difference in performance compared to random guessing and the deep learning method. However, for further research, it is highly recommended to acquire a larger dataset.","Distal radius fracture; Prediction; Machine Learning; Small dataset","en","master thesis","","","","","","","","","","","","Biomedical Engineering | Medical Physics","",""
"uuid:5388bc28-01ea-4692-b977-7298d33037d4","http://resolver.tudelft.nl/uuid:5388bc28-01ea-4692-b977-7298d33037d4","Deformation of structures upon impact with a liquid free surface","Hendriksen, Elon (TU Delft Mechanical, Maritime and Materials Engineering)","Wellens, P.R. (mentor); van der Eijk, M. (graduation committee); Delft University of Technology (degree granting institution)","2022","This thesis study is intended to research the effects on peak pressure during impact of a deformable structure with a liquid. To find an answer to this question, a novel wedge was designed to perform free fall wedge experiments at the TU Delft. This report describes the progress that lead to answering the research question:<br/><br/>What is the effect of dynamic deformation of a structure on the maximum pressure at the wedge surface during impact?<br/><br/>To create an overview of the problem, the various systems and knowledge required to answer the research question are discussed. Among others, a decision on wedge deformation type is made, the importance of multiple impact velocities and the sensors required to measure data of the impact are discussed. The proposed concept to perform experiments is with a deformable wedge that is allowed to fold around the keel upon impact with the free surface. Hypothesis is that the deformation on impact could lead to initial lower impact pressure but dynamic response could lead to higher peak pressures at later stage of impact.<br/>In the next phase, estimations of impact pressures, forces and accelerations are used to finalize the design of the wedge. Strength calculations were performed on the critical parts of the wedge. It is concluded that the analysed parts are strong enough to withstand repeated loading of the structure. Also during this phase, an extra experiment into dynamic calibration of the accelerometer was performed. By curve fitting the expected acceleration to the experiment data, the error of the accelerometer is determined. The accelerometer used in this experiment has an error of 0.48% which is within the limits of the manufacturers requirement of ≤1%. Before the start of the experiments the limitations of the setup are discussed and an uncertainty analysis is performed on the sensors.<br/>The experiment consists of a series of free falls with various wedge setups, either rigid or deformable. A rigid setup of the wedge is tested at impact velocities of 2, 4 and 6m/s and deadrise angles of 10 and 20 degrees to create a base line for maximum impact pressures. The results of the rigid experiment are compared against previously tested rigid wedges. It is concluded that the novel wedge showed similar peak pressures compared to previously tested rigid wedges. The deformable wedge is dropped at all impact velocities and deadrise angles with three different springs, varying in stiffness.<br/>Deformation of the wedge during impact resulted in decrease in peak pressure. Decreasing spring stiffness and increasing impact velocity resulted in increasing deformation of the wedge. With these results the research question set in the first chapter of the report is answered.<br/>The answer to the research question is that impact induced deformation of the structure leads to lower peak pressures. Dynamic effects were observed but did not lead to higher pressure than the rigid experiments. While further research into the matter is required, this result may already lead to improved ship design which could lead to lower manufacturing costs and lower emissions.","Deformation; Pressure; Free-fall; Impact; Wedge","en","master thesis","","","","","","","","","","","","","","52.001228974037645, 4.37112953666495"
"uuid:0629aa76-948d-4ccc-b852-eb2a241306be","http://resolver.tudelft.nl/uuid:0629aa76-948d-4ccc-b852-eb2a241306be","Integration of the Battery Energy Storage System in a 450 kW EV Charger","Guan, Heshi (TU Delft Electrical Engineering, Mathematics and Computer Science)","Qin, Z. (mentor); Bauer, P. (graduation committee); Santbergen, R. (graduation committee); Delft University of Technology (degree granting institution)","2022","Despite the Covid-19 pandemic and supply chain challenges, including shortages of semiconductor chips, the electric vehicle (EV) market is expanding rapidly. Automobile manufacturers have been progressively developing business plans, considering electrification as an opportunity to acquire market share and preserve competitive advantages. The main barriers to EV adoption are high vehicle costs, range issues, and charging infrastructure. Installing a comprehensive EV fast charging network will help alleviate range and charging problems on long intercity drives. However, fast and ultra-fast charging directly from the grid will place a huge and unpredictable load on the power system. Therefore, energy storage systems (ESS) appear as a promising solution to prevent grid overload during charging and help reduce infrastructure costs.<br/><br/>In this dissertation, the integration of the battery energy storage system (BESS) in a 450 kW EV charger is designed and validated via modeling, simulation and experiment. For the front end of the DC fast charger, the 3-phase 3-level T-type converter is selected as the PFC converter linked to the grid for its superior performance, especially for applications with low voltage and medium switching frequencies. An appropriate modulation method based on space vector modulation (SVPWM) and closed loop control will be illuminated and simulated via PLECS. Based on the comparison of several types of state-of-the-art cylindrical 18650 batteries, the battery energy storage system is designed from thermal issues and integration impact on the DC bus. In order to explore the heat dissipation and the temperature distribution across the pack, the thermal model based on the sub-model technique is developed via COMSOL, and a preliminary layout and cooling strategy are determined. <br/><br/>Finally, the proposed structure of the EV charger integrated with the battery energy storage system is validated based on a 6 kW rated lab-scaled hardware test bench. In conjunction with the actual scenario, both the prospective steady states and transitions have been implemented. Hence, the feasibility of the concept of directly connecting the BESS to the DC bus is also verified by observing the response of the front-end AC/DC converter with the modulation and control strategies utilized.","Fast charging; 3-phase 3-level T-type converter; BESS; System integration","en","master thesis","","","","","","","","2023-12-14","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:e769562e-7ded-452e-828d-9a2046e2189c","http://resolver.tudelft.nl/uuid:e769562e-7ded-452e-828d-9a2046e2189c","Value-sensitive Evaluation of Hybrid Human-AI Chatbots in Customer Services","Lee, Quentin (TU Delft Electrical Engineering, Mathematics and Computer Science)","Yang, J. (mentor); Houben, G.J.P.M. (graduation committee); Lukina, A. (graduation committee); Lippmann, P. (mentor); Delft University of Technology (degree granting institution)","2022","The state-of-the-art shows the potential of chatbots and other Machine Learning (ML) models to perform many tasks of high quality. Especially chatbots are already used by many companies to assist their customer service. However, chatbots will likely never be able to perform all tasks perfectly. Therefore, it is still the question whether such a chatbot is valuable for a business. Current research fails to describe how chatbots should be evaluated to compute the value of a chatbot for a business. In this research, we design an evaluation framework capturing the value of a chatbot in customer service. This framework consists of several key dimensions which should be computed in order to determine the value of the chatbot. To show that this evaluation framework captures the value of a chatbot, we perform a case study on water utility companies in The Netherlands. This case study showed the designed evaluation framework does capture the value of a chatbot in customer service.","Chatbots for Customer Service; Value-sensitive Machine Learning; Chatbot Evaluation","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:6e7e611b-9a7a-4886-8eb8-f1a172516d99","http://resolver.tudelft.nl/uuid:6e7e611b-9a7a-4886-8eb8-f1a172516d99","The Flux Divergence Method Applied to Nitrogen Emissions in The Netherlands","Bryan, Lotte (TU Delft Electrical Engineering, Mathematics and Computer Science)","Heemink, A.W. (mentor); Eskes, H.J. (graduation committee); Budko, N.V. (graduation committee); Delft University of Technology (degree granting institution)","2022","Emission of ammonia and nitrogen oxides puts pressure on vulnerable ecosystems in The Netherlands. Satellite data from TROPOMI and CrIS gives vertical column density (VCD) maps for nitrogen dioxide and ammonia respectively. The Flux-Divergence method converts a VCD map to an emission map, by temporally averaging the divergence of the flux of the trace gas and estimating a sink term. This research proposes two improvements to the current implementation of the Flux-Divergence method at the KNMI for nitrogen dioxide. On the one hand, noise is reduced by computing the divergence before interpolating TROPOMI data to a regular grid. On the other hand, some emission locations are enhanced by reducing divergence in the wind field. An algorithm is provided to reduce this divergence. This thesis also explores the sensitivities of the method to different choices in its implementation. Finally, this research implements the Flux-Divergence method for ammonia. The thesis shows that, for ammonia, the method depends strongly on the estimation of the sink term, as the flux-divergence map is not able to capture homogeneous, spread-out emission sources.","Flux-Divergence method; Reactive Nitrogen Emissions; Satellite data processing; TROPOMI; CrIS","en","master thesis","","","","","","","","","","","","Electrical Engineering","",""
"uuid:940bb90b-183a-4e00-bd1c-aee2f455b3f9","http://resolver.tudelft.nl/uuid:940bb90b-183a-4e00-bd1c-aee2f455b3f9","Parametric analysis of a double shaft batch-type paddle mixer: A DEM study","Emmerink, Jeroen (TU Delft Mechanical, Maritime and Materials Engineering)","Hadi, A.H. (mentor); Jovanova, J. (mentor); Schott, D.L. (graduation committee); Delft University of Technology (degree granting institution)","2022","The Discrete Element Method (DEM) in combination with an One Factor At a Time (OFAT) experimental simulation plan were employed to investigate the effect of a selection of factors on the mixing performance of a double shaft, batch-type paddle mixer. Most influential factors on the mixing performance of the paddle mixer are desired for optimization purposes. Selected factors are the three material characteristics (particle size, particle density, composition), three operational conditions (initial filling pattern, fill level, impeller rotational speed) and three geometric characteristics (paddle size, paddle angle and paddle number). <br/><br/>A 175L paddle mixer is converted into a simulation model and the material model is adopted from literature. The material model comprises of free-flowing, perfectly spherical glass beads. The Hertz-Mindlin contact model is used to simulate the granular material. Furthermore, the simulation strategy consists of the filling process and mixing process. In the former, all input settings are specified. The latter process uses the filling process results to mix the 2-component mixture for a total real-time of 30 seconds. To ensure robust, stable and fit-for-purpose DEM simulations, a 'worst-case scenario' simulation is built for the filling process. By variations in shear modulus and time step, the simulation time is being reduced without compromising the stability or realistic behavior of the material. The output is then used in both processes for all simulations in the experimental simulation plan.<br/><br/>The mixture quality is assessed by the mixing index Relative Standard Deviation (RSD), where both the mixing effectiveness (mixture quality after 30 seconds) and the mixing efficiency (the time it takes to reach a RSD lower than or equal to 0.2) are evaluated. The particle size and particle density have a significant effect on the final mixture quality after 30 seconds of mixing (KPI 1). Moreover, screenshots in x, y and z directions at predefined time steps are generated to serve as visual feedback to understand the mixing mechanisms and flow patterns qualitatively. And, the RSD only stipulates the global mixing performance of the system. To be able to observe local differences in mixture quality, heat maps are generated. Additional local grid systems derived from the global 14x14x9 are designed such that the mass concentration of one of the components can be visualized in x, y or z direction.<br/><br/>The particle size and particle density have a significant effect on the final mixture quality after 30 seconds of mixing (KPI 1). Moreover, the composition, initial filling pattern, fill level, impeller rotational speed and paddle size have a significant effect on how fast a steady-state mixture quality is reached (KPI 2). Finally, the paddle angle and paddle number have a significant effect on both KPIs and therefore holds most potential with respect to optimization purposes.","Double shaft paddle mixer; Discrete Element Method; Free-flowing particles; Batch mixing; DEM; Simulation","en","master thesis","","","","","","","","2025-12-14","","","","Mechanical Engineering | Multi-Machine Engineering","",""
"uuid:19de1308-7994-4bde-b2d7-56860fd79163","http://resolver.tudelft.nl/uuid:19de1308-7994-4bde-b2d7-56860fd79163","Assessing the impact of sustainable fuels for Large Surface Combatants: A comparison between sustainable methanol and diesel for the Future Air Defender of the Royal Netherlands Navy","Pothaar, Maarten (TU Delft Mechanical, Maritime and Materials Engineering)","de Vos, P. (mentor); Geertsma, R.D. (mentor); Kana, A.A. (mentor); Gangoli Rao, A. (mentor); Reurings, J.W. (mentor); Delft University of Technology (degree granting institution)","2022","Progressing targets on GHG emission reduction urge the the Netherlands Ministry of Defense (NL MoD) to reduce the use of fossil fuels, as they announced to contribute to the Paris agreement by reducing its dependency on fossil fuels by at least 70% by the year 2050. However, without sacrificing striking power, because future naval combatants need to perform their operations on the highest end of the violence spectrum and need to have sufficient autonomy to perform their operations at sea independent of logistic supply lines. The Royal Netherlands Navy (RNLN) is investigating the replacement of the Air Defense and Command Frigate (LCF) between 2030 and 2040 by a Large Surface Combatant. As it will be impossible to achieve substantial reduction of GHG emissions through energy-saving technologies, sustainable fuels need to be implemented in the design. In this thesis, the impact of sustainable fuel choice on the design of Large Surface Combatants with a displacement of around 6000 tonnes is assessed. In particular, the current and future developments of sustainable methanol and diesel have been reviewed from existing literature and are examined on the replacement Large Surface Combatant: specifically their advantages, disadvantages, production routes, future production cost estimates and availability to give an understanding which pathways can help the NL MoD to achieve their stated GHG emissions reduction goals. Furthermore, three different design concepts are presented with respect to fuel composition from which the impact of the established fuels is quantitatively examined. First, sustainable diesel is a drop-in fuel, which makes blending of sustainable diesel with fossil diesel possible in the existing infrastructure allowing a gradual transfer from fossil diesel to sustainable diesel. However, the production is less efficient in a well-to-wake approach and the cost of Bio-diesel and E-diesel is 5% to 30% more expensive with a mean estimated additional cost of 6 €/GJ compared to methanol. Secondly, operating on methanol has a significant impact on the design of a large surface combatant: the specific energy of methanol is more than twice as low as diesel and the ship needs a longer machinery space to allow for a diesel engine propulsion configuration. This results in a increase in displacement of 20%. Finally, navies could consider a two-fuel strategy: sail on methanol during operations with limited autonomy, typically in peace time, and operate on diesel during operations with high autonomy, during war time operations. In this case the design needs to include both diesel and methanol fuel systems and additional space for methanol safety measures. This results in a increase in displacement of 4%. However, the range when operating on methanol is reduced to 2187 nm compared to a 5000 nm baseline range. Assessing the impact of sustainable methanol and diesel for Large Surface Combatants at this level of detail and considering a two-fuel strategy is novel for the field. The results can be used by the Royal Netherlands Navy to compare the different concepts and serve as an indicative substantiation in the acquisition of a new Large Surface Combatant. Moreover, it can help in forming the strategy to migrate future naval combatants from current fossil fuels to future sustainable fuels.","Large Surface Combatant; Methanol; Sustainable diesel; FuAD; AWWF","en","master thesis","","","","","","","","","","","","Marine Technology","",""
"uuid:a980d837-970c-4e20-9602-18570ef4bb19","http://resolver.tudelft.nl/uuid:a980d837-970c-4e20-9602-18570ef4bb19","A real-time optimal control approach to autonomous drifting","Cador, Andrei (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Delft Center for Systems and Control)","Keviczky, T. (mentor); Shyrokau, B. (graduation committee); Bertipaglia, A. (graduation committee); Delft University of Technology (degree granting institution)","2022","Full vehicle automation requires complete control over all driving scenarios that can be encountered on roads in order to ensure passenger safety at all times. This extends to dangerous situations such as losing control on slippery surfaces, commonly known as drifting. This work aims to make a step toward ensuring passenger safety in these situations by gaining control over vehicle behavior in high side slip regions. As these regions tend to be highly nonlinear and drifting dynamics happen at a millisecond scale, the time availability for generating proper commands is highly restricted. This work further proposes a method based on Nonlinear Model Predictive Controller (NMPC) that conveniently splits and reformulates the drifting problem to reduce the computational burden of the control structure and make it suitable for real-time implementations. The overall performance and robustness will be evaluated in obstacle-avoidance scenarios and in more general driving situations.","autonomous drifting; limits of handling; nonlinear model predictive controller; NMPC","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:180f1c51-6f6c-470f-a3ff-58e4c7c4efd3","http://resolver.tudelft.nl/uuid:180f1c51-6f6c-470f-a3ff-58e4c7c4efd3","SSE Is Not As Secure As It Looks: New Attacks On Range Queries Using PQ-Trees And Auxiliary Information","Thomas, Jeroen (TU Delft Electrical Engineering, Mathematics and Computer Science)","Liang, K. (mentor); Chen, H. (mentor); Hahn, Florian (mentor); Smaragdakis, G. (graduation committee); Roos, S. (graduation committee); Delft University of Technology (degree granting institution)","2022","In a world where more data gets uploaded to the cloud, it is essential that the data gets stored securely. For users to keep search functionality, searchable symmetric encryption has been developed. SSE works by a user sending a token representing a keyword (or a range), after which the server returns the documents that match the keyword (or values in the queried range). These observed documents are called the access pattern. A number of attacks that work on range SSE schemes have been developed. Yet, most of these attacks work on density or query assumptions that hinder their performance if these<br/>assumptions are false. Furthermore, a number of these attacks use auxiliary information. Yet none of them uses known search tokens.<br/><br/>We, thus, propose a novel approach that uses a PQ-Tree to get the order of the observed documents. It uses the known pairs to assign possibilities for these documents and returns a list of options for each observed token and estimated values for each document. The basic attack guarantees that the correct query is always available by assigning document values based on the known tokens. A refined attack was made that assigns more known tokens by adding the best matches based on confidence score. This refinement allows for more exact token and query matches. Both of these attacks were extended using partial or similar documents from which document volume or rank information could be gathered<br/>to further increase the attack performance in cases where such data is available. We evaluate our attacks against current state-of-the-art and outperform those regarding document and query recovery on all tested datasets. Lastly, we use two countermeasures and see that all attacks are impacted but that our attack still outperforms most.","Range SSE; Auxiliary Information; PQ-trees","en","master thesis","","","","","","","","","","","","Computer Science | Cyber Security","",""
"uuid:63a922bc-c39f-470f-9af6-4e704fbc1fc4","http://resolver.tudelft.nl/uuid:63a922bc-c39f-470f-9af6-4e704fbc1fc4","Evolution of the welding residual stresses after cutting of a cruciform welded joint","Omari, Firas (TU Delft Civil Engineering & Geosciences)","Veljkovic, M. (mentor); Maljaars, Johan (graduation committee); Slot, Henk (graduation committee); Mohabeddine, A.I. (graduation committee); Delft University of Technology (degree granting institution)","2022","The use of welding is widely adopted to assemble structural components in the construction industry for many years. To ensure safety of these welded components, many fatigue tests have been conducted on many different shapes and configurations of welded connections to precisely assess the fatigue<br/>life. However, testing real-size structures and specimens is very limited due to it’s high cost and in-applicability. Thus, these full scale specimens are cut down into small scale specimens to allow applicability for testing. Different characteristics are exhibited between the full and the small scale specimens, as there are major difference in residual stresses induced by welding and cutting, which may give non conservative predictions for fatigue life.<br/>In this thesis, the objective is to forecast the evolution of the residual stress field originated by welding of a full scale and small scale specimens of a cruciform joint at the weld toe after breaking it down into smaller specimens using a cutting process by performing a numerical analysis using Abaqus<br/>finite element analysis software. To achieve this goal, first, a thermo-mechanical welding simulation was performed to obtain a welding<br/>residual stress field on a 910 mm long cruciform joint, which is done in two main parts, starting with the thermal model in which a temperature field is analysed. The temperature field from the thermal model<br/>is used as an input for the mechanical model in which the residual stress field is produced due to the temperature change and restriction of movement of material due to the shrinkage and expansion. Secondly, the 910 mm long full-scale cruciform joint was cut into five shorter specimens of 500, 210,<br/>120, 75, and 20 mm. The welding residual stress (WRS) levels at the weld toe for each specimen was recorded and showed large stress losses and relaxations as the specimen gets shorter in length. a major longitudinal stress loss of 97% and 77% loss of maximum principle stresses when cutting down<br/>the 910 to a 20 mm long specimen, making it almost free of WRS, but only a 5-6% loss of longitudinal and Max. principal stresses when going from 910 to 500 mm. Thirdly, after generating multiple welded specimens with different lengths, a tension load of 186.2 is set in the x-direction of the attachment plate of the cruciform joint, and the stress level at the weld toe was analyzed due to the applied load and the WRS. A 40% increase of the stress occur due to the<br/>applied load, but a very slight decrease in longitudinal stresses for the 910, 500 and 210 mm due to depicting a plate-like behaviour in contraction due to poisson’s effect. Finally, the same specimens were analysed under the 186.2 MPa load but without including the WRS. Different shapes of stress distributions were found, and differences in stresses when comparing<br/>the models with and without WRS in the models. The difference in longitudinal z-direction reached up to 282 MPa, while only 77 MPa in the transverse direction. The maximum principle stresses insured the importance of including WRS when performing fatigue assessment as it showed the fatigue failure to occur in the weld root with a crack to happen at the middle part. The specimens that exclude WRS would start cracking at the edges of the weld root, but in the central part of the weld seam when including WRS. The model that included WRS showed similar fracture location at the weld root as the fractured specimen performed in tests at TNO’s laboratories.<br/>The next steps in this research is the modification of a modelling methods. The results can be improved and smoothed by modelling using the effective notch method were a radius is introduced at the weld toe and the root to eliminate the stress singularities. The welding simulation can be improved<br/>to get better results by modelling the full cruciform joint without symmetry conditions, and include a weld order for all four welds with proper cooling time in between each weld.","Welding simulation; Residual stresses; Cutting; Fatigue; Weld toe; Cruciform specimen","en","master thesis","","","","","","","","2022-12-14","","","","Civil Engineering","",""
"uuid:b17f28de-5e5b-4d37-b648-2f753342f605","http://resolver.tudelft.nl/uuid:b17f28de-5e5b-4d37-b648-2f753342f605","Greening up my sports club: A qualitative exploration of sustainability transformation at Dutch sports clubs","Bliek, Esther (TU Delft Technology, Policy and Management)","Biely, K. (graduation committee); de Vries, G. (mentor); Pesch, U. (mentor); Delft University of Technology (degree granting institution); Universiteit Leiden (degree granting institution)","2022","The societal need for sustainability transformation is crucial in light of climate change, and the role of individual action and behavioural changes is considered critical in meeting the Paris agreement. Radical shifts in social norms are required, which could be achieved through reaching social tipping points. These tipping points could be reached earlier by focusing on ‘greening’ communities rather than individuals. Any type of social change however, needs initiation in one way or another. Knowing what makes people advocate for pro-environmental behaviour within their community or communities, could help initiate the needed sustainability transformation. A knowledge gap was found as the literature only partly covered this topic. Sports clubs in the Netherlands are popular and relevant community settings that are increasingly stimulated towards more sustainable practices, therefore this was the setting that was focused on in the study. An exploratory approach was taken to pinpointing which helping or facilitating conditions in sports clubs are experienced by individuals who make efforts in the sustainability transformation at their club. To do this, a conceptual model was created, taking a multi-level approach and combining the capability-opportunity-motivation-behaviour (COM-B) model with environmental citizenship. A total of 17 participants who considered themselves an initiative taker or achiever for sustainability at their sports club were consulted through semi-structured interviews. Elements of grounded theory were used to shape the analysis of the acquired data. The interview transcripts were coded and analysed using the COM-components of the conceptual model. The analysis shows that there is a multitude of factors that stimulate partaking in sustainability transformation at sports clubs, with community feel or communication, and (resulting) availability of skills and knowledge standing out. Limitations of the study included taking a rather broad approach, advising future studies to further deepening more self-contained dimensions. Recommendations for supporting organisations, policy makers and sports club members with environmental concerns, included communicating about concerns and providing support regarding sustainability transformations, among others.","Sustainability Transformation; Sports clubs; COM-B model; Pro-environmental behaviour; Environmental Citizenship; Change advocacy","en","master thesis","","","","","","","","","","","","Industrial Ecology","",""
"uuid:3f6f080e-5fd5-4bd2-804b-483b09b1409d","http://resolver.tudelft.nl/uuid:3f6f080e-5fd5-4bd2-804b-483b09b1409d","Semi auto-taggers for music: Combining audio content and human annotations for tag prediction","Lugtenburg, Jochem (TU Delft Electrical Engineering, Mathematics and Computer Science)","Liem, C.C.S. (mentor); van Gemert, J.C. (graduation committee); Kim, Jaehun (graduation committee); Delft University of Technology (degree granting institution)","2022","Auto-tagging systems can enrich music audio by providing contextual information in the form of tag predictions. Such context is valuable to solve problems within the MIR field. The majority of re- cent auto-tagging research, however, only considers a fraction of tags from the full set of available annotations in the original datasets. Because of this restriction, potential relationships between tags remain unconsidered and tagging may be less rich. These relationships suggest alternative ways to establish an auto-tagging system. For instance, a few accurate annotations from experts can improve the richness and quality of the auto-tagging system by providing explicit context in addition to audio content features. In this work, we propose an adaptation to the auto-tagging task, semi auto-tagging, to demonstrate such potential. In our framework, tags are allowed as contextual input to the tag pre- diction system in addition to audio content information. The system then suggests additional relevant tags. We implement two models that fit within the framework: content-aware matrix factorization and graph convolutional networks. To see whether we can improve upon a traditional auto-tagger, we compare these models with a multilayer perceptron as a baseline. Experimental results show that semi auto-tagger models can predict relevant tags both in the absence and presence of an audio content feature, and can predict tags for previously unseen songs similarly to an audio content auto-tagger. Based on a tag embedding comparison, we find that semi auto-tagger models can better learn implicit relationships between tags with a similar text string representation when compared to the baseline.","music; Tags; Machine learning","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:bff1f7ec-8ba1-46c1-8df5-d85fb9846597","http://resolver.tudelft.nl/uuid:bff1f7ec-8ba1-46c1-8df5-d85fb9846597","Relating polymer architecture to water absorption properties in a waterborne coating: Characterizing the physical structure of waterborne coatings via rheology and Positron Annihilation Spectroscopy","Biella, Riccardo (TU Delft Aerospace Engineering)","Garcia, Santiago J. (mentor); Delft University of Technology (degree granting institution)","2022","In this thesis, the relationship between the polymer architecture and the water absorption properties of a commercially available waterborne anticorrosion coating are investigated with the purpose of improving the barrier properties. \\<br/>To explore this relationship, the polymer architecture had to first be characterized. This is because waterborne polymers present a particular structure that is not well understood. These coatings are made from a suspension of polymer particles in water. This means that a heterogeneous structure is expected to arise despite the homogenization processes happening after the drying process. The main hypothesis of the thesis is that such chemical and physical heterogeneities can explain the relationship between polymer architecture and water absorption.<br/>To characterize these heterogeneities, positron annihilation spectroscopy experiments and the deconvolution of the continuous relaxation spectrum were used. <br/>\par \noindent<br/>The deconvolution of the relaxation spectrum allowed probing of the relaxation mechanism present in the material. An intermediate relaxation mechanism with a characteristic time in between the main chain relaxation and the terminal flow was observed. The analysis of the dependence of this mechanism on structural parameters such as the particle size and the annealing process allowed establishing it as the interdiffusion phase for smaller particles and the hydrophilic interface for bigger particle sizes. This confirms that a chemically and physically heterogeneous area<br/> exists in the material and characterizes its dependence on structural parameters.<br/>\par \noindent<br/>The Positron Annihilation Spectroscopy experiments allowed probing the physical structure of the material by studying its defect density and free volume. Two main results were obtained from this technique. \\<br/>Firstly, the characterization of the bulk of the material confirmed the results of the thermomechanical experiments, confirming the technique can be applied to this complex polymer. Despite the good agreement between the different techniques, however, the results were not sufficiently accurate to study the effect of water diffusion through the material, suggesting more efforts are necessary to improve the technique. \\<br/>A second interesting result was the observation of a physically heterogeneous structure along the thickness of the coatings, which was hypothesized to be related to the drying process. More experimental evidence could help not only improve the understanding of this structure, but also shed light on the incredibly important drying process. <br/>\par \noindent<br/>Relating the polymer architecture to water absorption revealed how the physical heterogeneities and the free volume present at the interdiffusion phase are not influencing the water absorption. Rather, it is the polar interface that is a leftover of the drying process to control the water absorption. \\<br/>This can be exploited to improve current anticorrosion waterborne coatings by reducing the particle size to increase the coherence of the film while at the same maintaining the polar character of the interface.","","en","master thesis","","","","","","","","2025-12-13","","","","Aerospace Engineering","",""
"uuid:80e64288-b740-4896-9fb3-4b36925dddc5","http://resolver.tudelft.nl/uuid:80e64288-b740-4896-9fb3-4b36925dddc5","Optimization of the lift point design decision-making process for offshore jacket decommissioning","Tetteroo, Daan (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Offshore and Dredging Engineering)","Ummels, B.C. (mentor); Metrikine, A. (graduation committee); ten Klooster, M. (mentor); Delft University of Technology (degree granting institution)","2022","All over the world, many offshore structures have been built in the last decades, both by the oil and gas industry and by the renewable industry. When these structures reach their end of life, they have to be removed. The removal is done in decommissioning projects. Many of those offshore structures are bottom founded. Of that amount, a big part has steel space frame substructures called jackets. Jackets are often removed with a heavy lift vessel. The crane hook of such a vessel is connected to the structure to be lifted by means of lift points. These lift points are the connection point of the rigging with the structure. The structures removed in decommissioning projects are often more than 30 years old. Because of that, there are a lot of uncertainties encountered by the industry in decommissioning projects that can lead to issues, such as loss of information or unknown material strength. The result is that all aspects of a decommissioning project have to be reconsidered each time. This makes the preparation phase costly and time-consuming. An aspect of the preparation is the selection of the lift point type, while it is unclear how and whether an optimum solution is chosen. Therefore the question arises, if the decision making process can be optimized by improving the selection of the lift point type in the preparation phase. One way to optimize such a decision-making process is by means of artificial intelligence. AI is able to compare data where humans see no connection, it can analyze large pieces of data in a much shorter time than humans can, it makes unbiased decisions and it can significantly reduce errors and increase accuracy and precision. This thesis will therefore focus on the optimization of the decision-making process of the lift point design of jackets by means of artificial intelligence. To answer the overall research question, first an analysis is made of various decommissioning projects of the past years. These projects were carried out by Boskalis. In this analysis, an attempt is made to visualize which steps are taken in the lift point selection process. By means of these steps it can be investigated whether there is a repetition or trend in the selection process of the lift points. In addition, the analysis aims to find the criteria the decisions are based on. Secondly, the analysis shows that certain steps are taken by Boskalis in the decision-making process of the lift point design in decommissioning projects. A trend was clearly visible in the way the lift points were selected. The relatively simple options are examined first, after which the more difficult options are investigated if the others prove impossible. In addition, the analysis found clear criteria that are used in the selection of the lift points. These criteria were reflected in the selection process of the execution strategy and in the selection process of the lift points. In addition to the total costs, among others ease of installation and the total duration also play a major role in the decision-making process. For example, an option was chosen that was more expensive than its alternative, but had a much shorter duration. This information made it possible to determine whether AI could be used in decommissioning projects in the future, to accelerate the preparation phase. Thirdly, it is investigated whether AI can improve the decision-making process of the lift point design. Therefore, three AI applications are examined and compared with the previous findings. The AI applications are: machine learning, genetic algorithms and single variable optimization. All three turned out not to be a good solution to the problem. For machine learning there is too little data available. Genetic algorithms do not seem to give the desired output with the given inputs. And single variable optimization is too limited in its solution. The final conclusion is therefore that the three investigated AI applications in this way will not improve the decision-making process of the lift point design. If the data set were to be expanded, machine learning could eventually be applied in the future. In addition, it could be investigated in future research whether genetic algorithms can be used if the input is changed. This thesis only briefly discusses what GA entails and whether the method has the desired output with the data found. Also, only a limited number of AI applications have been investigated in this thesis. But there are many today. For example, multi variable optimization could be a starting point for further research. Because there, the optimization function can have two variables, so that, for example, time and cost can be entered in different units.","Decommissioning; Jackets; Lift point design; Optimization; Artificial Intelligence","en","master thesis","","","","","","","","","","","","Offshore and Dredging Engineering","",""
"uuid:455ab29b-5dd6-424d-9710-ff116bbab5a5","http://resolver.tudelft.nl/uuid:455ab29b-5dd6-424d-9710-ff116bbab5a5","Rotational forming of thin SS316L sheets","Offerman, Maurice (TU Delft Mechanical, Maritime and Materials Engineering)","Walters, C.L. (mentor); Asgari, A. (graduation committee); Jovanova, J. (graduation committee); Zeestraten, Martijn (mentor); Delft University of Technology (degree granting institution)","2022","Bipolar half plates (BPPs) are important parts of Proton Exchange Membrane (PEM) hydrogen fuel cells. Metallic BPPs are generally produced by stamping or hydro forming. However, these processes are not continuous and relatively slow compared to rotary forming. Rotary forming is a continuous process and could potentially be a faster BPP production method. The BPPs are plastically deformed in bending and membrane modes. It is necessary to determine the bending and membrane strain because differentiating them can aid in the design of future BPP rotary forming production methods. Bending strain predominantly could lead to fractures on the outside of the bend. Membrane strain causes material thinning and could potentially lead to necking. These deformation modes need to be well understood so that the highest forming levels are achieved with a high level of geometrical consistency without exceeding material failure limits. The goal of this research is to determine the bending and membrane strain of 0.1 mm thick SS316L sheet material formed by rotary forming. This is done by experimental testing and analysis. From the experimentally deformed material, cross-sections are made and analysed. The thickness and bending strain are measured from these cross-sections. The experimental results are compared to FEA simulations. An important assumption is plane strain and it is experimentally validated. Plane strain FEA models are used to further understand the problem. The FEA simulations are validated, using the single channel strain experiments. Simulations with channels aligned with the cylinder axis are validated with a maximum thickness error of 3%. However, channels perpendicular to the axis are validated with an error of 8.9%. The FEA simulations are then used to further analyse equivalent plastic strain, stress, springback and final shape. The maximum equivalent plastic strain is 0.34. The maximum VonMises stress is 1200 MPa and maximum springback is 0.075 mm. The final shapes along the cylinder axis meet the experimental results the best. The bending and membrane strain are experimentally measured and simulated in Abaqus CAE. The bending and membrane strain highly depend on channel orientation and indentation depth. However, the bending strain is greater than membrane strain for both experiments and simulations. This research should be extended to investigate more complex geometries and designs. This is of course a more realistic example for BPPs.","Bipolar plate; rotary conversion; strain","en","master thesis","","","","","","","","","","","","Offshore and Dredging Engineering","",""
"uuid:485404dd-ef39-429e-837b-657c3f38c156","http://resolver.tudelft.nl/uuid:485404dd-ef39-429e-837b-657c3f38c156","A deep learning approach to (semi-) automatically track bone movement in ultrasound images of patients with a unilateral transtibial prosthesis","Donse, Daniël (TU Delft Mechanical, Maritime and Materials Engineering)","Marchal-Crespo, Laura (mentor); Tümer, N. (graduation committee); Jonkergouw, Niels (graduation committee); Zgonnikov, A. (graduation committee); Delft University of Technology (degree granting institution)","2022","Background: The procedure to fit a prosthetic socket to a patient, which can assure the patient’s comfort during activities of daily living, is labour intensive. Such a lengthy procedure could benefit from an automated and more efficient data-driven method capable of automatically tracking the relative movement between the patient’s tibia and the prosthetic socket. To investigate such a method, we acquired in-socket bone displacement data during the physical activities of the prosthetic user. Manually tracking the location of the tibia from, e.g., B-mode (imaging) ultrasound (US) sequences might be a solution, but this is time-consuming, and the interpretation of the sequences is highly operator dependent. Therefore, an automated and efficient method to assess socket fit in US sequences is needed. <br/>Methods: We used an existing 3D U-Net with a long short-term memory module (LSTM) and compared its ability to track a landmark location point on the tibia in US recordings by comparing the displacement and similarity in shape with data obtained from a semi-automatic single-point tracker. To evaluate the performance of the developed automated workflow, we obtained experimental data from three participants who performed three repetitive stepping tasks with their prosthetic leg in a sideways, forward, and backward motion. Three deep learning models were trained with a varying hold-out method (66% training data, 34 % test data) to test the ability to track a landmark location on the tibia in unseen data from one participant. To find the similarity of the deep learning models compared to a semi-automated single point tracker, the normalised root mean squared error (NRMSE) was calculated. We also evaluated the normalised maximum cross-correlation (NMCC) to account for the maximum similarity in displacement trajectory when a delay occurred between the true trajectory and that from the automated model. We analysed the repeatability of each step task per participant with the standard deviation from the mean tibia’s landmark location trajectories. <br/>Results: Due to the delay between the semi-automated single-point tracker and the DL model, the NRMSEs ranged between 27% and 90%. The similarity threshold (0,95) was reached for five trajectories of the tracked point on the tibia in the anterior-posterior direction, with a delay between 1,5% and 8,5% of the step duration. The similarity in the anterior-posterior direction of the tibia’s landmark location trajectory was higher than that in the lateral-medial direction. The SD for all participants was around 1 mm but varied proportionally to the amount of movement observed per participant. The SD of the DL models was similar to that of the semi-automated single-point tracker. <br/>Conclusion: We conclude that a DL model from a 3D U-Net with an LSTM module has the potential to assist prosthetists and researchers in tracking in-socket tibial bone movement in the anterior-posterior direction.","Biomechanical assessment; Ultrasound; Tibia; Deep Learning; Prostheses; Unilateral; Transtibial","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Vehicle Engineering | Cognitive Robotics","",""
"uuid:64a7b528-8b84-4aca-a5c3-7d35270eeb03","http://resolver.tudelft.nl/uuid:64a7b528-8b84-4aca-a5c3-7d35270eeb03","Raybot: Design and control of an underwater quay wall inspection vehicle","van Enckevort, Tijmen (TU Delft Mechanical, Maritime and Materials Engineering)","Ferranti, L. (mentor); Hernández, Carlos (graduation committee); Jovanova, J. (graduation committee); Bootsma, Bart (mentor); Delft University of Technology (degree granting institution)","2022","Quay walls are important structures that keep the water in harbours and canals within their bounds, and accommodate large infrastructure like roads or ship-handling structures on top of them. Due to their importance it is critical that they do not fail or collapse. Inspections are done to prevent this, as a better knowledge of the state of quay walls can help in predicting future behaviour of the quay walls. However, current inspection methods are not satisfactory and can be improved upon. This thesis proposes the Raybot. This is an Autonomous Underwater Vehicle that can move along the quay walls like rays swim along the walls of their aquariums. The design of the Raybot is presented, which keeps in mind the requirements that follow logically from the quay wall inspection mission. This resulted in a rectangular robot with an outward modular frame. The thrusters, on-board computers, and sensors can be mounted on the inside. Next, a Model Predictive Controller is proposed for the motion control of the Raybot. For this, the extensive kinematics and kinetics of the Fossen model are explained. The parameters of this Fossen model are estimated for the Raybot using various methods. A Model Predictive Controller is formulated for Autonomous Underwater Vehicles and implemented in the Robot Operating System 2. A physical and visual representative simulation environment is set up, which can simulate the motion of the Raybot. This is used to assess the path tracking behaviour of the Raybot. The Model Predictive Controller is compared to a cascaded PID controller by path tracking of a zig-zag path along the quay wall. An analysis of the tuning parameters of the Model Predictive Controller is presented. The Model Predictive Controller outperforms the cascaded PID controller on both the Mean Squared Error of the path tracking error and the completion time of the inspection mission, whilst adhering to constraints set by the minimum and maximum velocity of the Raybot and the minimum and maximum thruster inputs. This improved performance leads to a higher quality of the inspections, as they can be done more up-close, as well as a higher quantity of the inspections, as more inspections can be done in the same time. For future work it is recommended to estimate some parameters of the model on a real robot, as well as testing the Model Predictive Controller on a real robot in a tank. This will showcase the performance of the motion controller in an even more realistic scenario.","Model predictive control; underwater robotics; autonomous underwater vehicle; Quay walls","en","master thesis","","","","","","","","","","","","","",""
"uuid:e0bac06b-60a1-4c71-a04d-8bf9e1019b50","http://resolver.tudelft.nl/uuid:e0bac06b-60a1-4c71-a04d-8bf9e1019b50","Hierarchical Social Processes: Stochastic Meta-learning of Group and Individual-level Style","El Attar, Bilal (TU Delft Electrical Engineering, Mathematics and Computer Science)","Hung, H.S. (mentor); Raman, C.A. (graduation committee); Delft University of Technology (degree granting institution)","2022","How people behave in social interactions is influenced by a multitude of factors. A large part of human communication is embedded within non-verbal communication. This type of communication is sent throughout social signals, that are embodied within low-level social cues (e.g. gaze, posture, gestures). In order for intelligent systems to seamlessly interact with humans, they need to possess some form of social intelligence. That includes expressing and recognising social signals. The field of social cue forecasting intends to predict low-level behavioral cues within social interactions, allowing systems to adapt their behavior according to the forecasted behavior of interlocutors, or synthesize human behavior on the basis of the prediction. Within social science theory, it has been established that these behavioral cues are dependent on social context, as well as individual idiosyncrasies. Under earlier work within human behavior synthesis, the latter has been mostly used, and referred to as ’style’. This work attempts to broaden the traditional view of style and proposes a model for incorporating both group, and individual-level style using a hierarchical latent variable model. To adapt to unseen groups, we incorporate this hierarchical latent structure into a meta-learning model. Introducing the hierarchical neural processes and social processes models. After testing these models on a real-world dataset containing triadic interactions, it turns out that most models fail due to posterior collapse. This prevents them from learning a useful latent representation containing semantic information with respect to forecasting future sequences of social cues. To combat this, a constant weight was assigned to a part of the loss term. However, as the issue still persists, it leaves us unable to prove whether our proposed method improves upon the baseline approach. Therefore, future work on posterior collapse in neural processes models is needed.","","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:209dcc47-07e4-44ef-b4bf-4d00f39178d5","http://resolver.tudelft.nl/uuid:209dcc47-07e4-44ef-b4bf-4d00f39178d5","Improving irradiance prediction by using classification of sky images and deep learning","van Urk, Gijs (TU Delft Electrical Engineering, Mathematics and Computer Science)","Martinez Lopez, V.A. (mentor); Ziar, H. (mentor); Delft University of Technology (degree granting institution)","2022","Short-term solar forecasting is essential for the large-scale application of solar energy and is necessary for the operation of power plants, energy trading, and grid balancing. The main cause of uncertainty in solar forecasting is cloud movement, which can be observed by All-Sky Images. The spatial layout and temporal dynamics of clouds cannot be extracted by conventional cloud modelling approaches utilising image analysis techniques, leading to inaccurate predictions of the interaction with solar radiation. In this study an categorization method is made based on sky conditions and from that five classes are made. The goal of this classification method is to improve the 21-minute irradiance predictions which are made with a deep learning model. The outcome of the 21-minute deep learning model will get compared with the Persistence, Smart Persistence and ARIMA model. This classification method and irradiance prediction are applied for location Folsom, California and Delft, Netherlands. The irradiance predictions based on sky classification showed an improvement of 8.6% for location Delft and 29.3% for location Folsom when the same dataset sizes are used. The irradiance predictions were also done for various dataset sizes and compared per location. Finally, it provides a way forward to improve the classification method and deep learning models to anticipate short-term irradiance in the future.","","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:cb576f2e-adf4-43cd-859f-99910c197aed","http://resolver.tudelft.nl/uuid:cb576f2e-adf4-43cd-859f-99910c197aed","Cost Estimation for Factorized Machine Learning in Data Integration Scenarios","van Schijndel, Jessie (TU Delft Electrical Engineering, Mathematics and Computer Science)","Hai, R. (mentor); Katsifodimos, A (mentor); Chen, Lydia Y. (graduation committee); Houben, G.J.P.M. (graduation committee); Delft University of Technology (degree granting institution)","2022","The workflow of a data science practitioner includes gathering information from different sources and applying machine learning (ML) models. Such dispersed information can be combined through a process known as Data Integration (DI), which defines relations between entities and attributes. When all information is combined in one source suited for ML purposes, this source often contains duplicate data, resulting in longer operation times. Recent work has created algebraic rewrite rules for ML such that computations can be pushed down to individual sources. This method is referred to as factorized learning. In this work, we present an implementation of Amalur, a system for automated factorized learning that is novel because of its applicability in any DI scenario. Amalur shows significant speedups for some datasets and models, while for some other datasets and models, our implementation of factorized learning results in slowdowns. Whether factorized learning is efficient depends on the operations involved in the applied ML model and the data supplied to the model. The process of estimating the efficiency of factorization is known as cost estimation. Previous efforts on cost estimation do not generalize to the DI scenarios included in Amalur, are not tailored to different ML models, and are not properly evaluated. In this thesis, we create a cost estimation procedure for Amalur suitable for any DI scenario, which adapts to individual ML models. To evaluate this procedure we create a data generator capable of generating customizable DI scenarios. Our method outperforms its competitor on DI scenarios covered by the state of the art, and shows comparable performance on newly covered DI scenarios.","machine learning; factorized learning; data integration; cost estimation","en","master thesis","","","","","","","","","","","","Computer Science | Software Technology","",""
"uuid:cdb5c7dc-5bbb-4003-a29f-359f2f40bb00","http://resolver.tudelft.nl/uuid:cdb5c7dc-5bbb-4003-a29f-359f2f40bb00","Utilizing topology optimization to create cleanable structures","Peijen, Arjen (TU Delft Mechanical, Maritime and Materials Engineering)","Giele, R.J.P. (mentor); Langelaar, M. (graduation committee); Noel, L.F.P. (graduation committee); Delft University of Technology (degree granting institution)","2022","Topology optimization is a valuable tool for the optimization of all kinds of structures. It can create highly efficient but complex designs. This complexity can make these structures challenging to clean. However, cleanability is often a requirement in, for example, the medical or food industries. Currently, no method exists to reduce the complexity and create these cleanable structures using topology optimization. The goal of this project is to create a method that can generate two-dimensional cleanable structures. In this context, cleanability has been defined using two requirements. Every section of the surface must be visible, and no sharp edges can appear on the exterior. These requirements are met by generating a structural and cleanable shell around the design. The shell needs to be optimized to minimize the compliance of the entire structure. The addition of this shell has been achieved by the use of a hybrid method. This method combines two structural optimization methods, a level-set method, and the modified SIMP approach. The level-set method acts as a shape optimization method. Its shape forms a boundary in which the modified SIMP method is used to generate a design. Material is placed at this boundary of the level-set shape to create a shell that encloses the structure. Experiments on several sets of boundary conditions show a successful creation of a shell in every case. The resulting designs are not guaranteed to be cleanable, but a satisfactory result has been achieved in every case by changing some parameters. This method sets the stage for further development toward the application of topology optimization to create cleanable designs.","topology; optimization; clean; cleanable; shell; cover","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Precision and Microsystems Engineering","",""
"uuid:b8bcf2b0-ccb5-4a99-8fb6-7d7baab20499","http://resolver.tudelft.nl/uuid:b8bcf2b0-ccb5-4a99-8fb6-7d7baab20499","Evaluating the stability of terps in the Netherlands","Rossetti, Matteo (TU Delft Civil Engineering & Geosciences)","Ngan-Tillard, D.J.M. (mentor); Brinkgreve, R.B.J. (graduation committee); Lanzafame, R.C. (graduation committee); Delft University of Technology (degree granting institution)","2022","Terps are artificial dwelling mounds mostly found in the northern regions of the Netherlands, built to provide safe ground against water in such areas affected by flooding, storm surges, and high tides, before the development of dikes. In this thesis, the stability of these terps was evaluated via FEM models and analyses performed on PLAXIS. Results highlight considerable stability risks when the terp slopes are subjected to considerable external loading, such as those exerted by heavy agricultural vehicles being operated in proximity of these.<br","Terps; Stability; PLAXIS; Wierden","en","master thesis","","","","","","","","","","","","Geo-Engineering","",""
"uuid:4c08bbcf-21c9-4074-81bf-b66099b67734","http://resolver.tudelft.nl/uuid:4c08bbcf-21c9-4074-81bf-b66099b67734","Dynamic Airline Centric Inbound Priority Sequencing: A case study on Westerly morning arrivals for KLM at Schiphol","Hoogendoorn, Rik (TU Delft Aerospace Engineering)","Santos, Bruno F. (mentor); Li, Lishuai (graduation committee); Delft University of Technology (degree granting institution)","2022","During arrival waves at hub airports the surrounding airspaces can be congested, resulting in flight delays. To solve this congestion problem one of the current solutions is to sequence flights whilst they are still en-route by using an Extended Arrival Manager (E-AMAN). This paper aims at improving this E-AMAN concept by tackling two of its limitations. The first one is that priorities are not considered when sequencing the flights, as sequences are currently defined according to the First-Come-First-Served (FCFS) principle. The second limitation is that it is difficult to sequence so-called popup flights when creating the arrival sequence. These popup flights are defined as flights that have a departure airport that lies within the en-route horizon of the E-AMAN. The first limitation is tackled by proposing a dynamic Inbound Priority Sequencing (IPS) model for the use of a network carrier at their hub airport. The model sequences air traffic en-route in favor of the network carrier, by trading off the (potential delay) costs of individual flights. Each flight then receives a Target Time Over their Initial Approach Fix (TTO IAF). At the same time competitive traffic is not negatively influenced. The other limitation of E-AMAN is tackled by giving popup flights from small regional airports a so-called Company Calculated Take-Off Time (CCTOT) next to a TTO IAF, which is used to delay those flights whilst still on the ground. By the time flights enter the arrival Air Traffic Control (ATC) centers, the FCFS is applied up until landing, meaning ATC does not have to change their working principles. The objective of the IPS model is to minimize the overall arrival cost for the network carrier, consisting of optimizing for fuel cost, passenger missed connection cost, and Loss of Future Value cost. The model is formulated as a mixed-integer quasi-linear program. A novelty of the model, in addition to specifically including popup flights, is the fact that the sequence is recalculated each time new information is available. This information can be a new flight entering the action horizon of the model or a new Estimated Off Block Time for a departing flight at the hub to which passengers of an arriving flight have to connect to. At the same time the stability of the sequence is kept in mind by including a cost penalty for adjusting the TTO IAF. Results of a case study performed at Amsterdam Airport Schiphol for a Dutch network carrier show cost savings of 12\% compared to the traditional FCFS without en-route sequencing in a simulation environment. During validation of the model, by means of performing shadow runs using real-time flight data, it turned out the model can indeed be of help to reduce costs for a network carrier.","Inbound Priority Sequencing; E-AMAN; Arrival Management; Arrival Scheduling; Arrival Manager; Arrival Sequencing and Scheduling; popup flights; Airline priorities","en","master thesis","","","","","","","","","","","","Aerospace Engineering | Air Transport and Operations","",""
"uuid:e3e9a825-d8ed-40ad-b49e-c30cc02520ba","http://resolver.tudelft.nl/uuid:e3e9a825-d8ed-40ad-b49e-c30cc02520ba","Thermal Modelling of a Concept for a Hybrid Micro Combustion Generator","Böhme, Florian (TU Delft Mechanical, Maritime and Materials Engineering)","Goosen, J.F.L. (mentor); van Ostayen, R.A.J. (graduation committee); Peeters, J.W.R. (graduation committee); Delft University of Technology (degree granting institution)","2022","Mobile electronics or remote devices like sensors for the Internet of Things (IoT) require energy storage with increasing energy densities, approaching the limits of the widespread lithium batteries. At the same time, lithium batteries are subject to growing criticism about their environmental impact due to their raw materials and their mining methods. Chemical energy seems to be a promising alternative and the development of micro combustion to make use of it is already for almost 30 years the topic of ongoing research. Recent studies show that compliant combustion engines are a good solution to mitigate some problems like leakage and friction and thus, achieve higher efficiencies. However, the most prevalent problem is heat losses through the walls because of the high surface-to-volume ratio in small-scale combustion. In this work, a design concept was proposed that not only insulates the compliant combustion chamber of the actuator for Flapping Wing Micro Air Vehicles (FWMAV) but also uses the waste heat to generate electricity. That was done by attaching Thermoelectric (TE) modules to a support structure and thermally connecting them with porous media to the oscillating combustor wall. The actuator uses the heat and pressure generated by the catalytic reaction of hydrogen peroxide and therewith, only emits steam and oxygen. With the help of a one-dimensional steady-state heat resistance model and a one-dimensional transient heat resistance-capacitance model, an optimum design was found. With that, it is possible to create a temperature difference sufficient enough to enable energy harvesting by TE modules. That was achieved by implementing an exhaust gas recirculation which<br/>transfers heat to the modules and simultaneously serves as a heating blanket for the combustor. A downside of the design is the relatively long time it takes to reach its steady state and especially for FWMAV, the increase in weight.","Hybrid Micro Generator; Micro Internal Combustion Engine; Micro Thermoelectric Generator","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Mechatronic System Design (MSD)","",""
"uuid:c37858e5-7099-4e02-9ece-24aec99f36de","http://resolver.tudelft.nl/uuid:c37858e5-7099-4e02-9ece-24aec99f36de","Velocity Reconstruction in Pool Fires using Physics-Informed Machine Learning","de Boer, Dirk (TU Delft Aerospace Engineering)","Doan, Nguyen Anh Khoa (mentor); Sitte, Michael Philip (graduation committee); Delft University of Technology (degree granting institution)","2022","In many flow experiments it is complex to measure all flow states of interest, leading to the need for a method to retrieve unmeasured flow states from measured ones. This work focuses on Hidden Fluid Mechanics (HFM), which refers to a Physics-Informed Neural Network (PINN) able to incorporate the Navier-Stokes (NS) equations into the loss function of the Neural Network (NN) for the purpose of reconstructing flow fields. <br/><br/>As HFM is a recent framework which has not been applied to many flows yet, it is unknown if HFM is capable of reconstructing flow fields in chemically reacting flows where strong gradients are present. For this reason, the performance of HFM is investigated here using data sets from Direct Numerical Simulations (DNS) of an axisymmetric pool fire in cylindrical coordinates, for which the velocity fields are purposely removed and attempted to be recovered from the density, pressure and temperature fields. The implementation has been performed making use of TensorFlow in Python, where both steady and unsteady pool fires are considered.<br/><br/>Pool fires are simplified representations of real-life accidental and forest fires, illustrating the importance of their research. If the critical pool diameter is not exceeded, a steady flow occurs. However, if surpassed, the flow exhibits an unsteady flickering behaviour known as puffing.<br/><br/>The main finding is that both in the steady and unsteady pool fires, the PINN is capable of reconstructing the most prominent features of the velocity fields when density, pressure and temperature are provided, even though strong gradients are usually underestimated by the PINN, causing wrongly predicted extreme values. This implies that the method can be used mainly for qualitative purposes, as the exact values are not always captured. It is found that the accuracy is lower in the unsteady flow compared to the steady flow. Furthermore, the axial velocity field is generally reconstructed to a higher accuracy than the radial velocity field. <br/><br/>It is found that the accuracy decreases when increasing the spacing between provided data points, from which implications on possible applications to real-life measured data can be drawn, as not all measurement equipment might reach the required spatial resolution. Investigating the effect of adding artificial white noise to mimic measurement noise, it has been found that the method is robust to noise, but less so for the steady case than for the unsteady flow case. Lastly, the effect of removing the density and/or pressure from the provided flow states is investigated, where it is found to have a detrimental effect on the accuracy except if physical assumptions are given to the PINN (i.e. the ideal gas law). Using the right assumptions, it is found that for the steady case providing only the temperature field is deemed enough to reach a relatively similar accuracy compared to not removing any flow states, whereas for the unsteady case at least the temperature and pressure fields need to be provided. The current research shows the capabilities but also the limitations of the HFM framework in case of steady and unsteady flow with chemical reactions and strong gradients, creating opportunities for further research of HFM in other flow cases and for potentially applying the framework to real experimental data of fires or other flows.<br","Machine Learning; physics-informed neural networks; Flow Reconstruction; Pool fire","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:6ad72d54-330c-4311-92c8-f811b50fbb03","http://resolver.tudelft.nl/uuid:6ad72d54-330c-4311-92c8-f811b50fbb03","Wi-Closure: wireless sensing for multi-robot map matching: Enabling fast and reliable search of inter-robot loop closures in repetitive environments","Kemmeren, Anne (TU Delft Mechanical, Maritime and Materials Engineering)","Alonso Mora, J. (mentor); Jafarian, M. (mentor); Wang, W. (mentor); Kooij, J.F.P. (graduation committee); Kok, M. (graduation committee); Delft University of Technology (degree granting institution)","2022","This thesis proposes a novel algorithm, Wi-Closure, to improve computational efficiency and robustness of map matching in multi-robot SLAM. Current state-of-the-art techniques connect maps with inter-robot loop closures, that are usually found through place recognition. Wi-Closure decreases the computational overhead of these approaches by pruning the search space of potential loop closures, prior to evaluation by a typical place recognition algorithm. Wi-Closure achieves this by identifying where trajectories are close to each other through sensing spatial information directly from the wireless communication signal. Then, place recognition is only performed on scans taken at locations close to each other. Wireless sensing provides information even when operating in non-line-of-sight or without existing communication infrastructure. The validity of Wi-Closure is demonstrated in simulation and hardware experiments. Results show that using Wi-closure greatly reduces computation time, by 54% in simulation and by 77% in hardware, compared with a multi-robot SLAM baseline. Importantly, this is achieved without sacrificing accuracy. Using Wi-Closure reduces absolute trajectory estimation error by 99% in simulation and 89% in hardware experiments. This improvement is due in part to Wi-Closure’s ability to avoid catastrophic optimization failure that typically occurs with classical approaches in challenging repetitive environments.","Multi-robot systems; wireless sensor networks; SLAM","en","master thesis","","","","","","","","","","","","","",""
"uuid:ba59787c-221b-4d63-9bab-46175b6f17b5","http://resolver.tudelft.nl/uuid:ba59787c-221b-4d63-9bab-46175b6f17b5","Design of a Nonlinear Stiffness Unit Cell Aided Magnetic Gravity Compensator","Kouwenhoven, Timo (TU Delft Mechanical, Maritime and Materials Engineering)","Hassan HosseinNia, S. (mentor); Kaczmarek, M.B. (graduation committee); Delft University of Technology (degree granting institution)","2022","A novel nonlinear stiffness unit cell aided magnetic gravity compensator is proposed for the purpose of isolating low-frequency vibrations. A negative stiffness magnet setup is combined with a compliant unit cell with tailored nonlinear force-displacement characteristics. This combination offers a large range of motion featuring low stiffness, a high force density, and passive stability, creating a large vertical displacement passive magnetic gravity compensator (LVDPMGC). The passive stability of the system eliminates the need for active stabilization, reducing costs and complexity. An adjustable load-bearing capacity can be obtained by changing the number of unit cells, increasing scalability compared to conventional magnetic gravity compensators (MGC's) which have a fixed load-bearing capacity. The stiffness characteristics of the unit cell and magnet setup are analysed with FEM, showing which parameters influence system performance. Parameters are iteratively adjusted after which a prototype is manufactured and tested. The experimental results show that the unit cell can effectively stabilize the magnet setup while increasing the low stiffness range of motion, force density, and scalability compared to conventional MGC's.","Magnetic Gravity Compensation; Magnetic Levitation; Compliant Mechanisms; 3D printing; Compliant Unit Cell; Nonlinear Stiffness; Passive Vibration Isolation","en","master thesis","","","","","","","","2024-12-13","","","","Mechanical Engineering | Mechatronic System Design (MSD)","",""
"uuid:cca2e04a-569c-451b-8f9e-7b5bf3110dd7","http://resolver.tudelft.nl/uuid:cca2e04a-569c-451b-8f9e-7b5bf3110dd7","An interface-enriched finite element method for electromagnetic analysis and optimization of 2D problems","van Bergen, Steven (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Precision and Microsystems Engineering)","Norte, R.A. (mentor); Aragon, A.M. (graduation committee); Delft University of Technology (degree granting institution)","2022","Nanophotonics is the study of structures’ interaction with light with features at or below the nanometer scale. It has gained the interest of many researchers, as it can be used to control the flow of light very effectively in the design of, e.g., solar cells, highly efficient biosensors or lasers. The design of such devices can be non-intuitive and complex and therefore computational tools like topology optimization techniques have been used to improve their designs. However, the topology optimization methods used in the literature often use a density-based representation of the geometry, which often leads to jagged edges. It has been shown in the literature that jagged edges can deteriorate the accuracy of simulation results. Using a level-set method in combination with an enriched finite element method offers a smoother boundary representation than the often used density-based methods. This work aims to develop an analysis and level set optimization for 2D electromagnetic scattering and eigenvalue problems using an enriched finite element method. Furthermore, we showcase that even for a non-conforming discretization, the enriched finite element method achieves the same convergence properties as the standard finite element method with fitted meshes. Finally, we perform topology optimization on the design of both a 2D meta lens and 2D reflector, maximizing their ability to focus light onto a point, using a level set method to define the geometry in combination with the enriched method used in the analysis.","FEM; enriched FEM; IGFEM; optimization; level set; electromagnetics; nanophotonics","en","master thesis","","","","","","","","2024-06-01","","","","Mechanical Engineering | Precision and Microsystems Engineering","",""
"uuid:63658edc-2f9e-4789-81f1-2fff3e7a73be","http://resolver.tudelft.nl/uuid:63658edc-2f9e-4789-81f1-2fff3e7a73be","Ampacity Estimation of Medium Voltage Cables for Changing Load Profiles and Uncertain Site Conditions","Crooijmans, Bastiaan (TU Delft Electrical Engineering, Mathematics and Computer Science)","Vergara Barrios, P.P. (mentor); Rueda, José L. (mentor); Delft University of Technology (degree granting institution)","2022","Climate agreement goals set by the Dutch government increase the urge to reduce our greenhouse gases. To fulfil these goals on a residential level a reduction of the emission of carbon which is produced during household demand and transportation (commute) is required. On a residential level, the amount of photovoltaic systems (PV) and electric vehicles (EV) is increasing rapidly to meet these requirements. All these individual changes in the low voltage (LV) grid will have an impact on the aggregated load profile in the medium voltage (MV) network. <br/>The MV network consists of underground cable connections, which play a vital role in the transmission and distribution of electrical power. Currently, the distribution network operator (DNO) uses a fixed ampacity which is based on fixed site conditions to rate their MV cables. The current methodology only considers the current peak of the load profile, but the ampacity of a cable connection is governed by its temperature.<br/>Ampacity ratings for MV cables are specified for a continuous load applied on the specific underground MV cable in certain ambient conditions. When a cyclic load profile is applied the temperature of the cable will not remain constant over a 24 hour load cycle. Since this introduces moments of lesser loading the underground cable has moments during its load cycle to be able to cool down. If this method is applied the whole load profile which is applied on the MV cable could be raised by a factor so that the peak of the profile safely exceeds the nominal ampacity, but stay within the specified thermal limits. <br/>The area in which the DNO operates is quite expansive, the material surrounding the underground MV cable connection will differ for each area. There is a big uncertainty in terms of ground conditions for the majority of the MV cables. The effect that this has on the ampacity of the cable connection will be examined. By running multiple simulations with different ambient conditions, the impact that this uncertainty has on the ampacity can be concluded. <br/>The simulations will be done with an analytical- and a finite element model (FEM). With these models, the effects of uncertain ground conditions and the possibility to use an cyclic rating factor for specific load profiles can be calculated. This will be used to study the impact of the changing cyclic load profile due to the increase of PV and EV in the network. The interplay between these factors is interesting since the uncertain ground conditions have a negative impact on the overall ampacity while the cyclic rating factor can (partly) compensate for this loss.","MV cable; Changing Load Profile; Uncertainty Analysis; Transient thermal response; Analytical cable model; Electrical Vehicles; Photovoltaic Systems; Ground Conditions","en","master thesis","","","","","","","","","","","","Electrical Engineering | Electrical Power Engineering","",""
"uuid:2f17706d-cd17-42a0-b2bf-f2bb5f0c84e9","http://resolver.tudelft.nl/uuid:2f17706d-cd17-42a0-b2bf-f2bb5f0c84e9","Modelling and Topology Optimisation of Medium Voltage Representative Networks for The Netherlands","Brouwers, Marcel (TU Delft Electrical Engineering, Mathematics and Computer Science)","Vergara Barrios, P.P. (mentor); Panda, Nanda Kishor (graduation committee); Rueda, José L. (graduation committee); Bruninx, K. (graduation committee); Delft University of Technology (degree granting institution)","2022","The electrification of modern-day society keeps increasing and the demand for electricity grows along with it. Technologies like EVs and heat pumps are both part of the new types of demand, while PV systems and wind farms are meant to be our main new sources of generation. Contrary to traditional resources connected to the electricity network, most of these resources tend to be placed and operated in a distributed manner, increasing the demand for transport capacity within the LV and MV grid. This demand cannot always be met however, which leads to situations of congestion.<br/><br/>This thesis seeks to reduce this congestion by means of optimising the grid topology in line with the seasonal variations in the supply and demand of electricity. This is done by means of implementing a two-stage reconfiguration algorithm. The benefit of network reconfiguration is that it is a short-term and low-cost solution which can be implemented by the DSO without relying on other external parties. <br/><br/>In the first stage of the reconfiguration algorithm, the positions of the normally open switches within the network are optimised in order to adjust the power flow therein. These optimised positions are subsequently used in the second stage to calculate the network variables. The first stage is implemented as a MILP optimisation in Python, while the second stage consists of a Newton-Raphson calculation in the commercial software PowerFactory. This distinction is made to enhance the accuracy of the final network parameters, while still being able to optimise the switch positions in a deterministic manner.<br/><br/>Rather than day-ahead or real-time reconfiguration, as is often considered in most literature, this thesis focuses on seasonal reconfiguration to accommodate for the manual operation of the switches present within the MV grid in the Netherlands. These manually operated switches severely reduce the frequency by which reconfiguration actions can be performed, but that does not mean that the topology of the grid cannot be enhanced. <br/><br/>The presented reconfiguration algorithm is able to consistently reduce congestion within the analysed network, completely removing it or reducing its severity. It also outperforms two optimisation options in PowerFactory with regards to the objective function value. Those being an iterative exploration of meshes and a genetic algorithm.<br","Congestion; Optimisation; Reconfiguration; Distribution grid; power flow; Stochasticity","en","master thesis","","","","","","","","2023-01-30","","","","Electrical Engineering","",""
"uuid:5375bcbc-8e4e-492c-8a19-f4c1941ef1b5","http://resolver.tudelft.nl/uuid:5375bcbc-8e4e-492c-8a19-f4c1941ef1b5","&#x1d436;&#x1d442;2 capturing natural fibre reinforced algae-derived polyurethane composites","SHETTY, SOWRABH (TU Delft Aerospace Engineering)","Masania, K. (mentor); Kumru, B. (graduation committee); Delft University of Technology (degree granting institution)","2022","In the past two decades, there has been a substantial increase in the use of natural fibres in bio-composites; these fibres have a Greenhouse gas (GHG) footprint of about 60,000 times less than virgin carbon fibres. The synthesis of polymers from renewable resources is gaining importance as a solution to the critical issues of depleting crude oil reserves and widespread pollution. To date, polymers have been manufactured utilising a vast array of biomass and bio-based platform chemicals. One such polymer is Polyurethaneane. Polyurethane (PU) is typically produced through the reaction of a polyol (polyol polyether or polyol polyester) derived from petroleum with isocyanate. With a few adjustments to the polyols and diisocyanates, the properties of PU can be significantly improved. Due to its adaptability, PU is utilised in many products, such as foam, spandex, coatings, and adhesives. Despite its usefulness, the primary raw material of Polyurethaneane (PU) is petroleum-based material which is nonrenewable and has low biodegradability, resulting in severe environmental problems. Cellulose, vegetable oil, lignin, proteins and starches are all biological components that can be used in the synthesis of Polyurethaneane (PU). These biomass materials are advantageous because they are abundant, inexpensive, high-yielding, and have a minimal environmental impact. The primary focus of this study is new developments in synthesising polyols from biomass and their use in PU materials. The primary goal of this research is to characterise a PU produced from algae biomass and utilise this to manufacture a prototype composite material. Whilst also studying the amount of carbon dioxide embodied in the system. The thesis aims to conclude that bio-based resin systems can produce good mechanical properties while reducing environmental impact.","Natural fibre composites; Algae based resin; Embodied CO2","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:910a9a84-40f6-4a9e-a993-14a7b5d623e8","http://resolver.tudelft.nl/uuid:910a9a84-40f6-4a9e-a993-14a7b5d623e8","Groupwise registration for longitudinal MRI analysis of glioma based on deep learning","Chinea Hammecher, Claudia (TU Delft Mechanical, Maritime and Materials Engineering)","Vos, F.M. (mentor); Bron, Esther E. (mentor); Li, Bo (mentor); Delft University of Technology (degree granting institution)","2022","Glioma progression is monitored by routine MR scanning, enabling tumor growth evaluation with respect to earlier time-points. This growth may present both as a mass effect and as an extension of abnormalities into previously healthy tissue. To accurately quantify tumor growth and tumor-induced deformations, longitudinal intrasubject image registration is often used. However, such registration in cases with large deformations and tissue change is highly challenging. Longitudinal image registration may benefit from groupwise strategies in which multiple images are concurrently aligned. This avoids introducing bias towards an a priori-selected reference image. However, existing learning-based methods for image registration mostly concern pair-wise approaches. Moreover, the few proposed learning-based methods for groupwise registration are designed for the analysis of images without pathologies and are prone to fail to register glioma images. <br/>To bridge this gap, we present a learning-based method for the non-linear registration of longitudinal glioma images. We adapt an existing learning-based groupwise method to handle tumor infiltration by means of cost-function masking. The proposed method is able to register glioma images despite the presence of non-correspondences across the time-points by focusing on the normal-appearing tissue similarity. We train the framework both in one resolution and with a multi-stage strategy exploring multiple resolutions. <br/>We evaluate on a dataset from the Glioma Longitudinal AnalySiS consortium and compare it to conventional groupwise registration methods. We achieve comparable Dice coefficients, with higher SSIM and more detailed registrations. These evaluation metrics are further improved when trained as a multi-stage method. The proposed framework preserves the diffeomorphic conditions and the geometric centrality of the deformation fields, while significantly reducing the runtime to under a minute. The proposed methods may serve as an alternative to conventional toolboxes to provide further insight into glioma growth.<br","Image registratiion; Groupwise registration; Deep Learning; Glioma; Cost-function masking","en","master thesis","","","","","","","","2023-12-01","","","","Biomedical Engineering","",""
"uuid:b19bab9d-f06c-41a2-a226-006734731494","http://resolver.tudelft.nl/uuid:b19bab9d-f06c-41a2-a226-006734731494","Testing a Thermal Dispersion-Based Upscaling Method for Geothermal Reservoir Simulation","van Nieuwkerk, Pelle (TU Delft Civil Engineering & Geosciences)","Rossen, W.R. (mentor); Daniilidis, Alexandros (mentor); Tang, J. (mentor); Delft University of Technology (degree granting institution)","2022","The United Nations’ Paris Agreement forces nations and industries to transition from conventional hydrocarbon-based energy sources to more sustainable and less-emitting alternatives such as geothermal energy. Geothermal doublets are used to provide a source of green heat to greenhouses and residential buildings. In industry, reservoir simulators are used to make predictions about the energy production and thermal lifetime of such a geothermal project; however they can be computational expensive. Upscaling approximates the expensive fine-grid simulation and reduces the necessary computational power, but is by definition not mathematically exact. This thesis tests a newly derived thermal dispersion-based upscaling method, referred to as Taylor-based upscaling, and compares it to conventional arithmetic upscaling and a reference fine-grid simulation. The upscaling methods are applied on reservoir descriptions from the Margretheholm-1A and the HON-GT-01 reservoirs, and simulations are done using Delft Advanced Research Terra Simulator (DARTS). The reservoirs are modelled as 2D layer-cake models in the form of a geothermal doublet with a fine longitudinal resolution, 1000 grid blocks between injector and producer, to minimize numerical dispersion. The results are presented as 2D-temperature profiles and breakthrough-curves. The deviations are quantified in the form of L2-norm calculations and by comparing the amount of days it takes for each upscaling method to reach a 1◦C or 5◦C drop in production temperature. The results show that arithmetic upscaling underestimates the spreading of the cold-temperature front leading to later breakthrough, whereas Taylor-based upscaling overestimates this spreading. For the Margretheholm-1A reservoir Taylor-based upscaling mimics the fine-grid reference simulation better compared to arithmetic upscaling, whereas arithmetic averaging performs better for the HON-GT-01 reservoir. Increasing the vertical thermal conductivity (kz ) leads to Taylor-based upscaling coming closer to the fine-grid reference simulation; however different reservoir descriptions require a different kz adjustment. In conclusion, the Taylor-based upscaling method does not outperform conventional arithmetic upscaling for all reservoir descriptions. Also, no universal rule was found for increasing the kz -value to improve the Taylor-based upscaling method.","Geothermal Energy; Reservoir Simulation; Upscaling; Thermal Dispersion","en","master thesis","","","","","","","","","","","","Applied Earth Sciences","",""
"uuid:746aa83f-ddcf-4b8e-8dfb-6ebcc314624d","http://resolver.tudelft.nl/uuid:746aa83f-ddcf-4b8e-8dfb-6ebcc314624d","Flight Dynamics Analytically-Derived Mathematical Model of Tiltrotor Aircraft: The development of an approachable tilt-rotor flight mechanics model, with clearly defined limitations, suitable for performance and piloted flight simulation","Sokołowski, Piotr (TU Delft Aerospace Engineering)","Pavel, M.D. (mentor); Delft University of Technology (degree granting institution)","2022","State-of-the-art tilt-rotor flight mechanics models appear to be inadequate in predicting the flight dynamics behavior across the entire flight envelope due to a lack of experimental data suggesting the need for more generic models. This paper presents a middle ground between model flexibility (genericity) and accuracy. For this purpose a generic 7-degrees-of-freedom tilt-rotor flight mechanics model is derived analytically. A novel ordering scheme is employed ensuring a bounded expression simplification error which is not found in existing tilt-rotor models. The research highlights the effects of the tiltable nacelle on the rotor analytical expressions and static flight mechanics. The model is validated against the XV-15 implementation of the NASA GTRS model showing promising overlap. It is concluded that the tiltable nacelle mainly affects the rotor expressions through the velocity experienced by the rotor hub and blade element, and that the nacelle tilt rate and acceleration are considered significant contributors to many rotor expressions. It is also shown that the nacelle tilt rate has an observable effect on handling and performance. Terms unique to tiltable proprotors are shown to exist, most notably the Coriolis effect of the nacelle tilt on the flapping dynamics. Several assumptions common in tilt-rotor modeling are also shown to be grossly violated. The future recommendation is to incorporate more sophisticated wing, control surface, and fuselage models, while the rotor model should include disk tilt and inflow dynamics, and a non-uniform inflow distribution.","tilt-rotor; tiltrotor; BEM; XV-15; GTRS; analytical; flapping equation; proprotor; flight mechanics; ordering scheme; Haffner","en","master thesis","","","","","","","","2024-11-27","","","","Aerospace Engineering","",""
"uuid:52480fee-a585-4bbe-8785-319b94367ca0","http://resolver.tudelft.nl/uuid:52480fee-a585-4bbe-8785-319b94367ca0","Data-Driven Turbulence Modeling: Discovering Turbulence Models using Sparse Symbolic Regression","van Leeuwen, Elske (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Numerical Analysis)","Heinlein, A. (mentor); Lazeroms, Werner (mentor); van Gijzen, M.B. (graduation committee); Dijkstra, Y.M. (graduation committee); Delft University of Technology (degree granting institution)","2022","Computational Fluid Dynamics (CFD) is the main tool to use in industry and engineering problems including turbulent flows. Turbulence modeling relies on solving the Navier-Stokes equations. Solving these equations directly takes a lot of time and computational power. More affordable methods solve the Reynolds Averaged Navier-Stokes (RANS) equations. <br/>The most commonly used RANS models rely on Linear Eddy Viscosity Models for the Reynolds stress closure. However, this type of modeling does not provide satisfactory accuracy in general problems, which include curvature, impingement and separation. The rapid developments of Machine Learning (ML) in fluid dynamics and the increase of available high fidelity data of turbulent flows led to the introduction of data-driven RANS turbulence modeling. ML-augmented RANS models are promising but often lack generalisability or does not meet the preference of being interpretable. In this thesis, a sparse symbolic regression method has been used to generate interpretable algebraic equations for the non linear anisotropic Reynolds stress. These equations are built from a library of candidate functions of which the best fitting functions are selected by solving a sparse regression problem. <br/>A deeper understanding of this methodology is achieved by creating models using different input features, including a wall damping function to improve near-wall behaviour of the model. Furthermore, different sparse regression problems are investigated, including constrained regression problems for which physical knowledge is used. The discovered models are propagated in a CFD solver to obtain a corrected velocity field.<br/>Most of the discovered models improve the prediction of the Reynolds stress and its anisotropy compared to the $k-\omega$ RANS model. A small number of the discovered models are able to improve the prediction of the streamwise velocity compared to the RANS model. By analysing the discovered models, it is recognised that a specific term in the algebraic model is the basis of an inadequate prediction of the velocity. Furthermore, it is observed that a considerable amount of the implemented models provide an unconverged solution, which is visible as instabilities in the flow variables. Suggestions are given to improve the stability of the models. The discovered models, which include more physical knowledge by applying physical constraints to the regression problem or by including near-wall treatments, give promising results.","Turbulence modeling; CFD; Sparse symbolic regression","en","master thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:b1cad9d4-48e9-4e6e-8760-5aabc3d8bd9f","http://resolver.tudelft.nl/uuid:b1cad9d4-48e9-4e6e-8760-5aabc3d8bd9f","GNNs and Beam Dynamics: Investigation into the application of Graph Neural Networks to predict the dynamic behaviour of lattice beams","Niessen, Lex (TU Delft Civil Engineering & Geosciences)","van der Meer, F.P. (mentor); Gärtner, T. (mentor); Storm, J. (mentor); Taormina, R. (mentor); Delft University of Technology (degree granting institution)","2022","In the past decade, the application of Neural Networks (NNs) has received increasing interest due to the growth in computing power. In the field of computational mechanics, this has led to numerous publications presenting surrogate models to assist or replace conventional simulation methods. A subset of these networks, referred to as Graph Neural Networks (GNNs) impose the graph-like structure of many physical problems as a relational inductive bias. Several time-stepper implementations of these GNNs are reported to be able to simulate the dynamic behaviour of various physical objects. Within this work, it is investigated whether such GNN-based surrogate models can be applied to simulate the dynamic behaviour of lattice structures.<br/>Upon inference of such a GNN surrogate model, the computational time required for studying lattice behaviour could be considerably reduced, thus advancing research into lattice structures as metamaterials. In addition, many large-scale structures also form a composition of beams, which could be modelled with a similar GNN. <br/>To this end the following research question was defined: ”To what extent can GNNs be applied to simulate the dynamic behaviour of lattice structures using time-stepper methods?”. To answer this question, several GNN architectures were constructed and subsequently analyzed.<br/><br/>In this research, it was found that the complexity of lattice structures could not be modelled in such a way as to obtain reliable, generalisable and stable behaviour, using a time-stepper method with an architecture similar to that of Pfaff et al., 2020. It was found that due to the existence of three physically different coupled Degrees of Freedom (DOF) per node the behaviour was too complex to learn for the proposed surrogate.<br/>At the time of writing, there is no publication presenting an effective surrogate model to simulate the dynamic behaviour of a Timoshenko beam using time-stepper methods. It is concluded that the need to capture both bending and shear behaviour using a Timoshenko beam formulation is the bottleneck for successfully modelling lattice structures.","Dynamic modelling; Graph Neural Networks; Timoshenko; Lattice structures; Surrogate Model; Time-stepper method","en","master thesis","","","","","","","","","","","","Civil Engineering","",""
"uuid:05b6a25d-c393-47e3-b375-8bdd1027284a","http://resolver.tudelft.nl/uuid:05b6a25d-c393-47e3-b375-8bdd1027284a","A durable in-car interface design for future Lightyear models: A user-centered approach in avoiding obsolescence of the in-car experience ","Hermans, Justus (TU Delft Industrial Design Engineering; TU Delft Human-Centered Design)","Kets, W.F. (mentor); van Kuijk, J.I. (graduation committee); Delft University of Technology (degree granting institution)","2022","i>A significant problem within the automotive industry and for in-car interfaces in general, is the fact that the in-car user experience becomes obsolete at a much faster pace over time compared to the potential lifespan of the car itself. Moreover, there is also a societal future need for long lasting products in order to have a positive impact on sustainability to achieve the goals as decribed in the EU Road Map to a Resource Efficient Europe by 2050 (Cooper, 2010)(den Hollander 2014). Both these statements form the personal incentives and indicate its relevance. This project aims at developing a design proposal of a durable in-car interface for future Lightyear models. This proposal is based on updateability by designing a both physically and digitally updateable in-car interface. The design process is done through a user-centered approach which can be utilized for future designs of in-car interfaces or as a approach in itself.</i><br/><br/><br/><b>Problem </b><br/><br/>When the user experiences a sense of obsolescence of the in-car experience, it causes users no longer<br/>perceiving the interfaces as useful and/or meaningful, which causes them no longer regarding the interfaces as useful and/or meaningful. This results in people perceiving the product as if its no longer relevant although it still has a substantial life to come. For an in-car interface many resources were acquired for development and production purposes. Subsequently, a user-centered design approach of extending product lifetime, is not (yet) focussed on within the automotive industry, and especially not within the design fields of in-car interfaces. <br/><br/><br/><b>Challenge</b><br/><br/>The main challenge is to create a durable in-car interface by doing research, user tests, and apply design principles within in-car interfaces to manage obsolescence of the in-car user experience. <br/><br/><b>Literature Studies</b><br/><br/>In order to come up with a suitable concept, extensive literature research, context research, future framing, evaluation sessions, and user tests are done in order to identify design principles that a conceptual solution can be built upon. The concept includes three main principles based on existing literature and methods for managing obsolescence described by the following typologies:<br/><br/>- Extended Use<br/>- Recovery<br/>- Long Use<br/><br/>These principles are named this report respectively: Smart Support, User as Creator, and Concept of Time. <br/><br/><br/><b>Research &amp; Evaluation</b><br/><br/>The user evaluation sessions and user tests provide insights in use and to validate interaction design principles. Three principles have been tested in order to establish clear guidelines for the final design proposal. The objective of the user tests was to gain knowledge about to what extent these principles facilitate the user’s behaviour, needs, wants, expectations, and preferences.<br/><br/><br/><br/><b>Design Proposal </b><br/><br/>After the evaluation and testing phase a clear design proposal can be formulated. It is concluded that the design of an in-car interface should have a supporting system that analyzes the use and gives feedback and recommendations on the basis of a performed analysis by this sytem which is customized to the users average rides and interface use. Secondly the design should have a modular principle aiming at updating physical functional modules. Lightyear should provide installation support for updating physical modules and/or panels. In terms of payment, most users prefer paying by one time purchase for (physical) updates over time, to make a well considered decision on what and when to update. <br/><br/><br/><b>Essential Factors </b><br/><br/>In order to solve the problem, it requires not only a new way of designing in-car interfaces, but also demands to rethink product lifecycle management, product value proposition, and a circular business model in order to enable successful implementation. Though the prospect of this needed change starts by a change in mindset on durability of the in-car experience for both the future user as well as Lightyear as a company. ","Automotive; Obsolescence; Durability; In-car interface; Interface Design; Human Machine Interaction; User-Centered Design; User Experience; Sustainability; Sustainability strategy; Circular Business Model","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:aadb7e34-62af-47bb-86bc-8ccb6dd44cd8","http://resolver.tudelft.nl/uuid:aadb7e34-62af-47bb-86bc-8ccb6dd44cd8","Adjustment of the MDAO Problem Formulation using Sensitivity Analysis to Reduce the Computational Cost within Aircraft Design","Rein, Max (TU Delft Aerospace Engineering)","Bruggeman, A.M.R.M. (mentor); la Rocca, G. (mentor); Delft University of Technology (degree granting institution)","2022","The increasing complexity of aeronautical systems and the prevailing focus to develop sustainable technological innovations for future aircraft configurations and technologies have emphasized a particular demand on advancing the Multidisciplinary Design Analysis and Optimization (MDAO) technique. MDAO addresses the complex synergy within aircraft design where multiple coupled disciplines and domains need to be efficiently analyzed and optimized. Considerable developments within MDAO have already generated a significant time reduction for setup and solving of an MDAO problem and consequently in lead time and costs of aircraft design. For example, through the introduction of the software KADMOS (Knowledge-and graph-based Agile Design for Multidisciplinary Optimization System), that can automatically formulate MDAO workflows based on a repository of tools. The aims of this thesis are to further enhance the current application of MDAO for aircraft design and to alleviate the significant computational expense of MDAO problems through the consideration of sensitivity data during the MDAO formulation phase. Therefore, two approaches where the generation and evaluation of sensitivity information play a key role, were evaluated within this thesis, with the subsequent goal to shorten the MDAO execution time. Through the development and the following implementation of a sensitivity analysis tool into the sequencing and decomposition algorithms of KADMOS, this thesis demonstrated a new contribution to investigate on how to adjust the MDAO problem formulation. Sequencing is defined as the execution order and decomposition is the distribution of disciplines over various partitions. Furthermore, sensitivity information was used to identify the non-influential design variables respective to the objective during the MDAO problem formulation. Thus, during this thesis two independent methodologies were created in which the first methodology used a global sensitivity method to identify non-influential design variables, while the second methodology used a local sensitivity method to enhance the sequencing and decomposition algorithms of KADMOS. The methodologies were tested on an aircraft design problem and efficiently demonstrated the identification and removal of low sensitivity design variables from the problem formulation, with minor impact on accuracy. Overall, this thesis demonstrated that although incorporating sensitivity information in the MDAO problem formulation phase is advantageous, the computational effort to perform the sensitivity analysis may diminish the benefits.","Multidisciplinary Design Optimization; Sensitivity Analysis; Aircraft design; KADMOS","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:506e0492-c679-4c9d-997b-0cf7a06a7802","http://resolver.tudelft.nl/uuid:506e0492-c679-4c9d-997b-0cf7a06a7802","A Numerical Analysis of the Flow in a Carousel Wind Tunnel in Martian Atmospheric Conditions","Van Dam, Stijn (TU Delft Aerospace Engineering)","Avallone, F. (mentor); de Vet, S.J. (graduation committee); Michelis, Theodorus (graduation committee); Ragni, D. (graduation committee); Delft University of Technology (degree granting institution)","2022","With new rovers landing on Mars, like the Perseverance rover in 2020, the interest in Mars has grown recent years. The atmospheric conditions on Mars result in challenging conditions due to its low density atmosphere and extremely low temperatures. With a density on Mars that is 1% of that on Earth, creating sufficient lift for vehicles to fly becomes a challenge. The low density results in low Reynolds numbers. The low temperature has an effect on the speed of sound, due to which the Mach number is significantly higher at the same flow velocity compared to Earth. Airfoil data at these conditions, low Reynolds number - high Mach number, are sparse, but crucial for design of aerial vehicles. Next to the aerodynamic conditions, dunes on Mars are formed and migrate. The parameter of interest which defines the conditions required for transportation of particles is the threshold shear velocity. This parameter has been determined by different analytical expressions. However, the outcome remains a broad range, which point out the difficulty and inaccuracy of the results. Therefore, in this document, the design of a carousel wind tunnel is investigated to determine its feasibility to perform aerodynamic and aeolian measurements. The carousel wind tunnel consists of two concentric drums, of which the inner one rotates. The carousel wind tunnel is analysed by a computational fluid dynamics analysis with the k - ω turbulence model. The results indicate that due to secondary flow effects and the wake of a test object, no accurate aerodynamic measurements can be performed. Aeolian measurements are deemed feasible, with increased accuracy at sufficiently high rotational velocities.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:dea317b8-57ba-4072-bd36-fd9408c7a5c8","http://resolver.tudelft.nl/uuid:dea317b8-57ba-4072-bd36-fd9408c7a5c8","Wall-normal pores for turbulent drag reduction: Experimental investigation into drag performance and flow mechanics","JAWAHAR, SAHANA (TU Delft Aerospace Engineering)","van Oudheusden, B.W. (mentor); Schrijer, F.F.J. (mentor); Avallone, F. (graduation committee); Modesti, D. (graduation committee); van Nesselrooij, M. (mentor); Delft University of Technology (degree granting institution)","2022","class=""MsoNormal"" style=""text-align:justify"">Flat surfaces with arrays of wall-normal pores called micro-cavity arrays have shown potential to reduce turbulent skin friction drag. Their designs have been inspired by acoustic liners which are sandwich panels consisting of a honeycomb core, a perforated top plate and a solid back sheet used on aircraft engine nacelles for noise abatement. Research on acoustic liners has paved the way to identify the parameters that are crucial for optimising the design of micro-cavity arrays. Spanwise rectangular grooves, a special case of cavities, have also shown potential to reduce skin friction drag. This thesis aims to validate the reported drag performance of micro-cavity arrays and grooves through experimental methods used in literature and direct force measurements. </p><p class=""MsoNormal"" style=""text-align:justify"">In this research, experimental results show that although pores and grooves are capable of reducing turbulence energy in the boundary layer, there is a significant drag increase with respect to a smooth reference. Based on measured drag performance and past research on cavity flows, it has been argued that the observed drag increase is caused by pressure forces acting on the inner walls of the pores and grooves. As past research on micro-cavity arrays did not perform direct force measurements, the contribution of pressure drag had not been investigated. Pressure drag is expected to be present and perhaps even dominate over skin friction drag reductions. Further research into the flow mechanics inside the pores is required to validate this argument and find a way to minimise the pressure forces. Wall-normal pores could still be an effective turbulent drag reduction technique if arrays are optimised for skin friction drag reductions that surpass pressure drag.","Turbulent Drag Reduction; Micro-perforated plate; Wall-normal pores; Flow Control","en","master thesis","","","","","","","","2024-12-12","","","","Aerospace Engineering","",""
"uuid:384bdf2f-413c-4a63-91b3-b432c84e0173","http://resolver.tudelft.nl/uuid:384bdf2f-413c-4a63-91b3-b432c84e0173","Modelling and stabilization of coil deposition in intracranial aneurysm treatment: Improving the safety of neurovascular interventions","van der Staaij, Jasper (TU Delft Mechanical, Maritime and Materials Engineering)","Jafarian, M. (mentor); Sakes, A. (mentor); van den Boom, A.J.J. (graduation committee); Della Santina, C. (graduation committee); de Winter, J.C.F. (graduation committee); Delft University of Technology (degree granting institution)","2022","An intracranial aneurysm is a bulge in the cerebral vasculature. The rupture of an aneurysm results in a brain bleed. As a consequence, most patients become severely handicapped or may even die. Preventive treatment with endovascular coiling is controversial due to the high risk of complications. These complications are partly caused by the current uncontrolled delivery of coils to the aneurysm. While recent developments in microcatheter design allow for improved positioning, no method has been devised to model and control the tension applied by the coil on the aneurysm wall throughout a coiling procedure. This thesis aims to come up with a method to improve the safety of aneurysm treatment.<br/><br/>This thesis presents a new way to dynamically model an endovascular coil and its interaction with a microcatheter and the aneurysm wall throughout a coil deployment procedure. The main advantage of this model is its low computational complexity allowing real-time control computation. A control architecture is presented that enables regulation of the contact force between the coil and the aneurysm wall while obeying the constraints imposed by the equipment and the environment. The presented architecture comprises an augmented energy-shaping controller working in parallel with a constraint preservation controller.<br/><br/>This thesis shows that this control architecture asymptotically stabilizes the aneurysm wall tension at the desired value throughout the coil deployment procedure.<br/><br/>This work provides a basis for modelling and control in future experimental validations. Therefore, this work is a promising first step in the modelling and control of robotic systems for neurovascular interventions and a step forward in the preventive treatment of intracranial aneurysms.","Soft Robotics; Intracranial Aneurysms; Endovascular Coiling; Coil Modelling; Passivity-Based Control","en","master thesis","","","","","","","","2023-03-01","","","","Mechanical Engineering | Vehicle Engineering | Cognitive Robotics","",""
"uuid:7b1d012c-fd73-4737-bf66-9d5957cec87c","http://resolver.tudelft.nl/uuid:7b1d012c-fd73-4737-bf66-9d5957cec87c","Hydrodynamic loading of breaking waves on offshore inspection platforms","Pavilons, David (TU Delft Mechanical, Maritime and Materials Engineering)","Wellens, P.R. (mentor); Delft University of Technology (degree granting institution)","2022","The most violent breaking waves cause the largest platform forces at sea, however it is unknown which wave in a sea state leads to these forces if run-up is included. Offshore inspection platforms give access to wind turbine monopiles. They are positioned above mean sea level. Wave interaction with monopiles leading to runup causes vertical impact forces on inspection platforms. Predicting the vertical impact is challenging. The objective of this article is to find the wave in a sea state that causes the largest vertical impact force on a horizontal platform. It is hypothesized that breaking waves will cause the largest vertical forces. Detailed numerical OpenFOAM Volume-of-Fluid simulations are performed to investigate wave breaking interaction with structures. long-crested wave propagation was considered in 2D with a schematized inspection platform, composed of a horizontal deck and a vertical wall above mean sea level – the minimum requirements to still cause wave run-up and a vertical impact. This simplified numerical setup results in high resolution particle velocities that we require for further investigation with the kinematic breaking criterion. A potential flow solver, OceanWave3D, was used to generate a three-hour sea state representative of North Sea conditions. From the sea state, 17 waves were selected based on the kinematic breaking criterion and their surface elevation. The selected waves were fed into an OpenFOAM domain with and without structure to determine their breaking index, particle velocities and forces on the structure. This is the first study to use the breaking index as a screening parameter for critical wave selection. The three waves causing the largest forces on the structure were simulated again with the structure present at various horizontal positions relative to the point of wave overturning. The wave with the highest surface elevation and the highest breaking index overturning one third of the peak wave length before the inspection platform caused the largest vertical forces. This is due to the strong relation between impacts loads and the free surface particle velocity","breaking waves; platform impacts; breaking index; Hydrodynamic loading; breaking strength; free Surface velocity","en","master thesis","","","","","","","","","","","","Marine Technology","",""
"uuid:650f171a-ddb6-4795-8afb-f94950caf3ec","http://resolver.tudelft.nl/uuid:650f171a-ddb6-4795-8afb-f94950caf3ec","AudioLocNet: Deep Neural Network Based Audio Source Localization for Inter Robot Localization","van der Horst, Casper (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Embedded and Networked Systems)","Venkatesha Prasad, Ranga Rao (mentor); Rajan, R.T. (graduation committee); Amjad Yousef Majid, Amjad (graduation committee); Delft University of Technology (degree granting institution)","2022","For my Master’s thesis, I developed and trained an audio-based localization system for indoor localization called AudioLocNet. AudioLocNet is based on convolutional neural networks and maps recordings from a small(10cm diameter) microphone array to a grid of locations around said array. AudioLocNet was made to be used by swarms of small robots to locate each other using audio signals. AudioLocNet was trained using orthogonal chirp signals which have a low cross-correlation. Said signals can also be used for simultaneous communications between multiple robots. These signals were recorded in indoor environments ranging from simple line-of-sight environments to reverberant non-line-of-sight ones. Audio signals are used since they form a propagational middle class when compared to radio frequency (RF) and light-based signals for localization. Whereas light requires a line of sight, audio can bend around corners; and whereas RF signals pass through walls, reaching robots that are outside of each other’s spheres of influence, audio will not.<br/>AudioLocNet reaches high accuracies for both a coarse grid (99.96 %) and a fine grid (99.89 %) of possible locations, where only the final layer of the network architecture must be changed to account for the increased resolution of the fine grid.","Sound Source Localization; DNN; Swarm Robotics","en","master thesis","","","","","","","","","","","","Electrical Engineering | Embedded Systems","",""
"uuid:012701f3-c578-4abc-a91c-8c1432c9364f","http://resolver.tudelft.nl/uuid:012701f3-c578-4abc-a91c-8c1432c9364f","Product Life Extension Strategies for PV in the Netherlands: Theory and Practice","Haak, Youri (TU Delft Technology, Policy and Management)","Peck, David (mentor); Sprecher, B. (graduation committee); Delft University of Technology (degree granting institution); Universiteit Leiden (degree granting institution)","2022","The EU has set out to reduce negative impacts from electricity generation on the environment, human health and towards our dependence on fossil fuels. As the fastest growing renewable source of electricity, photovoltaics plays an important role in the energy transition. The manufacturing of photovoltaic modules requires materials classified as critical, making them prone to supply disruptions. Although these materials are essential to the EU economy, they are not sufficiently recovered at the end of a photovoltaic module’s life. An alternative intermediate solution could be to extend the lifespan of existing modules, to slow down demand for these materials in the future.<br/>The aim of this study was to analyse the theoretical options and practical examples of product life extension strategies for photovoltaics. The R-Ladder was used as a guiding framework, which provided examples of life extension strategies. These include Reuse, Repair, Refurbishment, Remanufacture and Repurpose. Aspects for each of these strategies were analysed to find potential benefits and challenges related to four aspects: economics, environment, energy, and materials.<br/>The approach of this study includes a literature review to identify the life extension strategies discussed specifically for photovoltaics in the context of the circular economy. This was followed by a multi-case study on practical applications of Reuse, Repair and Repurposing of photovoltaic modules. Findings from literature and the case study were further supplemented with the insights from six experts. These experts had diverse backgrounds in research, manufacturing, and procurement to offer a variety of insights and perspectives on life extension strategies for photovoltaics. Finally, two scenarios were created for possible life extension pathways for used photovoltaic modules to illustrate the potential impacts compared to a commonplace premature replacement scenario.<br/>Economics and module performance are key factors in decision-making and acquisition of a photovoltaic system. Reuse offers a compelling alternative to current recycling capabilities but offers no sufficient business case. Repair may extend a module’s lifespan to continue the generation of renewable electricity but is only possible in cases of minor damage for which replacement parts are available. Refurbishment could restore more severe damage but is limited by economies of scale and the technical difficulties resulting from current photovoltaic module design. Remanufacturing has the potential to restore a solar cell’s original performance or even upgrade it using newer processing methods but suffers from the same design limitations as Refurbishment. Repurposing used modules can offer a pathway to extract the remaining capacity if it is implemented in a context where generation density is of no concern. Combined, these strategies could buy time to address the resource challenges amplified by the energy transition.","Circular Economy; Critical Raw Materials; Energy Transition; Photovoltaics; Product Life Extension","en","master thesis","","","","","","","","","","","","Industrial Ecology","",""
"uuid:da76403e-5c81-4273-891e-d11de7c7a948","http://resolver.tudelft.nl/uuid:da76403e-5c81-4273-891e-d11de7c7a948","Thermal ablation of primary liver tumors: Correspondence of the predicted ablation zone with the clinically obtained ablation zone","van Erp, Gonnie (TU Delft Mechanical, Maritime and Materials Engineering)","Burgmans, Mark (mentor); Broersen, Alexander (mentor); Hendriks, Pim (mentor); Klein, Stefan (graduation committee); Scherptong, Roderick (graduation committee); Delft University of Technology (degree granting institution); Universiteit Leiden (degree granting institution); Erasmus Universiteit Rotterdam (degree granting institution)","2022","b>Purpose</b> Manufacturer’s predictions of ablation zone dimensions are the current directives for treatment planning in thermal ablation, while they are mostly based on ex vivo experiments making its reliability questionable. The aim of this study is to determine the correspondence in dimensions, volume, shape and overlap of the manufactures’ predicted with the clinically realized ablation zones following thermal ablation of hepatocellular carcinoma (HCC). The secondary objective is to determine the effect of tumor- and liver characteristics on this correspondence.<br/><b>Methods</b> Data was retrospectively collected from two prospective studies. A registered pre-ablation and post-ablation computed tomography scan with liver, tumor and ablation zone segmentations were available for analysis. Needle position reconstruction was performed based on image visual assessment (e.g., gas formation, tumor location and subcapsular hemorrhage) using in-house developed software. The dimensions of the predicted ablation zone were derived from the manufacturer’s chart corresponding to treatment settings used during ablation. The long axis diameter (LAD), short axis diameter (SAD) and volume of the realized and predicted ablation zone were compared. The overlap was determined using the Dice similarity coefficient (DSC) and the average surface deviation between the realized and predicted ablation zone. The effect of tumor location, vascular proximity and liver cirrhosis on the overlap was quantified using the DSC and average surface deviation.<br/><b>Results</b> Nineteen patients and 21 ablations were included for analysis. The median realized volume did not significantly differ from the predicted volume, 25.7 cm3 and 22.6 cm3 respectively (p = 0.526). The median LAD and SAD of the realized ablation zone differed significantly from the manufacturer’s prediction (51.9 mm vs 40.0 mm, p&lt;0.001 and 36.9 mm vs 35.0 mm, p&lt;0.001 respectively). The predicted ablation zone corresponds to the realized ablation zone with a mean DSC of 0.73 and mean average surface deviation of 3.04 mm. Tumor location and vascular proximity did not affect the overlap between the realized and predicted ablation zone. The effect of liver cirrhosis was not assessed due to a low sample size of HCC in a non-cirrhotic liver (n=2).<br/><b>Conclusion</b> The manufacturer’s predicted volume of liver ablation zones corresponds well to the clinically realized ablation volume. However, the LAD and SAD are underestimated by the manufacturers. The shape and overlap of the predicted and realized ablation zone were sufficient. Further studies evaluating the effect of tumor- and liver characteristics on the correspondence of the predicted with the realized ablation zone with a larger patient cohort is needed.","Thermal ablation; Hepatocellular carcinoma; Ablation zone","en","master thesis","","","","","","","","2024-08-01","","","","Technical Medicine | Imaging and Intervention","",""
"uuid:39092c92-a849-4eb0-9649-8356ec5798f1","http://resolver.tudelft.nl/uuid:39092c92-a849-4eb0-9649-8356ec5798f1","The Development of a Dashboard to Optimise Neuromonitoring of Paediatric Traumatic Brain Injury Patients in the Intensive Care Unit","Formsma, Bart (TU Delft Mechanical, Maritime and Materials Engineering)","Kuiper, Jan Willem (mentor); Schouten, A.C. (graduation committee); de Jonge, Rogier (graduation committee); van Twist, Eris (graduation committee); Delft University of Technology (degree granting institution); Erasmus Universiteit Rotterdam (degree granting institution); Universiteit Leiden (degree granting institution)","2022","b>Introduction</b> Traumatic brain injury (TBI) is a leading cause of childhood morbidity, disability and mortality worldwide. In the treatment of TBI, neuromonitoring is essential to prevent secondary neurological damage. However, the use of neuromonitoring and specifically therapeutic targets is currently limited evidence-based.<br/><b>Objective </b>The primary objective is to implement suitable neuromonitoring parameters into a novel bedside dashboard for paediatric TBI patients. In addition, basic insights into neuromonitoring parameters between different outcome groups are provided.<br/><b>Methods</b> Intracranial pressure (ICP), cumulative ICP (ICP<sub>cum</sub>), cerebral perfusion pressure (CPP), pressure reactivity index (PRx), wavelet transform PRx, optimal CPP (CPP<sub>opt</sub>), partial pressure of arterial oxygen (P<sub>a</sub>O<sub>2</sub>), partial pressure of arterial carbon dioxide (P<sub>a</sub>CO<sub>2</sub>), end tidal CO2 (etCO<sub>2</sub>), temperature and sodium levels were implemented into a dashboard. The parameters (except wPRx) were retrospectively analysed in TBI patients admitted to the paediatric intensive care unit (PICU) of the Erasmus MC- Sophia. Patients were divided into a good (GO) or bad (BO) outcome group. Per outcome group, the mean and 95 % confidence interval or the median and interquartile range of parameters were calculated.<br/><b>Results</b> A total of 35 patients (24 GO, 11 BO) were included. Significant differences between GO and BO were observed in median PRx (-0.06 [-0.13 – 0.01] vs. 0.17 [-0.05 – 0.39]), median percentage outside of the CPP<sub>opt</sub> (curve) range (15 % [4 – 26] vs. 30 % [26 – 34]), ICP<sub>cum</sub> distributions (12.0 mmHg [8.0 – 16.0] vs. 12.0 mmHg [8.5 – 15.5]) and mean sodium levels (146.4 mmol/L (144.5 – 148.3) vs. 151.2 mmol/L (148.6 – 153.8)).<br/><b>Conclusion</b> In a retrospective analysis, PRx, CPP<sub>opt </sub>(curve) and ICP<sub>cum</sub> showed potential to improve prognostication for paediatric TBI and to determine therapeutic targets. Based on our results, we recommend implementing MAP, ICP, ICP<sub>cum</sub>, CPP alongside CPP<sub>opt</sub> (curve), and sodium levels in a future neuromonitoring dashboard.<br","Neuromonitoring; Paediatric traumatic brain injury; Paediatric Intensive Care Unit","en","master thesis","","","","","","","","","","","","Technical Medicine | Sensing and Stimulation","",""
"uuid:89c50252-9d6a-4653-a252-4407e4661e58","http://resolver.tudelft.nl/uuid:89c50252-9d6a-4653-a252-4407e4661e58","A proof-of-concept on Adaptive Control for High-Speed Atomic Force Microscopy","van der Maarel, Stefan (TU Delft Mechanical, Maritime and Materials Engineering)","Verbiest, G.J. (mentor); Noom, J. (mentor); Smith, C.S. (mentor); Alijani, F. (graduation committee); Delft University of Technology (degree granting institution)","2022","High-Speed Atomic Force Microscopy is widely used for investigating biological architectures and the semiconductor industry. The main limitation comes from parachuting or the Wile E. Coyote effect. Parachuting is the phenomenon where the cantilever taps on the sample towards a steep decrease in height, but does not get adjusted for this decrease fast enough, resulting in poor imaging quality at higher scan speeds. A proof-of-concept has been modeled for an adaptive raster scanning methodology on the X and Y piezo actuators. There will be investigated how a variable scan speed can decrease the effect of parachuting and thereby improve the spatial resolution. A detection algorithm is designed to measure the parachuting and uphill events at high scanning speed as accurately and precisely as possible during the forward scan. This has been done by defining a mixed signal that multiplies the first and second derivatives of the filtered deflection signal. A variable scan speed will be applied for the backward scan. The detection algorithm turned out to have a very high repeatability of 97.1% for the uphill events, and 93.6% for the parachuting events. Its accuracy turned out to have a maximum deviation of one signal period, which has been accounted for within the controller. Implementing this for the adaptive controller results in an improvement in both resolution and time efficiency. The adaptive controller is up to 9.5 times more accurate and time efficient compared to conventional methods.","Atomic Force Microscopy; AFM; HS-AFM; High-Speed Atomic Force Microscopy; Adaptive Control; Variable Speed; Parachuting; Spatial Resolution","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Precision and Microsystems Engineering | High-Tech Engineering","",""
"uuid:d36e15d4-e99a-4938-8f11-088da4fb3278","http://resolver.tudelft.nl/uuid:d36e15d4-e99a-4938-8f11-088da4fb3278","The design of an intuitive interface for the GyBAR: Simplifying the controls of a balance assistance device for optimal adoption by physical therapists","Estrada, Daniela (TU Delft Mechanical, Maritime and Materials Engineering)","Poggensee, K. (mentor); Sterke, B.T. (mentor); Vallery, H. (graduation committee); de Winter, J.C.F. (graduation committee); Delft University of Technology (degree granting institution)","2022","According to the WHO, falls are responsible for over 38 million disability-adjusted life years lost each year, globally. Additionally, an estimated 684.000 individuals die of falling each year, making it the second leading cause of unintentional death. One of the most effective physical activity interventions to reduce the risk of falling, is targeted exercise that safely challenges balance. One tool, that is currently<br/>being developed, which can aid physical therapists with these interventions is the GyBAR. A wearable device that uses gyroscopes to apply moments to the patient. This can be used to either provide balance assistance or challenge balance by applying perturbations. The goal of this research was to develop an interface for the GyBAR. The interface should contribute to the acceptance of the GyBAR. This can be achieved by an excellent perceived ease of use, which combined with perceived usefulness<br/>are indicators for the Technology Acceptance Model (TAM). The interface inspired by a Voodoo-doll was developed by going through the following design process steps; the creation of a list of requirements; a brainstorm to generate ideas; the development of three concepts; and the selection and development of one concept into a prototype. The Voodoo Doll controls the GyBAR by a handheld model of the patient, which can be manipulated and translates the movements of the model to the actual patient. User tests were performed to validate the design. With a SUS-score of 82.81 (SD=7.48), which is within the 90-95 percentile, it can be concluded that the interface has an excellent perceived ease of use. Further development is encouraged are several recommendations for points of improvement are given.<br","Interface design; Technology Acceptance Model; Balance assistance; GyBAR","en","master thesis","","","","","","","","","","","","Biomedical Engineering","",""
"uuid:8348ea1f-289c-4bc5-a031-455cd6efdcec","http://resolver.tudelft.nl/uuid:8348ea1f-289c-4bc5-a031-455cd6efdcec","Automated Spray Deposition Platform for Additive Manufacturing of P(VDF-TrFE CTFE) Actuators","IJssel de Schepper, Stijn (TU Delft Mechanical, Maritime and Materials Engineering)","Hunt, A. (mentor); Delft University of Technology (degree granting institution)","2022","Unlike conventional actuators, unimorph bending cantilever actuators rely on deformation of bulk material, and therefore require no complex mechanisms or moving components. This allows for simple fabrication, and makes them suitable for miniaturisation. This enables various applications not feasible or practical with conventional actuators, including microrobots, embedded sensing, deformation control, and vibration suppression. Conventional methods used in EAP actuator manufacturing include screen printing, spin coating, and photolithography. These methods are implemented manually, and are not suitable for development of tailored designs. Inkjet printing has shown to be successful in automation and fabrication of tailored designs, but is limited to deposition of material within a narrow range of rheological properties. Spray deposition has been successfully used in EAP manufacturing, but was implemented manually, lacking the repeatability and precision of automation. The objective of this study is to develop an platform and process for automated manufacturing of EAP actuators with both single and multiple active layers. An additive manufacturing platform was designed and built based on a 3D printer platform and two fluid atomizer. The resulting platform is capable of printing at resolution of &gt;0.5 mm and capable of atomizing polymer solutions with loading factor of 7% at a cost of &lt;€1000. Using the platform, unimorph bending cantilever actuators with single and multiple active layers were manufactured based on the P(VDF- TrFE-CTFE) EAP and carbon black electrodes. The actuators dimensions were 18x4 mm, whereas 17.5x3 mm was the active area covered by the top electrode. The fabricated actuators achieved maximum steady state deflection of 720 μm at 440V. This represents a 149% improvement in deflection, and a 139% improvement in strain per volt compared to actuators of similar dimensions and materials from previous studies. The platform’s ability for repeatable deposition of materials with wide range of material properties at multi scale resolution and deposition rates, combined with low cost and simplicity, offers great outlooks for additive manufacturing of EAP actuators of both ionic and electronic type, and other stimuli-responsive devices.","P(VDF-TrFE-CTFE); Spray; Deposition; Additive; Manufacturing; Actuators; EAP","en","master thesis","","","","","","","","2024-12-09","","","","Mechanical Engineering | High Tech |Mechatronic System Design","",""
"uuid:681c8107-d527-48a6-a62e-83cef97c24c5","http://resolver.tudelft.nl/uuid:681c8107-d527-48a6-a62e-83cef97c24c5","Involving older adults with an intellectual disability in the design process of the MakiMove: a modular intervention for stimulating physical activity","Adriaanse, Kim (TU Delft Industrial Design Engineering)","Kraal, J.J. (mentor); Vegt, N.J.H. (mentor); Oppewal, Alyt (mentor); Bunskoek, Marije (mentor); Delft University of Technology (degree granting institution)","2022","Regular physical activity helps to improve the health, fitness and quality of life of people, and prevent or decline aging related health issues. The amount of physical activity in older adults with an intellectual disability is extremely low. Contextual research indicates that this physical inactivity stems, among other things, from previous negative experiences, the habit of being inactive, limitations related to the cognitive and physical disability, and interventions that are not taking into account these limitations. These barriers emphasize the client’s dependence on an external incentive to become physically active, but caregivers of the clients lack time to provide this stimulus. Along with an increased life expectancy of people with an intellectual disability, this increases the need for a physical activity intervention that suits the individual abilities and interests of the clients, while asking minimal time from the caregivers.<br/><br/>Many interventions that have been created for stimulating physical activity in people with an ID, are either not adapted to people of an older age, or not created in (creative) collaboration with the older adults. This project is therefore carried out in close collaboration with six older adults with an intellectual disability, and their caregivers.<br/><br/>Literature and context research showed the current barriers and motivators towards physical activity, from the perspective of the clients, the caregivers, and the physiotherapist in this context. A research through design approach, consisting of creative sessions together with clients, caregivers, and other experts, resulted in a design that is adapted and adaptable to the diverse group of older adults. The design intervention proposed in this project is called the ‘MakiMove’.<br/><br/>The MakiMove is a large, vertical game board that offers fun and active activities to older adults with intellectual disabilities. The product provides a positive experience to the older adults, and simultaneously increases their physical activity. The variety of activities and difficulty levels make the design adaptable to the abilities and interest of the individual client.<br/><br/>Although the MakiMove allows the client to move without much assistance, it is not possible to interact with the concept completely independent of a caregiver or other supervisor. With social contact and encouragement being valuable facilitators for the client, it is questioned whether independent physical activity is the road to take. On this basis, it is recommended to look into how to enable caregivers or other supervisors to play a role in increasing the physical activity of the older adults.<br/><br/>To create a successful experience, it is important to adapt a design to the client’s abilities and interests. To get to know the clients well, they should be involved in the design process. The experiences in this project have led to guidelines for collaborating with the target group, aiming to inspire future researchers and designers to involve this increasing population of older adults with an intellectual disability in their projects.<br","Physical Activity; Intellectual disability; older adults; Research through Design","en","master thesis","","","","","","","","","","","","Design for Interaction","",""
"uuid:ec8b769a-84cb-4133-9ded-9acd8438e67c","http://resolver.tudelft.nl/uuid:ec8b769a-84cb-4133-9ded-9acd8438e67c","Lignin epoxy resins: synthesis and evaluation as coatings and composites","Santana Martin, María (TU Delft Mechanical, Maritime and Materials Engineering)","Picken, S.J. (mentor); Gonzalez Garcia, Y. (mentor); van Rijn, J. (mentor); Filonenko, G.A. (graduation committee); Delft University of Technology (degree granting institution)","2022","Epoxy resins are one of the most relevant and widely used thermosets in the market covering a wide range of applications. Industries are being forced to quickly transition towards sustainable alternatives due to the pressure from emerging environmental concerns, the depletion of petrochemical supplies, and compliance with environmental legislation. Since the primary component of epoxy resins is derived from petroleum (Bisphenol A (BPA)), companies like Westlake Epoxy have joined the search for innovative, environmentally friendly solutions. Many bio-based substitutes have surfaced in recent years, in efforts to eliminate or reduce the quantity of BPA in epoxy resins. Attention has been focused on lignin biomass as a viable feedstock in the manufacturing of these thermosets because of its large production volume and some structural characteristics.<br/><br/>This study addresses the synthesis of novel lignin-based epoxy resins and the evaluation of their potential application in the field of coatings and composites. For this research, different sources of technical Kraft lignin were employed. Since technical lignin is not very reactive due to the large molecular weight polymers, a Confidential Fractionation process has been developed. For its synthesis, both small- and large-scale glycidation processes were successfully implemented. To understand the chemical structure of lignin and its corresponding resins, different analytical techniques were used such as Gas Chromatography (GC), titrations, Nuclear Magnetic Resonance (NMR), Fourier-Transform Infrared Spectroscopy (FT-IR) and Gel Permeation Chromatography (GPC). Additionally, for the development and characterisation of coatings and composites, a variety of material testing techniques were employed, namely Differential Scanning Calorimetry (DSC), Dynamical Mechanical Analysis (DMA), Thermogravimetric Analysis (TGA), Interlaminar Shear strength (ILSS), Impact testing, Pendulum hardness, among many others. <br/><br/>Experimental results showed an average fractionation yield of 50-60% of technical Kraft lignin using the Confidential Fractionation process. Compositional differences in the fractionated lignin substrates studied via NMR analysis, predict some differences in the reactivity of these substrates towards glycidation, which is supported by different Epoxy Group Content (EGC) of the corresponding epoxy resins. The EGC of the lignin-based epoxy resin is significantly lower than that of the reference resin due to the presence of bulky moieties that hinder the reactivity of active sites. While lignin-based coatings exhibit comparable performance in hardness and direct impact resistance, however, its high viscosity and stiffness results detrimental in other areas. On the other hand, this high viscosity is a major challenge in the processes of prepreg laminates leading to poor adhesion of the fibres to the matrix, which has a negative effect when it comes to mechanical performance. However, adding lignin to epoxy resins has proved to improve the thermal stability of these materials. <br","Lignin; Epoxy Resin; Coating; Composite; Sustainability; Thermosets","en","master thesis","","","","","","","","2024-12-09","","","","Materials Science and Engineering","",""
"uuid:9d9d498b-b53d-46ec-95a9-12a41eb07522","http://resolver.tudelft.nl/uuid:9d9d498b-b53d-46ec-95a9-12a41eb07522","Tensor decomposition for Independent Component Analysis: Through implicit cumulant tensor manipulation","Denarié, Pierre-Antoine (TU Delft Mechanical, Maritime and Materials Engineering)","Batselier, K. (mentor); Hunyadi, Borbala (graduation committee); Delft University of Technology (degree granting institution)","2022","Blind Source Separation (BSS), the separation of latent source components from observed mixtures, is relevant to many fields of expertise such as neuro-imaging, economics and machine learning. Reliable estimates of the sources can be obtained through diagonalization of the cumulant tensor, i.e., a fourth-order symmetric multi-linear array containing the cross-kurtosis values of observed mixtures. The downside of such diagonalization methods is that they scale quartically with the increase of the amount of source components to estimate due to the tensor’s quartic size. Tensor decomposition can simultaneously diagonalize the cumulant tensor and address its size. However, it does not resolve the scalability issue due to the restriction of having to first explicitly compute the tensor.<br/><br/>It is studied how decomposing the cumulant tensor in implicit fashion can be used to solve the BSS problem while simultaneously addressing its scalablity issue. A class of implicit cumulant tensor decomposition algorithms is derived which scale more favorably than their explicit counterparts in terms of either computational cost, storage cost or both. Firstly, a novel QR-Tensor algorithm (QRT) is introduced which allows for the simultaneous diagonalization of a tensor’s outer-slices. It is theoretically shown how an implicit version of the QRT algorithm can be used to solve the BSS problem at a linearly scaling computational cost. Secondly, a fixed-point Canonical Polyadic Decomposition (CPD) iteration method is presented. It reduces the computational complexity from a quartic dependence to a linear dependence on the amount of signals to estimate. The source estimation performance of the devised implicit decomposition methods is compared to that of the state-of-the-art FastICA for an artificial linear BSS problem.<br/><br/>Results show that both fixed-point CPD and QRT are superior to FastICA when it comes to the computation time needed to reach convergence, while producing estimated sources of similar quality. It is shown that when the amount of sources to estimate is increased both QRT and FastICA struggle to converge. In contrast, the fixed-point CPD method converges within a consistent amount of iterations, suggesting a method more suitable for the estimation of a large amount of sources.","Blind source separation (BSS); Fourth-order cumulant tensor; Independent Component Analysis (ICA); Kurtosis; Tensor decomposition; Canonical Polyadic Decomposition; Higher-Order Singular Value Decomposition; QR-Tensor; Implicit decomposition","en","master thesis","","","","","","https://github.com/padenarie/Independent-component-analysis-through-implicit-cumulant-tensor-decomposition.git Github repository containing implementations and experiment code.","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:ce098ccc-4967-4c3b-a84c-d0a9a12a2212","http://resolver.tudelft.nl/uuid:ce098ccc-4967-4c3b-a84c-d0a9a12a2212","Modelling The Greenland Ice Sheet following The Mid-Eemian: A study of the impact of including lateral variations in the sub-Greenland Earth rheology on the GrIS' evolution since the mid-Eemian in a coupled 3D ice sheet and 3D GIA model","Kempenaar, Gydo (TU Delft Aerospace Engineering)","van der Wal, W. (mentor); van Calcar, C.J. (mentor); Delft University of Technology (degree granting institution)","2022","Uncertainty in ice sheet modelling affects centennial and longer time-scale projections of the Greenland Ice Sheet's (GrIS) sea level contribution. One source of this uncertainty is the interaction between the ice sheet’s evolution and the Earth’s deformation in response to changes in the applied surface loading as the ice sheet waxes and wanes. Such deformation, Glacial Isostatic Adjustment (GIA), causes a vertical displacement of the ice sheet’s surface which affects temperature dependent precipitation and ice ablation. The significance of this feedback mechanism depends on the magnitude of GIA which is dependent on the mantle’s viscosity. Studies find that the sub-Greenland mantle viscosity varies in three dimensions which leads to a spatially varying rate of GIA. Results obtained with an ice sheet model coupled with an Earth model including 3D variations in sub-Greenland viscosity illustrate its significant effect on the GrIS’ modelled evolution by affecting both elevation-melt and elevation-precipitation feedback mechanisms.","Glacial Isostatic Adjustment; Greenland Ice Sheet; 3D Rheology; Coupled Ice Sheet and Solid Earth Model","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:81b2faa6-7234-4c81-92a6-aaea09dd6b07","http://resolver.tudelft.nl/uuid:81b2faa6-7234-4c81-92a6-aaea09dd6b07","Implementation of spatial variability in PLAXIS","Pană, Paul (TU Delft Civil Engineering & Geosciences)","van den Eijnden, A.P. (mentor); Brinkgreve, R.B.J. (mentor); Soleymani Shishvan, M. (mentor); Delft University of Technology (degree granting institution)","2022","As a consequence of the difficulty to obtain complete direct information about the subsurface, and the importance of heterogeneity of soil properties in geotechnical design, a desire exists in the geotechnical community for a smarter use of the available data in common practice. The objective of this thesis is to provide a potential solution for this, by implementing the Random Finite Element Method (RFEM) in PLAXIS, a well-known geotechnical calculation software package, allowing users to stochastically model engineering problems while accounting for the spatial variability of soil properties. <br/><br/>As a result of this project, practitioners can use the upside of stochastic analysis using RFEM to derive new insights about the behavior of their system, such as potential soil-related asymmetries, all while obtaining a better picture of the risks associated with a certain design. As with any technological advancement, responsible use of the framework is required to ensure the upside is attained and computational concerns do not hinder the use of the model, feature which still requires further research and improvement.","Heterogeneity; RFEM; PLAXIS; User-Defined Soil Model (UDSM; scale of fluctuation; probability of failure; FEM; spatial variability","en","master thesis","","","","","","","","","","","","Geo-Engineering","",""
"uuid:82e5ba77-fe4b-495c-81ef-0e219ea04f55","http://resolver.tudelft.nl/uuid:82e5ba77-fe4b-495c-81ef-0e219ea04f55","An 11-bit 2MS/s column parallel SAR-RAMP ADC for ToF imager readout","Yang, Hankai (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Microelectronics)","Muratore, D.G. (mentor); Du, S. (graduation committee); Delft University of Technology (degree granting institution)","2022","Time-of-Flight (ToF) is an optical range detection technique that derives range from the round-trip time of light pulse between the imager and the target. Due to the simple hardware and distance extraction algorithm, ToF imagers are widely adopted in existing (automotive, consumer electronics, etc.) and emerging (AR/VR, etc.) applications requiring depth information. ToF is divided into Direct-ToF (D-ToF) and Indirect-ToF (I-ToF). Compared with the D-ToF system which directly measures the round-trip time of the laser beam, the I-ToF system indirectly measures the time from a phase measurement of the received modulated pulse. I-ToF provides a smaller detection range but it is less sensitive to jitter in the system and can achieve higher accuracy. Hence, I-ToF is used in short-range high precision applications such as face recognition.<br/><br/>This thesis describes the readout ADC design for the next-generation I-ToF imagers used for smartphone face recognition in collaboration with Infineon. A compact 11-bit 2 MS/s column-level ADC is developed in 65nm CMOS image technology. To balance between the available area and required speed, a hybrid SAR-RAMP ADC concept is proposed, which also embeds a threshold comparison phase to relax requirements on successive phases. The ADC has been verified with the post-layout extracted view of the column-level analog circuits and the schematic view of the central/digital circuits with an ideal ramp buffer, achieving a 1.1 V - 3.3 V input range with a 1.1 V reference, a signal-to-noise and distortion ratio (SNDR) of 64.3 dB, 45 µW power consumption, a Walden figure of merit (FOM$_W$) of 107 fJ/conv-step and an area of 7 µm $\times$ 815 µm.","SAR ADC; TOF; image sensor","en","master thesis","","","","","","","","2023-06-09","","","","Electrical Engineering","",""
"uuid:da5e6405-29d7-49b5-b974-ebb6d49e963c","http://resolver.tudelft.nl/uuid:da5e6405-29d7-49b5-b974-ebb6d49e963c","Continuous Adaptation of Climate Adaptation: Understanding climate adaptation governance and its capacities in Amsterdam Oud-Noord","Vuyk, Marit (TU Delft Architecture and the Built Environment)","Peters, Karin (mentor); Chen, Y. (mentor); Delft University of Technology (degree granting institution); Wageningen University & Research (degree granting institution)","2022","This research aims to understand the local governance capacity of Amsterdam Oud-Noord and discover how this area, together with its stakeholders, can improve its climate resilience through transformative climate adaptation governance. This was done by first understanding the research area, its challenges and needed climate adaptation, and by identifying the present climate adaptation stakeholders. Secondly, the governance climate adaptation governance capacity was analysed, according to the redevelopment and extension of an existing framework. Transformative governance climate adaptation governance capacity was analysed through four governance capacities; Stewarding, Unlocking, Transformative and Orchestrating capacity, and related indicators. This led to the identification of governance capacity gaps, followed by recommendations for improvement. <br/>The findings indicate that climate adaptation governance capacity is perceived as promising, but all identified indicators show that there is a need for improvement. The most pressing gaps identified are insufficient smart monitoring and insufficient stakeholder synergies. These are suggested to be improved by increasing the awareness and recognition of the value of monitoring. Next to that, accessible general methods should be developed, enabling all types of stakeholders to monitor their climate adaptation. Lastly, our results suggest that a platform should be created where stakeholders can share and coordinate their activities and possible concerns regarding climate adaptation.","Climate adaptation; Urban climate adaptation governance; Transformative capacities; Local governance; Public Space","en","master thesis","","","","","","","","","","","","Metropolitan Analysis, Design and Engineering (MADE)","",""
"uuid:624d2b88-73ad-4d7f-8040-48b08ab24732","http://resolver.tudelft.nl/uuid:624d2b88-73ad-4d7f-8040-48b08ab24732","Towards a Multi-site Kitaev Chain on Semiconducting-Superconducting Hybrid Nanowires","LI, XIANG (TU Delft Electrical Engineering, Mathematics and Computer Science)","Bordin, A. (mentor); Dvir, T. (mentor); Wimmer, M.T. (mentor); Delft University of Technology (degree granting institution)","2022","A minimal Kitaev chain can be realized by coupling two quantum dots to a superconductor on both sides. Andreev Bound States inside the superconductor mediate two types of interdot couplings: Cross Andreev Re ection (CAR) and Elastic Co-tunneling (ECT). Spin-orbit interaction (SOI) enables equal strengts of CAR and ECT, where Majorana Bound States with a quadratic protection emerge. By extending the chain to more dots, the protection is predicted to become stronger. In this project, semiconducting-superconducting InSb nanowires provide both SOI and superconductivity. We develop systematic procedures to tune a two-site device to hold Majorana Bound States. Next, quantum transport processes on a three-site device are studied. Sequential processes combining CAR and ECT are observed.","","en","master thesis","","","","","","","","","","","","Electrical Engineering","",""
"uuid:61b9ed9f-56ab-41bb-9b66-812ea5d5f895","http://resolver.tudelft.nl/uuid:61b9ed9f-56ab-41bb-9b66-812ea5d5f895","Controlling Spillback Effects In Multimodal Real-time Controlled Traffic Systems","Baak, Cornel (TU Delft Civil Engineering & Geosciences)","Hoogendoorn, S.P. (graduation committee); Taale, Henk (graduation committee); Schulte, F. (graduation committee); De Groot, T. (graduation committee); Mein, H.E. (graduation committee); Delft University of Technology (degree granting institution)","2022","When traffic demand is high and the intersection lacks throughput, oversaturated traffic phenomena occur, such as the oversaturation of a turning bay or intersection link. When such unsafe situations emerge, control strategies can be applied to handle or avoid these spillback effects. In this paper, a spillback component is designed that detects and controls spillback in a real-time controlled traffic system (RTCS) that optimizes multiple vehicle types in its optimization, with a high vehicle priority for the light-rail vehicle (LRV). A spillback control strategy was developed that assigns additional priority to the congested link when spillback is detected. For assessment, a simulation study is conducted to gain insight into the effects of applying spillback control strategies on the traffic and network performance at an isolated intersection and in a corridor. The results showed that the intersection performance decreased when a spillback control strategy was applied in the optimization, but the network performance increased during the peak period. Furthermore, a spillback penalty factor effectively decreases spillback durations while it works well in combination with higher prioritized public transit. A too-high priority negatively impacts the intersection and network performance. However, in some cases, a (high) spillback priority is necessary to provide enough priority so that a growing unsafe situation is avoided. Therefore, it is crucial to determine the intended use and applicability when providing spillback priority. The spillback priority is one of the few priorities that can be configured in the utilized RTCS; it is recommended to research the impacts when varying priorities are used.","Spillback effects; Spillback control; Microsimulation; Multimodal; Real-time controlled traffic system; signalized intersections","en","master thesis","","","","","","","","","","","","Transport, Infrastructure and Logistics","",""
"uuid:9b0ea393-3668-4731-bbdf-d1f4655b52bd","http://resolver.tudelft.nl/uuid:9b0ea393-3668-4731-bbdf-d1f4655b52bd","Optimal Energy Resource Control in Congested Areas: A Stochastic Resource Dispatch Optimization Model Considering Flexible Robust Constraints","van Doorn, Victor (TU Delft Electrical Engineering, Mathematics and Computer Science; TU Delft Intelligent Electrical Power Grids)","Vergara Barrios, P.P. (mentor); Ziar, H. (graduation committee); Rueda, José L. (graduation committee); Delft University of Technology (degree granting institution)","2022","Future energy systems are expected to rely increasingly more on distributed energy resources (DER). Prosumers that own energy resources such as photovoltaic (PV) generation and energy storage systems, will play a crucial role in the realization of DER’s in future power systems. Limited grid connections due to local electricity congestion make it more difficult for prospective industrially-sized prosumers to find suitable locations for their business operation. Energy resources such as batteries and PV, can be used to fulfil the desired electricity demands while adhering to the congestion related limits. By combining multiple energy resources and controlling them together the operational cost is drastically reduced. This thesis develops a stochastic optimization model that is able to find the optimal dispatch strategy for energy resources while adhering to constraints set by the DSO in a congested area. Also, a deterministic model is developed to be used as a comparison to the stochastic model. A deterministic model is simple and fast but it does not accurately represent the stochastic nature of PV generation, electricity consumption, and market prices. The stochastic model uses a set of different input scenarios for each time step and finds the optimal strategy considering all scenarios. In this thesis two models that consider stochasticity are developed: a stochastic and a robust model. For the robust model, the imposed grid constraints from the Distribution System Operator (DSO) have to be respected at each time step for each scenario and are classified as hard constraints. The model is able to find a optimal strategy for a week in each season when considering 11 scenarios. All predetermined constraints are respected for each simulation and while this makes the strategy reliable it also makes it conservative. For the second stochastic model, the DSO grid supply constraint is designed to be flexible and allow for occasional overshoot. In this case, flexibility is obtained by constraining the statistical distribution of grid power rather than the value at each time step and scenario. The calculated control strategy results in a simulated revenue increase between 3.67% and 4.78% depending on the season. For each season the objective cost reduces relatively more than the occurrence of grid overshoot. The term grid overshoot is used to indicate a situation where the DSO imposed grid limit is exceeded for a time step. The overshoot remains within the predetermined value threshold of 4% for all simulations of the stochastic optimization model.","Congestion; Optimization; PV systems; energy storage system; Energy management system; Stochastic Optimization; Robust Optimization; flexibility; DSO","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:c603336c-8c62-451f-a43a-b1825c0fd15b","http://resolver.tudelft.nl/uuid:c603336c-8c62-451f-a43a-b1825c0fd15b","Explorative case study to gain insight on the consequences of circular infrastructural construction projects: Investigating the effects of circularity in construction projects on project process and construction costs.","Kanters, Mark (TU Delft Civil Engineering & Geosciences)","Wamelink, J.W.F. (graduation committee); Schraven, D.F.J. (mentor); Di Maio, F. (graduation committee); Delft University of Technology (degree granting institution)","2022","The aim of this research was to investigate the effects of implementing circularity in infrastructural construction projects. As a very polluting sector, circularity is becoming a more and more popular theme in the construction industry. Driven by both governmental regulations of reaching a full circular economy in 2050 and intrinsic motivation, construction companies are slowly introducing practices which contribute to circularity. Unfortunately, not much is yet known about the effects on project process and construction costs when implementing circularity. This research has initiated the first step towards understanding what the effects of circularity are on infrastructural construction projects, providing welcoming insights to both the academic world and practice. Based on a case specific comparison, a circular construction project is more expensive than a regular construction project, due to extra activities which need to be executed before a secondhand material can be applied. Regarding the project process, the circular construction project introduced ''gathering of materials'' as a whole new process step which is constantly interchanging with (re)design until a final design has been completed.","Circular economy; Infrastructural innovation; Infrastructure; Construction sector; Construction costs; Project process; Implementation of circularity; Case study; Contractor; Project management","en","master thesis","","","","","","","","","","","","Civil Engineering | Construction Management and Engineering","",""
"uuid:101144b1-3585-444f-9def-360b6e9c835a","http://resolver.tudelft.nl/uuid:101144b1-3585-444f-9def-360b6e9c835a","Characterizing and modelling the perpendicular to the grain mode-I fracture process of (tropical) hardwood","Rademaker, Rolf (TU Delft Civil Engineering & Geosciences)","Ravenshorst, G.J.P. (mentor); van de Kuilen, J.W.G. (graduation committee); Esposito, R. (graduation committee); Mirra, M. (graduation committee); Mosleh, Yasmine (graduation committee); Delft University of Technology (degree granting institution)","2022","The demand to build with wood and other bio-based materials has increased rapidly the last decade, due to the ambition to build more with sustainable building materials. One of the major challenges in building with wood, is to account for the lower strength and stiffness perpendicular to the grain. Wood is an anisotropic material, meaning the material has different properties in different directions. Loading in the perpendicular to the grain direction is sometimes unavoidable and fracture often occurs in a brittle manner. Unfortunately, our understanding and knowledge of the perpendicular to the grain fracture is limited. This is especially the case for hardwoods, for which the material properties and the parameters important for the fracture process are often unknown. <br/><br/>The goal of this thesis is to reduce this knowledge gap on the material properties and the relevant parameters in mode-I (pure tension) fracture process of (tropical) hardwood. The knowledge gained in this research provides the answer to the main research question of this thesis: Which parameters should be considered when describing the constitutive model of a (tropical) hardwood in mode-I tension? <br/><br/>A single-end notch three-point bending (SEN-TPB) test demonstrated a strong influence of the orientation of the growth rings on the perpendicular to the grain fracture process of azobé. The value for the peak load and post-peak behaviour change significantly depending on the orientation in which the sample is placed. Furthermore, visual observations and results from a profilometer revealed that there is an inconsistency in the roughness of the cracked surface area between the different series. From the microscopic analysis is concluded that this inconsistency in general mechanical behaviour and the roughness of the cracked surface area is linked to the composition of ray and parenchyma cells. Moreover, the direction of the ray and parenchyma cells with respect to the fracture plane is different depending on the orientation of the sample. When the ray cells are orientated perpendicular to the crack plane, a higher strength is obtained. The thin-walled parenchyma cells significantly reduce the post-elastic stiffness if these cells are orientated perpendicular to the crack plane. The influence of the composition and orientation of both cells is reflected in the numerical value for the modulus of elasticity, the tensile strength and the fracture energy. This research showed that the composition of the cells in a wood specie and the orientation in which the growth rings are placed significantly influence the mode-I fracture process of a hardwood. This influence is reflected in the modulus of elasticity, the tensile strength, the fracture energy and the shape of the tension softening curve perpendicular to the grain. The results of this research provide new insight into the fracture modelling of hardwood. Both in numerical modelling and design considerations the variation in the material properties because of the orientation of the growth rings, should not be neglected.<br","Timber; fracture behaviour; Fracture energy; Hardwood; Mode I; Azobé","en","master thesis","","","","","","","","","","","","Civil Engineering | Structural Engineering | Structural Mechanics","",""
"uuid:f922c74c-174e-4b33-8c57-68409332624c","http://resolver.tudelft.nl/uuid:f922c74c-174e-4b33-8c57-68409332624c","Multivariable Anomaly Detection Framework for Multi-sensor Network: From rule-based to data-driven","Feng, Jingru (TU Delft Mechanical, Maritime and Materials Engineering)","Mohajerin Esfahani, P. (mentor); Hajee, B (graduation committee); Wisse, C.J. (graduation committee); Delft University of Technology (degree granting institution)","2022","With the demand for more information on the building’s indoor climate, a massive amount of multi-sensors are mounted in buildings. Sensor anomalies in smart buildings lead to higher energy consumption and a less comfortable indoor climate. In the state of practice, rule-based approaches were proposed to detect and diagnose sensor anomalies in the building sensor network. However, as the number of sensors is growing and the types of sensors are becoming more diverse, rule-based approaches become more and more limiting and expensive.<br/><br/>This project proposed a data-driven detection and diagnosis framework that transfer the knowledge from one sensor to the other sensors in the network for detecting and diagnosing sensor anomalies in the smart building. In the proposed framework, all the data from one room that contains targeted anomalies is chosen to be the training set. Principal component analysis (PCA) is used to extract the features, and support vector machine (SVM) is used to model the classifier. This framework is tested specifically on all the CO2 sensors in a smart building. Functions of detecting a single anomaly, detecting mixed anomaly and diagnosis anomaly are evaluated and compared with the state of practice. Moreover, the influence of anomaly rate on the performance of the proposed method is investigated. In order to test the sensitivity to the training dataset, a final experiment was performed where the room that provide the training data was changed to a different room.<br","","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:22b9a71f-85df-4948-9656-a468b2aaef12","http://resolver.tudelft.nl/uuid:22b9a71f-85df-4948-9656-a468b2aaef12","Reconstructed discontinuous Galerkin methods for high Reynolds number flows","Wegener, Malte (TU Delft Aerospace Engineering; TU Delft Aerodynamics)","Hulshoff, S.J. (mentor); Delft University of Technology (degree granting institution)","2022","Reconstructed Discontinuous Galerkin (rDG) methods aim to provide a unified framework between Discontinuous Galerkin (DG) and finite volume (FV) methods. This unification leads to a new family of spatial discretization schemes from order three upwards. The first of these new schemes is the rDG(P1P2) method, which represents the solution on each element as linear functions while reconstructing quadratic contributions to compute the fluxes inside the element and over the faces. For the rDG(P1P2) method, two different reconstruction methods were implemented. The first of these reconstruction methods is a least-squares based reconstruction. For this reconstruction, an inverse distance weighting was introduced to improve the discretization error in anisotropic mesh regions, as well as an extended reconstruction stencil variant, which aims to stabilise the reconstruction on simplicial meshes. The inclusion of an inverse distance weighting was found to be beneficial for high Reynolds number flows on the example of the two-dimensional zero pressure gradient flat plate. As a second method, a variational reconstruction method was implemented. For the variational reconstruction rDG methods it was shown that they can offer significantly reduced discretization errors compared to DG methods for smooth flows. It was shown on the example of a method of manufactured solutions, that all implemented methods reach their designed order of accuracy and can provide lower spatial discretization errors than a DG method of a comparable order on regular and randomly perturbed hexahedral meshes as well as on tetrahedral meshes. The rDG methods was applied to several two and three-dimensional RANS test cases. For these test cases, a stronger influence of the Reynolds number on the discretization error of rDG methods was found compared to the weaker influence observed for DG methods. For all test-cases, it was shown that rDG methods converge faster on the same mesh, however, yield a higher absolute error, due to the lower number of degrees of freedom compared to native DG methods.<br","discontinuous Galerkin; least-squares reconstruction; variational reconstruction; reconstructed discontinuous Galerkin; RANS","en","master thesis","","","","","","","","","","","","Aerospace Engineering | Aerodynamics","",""
"uuid:73da2697-edbb-4bb0-872e-67393289045d","http://resolver.tudelft.nl/uuid:73da2697-edbb-4bb0-872e-67393289045d","Day and Night Contrail Climate Impact of Optimised Trajectories","Kruin, Wessel (TU Delft Aerospace Engineering)","Yin, F. (mentor); Castino, F. (mentor); Grewe, V. (mentor); Delft University of Technology (degree granting institution)","2022","Contrail formation is one the largest warming contributions of aviation’s climate impact. Measures to mitigate contrail climate impact include the optimisation of flight trajectories to avoid the formation of warming contrails or to find air space where extra cooling contrails are formed. The latter option is only possible during daytime, due to the interaction of a contrail with the short-wave radiation from the Sun. Little research is done to evaluate the effect of the diurnal cycle on contrail climate impact mitigation. Moreover, models to predict this the contrail climate impact are still in the development face. This thesis aims to (1) find the daytime and nighttime contrail climate impact of eco-efficient flight trajectories, (2) to assess the prediction’s robustness and (3) to recommend a best practice for eco-efficient flying by using the difference between the daytime and nighttime contrail climate impact. To this end, simulations were carried out within the EMAC climate chemistry model, aided by the submodels AirTraf, CONTRAIL and ACCF. The robustness of the results were tested against a model parameter: the threshold time until sunrise (THsunrise). When a contrail is formed<br/>during nighttime, THsunrise determines whether the contrail is formed sufficiently close to sunrise to be considered a daytime contrail. It is concluded that winter daytime mitigation of contrail climate impact is more eco-efficient than winter nighttime mitigation. Overall, daytime mitigation achieves a larger maximum reduction of contrail climate impact than nighttime mitigation. moreover, summer mitigation is more effective than winter mitigation and winter<br/>mitigation has a larger reliance on the formation of extra cooling contrails. The thesis results are robust with respect to a varying THsunrise. However, overall results become biased to daytime results or nighttime results. Lastly, it is shown that differences between day and night contrail climate impact mitigation allow for the enhancement of mitigation results.","contrail mitigation; Trajectory Optimisation; Climate Impact; operational strategies; contrail formation regions; Pareto front; Pareto-optimal; ATM4E; FlyATM4E; Day and night","en","master thesis","","","","","","","","","","","","Aerospace Engineering","FlyATM4E",""
"uuid:1d4161ac-7f4c-4e31-bab7-76d080985220","http://resolver.tudelft.nl/uuid:1d4161ac-7f4c-4e31-bab7-76d080985220","The potential benefits of standardisation of the design of bed protections at waiting places at ship locks in the Netherlands","van der Wart, Lieke (TU Delft Civil Engineering & Geosciences)","van Koningsveld, M. (mentor); Hofland, B. (graduation committee); van der Hout, A.J. (graduation committee); van der Vorm, C. (graduation committee); Delft University of Technology (degree granting institution)","2022","In the near future, Rijkswaterstaat has the task to replace or renovate many ship locks. With the long-term project, MultiWaterWerk, Rijkswaterstaat aims to standardise components of these ship locks. This thesis contributes to the project by researching the potential benefits of standardisation of the bed protection design at waiting places at ship locks in the Netherlands. Only waiting places for inland vessels with the most commonly used bed materials are analysed. Similar waiting places are grouped together with a classification analysis, based on three parameters: bed material of upper layer, berth type, i.e. quay wall or piles, and expected maximum near-bed flow velocity. The variation in these three parameters and the measured erosion of the bed were then compared between and within the resulting classes. Furthermore, the waiting places are split up into different sizes by pre-defined CEMT-classes. Waiting places in CEMT-class II and VI waterways are more similar in design and erosion, so a potential for standardisation exists there. CEMT-class V is further analysed per corridor, because the variation between all waiting places is too high. Among those corridors, only the Nederrijn-Lek shows potential. In the Meuse and Twente channels, the erosion varies too much; other corridors contain too little waiting places for potential benefits to outweigh the effort for standardisation. It is recommended to standardise the design assumptions concerning ship dimensions and propeller characteristics. A potential standard design vessel per corridor or CEMT-class should lead to a more reliable estimation of the expected scour at the waiting places. Furthermore, estimations for new bed protections at waiting places on lifetime, building duration, cost, and required maintenance will be more reliable because there will be more similar waiting places.","ship lock; waiting place; bed protection; standardisation; flow","en","master thesis","","","","","","","","","","","","Civil Engineering","",""
"uuid:c49585ac-d82c-46ea-a59c-c2a8050a4446","http://resolver.tudelft.nl/uuid:c49585ac-d82c-46ea-a59c-c2a8050a4446","Preventing Anastomotic Leakage: An experimental approach to the redesign of a colorectal stent","van Kuik, Nout (TU Delft Mechanical, Maritime and Materials Engineering)","van den Dobbelsteen, J.J. (graduation committee); Vlot, J. (mentor); Dodou, D. (graduation committee); Delft University of Technology (degree granting institution)","2022","The large intestines, or colon, is the last part of the digestive tract before the rectum. Colorectal cancer is one of the main reasons that patients need a colon resection. A colon resection is a surgery in which the malignant part of the colon is removed. After removal of the tumor, the two ends of the colon need to be reattached, also called anastomosed. This is usually done using sutures or staples. One of the most frequently occurring and major complications is that the anastomosis does not heal correctly. This can cause an anastomotic leakage, which means that fecal matter and fluids with bacteria can flow into the otherwise sterile abdominal cavity. This is a serious complication that can even result in death. Therefore, a solution can be to insert a stent to cover the anastomosis from the inside, preventing feces and fluids from entering the abdominal cavity. Such a stent was developed at the department of Surgery of the Erasmus MC.<br/><br/>This thesis focuses on the redesign of this stent to cover an anastomosis. Two main problems with the stent were stent migration due to insufficient friction between the stent and the colonic wall, and intestinal blockage due to the presence of the stent. <br/><br/>Preliminary research and a literature study showed that the addition of barbs to the stent could increase friction with the colonic wall. Optimal barb dimensions were researched on fresh colon specimens in an experimental setup. Ideal barb parameters were a height of 1.5 mm, diameter of 1.0 mm, an angle of 30 degrees, with a distribution of 3 barbs per cm2. In addition, the ideal stent diameter was explored in an experiment with fresh colon specimens. The stent should expand the colon with 50-60%. To safely insert and extract a stent with barbs in the colon, a patent search was executed to explore the possibilities of barb and colon protection. A stent with a reducible diameter and a tubular protection structure were identified as the most promising methods to safely insert a barbed stent. The second problem of intestinal blockage was analyzed and causes of intestinal blockage were identified. Minimizing the frontal contact surface at the proximal end of the stent was assumed to be the most important factor to reduce intestinal blockage. A minimal frontal contact surface also reduces the force that feces exerts on the stent, thus reducing the chance of stent migration.<br/><br/>The previously mentioned experiments and analysis formed the basis of a list of design requirements for a new prototype stent. The requirements were divided into five categories; fixation, dimensions, materials, delivery method and performance. After analyzing different manufacturing processes and available materials, two concepts were designed and produced. One concept was chosen after careful considerations of both options.<br/><br/>The final prototype consisted of a stent with barbs that was 3D printed. This design was validated on the set of requirements that were set up earlier. The material of the stent is both flexible and stiff. For insertion and extraction of the stent, the diameter can be reduced by longitudinal inward folding, while the stent forms a rigid tube while in a deployed state. The barbs are stiff and strong and can withstand the force that would move the stent. The frontal contact surface of the stent was reduced by more than 18 times compared to the old prototype, to reduce the influence on intestinal blockage. The stent is surrounded by a sheet to protect the barbs and prevent tissue damage during insertion. A validation experiment showed that the stent was improved in fixation compared to the old prototype. Therefore, based on the research executed in this thesis, the final prototype should theoretically migrate less and cause less blockage. However, an ex-vivo experiment should validate the fixation force of the new prototype, and in-vivo experiments on pigs should determine if the prototype actually does not migrate and actually does not cause intestinal blockage.","Stent; Anastomosis; Anastomotic leakage; Colon; Colorectal; Large intestine","en","master thesis","","","","","","","","2024-12-08","","","","Biomedical Engineering","",""
"uuid:d44116a8-4c85-45b3-af2d-1eec6922a167","http://resolver.tudelft.nl/uuid:d44116a8-4c85-45b3-af2d-1eec6922a167","Venously Printed: Multi-material 3D printed responsive fluidic interfaces with programmable dynamic appearance triggered by mechanical deformation.","van Rijn, David (TU Delft Industrial Design Engineering)","Doubrovski, E.L. (mentor); Elkhuizen, W.S. (graduation committee); Delft University of Technology (degree granting institution)","2022","Venously printed contributes to the field of HCI and digital manufacturing by exploring the scope and possibilities for programmable and responsive fluidic interfaces, using multi-material 3D printing as a manufacturing technique. Novel meta-materials and computational composites have proven to open up new design paradigms and continue to expand the design space for HCI and material design with unprecedented I/O configurations and material experiences. By encoding the computational logic of dynamic and responsive behaviour into the material’s structure and properties, these materials allow shifting away from typical 2D (digital) interfaces towards embedded responsive 3D objects and materials without the need for external logical operators or controllers. <br/><br/>A novel concept within this field is fluidic interfaces, which utilise liquid flow as a medium to drive dynamic appearance triggered by mechanical deformation input such as pressure, twisting or bending. Within this research, multi-material 3D printing is explored as a manufacturing tool for such fluidic interfaces to allow for more complex 3D geometries, dynamic visual output and encoded computational logic. A set of demonstrators are developed with programmable dynamic appearance, showcasing the capabilities of this manufacturing workflow and the possibility of being tuned for specific material experiences or temporal form in interaction design. <br/><br/>To allow for the fabrication of these interfaces Venously printed presents a fabrication pipeline, including a computational design and simulation tool for designers to validate the responsive behaviour and iterate on their design before going into manufacturing. Additionally, a voxel-based support structure for 3D printing complex internal cavities is developed to provide better printing quality as opposed to available workflows whilst still being able to be removed from complex internal structures. Finally, a first step for the characterisation of the experiential qualities of fluidic interfaces has been performed via a set of interviews. This led to promising future applications and material experiences which can be explored in future work.","Human Computer Interaction; material design; Digital Fabrication; 3D printing; Multi-Material Additive Manufacturing","en","master thesis","","","","","","","","","","","","Integrated Product Design","",""
"uuid:50f199a7-ca2d-4eb0-a0b2-7570fe63c2ad","http://resolver.tudelft.nl/uuid:50f199a7-ca2d-4eb0-a0b2-7570fe63c2ad","The heat is on: examining the weights of factors influencing the choice between residential heating systems and their differences across the Netherlands","Biemans, Angelique (TU Delft Electrical Engineering, Mathematics and Computer Science)","van de Kaa, G. (mentor); Kamp, L.M. (graduation committee); Delft University of Technology (degree granting institution)","2022","","Best-Worst Method; Heat Transition; energy","en","master thesis","","","","","","","","","","","","Electrical Engineering | Sustainable Energy Technology","",""
"uuid:460c4758-002a-4711-a2d0-afbff5513e6c","http://resolver.tudelft.nl/uuid:460c4758-002a-4711-a2d0-afbff5513e6c","Floating Spar Optimization: A constraint set investigation for the use of simulated annealing for substructure optimization","Pietersz, Torsten (TU Delft Mechanical, Maritime and Materials Engineering)","Colomes, Oriol (mentor); Gao, Zhen (graduation committee); Delft University of Technology (degree granting institution)","2022","With the increase in need for offshore wind exploitation a research is set up with aims to develop a preliminary design tool. The introduction begins with background information on what role floating wind will play in the offshore wind industry and why this is a relevant topic. A general overview of floaters is presented with a comparison of the advantages of each type of floater. As well a chronological review of approaches to preliminary design. After which a numerical load and response model is developed. First theory is discussed regarding load and response modelling as well as the fatigue damage calculations. After the theory is covered, a test case is set up using the IEA 15MW reference turbine. The turbine is subjected to aerodynamic and hydrodynamic loading. This loading is calculated using Morison’s equations and a simplified thrust coefficient. In the test case the IEA15MW reference turbine is put atop a large floating substructure. For the environmental condition a site off the coast of Norway is used with an adjusted depth to allow for the size substructure. The response calculation is then, where the equations of motion are set up in matrix form, and terms in all of the matrices are then derived for the mass, added mass, stiffness and damping matrix. The stiffness matrix considers hydrodynamic stiffness and mooring stiffness. The terms in the damping matrix are derived from aerodynamic and hydrodynamic damping. Hydrodynamic damping only considers viscous damping terms. The model is then tested for a set of regular and irregular wave and wind conditions to analyse the system’s behaviour. For the fatigue calculation the substructure is divided into welded areas that will be investigated for lifetime global fatigue. This response model is validated by comparing natural frequencies of a smaller well documented 5MW floating spar. Optimization theory is covered, where multiple gradient and non-gradient based approaches are discussed. The simulated annealing algorithm is developed and tested on a set of test functions: Ackley &amp; Booth. The algorithm shows quick convergence for areas that have small changes. The optimization problem for this research is formulated. The design space is visualised and compared to the most similar test function. After which, the constraints used by the optimiser are presented. The first constraint set consists of logical design constraints determined by the spar geometry. After which, the constraint set also includes limitations on the extreme response in time domain simulation. In the results chapter, it is found that this slows down the process so much that it is not feasible to include fatigue damage in the constraint function. Furthermore, it is found that global fatigue damage wouldn’t be a governing constraint. The results chapter discusses the importance of mooring stiffness in this optimization. Present the results from constraining the optimiser with the time domain response and compare the fatigue lifetime of the optimal designs. It is found that global fatigue is not a governing design consideration. It is found that both geometrical and response constraints are relevant for this type of optimization. However using global fatigue as a constraint is both irrelevant and computationally infeasible for the optimization of a floating substructure. Finally, a discussion is presented where the work is critiqued, and recommendations are made for further work.","Optimization; Simulated Annelaing; FOW; Floating Wind","en","master thesis","","","","","","","","2023-12-08","","","","European Master in Urbanism (EMU)","",""
"uuid:350c2454-2c7a-42b4-a5a6-3c49c37fc892","http://resolver.tudelft.nl/uuid:350c2454-2c7a-42b4-a5a6-3c49c37fc892","Assessing the impact of climate change on streamflow in catchments across the United States, using an easily reproducible modeling approach","Hoogelander, Vincent (TU Delft Civil Engineering & Geosciences)","Hut, R.W. (mentor); Hrachowitz, M. (graduation committee); Lhermitte, S.L.M. (graduation committee); Delft University of Technology (degree granting institution)","2022","In this thesis, an easily reproducible modeling approach was developed for assessing the climate change impact on streamflow. This approach was tested by using it to assess the impact of climate change on streamflow in 5 different contrasting catchments across the United States. Many studies show that climate change is expected to influence streamflow regimes all over the world. However, these studies are often difficult to reproduce because the modeling approaches used are usually only locally applicable. In the approach used in this study, hydrological model calibration and validation were done using open-accessible ERA5 forcing together with observed streamflow data provided by the GRDC. The model performed best in a mountainous catchment, while the worst performance was found in a dry catchment and a catchment containing several lakes. The low performances here are mainly caused by imperfect forcing data used for calibration and the neglection of lake processes. The climate change impact analysis used forcing from two CMIP6 models with the SSP245 and SSP585 scenarios. The projections showed significant changes in streamflow in colder regions, which are most likely related to changing snow melt processes. The main finding in warmer regions is that streamflow is generally expected to decrease in the drier periods. Changes of streamflow in these regions are most likely related to changes in precipitation and evaporation processes. However, results remain very uncertain due to disagreements between climate models and sometimes doubtful performance of the hydrological, caused by oversimplification of the model and imperfect ERA5 calibration data. The designed modeling approach facilitates reproducibility of climate change impact analyses in a wide range of catchments using different climate models and scenarios. Its use makes it easier to expand similar analyses to a large ensemble of these aspects.","Climate change; Hydrological modeling; eWaterCycle II; Hydrology; Streamflow signatures","en","master thesis","","","","","","","","","","","","Water Management | Hydrology","",""
"uuid:72593663-6adc-4707-bf72-f9e4ae38af50","http://resolver.tudelft.nl/uuid:72593663-6adc-4707-bf72-f9e4ae38af50","HV power MOSFET embedding","Younis, Rami (TU Delft Electrical Engineering, Mathematics and Computer Science)","Poelma, René H. (mentor); Zhang, Kouchi (mentor); French, P.J. (mentor); van Zeijl, H.W. (mentor); Delft University of Technology (degree granting institution)","2022","Power electronics are an important technology used to convert electricity from a source like a battery or high voltage DC bus to more usable forms of electricity. This has to be done efficiently, reliably and without failures which is critical in applications like electric cars or datacenters. Power MOSFETs with upcoming SiC and GaN devices are an important building block used in these converters. Hence these power MOSFET devices have to be improved continuously to get a lower on resistance (R<sub>DSon</sub>), a better thermal dissipation and lower parasitic losses. In this thesis we will take a look at the embedding of power MOSFETs inside a PCB to obtain these improvements. This new technology needs to be evaluated in terms of reliability, failure-modes and thermal/electrical performance. By designing,<br/>manufacturing and testing a PCB with embedded devices. During manufacturing silver sintering has been used for attaching the die to a copper coin. In the end the manufacturing has been done successfully.<br/>Testing showed an 18% lower R<sub>DSon</sub> and a twice as low junction to ambient thermal impedance indicating a better performance compared to regular packaging.","Embedding; packaging; power MOSFET","en","master thesis","","","","","","","","2023-12-07","","","","Electrical Engineering | Embedded Systems","",""
"uuid:dc12e46e-0a59-448e-9cef-14d76ed9ebb7","http://resolver.tudelft.nl/uuid:dc12e46e-0a59-448e-9cef-14d76ed9ebb7","Attacks on Searchable Symmetric Encryption Systems: Revisiting Similar-data and File Injection Attacks","Ilbaş, Hakan (TU Delft Electrical Engineering, Mathematics and Computer Science)","Smaragdakis, G. (mentor); Liang, K. (graduation committee); Decouchant, Jérémie (graduation committee); Chen, H. (graduation committee); Delft University of Technology (degree granting institution)","2022","The amount of data individuals create keeps increasing every year to the point that the data cannot be stored on a single device anymore. Cloud storage provides a solution for this problem, but not everybody wants the cloud storage service providers to peek at their data and they thus encrypt their data before storing it on the service provider's servers. Unfortunately, due to the way encryption works, the users are not able to perform simple actions on their data, like for example keyword search. However with Searchable Symmetric Encryption (SSE) the users can still perform keyword search on their data when their data is encrypted. With the use of SSE, there is some information that is being exposed about the data that is being stored on the system, called leakage. This leakage can be used by attackers in an attack to perform query recovery.<br/><br/>Currently existing attacks are mostly known-data attacks which assume that the attacker already has access to a large part of the plaintexts stored on the system. However this is very unlikely in real-world scenarios. A few papers focus on similar-data attacks which have a slightly different assumption. With similar-data attacks, the assumption is that the attacker has a similar document set to the document set stored on the SSE system. These attacks are therefore more realistic than known-data attacks, but the best similar-data attack still has some flaws.<br/><br/>Therefore, in this thesis, we propose a new attack that is based on an already existing similar-data query recovery attack. This new attack is a combination of a file injection attack and a similar-data attack. This new attack achieves a higher accuracy than the best similar-data and known-data attacks, while injecting only a few files into the SSE system. To the best of our knowledge this is the first similar-data attack with a file injection component. The new attack is also more resilient to countermeasures such as padding and obfuscation. <br","","en","master thesis","","","","","","","","","","","","Computer Science | Cyber Security","",""
"uuid:c70dd2a9-a8b0-4e77-bfbb-732f9af15325","http://resolver.tudelft.nl/uuid:c70dd2a9-a8b0-4e77-bfbb-732f9af15325","Power to Fuel: Optimisation and characterisation of a small scale methanol synthesis reactor","de Jong, Alex (TU Delft Mechanical, Maritime and Materials Engineering)","de Jong, W. (mentor); Vroegindeweij, P.S.M. (mentor); van Kranendonk, J. (mentor); de Jong, W. (graduation committee); Vroegindeweij, P.S.M. (graduation committee); Eral, H.B. (graduation committee); Goetheer, E.L.V. (graduation committee); Delft University of Technology (degree granting institution)","2022","class=""MsoNormal"">In the effort against climate change the company ZEF has as its target to make methanol (CH3OH) out of atmospheric CO2; a process which can be seen as power-to-fuel and/or power-to-x. In light of the developmental cycle within ZEF a new reactor with an increased size and enhanced mass manufacturability is required. The reactor contains three main components: reactor bed, condenser and heat exchanger. The heat exchanger design has been shown to be highly efficient as well as the underlying design philosophy [1]. However, an exact in depth evaluation of the condenser performance has not been performed yet. Furthermore, in light of reactor optimisation, an investigation on the reactor bed design for the use case of ZEF is seen as necessary. The condenser plays a dual role in the reactor: it acts as the separation mechanism of products from the recycle stream and as vital factor in generating mass flow. Due to the current modelling architecture/philosophy of ZEF computationally simple descriptions of condensation phenomena are desired. A method based on linear relations for the latent heat release is developed. In combination with a PT-flash plug-in for MatLab this allows for modelling of heat effects and liquid-gas separation due to condensation. According to literature local heat transfer of condensation is significantly hampered com- pared to ideal Nusselt Film Condensation theory. The reason for this degradation is the presence of Non-Condensable Gasses which will limit the heat flux of the condensing species to the condenser surface. A sub model is used to evaluate whether this effect is significant. A combined model and experimental approach is used for evaluation of these models. The reactor bed is the generation site of the methanol and in previous work it has been found there might be limiting effects in this bed [1]. Evaluation of literature on the causes indicates that mass transfer and temperature limitations are likely the cause. Furthermore literature suggests that the reactor bed might be able to attain a higher Space Time Yield. A set of models are made to describe the mass and heat transport of the reactor bed. These are based on 1-D heat transfer correlations, a linearized Thiele modulus, and the Bussche &amp; Froment kinetic model. Furthermore, the reactor bed and condensation models are integrated into an existing overall model. This enables the simulation of synergy between these processes. A new reactor bed design is made based on these models which should increase the Space Time Yield, and is subject to experimental validation. For the experimental validation a new reactor was designed and build based upon the new models developed. Characterisation experiments indicate satisfactory qualitative behaviour of the condensation modelling. Quantitatively deviations are observed which are expected to be due the over prediction of methanol formation by the reactor bed models. The reactor bed model deviations are mainly attributed to a lower than predicted mass flow rate, and adverse flow fields in the reactor bed. A new reactor bed design is proposed which should significantly reduce the adverse flow field effects while increasing thermal performance. The reactor bed design used allows for a decrease in catalyst size without causing a significant decrease in mass flow rate. An increase of a factor 1.25 for the Space Time Yield compared to the previous design has been observed during experiments. Insulation performance is satisfactory with the insulation performing within 20 W as modelled. Thermal efficiency has decreased by a factor 1.8 and is attributed to the under performance of the reactor bed. Furthermore, the control of the reactor has been evaluated in terms of mass flow rate measurements, the prevention of the stalling of flow, and control. A new mass flow rate measurements device based on differential pressure, a new feed injection design, and further development of control have been experimentally validated. Designs for each of these subjects have been found to be satisfactory. Furthermore, it was found that reactor bed geometry also has an effect on the control of the reactor.   ","Methanol; Reactor design; Reactor Modelling","en","master thesis","","","","","","","","2024-12-07","","","","","",""
"uuid:15aafb4c-c217-43f5-a90e-1c20a01f1757","http://resolver.tudelft.nl/uuid:15aafb4c-c217-43f5-a90e-1c20a01f1757","Motion Primitive Recognition in Tooth Removal Surgery","Bornhijm, Bram (TU Delft Mechanical, Maritime and Materials Engineering)","Van Riet, T.C.T. (mentor); Kober, J. (mentor); de Lange, Jan (graduation committee); Dodou, D. (graduation committee); Delft University of Technology (degree granting institution)","2022","Whilst the extraction of teeth (exodontia) remains one of the oldest and most performed surgeries on earth, very little is understood about the procedure itself. Especially in the area of the required movements, torques and forces to remove specific teeth and how these interact with existing tissue. This knowledge gap has been hypothesized to contribute to an increasing referral rate towards Oral and Maxillofacial Surgery (OMFS) practices in the Netherlands for simple extractions due to low confidence in young dentists. The objective of this project is to apply techniques used in imitation-learning in the field of robotics to deconstruct complex movement into smaller fundamental building blocks called movement primitives (MPs) to deepen the understanding of exodontia. To achieve this an existing dataset was used consisting of high resolution force-, torque-, position- and rotation-data of extractions. This dataset was collected using a measurement setup consisting of fresh frozen cadaver material, a force torque sensor and a robotic arm in gravity compensation mode. In this paper a novel iterative two staged method for identifying movement primitives is introduced and employed to extract movement primitive information from these extractions in the dataset.","imitation learning; exodontia; movement primitive","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Vehicle Engineering | Cognitive Robotics","",""
"uuid:20fb119e-ccb7-431c-8335-0fd5cf9f4ead","http://resolver.tudelft.nl/uuid:20fb119e-ccb7-431c-8335-0fd5cf9f4ead","VisuaLayered: Combined Visual Analysis of MA-XRF and RIS Data","Popa, Andra (TU Delft Electrical Engineering, Mathematics and Computer Science)","Höllt, T. (mentor); Eisemann, E. (graduation committee); Oertel, Catharine (graduation committee); Delft University of Technology (degree granting institution)","2022","In this work, we present VisuaLayered, the implementation of a combined analysis workflow for pigment identification. VisuaLayered is an integrated, interactive system that focuses on the combined visual analysis of Macro X-Ray Fluorescence (MA-XRF) and Reflectance Imaging Spectroscopy (RIS) data.<br/><br/>Analysing paintings for pigment identification is relevant for many applications in the cultural heritage domain, such as conservation and restoration.<br/>Domain experts use non-invasive scanning techniques as an initial step in their analysis. Two such techniques are MA-XRF and RIS. They provide hyperspectral data on the elemental and molecular composition of pigments, respectively. Domain experts analyse these two complementary data modalities in order to determine the pigments present in the different paint layers of a painting. However, due to the size and high-dimensionality of these datasets, experts have problems with efficiently analysing the data. In general, they examine the two data modalities separately in the analysis workflow and use their knowledge to unify all the information without additional software support, as there is no integrated system that is designed specifically for the combined analysis of MA-XRF and RIS data.<br/><br/>We worked in collaboration with domain experts from the Rijksmuseum, Amsterdam in order to design and implement VisuaLayered based on current domain practices. We use t-SNE for projecting the high-dimensional data into a two dimensional space, which the user can interactively explore in combination with other linked views in order to find connections between the two data modalities. With our system, experts can explore the spatial distribution and the correlation between pixels that have similar molecular and/or elemental compositions. Additionally, for the RIS data, we support endmember identification and analysis based on the pigments' spectral profiles. <br/>We tested the efficiency of our system with respect to the designed workflow in a case study evaluation with our collaborator. They successfully used VisuaLayered for the analysis of one painting and found the views combining the two data modalities very useful for better understanding the relation between them. Moreover, they were able to identify new pigments, that they missed when using existing software.","Visual Analytics; Visualization; Painting Analysis; Cultural Heritage; MA-XRF; RIS; Interactive tool","en","master thesis","","","","","","","","","","","","Computer Science | Software Technology","",""
"uuid:354ff3d6-ed16-4a94-9787-e90fbe2c0f4a","http://resolver.tudelft.nl/uuid:354ff3d6-ed16-4a94-9787-e90fbe2c0f4a","Monitoring Erosion using Terrestrial Laser Scanning","Nijensteen, Ilse (TU Delft Civil Engineering & Geosciences; TU Delft Geoscience and Remote Sensing)","Lindenbergh, R.C. (mentor); Alfieri, S.M. (graduation committee); Bogaard, T.A. (graduation committee); Delft University of Technology (degree granting institution)","2022","The Catterline Bay, located in North East Scotland, is prone to erosion processes. Using Terrestrial Laser Scanning (TLS) two point clouds were obtained in 2019 and 2022 from this area of ca. 0.2 km<sup>2</sup>. Here, a methodology was proposed and tested to assess how erosion processes can be monitored from high resolution point clouds in small study areas. Filtering of ground points from the point clouds was done using a full 3D approach. The local dimensionality on multiple scales was used to generate features for the classification, for which Linear Discriminant Analysis was used. The algorithm was able to precisely separate non ground points from ground points with a precision on test data sets of 94.7% on ground points and 94.3% on non-ground points. <br/><br/>The ground points provided a basis for the Digital Terrain Model (DTM) raster. Several geomorphological quantities could be derived from this DTM. Next to these quantities, also information about vegetation height and 3D change detection using the Multi-scale Model to Model Cloud Comparison (M3C2) was extracted. <br/><br/>From a combination of the Terrain Ruggedness Index (TRI), change detection using the Multiscale Model to Model Cloud Comparison (M3C2) technique and photos, erosion zones were derived. Also stable, non-erosion, zones were identified. Various statistics from the geomorphological quantities were analysed for both zone types. Erosion zones have clear edges of high TRI values, indicating the scarps of landslides. The erosion zones also contain groups of negative M3C2 distances, indicating depletion zones. Not only the TRI and M3C2 distances have significantly different statistics for erosion and non-erosion zones, also the slope is steeper in these zones and the Topographic Wetness Index is smaller. The mean slope for erosion zones is 39.3° compared to 30.9° for non-erosion zones. To capture the behaviour of the TRI in the defined zones, p<sub>TRI</sub> was introduced which gives a rate of how many cells have a high TRI value in a defined zone. The p<sub>TRI</sub>, the rate of TRI values above 0.06 m, is more than 4 times larger for erosion zones (0.17) than for non-erosion zones (0.04). <br/><br/>Changes in vegetation height could be linked to locations of implemented Nature Based Solutions (NBS). The results were in agreement with changes in NDVI, which were calculated from optical satellite imagery.<br/><br/>In conclusion, the new methodology has great potential to identify erosion zones in complex sloped terrain and monitor changes in vegetation.","Terrestrial Laser Scanning; Point Cloud; Erosion; Ground Filtering","en","master thesis","","","","","","","","","","","","Geoscience and Remote Sensing","","56.894, -2.217"
"uuid:83f7d044-b507-41b6-98de-90f3385c0214","http://resolver.tudelft.nl/uuid:83f7d044-b507-41b6-98de-90f3385c0214","Aviation Emission Inventory: A contemporized bottom-up emission inventory for the year 2019","Kroon, Rik (TU Delft Aerospace Engineering)","Gangoli Rao, A. (mentor); Yin, F. (mentor); Delft University of Technology (degree granting institution)","2022","This report covers all major steps to establish an aviation emission inventory for 2019. This emission inventory is set up based on four consecutive steps. The first step is to gather all required data in the information model and this also includes some pre-processing of data to make it as complete as possible. The second step is to estimate the point performance of the aircraft at multiple waypoints along the trajectory based on the Base of Aircraft Data (BADA). This also allows for fuel consumption estimation. The third step uses the point performance data to estimate emissions under the respective flight condition. The last step addresses introduced uncertainties based on the different models. From a first principle perspective the uncertainty on a fleet wide scale (and for short and long haul flights) is found concerning the fuel consumption and various emission species (for example nitrogen oxides and carbon monoxide) using a Monte Carlo simulation. <br/><br/>The trajectory data is obtained from flightradar24 in which gaps were identified where the type of aircraft, origin airport or destination airport were missing. Complementing of the database is based around the provided flight numbers and call signs. Based on airline data a variety of assumptions is made relating to payload fraction (69%) and increase in flight distance (8%) compared<br/>to the great circle distance. The trajectory is estimated using the rate of climb and descent provided in BADA. The emission model then uses constant emission indices, the boeing fuel flow method 2 (BFFM2) and the DLR method to compute all emissions according to:<br/>• Constant emission index: carbon dioxide (corrected for emission index of carbon monoxide),<br/>water vapor and sulfur oxide.<br/>• BFFM2: carbon monoxide, unburned hydrocarbons and nitrogen oxides.<br/>• DLR: black carbon emission.<br/>The uncertainty analysis, finally, covers airline operational uncertainty, model uncertainty and engine aging uncertainty to find an average increase in fuel consumption of 4.2%. Due to the influence of fuel flow, other emission species are increased with a different fraction.<br/><br/>Due to computational limitations it has been decided to analyze one week, which will be representative of the entire year. Based on this analysis an annual fuel consumption of 272 Tg is simulated with corresponding carbon dioxide emission of 857 Tg. In addition, a nitrogen oxide emission of 5.3 Tg is found. All emission species are mainly emitted on the northern hemisphere on three geographical locations: north America, Europe and south-east Asia. The strongest recommendation is to include military flights and non-jet aircraft in the analysis (mainly turboprop aircraft). In addition, to decrease the dependency on data of a single week, it is advised to obtain more computational power to allow for analysis of multiple representative weeks preferably in both ICAO specified seasons.<br/>Finally it is recommended to extend the uncertainty analysis to cover more individual uncertainties such as the uncertainty in cruise altitude (based on airline routing) and to find more research on the uncertainty of sulfur content in kerosene.","","en","master thesis","","","","","","","","2024-12-07","","","","Aerospace Engineering","",""
"uuid:280a14ae-ffeb-40bd-a527-6e8a51bd0ff9","http://resolver.tudelft.nl/uuid:280a14ae-ffeb-40bd-a527-6e8a51bd0ff9","The central limit theorem in a random environment","van Kempen, Matt (TU Delft Electrical Engineering, Mathematics and Computer Science)","Redig, F.H.J. (mentor); Delft University of Technology (degree granting institution)","2022","In this paper we started by explaining what a Markov chain is. After this we defined some key concepts such as stationarity, reversibility and ergodicity which were used throughout the rest of the paper. Next, the classical central limit theorem was stated in order to refresh the reader of this theorem and to show that, because of the dependence, this theorem is not applicable for the Markov chains we discussed earlier. In the next section we started working on the Kipnis-Varadhan central limit theorem. We defined the Martingale central limit theorem and used it to show that the additive functions can be approximated by a martingale. This had the result that the Martingale central limit theorem implies the central limit theorem for the additive functions. Furthermore, we also derived an equation for calculating the limiting variance. For this we used the key concepts discussed in section 2 and another concept called spectral measures. The section is finished by a simple example in order to illustrate what we have discussed previously. In the next section we used simulations in one-dimension and two-dimensions to show that, in a random environment, the distribution of the additive functions indeed converges to that of the normal distribution. Because the probability distributions defined on the random environment was a symmetric distribution the Kipnis-Varadhan central limit theorem was not yet needed since the Martingale central limit theorem already applied. After this we defined some key concepts for a Markov chain working in continuous time. The Kipnis-Varadhan central limit theorem was proven for these Markov chains as well. Furthermore, a different equation was derived to find the limiting variance for continuous time Markov chains. In section 7 the random conductance model was explained. In this chapter the random conductance model was used in order to make simulations to show that the Kipnis-Varadhan central limit theorem works. After simulating the Markov chain in continuous time we indeed saw that the histograms show convergence towards the normal distribution. This shows that for the simulations the Kipnis-Varadhan central limit theorem works.","","en","bachelor thesis","","","","","","","","","","","","Applied Mathematics","",""
"uuid:564b8471-631f-4831-a049-58b187425aed","http://resolver.tudelft.nl/uuid:564b8471-631f-4831-a049-58b187425aed","Modernizing the WebDSL Front-End: A Case Study in SDF3 and Statix","de Krieger, Max (TU Delft Electrical Engineering, Mathematics and Computer Science)","Groenewegen, D.M. (mentor); Cockx, J.G.H. (graduation committee); van Deursen, A. (mentor); Delft University of Technology (degree granting institution)","2022","The front-end of a compiler reads the source program and performs analyses such as type checking. The goal of the front-end is to check for the presence of syntactic and semantic errors before the program is passed to the back-end of the compiler for tasks such as optimization and code generation.<br/><br/>WebDSL is a domain-specific language for web programming that is being used for over 15 years. With WebDSL, many applications have been developed which have thousands of daily users. While the language has evolved over the years, the core of its implementation remains unchanged and is starting to show signs of a legacy system. The current WebDSL syntax is defined in SDF2 and all other parts of the compiler are implemented in Stratego.<br/><br/>This thesis presents a modernized front-end of the WebDSL compiler, utilizing the meta-languages of the Spoofax language workbench. Specifically, we introduce a syntax definition of WebDSL in SDF3 that is implemented without the use of post-parse filters, and an executable declarative specification of the WebDSL static semantics in Statix.<br/><br/>We use the modernized front-end as the largest case study to date for the meta-languages SDF3 and Statix, in order to evaluate their expressiveness, performance, and elegance when they are used to implement a real world language.","WebDSL; Spoofax; SDF2; Stratego; SDF3; Statix; Parsing; Static analysis; Type checking; DSL; Domain-specific language; Language workbench","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:9476b5cc-2a38-4861-ae2a-93c0942fd95e","http://resolver.tudelft.nl/uuid:9476b5cc-2a38-4861-ae2a-93c0942fd95e","Application of the Heat Flow Cone Penetration Test to measure the thermal conductivity of offshore soils","Vrielink, Leon (TU Delft Civil Engineering & Geosciences; TU Delft Geoscience and Engineering)","Vardon, P.J. (mentor); Daniilidis, Alexandros (graduation committee); Murali, M. (graduation committee); Delft University of Technology (degree granting institution)","2022","Interpretation of the thermal properties of soils is an important challenge in the field of geo-engineering, for example the development of geothermal energy solutions and for the design of electricity cable routes used for offshore wind farms. Of the thermal properties, the thermal conductivity is of most interest to find, as this determines the long-term thermal response of the soil. The soil volumetric heat capacity is of secondary interest, as this mainly influences the short-term thermal response.<br/><br/>To find the thermal properties of offshore soils, a new in-situ test is being developed, called the heat flow cone penetration test (HF-CPT). This test uses a module that can be attached to a cone penetration test (CPT) which contains a heating element and temperature sensors. In this test, the penetration trough the soil is stopped at a required depth, the heating element is then activated, and the thermal response of the probe is measured. This thesis presents an interpretation method that can predict the thermal conductivity of soils based on the thermal response of the HF-CPT. The interpretation method is validated by conducting laboratory tests in four different materials: moist sand, saturated sand, kaolin clay and a water-agar mixture. With the interpretation method, excellent results are found with the laboratory tests conducted in saturated sand, kaolin clay and the water-agar mixture.<br/><br/>The interpretation method is suitable for offshore testing, as the runtime of the method is short and the storage space is low. The interpretation method gives an accurate prediction for testing duration of about 300 seconds, which is fast when compared to other in-situ tests to measure the thermal conductivity of the soil. With this interpretation method, the HF-CPT can become a successful new in-situ test to determine the thermal conductivity of offshore soils. This way, the thesis contributes to the implementation of geothermal energy solutions and offshore cable routes for wind farms.<br","HF-CPT; CPT; Thermal Conductivity; Volumetric Heat Capacity; Offshore; Soil Investigation","en","master thesis","","","","","","","","2023-05-29","","","","Geo-Engineering","",""
"uuid:2ef4a855-2da8-44d2-8f25-b55f88e98b4f","http://resolver.tudelft.nl/uuid:2ef4a855-2da8-44d2-8f25-b55f88e98b4f","Offshore Pile Drilling From a Floating Vessel: A Dynamic Heave Compensation Analysis","Ursem, Youri (TU Delft Mechanical, Maritime and Materials Engineering)","van der Stap, A.C.M. (mentor); van der Male, P. (mentor); Helmons, R.L.J. (mentor); Delft University of Technology (degree granting institution)","2022","To fulfil the ever-increasing need for wind energy, European offshore wind farm sites are selected in deeper waters with seabed conditions which can consist of hard consolidated sediments or even rock. The deeper sites require the use of floating wind turbine foundations that are moored off to anchor piles in the seabed. For rock seabed sites, the anchor piles must be drilled. As the water depth of these sites increases, commercially available jack-up vessels are no longer able to operate. Therefore, the anchor pile drilling operation must be performed from the deck of a floating vessel. An extensive techno-economic analysis has led to the finding that a topside-operated drilling rig mounted on a large construction support vessel with heave compensation (HC) added is the most cost-effective configuration. The performed research focuses primarily on the determination of which HC method is most effective at changing water depths of 50 m up to 200 m. Leading to the understanding which site requires the use of active HC, limiting the resources required to construct future floating wind farms. The configurations are tested for relevant wave conditions, determined by assessing potential European floating wind farm sites.<br/><br/>Firstly, the research assesses the maximum allowable topside displacements before the drilling column reaches either the operational limits of plastic failure or bottom hole assembly lift-off. Secondly, the operational vessel motions are determined for the relevant environmental conditions. By comparing the results, the need for HC in the drilling configuration is determined. Third and finally, the passive and active HC methods are assessed for a 3-hourly time simulation under the before-mentioned environmental conditions. The assessment is performed using two performance criteria; weight on bit variation and the occurring drill-string stresses. <br/><br/>The performed analyses and simulations show that the vertical upward vessel motion is the limiting factor for the operation’s workability. Also, HC is required in every considered environmental condition. Further, the system operating with passive compensation shows a decreased stiffness with respect to the active system, most noticeable at 50 m water depth. This leads to higher frequency vibrations and stress variations being present in the drill-string of the active system. This effect is no longer noticeable for water depths larger than 50 m.<br/><br/>For locations with a water depth of 50 m, the active system shows favourable workability results. The active system shows a larger sensitivity to wave conditions with larger wave heights, as the stiffness is larger and more stress variations occur as a response. However, the results remain more favourable in comparison to the passive system as the lift-off percentage is significantly smaller. The passive and active systems show similar results when considering short waves in 50 m water depth, this is best witnessed in the weight on bit and lift-off percentages.<br/><br/>For locations with a water depth of 100 m and 200 m, the active and passive HC systems show comparable results for the performance criteria, for all considered wave conditions. The stresses remain within the ultimate limit state, the fatigue damage is negligible in comparison to the time required to perform the drilling operation, and the lift-off percentage for both configurations are in the same order. Therefore, as the workability of the two systems are so comparable for a water depth of 100 m and 200 m the availability, day-rate, and mobilisation complexity of the equipment will determine which HC system is most effective per project.","","en","master thesis","","","","","","","","2024-12-06","","","","Offshore and Dredging Engineering","",""
"uuid:a05e39a3-2a33-40e7-b84f-e1e9ddbd6599","http://resolver.tudelft.nl/uuid:a05e39a3-2a33-40e7-b84f-e1e9ddbd6599","Burst Pressure Prediction of Cord-Rubber Composite Pressure Vessels: Using Global-Local Nonlinear Finite Element Analysis","Bhosale, Ahaan (TU Delft Aerospace Engineering)","Chen, B. Y. (mentor); van Campen, J.M.J.F. (mentor); Barendse, R. (graduation committee); Delft University of Technology (degree granting institution)","2022","This project aims at developing a model to predict the damage initiation and propagation in a cylindrical filament-wound cord-rubber structure under internal pressurization using non-linear FEA, and is conducted in cooperation with TANIQ BV, Netherlands.<br/>Cord-reinforced rubber composites are used in several safety-critical industries such as oil and gas and civil plumbing. Despite their widespread use, limited research is available that focuses on the single-cycle damage phenomenon that may occur in events such as over-pressurization.<br/><br/>The aim of this project is to close this knowledge gap by developing a theory that accounts for the key damage modes present in CRC structures. This involves experimental studies for material characterization and identification of relevant damage modes, the creation of a novel fibre overlap model that accurately replicates the meso-level filament-wound structure, and translation of the experimentally verified damage modes into functional damage initiation and propagation laws using a global-local FEA model. Verification of the created damage model is done experimentally on samples manufactured and tested at TANIQ, with differences between model predictions and experimental burst pressures being $\approx 6.5\%$. This is a marked improvement over Taniq's current FEA model, which overpredicts the solution by $\approx 27\%$.<br/><br/>The successful implementation of this model would help industries like TANIQ build efficient, strong, and lightweight rubber composite parts for various industries, thus adapting aerospace design principles to the development of more commonplace apparatus.<br","FEA Simulation; Composites; Rubber; Filament Winding; Damage; Pressure vessel","en","master thesis","","","","","","","","2024-12-15","","","","Aerospace Engineering","",""
"uuid:0a2c401d-9d61-46cd-bd9c-7149009264a4","http://resolver.tudelft.nl/uuid:0a2c401d-9d61-46cd-bd9c-7149009264a4","Effect of mechanical properties of paint on the craquelure propagation within historical paintings modelled as multilayered structure","Lefferts, Mathijs (TU Delft Mechanical, Maritime and Materials Engineering)","Dik, J. (mentor); Vandivere, Abbie (graduation committee); Suiker, Akke S. J. (graduation committee); Delft University of Technology (degree granting institution)","2022","","craquelure; mechanics; Painting","en","master thesis","","","","","","","","","","","","","",""
"uuid:e1f9f4ab-a33d-477c-aea4-a0efb9c590a8","http://resolver.tudelft.nl/uuid:e1f9f4ab-a33d-477c-aea4-a0efb9c590a8","Design overview of a thermally stable high NA telescope using ceramics and composite materials","Heezen, Emile (TU Delft Mechanical, Maritime and Materials Engineering)","Delft University of Technology (degree granting institution)","2022","Laser satellite communication offers new opportunities in global data transfer, and can provide crucial infrastructure to facilitate the ever-growing demand. Creating an optical link of 10.000 km in length requires a telescope with extreme thermal stability, in an environment where thermal loading is periodical as a result of the satellite’s orbit. As requirements get increasingly demanding, all-aluminium telescope designs require more and more complex solutions to work around thermal gradients. This thesis presents a number of telescope designs comprising different material combinations in order to increase thermal stability, including silicon carbide (SiC) and carbon fibre, integrated with aluminium where possible. Difficulties in manufacturing and alignment are treated as they have a critical impact on final performance. A critical thermal load case is defined for which the performance of each design can be tested. The most promising design comprises a carbon fibre hexapod in combination with an aluminium spider, which was built and tested for validation. The thermal stability was improved by factor 20 with respect to an all-aluminium design.","Telescope; Thermal stability; CFRP; Optomechatronics; Laser Communication","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Optomechatronics","",""
"uuid:21f8b29b-f87c-4099-8d2e-9b2b9ad7d86b","http://resolver.tudelft.nl/uuid:21f8b29b-f87c-4099-8d2e-9b2b9ad7d86b","The trade-offs between redundancy and flexibility orientated risk mitigation strategies for improving supply chain performance under disruptive risk","van Walsum, Joost (TU Delft Technology, Policy and Management)","Kwakkel, J.H. (mentor); Comes, M. (mentor); Delft University of Technology (degree granting institution)","2022","This thesis examines the trade-off relation between flexibility- and redundancy-orientated strategies and their impact on improving supply chain performance under disruptive forces. It does so by evaluating the supply chain practices at the Ministry of Defence in the Netherlands. Seeking to improve performance in terms of cost efficiency, and continuity of supply flow while disruptions affect multiple regions of the supply chain.","Discrete Event Simulation; Supply chain resilience; Simio","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:1ee4afca-4b5f-4cad-bff6-97f1908ae0dd","http://resolver.tudelft.nl/uuid:1ee4afca-4b5f-4cad-bff6-97f1908ae0dd","The transition from structures to textures in magnetorheological fluids","van Kuik, Thobias (TU Delft Mechanical, Maritime and Materials Engineering)","van der Meer, G.H.G. (mentor); van Ostayen, R.A.J. (mentor); Breugem, W.P. (graduation committee); Botto, L. (graduation committee); Delft University of Technology (degree granting institution)","2022","A magnetorheological fluid is a type of smart fluid that can change its rheological properties when a magnetic field is applied to the fluid. The fluid is a suspension of magnetizable particles in a non-magnetic carrier fluid. When a magnetic field is applied to the fluid, the particles will form structures along the magnetic field lines. These structures resist flow, thereby increasing the viscosity of the fluid. In a non-uniform magnetic field that is generated by a permanent magnet, the particles separate from the fluid and aggregate on the surface of the magnet. This phenomenon is of use in hydrodynamic bearings, where textures are used to increase the load capacity of the bearing. Replacing the fluid in the bearing by a magnetorheological fluid and placing permanent magnets at the desired texture locations, results in particles separating from the fluid, aggregating on the permanent magnets and forming textures. These textures are of a self-healing nature, because any particle that is sheared off, returns into the fluid and is replaced by another particle. Currently, not much is known about the formation of these textures and the influence of their formation on the rheological behavior of the magnetorheological fluid. Therefore, several discrete element models are constructed, that can simulate a magnetorheological fluid in non-uniform field. These models use basic physical laws to determine the dynamics of the particles. A single core model is constructed to simulate the behavior of the magnetorheological fluid in small domains using two different methods for the magnetic interaction forces between the particles. A parallel model is made to simulate the magnetorheological fluid in larger domains. Finally, a model that is used to simulate particulate flows, is modified to research whether two-way coupling is required to determine the steady state behavior of the magnetorheological fluid. The models show that the particles do not separate from the fluid due to the attractive force of the magnet by itself, but rather by a combination of the attractive force and the deformation of the structures when a flow is applied. Furthermore, the rheological behavior of the fluid can still be approximated using the standard viscoplastic models. Finally, the modified particulate flow model showed that two-way coupling is not required to determine the steady state behavior of the magnetorheological fluid.","magnetorheological fluid; Discrete Element Method; parallel computing; surface texturing","en","master thesis","","","","","","","","2024-12-06","","","","Mechanical Engineering | Mechatronic System Design (MSD)","",""
"uuid:38f68cf0-91ef-41cb-970e-f4f211b1f861","http://resolver.tudelft.nl/uuid:38f68cf0-91ef-41cb-970e-f4f211b1f861","Challenges and opportunities for material recovery and reuse in the construction &amp; demolition industry in Zuid-Holland and the role of Blockchain","Chiodo, Alex (TU Delft Technology, Policy and Management)","Peck, David (mentor); Van den Berghe, K.B.J. (graduation committee); Delft University of Technology (degree granting institution)","2022","Urban areas are becoming more densely populated. More than 50% of the global population is already located in them. The Netherlands is among the countries with the highest population density. In 2017, 80% of its population was living in urban areas. It is expected that by 2050 the Netherlands will need between 300’000 and 1.6 million new homes. Construction &amp; demolition (C&amp;D) is characterized as a rsource-intensive industry and among the largest consumer of ntural resources. Urban areas account for 80% of global greenhouse gas emissions (GHG) and their infrastructures generate 50% of the total waste produced on earth. Additionally, the increased demand for housing and infrastructure will lead to increased demand for virgin materials and resources, and in turn more waste. From this perspective, the C&amp;D industry will provide a significant contribution to sustainability and will be an important industry for the transition towards a circular economy (CE). The Netherlands has set very ambitious circularity targets for this industry. Specifically, the Government’s Real Estate Agency and Rijkswaterstraat must become fully circular by 2030. Circularity principles address the entire life-cycle of goods and resources, including <br/>waste management practices. The overarching objective is to keep resources within closed loops and at their highest level of utility without losing their technical and economic integrity. As of now, 88% of waste generated yearly by the Dutch C&amp;D industry is currently down-cycled for road backfilling purposes, 1-3% is currently reused or up-cycled for high-value practices and the remaining is incinerated.<br/><br/>The objective of this study is to identify the challenges that are characterizing recovery and reuse practices in the C&amp;D industry in Zuid-Holland and make a preliminary assessment on whether Blockchain (through DLT and Smart contracts technologies) can be a suitable solution for addressing them. The methods<br/>employed for conducting this study blend desk research with qualitative research (in the form of semistructured interviews) and a decision-making framework to assess the use of Blockchain technology.<br/><br/>The results indicate that the materials and construction elements to be considered more interesting concerning reuse and recovery are bricks, steel profiles and window/door frames. The decision-making process driving their reuse and recovery is company-specific and differs significantly across firms. In general, the data required for assessing the feasibility of reuse and recovery for construction elements are the material composition of new and old buildings, supply-and-demand specific information (volume and timing), technical specification and quality-related data as well as market prices. Challenges characterizing reuse and recovery practices are several. First, construction and demolition activities and asset management practices are asynchronous and separated by large time gaps. Material procurement starts significantly earlier than demolition activities and the process needs to be accurate and based on<br/>reliable data. Data management practices are inconsistent and not harmonized among companies. Digital asset management tools (such as BIM), are employed by large companies only and their use on a national scale is neither harmonized nor compulsory. These aspect limit the economic feasibility of reuse and<br/>recovery practices as the accuracy and reliability of data for driving decision-making is poor or nonexisting. Intra-project and intra-firm data sharing are therefore not possible. A Blockchain system which integrates smart contracts and distributed-ledger-technology (DLT) can partly address and tackle these<br/>issues. To address them fully, however, Blockchain technology must be combined with an asset management tool like BIM for making the solution consistent and scalable at an industry level which in turn requires the implementation of national and industry-wide data management protocols and standards that would harmonize the collection, management and distribution of data across the C&amp;D industry. The Netherlands, unlike other EU member states, has, at this point, no government-driven digitalization strategy in place and is rather opting for a market-driven transition.","Blockchain; Construction process; Sustainability; Reuse; Waste management","en","master thesis","","","","","","","","","","","","Industrial Ecology","",""
"uuid:5c6cffa9-7a27-4d3a-a8c6-e5bd621a47dc","http://resolver.tudelft.nl/uuid:5c6cffa9-7a27-4d3a-a8c6-e5bd621a47dc","Measuring Polkadot: The Impact of Tor and a VPN on Polkadot's Performance and Security","van Stam, Just (TU Delft Electrical Engineering, Mathematics and Computer Science)","Roos, S. (mentor); Delft University of Technology (degree granting institution)","2022","Begun in 2020, Polkadot is one of the largest blockchains in market capitalization and development. However, privacy on the Polkadot network has yet to be one of the key focus points. Especially unlinkability between the user’s IP address and Polkadot address is essential. Without this unlinkability, users are vulnerable to targeted ads, manipulation, blackmail, reputational damage, financial loss, physical harm, discrimination, and more. This thesis investigates the viability of Tor or a VPN with Polkadot as external privacy-enhancing tools to hide the user’s IP address, as users aiming to achieve unlinkability cannot easily change the Polkadot code.<br/><br/>To analyze the viability, we set up a measurement study to examine the performance of a Polkadot full node behind Tor or a VPN. We investigated, among other things, the latency, throughput, and the number of discovered and connected peers to determine the performance of three Polkadot full nodes located in London, Seoul, and North California. Furthermore, we did a security analysis to determine any vulnerabilities that could emerge from using Polkadot with either of the network environments. And we investigated in-depth the susceptibility of the Polkadot node to an Eclipse attack, as previous research has shown that Bitcoin with Tor was vulnerable to an Eclipse attack.<br/><br/>Our results show that a Polkadot node with Tor has considerably high latency and cannot maintain long-lasting connections. The short connection time decreases the time to perform an Eclipse attack on a Polkadot node from a couple of months and weeks for the normal and VPN environment to potentially six days or less for the Tor environment. We calculated the cost of running an Eclipse attack to be approximately €482 per week. The Polkadot node behind the VPN does perform considerably better. The Polkadot node in London, behind the VPN located in Frankfurt, performed similarly in terms of latency to the Polkadot node in a normal network environment. However, the Polkadot nodes in both<br/>the Tor and VPN environment have only outgoing connections. If too many nodes ran behind one of these environments, fewer peers would be able to establish connections with one another, resulting in network partitions or network failure.<br/><br/>This study emphasizes the importance of unlinkability between a Polkadot user’s address and IP. However, using Tor or a VPN as privacy-enhancing tools could impact the security of the Polkadot node and the whole Polkadot network. So users should avoid using Tor with Polkadot and carefully consider the tradeoff between privacy and security when using a VPN. The security issues mentioned in this thesis should be further investigated and tested. Furthermore, a default solution built into the Polkadot source code should be investigated.","Blockchain; Polkadot; Privacy; Unlinkability; Tor; VPN; Measurement; Eclipse Attack","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:76a685e5-2273-4e3f-8503-3e26d6f3e40f","http://resolver.tudelft.nl/uuid:76a685e5-2273-4e3f-8503-3e26d6f3e40f","Modelling information-flow in formal organisations: Case study of the Dutch Military Air Transport Unit","Janssens, Luka (TU Delft Technology, Policy and Management)","Comes, M. (mentor); Kwakkel, J.H. (graduation committee); Lont, Y.L. (graduation committee); Delft University of Technology (degree granting institution)","2022","The Dutch Ministry of Defence fulfils a crucial role in keeping the Dutch kingdom safe. From missions overseas to providing aid in the case of natural disasters, correct and efficient information-flow is critical for their operations. When a situation occurs, everything is dropped to make sure that they can handle it. The Royal Dutch Army, Navy, Airforce and Marechaussee make up the armed forces part of the military. Besides the branches of the armed forces, there are two support branches. Under one of them, Defensie Ondersteuningscommando, the Air Transport Unit of the Dutch military is located. This unit plans and advises on all forms of air transport for the Ministry of Defence, a unit where correct and timely information is flow critical.<br/>This thesis attempts to answer the following research question: What are the effects of formal network structures within public organisations on their information-flow quality? Attempting to fill gaps in literature surrounding the effect of formal network structures on information-flow quality. The study defines information-flow which is used for the KPIs. The effects of formal network structures on information-flow quality are studied using an ABM model developed in this thesis. The model is tested on the Air Transport Unit network and a diverse set of randomly generated networks. In this case, key findings from the model results indicate that in the case hierarchy, a more hierarchical structure positively affects their data correctness. However, this more hierarchical structure negatively affects their information timeliness. Employee business does not seem to be affected by hierarchy. Other findings relating to the number of employees whose function it is to control data for mistakes, have significant effects on improving data correctness while at the same time, negatively affecting the timeliness of information. Indicating that the optimum, hierarchical, or less hierarchical organisation lies with the ambitions and goals of an organisation. <br","ABM; Military; Information","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:98b46d33-c677-46be-b45f-f69799a71fe1","http://resolver.tudelft.nl/uuid:98b46d33-c677-46be-b45f-f69799a71fe1","Magnetic field SLAM: using an inertial human motion suit and reduced rank Gaussian process regression","Veen, Thijs (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Delft Center for Systems and Control)","Kok, M. (mentor); Osman, M.E.A. (mentor); Delft University of Technology (degree granting institution)","2022","Indoor localisation is a growing field of interest in recent studies. While GPS (global positioning system) is a standard for outdoor localisation, no such solution exists for indoor applications. The literature provides several methods to obtain the location of indoor systems, often using optical sensors. A small number of recent studies use the indoor magnetic field for localisation. Ferromagnetic materials in the structure of buildings cause magnetic anomalies that are distinct enough to use for localisation. To use the magnetic field for localisation, a map has to be created.<br/>In this thesis, a sensor setup different from other studies is used. This sensor setup consistsof a inertial HMTS (human motion tracking suit), containing seventeen IMUs (inertial measurement units) with magnetometers. This suit uses advanced techniques to obtain a better pose estimate than a single IMU can achieve. The combination of an inertial motion tracking suit with a magnetic localisation approach has not been studied before. Inspired by the state of the art approaches, a SLAM (simultatenous localistation and mapping) algorithm is proposed that is able to use information from the inertial HMTS. The algorithm consists of a reduced rank GP (Gaussian process) to create a map of the magnetic field. A RBPF (Rao-Blackwellized particle filter) is used to localise the HMTS. The algorithm allows for the use of multiple magnetometers to create the magnetic field map instead of a single one, which is a novelty.<br/>The proposed method is tested with real-life data. Live odometry obtained from the HMTS can be post-processed for improved inertial odometry. Both the live and post-processed odometry data from the HMTS is used in the proposed algorithm and the results are compared. Additionally, the differences between a magnetic field map constructed with a single magnetometer and a map constructed with multiple magnetometers is investigated. The trajectory estimated by the RBPF is compared to a groundtruth, obtained by an optical tracking system. The RBPF shows higher performance for trajectories longer than 250 seconds compared to the inertial odometry. The use of multiple magnetometers does not improve the performance of the algorithm.","Magnetic field SLAM; Gaussian process regression; Inertial human motion tracking; Kalman filter","en","master thesis","","","","","","","","","","","","Mechanical Engineering | Systems and Control","",""
"uuid:e8253e05-06f4-47a9-9d8a-da340734fd59","http://resolver.tudelft.nl/uuid:e8253e05-06f4-47a9-9d8a-da340734fd59","POD-based surface pressure reconstructions from sparse sensing: An experimental investigation","Hendriksen, Luuk (TU Delft Aerospace Engineering)","Sciacchitano, A. (mentor); Delft University of Technology (degree granting institution)","2022","Aerodynamic load determination through integration of the surface pressure distribution is limited in accuracy by the discrete number of measurements taken. Therefore, typically relatively large numbers of spatially distributed measurements are required which increase setup complexity, latency, cost and weight while requiring physical access in and around the model to house transducers/taps. Especially in practical settings outside of a wind tunnel, such setups might be unfeasible and a reduction in the required number of measurements desired. In this thesis work, experimental measurements of the surface pressure distribution around a bluff body square cylinder model are combined with a modal decomposition method; Proper Orthogonal Decomposition (POD) to encode the system in a low-dimensional representation. This low-dimensional representation is used for the determination of optimal sensor placement which is in turn used for sparse surface pressure measurements on the model at various angles of attack. An extension to the POD, known as Gappy POD (GPOD), combines the low-dimensional representation with the sparse measurements to infer full state surface pressure reconstructions at a reduced number of sensors. Based on this outlined approach, experimental surface pressure distributions and drag coefficients have been reconstructed in reasonable accordance with corresponding references at sparsity levels up to 85%. GPOD + tailored sensor placement can therefore effectively be used to relieve the sensor requirements in practical settings if prior experimental ‘training’ is an option. To reduce reliance on experimental measurements, RANS simulations were used for sensor placement and dominant low-dimensional flow feature identification instead as well. RANS simulations lacked the accuracy to replace experimental training through POD as reconstructions could not consistently remain accurate.","Proper Orthogonal Decomposition; Gappy POD; Sparse sensing; Surface pressure; Bluff body aerodynamics; Reduced Order Model; Experimental; Sensor placement; Drag determination","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:1911a06e-da04-4047-b51c-8a4b563d43d2","http://resolver.tudelft.nl/uuid:1911a06e-da04-4047-b51c-8a4b563d43d2","CFD Simulation of a Floating Wind Turbine with OpenFOAM: an FSI approach based on the actuator line and relaxation zone methods","Frontera Pericas, Pere (TU Delft Aerospace Engineering)","Viré, A.C. (mentor); De Tavernier, D. (mentor); Delft University of Technology (degree granting institution)","2022","Floating offshore wind turbines (FOWTs) have the potential to harness wind resources in deepwater, which is so far prohibitive for conventional approaches. This, however, comes at a cost: the platform’s extra degrees of freedom (DoFs) introduce complex aerodynamic and hydrodynamic behaviours. Therefore, FOWTs must be accurately modeled to reduce load uncertainties that ultimately prejudice their economic viability.<br/><br/>This project implements a framework for the coupled, high-fidelity simulation of FOWTs in OpenFOAM. The tool is built upon two existing libraries: turbinesFoam—for rotor modeling based on the actuator line method— and waves2Foam—for wave-field generation and absorption based on the relaxation zone method. The multi-phase simulation uses the interFoam solver in combination with a morphing mesh technique and rigid-body model to represent the platform. The mooring restraints are computed with a quasi-steady, catenary model from waves2Foam. The turbinesFoam library, targeted at bottom-fixed turbines, is modified so that it can accommodate arbitrary motions along the rigid-body DoFs. The platform-turbine FSI coupling follows a serial sub-iterating strategy based on the PIMPLE scheme.<br/><br/>The presented framework proved capable of modeling the aerodynamic performance of turbines under prescribed motion and produced plausible results for a semi-submersible FOWT under combined wind and wave conditions. Once carefully validated, this tool will have the potential to serve as a reliable technique for the advanced modeling of FOWTs.","Floating Wind Energy; Offshore Wind Turbines; CFD; FSI; OpenFOAM; Actuator Line Method","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:35e245ed-3b4f-44d4-a119-1065f2fa07e5","http://resolver.tudelft.nl/uuid:35e245ed-3b4f-44d4-a119-1065f2fa07e5","VQLS Read the Fine Print: Practical Challenges for Solving the Poisson Equation by Means of a Variational Quantum Linear Solver","Verduyn, Thomas (TU Delft Aerospace Engineering)","Gerritsma, M.I. (mentor); Delft University of Technology (degree granting institution)","2022","The need of computational power for engineering applications has been ever increasing and with classical computers approaching their physical limits, new ways of improvement have to be investigated. One of the promising solutions is quantum computing. Most engineering problems require solving a system of linear equations of higher dimensions and the Variational Quantum Linear Solver (VQLS) algorithm seems like a promising near term solution. This algorithm evaluates a cost function on a quantum machine and uses a classical optimizer to minimize this cost function. The minimum of this cost function corresponds to the solution of the linear system. This work aims at finding what the practical limitations are when solving the Poisson equation by means of VQLS. Results showed that problems small in size can be solved, however for larger problems obtaining the solution becomes effectively impossible due to barren plateaus, which are flat spots in the cost function landscape.","Quantum Algorithms; Poisson equation; Quantum Computing; Qiskit; Barren Plateaus; Optimisation; Quantum Mechanics; Variational Quantum Linear Solver; Variational Quantum Algorithm; Decomposition","en","master thesis","","","","","","","","","","","","Aerospace Engineering","",""
"uuid:cf3bf4e1-6328-4bd5-900c-5dada0e5caa9","http://resolver.tudelft.nl/uuid:cf3bf4e1-6328-4bd5-900c-5dada0e5caa9","Stability Analysis of a Rapid Mechanical Lifting System for the Vertical Transportation of Polymetallic Nodules","Mes, Willemijn (TU Delft Mechanical, Maritime and Materials Engineering)","Helmons, R.L.J. (mentor); Naaijen, P. (graduation committee); Hendrikse, H. (graduation committee); van Rhee, C. (graduation committee); van der Wal, Remmelt (graduation committee); Delft University of Technology (degree granting institution)","2022","Due to urbanization, improved living standards and electrification, approximately five times more raw minerals are necessary in 2050 compared to 2018. In deep oceans, the seafloor contains these minerals in the form of polymetallic nodules. Nodules are about the size of golf balls that grow throughout the ocean at depths between 3500 m and 6000 m. They contain a wide variety of metals, such as manganese, copper, nickel, cobalt. Nowadays, for large-scale applications, hydraulic lifting is almost exclusively considered for vertical transportation through the water column. However, there is little research available about using other techniques instead. To tackle this knowledge gap, this thesis studies the feasibility of transporting the nodules using a concept of mechanical lifting. The concept used in this thesis consists of two alternating containers that are lowered and hoisted by lifting and guidance wires. Due to the conditions, such as the large depth, the environmental characteristics and the positioning and heading of the vehicles, there are technical uncertainties regarding mechanical lifting. Risks include the yaw rotation of the container, which might result in rope entanglement and wearing of the ropes. This thesis presents a study into the yawing stability of the concept of mechanical lifting for the vertical transportation of polymetallic nodules, which is a crucial factor to operate reliably.<br/> <br/>The research question is answered by performing an experimental test and a CFD analysis. The experimental tests include the dynamics of the system while testing various configurations and is validated by an analytical integration in time and a CFD simulation at model scale. The CFD analysis takes away the uncertainties and unknowns: the drag force, the yawing moment and the fluctuation magnitudes and frequencies. The CFD analysis is performed using the open-source software OpenFOAM and simulates multiple configurations. The results of the simulations are compared to the restoring moment by the guidance wires, by transforming the excitation moments into static and dynamic responses of the system. The CFD model is validated by testing the model with a 2D cylinder and 3D sphere, and by performing a mesh convergence study. The CFD simulations are validated by literature. With the obtained drag forces, the energy consumption is calculated.<br/> <br/>From the results, it can be concluded that the system can stably be transported at 2 m/s, as the static and dynamic responses are well within the safety limits. The largest response occurs in the middle of the water column, as the rotational stiffness is the smallest at that location. The dynamic response is smaller compared to the static response, as the high frequent fluctuations (f &gt; 0.075 Hz) are damped. Rope entanglement will not occur during normal operation at 2 m/s. However, critical situations due to incidental events can arise, including a winch failure, friction or a sudden high current. This has not been evaluated in this research and therefore stability cannot be guaranteed. As lowering at 3 m/s with an inclined system and including the current results in a static maximum yawing rotation larger than the safety limit, the stability cannot be guaranteed for operating at 3 m/s.","","en","master thesis","","","","","","","","2024-12-13","","","","Offshore and Dredging Engineering","",""
"uuid:d28a4e1f-7d41-42f6-a652-12959a04d2cd","http://resolver.tudelft.nl/uuid:d28a4e1f-7d41-42f6-a652-12959a04d2cd","Sediment and Phosphorus Removal in a Decentralized Stormwater Treatment System: Assessing the performance of a modified SediSubstrator L in the city of Amsterdam","Little, Emma (TU Delft Civil Engineering & Geosciences)","van der Hoek, J.P. (mentor); Langeveld, J.G. (graduation committee); Rutten, M.M. (graduation committee); van de Ven, F.H.M. (mentor); Smits, Frank (graduation committee); Rip, Winnie (graduation committee); Delft University of Technology (degree granting institution)","2022","In the context of climate change and urbanization, sustainable urban drainage systems (SUDS) are widely adopted measures to manage stormwater in the city on-site. However, their performance in practice often differs from modelled and laboratory-scale predictions due to the variability in properties of real sediments (in terms of size, shape, density and coagulation) compared to the silicate standard Millisil®W4. Clogging is a common source of failure. <br/>The SediSubstrator L is a decentralized stormwater treatment device installed as a pre-treatment step to mitigate clogging in a storage and infiltration system on the Rooseveltlaan in Amsterdam. It consists of a sedimentation pipe with a flow-separating grate, the SediPipe, and a filter-adsorbent, the SediSorp+. It is purported to remove 80 % of TSS by DiBT (the technical authority in the German construction sector) test principles that use Millisil®W4 to simulate real sediments. The full-scale unit was monitored in the city throughout May-September 2022 to assess its performance. <br/>The stormwater runoff discharged from the catchment had high concentrations of lead (54 μg/L) and zinc (790 μg/L), likely due to contact with gutters and old roofing material, amplified by the relative contribution of these roofs to the total catchment discharge (accounting for 50 % of the area contributing to runoff). The sediment (TSS) concentration was low, equivalent to 20 mg/L on average. The sediments were also light and fine—with an organic fraction of 66 % and with 78 % of diameter smaller than 63 μm.<br/>In the SediSubstrator L, the TSS removal efficiency was 34 % on average. This corresponds to an estimated caught load of 2.7 kg for this period. The removal efficiency was shown to increase with an increasing stormwater TSS concentration, with longer antecedent dry periods and with lower TSS organic fractions. Turbidity dynamics in the system suggest that while a net sequestration of solids occurs in the SediPipe, there is a resuspension of fine solids. This was observed in a camera inspection to occur from solids which settle on or near the grate. In an extreme rainfall event on September 28th 2022, water collected on the section of the street connected to the SediSubstrator, the cause of which is still subject to speculation. The observed SediSorp+ filter resistance across the summer was not indicative of gradual clogging, but an inspection showed signs of decayed organic matter throughout the full length of the filter bedas well as traces of cement in two of the four cartridges. It is possible that these two effects together with turbulent inflows prompted the acute clogging behavior. <br/><br/>There is interest in using the SediSubstrator beyond the city of Amsterdam to reduce phosphorus loadings in the road runoff discharged to sensitive nature areas. On the Rooseveltlaan, the average total phosphorus removal efficiency was 18 % (50 % for dissolved, readily bioavailable ortho-phosphate). Interactions with settled sediments generated ortho-phosphate in the SediPipe, and fine particulate and colloidal organic phosphorus was shown remobilized in both the SediPipe and SediSorp+. The removal of ortho-phosphate in theSediSorp+ in natural rainfall was good (on average 50 %) and was shown to be consistent at different contact times (approximately 10-30 minutes). <br/>The installed unit should be monitored over a longer time period of two years for statistical significance and to capture seasonal variation in loads. Nevertheless, the removal efficiency observed on site is consistent with the results of a sedimentation model developed according to Ferguson &amp; Church (2004), using a stormwater sediment particle density as measured at another location in the city. Design adaptations are recommended to improve the SediSubstrator L to the conditions observed in Amsterdam: namely, better site selection, a longer SediPipe section (24 m) and a second filter stage to better capture the fine suspended solids.","","en","master thesis","","","","","","","","","","","","Civil Engineering | Environmental Engineering","",""
"uuid:6bbd6c4b-f3bd-4fbb-b003-2b902a412d3f","http://resolver.tudelft.nl/uuid:6bbd6c4b-f3bd-4fbb-b003-2b902a412d3f","Studies on coordinated traffic control: Using variable speeds and testing demand predictions","van der Horst, Gerben (TU Delft Civil Engineering & Geosciences; TU Delft Transport and Planning)","Hegyi, A. (mentor); Salomons, A.M. (graduation committee); Dabiri, A. (graduation committee); van Katwijk, R.T. (graduation committee); Delft University of Technology (degree granting institution)","2022","Urban mobility is challenged with increasing demand, while at the same time reducing emissions, without leading to an unpleasant living environment. Reducing the number of stops on the urban arterial controlled by the coordinated traffic controller can provide (part of) the solution to these challenges for urban mobility. Coordinated traffic controllers are subject to some limitations, especially regarding coordination between locally optimal signal timing plans and proactive optimization of the coordination with regards to traffic demand. These limitations where explored in this thesis, where a variable speed was proposed to be able to provide coordination between locally optimal signal timing plans and where the usage of predictions with regards to proactive optimizations was tested. A theoretical study showed no realistic potential for coordination between unequal cycle times, however theory does show significant potential of the usage of a variable speed for coordination between locally optimal signal timing plans, when coordinating in two directions. This potential of the variable speed was confirmed by using the MAXBAND model and performing a simulation study, which indicated a significant decrease in stops on the main arterial over optimizing with a fixed speed. Furthermore, the variable speed allowed for a lower network cycle time, which resulted in a decrease in delay on the side directions. Tests of demand predictions in TopTrac yielded no significant improvements of stops nor delay. In the investigated network, control decisions of the coordinated traffic controller did not correlate closely with fluctuating demand, which is needed for a prediction of the demand to produce significant improvements regarding the stops and delay in the network. Future research should focus on the variable speed, evaluating the theoretical applications in other networks and exploring the practical applications, potentially via Intelligent Speed Adaptation (ISA).","Coordinated traffic control; Variable speed; Demand prediction; Coordinated; Traffic; Control; Variable; Speed; Demand; TRANSYT; MAXBAND","en","master thesis","","","","","","","","","","","","Civil Engineering | Transport and Planning","Master Thesis",""
"uuid:e9bc9fcd-cff1-4699-ba71-732572cd0af6","http://resolver.tudelft.nl/uuid:e9bc9fcd-cff1-4699-ba71-732572cd0af6","Tax Shift for Circularity: a policy-oriented life cycle costing analysis of two construction case studies at the Floriade","van Ginkel, Manon (TU Delft Technology, Policy and Management)","Peck, David (mentor); Van den Berghe, K.B.J. (mentor); Bucci Ancapi, F.E. (mentor); Polet, M. (graduation committee); van Oppen, C. (graduation committee); Delft University of Technology (degree granting institution); Universiteit Leiden (degree granting institution)","2022","The Circular Economy (CE) has emerged as an economic paradigm that could provide a pathway to sustainable development. The transition to a CE is a complex process requiring wide multi-level and multi-stakeholder engagement, which can be facilitated by appropriate policy interventions. As value retention processes in the CE require additional labour, the transition from a linear to a circular economy can be viewed as a transition from a capital-based economy to a labour economy. Consequently, a ‘circular tax shift’, based on an introduction of environmental taxation paired with a reduction of labour taxation, could be a powerful lever for public policy.<br/><br/>The aim of this research was to assess the effect of this tax shift on the financial feasibility of circularity in the construction sector. The main research question is: ‘What is the effect of a circular tax shift on the financial feasibility of circular construction, in relation to linear construction?’<br/><br/>To answer this question, a micro-economic analysis has been applied on two circular construction case studies: the ‘The Voice of Urban Nature’ and ‘Circuloco’ pavilions that were built at the Floriade World Expo 2022. A linear and circular variant have been developed for both case studies, for which a life cycle costing analysis has been conducted. A life cycle assessment has been applied to determine the environmental impacts, on the basis of which environmental taxation was applied under the taxation scenarios, which reflected varying levels of the circular tax shift. <br/><br/>The results show that under the current taxation system, the total life cycle costs for the circular variants are 2,0 - 2,7% higher than for the linear variants, though environmental impacts are lower by 38,7 - 52,7%. The effect of the tax shift is that the cost differences between the linear and circular variants decrease, and in two of the high level tax shift scenarios, the circular variant of the Circuloco pavilion becomes more financially feasible than the linear variant. Although the external validity is low, the results of the research imply that the suggested circular tax shift could create incentives to use secondary and biobased materials in construction. <br/><br/>The tax circular shift also implies many other effects, which are outside the scope of this research, but have been suggested as subjects for follow-up research.","Circular Economy; Economic Policy Instruments; Environmental Fiscal Reform; Sustainable Development; Circular Built Environment","en","master thesis","","","","","","","","","","","","Industrial Ecology","",""
"uuid:eb8529e3-b118-46c1-bc4b-350bf286eb38","http://resolver.tudelft.nl/uuid:eb8529e3-b118-46c1-bc4b-350bf286eb38","Exploring the potential reuse of glass bottles in structural columns: Investigating the Structural Behaviour of Glass Columns Containing Glass Bottles through FE-modelling and Physical testing","Maachi, Younes (TU Delft Civil Engineering & Geosciences; TU Delft Applied Mechanics)","Louter, P.C. (mentor); Alkisaei, H. (graduation committee); Noteboom, C. (graduation committee); Justino de Lima, Clarissa (graduation committee); Delft University of Technology (degree granting institution)","2022","Very little research has been done on the potential use of glass bottles in a structural system. Knowledge gathered from past projects showed that individuals or communities usually tend to create structures with glass bottles with a cementitious material, which is usually concrete or mortar. Under vertical compressive loading, the corresponding failure mechanisms should predominately be fractures in either the heel or the shoulder. Using two different finite element models and Weibull Analysis, a characteristic tensile strength of abraded container glass of 20 MPa was found. When structures are created out of glass waste, designs should be made with the abraded state in mind.<br/><br/>Connections concepts are created to connect glass bottles together, i.e. 'Masonry', 'Stacked' and 'Bundled'. The 'Stacked' concept was considered the most suitable for this thesis. Eight different configurations of the Stacked concept were created, of which four were tested in a hydraulic displacement controlled compression machine in Stevinlab. These four configurations were called 'Whole-Up', 'Whole-FF', 'Whole-BB' and 'Cut-Double-BB'. The results showed that the Whole-Up had the highest vertical failure loads, followed by the Whole-FF and Whole-BB configurations, and the Cut-Double-BB have much lower failure loads, which is most likely due to the imperfections at the cut surface.<br/><br/>Following these results, two different design options were created. The final prototype contains a demountable glass bottle column with intermediate plates and plastic elements. A proposed design formula for the vertical compressive design load was created based upon collected data and safety factors. The limitations of the bottle column are mainly the tolerance issues due to the different bottle heights and connections, the costs of the connections and the capacity in comparison with more conventional materials. The bottle column could however be an interesting options for smaller or temporary projects. <br","Reuse; Glass Bottles; Glass; Columns","en","master thesis","","","","","","","","","","","","Civil Engineering | Building Engineering - Structural Design","",""
"uuid:d5dae48e-81d1-477f-be2f-6da2185cef8e","http://resolver.tudelft.nl/uuid:d5dae48e-81d1-477f-be2f-6da2185cef8e","Non-Local Effects of Support Structure Diameter on Wave Induced Fatigue Loads of Monopile-based Offshore Wind Turbines","Castellino, Francesco (TU Delft Mechanical, Maritime and Materials Engineering)","van der Male, P. (mentor); Muskulus, Michael (graduation committee); Daamen, Joris (graduation committee); Delft University of Technology (degree granting institution); Norwegian University of Science and Technology (NTNU) (degree granting institution)","2022","One of the main cost drivers of an offshore wind power plant are the support structures of the wind turbines, it is therefore of primary importance to optimize their design. Among the support structures available, the concept most widely adopted is the monopile-based support structure, whose design is often fatigue-driven. Offshore structures need to withstand the wave loads, that play a major role among the cyclic loads that excite the support structure. The design of the support structure’s geometry is of primary importance, since it determines the structural vibrations.<br/>Therefore, this thesis aims to understand how, varying the diameter of the support structure, affects the wave induced fatigue loads acting on a monopile-based offshore wind turbine. A FE model was developed to represent the structural motion, where the Euler-Bernoulli beam theory was adopted. The linear wave theory was used, and the wave loads were computed according to the Morison equation.<br/>The wave induced fatigue loads were calculated in frequency domain, assuming a narrow-banded response spectrum. A case study was provided by Siemens Gamesa RE, and the wind turbine was assumed in parked mode.<br/><br/>Two assignments were derived, to tackle the research question. First, a sensitivity analysis was <br/>performed, to study the non-local effects on the wave induced loads, due to varying the diameter of the support structure. Then, an analytical optimization was applied to a simplified structure, aiming to find the diameter that minimizes the mass of the support structure, accounting for fatigue damage. The hypotheses of thin wall and deep water regime were assumed.<br/><br/>The results of the sensitivity analysis suggested that the non-local effects do not differ significantly from the local ones, and that to reduce the loads: it is beneficial to reduce the diameter at waterline, to increase it around mudline, while variations along the tower are quite irrelevant to this end. The analytical optimization was run for different load cases. Wave induced fatigue loads alone were first considered,<br/>then a diameter-independent fatigue load was introduced. It was concluded that, accounting for resonant waves only, the smaller the diameter of the support structure, the better.<br","non-local effects; Wave Loads; Offshore Wind Energy; Support structure optimization; monopile foundation; Frequency domain analysis; Sensitivity Analysis; Fatigue Loads; Support Structure Diameter","en","master thesis","","","","","","","","","","","","European Wind Energy Masters (EWEM)","",""
"uuid:9f8d9811-5f32-43da-8714-9fb9f4dc1940","http://resolver.tudelft.nl/uuid:9f8d9811-5f32-43da-8714-9fb9f4dc1940","Three-dimensional visualization of the renal microcirculation using laser speckle contrast imaging","van Ooijen, Lisanne (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Biomechanical Engineering)","Dankelman, J. (mentor); de Bruin, R.W.F. (mentor); Gijsen, F.J.H. (graduation committee); Fang, Y. (graduation committee); Delft University of Technology (degree granting institution)","2022","class=""MsoNormal"" style=""margin-bottom:0cm;line-height:normal"">In the Netherlands, over 12% of the population has chronic kidney damage resulting in about 2000 patients with renal failure each year. Replacement of the kidney function by transplantation is desired, but due to a shortage of donor kidneys, the waiting list for a transplant is long. Extending the criteria that donors must meet can reduce the waiting list, but it is necessary that these organs are still of sufficient quality. Initial studies indicate that using the normothermic machine perfusion (NMP) preservation method results in better transplant outcomes and possibly improves donor kidneys’ quality. The quality of the organ during NMP can be used as a potential biomarker for graft survival. However, what is still missing is a reliable way to test the quality during NMP. Laser speckle contrast imaging (LSCI) is a non-invasive, continuous, real-time imaging technique that can visualize tissue perfusion. In this study, a method is designed to visualize the perfusion over the entire surface of normothermic machine-perfused kidneys using LSCI. A three-dimensional (3D) perfusion model is developed based on two-dimensional (2D) LSCI images. This method can then be used to determine the quality of the perfusion of donor kidneys before they are transplanted.</p> <p class=""MsoNormal"" style=""margin-bottom: 0cm; line-height: normal; background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial;"">A method is designed to obtain LSCI data of porcine kidneys undergoing NMP. Data is recorded during the first 100 minutes of NMP to evaluate the relationship between renal arterial blood flow and perfusion. The kidneys are then placed in six different positions from which LSCI data is collected. Using shape from silhouettes, a 3D model is made from each kidney. The 2D LSCI data is given depth using the 3D model by assigning each pixel a 3D coordinate. The perfusion model is validated by comparing the perfusion model for the situation where no ischemia is present in the kidney and the situation where ischemia is present in the kidney. </p> <p class=""MsoNormal"" style=""margin-bottom: 0cm; line-height: normal; background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial;"">The designed method and setup made it possible to obtain perfusion data over the vast majority of the surface of the kidneys. Further, the results show a positive linear correlation between measured perfusion and arterial blood flow in each kidney. With the collected perfusion data, a 3D visualization was made. 3D models from all kidneys could be used for this. The 3D visualization is represented as a point cloud and allows for easy and fast viewing of the perfusion over the entire surface.</p> <p class=""MsoNormal"" style=""margin-bottom: 0cm; line-height: normal; background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial;"">Validating the model with induced ischemia showed that the 3D visualization can indicate significant perfusion differences caused by ischemia. This makes LSCI a promising method for determining perfusion quality.</p><p class=""MsoNormal"" style=""margin-bottom: 0cm; line-height: normal; background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial;""","Laser Speckle Contrast Imaging; Normothermic Machine Perfusion; Kidney Transplantation; Organ Preservation","en","master thesis","","","","","","","","2024-12-02","","","","Mechanical Engineering | BioMechanical Design","",""
"uuid:17fbcc63-fced-4077-bb1d-efc2d10bd871","http://resolver.tudelft.nl/uuid:17fbcc63-fced-4077-bb1d-efc2d10bd871","Fencing off unwanted behavior: Improving and evaluating the Fency static analysis tool","van den Ham, Pieter (TU Delft Electrical Engineering, Mathematics and Computer Science)","Chakraborty, S.S. (mentor); Sprokholt, D.G. (mentor); Langendoen, K.G. (graduation committee); Delft University of Technology (degree granting institution)","2022","Computer architectures with weak memory models, such as ARMv8 and ARMv7, allow memory accesses to be reordered in many situations.<br/>Therefore, weak memory models may cause a program to exhibit more behavior than a strong memory model, such as x86.<br/>Fency is a static analysis tool that inserts memory fences to ensure that a program exhibits the same behavior when run on a weaker memory model.<br/>However, Fency lacks important features such as function call support, does not use LLVM's alias analysis algorithms, and inserts too many fences when targeting ARMv8.<br/><br/>We expand Fency with a new dependency tracking analysis, integrate it with LLVM's alias analysis infrastructure, and improve its usability.<br/>We show that while the new alias analysis fixes a vital soundness issue, it does not reduce the number of fences Fency inserts.<br/>Additionally, our evaluation of the dependency tracking analysis shows that it can eliminate some redundant fences.<br/>Finally, we run Fency on larger C/C++ programs, which we made possible by reimplementing Fency as a module pass.","weak memory model; robustness analysis; concurrency; computer architectures; static analysis","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:957d5888-cd4a-4b00-9277-62c27a24f5b5","http://resolver.tudelft.nl/uuid:957d5888-cd4a-4b00-9277-62c27a24f5b5","Predictions of Motion Sickness Incidence for EVTOL Passengers","Sîrghi, Florina (TU Delft Aerospace Engineering)","Pavel, M.D. (mentor); van Paassen, M.M. (mentor); Stroosma, O. (mentor); Delft University of Technology (degree granting institution)","2022","The interest in developing electric vertical takeoff and landing (eVTOL) vehicles has increased sharply in recent years. A concern for passenger acceptance of the new type of vehicle is that people may experience motion sickness. This is because eVTOL flight profiles are different from the motion conditions that people have previously experienced. The aim of this study was to predict the incidence of motion sickness amongst eVTOL passengers. To achieve this, a two degrees of freedom (2DOF) lateral theoretical motion sickness model was developed, with lateral acceleration and roll rate as inputs. The model parameters were tuned with data collected from flight simulator experiments performed in the SIMONA Research Simulator at the TU Delft. The participants (N=20) completed five trials, each time being exposed to one of five flight profiles: four eVTOL profiles (1—nominal condition, 2—high turbulence, 3—alternative control law, 4—seats turned 180°; t=24 min) and one helicopter profile (5—helicopter, t=31 min). Motion sickness severity in participants was measured using verbal ratings on the MIsery SCale (MISC). A significant difference was found between the MISC data for Profiles 1 and 2, showing that turbulence worsens motion sickness severity for passengers. No significant difference was found between Profiles 1 and 3 and between Profiles 1 and 4. The difference between the data from Profiles 1 and 5 was found to be statistically significant. However, given the discrepancy in how the two profiles were generated, further studies are needed to conclude whether flying in a helicopter in general induces more motion sickness than flying in an eVTOL. The 2DOF model was extended to 3DOF by adding vertical acceleration as input. After tuning both models with experimental data (mean MISC scores per participant), it was concluded that the 3DOF motion sickness predictions followed the trend of the measurements better than the ones of the 2DOF model. The developed models can be used for eVTOL design optimisation. To further improve the accuracy of the predictions, the 3DOF model will be extended to 6DOF in future studies.","eVTOL; Motion Sickness; Motion Sickness Modelling","en","master thesis","","","","","","","","2027-11-21","","","","Aerospace Engineering","",""
"uuid:1f3d6f35-cb81-4469-a4b3-0cd5e630a5f1","http://resolver.tudelft.nl/uuid:1f3d6f35-cb81-4469-a4b3-0cd5e630a5f1","QUANTIFYING EFFECTS OF SPINAL CORD STIMULATION IN CHRONIC REGIONAL PAIN SYNDROME PATIENTS","van Lange, Eline (TU Delft Mechanical, Maritime and Materials Engineering)","de Vos, C.C. (mentor); Huygen, Frank J.P.M. (mentor); Starmans, Martijn P.A. (mentor); Schouten, A.C. (graduation committee); Delft University of Technology (degree granting institution)","2022","Background: Complex regional pain syndrome (CRPS) is a clinical disorder characterized by continuous, disproportionate pain and sensory, vasomotor, sudomotor and motor trophic changes. CRPS patients have a heterogeneous clinical picture caused by multiple underlying pathophysiology mechanisms including inflammation, vasomotor disturbances and central nervous system (CNS) dysregulation. Spinal cord stimulation (SCS) is believed to target multiple CRPS mechanisms by stimulating the dorsal column in the spinal cord. Closed-loop SCS is a recently developed form of SCS in which the stimulation intensity adapts to the patient's position, continuously stimulating the same amount of fibers in the dorsal column. This constant perceived stimulation intensity may benefit CRPS patients who are generally hypersensitive.<br/><br/>Objectives: To better understand the effects SCS has on the CRPS mechanisms, my research focuses on quantifying changes in vasomotor disturbances due to conventional SCS treatment using thermographic image analysis. In addition, exploratory analysis is performed in patients treated with closed-loop SCS to evaluate its effects on CRPS mechanisms. <br/><br/>Method: Various histogram features indicating temperature intensity were selected based on histogram distributions of the thermographic images. These features were then extracted from the affected and unaffected extremities of each image. The histogram features of patients with and without vasomotor improvement were compared based on the change in differences between affected and unaffected extremities after 3 months of SCS. The change between improved or not improved was then determined for different characteristics of the patients, such as affected extremity and CRPS type. It was hypothesized that with improved vasomotor symptoms, the affected and unaffected extremities would become more similar and thus the difference would become smaller. <br/>For evaluation of the effects of closed-loop SCS on CPRS mechanisms, measurements were conducted before implantation and up to 6 months of follow-up. Measurements include thermographic images, CRPS severity score (CSS), Condition Pain Modulation (CPM), Temporal Summation (TS) and determination of sIL-2R levels using blood samples. In addition, conventional SCS was compared to closed-loop SCS, with patients randomized to receive both settings during the follow-up for two months.<br/><br/>Results: The following histogram features were selected: mean, median, minimum, maximum, peak, skewness, kurtosis, and quartile range. Based on 28 patients, for patients with improved vasomotor symptoms a decrease in difference was observed for histogram features mean, median, minimum, peak and quartile range. Furthermore, statistically significant differences were found in patients with vasomotor symptoms at baseline compared to patients without vasomotor symptoms for the mean (p=0.026), median (p=0.046), minimum (p=0.008), and quartile range (p=0.016). For patients with a cold CRPS type, statistically significant different feature values were observed between patients with and without vasomotor improvement in maximum (p=0.024), peak (p=0.016), and quartile range (p=0.027), with a decrease of histogram feature values. No statistically significant differences were found between the affected upper or lower extremities...<br/><br","Spinal cord stimulation; Complex Regional Pain Syndrome; thermographic images","en","master thesis","","","","","","MSc Technical Medicine Track Sensing & Stimulation","","","","","","Technical Medicine | Sensing and Stimulation","",""
"uuid:e1a0ae3a-df80-413c-b3b7-54efa6dfac17","http://resolver.tudelft.nl/uuid:e1a0ae3a-df80-413c-b3b7-54efa6dfac17","Proving functional correctness of monadic programs using separation logic","Clark, Liam (TU Delft Electrical Engineering, Mathematics and Computer Science)","Krebbers, Robbert (mentor); Delft University of Technology (degree granting institution)","2022","Interaction trees are an active development in representing effectful and impure pro- grams in the Coq proof assistant. Examples of programs they can represent are programs that use: mutable state, concurrency and general recursion. Besides representing these programs we also want to reason about and verify these programs using separation logic. That is the purpose of this thesis. More technically speaking interaction trees are new way to do shallow embeddings in the Coq proof assistant. They are a coinductive variant of the free monad and come with the usual constructions of events and event handlers. The aim of interaction trees is to represent impure programs and potentially non-terminating programs in their environment. Interaction trees are, in contrast to relational operational semantics, executable by interpretation or program extraction. Interaction trees come with a framework for reasoning about their behavior based on equivalency up to weak bisimulation. An open problem is to reason about interaction trees utilizing a separation logic rather than weak bisimulation. We developed Pothos as a solution to this problem. Pothos has an Iris based concurrent separation logic for interaction trees. We address the problem in a non-extensible setting, with mutable state, non-termination and concur- rency as our chosen effects. Pothos inherits all the executable properties from interaction trees and includes a novel relation of Iris’s step-index with coinductive types. We have proven our logic to be sound and include a case study of a spin lock library. The case study shows that our logic is both non-trivial and can utilize the standard Iris patterns for concurrency.","Separation Logic; functional correctness; Iris; Interaction trees; Coq","en","master thesis","","","","","","","","","","","","Computer Science","",""
"uuid:c093d0a3-b852-48c1-b9ee-9d515b29ce1f","http://resolver.tudelft.nl/uuid:c093d0a3-b852-48c1-b9ee-9d515b29ce1f","Bi-stable interlocks of sutured ABS geometries- A numerical study in Abaqus","Papoulidou, Sofia (TU Delft Civil Engineering & Geosciences)","Lukovic, M. (mentor); Šavija, B. (graduation committee); Delft University of Technology (degree granting institution)","2022","Concrete elements, partially or entirely prefabricated are becoming more and more popular in engineering practice. The biggest challenge in this process is the realization of connections between components. These connections fall within two categories: Precast-to-precast connections with hardened parts and<br/>precast-to-in situ connections, where an in-situ concrete element needs to adhere to a precast element. Some kind of interlocking surface might be effectual in both situations. Geometrical interlocking that exists in natural materials (turtle shells, diatoms), is the main inspiration for interlocking mechanisms in engineering practice. The concept of bistable interlocks has been introduced in the past few years to theoretical mechanics. These interlocks could allow many stable positions before the connection collapses, and may provide an additional ”safety boundary” in brittle concrete-to-concrete connections by spreading the nonlinear deformations through the material and making the transformed material less brittle and more damage tolerant. In this research, the properties of bistable interlocked materials will be explored based on the numerical models built. These properties are immediately correlated to the experiments performed. Sensitivity analyses are performed to investigate the parameters that can lead to the optimal behavior of the sutured geometries.","Bi-stable Interlocks; Sutures; Geometrical Interlocking; Multiple Equilibrium Positions","en","student report","","","","","","","","2022-12-02","","","","Civil Engineering | Structural Engineering | Concrete Structures","",""
"uuid:77736000-30c1-4c51-be17-bc34bb2037ab","http://resolver.tudelft.nl/uuid:77736000-30c1-4c51-be17-bc34bb2037ab","Bio2Cementation: A novel treatment coupling clay aggregation and bio-cementation in sand-bentonite porous media","Wennubst Pedrini, Rocco (TU Delft Civil Engineering & Geosciences)","Dieudonné, A.A.M. (mentor); Gebert, J. (graduation committee); Jonkers, H.M. (graduation committee); Delft University of Technology (degree granting institution)","2022","The geo-technical quest to couple technical, environmental, and economic innovation, has increased recent attention towards bio-inspired soil strengthening techniques. This thesis presents a proof-of-concept for a coupled clay inhibition and bio-cementation treatment tested in sand-bentonite, referred to as Bio2Cementation. Fine particles are first aggregated using a nitrogen based compound. By binding the electrical double layer of clay minerals, the aggregates become chemically and physically stable. Thereafter, bio-cementation treatments hydrolyze urea to precipitate calcium carbonate crystals within the pore space. The crystals bind the mineral particles, increasing the strength and stiffness of the soil.<br/>State of the art considerations regarding enzyme induced calcite precipitation and guanidinium hydrochloride research are used as the theoretical foundation for the treatment’s design. A diverse sand-bentonite matrix is tested, comprised of 10% and 30% bentonite, to evaluate the applicability limits of the technique. The implementation is tested in flow-cells, whereby soils are injected with Bio2Cementation treatments. Experiments show the dominant role of guanidine for stabilizing clay particles – the matrix aggregates, hydraulic conductivity improves by two orders of magnitude, surface charge interactions are minimized, and swelling is halted irreversibly. Hydraulic conductivity calcultations, unconfined compressive strength tests, image analysis of Micro-CT scans, and scanning electron microscope imaging evidence to notably improved bio-cementation following guanidine injections. Consistently, the optimized enzyme induced calcite precipitation was found to crystallize vigorously in 10% bentonite samples, but less successfully in optimally compacted 30% bentonite soils. The concept of Bio2Cementation is proven to work within certain limitations. <br/>Future research should explore the role of different clay minerals such as kaolinite, in view of better defining the treatment’s engineering applicability in-situ. Additional strength testing, soil-structure interaction analyses and environmental impact studies are also recommended <br","bio-cementation; Enzyme induced calcite precipitation; Soil improvement; grouting; clay inhibiors; biogrouting","en","master thesis","","","","","","Programme: Geo-Engineering, Applied Earth Sciences,Civil Engineering","","2023-12-31","","","","Geo-Engineering","",""
"uuid:85cbf0eb-0a2f-4be8-aecc-84616a5f8643","http://resolver.tudelft.nl/uuid:85cbf0eb-0a2f-4be8-aecc-84616a5f8643","Efficiently including reclaimed steel elements in a truss bridge design by performing a stock-constrained shape and topology optimization","van Lookeren Campagne, Fé (TU Delft Civil Engineering & Geosciences)","van der Meer, F.P. (mentor); Noteboom, C. (graduation committee); Kavoura, Dr. Florentia (graduation committee); Sonneveld, Michelle (graduation committee); Delft University of Technology (degree granting institution)","2022","To climb up the circular economy hierarchy and meet the goals of the European Green policy in the construction sector, steel profiles may be reused instead of recycled, which is currently the most common practice. An overarching digital database to efficiently match supply and demand of reclaimed structural elements will stimulate their application. To efficiently use the limited availability of reclaimed steel elements in a new structural system, the design process requires a different approach: form following availability. This thesis presents an algorithm to generate truss bridge designs using only reclaimed steel, optimising the material usage in relation to the function and avoiding cut-off waste. The algorithm is inspired by the growth method, a truss topology optimisation method in which truss designs are grown without the need to fit elements into an initial design or grid of possible positions, like the commonly used ground structure method. The growth method is a more intuitive starting point for stock-constrained design, as by attaching available reclaimed elements to each other, a geometry can be generated which effectively follows from availability. The algorithm has been scripted in Python within Grasshopper, resulting in a user-friendly parametric design process. By defining the required width and span of a truss bridge and providing a stock of reclaimed elements, a solution cloud is generated of locally optimal truss bridge designs in terms of capacity utilisation and which comply to Eurocode provisions and constraints regarding the manufacturability of connections. From this solution cloud, an optimal design can be selected with given objectives, e.g. the design with the lowest environmental impact. A comparison shows that the developed growth method, using reclaimed steel elements, can lead to a steel truss with 17% less embodied carbon than a truss design whereby reclaimed elements are fit in afterwards, and 63% less embodied carbon than a traditionally designed new steel truss.","Reclaimed steel elements; Circular economy (CE); Stock-constrained design; Growth method; Parametric design tool; Truss topology and shape optimisation","en","master thesis","","","","","","","","","","","","Civil Engineering | Structural Engineering | Structural Mechanics","",""
"uuid:c8b925b2-11ce-4029-b377-c0af6884cedb","http://resolver.tudelft.nl/uuid:c8b925b2-11ce-4029-b377-c0af6884cedb","Low Field Magnetic Resonance Imaging of the Eye: Inexpensive MRI for Ocular Conditions","Haasjes, Corné (TU Delft Mechanical, Maritime and Materials Engineering; Leiden University Medical Center)","Beenakker, J-W.M. (mentor); Remis, R.F. (mentor); Vos, F.M. (graduation committee); Herder, J.L. (graduation committee); Delft University of Technology (degree granting institution)","2022","Ultrasound imaging is an important modality in ocular oncology, allowing for fast examination of the eye by the ophthalmologist themselves. It is clinically used to measure tumour sizes for treatment planning. However, ocular ultrasound is limited to two-dimensional imaging, and suffers from poor contrast between tumour and sclera, which negatively impacts the accuracy of tumour measurements. In this work, low field MRI is investigated as a possible alternative for ultrasound imaging.<br/>Design requirements are a scan time of less than 4 minutes; resolution of 1.0 mm isotropic; Field of View (FOV) large enough to contain the eye and the orbit; contrast sufficient to distinguish the sclera, vitreous, tumour, lens and lipid. The experimental setup consists of a 46 mT Halbach-array based scanner, a volume coil as transmit coil and a custom-built surface coil as receive coil. Images are made of a water phantom to characterise the FOV, and a porcine eye to characterise the contrast.<br/>The FOV is found to meet the requirements, and the contrast is sufficient to distinguish the sclera, vitreous, lens and lipid in porcine eyes. The resolution is too low and the scans take too long (about 5 minutes at a resolution of 1.0 × 1.0 × 7.5 mm). Increasing the resolution and decreasing the scan time will result in a low Contrast to Noise Ratio (CNR), causing the contrast requirement to be violated. Fast, high-resolution three-dimensional imaging is therefore not feasible on the current system.<br/>The CNR can be improved by using a higher field strength, which requires the development of new hardware. Furthermore, in order to develop a clinically useable system, it is necessary to determine tumour contrast, design optimised pulse sequences, and test the method on human subjects.","low field MRI; eye; uveal melanoma; feasibility study","en","master thesis","","","","","","","","","","","","Biomedical Engineering | Medical Physics","",""
"uuid:aa5fe9a5-45b6-4495-bfa8-610d1cc27a46","http://resolver.tudelft.nl/uuid:aa5fe9a5-45b6-4495-bfa8-610d1cc27a46","A method for optimal charging station placement for ships: Combining a flow-refueling location model and an agent-based simulation","Driessen, Fabian (TU Delft Technology, Policy and Management)","Heijnen, P.W. (mentor); Warnier, Martijn (graduation committee); van Dongen, J. (mentor); Hoogvorst, P. (graduation committee); Delft University of Technology (degree granting institution)","2022","Extensive electrification of the inland shipping sector is necessary to achieve the EU goals to be climate neutral and increase inland shipping by 50\% by 2050. This requires a thoughtful and large-scale roll-out of new charging stations layouts, for ships with relatively high and largely varying energy demands. Current approaches for optimal charging station placement, mostly neglect temporal demand fluctuations and cannot cope with varying charging demands. Therefore, we aimed to develop a method that combined a capacitated flow-capturing approach and an agent-based simulation. Moreover, the resulting method was applied to the Dutch inland waterway freight transport sector in a case study. Results indicated that a large-scale transition to battery-electric propulsion is technically possible, but is likely economically unfeasible. The case study can be used to support decision-making towards renewable shipping. In addition, the newly designed may also be used to site energy hubs. Forthcoming, methods to come to efficient charging station layouts will be needed to stimulate the uptake of electrified transportation and avoid lock-ins to inefficient investments.","Agent-Based Modeling & Simulation; Charging infrastructure; Location decision-making","en","master thesis","","","","","","","","","","","","Engineering and Policy Analysis","",""
"uuid:00b96006-1698-4d5f-972f-881dbb920dc5","http://resolver.tudelft.nl/uuid:00b96006-1698-4d5f-972f-881dbb920dc5","Motion compensated offshore knuckle boom crane: A mechanical feasibility study","Pfeiffer, Marijn (TU Delft Mechanical, Maritime and Materials Engineering)","Jarquin Laguna, A. (mentor); Meijers, P.C. (mentor); Hogerheijde, Joost (mentor); Jiang, X. (graduation committee); Delft University of Technology (degree granting institution)","2022","To overcome the problem of wave-induced vessel motions on the crane tip, technologies have been developed to compensate for these motions. Most vessels nowadays, are equipped with dynamic positioning systems, these systems reduce the yaw, surge and sway movement of the vessel. This leaves, the motions roll, pitch and heave uncompensated. To reduce these motions, two main elements of motion compensation can be identified, consisting of heave compensation and anti load swing compensation. Existing technologies, like active and passive heave compensation tackle one of these elements. Other methods like the Stewart platform can compensate for both the heave motion and the load swing of the crane by stabilizing a platform on which the crane is mounted. In existing literature, not much work has been done to incorporate both the heave compensation and anti-swing control procedures in a combined control method. It would be much simpler if the crane could compensate the heave and payload swing by using only the crane's actuators. <br/><br/>This thesis, studies the mechanical feasibility of a motion compensated knuckle boom crane, compensating for the wave-induced vessel motions by controlling the available actuators in such a manner, that the crane tip stays stationary. A typical knuckle boom crane has three actuated degrees of freedom, consisting of the slewing, boom luffing and jib luffing angle. To study such a system, a numerical model is developed that combines the multi body dynamics of the knuckle boom crane with models for the hydraulic actuation of the crane and incorporates the full six degree of freedom vessel motions. The actuated degrees of freedom are controlled using three separate proportional integral controllers. The desired trajectories for the controllers are calculated using the geometric relations of the crane, based on the assumption that the desired crane tip coordinate in the global axis system is known.<br/><br/>Using the numerical model, insight is gained in the natural frequencies, forces/moments on the system, the necessary hydraulic properties and motion compensation performance. From the simulation results, it can be concluded that the cylinder forces and slewing torques increase when the motion compensation is turned on, compared to an uncompensated crane. Comparing the simulation results, to the Barge Master T40 crane, it can be concluded that cylinder forces, cylinder sizes, stroke velocities and power requirements are in line with requirements that can be achieved with existing technology. The main limitation, is expected to be the rated torque of the slewing motor, when the crane is positioned parallel to the vessel. In this position the main contributor to the motion compensation is the slewing motor. Using the proposed concept, motion compensation performance comparable to the existing Barge Master T40 is achieved. From the presented simulation scenarios, results indicate that the operational parameters and motion compensation performance of the system are feasible and competitive compared with existing technology.<br","Knuckle boom crane; Hydraulics; Numerical model; Computational dynamics; Motion Compensation; Control; Offshore","en","master thesis","","","","","","","","2027-12-01","","","","Offshore Engineering","",""
"uuid:95833ee5-5b12-4a7a-908b-b2acc8664dda","http://resolver.tudelft.nl/uuid:95833ee5-5b12-4a7a-908b-b2acc8664dda","A real-time energy management system for a grid-connected solar park using an electrolyser in the Netherlands: Optimizing to maximize the revenue","Middelkoop, Sanne (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Marine and Transport Technology)","Polinder, H. (mentor); Wildschut, Michiel (mentor); Schulte, F. (graduation committee); Nasiri, S. (graduation committee); Delft University of Technology (degree granting institution)","2022","This paper describes a real-time energy management system developed for a solar park in the Netherlands using an alkaline electrolyser. The optimization problem is split into a two-step optimization, taking into account the specifications of the electrolyser and allowing the electrolyser to respond to changes in the imbalance market. The first optimization step determines the state of the electrolyser one day in advance. The second optimization step determines the electrolyser power, using the state of the electrolyser as an input. Simulations using data from 2020, 2021 and 2022 show that the use of the electrolyser is limited to a number of days in the year with a lot of solar generation, causing the day-ahead prices to be low. Different scenarios have been tested to get insight into how the use of the electrolyser is influenced by these changes. The type of electrolyser, being able to put the electrolyser on standby and allowing the grid to be used for the electrolyser hardly affected the results. At last, different hydrogen prices are compared. The higher hydrogen prices lead to more use of the electrolyser. This real-time EMS contributes to the ability of an alkaline electrolyser to respond to the sudden changes in the grid and by doing this making it possible to use alkaline electrolysers for balancing the grid and contributes to the use of green hydrogen in the industry for a competitive price.","Energy Management System; hydrogen; electrolyser","en","master thesis","","","","","","","","2023-12-01","","","","Mechanical Engineering | Multi-Machine Engineering","",""
"uuid:a238c857-2bd6-4c4d-9e23-d867d8cde9cd","http://resolver.tudelft.nl/uuid:a238c857-2bd6-4c4d-9e23-d867d8cde9cd","Development of an Intense Positron Beam lifetime spectrometer","Boekel, Mark (TU Delft Applied Sciences)","Schut, H. (mentor); Bouwman, W.G. (graduation committee); Eijt, S.W.H. (graduation committee); de Boer, M.R. (mentor); Delft University of Technology (degree granting institution)","2022","A new intense positron beam lifetime spectrometer is being developed at the Reactor Institute Delft that should be able to perform positron lifetime measurements with depth profiling. The positrons are generated by pair formation using high energy gamma-photons from the Hoger Onderwijs Reactor. This new positron lifetime spectrometer has a unique way to determine the point in time when a positron is injected into the sample material. Before the positrons are injected, they travel through a carbon foil which will then release secondary electrons. These secondary electrons are detected by a microchannel plate detector which starts a timer. Once the positron annihilates within the sample it releases two 511 keV photons. If one of these photons is detected, the timer is stopped, and the elapsed time is stored. Many measurements of the elapsed time are needed to create a positron lifetime spectrum. <br/> <br/>The main research goal is to further develop this new positron lifetime spectrometer such that it is able to measure a positron lifetime spectrum. Multiple adaptations and tests were performed in order to achieve the research goal. <br/> <br/>At the start of the project, the positron lifetime spectrometer could not deliver a thermalized positron beam from its 50 nm thick tungsten moderator. This problem was solved by reannealing this moderator. Additionally, a new moderator was prepared and annealed. The Variable Energy Positron (VEP) facility was used to perform characterization measurements on the moderators. This facility was modified to allow the transmission of positrons through the moderator and measure emitted thermalized positrons by the moderator. At the same time, a model based on the positron transport equation was developed to simulate and verify the characterization experiments. Both the old and new moderator have shown that they can emit thermalized positrons. The old moderator has a measured efficiency of 0.073 ± 0.002 when the positron implantation energy equals 3.7 ± 0.1 keV. The new moderator has a measured efficiency of 0.123 ± 0.002 when the positron implantation energy equals 3.2 ± 0.1 keV. <br/> <br/>During the project, the microchannel plate detector which measures secondary electrons had to be tested, because no detections were observed in previous experiments. Additionally, the scintillation detector which is used to measure annihilation photons was tested. Eventually, both detectors have showed that they work correctly. <br/> <br/>Finally, the positron beam of the lifetime spectrometer was aligned such that the positrons travel through the carbon foil onto the target. Secondary electrons generated by positrons have been measured by the microchannel plate detector. Afterwards, the first positron lifetime spectrum was measured using this new instrument. This lifetime spectrum is still rather crude as it shows multiple peaks and a time resolution function with a full width half maximum of 0.57 ns. The research goal of this project has been achieved, but further development is needed in order to accurately measure positron lifetimes.","PALS; Positron beam; Positron moderator","en","master thesis","","","","","","","","","","","","Applied Physics","","51.991241192481716, 4.381477822110091"
"uuid:6e6b98bb-6f94-49dc-829d-9d675344c6e5","http://resolver.tudelft.nl/uuid:6e6b98bb-6f94-49dc-829d-9d675344c6e5","Predicting ecotopes for the assessment of Nature-based Solutions: A case study on the Western Scheldt","Brunink, Soesja (TU Delft Civil Engineering & Geosciences)","Herman, P.M.J. (mentor); Bosboom, J. (graduation committee); Hendrickx, G.G. (graduation committee); Delft University of Technology (degree granting institution)","2022","Nature-based Solutions (NbS) have recently gained more interest in hydraulic engineering. It is based on the concept of using forces of nature rather than working against them. In addition, it focuses on using natural processes to fulfil co-benefits for the parties involved. <br/>One of the parties involved is nature. However, a quantitative analysis of ecological development is necessary to determine possible co-benefits for nature. This is still found challenging due to the dependency on many variables, the difference in spatial and temporal scales, the limitations in available information, and the non-linearity.<br/><br/>Ecological development can be expressed with ecotopes, linking geomorphological and hydrological characteristics to abiotic characteristics. <i>A Dutch Ecotope System for Coastal Waters</i> (ZES.1) is a classification system of Rijkswaterstaat. It is a hierarchical system based on abiotic characteristics that classify ecotopes based on thresholds that are determined by ecological differences. <br/><br/>In this thesis, <i>the Ecotope Map Maker based on Abiotic characteristics</i> (EMMA), is developed. It uses data from a validated hydrodynamic model as input and subsequently maps ecotopes based on the ZES.1. Ecotope labels are composed by combining labels that are given to values of salinity, inundation, flow velocity and substrate composition. <br/><br/>The thresholds are calibrated using an ecotope-map of the Western Scheldt of RWS. This map is based on aerial photographs, laser altimetry, soundings, field measurements, and several models. The performance increased from 63 % to 84.6 % after the calibration. This increase is mainly due to (1) differences in the underlying data and (2) the application of deviating thresholds in the ecotope-map of RWS compared to the ZES.1.<br/><br/>EMMA is developed for the preliminary design stage. How EMMA can be implemented is demonstrated by applying EMMA on an idealised estuary. Different ecotopes and varying acreages of ecotopes are found when the depth of the estuary is modified. <br/><br/>In conclusion, EMMA creates many possibilities for ecotope-maps since it no longer depends on aerial photographs and other real-time data. A translation can be conducted between ecotopes and ecosystem services when a monetary value is preferred, or ecotopes can be broken down into eco-elements, which can subsequently be linked to biodiversity. With EMMA it is possible to predict ecological development, which contributes to the design of NbS.","Nature-based Solutions; Western Scheldt; Ecotope","en","master thesis","","","","","","","","","","","","Civil Engineering | Hydraulic Engineering","",""
"uuid:b108e827-9a1a-44d0-86f8-10ddb55d0946","http://resolver.tudelft.nl/uuid:b108e827-9a1a-44d0-86f8-10ddb55d0946","Transport properties of acid gasses in aqueous MDEA solvents","van der Geest, Casper (TU Delft Mechanical, Maritime and Materials Engineering)","Moultos, O. (mentor); Delft University of Technology (degree granting institution)","2022","Acid-gas capture systems are used to remove acid-gasses from waste gas streams from combustion or other chemical processes. A commonly used solvent is an aqueous solution with the primary amine monoethanolamine (MEA). Removing the acid gasses typically involves heating the solvent to approximately 378-383K in the stripping reactor. Using methyldiethanolamine (MDEA) instead of MEA can reduce the heating energy consumption of the stripper due to its lower reaction heat. The design of new reactors using aqueous MDEA solvents requires more data describing the properties of this solvent. Literature reporting thermophysical properties of aqueous MDEA solvents and transport properties of acid gasses in these solvents is exceedingly scarce. This work fills that information gap. Molecular dynamics were employed to compute density, viscosity and diffusivity of MDEA, CO2 and H2S in aqueous MDEA ranging in 0-50 wt% MDEA and 288-323K. The simulations were conducted using fully atomistic force fields for all species. The charges of MDEA were computed using Gaussian09 and scaled to achieve optimal agreement with experimental density and viscosity data. It has become clear that N-C-C-O dihedral in MDEA is crucial to reproduce experimental data of the viscosity and the diffusivity of MDEA. Two dihedrals were tested to achieve the best results. The resulting computed density, viscosity and diffusivity of MDEA are in good agreement with experimental data. The mixing rules between MDEA and CO2 were adjusted to increase accuracy of the prediction of diffusivity of CO2. The results are in good agreement with experimental data at 0-10wt% MDEA or 288K. The deviations become larger with higher wt% MDEA or higher temperatures.","","en","master thesis","","","","","","","","","","","","Mechanical Engineering","",""
"uuid:95d00046-865c-4522-885b-036eee747748","http://resolver.tudelft.nl/uuid:95d00046-865c-4522-885b-036eee747748","Using green facades to increase urban sustainability and resilience: An assessment of potential vertical green locations to enhance urban green space in Amsterdam","Rang, Thijs (TU Delft Architecture and the Built Environment)","Vreugdenhil, L.C. (mentor); Luo, S. (mentor); Delft University of Technology (degree granting institution); Wageningen University & Research (degree granting institution)","2022","Urban living has many advantages but also has its fair share of issues. This thesis tries to indicate the urban issues that can be solved by implementing vertical green systems (VGS). A literature review is undertaken, and expert interviews are held to examine socio-ecological criteria. The criteria heat stress, air pollution, water stress, noise pollution and percentage of green are determined to be the themes that can designate which locations in the city are suitable for vertical green. Since VGS are implemented on streets, it is necessary to figure out the need for vertical greening on street level. This is done by performing a spatial analysis using QGIS. The spatial analysis uses the criteria to create five thematic maps, showing the Urban Heat Island effect, levels of particulate matter in the air, water depth after extreme rainfall, noise pollution, and the percentage of urban green in an area of ten-by-ten meters. These thematic maps are combined to create the combination map and ultimately a street map that shows the need for vertical green on street level. The underlaying data of this map presents a ranking of streets. This ranking shows that most of the streets that are in very high need for vertical green are located in Amsterdam Centrum and Amsterdam West. To assess peoples’ perception of VGS to assess their willingness to pay for implementation a questionnaire is held. The result from the questionnaire shows that half of the respondents are knowledgeable about the benefits of VGS. When people learn about the benefits, they are more likely choose for a green façade or living wall would they get the change. The questionnaire shows that money is the most determining factor in the decision-making process of the respondents, meaning that for implementation of VGS on a large scale to be successful, subsidies would have to be implemented.","Urban green; Vertical greenery systems; Amsterdam","en","master thesis","","","","","","","","","","","","Metropolitan Analysis, Design and Engineering (MADE)","",""
"uuid:fba2c5a7-8769-4ee8-90e2-7d361fc41c03","http://resolver.tudelft.nl/uuid:fba2c5a7-8769-4ee8-90e2-7d361fc41c03","An exploratory journey to combine schema matchers for better relevance prediction","Wang, Wang Hao (TU Delft Electrical Engineering, Mathematics and Computer Science)","Katsifodimos, A (mentor); Houben, G.J.P.M. (graduation committee); Chen, Lydia Y. (graduation committee); Ionescu, A. (mentor); Delft University of Technology (degree granting institution)","2022","Current speed of data growth has exponentially increased over the past decade, highlighting the need of modern organizations for data discovery systems. Several (automated) schema matching approaches have been proposed to find related data, exploiting different parts of schema information (e.g. data type, data distribution, column name, etc.). However, research showed that single schema matching techniques fails to effectively match schemas, whilst combinatorial schema matching systems show more promise. With the introduction of combinatorial schema matching systems, new challenges arise regarding selection and combining strategies. This research attempts to explore different techniques for determining the importance of each matcher in a combinatorial schema matching system by determining the weights of each matcher and comparing them through a comprehensive evaluation.","Schema Matching; Data Discovery; Combining Schema Matchers","en","master thesis","","","","","","","","","","","","Computer Science | Software Technology","",""
"uuid:7b53d744-c975-473f-b0db-302f69c209e4","http://resolver.tudelft.nl/uuid:7b53d744-c975-473f-b0db-302f69c209e4","On the applicability of selective laser melting on pistons for the oil &amp; gas industry: Fatigue limit and fracture toughness of selective laser melted TI6AL4V","Niehaus, Anya (TU Delft Mechanical, Maritime and Materials Engineering; TU Delft Materials Science and Engineering)","Rans, C.D. (mentor); Kumar, Siddhant (graduation committee); Delft University of Technology (degree granting institution)","2022","Pistons for reciprocating compressors for industrial applications are often made of specialised materials. These prove to have problems with manufacture due to the high quality and short production times needed in combination with a low production volume per design. Additive manufacturing, specifically selective laser melting, could solve the production problems, provided that the material retains the needed mechanical properties. Ti6Al4V is the most appropriate material for this application. The most important mechanical properties for the application are the fatigue limit and the stress intensity factor, which are not well established properties for printed materials. For this reason fatigue limit and stress intensity factor tests were performed for both stress relieved and hot-isostatic pressed test pieces on longitudinal and transverse directions. Strength, toughness and fatigue limit is higher in hot-isostatic pressed test pieces of Ti6Al4V, and these are proven to be appropriate for application in compressor pistons. However the fatigue limit of stress relieved Ti6Al4V is lower, anisotropic, and has more scatter, and as such is insufficient for the application, which is due to deleteriously oriented microstructure and the presence of porosities. This can be solved by changing the printing parameters – laser power, cooling rate or heat treatment – although the exact combination of parameters for optimised values is not known and will be part-specific.","Selective Laser Melting; Fatigue; Fracture toughnes; Reciprocating compressor; Piston; Microstructure; Fractography; Ti6Al4V","en","master thesis","","","","","","","","","","","","Materials Science and Engineering","",""
