"uuid","repository link","title","author","contributor","publication year","abstract","subject topic","language","publication type","publisher","isbn","issn","patent","patent status","bibliographic note","access restriction","embargo date","faculty","department","research group","programme","project","coordinates"
"uuid:ebbe88d3-effa-45d2-a9a6-716b95614ef3","http://resolver.tudelft.nl/uuid:ebbe88d3-effa-45d2-a9a6-716b95614ef3","An Improved Method for the Monitoring of the Productivity of Natural Gas Wells","Vesters, J.B.","Zitha, P.L.J. (mentor); Blandamour, H. (mentor)","2013","Up to now the well performance department within Total Exploration and Production Netherlands (TEPNL) base the assessment of well inflow performance on experiences in the field. No tools are available to systematically monitor and assess the reservoir-completion-tubing performance in the longer term (years). This makes that normal production decline cannot be discriminated from abnormal production decline and productivity decline over long periods of time cannot be observed. The well management process is complicated by the large number of small reservoirs operating in different circumstances. As a result well performance interventions have largely become a remedial activity rather than a pro-active way of increasing production. In this thesis we will discuss the development of two tools that will allow the performance engineers to monitor all 52 TEPNL productivities over the entire period of time digital production data is available. Problematic wells are selected based on their initial productivity and their current productivity. Productivities are determined using Forchheimers correlation. Tagged well are coupled to an appropriate analytical skin model, depending on the well configuration. Evolution of certain parameters that are identified as being impactful on the PI of the specific are calculated. Certain mechanisms have been proposed which cause well performance deterioration. The root cause for the decline is interpreted based on well historics, surface measurements of salinity and the evolution of PI. Finally, when a cause has been established and it appears to be skin related an intervention can be proposed and potential production gains can be estimated. The new tools can also be used to review past interventions in a systematic and simple manner. At this moment well interventions are not or hardly reviewed on their impact. The tool can now help to quantify the problem, as well as give an objective measure of the success of past interventions. The approach proposed in this thesis is new, and only limited data is available to validate the approach. Some promising results are observed based on the 4 interventions done in the past as well as well historics currently available. At this stage, the method tags an additional 9 wells as declining faster as expected. 4 of which are suspected to be related to skin buildup, 1 to water invasion, 1 to interference with another well and 1 due to tubing damage. The remaining 2 wells could not be linked to a single specific cause, 1 well is either suffering from salt deposition or water advancement, while the other either salt deposition or tubing damage.","productivity; gas wells; North Sea; well decline","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Petroleum Engineering","",""
"uuid:940f7ece-b7de-4e42-a26a-9e8c276d9677","http://resolver.tudelft.nl/uuid:940f7ece-b7de-4e42-a26a-9e8c276d9677","Innovative Multi-Touch Interaction","Beekmans, F.M.S.; Licht, J.D.; Van Otterdijk, M.","Eisemann, E. (mentor); Bidarra, R. (mentor)","2013","Given the rise of touch-screen technology in recent years, it makes sense to explore new possibilities to employ them. So too thought the municipality of Delft. For their planned new office, they are currently experimenting with different ways and technologies to boost productivity. These experiments take place in the innovation lab, or iLab. One such experi-ment aims to find innovative uses for touch- screens. The muncipality of Delft has outsourced part of this experiment to teams of students from the Delft University of Technology as their Bachelor project. A collaborative multi touch game, called Jest, was chosen as the product to meet these needs. By focusing on the interaction and the user experience, familiarity with innovative techniques can be nourished. This report documents the development process of Jest. In order to ensure a modicum of technical quality, proven techniques such as unit testing and pair programming were used. An external party also evaluated the code artifacts of the product, and commended the clear structure and simple separation of concerns, but found some amount of code duplication in the tests. In Jest, players have to create a network of paths and instructions to guide vehicles carrying cargo to their destinations. Players face several challenges along the way, such as timing issues and interesting level properties. Jest is developed for the JVM in the Clojure language, loosely following a system design focusing on clear module separation and scalability. Jest is deployable on both Windows and GNU/Linux. Several hurdles had to be overcome while developing Jest, such as the fact that the JVM originally did not support the multi touch API on Windows, requiring jumping through several hoops to make this work. The project was delayed, mostly due to developer inexperience, which led to the project lasting 18 instead of 10 weeks. Aside from some rough spots in the planning and development process, the project resulted in a working prototype which can easily be improved upon for many different situations.","multi-touch; touch; game; game-design","en","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Computer Graphics and Visualization","","","",""
"uuid:e89dcc65-4c52-4e5b-8c49-bfd76520be14","http://resolver.tudelft.nl/uuid:e89dcc65-4c52-4e5b-8c49-bfd76520be14","Resultaten van de CoCo-module ""Groeien planten beter met chilisalpeter"" bij 4 havo leerlingen","Besselink, J.M.; Robeerst, D.J.","Henze-Rietveld, F.A. (mentor); Jacobs, M.A.F.M. (mentor)","2013","Het ministerie van OC&W heeft het doel gesteld om de bèta en technische opleidingen aantrekkelijker te maken, door o.m. het huidige scheikunde curriculum te actualiseren. In dit beschrijvende, kwalitatieve onderzoek stellen we de onderzoeksvraag of de context-en-conceptbenadering (CoCo-benadering), die gehanteerd gaat worden bij het nieuwe scheikunde curriculum, een oplossing is voor drie pijnpunten, die geconstateerd zijn bij het huidige scheikunde curriculum. Dit onderzoek is gericht op de leerervaringen, die een groep 4 havo leerlingen opgedaan heeft tijdens doorlopen van een aangepaste versie van de CoCo-module, genaamd “groeien planten beter met chilisalpeter”. Conceptmaps, leerzinnen en de resultaten van een cognitieve toets zijn hierbij gehanteerd als onderzoeksinstrument. Uit de beantwoording van de deelvragen, van de onderzoeksvraag, is geconcludeerd dat de CoCo-benadering een goede start is voor het adresseren van de pijnpunten van het huidige scheikunde curriculum. Oefenen met de de- en recontextualisatie van de concepten in de les en tijdens cognitieve toetsen is noodzakelijk. Het is ook evident dat de docent expliciete, continue aandacht aan de leerlingen moet schenken om de koppelingen tussen de contexten en de concepten te leggen.","scheikunde; CoCo; conceptmap; context-en-conceptbenadering; decontextualisatie","nl","master thesis","","","","","","","","","Applied Sciences","Science Education and Communication","","Science Education","",""
"uuid:6de1f8cb-3111-4afa-8f59-f5a1ba8491af","http://resolver.tudelft.nl/uuid:6de1f8cb-3111-4afa-8f59-f5a1ba8491af","DE-XRT assessment on Porphyry Copper ore from Chile","Roukema, M.","Buxton, M.W.N. (mentor); Dalm, M. (mentor)","2013","","","en","bachelor thesis","","","","","","","","2013-12-17","Civil Engineering and Geosciences","Geoscience & Engineering","","","",""
"uuid:28cef3c7-4139-46ed-b9c6-0306f3be7eec","http://resolver.tudelft.nl/uuid:28cef3c7-4139-46ed-b9c6-0306f3be7eec","Informatie en communicatie: Beslisfactoren voor invoering van een vak","Sedee, B.; Azcarate Onaindia, A.","Jacobs, M. (mentor); Bruggink, M. (mentor)","2013","In december 2012 heeft de KNAW een rapport opgesteld over de huidige staat van het Nederlandse informaticaonderwijs. Uit dit rapport kwam als advies dat er in de onderbouw een nieuw vak ingevoerd zou moeten worden, genaamd “informatie en communicatie”. Omdat er vanuit de overheid geen actie wordt ondernomen hebben wij in deze scriptie twee case studies gedaan op scholen om te achterhalen welke beslisfactoren een rol kunnen spelen bij het besluit om het vak op scholen toch ingevoerd te krijgen. Naar aanleiding van interviews met directieleden, vakdocenten en leden van de medezeggenschapsraden, hebben wij een aantal van de factoren kunnen benoemen. Zo blijkt dat financiële middelen een grote rol spelen voor directieleden, terwijl dit voor vakdocenten veel minder het geval is. Vakdocenten hechten daarentegen veel meer waarde aan een compleet lespakket en een doorlopende leerlijn. Aan de hand van deze, en andere conclusies die staan beschreven in deze scriptie, kunnen we een basis leggen voor de mogelijke invoering van een pilot voor het vak “informatie en communicatie”.","informatie en communicatie; invoering nieuw vak; beslisfactoren; KNAW","nl","master thesis","","","","","","","","","Applied Sciences","Science Education and Communication","","Education","",""
"uuid:a89daed8-9697-47b6-b500-d7045a26d661","http://resolver.tudelft.nl/uuid:a89daed8-9697-47b6-b500-d7045a26d661","Injection of Water above Gas for improved sweep in Gas IOR: Non-uniform Injection and Sweep","Mahalle, N.A.","Rossen, W.R. (mentor); Farajzadeh, R. (mentor)","2013","With the continuous increase in the demand for oil and gas, there is a need for application of novel techniques such as Improved Oil Recovery (IOR) and Enhanced Oil Recovery (EOR) methods. Most of the secondary recovery processes start with water flooding. However, injecting gas along with water gives higher recovery than water flood alone. This happens due to the presence of residual gas saturation at the end of the flood which results in lower residual oil saturation than would result from water flood only. Water alternating gas (WAG) injection is the accepted approach for field application in which slugs of water and gas are injected alternatively. Gravity governs the fluid flow in the reservoir if the heterogeneities are not significant. Gharbi et al. (2003) and Stone (2004, 2007) propose an injection scheme in which water is injected simultaneously with, but above, gas into the reservoir. Algharaib et al. (2007) calls this process “modified SWAG (simultaneous water and gas)” injection. Jamshidnezhad et al. (2010) further investigate the effect of instability of gas injection in this process. Non-uniformity of gas injection correlates inversely with the total injection rate and directly increasing vertical distance between the two horizontal injection wells. The paper also speculates that the relationship of gas saturation and gas relative permeability is one of the factors causing instability. The objective of the thesis is to find out the factors that controls the stability of gas injection. To do so, we propose a simulation study which will take into account sensitivity on several parameters that can contribute to stability of gas injection. We start with a homogeneous reservoir model and later investigate the effects of local grid refinement near the well and heterogeneities. We speculate that the relationship of gas injection rate with gas relative permeability and well gridblock pressure are the vital factors that control the stability of gas flow through the reservoir. The simulation output data is analyzed for varying input data. The variation in the input data is controlled so as to have a clear understanding between results and parameters. The results from the study indicate that the non-uniform nature of gas injection depends on saturation and relative-permeability behaviour in the neighbouring gridblocks. The instability in the injection process is triggered in the near-well region. Refining the area near the well solves the issue of non-uniform injection process, at least in this study. Segmenting the well into multiple segments gives a wider spread of gas front instead of localized fingering from either end of the well. We study one of the issues in simultaneous water and gas injection process, but several problems like the geology of the reservoir, rock type, geometry of the field, operational aspects and feasibility needs more research and development.","SWAG","en","master thesis","","","","","","","","2013-09-04","Civil Engineering and Geosciences","Geoscience & Engineering","","Petroleum Engineering","",""
"uuid:afb5c976-333b-4964-aa61-b38b20069bb7","http://resolver.tudelft.nl/uuid:afb5c976-333b-4964-aa61-b38b20069bb7","Derivation of and Simulations with BiGlobal Stability Equations","Groot, K.J.","Van Oudheusden, B.W. (mentor); Pinna, F. (mentor)","2013","Laminar to turbulent transition has an important role in the aerospace domain in view of its impact on aerodynamic drag and, regarding the high velocity regime, heat transfer. State of the art computational methods, like DNS, LES and RANS are found to be too expensive or rely on case dependent turbulence models to be used for obtaining information regarding the transition phenomenon. Transition is typically initiated by the onset of instability of the laminar flow. Linear stability theory describes the eigenmode growth mechanism. Although this yields a restriction, because additional mechanisms play a role too, the eigenmode growth phase establishes an important base in many practical situations. However, the linearization provides a considerable step in the simplification of the analysis, while the stability theory can be adapted according to the structure of the given mean flow. At the Von Karman Institute (VKI), the VKI Extensible Stability and Transition Analysis (VESTA) toolkit has been developed, which mainly involves methods based on the linear stability theory. In the current project, the main goal was to extend the already present tools to incorporate the BiGlobal stability equations, which, together with appropriate boundary conditions, form an eigenvalue problem. This particular problem is solved for perturbations inhomogeneous in two spatial directions and their complex growth rate and frequency. This extension involved a new version of the tool for the derivation of the BiGlobal stability equations, a tool for their automatic implementation in Matlab via the spectral collocation method and a simulation tool to apply boundary conditions and execute the analysis corresponding to a prescribed mean flow. The derivation of the BiGlobal equations and their verification formed the first part of the project. Both incompressible and compressible versions are derived for different kinds of coordinate systems (e.g. Cartesian and cylindrical) and formulations in the compressible case (e.g. involving temperature and pressure and the energy equation based on static enthalpy). This allowed the verification of the tool with a large number of previously published references. All references, to the knowledge of the current author, that have thus far reported the compressible equations were found to contain errors and had to be cross-verified to yield the ultimate positive outcome. It is hence deemed that the present treatment is the first to report the full compressible BiGlobal stability equations in primitive variable formulation correctly. The second part of the project involved the verification of the performance of the combination of the derivation, implementation and simulation tools. This was done by considering three test cases (mean flows). In all cases, the eigenvalue problem was solved using the QZ algorithm. In cases that required high resolution, the Arnoldi algorithm was used in addition, because of its lean performance with respect to required memory. The first test case was the parallel Blasius boundary layer. Because of its one-dimensional nature, this flow has been intensively analysed in the past by means of the classic local stability analysis type (LST). This allowed the BiGlobal analysis of this mean flow to be thoroughly verified in both the incompressible and supersonic regime. The second case involved the developing incompressible Blasius boundary layer. This flow was chosen because of its better affinity with the actual Blasius boundary layer flow, which has an intrinsic developing nature. The BiGlobal approach involved artificial in- and outflow boundary conditions. Analyses were performed on a domain with a small and large streamwise extent to focus on a flow that is weakly and strongly developing, respectively. The former analyses were again compared to LST simulations to yield an internal verification and consistency check. The results of the analyses on the larger domain could be compared to the literature and were found to agree well in a qualitative sense. The Tollmien-Schlichting branch obtained in this study was found to lie too high with respect to the one reported in the literature. Although the exact reason for this could not yet be established, the most likely cause is a (small) difference in the prescribed mean flow. It is expected that the test case will yield identical results when exactly the same mean flow will be used, as some key differences can be identified in the literature in this regard. It was found that the artificial boundary conditions caused an odd/even effect with respect to the continuous eigenmode branches in the spectrum when the number of points in the streamwise direction was taken to be either odd or even. A similar behaviour was observed when consulting the literature, although the effect was never elaborated on explicitly. Lastly, the incompressible complex lamellar bidirectional vortex was considered. This mean flow is defined on a cylindrical coordinate system and is highly inhomogeneous in at least two spatial directions. Therefore, this case requires the BiGlobal approach and all power of the newly developed tools could be tested. A test case handled in the literature was very precisely reconstructed. Although it was found that no part of the spectrum was converged, the results were nearly identically retrieved. The solutions to all three test cases have been obtained successfully and compare reasonably well with the literature. It is therefore concluded that all capabilities of the newly developed tools have been tested successfully and the tools can be considered to be verified.","BiGlobal linear stability; VESTA; automatic derivation; non-parallel","en","master thesis","","","","","","","","","Aerospace Engineering","Aerodynamics","","","",""
"uuid:809ca182-ee8c-4214-b1ea-16441d70559d","http://resolver.tudelft.nl/uuid:809ca182-ee8c-4214-b1ea-16441d70559d","Single Pilot Commercial Operations: A Study of the Technical Hurdles","Faber, A.","Mulder, M. (mentor)","2013","History has shown that a larger flight crew does not per se imply that aircraft operations will be safer. The goal of this thesis is to determine the technical hurdles to Single Pilot Commercial Operations (SPCO). Continued technological developments, the upsurge of commercial Unmanned Aerial Systems, the non-negligible cost of air crews, and yet, stagnation in commercial crew reductions since 1980 are reasons to clarify the current technical hurdles to SPCO. The research was initiated with a broad literature survey. It was found that advances in technology and human factors understanding have made each historical crew reduction possible, through a redistribution of tasks across (fewer) humans, automation, supporting infrastructure and accompanying procedures. An exhaustive list was then formulated of all issues that could potentially affect a reduction to SPCO. Consequently, in-depth research of each issue determined the most predominant challenges to SPCO are; a. providing the single pilot with the correct situational awareness at a manageable workload; b. ensuring adequate monitoring of pilot performance without an on-board human co-pilot; and c. ensuring redundancy in case of incapacitation. Finally, Single Pilot Incapacitation Redundancy (SPIR) solutions were explored by means of a scenario analysis and functional analysis. The greatest challenge to SPIR turns out to be the setting of the incapacitation detection sensitivity threshold; avoiding excessive false warnings (alarm problem) yet retaining immediacy for timely recovery of stable flight; both incapacitation detection and seem-less control take-over are tasks more suited to the adaptability of humans. A concept for a SPCO flight deck has been presented in which these issues become obsolete.","Single Pilot Commercial Operations; Human Factors; SPCO; Crew reduction; Crew size; Flight crew; Single Pilot","en","master thesis","","","","","","","","","Aerospace Engineering","Control and Simulation","","Master Aerospace Engineering. Track 3 Dynamics and Control of Aerospace Vehicles","",""
"uuid:a0616e4e-e433-4265-b5f6-4972bc06f01e","http://resolver.tudelft.nl/uuid:a0616e4e-e433-4265-b5f6-4972bc06f01e","Electrical characterization of PureB layers in contacts, diodes and transistors","Ramesh, S.","Nanver, L.K. (mentor)","2013","","","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Microelectronics","","ECTM","",""
"uuid:c1fa559b-874e-40d5-a7cb-b375846df27b","http://resolver.tudelft.nl/uuid:c1fa559b-874e-40d5-a7cb-b375846df27b","Multicomponent Seismic Processing for Coherent Noise Suppression and Arrival Identification","Sollberger, D.","Greenhalgh, S. (mentor); Schmelzbach, C. (mentor)","2013","Multicomponent seismic processing provides significant potential advantages compared to conventional scalar wavefield processing. Triaxial sensors which measure three orthogonal components of the ground particle motion are able to determine the wave polarization and can thus record the complete vector wavefield with all of its modes (P, S and surface waves). This fact can be exploited to design polarization filters for wavefield separation and high resolution P- and S-wave imaging techniques. A successful illustration of the benefits of multicomponent processing is only possible if the concepts are extensively tested both on synthetic data and real data. Such tests were performed during the course of this project. The results obtained confirm that vector wavefield processing is indeed a valuable tool in the analysis of seismic data and provides information that supplements the information obtained by conventionally processed vertical component P-wave data. In this thesis, I show how polarization properties can be exploited to determine the direction of arrival or to build filters that suppress coherent or random noise. If moveout characteristics are considered in addition to the polarization information, a separation of the wavefield can be achieved. Also, the polarization information can be incorporated into migration algorithms to obtain separated P- and S-wave images of the subsurface. Several computer scripts were developed to test these concepts. All of them performed well on synthetic data. On real data, a successful reduction of ground roll and a partial separation of the wavefield was achieved. Additionally, P- and S-wave images could be obtained using a multicomponent migration routine. The dataset that is treated in this thesis was provided by the National Cooperative for the Disposal of Radioactive Waste (Nagra). It is a VSP dataset that was recorded in the Benken borehole in Switzerland. Although the results of the analysis probably do not represent the precise geological structure in the region, it is shown that further multicomponent analysis of this dataset could be profitable.","Multicomponent Seismic Processing","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Joint Master's in Applied Geophysics","",""
"uuid:a4ac3bbc-3447-421f-9e8b-af0cd7c73b82","http://resolver.tudelft.nl/uuid:a4ac3bbc-3447-421f-9e8b-af0cd7c73b82","Aircraft Interior Design 2050","Wang, Y.T.","Vink, P. (mentor); Lie, J. (mentor)","2013","As the role of cross-continental air travel becomes increasingly crucial and common, the importance of in-flight comfort and experience also enhances. However, the current aircraft interior is commonly considered as providing an unpleasant and dreadful experience, especially in a long distance flight. Since the travel pattern and perceptions in travel will be altering considerably with regard to the rapid pace of developments in all fields, the interior design needs a fresh plan for the future. An aircraft interior design is proposed for the Blended Wing Body for year 2050 with the focus on enhancing crowd wellbeing. Research covering interaction in the field of sociological psychology in current context in combination with designing the future context in 2050 lead to a final design proposal. The final design features use of the Blended Wing Body as the platform, the wearable technology as the tool, the social interaction as the mean and the crowd well-being as the goal. This design project aims at delivering an inspirational design concept, which provides different possibility in arrangements of aircraft interior. The implementation of the Blended Wing Body is also a significant trial in showing the new concept in function and meaning of air travel.","design; automotive; aircraft interior; crowd well-being; social interaction; positive emotion","en","master thesis","","","","","","","Campus only","2014-08-30","Industrial Design Engineering","Industrial Design","","Master of Science Design for Interaction","",""
"uuid:1e5ca95d-df73-44aa-b856-855c142d84ef","http://resolver.tudelft.nl/uuid:1e5ca95d-df73-44aa-b856-855c142d84ef","Improving the economic performance of AkzoNobel's EVB plant","Borren, A.J.","Herder, P.M. (mentor); Lukszo, Z. (mentor); Stougie, L. (mentor); De Bruijne, M.L.C. (mentor)","2013","AkzoNobel Energie Voorzienings Bedrijf (EVB – Energy Supply Company) is located at the Botlek business park in Rotterdam. EVB produces and supplies energy and utilities to other production plants at the Botlek site. Due to the intertwined value chain and reuse of each other’s residual and waste products, the situation at the Botlek is complicated. This report describes the development of a decision support model that contributes to an improved economic efficiency of AkzoNobel’s EVB plant. The decision support model calculates the optimal production settings that minimize the variable costs and assure that at all times the critical operational conditions are met. By comparing the results of the optimization model with the base case model, it can be concluded that there is a savings potential of more than 6% of the variable costs of the EVB plant. From the optimized production settings a pattern is distinguished. This pattern is translated into a set of operational rules that can be applied to the EVB plant to realize the savings potential. The next step is to carefully analyze the consequences of the operational rules for the operations and the implications for customers. Only then the new operational rules can be incorporated and the savings potential can be realized.","optimization; decision support model; chemical industry; economic efficiency","en","master thesis","","","","","","","","2014-03-01","Technology, Policy and Management","Energy & Industry","","SEPAM","",""
"uuid:37e91727-4f39-468c-997a-b388bbc6cccc","http://resolver.tudelft.nl/uuid:37e91727-4f39-468c-997a-b388bbc6cccc","Modelling of seismic wave propagation through realistic and complex fracture networks","Parker, A.C.","Barnhorrn, A. (mentor); Thorbecke, J. (mentor)","2013","Rock heterogeneities exist in mostly all rock types present in the Earth’s crust. Fractures are one such heterogeneity, which can range in size from very small micro-scale diffuse fractures to huge kilometer-wide regional features and meso-scale fracture corridors. The characterisation of fracture properties has many important implications for a wide range of industries. One way of characterising fractures is by making use of numerical forward modelling experiments. By observing how seismic waves are being affected when travelling through fractured media, information about the fractures might be obtained. In this study, seismic wave propagation through various fracture models is being investigated, using a finite difference modelling code (FDELMODC). The main objectives of this work are to determine whether the effects of fractures can be seen in the seismic response, and in particular whether the seismic method can be used to detect fracture networks. In addition to investigating whether the detection of fractures and fracture networks is possible, this study also focuses on the question whether fractures and fracture patterns can be identified.","forward modelling; seismic wave propagation; fractures","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Applied Geophysics and Petrophysics","",""
"uuid:b96aaa13-96fc-488b-be96-24c627c12be6","http://resolver.tudelft.nl/uuid:b96aaa13-96fc-488b-be96-24c627c12be6","Orchestrating Investment in an Evolving Power Sector: An Analysis of Capacity Markets","Iychettira, K.K.","De Vries, L.J. (mentor); Bots, P.W.J. (mentor); Cunningham, S. (mentor); Herder, P.M. (mentor)","2013","There is increasing concern that energy-only markets are inadequate when it comes to ensuring generation adequacy in the power sector over the long term. This is reflected in the fact that several Independent System Operators have commissioned studies about security of supply over the last few years; OFGEM and CEER (Council of European Energy Regulators) are some of them. There is some empirical evidence and substantial theory as to why incentives for investments are insufficient in such markets. Capacity mechanisms are policy tools that aim at providing incentive to this investment into reliability – both over the long-term and short-term. Compounding this inadequacy of energy-only markets is the expected change in the composition of the generating portfolio over the coming decades. It is expected that the European electricity industry is almost entirely carbon free by 2050. In addition, implementation of a capacity market in a country in hugely interconnected Europe might show cross border effects that need further insight and understanding. The purpose of this work is to evaluate the effectiveness of capacity markets, a type of capacity mechanism, in its ability to ensure long term generation adequacy, and more generally, improve the performance of the electricity sector and increase consumer and producer welfare. The effectiveness of capacity markets are assessed primarily on the following indicators: performance of the electricity market (adequacy of supply, stable energy prices), consumer welfare and producer welfare. This work is part of a larger project at the Energy and Industry section of TPM, EMLab Generation, which is focused on studying the electricity market in transition towards a low-carbon regime. The methodology applied to carry out this research is agent based modelling. A model of the capacity market has been built and analysed. In order to conceptualize a capacity market model, a thorough literature review and empirical study was carried out on the existing variations of capacity markets that are implemented across the world. While there are slight variations between them, the overarching principle beind them remains the same - to administratively place an obligation on the load to buy supply to meet a certain reserve margin of generation. The New York ISO Installed Capacity (NYISO ICAP) market was used as the primary basis to conceptualize the capacity market. The NYISO ICAP was chosen due to its relatively simple design (there are no forward capacity requirements), and well-established nature. The conceptualization was then adapted to the existing EMLab model. From this conceptual model a pseudo code for the formal model was created, and then implemented in the software. After a lengthy process of verification, the experimental set-up was designed to reflect 1. a sensitivity analysis to capacity market design parameters such as price cap and slope. 2. the effect of a capacity market in a single country, with and without target investment in renewable energy 3. the effect of a capacity market in a two country scenario, with one of the countries having an energy-only market, also with and without target investment in renewable energy. The insights from the model are mainly that the capacity market works as intended, improves the performance of the electricity sector in general, affects the adequacy and therefore the stability of the power system, affects the type of generation portfolio that might arise as a result. Specifically, On Capacity Market Design - The performance of the electricity market is highly sensitive to the price cap and slope of the capacity market. To ensure the desired level of adequacy in the system, the price cap in the capacity market must be sufficiently high (1.5 times CONE) to incentivize and induce investment. If a low price cap (say, CONE) is implemented, there could still be sufficient investment signal if the demand curve is relatively flat. A vertical demand curve is detrimental to the electricity market in general, because staggered revenues from the capacity market hugely increase the volatility in the system, reducing consumer benefit, leading even to negative profits (on an average) for producers. On Cross Border Effects of Capacity Market - The capacity market ensures the desired reserve margin in the country where it has been implemented. However it does so at a higher cost to the consumers of that country. The reasoning behind this is explained in the previous chapter. Interestingly, the model suggests that, without export constraints, between the two countries involved, the surplus capacity in the country with the capacity market dampens investment in the neighbouring country with an energy only market. This even leads to a marginally higher chance of outages in the neighbouring country. On Performance of the Capacity Market with Substantial Renewable Energy - Simulations suggest that reserve margins may need to be increased if the same level of reliability were to be maintained in a scenario with substantial renewable energy generation. Although the choice of capacity mechanism is highly dependant on the context, this work does not intend to recommend capacity market as the solution for problems with the energy only market. However, this research provides valuable insight into capacity market design, on the effects if the capacity market on producers and consumers, and in other relevant scenarios as described above.","security of supply; capacity markets","en","master thesis","","","","","","","","","Technology, Policy and Management","Infrastructure Systems & Services Department","","Energy and Industry","",""
"uuid:8b94e22b-cd51-407c-af86-9c2389f20e4c","http://resolver.tudelft.nl/uuid:8b94e22b-cd51-407c-af86-9c2389f20e4c","A Capacitance-Based Reference Scheme for a 14b-Linear, 100 MS/s SAR-Assisted Pipeline ADC","Elumalai, I.","Long, J. (mentor); Bult, K. (mentor); Ward, C. (mentor)","2013","Voltage reference buffers have always been the most power-hungry blocks in switched-capacitor SAR ADCs. High frequency dynamic loading of the buffer by the capacitive DAC causes glitches on the reference voltage, and the buffer has to be fast enough to recover such transients to 1/2 LSB precision in every bit cycle. Such stringent requirements entail an immensely capable buffer for high-speed, high-resolution converters. One obvious olution circumventing the active buffer is to use a stand-alone capacitor that holds the reference voltage during SAR evaluation. This solution accompanies, besides good power efficiency, excellent DAC settling speed and noise properties, thereby greatly helping the ADC FoM. Reducing the capacitance of the stand-alone capacitor for chip area concerns brings in code-dependent errors on the reference, leading to heavy distortion. This project implements an area-conscious, capacitance-based reference buffer scheme for a 14b-linear, 100 MS/s SAR-assisted pipeline ADC in 28 nm CMOS. With moderately-valued capacitances, two elaborate calibration techniques are proposed that help to suppress the reference-induced distortion to less than 84 dB, effectively not degrading the SNDR. Designed for 12-bit SNR, the prototype ADC with the implemented reference scheme consumes 1.81 mW and achieves a Schreier FoM of 175.5 dB.","ADC; SAR; charge redistribution; reference buffer; high speed; low power","en","master thesis","","","","","","","","2014-09-20","Electrical Engineering, Mathematics and Computer Science","Electronics","","Microelectronics","",""
"uuid:a04d3ee0-5376-4f2a-b488-18e2d06d9646","http://resolver.tudelft.nl/uuid:a04d3ee0-5376-4f2a-b488-18e2d06d9646","Geomechanical modelling and subsidence prediction of salt deposits for solution mining","Wijermars, E.A.M.","Buxton, M.W.N. (mentor); Ngan-Tillard, D.M.J. (mentor); Vardon, P.J. (mentor); Pinkse, T.M. (mentor); Schreppers, G.M.A. (mentor)","2013","","salt; geomechnanical modelling; subsidence; solution mining","en","master thesis","","","","","","","","2016-01-01","Civil Engineering and Geosciences","Geoscience & Engineering","","Section Resources Engineering","",""
"uuid:219076b2-e886-4370-b4ae-2d0e2ad8d2ac","http://resolver.tudelft.nl/uuid:219076b2-e886-4370-b4ae-2d0e2ad8d2ac","Aeroacoustic Investigation of Beveled Trailing Edges by High-Speed Particle Image Velocimetry","Gupta, Abhineet (TU Delft Aerospace Engineering)","Scarano, Fulvio (mentor); Ragni, Daniele (mentor); Kotsonis, Marios (mentor); Pröbsting, Stefan (mentor); Delft University of Technology (degree granting institution)","2013","The aerodynamic noise generated by trailing edge of aircraft wings at take-o_ and approach con_guration continues to be a critical factor in the future development of aviation. Trailing edge noise is also a serious concern for wind turbines, marine propellers, helicopter rotors, axial and centrifugal turbines and compressors. A fundamental understanding of how the energy contained in turbulent motions around trailing edges is converted to sound will be bene_cial for designing silent airfoils and control surfaces. Current research aims at applying new tools of ow _eld interrogation i.e. high-speed planar and tomographic PIV to the canonical problem of trailing edge noise. In analytical models, the far _eld noise can be described using turbulent quantities like the spanwise coherence. The use of high-speed tomographic PIV creates a link between the phenomenological description of the ow and acoustic _eld in terms of coherence of structures and noise. The geometric con_guration used involves an airfoil with an elliptic leading edge and an asymmetric beveled trailing edge with 25 deg tip angle (_) and three di_erent radii of curvature (R). The measurements are taken at four di_erent Reynolds numbers.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering | Aerodynamics and Wind Energy","",""
"uuid:3b058f0d-de7d-4607-963d-4aea35754cf3","http://resolver.tudelft.nl/uuid:3b058f0d-de7d-4607-963d-4aea35754cf3","A user centred product-service system for efficient collective solar-power consumption","Van Wijk, O.","Keyson, D.V. (mentor); Van der Lugt, R. (mentor); Van der Veen, O. (mentor)","2013","The production of solar power is one of the solutions to limit the emission of polluting gases. One of the characteristics of solar power is the discontinuous character of its activity. This can cause a heavy load on the energy grid, especially because most solar power is being produced when energy consumption of households is low. This can result in breakdowns. ‘Peak shaving’: increasing consumption at moments of peak production, is a method to avoid these problems. Smart grids will play an important role within this development. For this thesis an interactive interface is developed by which people can see if enough local solar power is available for consumption. They can make use of this energy if they shift the usage of their appliances to moments of high solar power levels. Households have to share the local production. Research took place in two neighbourhoods in the Netherlands. Through a simulation session the possibility and willingness of people to change their habits was tested, and through a pilot, a working model of the interface was tested on interaction and perception. The willingness to use solar energy appears to be high, but it is hard for people to find ways to shift consumption, and, it remained hard to realise you share energy in a community. So, the behavioural change will be small and the interface design needs some improvement. If people will really change their energy consumption by making use of the system can only be answered when the complete system is working and in use for a meaningful time.","solar power; smart grid; energy consumption; peak shaving; interface","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Design for Interaction","",""
"uuid:16dcd641-b567-4a14-8482-c5536288e926","http://resolver.tudelft.nl/uuid:16dcd641-b567-4a14-8482-c5536288e926","Startup entrepreneurs vs accountants - a platform to motivate early collaboration and support","Arvidsson, M.E.L.","Pasman, G. (mentor); Liu, W. (mentor); Boschman, J. (mentor)","2013","Startup entrepreneurs are digital natives, a new generation entering the job market and challenging today’s ways of working. They are accustomed to highly interactive technologies and use expressive and fast work methods. These richer ways of interacting however, are not always supported in the rather traditional context of accounting and collaborating with accountants. Problem A design challenge presents itself in bridging the gap between startup entrepreneurs and accountants. As a result, this research and design project was initiated with the aim to explore needs of startup entrepreneurs and accountants and define how to best: - support startup entrepreneurs and improve their accounting experience and collaboration with accountants. - help accountants to position themselves in the new market and adapt to changing user needs. This report is the final result of a MSc graduation project in affiliation with the Industrial Design program at Delft University of Technology and in collaboration with Exact, a global provider of business software located in Delft. Research An extensive user research including literature reviews, user interviews and context mapping studies drove the development of a final concept for the small business and collaboration between entrepreneurs and accountants. The rich data gathered was translated into insights describing (1) needs and emotions, gaps and touch-points between the target groups and (2) attitudes towards the final concept design and improvements possible. The research led to the following conclusions. Accountants and startup entrepreneurs are each other’s opposites in terms of personality, preferred methods of working and communicating, expectations and knowledge levels which all can lead to problems when collaborating. Throughout the development of a startup, needs for financial support change greatly. In the early stages of a startup, entrepreneurs express mostly negative emotions in relation to accounting. Early-stage entrepreneurs need; personal support, knowledge and simple functionality to build up their confidence in starting and managing a business. - Accountants are facing difficult times of decreasing revenues. Big adjustments are required in order to reverse the downward trend. A new kind of accountant is needed, one that focus on not only accounting but also communication, relations, marketing and sales. The future will show how well current accountancy professionals can live up to the new expectations. - Technological innovation and a new generation of demanding customers have big consequences for the activities and work roles of accountants today and in the future. By providing opportunities to build relationships with the early-stage startup entrepreneurs, accountants can grow their businesses. By focusing on early-stage entrepreneurs, rather than more mature businesses, new opportunities for customer acquisition are created in a market that is less crowded. Startups present a new market opportunity, but they also challenge accountants to start doing things differently. Solution The proposed concept is a knowledge and achievement based system, that guides the entrepreneur in starting their business and related accounting activities. It provides instant accountancy support through chat and video-conferencing as well as rating systems and matching tools for choosing the right accountant. Third-party integration with financial parties such as banks, the Tax office, the Chamber of Commerce, make early accountancy activities more efficient. The concept is simple but smart. As a cloud-based solution, all data is safely stored in one place and automatically updated. Financial activities are easily planned, managed and executed via the financial calendar that provides alerts and reminders. When in need of more advanced solutions, the system provides for easily import to Exact Online. Reception Evaluations with five target users and an interactive prototype indicate that the concept has great potential to fulfill the user needs and attract both startup entrepreneurs and accountants. Additional research is required to assess the potential size of this market. Further work is also needed for getting the concept to a final state. The recommendations following from the user tests should support this development. Conclusion The project was successful in achieving its two main purposes: 1) develop and communicate a deep understanding for new user demands and future challenges related to accounting and 2) identify opportunities for Exact to better support the needs of accountants and startup entrepreneurs. The research has also proven useful to Exact as it points towards a possible future of accounting and collaboration between accountants and entrepreneurs. The continued prosperity of Exact will depend on the ability to attract new generations of customers and adapt to their needs and preferences. This project’s outcomes and insights will hopefully support further advancements and provide a starting point for bridging the gap between accountants and startup entrepreneurs.","startup entrepreneurs; accountants; accounting; generation Y","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","","",""
"uuid:82ea9089-24ed-4f3d-80e3-dd23acd8aa2a","http://resolver.tudelft.nl/uuid:82ea9089-24ed-4f3d-80e3-dd23acd8aa2a","Foam Stability in Presence of Oil: A Simulation and Experimental Study","Hussain, A.A.A.","Rossen, W.R. (mentor); Farajzadeh, R. (mentor); Vincent-Bonnieu, S. (mentor)","2013","This thesis investigates bulk foam stability in absence of oil, and in presence of oil (hexadecane). Foam in absence of oil was produced by sparging nitrogen at a fixed flow rate through the surfactant solution. Foam in presence of oil was produced by stirring a mixture of surfactant and oil with an immersion mixer. The behavior of foam in absence of oil did not give any prediction of the behavior of foam in the presence of oil. We show that commonly referred methods for foam stability in presence of oil, the entering, spreading, and bridging coefficients and lamella number, did not give reliable predictions. The surfactants that produced most stable foams in presence of oil had the lowest interfacial tension with oil. We also show that in our experiments, foam in presence of oil does not show a relationship between foam bubble diameter and drainage rate, unlike foam in absence of oil. We illustrate that foam in presence of oil, produced with a mixture of surfactants, can be more stable than the foams in presence of oil, which were produced with the individual surfactants. We observed emulsions forming under foam in presence of oil, and their maximum volumes have not shown any relationship with other parameters. This thesis also investigates foam injection into a water-flooded reservoir by a single cycle surfactant-alternating-gas (SAG) mode. We demonstrate that if not enough surfactant is injected into the reservoir, the oil bank (ahead of the foam front) does not reach the production well. Therefore less oil is produced, since less gas is injected due to foam reducing the injectivity of gas. We show the effect of oil on the foam front stability. In our simulations foam collapses in gridblocks where oil saturation is above a certain threshold value. The liberated gas flows upward in the reservoir, and pushes down oil and water. This can result in the formation of an oil bank at the bottom of the reservoir, and in our simulations this oil bank is not displaced by foam because its oil saturation is high enough to destroy foam. We varied the threshold value of minimum water saturation for stable foam; if the threshold is set at a larger value (reflecting less stable foam), then foam has a less significant impact on oil production and gas injection than if it is set at a lower threshold value (reflecting more-stable foam).","foam; EOR; SAG; oil","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Petroleum Engineering","",""
"uuid:1eec6d3c-d49a-42ad-85c8-01bc28682883","http://resolver.tudelft.nl/uuid:1eec6d3c-d49a-42ad-85c8-01bc28682883","Life cycle assessment and simplified life cycle costing on Industrial Symbiosis","Zhu, B.","Korevaar, G. (mentor); Babbitt, C. (mentor)","2013","This paper adopts the life cycle thinking as the approach to assess the economic and environmental performances of industrial symbiosis. A detailed guidance of implementing LCA on industrial symbiosis under four research purposes: accounting of symbiosis, existing symbiosis, exploring symbiosis and comparing symbiosis design options is presented. 19 scenarios of two firms interacting with each other are analyzed in detail regarding the choice of functional 6unit, the determination of LCA alternatives and the quantification of material flows. Symbiosis is considered as a multifunctional process, which enables the comparison of symbiosis design options. This research contributes to develop a framework of LCA and life cycle costing (LCC) on industrial symbiosis. The equation of calculating LCC from the perspective of symbiosis is presented. The steps and procedures of this framework are illustrated with a case study with two definitions of functional unit applied, which shows the environmental benefits and costs savings industrial symbiosis can achieve. A symbiosis assessment diagram with flows as well as monetary and physical parameters is designed to visually reflect the relevant information regarding LCC and LCA. Simplifying the LCA approach, the essence of LCC from the perspective of symbiosis, the necessity of having an integrated framework and the symbiosis design of the case study are discussed. While future researches are recommended on deepening the case study, broadening the methodology and incorporating consequential approaches.","Industrial Symbiosis; Life cycle analysis; life cycle costing; Industrial Ecology","en","master thesis","","","","","","","","","Technology, Policy and Management","Engineering Systems and Services","","","",""
"uuid:1e564bfb-9cda-4e31-9180-e165546a0e3c","http://resolver.tudelft.nl/uuid:1e564bfb-9cda-4e31-9180-e165546a0e3c","The potential for customer information systems to reduce the cost to serve of electricity suppliers: An explorative study towards describing the influence of customer information systems on cost to serve and quality of service","Van den Engel, B.N.H.","Lukszo, Z. (mentor); De Bruijne, M. (mentor); Weijnen, M. (mentor)","2013","One known way of reducing the CtS is the implementation of a customer information system [CIS]. Ferranti Computer Systems n.v. is one of the main suppliers of these CIS, with regard to the utility sector, the utility specific CIS offered by Ferranti is called MECOMSTM. However, a CIS implementation does not only influence the CtS it also has an impact on the quality of service [QOS], focusing on CtS and not taking QOS into account would be inadequate. The initial goal of this research was to create a generic model that describes the influence of a CIS on CtS and QOS, for B2C energy supply companies in Belgium and the Netherlands. In order to construct such a model it appeared that in-depth financial as well as quality level data was required, however, the energy companies which agreed to join in this research proved unwilling to present this data. The unwillingness to share data has led to a new research question (the original research questions can be found in paragraph 1.2 while the redefined research questions can be found in paragraph 6.3.2): Which steps are required for an energy supplier, to make an in-depth consideration for a CIS implementation?","cost to serve; customer information system; quality of service","en","master thesis","","","","","","","","","Technology, Policy and Management","Energy and industry","","SEPAM","",""
"uuid:b2ce8e9a-73df-4bc9-92ef-c533f01a0619","http://resolver.tudelft.nl/uuid:b2ce8e9a-73df-4bc9-92ef-c533f01a0619","Capitalising Renewable Energy Projects Through the Incentivisation of Private-Sector Investments via the New Market Mechanism (NMM)","Van Duinen, L.C.","Mulder, K.F. (mentor); Storm, S. (mentor)","2013","The European Union (EU), United Nations (UN) (as stressed through the United Nations Framework Convention for Climate Change (UNFCCC)), and other nations and international organisations would like to see significantly lower global carbon & greenhouse gas emissions. To reach or surpass Kyoto commitments, considerable (technological) steps must be taken requiring billions of US$ of investments. Due especially to the current economic crisis which diverts attention away from climate change and sustainability, governments would like to see private-sector investment to reach the estimated 15 trillion US$ of needed investment until 2035 for mitigation1. As alternatives to market-based mitigating solutions seem (politically) unfeasible and the current flexibility mechanisms of the UNFCCC (such as the Clean Development Mechanism (CDM) & Program of Activities (PoA)) have not managed to notably slow the increase in the level of greenhouse gases in the environment, a scaled up market-based mechanism seems necessary. The idea of such a new market-based mechanism as a sectoral instead of project-based approach was introduced during the Conference of the Parties (CoP) at Durban in 2011 and is currently being debated by policymakers on an international level, with pilot & case studies gradually taking off to test this new mechanism.","NMM; CDM; UNFCCC; Renewable Energy; van Duinen; Luc","en","master thesis","","","","","","","","2014-02-06","Applied Sciences","Technology Dynamics & Sustainable Development","","Sustainable Energy Technology","",""
"uuid:4ea853e2-283d-469d-a737-058092c3f7de","http://resolver.tudelft.nl/uuid:4ea853e2-283d-469d-a737-058092c3f7de","The Road to Success: Effects of Top Management Supervision on NPD Processes and Outcomes","Dehghani Tafti, L.","Hultink, H.J. (mentor); Sääksjärvi, M.C. (mentor)","2013","In this project the author studies the effect of top management supervision on two NPD structural elements, namely customer orientation and portfolio management processes, and on NPD success factors: new product innovativeness, NPD speed and costs. Additionally, the effect of the two aforementioned structural elements on the noted NPD success factors is examined. Also, a model portraying these relationships is proposed. Using a data sample collected through direct interviews and questionnaires from top managers and team members participating in NPD projects in various industrial sectors in the Netherlands and Italy (one manager and one team member in each firm), the author conducts qualitative and quantitative analysis to test the hypotheses. The main outcomes are: Top management is found to have a positive effect on new product innovativeness and market success. New product innovativeness, in turn, also leads to market success. No relationship between top management supervision, and speed and costs is found. Top management is found to have a positive influence on portfolio management processes, but no influence on customer orientation. The latter result might be due to the small sample size for this relationship, and should be further investigated. Customer orientation and portfolio management processes are not found to have an influence on NPD success factors. However, responsive customer orientation is found to have a negative relationship with overall product performance. In addition, the following observations are made: Annual sales and profits of new products are found to be negatively related to theestablishment year of the company, meaning that the younger the company is, the lower its annual sales and profits will be. Speed and costs are also found to be strongly (negatively) correlated. Future research can address the relationship between other important NPD structural elements and outcomes, and the effect of top management supervision in this regard. Since the importance and the effect of NPD structural elements on the outcomes may vary in different market sectors, and since this can also affect the influence of top management supervision, future research can also focus on this aspect to look for possible variations in the results.","Top management supervision; Portfolio management; Customer orientation; Innovation; NPD success","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product Innovation Management","","Master of Science Strategic Product Design","",""
"uuid:f798917f-7f4a-4e00-9fa2-2c9d7184c546","http://resolver.tudelft.nl/uuid:f798917f-7f4a-4e00-9fa2-2c9d7184c546","Seismic Stratigraphic Interpretation and High Amplitude Anomalies of the Cretaceous Sequence, Porcupine Basin","Quintero, J.A.","Luthi, S. (mentor); Qayyum, F. (mentor)","2013","This report presents a description of a set of high amplitude anomalies along a 3D seismic stratigraphic interpretation for the Cretaceous sequence in the north-west margin of Porcupine basin. Porcupine is a sedimentary basin, western offshore of Ireland, closely related to the Opening of the North Atlantic Ocean. This basin presents three tectono-sedimentary sequences: late Permian to Early Triassic pre-rift sequence, middle Triassic to Jurassic syn-rift sequence and Cretaceous to present post-rift sequence. The Cretaceous sequence is characterized by two main events: a Berriasian to Aptian thermal passive sag and an Albian-Maastrichtian tectono-eustatic relative sea level rise. During the former a series of relative sea level changes were masked by the thermal sag. Deposition was mainly related to submarine fan deposits. The latter was characterized by prograding events when the thermal sag slowed down. Deposition was dominated by siliciclastic deltaic deposits and carbonates that deposited a chalk unit on top of the Cretaceous sequence. The Cretaceous sequence was subdivided into four sequences, namely sequences I, II, III and IV respectively and further subdivided into systems tracts. Six high amplitude anomalies were reported. They are constrained in sequences II and III with no apparent connection to a particular systems tract. The anomalies are located basinward as deep water deposits that either follow the basin floor along contours or are merely spread out. They can be mudstone-prone and sandstone-prone. Despite a lack of proper control, they have been interpreted as contourite deposits that sequentially step out landward. This is only a hypothesis based on the seismic character of the anomaly and its geometry. However, contourites have been already reported in the Porcupine basin in younger deposits of Tertiary age. Future studies should bring a proper controlled data in order to define the precise origin of these high amplitude anomalies and to assess their hydrocarbon potential.","porcupine basin; high amplitude anomalies; seismic stratigraphic interpretation; cretaceous sequence","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Applied Geophysics and Petrophysics","",""
"uuid:3d7851e5-be3c-43cc-a1f2-10eb094dfb34","http://resolver.tudelft.nl/uuid:3d7851e5-be3c-43cc-a1f2-10eb094dfb34","A brand strategy for the Reinvent the Toilet Challenge","Oikonomou, S.","Van Boeijen, A.G.C. (mentor); Roscam Abbing, E. (mentor)","2013","The lack of proper sanitation has cost many deaths to subsistent citizens all around the world. In India, open defecation is still practiced in urban and rural areas. Many efforts to provide toilets to the people that lack them, met failure because they lack one necessary element. Emotional engagement. This report presents “SANIR“. An value-based, aspirational brand was designed to guide the innovation process and accompany the implementation of an innovative sanitation solution for Indian slums. This project is conducted of the “Reinvent the Toilet Challenge“. A collaboration between the Bill and Melinda Gates Foundation and leading Universities around the world. The project seeks to find new innovative, highly technological solutions to the problems that the lack of proper sanitation brings all around the developing world. This brand strategy was done to support the effort of TUDelft to bring the user-centered design principles into this technology-led project, thus creating solutions that people will enjoy to use. The brand strategy developed aims, firstly, at changing the often gloomy and unprofessional image that brands for NGO and social businesses have. “SANIR“ is a strong, professional brand that sets to affect not only the sanitation habits of those who experience it but also help them grow and find the power to change their lives for the better. The brand is set to change the relationship that slum dwellers have with sanitation solutions and help spreading a positive message. Internal research fitted to the environment of a Not-for-Profit organisation was initially conducted to uncover clues suitable for the brand. An in depth secondary research using new media was employed to set the ground for a field research in the future context of application. The research had as a main goal to discover the aspirations and intrinsic motivations of slum dwellers and trends in the context. The results were used to build a framework for a brand startegy for a social business and the development of the respective brand identity. The project concludes with a designed brand communication and corporate visual identity, a touchpoint system to support the initiation of the implementation and some examples of possible implementation on brand touchpoints.","brand strategy; sanitation","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Master of Science Strategic Product Design","",""
"uuid:6aa33047-65b7-4f8f-bc07-b629f52bddbe","http://resolver.tudelft.nl/uuid:6aa33047-65b7-4f8f-bc07-b629f52bddbe","In the Loop: Design of a Serious Game to Create Awareness about Critical Raw Materials","Whalen, K.A.","Peck, D.P. (mentor); Keyson, D.V. (mentor)","2013","This masters’ thesis is the result of research conducted on companies and critical raw materials in 2012 by TU Delft and the FME-CWM Association. The FME is the largest representative body for the Dutch technological industry and aims to support their member companies. As the result of the 2012 study showed a lack of awareness in their member companies about the topic of critical raw materials, the FME has sought tools that could help bridge these knowledge gaps. However, little such tools exist. Therefore, the goal of this project was to create a tool that could help raise awareness about critical raw materials. Critical raw materials, or materials with high economic importance and significant supply risk, have been receiving increased attention in recent years. As this project is conducted for Dutch companies, the project focuses on critical raw materials as defined by the European Union. In order to develop the tool, literature research was conducted on the topic of critical raw materials and product design. This led to an understanding of the context of critical raw materials in terms of products and product design. The major takeaway from the analysis was that there is no clear-cut solution to dealing with critical raw materials. Case studies on companies and critical raw materials were also reviewed to find gaps in existing practice and the literature. Takeaways included that companies do not think in terms of critical materials but critical components, transparency about material and supply chains is lacking, sources of knowledge about critical raw materials is limited, and product design is not frequently viewed as an option for dealing with critical raw material issues. It became clear that providing company-specific answers would not be a possibility in the tool because every company faces different challenges in relation to critical raw materials. Introducing company teams to the reasons behind material criticality and showing the solution space, could, however, give companies the knowledge they need to be able to further investigate the issue in their company. Research on tools showed little existing tools mention critical raw materials, while even fewer are focused specifically them. The tool exploration also led to a serious game being selected as the vessel to transfer knowledge about critical raw materials. This was chosen because of the increased interest in game-based learning, ability of games to be a catalyst for discussion about topics as shown through best practice, and serious games’ abilities to create awareness about issues. Research on game design was undertaken to understand game design methods, game structure, and game elements. After analysis, a framework for the game was developed, specifying the knowledge content the tool should contain as well as criteria for the final tool’s service/use, interaction, content, and appearance. After playing the game, users should be able to demonstrate knowledge of 1) situations and events that cause concern for material criticality and 2) how to prevent/mitigate these issues. They should also be able to 1) start to identify their company’s products and/or processes that contain critical raw materials and 2) begin to identify how these issues could potentially impact their company. Finally, the tool should serve as a catalyst for discussion and investigation of the topic further. Insight on how the game should provide the knowledge transfer was also acknowledged, such as through chance and money. Based on the requirements, the game was developed from six initial design directions. Game methodology was used to assess the developed concept. The process was iterative, with each session building off the other. A total of eight product evaluation sessions were conducted for the game. Sessions were done with future users of the tool, academics from business and design, and industry and government representatives. While the first four sessions focused mainly on the game play rather than content, the last four were designed to evaluate the game on its knowledge content and learning outcomes. In the Loop: The Critical Raw Materials game is the final result of the evaluation sessions. It is a board game where players are presented with critical raw material issues as they try to produce products. Players must make strategic choices to avoid bankruptcy, continue making their product, and win. Product cards allow customization of game play to the users while material cards provide more information and greater depth to the subject. While the evaluations have resulted in recommendations for future testing, they support that In the Loop can be used to create awareness about critical raw materials and transfer the intended learning outcomes. Further validation in FME companies is recommended, and a method for testing is provided, but the tool’s ability to instigate discussion about the topic of critical raw materials would be beneficial to the FME, as it would lead to increased awareness.","critical raw materials; awareness; serious game","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","","",""
"uuid:84162702-9e09-4e02-bc47-425a77ca38c9","http://resolver.tudelft.nl/uuid:84162702-9e09-4e02-bc47-425a77ca38c9","The relationship between user satisfaction and sustainable building performance: The case study of Leiderdorp’s Town Hall","Mamalougka, A.","Van Hal, J.D.M. (mentor); Van Bueren, E.M. (mentor); Van Doorn, A.J. (mentor)","2013","","sustainable buildings; sustainable town halls; building performance; evaluation; user satisfaction; Leiderdorp; monitoring tools; occupant confort servey","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Construction Management and Engineering","",""
"uuid:a268ac47-cac6-4e33-88c8-e0c32cbfe90d","http://resolver.tudelft.nl/uuid:a268ac47-cac6-4e33-88c8-e0c32cbfe90d","Supply Chain Trends impacting the Air Cargo Industry: Assessing Trends and their Impacts in three Industry Sectors","Schmidt, F.","Tavasszy, L.A. (mentor); Ludema, M.W. (mentor); Den Hartigh, E. (mentor); Keyrouse, R. (mentor)","2013","Supply chain management is ever-evolving. The supply chain of large shippers is constantly changing in response to external drivers. But which of these supply chain trends truly impact the air cargo industry and to what magnitude. This research identifies a number of supply chain trends based on an extensive literature review. After that, these trends are tested by means of in-depth interviews and a follow-up questionnaire with supply chain managers of global shippers in three different industry sectors (high tech, pharmaceuticals and automotive). After an qualitative assessment on the impacts of the supply chain trends, Seabury's databases are used to quantify the magnitude of a number of trends.","air freight; supply chain trends; interview; database analysis; triangulation","en","master thesis","","","","","","","","2014-08-30","Technology, Policy and Management","Transport and Logistics","","Management of Technology","",""
"uuid:6b6fb71e-5e2e-46fd-bec5-4143e308243c","http://resolver.tudelft.nl/uuid:6b6fb71e-5e2e-46fd-bec5-4143e308243c","Analysis of current distribution and circulating currents in a permanent magnet synchronous machine with parallel coils","Van de Wetering, R.","Polinder, H. (mentor); Van der Geest, M. (mentor)","2013","In this thesis the current distribution among parallel coils and the presence of circulating currents in an electric machine is investigated. Differences in induced voltage and in impedance between the parallel coils might lead to an uneven current distribution, which may cause the temperature of a single turn to become too high. To determine the flow of current in the machine it is necessary to model the machine in sufficient detail. For this research the coils in the machine have been modelled as a series connection of a voltage source, and inductance (with mutual coupling to other coils) and a resistance. This was made possible by the machine designer, who provided these parameters for every copper turn in the machine. The most important result of this research is that the difference in amplitude of the currents through parallel wires is very small, for this specific machine. The phase difference between the currents is larger, but the impact of this is still insignificant. Furthermore, the investigation on circulating currents has shown that the magnitude of these currents mainly depends on the difference in induced voltage between parallel wires and the resistance of the wires. The inductance of the coils was found to have negligible influence on the magnitude due to very good magnetic coupling between the parallel coils.","current distribution; synchronous machine; parallel coils","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Electrical Power Engineering","","","",""
"uuid:7388afd6-7f94-4a9c-8905-f951cb5b386b","http://resolver.tudelft.nl/uuid:7388afd6-7f94-4a9c-8905-f951cb5b386b","Creative Growing Pains - A growth Strategy for JAM Visual Thinking","Post, D.J.","Smulders, F.E.H.M. (mentor); Van der Meer, J.D. (mentor); Overdijk, M. (mentor)","2013","Getting to know the ins and outs of a growing creative company was the foundation for a growth strategy that will help JAM grow on their own terms. Guided by a measurable model that addresses all the issues that need to be resolved in order to ensure sustainable growth. everal steps were taken to ensure the relevance of the strategy. An analysis of relevant scientific literature was combined with an analysis of the internal and external situation of JAM. Interviews with both competitors and customers of JAM provided insights in the external situation of JAM. A case study of successful growth realisations in young professional service firms provided valuable insights into foundations of growth. The growth strategy bridges the gap between JAM’s current and desired state. To reach the desired state each of the growth bubbles needs to be further developed, implemented and supported by both owners and employees of JAM. A roadmap and corresponding product-service combinations will provide JAM with the first steps to start the strategic change process. Implementing the growth strategy will need to be a group effort. This will stimulate co-operative working styles and create a shared purpose. JAM will go through the growth model to fulfil each factor in the growth foundation. The bubbles show a few important steps that JAM will take. When the first four growth foundations are fulfilled, JAM will be able to experience the next evolution. Growing the company will be a challenging, exciting, intensive and somewhat confronting process. With the creative minds of JAM and the guidance of the growth model, JAM will strive to a bright future.","growth model; growth; strategy; roadmap","en","master thesis","","","","","","","Campus only","2014-08-30","Industrial Design Engineering","Product Innovation Management","","Master of Science Strategic Product Design","",""
"uuid:8c533126-8062-4279-98cd-2df03d131fc3","http://resolver.tudelft.nl/uuid:8c533126-8062-4279-98cd-2df03d131fc3","Prognostic Molecular Classification of Breast Cancer Based on Features Extracted from a Scale Space","Wu, Y.; De Ridder, J.; Reinders, M.J.T.","De Ridder, J. (mentor); Reinders, M.J.T. (mentor)","2013","Breast cancer is one of the most prevalent cancers affecting females in the world. In recent years, many cancer researchers have been trying to determine molecular prognosis tools that predict cancer patient treatment response and/or chance of survival. In particular, the determination of gene expression signatures obtained by feature selection methods applied to large microarray datasets has shown potential. The main purpose of this study is to extend these gene signatures and molecular prognostic classifiers by investigating features constructed from a scale-space representation of the microarray data. Here, we construct a scale space by first mapping all genes to a one-dimensional functional space using protein family information. Next, we applied successive smoothing to the expression values resulting in one scale-space representation of the gene expression data from one sample. At the lowest scale, the scale space contains the original gene expression values, whereas at higher scales meta-features are formed, which are weighted sums of groups of genes. To test whether a scale-space representation is useful we performed feature selection and classification on a publicly available breast cancer expression dataset. We found that, instead of signatures consisting of single genes, meta-genes (i.e. groups of genes) that exist at higher scales were preferentially selected. We furthermore determined cross-validation errors using seven distinct classifiers (NMC, LDC, QDC, FISHERC, PARZENC, 3NNC, and LOGLC) and found that better performance is obtained using the scale-space representation than with the traditional representation of the gene expression data. As a result, we conclude that the scale-space analysis constitutes a potent way of selecting molecular signatures and is useful for prognostic classification.","breast cancer; scale space; classification; feature selection","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Intelligent Systems","","Pattern Recognition and Bioinformatics","",""
"uuid:d6d4054d-f346-4fa2-a5ae-c790836d341d","http://resolver.tudelft.nl/uuid:d6d4054d-f346-4fa2-a5ae-c790836d341d","Calculating the required capital of an insurance company by means of elliptical copulas","Van Tol, P.J.M.","Kuut, A. (mentor); Oosterlee, C.W. (mentor)","2013","A couple of topics on calculating the required capital of an insurance company are covered in this thesis. We derive a new method in order to compare correlation matrices of aggregation methods consisting of one- or two-levels. Different from earlier time series analysis, we show that a prediction for the one-year correlation can be made with the use of frequently available data and employing time series analysis. Furthermore, a robustness analysis of the Standard Formula is performed and an estimation for the degrees of freedom parameter of a t-copula is obtained from market data.","required capital; copulas; correlation matrices; aggregation; time series analysis","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","DIAM","","Master Applied Mathematics","",""
"uuid:2bb6c35c-40d7-4ded-876c-dd4d911ae94b","http://resolver.tudelft.nl/uuid:2bb6c35c-40d7-4ded-876c-dd4d911ae94b","ONE SIZE DOES NOT FIT ALL; Implementing technical and social assessments of sanitation reforms in rural Indonesia","Binol, R.R.","Lier, J.B. van (mentor); Kreuk, M.K. de (mentor); Molenbroek, J.F.M. (mentor)","2013","The deadline for the Millennium Development Goal (MDG) No. 7, to halve the world’s population without access to improved sanitation is fast approaching. Reports have shown that significant progress have been made since its first initiation in the 1990s. Unfortunately, based on the current development rate, the estimated population of the world that will have improved sanitation in 2015 will be 67%, which lags behind the target goal of 75%. Regardless, countries, government agents, sanitation experts and health organizations worldwide are continuously cooperating together to stay on track with the MDG with the objective of improving the health of the world’s population and to achieve environmental preservation. In order to provide sanitation facilities that achieves this objective, many different types of decision-making frameworks have been developed to guide decision makers in selecting the most optimal sanitation facility that could function under local conditions. These tools have varying criteria, there are one that focuses on the technical feasibility and other assess the systems based on the incurred cost as well as the willingness to pay of the user. Models that recognizes the sensitivity of the social-cultural influence of the users have also been created. Though, difficulties may come when communities ought to be assessed and expressing findings or social phenomenon in quantified values. In light of progressive development in the sanitation world, this research aims to participate in implementing a socio-tech assessment on sanitation options in Banten, Indonesia. It has been abundantly seen that sanitation options implemented in the past stopped functioning within a period after its construction. Poor operation and maintenance, lack of managerial oversight and unavailable funds are some of the issues that trigger the abandonment of these monumental sites. The technical functionality of different sanitation options will be assessed by adopting the decision making tool developed by Malekpour (2012). Furthermore, social assessments using qualitative analysis were conducted using three different case studies to investigate the current practices of the communities and to identify their needs and requirements with the available sanitation options. The three different sanitation systems that have passed the screening stage were 1) pour flushed toilet – communal septic tank – subsurface constructed wetland; 2) pour flush toilet – communal septic tank – upflow filter; and 3) pour flush toilet – biogas digester. After sanitation options were assessed based on a probability evaluation on their performances for the criteria of exposure to health hazard, accessibility, reliability and sustainability, the sanitation option that performed the best was the option that used the pour flush-toilet connected to a communal septic tank and subsurface wetland. Results from the social assessments showed that receptivity of a technology is greatly influenced on its fulfilment on the demands of the users. Factors found to be of dominant requirements include: maintainability, affordability, water accessibility and convenience. By combining the findings from both the technical and social assessment, this research proposes an open toilet design that have been tailored to the practices of the local users, with a squatting pour flush toilet pan (aiding local users that are classified as washers), connected to a communal septic tank and finally to a constructed wetland with subsurface flow. This design aims to attain acceptability from the users, to motivate optimal usage of the facility and achieve health and environmental improvement in the project area of Banten, Indonesia.","socio-tech assessment; sanitation; Banten","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Water Management","","Sanitary Engineering","",""
"uuid:37030723-ced8-4358-9103-5f19d7b640d0","http://resolver.tudelft.nl/uuid:37030723-ced8-4358-9103-5f19d7b640d0","The implementation path to a future of Smart Thermal Grid: Designing a roadmap for Smart Thermal Grid neighbourhood implementation for an energy supplier by creating a socio-technical framework","Van Tol, W.A.J.","Herder, P.M. (mentor); Lukszo, Z. (mentor); Hermans, L.M. (mentor); Van Laarhoven, M.A.J. (mentor)","2013","","Smart Thermal Grid; Socio-technical system; Socio-technical complexity; Roadmap; TIP-framework","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Energy & Industry","","Systems Engineering, Policy Analysis and Management","",""
"uuid:203fdcbd-5992-406d-8033-c021da0710ce","http://resolver.tudelft.nl/uuid:203fdcbd-5992-406d-8033-c021da0710ce","Network Monitoring with Software Defined Networking: Towards OpenFlow network monitoring","Gourov, V.N.","Kuipers, F. (mentor); Van Adrichem, N. (mentor)","2013","Network monitoring is becoming more and more important as more Internet Service Providers and Enterprise networks deploy real-time services, like voice and video. Network operators need to have an up-to-date view of the network and to measure network performance with metrics like link usage, packet loss and delay, in order to assure the quality of service for such applications. Obtaining accurate and meaningful network statistics helps the service providers to estimate the ""health"" of their network, to find service degradation due to congestion and could even use them for routing optimization. Finally, a more accurate picture of the nature of the Internet traffic is important for continued research and innovation. In this thesis, Software Defined Networking is used as a unified solution to measure link utilization, packet loss and delay. Currently, there is no single solution capable to measure all the mentioned metrics, but a collection of multiple different methods. They all need separate infrastructure which needs additional installations and expenses. Furthermore, those methods are not capable to meet all the requirements for a monitoring solution, some are not accurate or granular enough, others are adding additional network load or lack scalability. Software Defined Networking is still in an early development stage. Unfortunately, obtaining network statistics is a problem that has not been discussed very much. Nevertheless, OpenFlow protocol is already gaining a lot of popularity and it could be used as a unified monitoring solution. Its built-in features are already sufficient to provide accurate measurements. This thesis explores what are the current monitoring methods with and without Software Defined Networking and how monitoring could be archived in an OpenFlow enabled topology. It proposes methods to measure link usage, packet loss and delay. In terms of link usage statistics several approaches are proposed to reduce the generated overhead. Furthermore, the thesis also suggests how to measure how packet loss in networks that use OpenFlow.","SDN; OpenFlow; monitoring; packet loss; utilization","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Telecommunications","","Network Architectures and Services Group","",""
"uuid:3a0eeaeb-8427-45b8-858c-3272bf104cd5","http://resolver.tudelft.nl/uuid:3a0eeaeb-8427-45b8-858c-3272bf104cd5","A BYOD Enterprise Security Architecture for accessing SaaS cloud services","Samaras, V.","Daskapan, S. (mentor); Van den Berg, J. (mentor); Koornneef, F. (mentor); Rook, L. (mentor)","2013","In contemporary times IT plays a major role in enterprises’ business processes. Companies pursue the adoption of new technological trends in order to improve their business in terms of both performance and efficiency so that they can keep up with the fierce market competition. However, the introduc tion of cloud computing services and the opportunity for employees to work using their own smart phones through the adoption of BYOD/BYOS policies introduce additional risk for the firms’ processes. The question that needs to be answered is how the aforementioned risks can be reduced to acceptable levels, in order to support a secure adoption of IT consumerization and SaaS cloud computing trends. In order to answer this question, this report proposes a component security architecture for enterprises. The design of it is based on a desk research on academic and industrial literature, by which the enterprise environment is defined. Additional hardware, software and service-oriented security components are applied, using the SABSA security architecture framework, in order to secure the SaaS cloud services access by Smartphone BYOD.","SABSA Security Architecture; Smartphone; BYOD; BYOS; Cloud Sprawl; Mobile Device Management","en","master thesis","","","","","","","","","Technology, Policy and Management","ICT","","Management of Technology","",""
"uuid:bc6eff59-2756-4ef8-bae5-f51d4d7079cd","http://resolver.tudelft.nl/uuid:bc6eff59-2756-4ef8-bae5-f51d4d7079cd","The value of 4D seismic data to production forecasting","Van Oeveren, H.E.J.","Jansen, J.D. (mentor)","2013","Minimizing the mismatch in the output of a petroleum reservoir model to 4D seismic data has the potential to increase its production forecast accuracy. However, the impact of 4D seismic data on the economic value of improved reservoir management decisions enforced during the production forecast has not been quantified. This work investigates the potential net present value (NPV) of an oil field production strategy, optimized on models conditioned to 4D seismic data, production data, or both data, controlling the production forecast in a method of adjoint-based assisted history matching and model-based optimization. Applying independent porosity updates in AHM might result in geologically unrealistic parameters; therefore this work applies customized gradients to update the permeability field and dependent on that the porosity field honoring a porosity permeability relation. The method is tested on a 3D synthetic oil model, and repeated by starting on nine prior models, which results in an average gain in the achieved NPV with respect to the prior models of 6.45%, 7.04%, and 7.96%, based on assimilating respectively 4D seismic data, production data, or the combined data set into the prior model after five years of historical production. This gain in NPV is lost when the workflow is postponed by five years. This implies that the moment of applying the proposed method can be essential to the achieved gain in economic value. This work also illustrates that the accuracy of the model to predict liquid rates during both the historical production and the production forecast is increased by assimilating the combined data set.","assisted history matching; model-based optimization; 4D seismic data; Brugge benchmark; reservoir management","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Petroleum Engineering","",""
"uuid:e5e3618d-5a1d-4ebd-91b8-580072ac2370","http://resolver.tudelft.nl/uuid:e5e3618d-5a1d-4ebd-91b8-580072ac2370","An Innovative Lighting Solution for Packaged Food and Supermarket Aisles","Chew, W.B.","Christiaans, H. (mentor); De Lille, C. (mentor)","2013","There has been a paradigm shift in the lighting industry brought by a fundamental change in technology of using solid-state lighting so called light emitting diode (LED). This digital technology brings new benefits such as long LED lifespan but It also results in new competition from the LED entrants from non-lighting background. Against this treat, traditional lighting manufacturers have to move upwards into the solution market and focus in new application areas such as the supermarket aisles. At the same time, supermarkets are experiencing very high market competition as a result of the market saturation. Brands have to continue to innovate and differentiate to gain a competitive advantage. Increasingly shoppers are more demanding in their shopping experience. Ultimately, a supermarket experience is about convenient. The analysis suggests lighting has to be seen in the holistic system; shopper wants to conveniently seek a product. A convenient buying experience need not be functional in a supermarket. The taste in the products is motivated by personal emotions. The concept is to help users seek products in the supermarket easily by recommendation. The recommendation is given in accordance with the user’s emotion input into the smartphone. Thereafter, LED light strip on the product shelf will light if a product matches the users profile. The encounter between product and light create an element of surprise that allows user to seek product emotionally.","retail design; lighting design","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Strategic Product Design","",""
"uuid:ba51915d-048e-42a5-a004-8022f82ca83a","http://resolver.tudelft.nl/uuid:ba51915d-048e-42a5-a004-8022f82ca83a","Improving the Algal Bloom Prediction in the North Sea by Ensemble Kalman Filtering in the GEM/BLOOM Model","Rens, E.G.","El Serafy, G.Y.H. (mentor); Heemink, A.W. (mentor)","2013","The ecological state of the North Sea surface water can be indicated by ocean variables such as the Chlorophyll-a (Chlfa) concentration. Chlfa is the principal photosynthetic pigment and is common to all phytoplankton and can therefore be used as a measure of phytoplankton biomass. The GEM/BLOOM model developed at Deltares is a generic ecological model that simulates transport of substances in a water system along with various ecological processes. This model is able to estimate the Chlfa concentration. Models are always prone to errors due to assumptions made in the development and the use of numerical approximations. Such errors can be reduced through the use of data assimilation and thus can significantly improve the forecast. The ensemble Kalman filter (EnKF) is a generic data assimilation method which is suited for highly nonlinear models with a large scale. This filter is validated by the use of twin experiments on the GEM/BLOOM model. It successfully improves the prediction of Chlfa,but however shows filter divergence in some grid points. The performance is further improved by the use of the Ensemble Square Root Filter (ESRF) with a localized analysis. Finally, application of this filter to assimilating daily MERIS remote sensing images is explored and shows to be promising, but requires more tuning before it can operate.","data assimilation; ecological modeling; remote sensing images; ensemble kalman filter; ensemble square root filter; covariance localization; chlorophyll-a concentration; algal blooms; phytoplankton; north sea","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied Mathematics","","Mathematical Physics","",""
"uuid:34cd19c5-a65d-4004-95ee-7685e502d7c6","http://resolver.tudelft.nl/uuid:34cd19c5-a65d-4004-95ee-7685e502d7c6","Framing analysis as a tool for science press officers: The biofuel debate case in the Argentinean and British press","Rodriguez, N.","Van der Sanden, M.C.A. (mentor); Wehrmann, C. (mentor); Olenyi, S.R. (mentor)","2013","","framing; biofuel; sustainability; press officer","en","master thesis","","","","","","","","","Applied Sciences","Science Education and Communication","","","",""
"uuid:93cd7be7-0790-41a6-9b79-181d90dd0258","http://resolver.tudelft.nl/uuid:93cd7be7-0790-41a6-9b79-181d90dd0258","Shifting From Go/No Go to Flexible Offshore Wind Farm Investment Decisions","Van der Beek, J.C.","De Vries, L. (mentor)","2013","In the current paradigm of looking into investments in offshore wind farms (OWFs), a conscious flexible investment strategy of a project developer does not often occur. This research shows that from a rational economical perspective, flexibility in the investment strategy of an OWF project developer can matter. Two experiments are done to investigate the added value of a flexible investment strategy compared to a ‘develop and delay’ investment strategy. The outcomes of interest are compared for both the realised relative and realised absolute returns on equity. The most important conclusion is that in case of the realised relative return on equity the ‘flexible cautious’ strategy in the model is superior to the ‘develop and delay’ strategy in every future scenario. It is already confirmed by different other authors, that waiting for more favourable external conditions matters. This study provides a new insight to this phenomenon, that the benefits obtained by waiting for more favourable external conditions can be exploited when combined with a ‘flexible cautious’ investment strategy.","adaptive policies; Exploratory Modelling and Analysis; investment decisions; offshore wind farms","en","master thesis","","","","","","","","2013-08-30","Technology, Policy and Management","Energy & Industry","","Systems Engineering, Policy Analysis and Management","",""
"uuid:616713c8-5dad-4ee0-a9d6-304d8d8c9f81","http://resolver.tudelft.nl/uuid:616713c8-5dad-4ee0-a9d6-304d8d8c9f81","Mokkop: A personal moment for parents of hospitalized children with cancer","Van Beusekom, J.","Giaccardi, E. (mentor); Rozendaal, M.C. (mentor); Vermeeren, A.P.O.S. (mentor)","2013","When a child is diagnosed with childhood cancer, parents tend to forget about their own well-being and focus totally on their child. In many cases, parents break during the two year treatment and get emotional problems. Mokkop is coffee mug that reminds parents to take a moment for themselves. Five times a day it lights up to trigger parents to consider that moment as a suitable moment to leave for a 5 to 10 minute break for a coffee or a walk. Extra strength is added to this trigger, based on their social isolation, by having a neighbour get a signal at that same moment. Mokkop, a small gesture with large impact.","childhood cancer; Prinses Maxima Centrum; parents; well-being; coffee; emotional problems; remind","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Design for Interaction","",""
"uuid:0d4dc316-deae-4b39-a67b-7fc260c4881d","http://resolver.tudelft.nl/uuid:0d4dc316-deae-4b39-a67b-7fc260c4881d","Heineken Reverse Innovation: Innovating for and from emerging markets. Revealing market opportunities in developed countries","Torres, M.","Calabretta, G. (mentor); Roscam Abbing, E. (mentor)","2013","Nowadays, innovation is embedded in an ever-changing scenario which requires companies to constantly reshape their upcoming strategic decisions. Reverse Innovation is a clear reflection of that transition landscape where significant differences in the level of development of countries influences how to innovate. To HEINEKEN, this new approach presents a double challenge: to reaffirm the course of innovation as an driver for sustainable growth, and to leverage the international reach of the company to maximize the innovation potential of its subsidiaries. The main objective of this project is to address Reverse Innovation from an integrated overview, including a reverse innovation case study, the role of front end innovations in emerging markets, and ultimately, the development of a framework which can be used by HEINEKEN in future initiatives. To this end, the Nigerian market (and subsidiary) was selected by HEINEKEN as a host for this project.","reverse innovation; developing countries","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product Innovation Management","","Strategic Product Design","",""
"uuid:0729b0b2-125e-4806-94d2-1578717c2436","http://resolver.tudelft.nl/uuid:0729b0b2-125e-4806-94d2-1578717c2436","FUTURE.ME: Exploring design opportunities to enrich social intimacy through everyday practices","Wei, H.","Giaccardi, E. (mentor); Sonneveld, M. (mentor)","2013","This project focuses on 2 issues: 1. Explore the meaning to make social media tangible and 2. Sustain and enrich social intimacy on social media services. The 1st issue was the initial project goal, while later on we choose to address it through creating a design to fulfil the 2nd issue, since through a preliminary investigation we did see the potential of optimizing intimacy through tactual experience and besides, the space to research intimacy on social media platform is quite broad. After a user research on social intimacy, design exploration through tangible interactions in everyday practices, and iterative concept development cycles, we concluded the design vision as enriching intimacy between good friends in a light and playful manner and created a design scenario of Future.me, with a combined use of a web-service and a tangible product. Future.me is a novel web-service based on big social platforms like facebook, allowing people to joke about their friend’s future in a light and playful manner. Meanwhile, as a derivative product for the web-service, a tangible clock was also created to provide user an optimized experience in browsing generated social predictions and past traces. Through iterative tests and the final user test, the overall concept was proven to fulfil the design goal and interaction vision quite well: the online platform, being considered as light and unserious by participants, was able to collect interesting and personalized predictions from good friends, through which user could perceive the effort and authenticity of that person(sender), and they felt particularly intimate and engaged with those based on real mutual experience in the past, which makes the platform act like an intimacy filter. Besides, additional features designed to interact with predictions on the platform were also perceived as quite playful and easy, fitting the overall impression of the platform. As a supply to the web-service, the tangible clock was proven to provide a more playful and engaging experience with social contents visualized in such an intuitive way. Besides, entertaining, relaxing, handy and personal, according to our participants, are the added values the tangibility of the clock brought to the overall concept. In the end, the design case of future clock, representing product that facilitates tangible interactions between people and generated social data, was concluded to be able to: 1. enrich people’s experience when interacting with social data; 2. influence people’s habit of approaching social data and ultimately, 3. change people’s perception towards social data by wrapping it with a tangible form.","social media; intimacy; tangible interaction","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Design for Interaction","",""
"uuid:65889c83-2167-4d2d-b9ed-9558c0043271","http://resolver.tudelft.nl/uuid:65889c83-2167-4d2d-b9ed-9558c0043271","The role of power equipment companies in shaping the industrial Microgrid in the Dutch context","Brahim, A.S.","Weijnen, M.P.C. (mentor); Lukszo, Z. (mentor); Bruijne, M.D.E. (mentor); Weterings, R. (mentor)","2013","The objective of this research is to map the development of the innovative system, the industrial Microgrid, in the Dutch context. Furthermore, a recommendation is formed for power equipment companies regarding the role they can play in shaping the development of the industrial Microgrid in the Netherlands. A new analytical framework is constructed which conceptualizes the factors influencing innovations and the roles companies can play based in their ecosystem to influence the development paths. A scientific paper is also added, which focuses solely on the construction of the analytical framework. Its called: ""A strategic role for companies in the development of radical innovations: an analytical framework proposed.""","business ecosystems; industrial Microgrid; innovation development; strategic role","en","master thesis","","","","","","","","","Technology, Policy and Management","E&I","","","",""
"uuid:77005b40-e79f-479f-aa68-5a197a310c56","http://resolver.tudelft.nl/uuid:77005b40-e79f-479f-aa68-5a197a310c56","Underground mining method selection and preliminary techno-economic mine design for the Wombat orebody, Kylylahti deposit, Finland","Peskens, T.W.","Buxton, M.W.N. (mentor); Rinne, M. (mentor); Vervoort, A. (mentor)","2013","Mining method selection lies at the basis of every mining operation and is essential for maximizing economic return. Especially in the current market with decreasing metal prices selecting the right method can mean the difference between a viable and a non-viable operation. More importantly the right mining method increases the safety of employees and secures the production. The Kylylahti underground copper mine, owned by Altona Mining ltd. is located in Northern-Karelia, Finland. This deposit consists of two orebodies, the upper Wallaby and the lower Wombat. Longitudinal bench stoping is proposed for the Wallaby and Wombat orebodies. The Wallaby orebody is currently mined using the proposed method. However, different orebody characteristics suggest a more suitable mining method for the Wombat orebody. This work determines the mining method which maximizes economic return for the Wombat orebody. This is a three phase process. First phase is the mining method selection on technical suitability to the orebody; for which two methods are. The UBC method is applied first resulting in the selection of the area of sublevel stoping methods. Later a new technique is introduced to optimize the mining method selection process and to control the wide spectrum of mineral deposits. This technique is called the Fuzzy Analytic Hierarchy Process approach and is based on Multiple Criteria Decision Making. Six factors specifically applicable to the Kylylahti mine are used as input for the approach resulting in transverse bench stoping as the most suitable method for the Wombat orebody. In the subsequent phase, the rock mass properties of the ore zone and the host rock masses are calculated using the Q-classification method. These values are combined with the results of in situ stress measurements to determine the stability of the open stopes at different depths. Dimensions of the stopes are determined depending on the resulting stability limits on stope height, width and length. Applying these stope limits a preliminary mine design was made, resulting in a reserve estimation of 3.4 Mt of ore in place. This gives a life of mine of 6 years and 3 months for the Kylylahti mine using transverse bench stoping. The combination of all obtained data is the input for the financial analysis phase for the Wombat orebody; comparing the proposed longitudinal bench stoping to transverse bench stoping, as recommended in this thesis. The sensitivity of the net present value to metal price is investigated in two different metal price forecasting scenarios resulting in an economic return. In both scenarios transverse bench stoping maximized the economic return delivering $52 million and $63 million extra profit at the end of mine life.","Mining Method Selection; Fuzzy Analytic Hierarchy Process; Multiple Criteria Decision Making; Transeverse Bench Stoping; Underground deposit","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Resource Engineering","",""
"uuid:9a244be3-d1e4-4761-8481-92eb579ec7e5","http://resolver.tudelft.nl/uuid:9a244be3-d1e4-4761-8481-92eb579ec7e5","Horticulture water purification system: Design of a water purification system for the horticultural industry","Stricker, E.R.","Song, Y. (mentor); Van Os, E. (mentor)","2013","Water is one of the primary demands for plant growth. The quality and quantity of produce are also directly linked to the nutritional value of the water. But with every system that water passes through, the environment acts upon it, changing its composition along the way. Within horticulture it all comes down to control of the growing environment. One of the important systems in controlling this environment, is a water purification system. It purifies the water enabling it for use in irrigation. The most common system used to date is a reverse osmosis system. The technology operates through pressing water through a membrane with minute pores. The unwanted substances stay one side of the membrane, while purified water comes out through the other side. Disadvantages of this technology is the unsustainable character, and high running and maintenance costs. This project is set up to find an alternative technology that does not have the disadvantages that RO systems have. Through extensive technology research capacitive deionization has been found to be the best suitable alternative for purifying water. It is an emerging technology that operates by removing the ions from the water, instead of removing the water from the ions (RO). Capacitive deionization technology is far more sustainable than RO. Electricity uses can be cut down up to 95% and chemical cleaning is needed much less than with RO. The technology is fully modular and allows for a wide range of operating characteristics, be it water recovery percentage or removal percentage. This report proposes a design that implements this technology and enables H2ollandWater (the company that offered this project) to compete with RO systems and distinguish themselves as an innovative brand. To date the technology is quite expensive, but it already allows a profit to be made over RO systems within 2-3 years of operation. Within the next few years, large CD modules will be developed, significantly lowering cost price and enabling H2ollandWater to compete in the market at a high level.","capacitive deionization; horticulture; water purification; innovative","en","master thesis","","","","","","","Campus only","2014-08-30","Industrial Design Engineering","Design Engineering","","Master of Science Integrated Product Design","",""
"uuid:04082eb3-bb8c-4077-9ec2-0855da97a645","http://resolver.tudelft.nl/uuid:04082eb3-bb8c-4077-9ec2-0855da97a645","Dynamic peer-to-peer game networks using WebRTC","Abbink, J.; Grigorjancs, K.; Verdoorn, J.P.","Klos, V. (mentor); Hidders, J. (mentor)","2013","This document is the final report on the Bachelor Project conducted by Jasper Abbink, Karens Grigorjancs and Joost Verdoorn on Dynamic peer-to-peer game networks using WebRTC. In this report we detail our findings on the recently developed WebRTC technology. WebRTC enables the creation of web applications built around peer-to-peer technologies by providing the means to directly connect one browser to another. With this project we aimed to facilitate web developers by developing a software library that is a drop-in solution for large-scale peer-to-peer networks. We investigated the scalability of WebRTC networks and attempted to seek the edges of the technology. We evaluated a number of ways by which a browser-based peer-to-peer networks can be deployed, and implemented the ones that best suited our needs. To demonstrate our library we created a small massively-multiplayer arcade game as an entertaining way to display WebRTC's capabilities.","","en","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Software Computer Technology","","","",""
"uuid:56ad3010-0de5-4ef7-838c-681158cdc40e","http://resolver.tudelft.nl/uuid:56ad3010-0de5-4ef7-838c-681158cdc40e","KLM Crown lounge 2020","Vermeeren, B.","Santema, S.C. (mentor); Van Heur, R.J.H.G. (mentor)","2013","The KLM Crown lounge is an airline lounge offered to the premium passengers (PAX) of KLM and partners. The current lounge is a one-size-fits all concept fulfilling the basic needs (basic food and beverages assortment, Wifi and comfortable seating) of PAX. Overall lounge rating is declining while the competition has invested recently in their airline lounges. Above mentioned has resulted in a decreased ranking of the KLM Crown lounge compared to industry. Due to major rebuilding at Amsterdam Airport Schiphol the opportunity has presented itself to expand the current KLM Crown lounge in the non-schengen area. This opportunity will be taken to expand the lounge and deal with occupational problems occurring weekly. The upcoming expansion of the KLM Crown lounge creates the opportunity to develop a distinguishing lounge concept in line with a new lounge vision. Based upon an extensive analysis including observations, interviews, creative sessions, external analysis including a benchmark study and an internal analysis building blocks for the new lounge vision are formed. Based on these buildings blocks pillars are created; inspirational, tailor-made experience, hospitality and comfortable atmosphere. The different intermingled pillars forms the basis for the new vision of the KLM Crown lounge; visiting the KLM Crown lounge should be an inspirational tailor-made experience of hospitality in a comfortable atmosphere. PAX visiting the KLM Crown lounge have different moods. Based upon the new lounge vision a distinguishing lounge concept is developed. The new lounge concept offer a more tailor-made experience based on the moods of the PAX, away from the one-size-fits all concepts. 4 different more or less timeless moods of the PAX visiting the KLM Crown lounge are found and translated into zones; feeling of being home, energize, efficient working and indulge moments and presented graphically in mood boards. Movable walls separate the zones. The walls are equipped with advanced lighting technology enhancing the atmosphere fitting the mood. Moods of PAX are however not fixed. The space between areas is open and easy accessible to lower the threshold to switch zones. A concept for a mobile tool to simplify the selection process of choosing the right zone is developed; MyLounge. MyLounge could be integrated into the KLM app. The tool will be used to communicate with PAX; reserve a shower and send push notifications when the plane is ready for boarding making noisy announcements otiose. In line with the assignment the lounge’ business model should enable KLM to earn additional revenues, a new business model is developed for the lounge. The lounge concept offers PAX choice and the opportunity to be in control of composing their ideal lounge experience; there is a free basic assortment of amenities and on top of different paid options generating ancillaries. The offered amenities form a compliment to the customer’s journey. The atmosphere of the zone has positive affects, seducing PAX to spend money on desired paid amenities. Based upon the lounge vision, the developed concept and business model a roadmap is developed until the year 2020.","KLM; airline; lounge; crown","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","PIM","","SPD","",""
"uuid:e91fb785-f2b8-459c-a5c7-ab926da5d9cf","http://resolver.tudelft.nl/uuid:e91fb785-f2b8-459c-a5c7-ab926da5d9cf","A Generic and Automatic Test Strategy for Compiler Testing","Simoes Dias Vieira, A.M.","Wachsmuth, G. (mentor); Visser, E. (mentor)","2013","Domain-specific Languages (DSLs) are languages specifically tailored for an application or expert domain. These can be implemented as compilers, which check the correctness of an input program and translates it to a target language. Manual testing of compilers is a time consuming and labor intensive task. This motivates the development of approaches to facilitate the quality assurance process. In this thesis we present an automatic and generic test strategy for the generation of test cases for Spoofax developed compilers. We use a program generator to generate large syntactically correct programs from Syntax Definition Formalism (SDF) grammars. Additionally, we improve the program generator with an expansion of our generation algorithm to use Name Binding Language (NaBL) modules to generate partial name correct programs. We also provide a DSL to define error fixes that are used to attempt the repair of static semantic errors reported after compilation. After program generation we use a partial oracle to automatically detect failures during the invocation of the compiler. Finally, we provide a heuristic to reduce the size of generated programs, whilst preserving their failure inducing behavior. This test strategy was used to generate test cases forWebDSL, a DSL targeting the domain of developing dynamic web applications with a rich data model. The generated test cases unveiled eleven unique faults in the analysis phase of compilation. These were reported together with the programs reduced by our program shrinking heuristic and they were positively received by the WebDSL development team.","compiler; testing; test case generator","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","SERG","","Computer Science","",""
"uuid:2a4f7805-286f-4dfa-94f4-659874537398","http://resolver.tudelft.nl/uuid:2a4f7805-286f-4dfa-94f4-659874537398","A Framework for Measuring the Alignment between Business Models and Business Processes in Software Development Companies","Stoilov, I.","Tan, Y. (mentor); De Reuver, G.A. (mentor); Van der Duin, P.A. (mentor); Solaimani, H. (mentor); Hosseini, S. (mentor)","2013","Currently, there are plenty of tools and frameworks of measuring the strategic alignment of a company – the consistency between the corporate strategy and its business processes. However, no one has proposed a tool for measuring the alignment between a business model and business processes. This research project aims to fill this gap in the literature by developing a framework that enables the creation of performance measurement systems which aim at measuring the alignment between a company’s business model and its business processes. The framework we propose will be targeted at software development companies. We build our framework following the design-oriented research paradigm and one full design cycle was completed. The framework we built was applied to a real-live case in Dutch company. We build an business model / business processes alignment measurement system there and evaluated it with the help of employees of the company.","business model; business processes; alignment; performance measurement; measurement system; VIP framework","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","ICT","","Management of Technology","",""
"uuid:aebba960-17a2-4f9e-bdf8-8f9ff3c205cf","http://resolver.tudelft.nl/uuid:aebba960-17a2-4f9e-bdf8-8f9ff3c205cf","Enhancing the efficiency of retail cash handling processes at Amsterdam Airport Schiphol","Hashemi Ahmadi, M.","Van Duin, R. (mentor); Tavasszy, L. (mentor); Meijer, S. (mentor); Rozenberg, P.J. (mentor)","2013","During the recent years, electronic payment methods have become more customary and in cases more preferable. Nevertheless, cash remains a popular form of payment due, inter alia, to its ubiquity. Large use of cash is associated with security issues, investment costs, logistics costs of transport and handling cash, personnel costs, and the like. To deal with these issues, many retailers have, to different extents, outsourced cash handling services to CiT companies. Kappe’ and Schiphol Airport Retail (SAR) are two retail groups functioning at a number of locations in Amsterdam Airport Schiphol. They currently outsource part of their cash handling services to ABN-AMRO and GWK-Travelex. This results in a further increase in costs incurred by Kappe’ and SAR. Consequently, enhancing the efficiency of money flow is of significant importance to both corporations. The aim of this research is to develop cash handling processes which can bring about a more efficiency. This is done firstly by conducting a literature review on the reasons behind large costs of cash handling for retailers. Then the current processes of cash handling at Kappe' and SAR are studied to explore their deficiencies. After that, alternatives (e.g. automation, joint cash office, clustering) which can bring about a more efficient cash handling process are proposed and assessed on criteria of interest to the problem owners (Kappe' and SAR). The implementation chapter is done for the selected alternative. In the next stage, the prudence of the selected processes is e-evaluated by using a multi-criteria analysis methodology and also based on the trends in customers’ use of cash in payments. Finally, given the findings of the research, recommendations are provided for future improvement in cash handling processes.","retailers costs of payment; efficient cash handling processes; Activity-Based Costing; Cash-in-Transit Company; cash recycling; Multi-Criteria Decision Making","en","master thesis","","","","","","","","","Technology, Policy and Management","Transport and logistics","","Management of Technology","",""
"uuid:38e0223b-5742-4b36-b8a2-108182965a35","http://resolver.tudelft.nl/uuid:38e0223b-5742-4b36-b8a2-108182965a35","“Assessing the possibility of cooperation between Amsterdam and Hanoi in the Field of Solid Waste Management”. Study case: Feasibility of transferring Dutch technology of Waste-to-Energy from Amsterdam to Hanoi","Nguyen, M.T.","Weijnen, M.P.C. (mentor); Lukszo, Z. (mentor); Van Daalen, E. (mentor); Wenzler, I. (mentor)","2013","Hanoi, the capital city of Vietnam, currently faces a price of booming development: pollution from waste. For example, within the last 10 years, the amount of municipal solid waste (MSW) has tripled in the city, from roughly 800,000 tons/year in pre-2007 to 2,400,000 tons/year in 2010. As the result, this situation challenges the home city of 6 million Vietnamese to reach out to experts and experienced organizations, looking for plausible solutions regarding its pollution issue. At the end of 2012, Hanoi authority approached Amsterdam with an appeal of a cooperation in solid waste management, in which the transfer of Amsterdam’s technology of Waste-to-Energy (WtE) is one of suggested options. However, there are various questions regarding the capability of Hanoi to invest in and handle the state-of-art technology, which has inspired the author for this research. The focus of this research is to assess the possibilities of cooperation between Amsterdam and Hanoi in the field of Solid Waste Management, with the case study of technology transfer in Waste-to-Energy.","solid waste managment; waste to energy; waste incineration; municipal solid waste; Hanoi; Vietnam; Amsterdam; The Netherlands; World Bank; cooperation; developing countries","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Infrastructure Systems & Services","","Engineering and Policy Analysis","",""
"uuid:da0ade3f-e05a-41e1-97de-28d672842d78","http://resolver.tudelft.nl/uuid:da0ade3f-e05a-41e1-97de-28d672842d78","Een selectie algoritmen voor lineair programmeren (A selection of algorithms for linear programming)","Van Katwijk, B.","Aardal, K. (mentor); Van den Berg, P. (mentor)","2013","In dit verslag zijn enkele algoritmen voor lineair programmeren (LP) beschouwd en afgeleid, in het bijzonder het relatief nieuwe relaxatiealgoritme van S. Chubanov dat sterk-polynomiaal is voor een specifieke klasse LP-problemen.","algorithm; linear programming; chubanov; ellipsoid","nl","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Optimization","","","",""
"uuid:17361dd2-62ac-476b-9c2f-af1a2475bb84","http://resolver.tudelft.nl/uuid:17361dd2-62ac-476b-9c2f-af1a2475bb84","Process Algebraic - Performance Modeling of Embedded Software","Seetharama Aithal, R.","Van Genderen, A. (mentor)","2013","A compiler for embedded platforms has many optimization flags providing code size and speed improvement. Traditional profiling methods take lot of time to identify the best combination of the compiler flags to suit the requirement especially if the software stack is very huge. AUTOSAR is one such growing software market in which there is a need for rapid performance assessment. In this thesis a means to estimate the performance of a program using the process algebraic language (PEPA) is investigated. The assembly program is converted in to the PEPA model and the performance measures obtained by solving the model is verified against the actual execution time of the program. The experimental results provide valuable insights on the methodology.","AUTOSAR,PEPA,Performance Modeling,Process Algebra,Optimization","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Computer Engineering","","Embedded Systems","",""
"uuid:3bf8a7dc-cbce-4dfd-8ba4-ff923725c4a4","http://resolver.tudelft.nl/uuid:3bf8a7dc-cbce-4dfd-8ba4-ff923725c4a4","Effect of oil on foam flow in porous media modeled by the Stochastic Bubble Population model","Janmahomed, F.R.","Zitha, P.L.J. (mentor)","2013","The Stochastic Bubble Population (SBP) model invented in 2006 by Prof. Dr. Zitha has been improved to take in account for the oil presence in the porous medium through which foam flows. The assumptions of the SBP model are that foam flow in porous media is a complex fluid and bubble generation is a stochastic process. The SBP model is a simple model as it describes the net bubble generation using three parameters: maximum bubble density, bubble generation and bubble destruction coefficients. Oil present in the porous medium through which foam flows destabilizes the foam indicating that there is a bubble destruction coefficient not equal to zero, which in turn is dependent on the prevailing oil saturation. In this paper we first introduce the modifications made for taking in account the presence of oil in the porous medium. Then we consider the SBP model for the case of a strong foam, thus bubble destruction coefficient equal to zero and perform a sensitivity analysis. Afterwards, the SBP model is considered again but then for the case of a destabilized foam, thus bubble destruction coefficient not equal to zero and perform another sensitivity analysis. Finally, the cases of zero and nonzero oil presence in the porous medium are compared with each other.","Stochastic Bubble Population model; foam flow; porous media; maximum bubble density; bubble generation; bubble destruction coefficients","en","bachelor thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","","",""
"uuid:8ac14732-ea14-46da-b279-c845bc3e9353","http://resolver.tudelft.nl/uuid:8ac14732-ea14-46da-b279-c845bc3e9353","Understanding the Base of the Pyramid: Inclusive Innovation Context Analysis Framework","Thapa, P.","Kamp, L.M. (mentor); Blom, E.M. (mentor); Van Beers, C.P. (mentor)","2013","Around 4 billion people are currently living below income of $3000 a year, constituting the largest and poorest socio-economic group in the world. This group of people, termed as the Base of the Pyramid (BoP), can be a lucrative market for innovative companies due to its massive size when targeted with innovative products and appropriate business models. The innovations targeted for the BoP markets, which aspire to help in eliminating poverty and promoting inclusive economic growth through market mechanisms, are called inclusive innovations. Inclusive innovation is an emerging practice. While some of the inclusive innovations have been successfully introduced and deployed, some other innovations, although having potential, have failed to achieve the aimed level of impact. This failure can, at least partially, be related to the lack of information about the BoP context. This research is conducted in collaboration with BoP Innovation Center (BoPInc), an intermediary organization working to facilitate inclusive innovations. The thesis has the objective to propose a preliminary methodological framework to collect, analyze, and use relevant strategic information about the inclusive innovation context for facilitating organizations looking to operate in the base of the pyramid markets. A four-step approach is followed to develop the methodological framework, termed as Inclusive Innovation Context Analysis Framework (IICAF). First, existing theoretical frameworks are reviewed to have a holistic perspective of inclusive innovation from relevant fields. The literature review includes the study of theoretical concepts and frameworks related to the characteristics and process of inclusive innovation, innovation context, as well as organizational capabilities and strategies. The theoretical frameworks, identified during the literature study, are then systematically combined to form an integrated framework. In the second step, the IICAF is refined further, by consulting experts in the field of inclusive innovation. In the third step, practices of inclusive innovation in the Netherlands are studied, compared with the insights from the theory and analyzed to reach to the final version of the IICAF. In the forth step, the methodology to use the proposed IICAF is described and illustrated, using a demonstration case of a company developing inclusive innovation. The IICAF systematically categorizes the appropriate contextual information that needs to be collected, and presents the methodology to use this collected information to make necessary strategic decisions in the inclusive innovation process. The IICAF recommends to use a systemic perspective by collecting relevant information about the innovation context and categorizing the information into three broad categories of (a) Market, (b) Institutions, and (c) Infrastructure. Infrastructure can be considered as the hardware of the innovation system. Institutions can be considered as the software, which enables operation of the infrastructure (hardware) to deliver the desired output, i.e. inclusive innovation. The characterisitics of the desired output (inclusive innovation) is influenced by the existing market conditions. To study the market, infrastructural and institutional conditions of the innovation context, a structural and a functional study of innovation system is recommended. To analyze and use the contextual information obtained from innovation system studies, it is recommended to perform an organizational scan to assess the objectives, resources, and capabilities of the organization itself. The organizational scan helps to utilize the information about innovation context to make appropriate strategic choices in the inclusive innovation process to develop innovations with desirable inclusive innovation characteristics. The research has identified a list of eight desirable inclusive innovation characteristics. The research has also formulated the stages related to the process of inclusive innovation. The IICAF delineates the organizational and contextual information to be used step by step in the inclusive innovation process. The IICAF is divided into six steps: (1) strategic phase, (2) idea generation, (3) market scanning, (4) focused study, (5) marketing mix, and (6) scaling. The most important use of the IICAF is in the market selection process. The market selection process is divided into two stages: market scanning, where a group of attractive markets are short-listed, and, focused study, where the most optimal market of entry is selected. Information about the structure of an innovation system can be used in the market scanning phase. To study the structure of the innovation system, collecting secondary quantitative data from built-in databases is recommended. The quantitative data are analyzed using a multi-criteria decision analysis procedure. The attractive markets can be selected based on the overall weighted score for each alternative markets, where weights to each criteria are provided based on the organization’s objectives and resources. The focused study aims to select the optimal market. To do so it collects, information about the functions of innovation systems of the attractive markets that are identified in the market scanning. The information about functions of innovation system can be collected and used in parallel with the business model development process, by following a methodology developed and described in the thesis as ‘why-what-who-how’ analysis. The why-what-who-how analysis can be used to identify a ‘window of opportunity’ for entering the most optimal market. From the research it can be concluded that by combining frameworks used to study the inclusive innovation, innovation context, and organizational strategies, BoP markets can be studied systematically. The findings of the research can contribute in streamlining the inclusive innovation process. The IICAF is primarily developed as a market development tool for organizations willing to deploy inclusive innovations. However, the IICAF can also be used by policy-makers, researchers, intermediary organizations, and governments who are interested in analyzing the inclusive innovation context. BoP Innovation Center, for whom the framework is designed for in this research, can play an intermediary role in supporting organizations to apply the IICAF.","BoP; Base of the Pyramid; Bottom of the Pyramid; poverty; innovation; framework; inclusive innovation; aQysta","en","master thesis","","","","","","","","","Technology, Policy and Management","Technology Dynamics and Sustainable Development","","Management of Technology","",""
"uuid:95c42e6f-1764-45c0-a5da-e63e166c4a65","http://resolver.tudelft.nl/uuid:95c42e6f-1764-45c0-a5da-e63e166c4a65","An Energy-Efficient, Resistor-Based, Smart Temperature Sensor","Souri, K.","Makinwa, K.A.A. (mentor)","2013","","CMOS; temperature; sensor; resistor; phase domain; sigma delta; hybrid; continuous time; discrete time","en","master thesis","","","","","","","","2013-09-03","Electrical Engineering, Mathematics and Computer Science","Mircroelectronics","","Electronic Instrumentation","",""
"uuid:e109803e-b215-463a-9b62-74e5233d5e47","http://resolver.tudelft.nl/uuid:e109803e-b215-463a-9b62-74e5233d5e47","Forecasting and Modelling of Cash Payments at Retail Stores: The Case of SAR and Kappe","Ozkale, B.","Rezaei, J. (mentor)","2013","Recently, some retail stores face large amount of cash transactions and thus leave traditional cash handling organizations to improve the efficiency. When switching to a new cash management system, retailers need forecasts of cash payment volumes. Two airport retailers, Schiphol Airport Retail (SAR) & Kappe are among those companies that seek for a solution to reduce the costs and improve the efficiency related to logistics of money flow. In this study, aggregate and disaggregate factors influencing the cash payments of retail customers have been investigated in order to explore the drivers behind fluctuations in cash payments. The existing studies are extended to airport retailers’ case in order to see which factors can be influential in those two specific cases. Next, the common forecasting methodologies used by businesses have been applied to the two airport retailers according to the problem specification and data available. The performances of these methods are compared and the output of the forecast model suggested in this study have been used by another study that investigates different alternatives for cash handling organizations.","forecasting; behavioral modelling","en","master thesis","","","","","","","","2016-01-01","Technology, Policy and Management","Transport and Logistics","","Management of Technology","",""
"uuid:bc9e86ce-3268-49ea-a8c1-88945993b390","http://resolver.tudelft.nl/uuid:bc9e86ce-3268-49ea-a8c1-88945993b390","Design for Obesity","Wu, C.C.","Moes, C.C.M. (mentor); Molenbroek, J.F.M. (mentor)","2013","This report describes the process and the results of a project which focuses on designing for obesity. The project starts with fuzzy front end which is to explore the needs of obese people. A thorough literature is carried out to understand obesity in different perspectives. Later on, an internal analysis shows the background and the knowledge of the company, the opportunity in the obesity market and the advantage to develop a product for obesity. An external analysis reviews the current situation correlating with obesity in the society. Moreover, it gives an overview of competitors and stakeholders; the prior one indicates the threats to Tilcentrum and the later one lists the people involved with priority. A field research including interviews and observation of obese people. The purpose is to gather the information which cannot be obtained from the literature research. The result of the literature research and the insights gained from the field research formulate the design vision: “By combining home activities and training exercises for better physical condition, the defined end-users are motivated to be active and further improve the quality of life.” The second phase, concept development phase, starts with the list of functions that is the research result of the vision development phase. Some of the functions need more specific definitions, so a brief literature research is conducted to support the elaborated functions. Five of the functions, indication, motivation, reminder, integration and challenging, are considered as a starting point for idea generation. The other functions such as aesthetics or accessibility are concentrated at the stage of conceptualization. The ideas are generated by the means of creative session which is a systematic process inspired by the possible solutions for each function. Eight principle solutions are selected and developed into ideas. After evaluating the ideas involving the opinions from end-users and Tilcentrum, three ideas are chosen to be the future concepts. They are separately Sit-up Assistant, Squat Assistant and Stand-up Assistant. Each concept has detailed descriptions of its design and the usage scenario. A principle test (preliminary user testing) and free body diagram are made in order to examine and prove the working principles of the concepts. Afterward, three concepts are evaluated by an extended version of criteria. The criteria with marketing orientation ensure the evaluation process to be more comprehensive. The concept, Squat Assistant, is selected as the final design proposal after comparing the pros and cons of all the concepts. In the beginning of the embodiment phase, the requirements of Squat Assistant are listed. The requirements are generated from the product process tree and the research results from different phases. They are continuously adjusted during the design process. The working principle of the concept is evaluated by a preliminary user testing. This testing also defines some of the geometrical shape and dimensions like the knee padding height. There are valuable comments from the testing which are implemented in the final design. Currently, there is no sufficient anthropometric data relating to obesity. An ergonomic research is simultaneously carried out to collect referable data. The final design has an added function; Squat Assistant can be used as a chair. At this stage, all the dimensions, materials and assembly have been defined. However, the functional prototype has slight differences from the final design; it is built with available materials and inspired by force simulations. The prototype is used for user testing at which two participants are instructed to evaluate the concept. Two opposite results come from the distinct participants. The participant representing the smallest group (P5 female with BMI 33) is satisfied with the product functions; the participant representing the biggest group (P95 male with BMI 45) cannot squat properly. These results indicate the shortcomings of the concept, but the working principle is approved by the user who is capable to squat. Furthermore, a long term study is needed to explore the long-term influence of changing behavior.","obesity; active; exercise","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Applied Ergonomics & Design","",""
"uuid:b7665bca-88d0-4821-adde-7467577ed597","http://resolver.tudelft.nl/uuid:b7665bca-88d0-4821-adde-7467577ed597","From value creation to value capture: Instruments of indirect value capture to fund investments in road infrastructure projects","Slegtenhorst, I.","Hertogh, M.J.C.M. (mentor); Verlaan, J.G. (mentor); De Wolff, H.W. (mentor); Schuurman, E.J. (mentor)","2013","","value creation; value capture; instruments; financial feasibility; road infrastructure projects","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Construction Management and Engineering","",""
"uuid:a07d9375-82f9-4d22-a562-3352a14f9e27","http://resolver.tudelft.nl/uuid:a07d9375-82f9-4d22-a562-3352a14f9e27","Assessing the potential of depleted gasfields for geothermal energy","Daarnhouwer, M.F.","Salimi, H. (mentor); Wolf, K.H.A.A. (mentor)","2013","In this thesis, the feasibility of a geothermal doublet in the former Barendrecht gas field is investigated. The aim of this work is to stay as closely as possible to the original well configuration. An IMPEXS model for the movement of the cold-water and thermal front is built to calculate the possible potential of the field. Wellbore heat losses and pump capacity were taken into account to evaluate the exergy (useful energy) created by the geothermal doublet. The results obtained by the model show that the amount of injected cold-water and consequently the amount of heat extraction from the gas field is very sensitive to the permeability of the field and the viscosity of the fluid. Inclusion of heat gain from over- and under-burden in the numerical model causes the thermal front to move slower. Since the feasibility of the project is predominantly dependent on the duration of the saturation of the field, this effect will not improve the feasibility of the project. Because only gas at a low pressure is still present in the reservoir, the field has to be saturated with cold water before production of hot water can be started. This process takes around 30 years. After that, a production rate of 5 m3/hr can be established. The temperature of the production would be 69.7 °C initially and becomes 64 °C after 500 years. When taking into account a pump that uses 100 KW to pump the water out of the formation, an exergy of 200 KW can be established. Because of the large saturation time and the limited exergy compared to other sustainable energy sources it is concluded that this project is not feasible.","geothermal energy; depleted gas fields","en","bachelor thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Applied Earth Sciences","",""
"uuid:e606b0a9-f273-425f-86ac-11840676e03d","http://resolver.tudelft.nl/uuid:e606b0a9-f273-425f-86ac-11840676e03d","Sampling time error calibration in Time-interleaved ADCs","Mehta, N.","Van der Goes, F. (mentor); Bult, K. (mentor); Makinwa, K.A.A. (mentor)","2013","","LMS calibration loop; Timing error detection; Time-interleaving; Observer Effect; Reference lanes; Wideband capture ADC; Digital-to-Analog converter; Track-and-hold; Low-power.","en","master thesis","","","","","","","","2014-08-29","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","MSc Microelectronics","",""
"uuid:8d9a71a3-7b03-43bc-85dc-67c357f18c23","http://resolver.tudelft.nl/uuid:8d9a71a3-7b03-43bc-85dc-67c357f18c23","ICT, Productivity and Economic Growth","Karkukli, O.O.S.","Van Beers, C. (mentor); Storm, S. (mentor); Rook, L. (mentor)","2013","This master thesis is part of the project that Statistics Netherlands (CBS) conducts for the Dutch Ministry of Economic Affairs. The main purpose of this project is to study the influence of ICT on productivity and economic growth. This thesis had three objectives: (1) to define ICT and indicators to measure ICT intensity, (2) to investigate the influence of ICT on productivity growth, and (3) to list the complementary factors of ICT that influence the productivity growth.","ICT; productivity growth; MFP growth","en","master thesis","","","","","","","Campus only","2014-08-29","Technology, Policy and Management","Technology, Strategy & Entrepreneurship","","","",""
"uuid:38e13168-0a82-48da-a598-3b8cb3c027e4","http://resolver.tudelft.nl/uuid:38e13168-0a82-48da-a598-3b8cb3c027e4","Automated Code Review for Fault Injection","Diaconescu, A.I.","Bertels, K. (mentor); Nane, R. (mentor); Breunesse, C.B. (mentor)","2013","The software quality relies, among others, on security. In the smartcards domain assumed throughout this paper, the focus is on security. Smartcards are embedded systems that contain sensitive information. Code review is one of the most efficient evaluation techniques applied to smartcards. It is used for the examination of the smartcard source code in order to find security weak points. Since the code review is expensive, time-consuming and error-prone when done manually, we developed an application that is performing this process automatically. According to our knowledge, this automation of the code review process for smartcards is an innovative approach. In this study, we use our application to identify the smartcard software vulnerabilities in order to further exploit them using fault injection. Fault injection is one of the most common attacks against smartcards. The developed application was evaluated and validated based on a test-suite composed of smartcard programs. The test-suite is composed of 12 smartcard programs that are based on defensive programming patterns against fault injection attacks. We were able to identify 15 vulnerability types in the test-suite. The success rate of the identified vulnerabilities from the test programs varies between 30% and 100%. As a result, we believe that the application will be a significant factor in evaluating the smartcard software.","code review; fault injection; embedded; security; smartcards","en","master thesis","","","","","","","","2013-10-19","Electrical Engineering, Mathematics and Computer Science","Computer Science","","Embedded Systems","",""
"uuid:72bc648d-2e4d-4215-9219-d378266f4427","http://resolver.tudelft.nl/uuid:72bc648d-2e4d-4215-9219-d378266f4427","Resonant Air Quality Sensor","Verloop, W.A.","Creemer, J.F. (mentor)","2013","In this Thesis report the modeling, design, simulation, fabrication and measurements done at the Resonant Air Quality Sensor is described. The sensor is based on a resonant system, made in a silicon wafer with MEMS technology. By depositing the particles to be measured on top of the mass, the total mass of these particles can be measured by measuring the change in resonant frequency of the system. This sensor is made in the DIMES Cleanroom, and the fabrication process used is based on the existing DIMES BICMOS5 process, extended with a by the author designed MEMS module. The mean resonant frequency of the clean device is measured to be 498 kHz, with a quality factor of 1400. The mass sensitivity of the sensor is measured to by 920Hz/ng.","SOI-MEMS; Resonant system; particle sensing","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Electrical Engineering","","Microelectronics","",""
"uuid:916d6801-80f2-4741-bbf2-14704cf6a43b","http://resolver.tudelft.nl/uuid:916d6801-80f2-4741-bbf2-14704cf6a43b","The organization of transmission infrastructure regulation in the Netherlands","Eggen, J.","Correlje, A.F. (mentor); De Vries, L.J. (mentor); Kunneke, R.W. (mentor)","2013","The thesis evaluates present Dutch organization of regulation of transmission infrastructure and suggests several improvements. The analyzing framework is based on transaction cost regulation.","transaction cost regulation","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Economics of Infrastructure","","","",""
"uuid:b5abb48e-963c-4599-b737-b3b7a4a0874f","http://resolver.tudelft.nl/uuid:b5abb48e-963c-4599-b737-b3b7a4a0874f","Designing New Handling and Sorting Equipment","Thissen, J.J.","Prins, J.F. (mentor); Kooijman, A. (mentor); Vos, M. (mentor)","2013","The design of new handling and sorting equipment, together with the corresponding procedure. The equipment is designed for the (soda-) can industry. It has besides ergonomic advantages for the employees also quality improvements.","consistency of quality; ergonomically improvements; separator sheet sortation","en","master thesis","","","","","","","Campus only","2014-08-28","Industrial Design Engineering","Design Engineering","","Master of Science Integrated Product Design","",""
"uuid:49f1246d-6df1-490c-9678-847c7004d74b","http://resolver.tudelft.nl/uuid:49f1246d-6df1-490c-9678-847c7004d74b","Aircraft Separation Assurance Using Implicit Maneuver Coordination: Issues and Potential Solutions","Kastelein, M.R.","Theunissen, E. (mentor)","2013","In earlier research projects, the depiction of airspace in which a loss of separation is predicted to occur has been explored as a means to increase conflict awareness. The computation of the conflict space is based on the current state of traffic and ownship. If the traffic maneuvers, the location and extent of the conflict space will change accordingly. Hence, if the other traffic also maneuvers to avoid the predicted loss of separation it is of fundamental importance that the maneuvers of ownship and traffic are complementary. To ensure that a conflict will indeed be avoided by such a maneuver and not accidentally made worse when both maneuver simultaneously, a form of coordination is necessary between the aircraft involved. Some research has been done in the area of implicit coordination between two aircraft, which provides coordinated resolution maneuvers to conflicting aircraft based on an epsilon criterion when only state information is periodically broadcast by the aircraft. This thesis explores conflict scenarios that need additional rules to be safely resolved using implicit maneuver coordination and provides possible solutions. Furthermore, a system is developed for the application of implicit maneuver coordination in scenarios that involve multiple intruders. This system is summarized in a decision tree that can be used to categorize scenarios according to the location of the closest point of approach of the intruders and the connectedness of the corresponding conflict areas. These factors determine the scenario complexity and the available or preferred conflict resolution options. The system can be used to support pilots in quickly assessing the most optimal maneuver in complex conflict scenarios, plan aircraft routes, or make preventive maneuvers. Maximum airspace density with implicit maneuver coordination is addressed based on the minimum distance to conflict at which a maneuver must be made to prevent loss of separation.","avionics; implicit coordination; separation assurance; conflict probing; multiple intruders; airspace density","en","master thesis","","","","","","","","2013-08-29","Electrical Engineering, Mathematics and Computer Science","Telecommunications","","Electrical Engineering","",""
"uuid:fd4944a9-b82c-4df3-a8ef-c5a9f13f57c4","http://resolver.tudelft.nl/uuid:fd4944a9-b82c-4df3-a8ef-c5a9f13f57c4","Selecting Bug-prone Components to Study the Effectiveness of Reengineering and Unit Testing","De Swart, J.","Zaidman, A.E. (mentor); Van Deursen, A. (mentor); Vengina, W. (mentor)","2013","Many software companies see their code grow into legacy code. Making changes to such code is risky, as existing functionality elsewhere can easily be broken. By reengineering the code and covering it with unit tests, the code can be brought back into a maintainable state. In this study we measure the effect of reengineering and unit testing code on the number of fixed bugs. We do so by comparing the predicted and actual number of bugs for a component, after reengineering and unit testing it. We predict the bug-proneness of components by mining the bug repository, and provide and evaluate an approach for selecting the most feasible components by including the estimated test effort. Initial results indicate that the number of bug fixes decreases after a bug-prone component has been reengineered and covered with unit tests. We conclude that our approach is able to predict the bug-proneness of components, and successfully ranks them by feasibility. But in order to formulate a final answer on the effectiveness, more data is needed.","bug; prediction; reengineering; unit testing; bug-proneness","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Software Technology","","Software Engineering Research Group (SERG)","",""
"uuid:d3360b59-bf0f-479a-adb9-99421df25a32","http://resolver.tudelft.nl/uuid:d3360b59-bf0f-479a-adb9-99421df25a32","A Cash-Flow Analysis and Profitability Study on a Peer-Group of Mining Companies","Wansink, J.B.","Benndorf, J. (mentor); Weijermars, R. (mentor); Buxton, M.W.N. (mentor)","2013","In this study a cash-flow analysis is done in order to establish the cash sources and sinks of a peer group of mining companies in the iron ore sector. The peer-group ranges from junior companies to major mining companies. The study also looked in to the performance and profitability of the peer group using ROCE and share prices as indicators. The role of credit ratings in both the cash-flows and profitability is discussed too. The results are compared to results from similar studies done on the oil and gas industry.","mining; credit rating; cash-flow; ROCE; profitability; market capitalization; iron ore; corporate strategy","en","bachelor thesis","","","","","","","","2013-08-30","Civil Engineering and Geosciences","Geoscience & Engineering","","Resource Engineering","",""
"uuid:45b4dd8d-bd83-4edb-87bd-511a92fb9dc4","http://resolver.tudelft.nl/uuid:45b4dd8d-bd83-4edb-87bd-511a92fb9dc4","Declaratively Defining Domain-Specific Language Debuggers","Lindeman, R.T.","Visser, E. (mentor); Kats, L.C.L. (mentor)","2013","Tool support is vital to the effectiveness of domain-specific languages. With language workbenches, domain-specific languages and their tool support can be generated from a combined, high-level specification. This thesis shows how such a specification can be extended to describe a debugger for a language. To realize this, we introduce a meta-language for coordinating the debugger that abstracts over the complexity of writing a debugger by hand. We describe the implementation of a language-parametric infrastructure for debuggers that can be instantiated based on this specification. The approach is implemented in the Spoofax language workbench and validated through realistic case studies with the Stratego transformation language and the WebDSL web programming language.","spoofax; debugger; domain specific languages; language-independent debugger implementation framework; instrumentation","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Software Technology","","Software Engineering Research Group","",""
"uuid:e0259a52-bd9a-4de5-939c-774792a4b808","http://resolver.tudelft.nl/uuid:e0259a52-bd9a-4de5-939c-774792a4b808","Strategic Solutions for Household Water Containers in Disaster Relief Situations","Olubunmi, M.A.","Smulders, F. (mentor); Diehl, J.C. (mentor)","2013","This report is the result of a six-month project executed for ‘Practica Foundation’, a partner company in the ‘S(P)EEDKITS project’. S(P)EEDKITS is an European union initiative with the goal of (re)designing emergency response kits. The existing foldable household water containers used in humanitarian relief had several bottlenecks. The goal of the assignment was to identified the bottlenecks and propose alternative product idea(s) and strategy for an household water container suitable for use in emergency relief. The various stakeholders were analysed, disaster analysis explored the context of use for the household water containers, product analysis explored bottlenecks in existing water containers and the requirements for a suitable household water container. The result of the stakeholder analysis showed that there were similar and sometimes conflicting requirements from different stakeholders. The result of the disaster analysis showed the need to develop a product that can withstand rough transportation condition. The product analysis highlighted benchmarks such as the need to have a 10 and 20-litre water container, the importance of preserving water quality, the need to make the water container foldable and the need for a opening small enough to prevent contamination by external material, while also large enough to avoid wastage of water at the tap. The gaps identified in these analyses made up the expert interview. Six humanitarian relief experts were interviewed. The result of the interview includes the need for the container to be stable on the ground in order to avoid water contamination when the container falls over, the need for the container to withstand harsh transportation and handling conditions and also the need to have handles strong that are enough to withstand frequent lifting of the container when filled with water. A summary of the requirements identified in the stakeholder analysis, disaster analysis, product analysis and expert interview were the starting point for the design and strategy proposed. An idea generation session consisted of participants from stakeholder companies and designers from Delft University of Technology. Seven concepts were generated during the session, and a final concept was selected based on earlier identified requirements. Furthermore, the strategy presented mapped out the extra benefit of the water container beyond the phase of emergency relief. A flexible pipe was proposed as an add-on to be used by disaster victims for the household purification of water. In conclusion, durability was identified as a major bottleneck of existing foldable water container. Therefore, the proposed concept was designed to have a rigid bottom and a flexible top. The flexible top will be stored in the rigid base during transportation by relief organizations.","water; disaster relief; household water container","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Strategic Product Design","",""
"uuid:20f7400f-65f9-4660-8299-ef6301830c73","http://resolver.tudelft.nl/uuid:20f7400f-65f9-4660-8299-ef6301830c73","How can KDVS, a highly specialized SME, become more entrepreneurial? A case study exploring corporate entrepreneurship at KDVS, a SME in the luxury yachting industry","Haselhoff, D.T.","Scholten, V.E. (mentor)","2013","In depth analysis of an organization that was in need for a more entrepreneurial corporate strategy.","corporate entrepreneurship; yachting industry; entrepreneurial strategy","en","master thesis","","","","","","","","2018-08-28","Technology, Policy and Management","Management","","Technology, strategy and entrepreneurship","",""
"uuid:1d235433-6f66-42a6-87b1-ef2843f0db38","http://resolver.tudelft.nl/uuid:1d235433-6f66-42a6-87b1-ef2843f0db38","Libswift-PPSPP Information Centric Router: SHA1 Accelerator","Verdugo Sanchez, G.E.","Bertels, K. (mentor); Pouwelse, J. (mentor)","2013","Peer to peer content streaming is the next generation content delivery method, making obsolete the client-server communication model which is not sustainable in the current Internet environment. One effort to standardize this new protocol is represented by the Libswift-PPSPP (Peer to Peer Streaming Peer Protocol) Information Centric Network (ICN). In this thesis we lay the foundation for developing a Libswift ICN router using FPGA technology. We start by describing the protocol, provide a set of requirements for the generic router and identify a subset that we will implement. Using the NetFPGA development platform, we build a hash (SHA1) computation accelerator, which is one of the fundamental building blocks for the Libswift ICN router. Our measurements show that the prototype outperforms a general purpose CPU in hash calculation. The measured speedup is of 1.54 and the area overhead is small considering the complete system. Possible optimizations are discussed and the impact of those optimizations is compared with our working implementation. We conclude with a brief description of further work needed to obtain a complete Libswift-PPSPP ICN Router.","PPSP; Content-Centric Networking; Libswift; Information Centric Router","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","","",""
"uuid:bcba7e5b-e898-4e59-b636-234ad3fdc432","http://resolver.tudelft.nl/uuid:bcba7e5b-e898-4e59-b636-234ad3fdc432","Code Smells in the Mobile Applications Domain","Verloop, D.","Geers, H.J. (mentor)","2013","The mobile applications market is growing rapidly, over 85 billion mobile applications have been downloaded. Smartphone sales are already bigger than computer sales and this might become the first year in which over one billion smart phones will be sold. Regardless of these statistics there is not a lot of research to be found on the subject. In this thesis one of the observations done in a recent study on mobile applications is reproduced. We also look for code smells (patterns in source code that are associated with bad design and bad programming practices) in a number of commercial and open source applications. The results of this analysis is used to determine if certain code smells have a higher likelihood to appear in mobile application source code.","android; code smells","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Software and Computer Technology","","Software Engineering","",""
"uuid:cee403d1-2999-4224-b71c-6dc3116dc1e1","http://resolver.tudelft.nl/uuid:cee403d1-2999-4224-b71c-6dc3116dc1e1","3D Audio for Virtual Reality Exposure Therapy","Hoekstra, A.R.D.","Brinkman, W.P. (mentor); Heynderickx, I. (mentor); Egmond, R. (mentor)","2013","Virtual Reality Exposure Therapy (VRET) is an effective method to treat anxiety disorders and comes with many advantages over exposure in vivo, the latter being exposure in real-life. VRET is done by exposing patients gradually with their fear by using immersive virtual environments (VEs). Most attention in VRET research goes to visuals and less to audio, haptics, smell and taste. This report focuses on the use of audio, and in particular on 3D audio, in VRET systems. 3D audio is the only audio technique that is able to reproduce sounds as they are heard in real-life. Unlike other audio techniques, 3D audio uses a model of the human hearing in order to replicate accurate horizontal (azimuth), vertical (elevation) and distance information cues. Audio, especially combined with other modalities like vision, provides added value in terms of immersion. Audio is also indicated to have a significant effect on presence and presence is assumed to be a key factor in VRET performance. This report discusses if 3D audio can create more presence, anxiety and spatial perception compared to other commercially available audio techniques. This was done by doing three experiments, using stimuli of a flying wasp in order to generate a global sense of anxiety and/or discomfort. All audio was represented using headphones. Results indicate that people are able to hear differences in a direct comparison between 3D audio and mono, stereo and dolby headphones for the given wasp stimuli. People also report more presence and anxiety for 3D audio without the addition of visual information, but they don't focus on these differences anymore as soon as visual information is added to the audio. This is probably because the audio is overruled by the visuals when combining the information. Vision is known to be the dominant sense, and when combining audio with visuals, visuals ""take over"". As a consequence, different audio techniques may result in a similar experience. Suggestions are done for future research and it is currently advised to use stereo audio in a VRET system until future research shows otherwise. It is also stated that it may be more effective to increase the number of matching modalities instead of optimizing only one in particular.","3D audio; binaural; virtual reality exposure therapy; vret; exposure therapy; audio; stereo; dolby surround; dolby headphones; mono; headphones; vr; virtual reality; anxiety; fear; gradual exposure; sound; virtual environments; presence; immersion; spatial perception; sud score; sud; heart rate; galvanic skin response","en","master thesis","","","","","","","","2013-08-22","Electrical Engineering, Mathematics and Computer Science","Interactive Intelligence","","Media & Knowledge Engineering","",""
"uuid:d2ebe038-fc1e-47b4-a708-e043e9d3ca74","http://resolver.tudelft.nl/uuid:d2ebe038-fc1e-47b4-a708-e043e9d3ca74","Separate Compilation as a Separate Concern: A Framework for Language-Independent Selective Recompilation","Bruning, N.","Visser, E. (mentor); Groenewegen, D. (mentor)","2013","Aspect-oriented programming allows developers to modularize cross-cutting concerns in software source code. Concerns are implemented as aspects, which can be re-used across projects. During compilation or at run-time, the cross-cutting aspects are ""woven"" into the base program code. After weaving, the aspect code is scattered across and tangled with base code and code from other aspects. Many aspects may affect the code generated by a single source module. It is difficult to predict which dependencies exist between base code modules and aspect modules. This language-specific information is, however, crucial for the development of a compiler that supports selective recompilation or incremental compilation. We propose a reusable, language-independent framework that aspect-oriented language developers can use to automatically detect and track dependencies, transparently enabling selective recompilation. Our implementation is based on Stratego/XT, a framework for developing transformation systems. By using simple and concise rewrite rules, it is very suitable for developing domain-specific languages.","separate compilation; aspect-oriented programming; compiler design","en","master thesis","","","","","","","","2013-08-28","Electrical Engineering, Mathematics and Computer Science","Software and Computer Technology","","Software Engineering","",""
"uuid:dfb5ab81-86fd-4e06-8534-4e61043c24dd","http://resolver.tudelft.nl/uuid:dfb5ab81-86fd-4e06-8534-4e61043c24dd","Business ecosystems governance: A framework for tackling complex systems","Pagkozidis, A.","Den Hartigh, E. (mentor); Appelman, J. (mentor); Van Beers, C. (mentor); Van Baars, D. (mentor)","2013","This document is the final Master Thesis Dissertation of Alexios Pagkozidis during academic year 2011-2013. It describes the findings of the research related to Business Ecosystem Innovation Governance for Smart Living platforms. The research was done with collaboration of Delft University of Technology and TP Vision B.V.. This work is part of bigger research project: End-User requirements analysis for Virtual Factories and Enterprises in Manufacturing Service Ecosystems which will be developed in collaboration of European Union with four manufacturing companies: TP Vision, Indesit, Bivolino and Ibarmia. This work has examined requirements and means in order to create a governance framework for business ecosystems for TP Vision ecosystem. The results lead to four stage framework that is governing both low and high levels of business ecosystems.","business ecosystems; servitization; platforms; governance; services; framework; complex adaptive systems; business ecosystems health; co-opetition; innovation systems","en","master thesis","","","","","","","Campus only","2014-08-28","Technology, Policy and Management","Technology Strategy and Entrepreneurship","","Management of Technology","",""
"uuid:867c3ff1-80f7-4289-95b0-401d39d36423","http://resolver.tudelft.nl/uuid:867c3ff1-80f7-4289-95b0-401d39d36423","The Micro Greenhouse: The development of a fully automated, modular and scalable urban greenhouse","Kornet, M.A.","Reinders, A.H.M.E. (mentor); Schoormans, J.P.L. (mentor); Ray, N.P. (mentor); Budding, J. (mentor)","2013","The Micro Greenhouse Project consists of the development of a fully automated, modular and scalable urban greenhouse which focuses on the growth of different types of crops at home, at schools or universities and in restaurants or canteens. Different developments of the horticulture industry including urban farming, vertical farming, LED lighting, measurements at different layers and the new way of harvesting are used to develop the micro greenhouse concept. The controlled climate variables of the micro greenhouse includes energy, light, water, nutrients, EC value, relative humidity, temperature, ventilation and the support of the crops during growth. The different crops are divided in the categories summer vegetables, fruits, winter vegetables and herbs which all have their own optimal climate. Soil substrates based on peat and coconut are used as subsoil and Pokon, a commercially sold nutrient mix, is used as nutrients for the crops. The micro greenhouse concept consist of a fertigation system, an air circulation system and a lighting system which are all combined by means of a modular and scalable construction. The fertigation system takes care of the irrigation of the crops by means of water and nutrients, the air circulation system controls the climate of the crop growing area and the lighting system delivers the exact light recipe for the specific crops by means of LED lighting. Both the fertigation system, the air circulation system and the lighting system are tested in order to combine it with the construction and develop the final micro greenhouse prototype which is the focus of the project.","greenhouse; crops","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Master of Science Integrated Product Design","",""
"uuid:a1689901-8ebe-4d2a-bab9-9e9569e3d83c","http://resolver.tudelft.nl/uuid:a1689901-8ebe-4d2a-bab9-9e9569e3d83c","Implementation of Bio-Informatics Applications on Various GPU Platforms","Amir, A.","Bertels, K. (mentor); Al-Ars, Z. (mentor)","2013","As of 2012, the world creates 2.5 quintillion bytes of data every day. Much of this data generated is what we refer to as Big Data. To explore how Big Data can create potential value and show the technical challenges accompanied with Big Data applications, we choose an application from bio-informatics: the Smith Waterman genetic database alignment algorithm, which is used for finding optimal genetic sequence alignments. The continuous increase in the volume of data in genetic databases leads to the exponential increase in the time required for comparing these genetic sequences. This thesis investigates the acceleration and optimization of the Smith Waterman algorithm using GPU platforms. The thesis uses DOPA, an existing implementation, which was optimized for the GTX275 GPU platform from NVIDIA. DOPA resulted in a huge performance gain compared to other implementations running sequentially on CPU. Our thesis aims to study and improve the behavior of this implementation on different NVIDIA GPUs: the Tesla C2075 and the GeForce GT640. We improved the cores occupancy of DOPA on different GPU cards resulting in an efficient workload distribution, thereby improving the performance by about 17% to 61%. We achieved 25 GCUPS performance on the C2075 and 11 GCUPS on the GT640 compared to a straight forward DOPA port on the same cards achieving 21.9 and 6.8 GCUPS, respectievly. To achieve considerable performance for Big Data application for different platforms, two important factors have to be taken into account: increase the parallelism in the software and increase the utilization on the hardware side. We evaluated and presented other metrics such as the cost in terms of euro and watt to be considered along with GPU performance.","big data; bio-informatics; GPU; performance analysis","en","master thesis","","","","","","","","2013-08-28","Electrical Engineering, Mathematics and Computer Science","Computer Engineering","","","",""
"uuid:98b8ecc6-42cb-4659-b988-9e4410c7918d","http://resolver.tudelft.nl/uuid:98b8ecc6-42cb-4659-b988-9e4410c7918d","Design of Olla-on-the-Move: Toilet for Chemotherapy Bodily Waste Containment","Chang, S.F.S.","Koster, R.P. (mentor); Ruiter, I.A. (mentor)","2013","The topic of this graduation project is the design of “Olla-on-the-Move”, the name given to a toilet on the move, for cancer patients undergoing chemotherapy. Working together with the host company, Pharmafilter B.V., the starting point was to design a product or product-service system to “[p]rovide a hygienic and dignified program of care for removing hazardous chemotherapy bodily fluid waste, that being urine and faeces, from the home, to be treated by the Pharmafilter purification process.” The research involved nurses, doctors, patients and family members to gain in depth under- standing of the design context. The analysis yielded four main insights, which were used to further define the design direction. The rede- fined direction was to design “A mobile toilet tailored to the changing needs of patients, providing dignified care in usage and service, that allows the collection of chemotherapy waste into packages for collection and transport.” Three concept directions were made, and the final decision was made based on inputs from nurses and doctors. The final design was a toilet that allows the patient and family members to share the same lavatory. This allows the patient to follow their normal toilet routine in the lavatory room, providing a feeling of “dignified care”. The product is designed to also be convertible to become stand-alone unit to allow for use outside of the lavatory in situations that demand it. A prototype was built to test the placement, ergonomics and usability. Twelve participants tested the prototype in five different lavatory environments. The criteria for comfort, perceived safety and usability were rated from 1 to 10, with 10 being the highest. The average ratings for comfort, perceived safety and usability were 7.7, 7.7 and 7.6, respectively. The findings from the evaluation were translated into recommendations for the future development of the project.","toilet; medical","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Integrated Product Design","",""
"uuid:1e757ad2-b991-43d6-add3-e2d13af7e9f8","http://resolver.tudelft.nl/uuid:1e757ad2-b991-43d6-add3-e2d13af7e9f8","Progressive Texture Streaming","Van Muijden, J.","Jansen, F.W. (mentor)","2013","Since its conception, the increasing need for graphical detail has been a driving factor for the gaming industry. The 3D scenes rendered in modern games have increased in detail and scale at a rapid rate, and will continue to do so for the foreseeable future. The ever-increasing processing power and the development of faster 3D rendering hardware has enabled game developers to present the player with large, densely populated 3D virtual worlds containing thousands of high resolution textures and models. In order to render these virtual worlds on current gaming hardware, texture streaming is quickly becoming a necessity: the current gaming consoles cannot contain all texture data of a game world within their graphical memory. The proposed texture streaming solution addresses this problem by managing the texture data between the optical media and graphical memory at run-time. This thesis details a progressive, mipmap aware texture streaming scheme, designed around the optical media used by the current generation of gaming consoles. In the proposed solution, bandwidth usage is reduced by progressively streaming textures through a DCT (Discrete Cosine Transform)-based compression scheme. Seek time of the optical media is reduced by employing a spacial packing scheme which aims to minimize the amount of separate read operations. Using these tools, textures can be accessed and streamed in various levels of detail, providing an efficient use of memory while keeping bandwidth usage and seek times at a minimum.","texture streaming; mipmap","en","master thesis","","","","","","","","2013-08-28","Electrical Engineering, Mathematics and Computer Science","Computer Graphics and CAD/CAM","","","",""
"uuid:a15fe055-7389-4c05-8c8f-90bbca70d39a","http://resolver.tudelft.nl/uuid:a15fe055-7389-4c05-8c8f-90bbca70d39a","Relationship governance in mobile ecosystems: The case of mobile application developers","Hakvoort, R.A.","Den Hartigh, E. (mentor); De Reuver, M. (mentor); Van Beers, C.P. (mentor)","2013","","relationship governance; business ecosystem; transaction cost economics; mobile ecosystems; application developers","en","master thesis","","","","","","","","","Technology, Policy and Management","Technology, Strategy, and Entrepreneurship","","","",""
"uuid:f1c0bd70-e67c-48fa-ac1c-532b3ce0ec73","http://resolver.tudelft.nl/uuid:f1c0bd70-e67c-48fa-ac1c-532b3ce0ec73","Fatigue Analysis and Loading Scenarios of Steel Chain Links used for Subsea Rock Installation","De Wildt, W.N.","Metrikine, A. (mentor); Hendriks, M.A.N. (mentor); Romeijn, A. (mentor); Hoving, J.S. (mentor); Voormolen, J.R. (mentor)","2013","This study analyses the fatigue failure and the loading scenarios of steel chain links used for suspending a Flexible Fall Pipe during Subsea Rock Installation. For that purpose, OrcaFlex is used to evaluate and quantify the global loading conditions in the chain links during the Subsea Rock Installation process. In Ansys, a Finite Element Model is created which investigates the chain links on a local scale when subjected to the loading conditions from OrcaFlex. Further, through an analytical design process and fatigue testing experiments, fatigue curves are constructed under various conditions. As a result, a method has been established for predicting the fatigue damage factor over the length of the Flexible Fall Pipe chains for various conditions, inter alia water depth, wave height and rock installation rate. Fatigue was found mainly in the upper part of the Flexible Fall Pipe chains. The level of fatigue increases rapidly and further down the Flexible Fall Pipe with increasing working depth and wave height. Additionally, it was found that chain link rotations can increase the peak stresses and the effect is larger with a higher friction factor. For further study, it is recommended to verify the OrcaFlex model by means of tests in a towing tank and the established fatigue curves by means of further fatigue testing experiments.","fatigue; chain; links; subsea; fallpipe","en","master thesis","","","","","","","","2018-08-01","Mechanical, Maritime and Materials Engineering","Offshore Engineering","","Offshore and Dredging Engineering","",""
"uuid:6b981b70-ae6b-4eb4-a183-93695117cc18","http://resolver.tudelft.nl/uuid:6b981b70-ae6b-4eb4-a183-93695117cc18","Fast iterative methods for solving the incompressible Navier-Stokes equations","Echeverria Serur, C.","Vuik, C. (mentor); Heemink, A. (mentor); Van Gijzen, M.B. (mentor); Van Horssen, W.T. (mentor)","2013","This thesis approaches the solution of the linearized finite element discretization of the Navier-Stokes operator matrix via the use of Krylov subspace methods preconditioned by SIMPLE-type pre conditioners aided by deflation. It includes an explanation of the theoretical setting of the problem as well as a collection of numerical experiments which lead to the construction of a two-level preconditioned GMRES algorithm.","numerical linear algebra; preconditioners; deflation; finite elements; Navier-Stokes","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied Mathematics","","COSSE/Numerical Analysis","",""
"uuid:bf0a67e1-c74a-4291-917f-c686f7501a9b","http://resolver.tudelft.nl/uuid:bf0a67e1-c74a-4291-917f-c686f7501a9b","A new touch in Braille display design: The design of a next generation Braille display","Jagtman, S.","Moes, C.C.M. (mentor); Dekker, M.C. (mentor)","2013","A Braille display is an alternative interface that is used to make computers, tablets and phones accessible for the blind. This interface enables those that can read and write in Braille to navigate through and access digital information which is usually viewed on a screen. More advanced Braille displays are also equipped with input keys, so that the Braille display can be used as alternative keyboard as well. The company Optelec is world leader of technology products for blind and visually impaired people. In 2006 Optelec launched the Alva BC6 Braille displays. When launched, the Alva BC6 Braille display was a major innovation in the Braille display market. The compactness and the non-stigmatizing design have been the unique selling points of the Alva BC6 Braille display since its market introduction in 2006. But now the competition closed the gap and is able to produce cheaper, more compact displays. Thereby, eliminating the most important unique selling points of Optelec’s current Braille display. In order to stay ahead of the competition Optelec wants to develop a new innovative Braille display. The aim of this project was to design this next generation Braille display. The project was divided in three stages. In the product definition stage a design direction for the to be developed Braille display was defined on the basis of an an analysis of the state of the art of Braille displays and an exploration of the possibilities of a new generation Braille displays. In the design integration stage different concept directions were evaluated and the chosen concept direction was further detailed into the final design. In the last stage, the design evaluation, prototypes were built to evaluate the proposed design and recommendations for further development of the design were made. It was found that Braille display users can be roughly divided in a group of ""simplicity"" users and a group of ""multifunctionality"" users. Since the users of both groups often have conflicting needs and wishes it is difficult to make one product that is suitable for both groups of users. Currently Optelec is primarily reaching the “simplicity users”. It is however expected that the group of simplicity users will decrease in the future while the group of multifunctionality users increases. Due to the price driven, small size nature of the Braille market Optelec should avoid investing in the development of multiple different products for this market. At the same time their product should serve two types of users with conflicting needs and wishes. Therefore, the designed Braille display consist of two product configurations: a basic configuration that is aimed at the “simplicity users” and an advanced configuration that is aimed at the “multifunctionality users”. These configurations are designed in such a way that no additional investments have to be made to produce two product configurations instead of one. Other distinguishing features of the developed Braille display are the touchpad Braille keyboard and the foldable design which increased the portability of the device. This touchpad Braille keyboard replaces the Braille input keys that are currently used on Braille displays. Instead of these keys the touchpad uses virtual keys that are able to follow the fingers. Based on a research on Braille typing inconsistency, smart software was devised to realize this touchpad Braille keyboard. A working prototype of the touchpad Braille keyboard was developed to test the functioning of this software. In its current state the developed software works not good enough yet to be an equivalent replacement of the regular Braille keyboard. Users were however, enthusiastic about the touchpad keyboard as it is more robust and quiet than the regular Braille keyboard and every hand can be ergonomically positioned on this keyboard. Therefore, it is expected that when the recommendations for further development for this touchpad are realized, the touchpad Braille keyboard will become a worthy competitor of the regular Braille keyboard.","Braille; Braille display; visually impaired; touchpad; blind","en","master thesis","","","","","","","Campus only","2014-08-28","Industrial Design Engineering","CADE","","IPD","",""
"uuid:ce266e05-cf6a-4661-bde4-e50860ea0db5","http://resolver.tudelft.nl/uuid:ce266e05-cf6a-4661-bde4-e50860ea0db5","Increased Energy Yield using the Smart Rotor: Sizing and Control of Trailing Edge Flaps on a Smart Rotor for Maximum Power Generation in Low Fatigue Wind Regimes","Smit, J.","van Bussel, G.J.W. (mentor); van Kuik, G.A.M. (mentor); van Wingerden, J.W. (mentor); Bernhammer, L. (mentor)","2013","","Windenergy; wind turbine; smart rotor; performance optimization; trailing edge flap; smart rotor control; fatigue","en","master thesis","","","","","","","","","Aerospace Engineering","Wind Energy","","","",""
"uuid:431bf409-a321-4724-99d0-fc0679145f46","http://resolver.tudelft.nl/uuid:431bf409-a321-4724-99d0-fc0679145f46","Online Banking Fraud Mitigation: A Quantitative Study for Extracting Intelligence about Target Selection by Cybercriminals from Zeus Financial Malware Files","Tajalizadehkhoob, S.","Van Eeten, M.J.G. (mentor)","2013","","malware; target selection; Zeus; online banking fraud; intelligence; cyber criminal; cyber security","en","master thesis","","","","","","","","2013-08-28","Technology, Policy and Management","POLG","","Engineering and Policy Analysis, ICT Management","",""
"uuid:faf79020-4c07-4931-9bf6-dcdbe491bca8","http://resolver.tudelft.nl/uuid:faf79020-4c07-4931-9bf6-dcdbe491bca8","Modelling of Peat Compressed under Sand Bodies: Experimental and Numerical Approach","Papadaki, E.","Ngan-Tillard, D.J.M. (mentor); Zwanenburg, C. (mentor); Bakker, K.J. (mentor); Van Meerten, H. (mentor); Jommi, C. (mentor)","2013","This study being part of the Weesp Bloemendalerpolder Project, is concentrated on the compression of a peat layer under the weight of a trial sand embankment; examined under two scopes, the laboratory K0-CRS test and the field settlements. Their interconnection is also evaluated. Peat being an organic material with many distinctive characteristics such as time dependency due to the visco-plastic nature, a high water content, fibrosity, etc, required a broad literature study concentrated on its nature, dominant properties and the numerical models that can sufficiently capture such behaviour. Classification laboratory tests (pycnometer and loss on ignition) together with correlations found in the literature that are commonly used in the engineering practice highlight the interdependency of some characteristics in the overall response of the peat, and aided in increasing the trust in the available dataset. Two series of K0-CRS tests were conducted, prior and post the embankment construction, providing an insight into the changes of the material properties due to compression. The laboratory tests are then simulated with the Soft Soil Creep (SCC) model with PLAXIS software with two approaches; using the soil Test Facilities and the Finite Element mesh analysis. Their ability to model the large deformations together with aspects such as samples saturation, parameter transformation and the deviation between the laboratory and fitted values are discussed; with the objective of creating a dataset capable of describing the material in situ. Shifting the focus to the field situation, the settlements are calculated with the SSC model and compared to the monitoring data. The fit illustrates the value and utility of the laboratory test calibration. Alternative settlement calculations are conducted using the abc Isotache model implemented in D-Settlement software, where the settlements produced are fitted to the monitoring data, and the deviation of the parameters is evaluated in comparison to both the former settlement prediction and the laboratory derived values. The water content and permeability are found to play vital role on the layer compressibility. The local character and heterogeneity of the properties are highlighted. Finally the inadequate strength parameter determination by the compression tests is emphasized and the influence on the laboratory tests and the horizontal displacement of the compressed material in the field is illustrated.","peat; settlement; K0-CRS","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Geo-Engineering","",""
"uuid:c94a5b2d-b1fc-4018-92b3-2692e03ed279","http://resolver.tudelft.nl/uuid:c94a5b2d-b1fc-4018-92b3-2692e03ed279","Strategic workforce planning: Steps, requirements and quantitative models in use: An explorative study into Accenture’s clients’s needs","Matienzo Carcases, Y.","Van Daalen, C. (mentor); Verburg, R.M. (mentor)","2013","Article: Quantitative modeling approaches to support strategic workforce planning Workforce planning is an activity performed by organizations to ensure that investments in human capital lead to effective achievement of organizational goals. At a strategic level, it tries to proactively design strategies to reduce gaps between demand and supply of the workforce for which modeling capability is key. However, studies suggest that many companies do not have gap reducing strategies in place, mainly because of the lack models. In this paper, a literature review is performed to identify whether there are modeling approaches capable to support workforce planning at its strategic level. The results suggest that the lack of models is not the real problem. Different modeling approaches have been offered by the scientific community to support strategic workforce planning. Models based on trend extrapolation, econometrics, markov chain and simulation are some examples. Further research is therefore needed to understand why companies are not applying them.","strategic workforce planning; Markov chain models; system dynamics; object oriented simulation; linear optimization","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Policy Analysis","","SEPAM","",""
"uuid:7cd6c046-956b-47bf-bd21-d631a1677e98","http://resolver.tudelft.nl/uuid:7cd6c046-956b-47bf-bd21-d631a1677e98","U-Sem, a platform for augmented user modelling","Todorov, B.","Hidders, J. (mentor)","2013","With the increasing popularity of social media, more and more user data is published on the web everyday. As a result, there is a high demand for engineers to devise different algorithms for user modelling based on that data. The U-Sem framework defines an approach for constructing such algorithms and providing them to the customers in the form of user modelling services. The process of building these services, however, requires engineers to perform a lot of manual tasks, many of which are not connected to the core of the engineers’ specialization. These tasks are considered as significant overhead and are reported to cause poor performance of engineers. Therefore, in order to solve that problem, in this thesis we present the design and implementation of the U-Sem platform. It extends the U-Sem idea for building user modelling services by providing a platform that facilitates the work of the engineers. Based on the analysis of the current process for building U-Sem services we solve the two problems which solutions were indicated to be the most beneficial for the engineers. The first one is to enable engineers to add and remove the functional components that build up the services to/from the platform on demand without affecting the work of others using it. While the second problem is to enable engineers to create and process the persistent data required for the services transparently without being aware of where and how it is actually stored.","user modelling; U-Sem; plug-in environment; data management","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Software and Computer Technology","","Computer Science","",""
"uuid:4d6bd8fd-e487-439c-9051-f201a068272c","http://resolver.tudelft.nl/uuid:4d6bd8fd-e487-439c-9051-f201a068272c","Creating a Framework for Effective Innovation Project Portfolio Management","Boon, M.J.G.N.","Van Beers, C.P. (mentor); Den Hartigh, E. (mentor); Van der Voort, H. (mentor)","2013","Most firms have more ideas for innovation projects than the R&D budget can support. On top of that, the industry of firm-X (at which the research took place) is characterized with long development cycles and expensive full scale testing. Therefore, it takes these firms a long time to actually see effects in form of the returns on their investments. Selecting the right innovation projects becomes very important for the long term survival of these firms. Innovation Project Portfolio Management (IPPM) has the potential to bring considerable benefits to structure the Innovation Project Portfolio (IPP) of these organizations, being a mindset where portfolio thinking is central. However many tools used for IPPM are based upon unreliable information or implicit judgment reducing the effectiveness. The design of an integrated and effective IPPM framework and understanding the factors that affect this framework are central in this research. This thesis describes the design of such an IPPM framework for the industry of firm-X, which is based on firm-X. It has been investigated at firm-X how the following aspects affect the IPPM decision making process: long term, top-down/bottom-up innovation approach, technological push & pull, formality of IPPM approach, and inter-organizational innovation activities. These aspects are important because they are affected by the choices made in the IPPM decision making process. Especially the collaboration of inter-organizational innovation activities can increase the value of R&D and also increase the performance of the current IPP. To conduct this research first of all a literature study was undertaken to understand the concepts related to IPPM and investigate contemporary tools for IPPM. Next, the current framework at firm-X is assessed by analyzing internal documents and conducting open interviews. Thirdly semi-structured interviews have been executed in two rounds with respectively 13 and 5 respondents from firm-X to find out how the aspects central in this study affect the IPPM decision making process. Finally, the results of the preceding are used to design an integrated and effective IPPM framework. The results show that top down/bottom-up innovation approach, a long term focus, and technology push & pull can be integrated in the framework. The interviews show in contrast to the theory that not all innovation projects should be aligned with the strategy, in particular innovation projects that are radical and young need to be given space to develop. The reason why this is done, is because it is often difficult to assess whether these innovation projects fit the strategy. The literature study and the research conducted at firm-X leads to a set of requirements for the new framework. The general framework consists of four steps, 1) measuring the current IPP state, 2) indicating the desired IPP state, 3) comparing the two states, 4) use the outcome of step three to adjust the current IPP state to approach the desired IPP state. This framework will help to reduce implicit judgment in the decision making process and will create a more systematic approach to select the right innovation projects. This integrated approach should lead to achieving the three goals of effective IPPM: strategy alignment, value maximization and creating balance IPP. The four steps of the general framework just discussed are transformed into a framework that is applicable at firm-X is based on a strategic bucket approach, technology roadmapping, and expected commercial value (ECV) calculations. Traditionally the strategic bucket approach is used to divide the R&D budget over one set of buckets. In the new framework the strategic bucket approach is operationalized by dividing R&D over multiple sets of buckets. This is done by dividing the R&D budget over four sets characteristics of innovation: 1) Technology Readiness Levels (TRL’s), 2) parts of the value chain, 3) product groups and 4) key technologies. These four characteristics lead to four sets of independent strategic buckets that indicate the current IPP state. The desired state of the R&D budget over the different TRL’s and parts of the value chain were indicated in interviews (with firm-X employees), therefore allowing an easy comparison of the current and the desired IPP state. The desired state of the Product Groups (PG) and Key Technologies (KT) is dependent on both the business environment and strategy. An ECV calculation of all the future products (indicated in the technology roadmap) will indicate the importance of each PG and KT for the future of firm-X, which can be seen as an indication of the desired state for the PG and KT. This approach enables that the four innovation characteristics of the framework can be balanced at the same time. Also, technology roadmaps that show development logic limit the number of IPP combinations. The aforementioned method in turn helps in choosing a specific path for selection of innovation projects that match the four desired states of TRL, parts of the value chain, PG and KT. It is due to these characteristics that the effect of inter-organizational innovation activities can easily be incorporated to see its effect on the current IPP state. Finally during the thesis also the supporting tools have been developed for the framework, meaning that an excel basis has been developed where all the innovation projects can be summarized and then automatically the graphs of the four characteristics for the current and desired IPP state are created. Also a program has been written in the matlab environment that can read the excel file and then produces the technology roadmaps. In this way the new IPPM framework can be supported, increasing the speed and the creation of the evidence based decision making process in IPPM.","Innovation Project Portfolio Management; Inter-organizational Innovation Activities; Effective IPPM","en","master thesis","","","","","","","","2015-09-27","Technology, Policy and Management","Strategy, Technology & Entrepreneurship","","Management of Technology","",""
"uuid:9674582d-80eb-4529-b73b-bc20fcff498b","http://resolver.tudelft.nl/uuid:9674582d-80eb-4529-b73b-bc20fcff498b","Accuracy of Calculation Procedures for Offshore Wind Turbine Support Structures","De Valk, P.C.","Tiso, P. (mentor)","2013","The demand for energy will continue to increase in the coming years and offshore wind energy shows great potential to become a key player in Europe’s renewable energy future. The wind flow offshore is more stable and the average wind velocity is higher than onshore. Moreover, no size restriction exists for offshore wind turbines. However, the levelized cost of electricity for offshore wind energy should be decreased in order to ensure that the transition to offshore wind energy is economically feasible. One way to realize this cost reduction is by optimizing the structural design of the offshore wind turbine. As the support structure is one of the main cost items of the offshore wind turbine, structural optimization of this structure should be investigated. In the current support structure design procedure, the turbine designer (TD) is responsible for the design of the tower, whereas the foundation designer (FD) is responsible for the design of the foundation and the transition piece. These designs are driven by the dynamic loads acting on these structures during the lifetime of the offshore wind turbine. Hence, accurate load predictions are a rerequisite to enable design optimization of the support structure. Therefore the TD runs a large number of aero-elastic simulations with the complete offshore wind turbine model to determine the global loads on the offshore wind turbine. From these simulations, loads or displacements at the tower/foundation interface are extracted and provided to the FD. Subsequently, the FD uses these interface responses in a post-processing analysis in order to obtain loads in the foundation structure. However, inaccuracies can arise at two points in the support structure calculation procedure: * In the aero-elastic model if a reduced or simplified foundation model is integrated in order to keep the aero-elastic model compact and to minimize computation costs. * In the post-processing analysis applied by the FD. To retrieve the response of the foundation model the FD can use either interface loads or displacements, applied either in a dynamic or a quasi-static analysis. By combining different model reduction and post-processing methods, various calculation procedures can be defined. In this thesis the accuracy of these different calculation procedures, that eventually determine the design of the offshore support structure, are analyzed. To this end, both a qualitative and a quantitative study are performed. In the first part of this thesis the different calculation procedures are analyzed from a theoretical perspective. Model reduction methods are explained and the impact of the reduction on the accuracy of the results is investigated. Furthermore, the accuracy of the post-processing methods is investigated and the differences between a quasi-static and a dynamic analysis and between a force and a displacement controlled approach will be outlined. The second part of this thesis concerns a case study in which the various calculation procedures will be applied to a representative offshore wind turbine model on both a monopile and jacket type of foundation. Finally, as fatigue is often the main design driver of the support structure, this case study is used to analyze the impact of an error in the response on the fatigue damage result. This study shows that the use of reduced foundation models in the aero-elastic model can decrease the accuracy of the results, as the reduced model is an approximation of the full model. Therefore, in order to obtain accurate results, the offshore wind turbine model with the reduced components should be spectrally and spatially converged within the frequency range of the external load spectrum. With respect to the post-processing methods, it will be shown that a quasi-static analysis provides accurate results only if the first free or fixed interface eigenfrequency of the foundation structure is higher than the highest excitation frequency in the external load for respectively the force or the displacement controlled approach. Moreover, as the first fixed interface eigenfrequency of a structure is higher than its first free interface eigenfrequency, a quasi-static displacement controlled approach will remain accurate up to higher excitation frequencies than a quasi-static force controlled approach. Furthermore, since both a monopile and a jacket based support structure are modeled, it is found that the accuracy of the different calculation procedures strongly depends on the type of foundation structure. This is reflected by the results from the fatigue calculations; as the monopile behaves in a quasi-static manner within the excitation bandwidth the fatigue damage results are relatively accurate for all calculation procedures. However, the jacket shows much more dynamic behavior and subsequently the fatigue damage results of the quasi-static force controlled approach are highly underestimated. Finally, it is shown that when expanding the response of reduced models, the fatigue damage results can be greatly improved through a quasi-static residual load correction. In conclusion, this work gives an overview of the accuracy of different calculation procedures to determine the design of an offshore wind turbine support structure. As the accuracy depends on several aspects (i.e. characteristics of the structure, use of reduced models, post-processing method and external load spectrum), several requirements are formulated for specific calculation procedures in order to make sure the obtained results are accurate. As a result, one can have more confidence in the optimized design of the support structure and over-dimensioning or the application of additional safety factors is unnecessary. In the end, this will lead to a reduction of costs for the support structure which thereby reduces the levelized cost of electricity for offshore wind energy.","Offshore Wind Turbine; Support Structures","en","master thesis","","","","","","","","2014-01-01","Mechanical, Maritime and Materials Engineering","Precision and Microsystems Engineering","","","",""
"uuid:938e7437-c4d3-4c85-bd20-5bba8bafa2a0","http://resolver.tudelft.nl/uuid:938e7437-c4d3-4c85-bd20-5bba8bafa2a0","Trust Service Broker: A proposal to overcome global distrust in information infrastructures","Karypidis, C.","Daskapan, S. (mentor); Van den Berg, J. (mentor); Rook, L. (mentor)","2013","The globalization of economy has significantly increased the role of online information exchange between transacting parties worldwide. Currently implemented trust models, such as Public Key Infrastructure, provide enough means to enable the secure exchange of data, but only within specified territories, thereby forming different trust domains worldwide. Due to technical, organizational and political hindrances, an efficient universal trust model interconnecting different trust domains cannot be established by relying on one of the current archetypes of trust models. In this paper, we propose an Architecture based on an alternative, hybrid trust model in order to deal with the interoperability issues across different trust domains: the Trust Service Broker Architecture. We demonstrate the effectiveness of the TSB in a scenario related to international supply chain operations. We begin by describing a particular logistics case, more specifically an import trade lane from Malaysia to the Netherlands, as well as the issues associated with the information exchange between relevant stakeholders, which subsequently drive the requirements for the TSB architecture. Building on current knowledge, we then present a detailed overview of the TSB architecture and how it can facilitate safe and reliable information exchange for organizations involved in the logistics case. In order to do so, we also present a high level overview of the internal TSB security risks. Finally, we attempt to validate and generalize the TSB solution from a theoretical perspective, while also discussing the results and the implications for future research.","Online Trust Management; Trust Domains; Interoperability; Online Security; International Supply Chain; Trust Service Broker; TSB Architecture","en","master thesis","","","","","","","","","Technology, Policy and Management","ICT","","Management of Technology","",""
"uuid:de405dfa-74bf-445b-b96e-e06a92a4812c","http://resolver.tudelft.nl/uuid:de405dfa-74bf-445b-b96e-e06a92a4812c","An Exploratory Model to Investigate the Dynamics of the World Energy System: A Biophysical Economics Perspective","Mir Mohammadi Kooshknow, S.A.R.","Herder, P.M. (mentor); Dijkema, G.P.J. (mentor); Correlje, A.F. (mentor); Ghorbani, A. (mentor); Kamp, A. (mentor)","2013","Energy is inherent part of our current life. No one can imagine living without it. It has changed the lifestyle of people and it will continue to do so in future. About 80% of current global total primary energy supply belongs to non-renewable resources. It is also expected that non-renewable resources dominate in total primary energy supply in next decades. The world is moving towards scarcity in non-renewable energy resources. Most studies about the world energy-economy system use standard economic theories. These theories do not include limitations of natural resources and the environment. Biophysical economics theory considers the relation between economy and natural resources. It has been used as the basis of various energy-economy models. However, those models have a global view on this system. They do not sufficiently provide insights into the properties and international trading behaviors of energy suppliers and consumers. So, they do not provide insight on the effects of these interactions on the emergent behavior of the global energy system. Biophysical economics has high potential for providing insights into the world energy system. However, the current biophysical models are not capable of representing the world energy system considering trade and other interactions among regions. Considering this problem the main research question in this thesis is stated as follow: What can be learnt from biophysical economics theory when it is used for the modeling of the world energy system considering energy trade? In order to answer this question, the objective of this research is set to develop a model for exploring the behaviors of the world energy system with multiple interacting regions. The theory of complex adaptive systems (CAS) is used to enable biophysical economics theory to consider trade and other interactions among regions. In order to model and analyze the world energy system from both biophysical economics and CAS perspective, agent-based modeling is identified as the most appropriate paradigm. This thesis provides an analysis of the world energy system from both technical and actor perspectives. The technical analysis aims at describing the main characteristics of and activities in the world energy system. It also identifies the main uncertainties within this system. Actor analysis aims at providing a regional decomposition for the world energy system. To achieve this goal, a number of current regional decompositions are identified. One of those is selected on the basis of a number of criteria. This research uses the 11-region decomposition of (IIASA, 2012b) To develop the objective model, a two-step approach is used. In the first step, the aggregated world energy model is developed without considering energy trade. In the second step, the multi-region world energy model is developed considering energy trade. The aggregated world energy model is the implementation of the most recent biophysical economics model in the literature, GEMBA by (M. A. J. Dale, 2010), in NetLogo. The multi-region model inherits all characteristics of the first model. However, it considers each world region as a world and facilitates the energy trade among them. The models are evaluated by comparison with historical data and literature. The multi-region model shows that the energy trade can be modeled and explored using the biophysical economics perspective. Since it includes energy price as a parameter, it also shows that energy trade can be an interface between biophysical economics and standard economics as well. In addition, exploratory experiments show that size of energy trade for regions is low in comparison to their total production/consumption. Moreover, they show that the size of total energy trade will peak and decline. It is because energy trade mostly belongs to non-renewable energy and the production of non-renewables will peak and decline in the future. In addition, it shows that lower energy trade can increase the share of production of energy.","biophysical economics; agent-based modeling; world energy system; world regions; exploratory modeling","en","master thesis","","","","","","","","","Technology, Policy and Management","Infrastructure Systems & Services","","System Engineering, Policy Analysis and Management","",""
"uuid:71f7e38d-a05b-4e6e-bb84-88fa4d6f31b9","http://resolver.tudelft.nl/uuid:71f7e38d-a05b-4e6e-bb84-88fa4d6f31b9","Hydrodynamics of partially vegetated channels: Stem drag forces and application to an in-stream wetland concept for tropical, urban drainage systems","Buckman, L.J.","Uijttewaal, W.S.J. (mentor)","2013","Introduction: The addition of vegetation to the banks urban drainage channels is an increasingly common measure for improving water quality, enhancing ecological health, and improving aesthetic appeal. An in-stream wetland concept is proposed for channels in Singapore to just that, but faces a major challenge in that high flow rates during storm events will increase the risk of damage to the vegetation. Problem definition: In high-flow situations, flow around the vegetation causes a region of turbulent shear to develop along the interface between the vegetation and main, open-channel flow. This is expected to impact the hydraulic resistance in the channel and the drag forces experience by individual plants, especially those nearest to the interface. For design it is important to understand the effects of this turbulent shear on drag to optimize design to limit upstream flooding risk and assess the risks of damage to plants. Research: The aim of the research was to increase understanding of the effects of lateral, turbulent shear on the channel resistance and forces experienced by individual stems in a uniform patch of vegetation. A patch of uniform vegetation was modelled by an array of rigid cylinders in an experimental flume. Measurements of the flow field and the drag forces on individual cylinders were recorded. Using this data, answers to the following questions were found: 1) What is the effect of lateral turbulent motion on channel resistance? 2) How do drag forces on individual stems vary spatially over the patch and in time, with special attention to local maximums? 3) What is the effect of lateral turbulent motion on fluctuations in the stem drag force? 4) What are the implications for estimation of the mean and maximum stem drag forces? Results: Analysis of the experimental results revealed the following: 1) The presence of a lateral shear layer significantly increased channel resistance, by 175% when compared to similar conditions when the shear layer was not allowed to develop. 2) Drag forces on stems mirrored the velocity distributions in both time and space, showing both higher mean and maximum values near the interface between the stem array and open channel. 3) Similar periodicity in the velocity and force signals gave evidence of coherent, turbulent structures as the primary means of momentum transport across the vegetation interface. This motion causes a sweep-ejection pattern in the flow at the interface with a net flux of momentum towards the vegetation, resulting in a skewed distribution of stem forces towards higher extreme values. Conclusions and recommendations: Lateral turbulent shear is an important factor in both the channel resistance and stem drag forces in a partially vegetated channel. Coherent structures at the vegetation interface were determined to be the main factor in stem force distribution within the region of shear. The mean stem force can be derived directly from the mean velocity given adequate assumptions of the vegetative drag coefficients. A conceptual model was developed to describe the maximum force in the vegetation patch as a function of the mean velocity at the vegetative interface and a fraction of the difference in velocities between the vegetated and open channel sections.","vegetation; hydrodynamics; drag force","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Water Management","","NUS-TUD Double Degree Programme","",""
"uuid:a169edde-713f-458b-b1b3-6297f3d2c901","http://resolver.tudelft.nl/uuid:a169edde-713f-458b-b1b3-6297f3d2c901","Therapeutic Device For Treatment Of Low Back Pain","Vu, T.T.","Goossens, R. (mentor); Hajian, M. (mentor)","2013","This report discusses on the development of a new therapeutic device for treatment of low back pain, which was initiated by Enraf-Nonious B.V - one of a leading company in the field of physiotherapy and rehabilitation. Low back pain is a common source of musculoskeletal complaints and has been known to affects the daily life of many people. The problems at the low back, however, are only the tip of the iceberg, whereby there exist great variations of underlying causes and mechanisms. Due to the complexity of the symptom, treatment of low back pain remains a topic of active debates among the physicians, in which the therapists tend to employ different styles and methods for diagnosing and designing the treatment programme. The current project explores on the potential benefit of passive mobilization in treatment of the low back, as well as on the selective techniques that are commonly used in the course of mobilization. The research findings identified back rotation and flexion/extension as among the simplest and most beneficial movements in passive mobilizations, due to which the techniques were selected to be incorporated in the new designs. As the first experimental step towards a new line of automotive therapeutic devices, this project would not look into the details of design, but rather focus on the augmentation, development and verification of the proposed concept. To support the very purposes, a full scale partially functional prototype has been developed and tested to demonstrate the feasibility of the design. Results from the user test (with the prototype) was subsequently used to adjust and refine the final concept, which earlier had been developed into virtual 3D model. This report describe the journey to realize the final design, from an initial motivation and exploration to idea generation, concept development and end with the construction and testing of the first prototype. The entire project was conducted mainly by one design student as the graduation thesis.","low back pain; mobilization","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","Master of Science Integrated Product Design","",""
"uuid:865eef32-e5fb-49f6-b561-71428cea9b37","http://resolver.tudelft.nl/uuid:865eef32-e5fb-49f6-b561-71428cea9b37","The design of a recliner mechanism","Van Vliet, L.M.D.","Ruiter, I.A. (mentor)","2013","A graduation report illustrating the design process of a mechanical solution for a reclining chair mechanism that facilitates size adjustments.","recliner; chair","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Design Engineering","","","",""
"uuid:de1cf883-7e6e-4d0e-98eb-c8e34e70682f","http://resolver.tudelft.nl/uuid:de1cf883-7e6e-4d0e-98eb-c8e34e70682f","Strategic Decision-Making in Asset Management: An Approach to Study Long-Term Strategic Decisions in Water Cycle Infrastructures","Gonzalez-Moscoso, J.A.","Herder, P.M. (mentor); Van der Lei, T.E. (mentor); Slinger, J.H. (mentor); Kloosterman, R. (mentor)","2013","Climate change, population growth and increasing consumption patterns of water and increasing urbanisation are challenges and future uncertainties that place stress upon urban water infrastructures. These urban challenges, along with the complexities of asset-intensive systems and socio-economic structures, make the development of efficient long-term strategies for the asset management of urban water cycle systems (WCS) problematic. Vitens - the largest drinking water company in the Netherlands - has considered changing their risk based asset management approach from input oriented short term, to an outcome oriented long-term approach in line with the institutional environment, which could lead to the development of efficient long-term strategies that would help cope with the complex characteristics of drinking water systems and uncertainties of the future. However, there are related complexities to effectively study the strategic decision-making process for asset management. This thesis aimed to develop a methodological framework that links the complexities of studying long-term strategic decision-making processes for asset management at water companies. The case study research shows that the strategic decision-making process of asset management can be studied by applying an integrated and systematic methodological framework based using the systems diagram method with a different approach. The approach manages three articulated complexities to study the strategic decision-making process: 1) the contentious concept of the asset management process, as it varies within industries, strategic asset management maturity and institutional arrangements; 2) the complex functions of the assets in Water Cycle Systems, and the norms governing them, that are hard to define and quantify; and 3) the difficulties in characterising the interrelations between the internal and external context that constitute the decision-making process. As a result, knowledge relevant to Vitens’ needs was gained in terms of: 1) the decision-making process to develop long-term strategies and strategic objectives; 2) the alignment within in the levels of the asset management process; and, 3) the integration of society needs, institutional arrangements, the environment and the business functions in the decision-making process.","Asset Management; Water Cycle System; Strategic Decision-Making; Systems Diagram; Socio-technical System; Long-Term Strategies","en","master thesis","","","","","","","","","Technology, Policy and Management","Engineering and Policy Analysis","","Energy and Industry","",""
"uuid:597b318c-a1af-4fde-865f-4422f548336b","http://resolver.tudelft.nl/uuid:597b318c-a1af-4fde-865f-4422f548336b","ORM Optimization through Automatic Prefetching in WebDSL","Gersen, C.M.","Groenewegen, D.M. (mentor); Visser, E. (mentor)","2013","Object-Relational Mapping (ORM) frameworks can be used to fetch entities from a relational database. The entities that are referenced through properties are normally not fetched initially, instead they are fetched automatically by the ORM framework, when they are used by the application. This is called lazy-fetching and can result in many queries, causing overhead. The number of queries can be reduced by prefetching multiple entities at once. There are two types of prefetching techniques, static and dynamic. Static techniques perform optimization during compilation and dynamic techniques collect information during runtime in order to perform prefetching. Multiple static prefetching techniques are implemented into WebDSL that all use the same static code analysis, however, they generate different queries. The static analysis determines the entities that are going to be used and should be prefetched. These static techniques are compared to the dynamic techniques already present inside the Hibernate ORM framework. The evaluation is performed using the OO7 benchmark and complete WebDSL applications. The results of the OO7 benchmark show a response time improvement of up to 69% over lazy-fetching. On complete web applications some of the static techniques implemented in WebDSL improve the performance on average, however, the performance may be improved further, using a more fine-grained method of choosing an optimization technique.","optimization; prefetching; ORM; DSL; database","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Software Technology","","","",""
"uuid:61f7f022-60a4-4935-af13-6b5438d89c04","http://resolver.tudelft.nl/uuid:61f7f022-60a4-4935-af13-6b5438d89c04","A Domain-Specific Language for Internal Site Search","Van Chastelet, E.","Visser, E. (mentor); Groenewegen, D.M. (mentor)","2013","The importance of search facilities on a website grows with the size of the content being served. User expectations for internal site search are greatly influenced by global web search engines, requiring developers of web applications to go beyond basic search functionality. In this thesis, a domain-specific language (DSL) for internal site search is designed and integrated as a sublanguage of WebDSL (the base language). WebDSL is an existing DSL for web development. Through an exploration of the problem and solution space, the facets related to internal site search are explained. Furthermore, an iterative approach applied at the development of the DSL is presented. This approach is based on the use of existing base language constructs as core language. The core languages provide access to implemented search features. Linguistic abstractions are added on top of the core languages, constituting the eventual interface of the language. Evaluation by means of enriching two web applications with search features show that the DSL has substantial coverage of the internal site search domain.","dsl; domain-specific language; information retrieval; search; dsl-engineering","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Software Technology","","Computer Sience","",""
"uuid:b01f7559-e5d2-44f1-8a65-a8776ddf95e7","http://resolver.tudelft.nl/uuid:b01f7559-e5d2-44f1-8a65-a8776ddf95e7","Credit to SMEs? Robust Lending Decisions with Exploratory System Dynamics Modelling and Analysis","K?vári, A.","Thissen, W.A.H. (mentor); Pruyt, E. (mentor); Storm, S. (mentor); Braje, S. (mentor)","2013","This project’s commissioner, the head of ING’s emerging markets credit trading desk developed a loan structure called Revenue Participation Loan to fit the needs of SMEs in emerging markets. He now wants to combine this new product with innovation in his approach to uncertainty. With these types of loans SMEs agree to pay a fixed percentage of their revenues (a ‘cut’) to the lender until an agreed multiple of the principal is reached. The advantage of this structure is that it tolerates the sales fluctuations, but the implication is that it is unknown how long it will take to repay the loan. In the face of this uncertainty the bank needs analytical tools to select the best candidates and make robust lending decisions. No analytics can exactly predict the future. However, a good model-based analysis usually leads to better decisions than flipping a coin. But that too depends on good quality models and on how they are treated. A good addition to the well-established accounting models seems to be System Dynamics (SD) modelling. SD’s dynamic approach allows building and simulating stock-flow models that better represent the non-linear systems of companies. To make sense of the uncertainties in these models the Exploratory Modelling and Analysis (EMA) tools are proposed. The objective of this project is to investigate in what ways SD modelling combined with an exploratory approach could support lending decisions and monitoring of an SME credit portfolio. Traditional business plans aim to create the model that most accurately predicts the future performance of the company. Lending decisions based on such best-guess models are problematic given the deep uncertainties inherent in the mid- to long-term future. Opposed to this ‘consolidative’ approach, an exploratory study aims to systematically analyse a wide range of plausible future scenarios. The aim becomes to better understand the nature and implications of uncertainties and to devise robust measures that perform well over a wide range of possible futures. Such analyses can be supported by existing EMA tools also developed at TU Delft. Two case studies based on existing loans are presented to explore how SD modelling of SMEs could be performed and to illustrate the capabilities offered by the EMA workbench. Although these cases featured two very different companies a relatively similar framing of the problem can be recognized: the availability of cash balance is a critical enabler of these companies’ growth. Based on the SD models and their uncertainties considered the EMA tools can plot the range of scenarios that can occur. The most important indicator from the point of view of the bank is the time it takes to repay the loan. Using plausible uncertainty ranges for each input parameter the possible outcomes range from around 4 years to infinite repayment time. Feature selection algorithms then can be used to understand what are the most influential model parameters determining this outcome. Further analysis can reveal what combinations of uncertainty ranges will likely lead to the most (un)desirable scenarios. Finally, a robust optimization tool is introduced that can determine the optimal loan size and cut taking into account the uncertainty surrounding key exogenous variables. The study performed on the two cases could be performed during the assessment of the companies that are willing to receive a loan. However, this has some implications on the nature of the assessment. It became clear that more information needs to be asked and the nature of questions has to be broadened to what is commonly considered ‘soft information’. Although SME managers might not be used to it, explicit, clear and quantitative expression of causal relationships is at the core of SD modelling. Historical data records and a skilled modeller can make the inquiry manageable. The detailed modelling might be demanding for both the bank and SMEs, but the effort can pay off when more company models are analysed together. A combined analysis is envisioned in which the company models are embedded into the relevant macroeconomic environment, therefore allowing a consistent portfolio-level analysis. A higher level of detail allows for broader detection of weak signals of change and can also lead to more efficient monitoring through shared understanding between bank and company. It is recommended that the steps presented in the case studies are performed for a real company assessment to gain real-time experience with the EMA tools. The insights gained should be used to continually develop and improve the process of application. Despite its added value, the EMA approach and analytic tools probably cannot replace the need for good human judgement. But as a supporting companion for decision-making, they can give a sharper and more colourful picture of the uncertain future.","commercial banking; uncertainty; system dynamics; exploratory modelling & analysis; business modelling","en","master thesis","","","","","","","","","Technology, Policy and Management","Policy Analysis","","","",""
"uuid:d2bfe438-36f4-4fb6-8b51-0480f17449c2","http://resolver.tudelft.nl/uuid:d2bfe438-36f4-4fb6-8b51-0480f17449c2","Interconnect Testing for 3D Stacked Memories","Masadeh, M.","Hamdioui, S. (mentor); Taouil, M. (mentor)","2013","Three-dimensional stacked ICs (3D-SICs) technology based on Through-Silicon Vias (TSVs) provides numerous advantages as com- pared to traditional 2D-ICs. TSVs are holes going vertically through the chip silicon substrate filled with a conducting material. A potential application is a 3D-SIC where one or more memory dies are stacked on a logic die; thereby increasing the memory density, enhancing its throughput, and reducing its latency and power consumption as compared to planar ICs. However, testing the TSV interconnects between the memory and logic die is challenging, as both memory dies and logic dies might come from different manufacturers. Currently, extended versions of two 2D standards might be applicable to test these interconnects. The first (Boundary Scan Based) method extends JTAG in which Boundary Scan Cells (BSCs) are placed on both TSVs ends providing full TSV controllability and observability to the TSVs. The second (Logic Based) method that can be applied is an extended form of the IEEE 1581 standard. In this standard, interconnects are tested by bypassing the memory. In the test mode, memory outputs are a direct logic function of the inputs. Both methods, however, result in extra area overhead, inflexible, and fail to address dynamic and time-critical faults (at speed testing). In addition, memory vendors have been reluctant to put JTAG or additional DfT structures on their memory devices. In our Memory Based Interconnect Testing (MBIT) approach, we perform a post-bond memory based test where we test the interconnects by converting the developed test patterns to memory read and write operations. This method results in (1) zero area overhead, (2) the ability to detect both static fault and dynamic faults, (3) at speed testing, and (4) flexibility in applying the test patterns, as this can be executed by the CPU on the logic die.","3D-SICs; memory-on-logic; dynamic faults; interconnect testing","en","master thesis","","","","","","","","2014-08-27","Electrical Engineering, Mathematics and Computer Science","Computer Endineering","","","",""
"uuid:1327ad1b-4638-407b-a801-4baac7b23f27","http://resolver.tudelft.nl/uuid:1327ad1b-4638-407b-a801-4baac7b23f27","Kinetics of self-healing reaction in TBC with MoSi2 based sacrificial particles","Mao, W.","Sloof, W.G. (mentor)","2013","","self-healing; kinetics; thermal barrier coating","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Materials Science & Engineering","","Materials Science & Engineering","",""
"uuid:40cf0dff-e029-4367-ade9-cca471987ebe","http://resolver.tudelft.nl/uuid:40cf0dff-e029-4367-ade9-cca471987ebe","Modeling of residential demand response of smart electricity grids to day ahead markets","Mahalingam, A.","Herder, P.M. (mentor); Hakvoort, R.A. (mentor); Nikolic, I. (mentor); Cunningham, S.W. (mentor)","2013","Developments in the electricity system need to accommodate the pressure of steadily rising demand, advanced technology integration in addition to increasing penetration levels of renewable energy sources (RES) and distributed generation (DG). As such, European energy policy for 2020 is aimed at reducing greenhouses gases by 20%, increasing RES by 20% and curbing energy consumption by 20%. Renewable generation in the Netherlands accounts for 4% of the national energy use with an expected 14% increase by 2020. Traditionally, power system control has adapted the supply side to meet fluctuations in consumption, with little attention paid to demand side modifications and thus accounting for the resultant system and grid inefficiencies. As the Dutch veer away from flexible fossil-­?based electricity supply and towards greener stochastic generation the system will have to consider all available resources for balancing, including the demand side. The implementation of Demand Side Response (DSR) has the potential to provide added flexibility to dynamic system conditions solely based on reshaping the demand for electrical energy. DSR mechanisms entail incentivizing load flexibility in response to an economic stimulus reflective of generation or transport constraint in the power system. Given today's grid capabilities and owing to the intermittency of the power production by Renewable Energy Sources (RES), there is little scope of integration of renewables and other decentralized power generating units. The consumers would thus be ""prosumers"" in the future, wherein their domestic power production through PV and wind would be integrated within the framework of the conventional electricity grid. This would not be possible without insights into their production characteristics and consumption behavior. However, the precise impact of the DSM policies on the consumer behavior in the Netherlands is not yet known. Agent-­?based simulation is used to model the consumer behavior with respect to Demand Side Response in the liberalized Dutch electricity market. The model inputs include electricity consumption by household type, APX power NL Day-­?Ahead auction results and selected price-­?based DSR mechanisms. In order to assess the potential of residential DSR, a bottom-­?up construction methodology is used to simulate the average domestic electricity consumption for every household type. Household profiles are generated on the basis of current data from domestic electricity consumption of appliances in Dutch households, whereby accurately representing the electricity consumption and flexibility feasibility on a 24 hour basis. Consumer response to implemented mechanisms is modeled based on the potential drivers for Dutch power consumption behavior: convenience, cost, conscious and climate. Furthermore, price results from the Day-­?Ahead auction are used and DSR mechanisms (TOU, CPP and RTP) are constructed from the resulting hourly prices. The emergent behavior from the hourly interaction between consumer response and mechanism serves as an illustration of the tangible value of aggregated demand-­?side flexibility. Decentralized power production from renewable energy sources like PV and wind are modeled as components of the prosumers. The effect of renewables integration and distributed generation in the form of rooftop PV's and the effect of electric vehicle charging based on the current ownership rate are integral to the model. The ultimate objective of the model is to provide insight into the effectiveness and feasibility of residential Demand Side Response to price fluctuations in the day-­?ahead market, serving as a decision support tool for effective policymaking from simulation of various scenarios (penetration rate of appliances and levels of renewable energy share to the prosumer generation mix) based on the pricing mechanisms set by regulators. It would also inform the policymakers of the policies that could augment the overall system efficiency and thus engage the gear towards sustainable development. Furthermore, it is expected to facilitate them to formulate effective policies that would maximize the net social welfare of the economy and incentivize the adoption of smart metering technologies by consumers. Results of the research show that Critical Peak Pricing (CPP) price mechanisms have the highest saving potential for the consumers and resulted in the maximum reduction in the system peak demand for the residential electricity system. As a consequence, it was estimated that the investment on smart meters in the households would pay its upfront investment back in roughly 6 months from the date of use. From the analysis of model results, it was found that the mere virtue of design of the policies, the system could be influence to great extents as a result. It was also found that the design of policies is key to expediting the diffusion of a particular technology (EV and PV) and promoting social welfare in the electricity system. Additionally, CPP policies were found to be the best to incur the least cost for consumers at higher penetration levels of these green technologies, which incentivizes an increase in the share of decentralized residential power production by PV for self-­?consumption. From extensive analysis and upon reflection, it is concluded that the newly proposed CPP-­?7PM policies fare better than the other alternatives and therefore are recommended for adoption in the Dutch electricity system. As an extension of the conclusions from the model, additional measures including awareness creation programs about the benefits of energy saving measures and participating in load shifting for the consumers are to be introduced in order to be able to fully maximize the potential of Demand Response as a flexibility resource in the electricity market.","agent based modeling; electricity policy; demand response; smart grids","en","master thesis","","","","","","","","","Applied Sciences","Energy and Industry","","Sustainable Energy Technology (Applied Sciences)","",""
"uuid:421513b8-c95c-4229-bfe1-bcbba6667891","http://resolver.tudelft.nl/uuid:421513b8-c95c-4229-bfe1-bcbba6667891","Development and Evaluation of a Numerical Model being able to Simulate Soil Pore Size Change","Liu, X.","Heimovaara, T.J. (mentor); Jommi, C. (mentor); Van Paassen, L.A. (mentor); Barnhoorn, A. (mentor)","2013","","","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Geo-engineering","",""
"uuid:bd8da54e-7c02-4591-80d9-d56b346e4522","http://resolver.tudelft.nl/uuid:bd8da54e-7c02-4591-80d9-d56b346e4522","Economic and Environmental Assessment of Extended Producer Responsibility and No Reuse Policies in Mobile Phone End of Life Networks","Bellinga, P.B.","Nikolic, I. (mentor); Blass, V. (mentor); Pruyt, E. (mentor); Herder, P. (mentor)","2013","This thesis presents an assessment of the economic and environmental effects of Extended Producer Responsibility and No Reuse Policies, by using an agent-based model of Mobile Phone End of Life Networks. Electronic waste of mobile phones is an increasing problem. Governments have reacted by adopting various types of legislation, the most common being Extended Producer Responsiblity (EPR). EPR makes producers reponsible for the collection and processing of their End of Life products. Companies have also reacted. Either because of fear of competition of reused phones, or because of data security concerns, some companies have adopted No Reuse Policies (NRP). NRP means that phones are not allowed to be reused. The findings show that EPR is beneficial for the environment and for the economics of refurbishers. The effects do depend heavily on the disposal choices made by individual consumers. Findings also show that the effects of NRP are not significant. Because the effects (of EPR) depend heavily on parameters which are not yet supported by data, further research should concentrate on gathering empiric evidence.","Agent Based Modeling; Exploratory Modeling Analysis; End of Life; E-Waste; Extended Producer Responsibility; No Reuse Policies","en","master thesis","","","","","","","","","Technology, Policy and Management","Energy and Industry","","","",""
"uuid:f6c7d815-0713-4d21-ae93-d29e52cbb324","http://resolver.tudelft.nl/uuid:f6c7d815-0713-4d21-ae93-d29e52cbb324","Graphene - Propagating Wave Interaction by means of Surface Acoustic Waves (SAW) Devices","Atar, O.G.","Staufer, U. (mentor); Perez Garca, H. (mentor)","2013","Not available because of confidentiality","graphene; surface acoustic waves; RAMAN; MEMS","en","master thesis","","","","","","","","2014-07-01","Mechanical, Maritime and Materials Engineering","Precision and Microsystems Engineering","","","",""
"uuid:d9935e78-7657-42b1-8bcf-fbd935ae030f","http://resolver.tudelft.nl/uuid:d9935e78-7657-42b1-8bcf-fbd935ae030f","Impacts on passengers and operators of service reliability for the case of a multi-level public transit network","Lee, A.P.H.","Van Arem, B. (mentor); Van Nes, R. (mentor); Van Oort, N. (mentor); Annema, J.A. (mentor)","2013","A framework is developed to calculate reliability from the passengers perspective in a multilevel public transit network. The major variables that impact reliability for transfers passengers are identified as: scheduled transfer time, headways of connecting lines, variation of vehicle operations, transfer walking time and proportion of transferring passengers. These variables are examined in the context of changing the scheduled transfer time in a hypothetical network and in the case that a holding strategy is added at the transfer point. It is shown that a trade-off exists between scheduled transfer time and reliability. Holding at a transfer point can be beneficial to passengers transferring to the held line, depending on the scheduled transfer time. The calculation method is applied to a cost-benefit analysis to a small example using data from the tram network in The Hague, Netherlands. Benefits to passengers are quantified from changes to the magnitude of a passenger’s travel time, including scheduled travel time and additional travel time, as well as the width of the travel time distribution using the reliability ratio as a value for reliability. Although it is difficult to set a schedule that benefits different groups of transferring passengers, it is possible to realize travel time and reliability benefits through scheduling.","","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Transport & Planning","","Transportation, Infrastructure and Logistics","",""
"uuid:59d5a00d-6bb7-490d-9887-32e9530eb33e","http://resolver.tudelft.nl/uuid:59d5a00d-6bb7-490d-9887-32e9530eb33e","GPU-based simulation of brain neuron models","Du Nguyen, H.A.","Al-Ars, Z. (mentor)","2013","The human brain is an incredible system which can process, store, and transfer information with high speed and volume. Inspired by such system, engineers and scientists are cooperating to construct a digital brain with these characteristics. The brain is composed by billions of neurons which can be modeled by mathematical equations. The first step to reach that goal is to be able to construct these neuron models in real time. The Inferior Olive (IO) model is a selected model to achieve the real time simulation of a large neuron network. The model is quite complex with three compartments which are based on the Hodgkin Huxley model. Although the Hodgkin Huxley model is considered as the most biological plausible model, it has quite high complexity. The three compartments also make the model become even more computationally intensive. A CPU platform takes a long time to simulate such a complex model. Besides, FPGA platform does not handle effectively floating point operations. With GPU's capability of high performance computing and floating point operations, GPU platform promises to facilitate computational intensive applications successfully. In this thesis, two GPU platforms of the two latest Nvidia GPU architectures are used to simulate the IO model in a network setting. The performance is improved significantly on both platforms in comparison with that on the CPU platform. The speed-up of double precision simulation is 68.1 and 21.0 on Tesla C2075 and GeForce GT640, respectively. The single precision simulation is nearly twice faster than the double precision simulation. The performance of the GeForce GT640 platform is 67% less than that on the Tesla C2075 platfom, while the cost efficiency on the GeForce GT640 is eight times higher than that on the Tesla C2075 platform. The real time execution is achieved with approximately 256 neural cells. In conclusion, the Tesla C2075 platform is essential for double precision simulation and the GeForce GT640 platform is more suitable for reducing execution time of single precision simulation.","GPU; Inferior Olive; neuron model","en","master thesis","","","","","","","","2013-08-26","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","Computer Engineering","",""
"uuid:070ac4de-64e1-4877-ae96-01169383acd2","http://resolver.tudelft.nl/uuid:070ac4de-64e1-4877-ae96-01169383acd2","Numerical Modelling of Sintering of Alumina","Fan, B.","Vuik, C. (mentor); Lahaye, D. (mentor)","2013","In this project we introduce the sintering process, which involves two basic phenomena, pore shrinkage and grain growth, occurring simultaneously. The objective of this project is to quantitatively describe the sintering process incorporating the kinetics of pore shrinkage and grain growth. First we build a model for pore shrinkage separately. An important use of the results from pore shrinkage model is to estimate the relative density of the sintering material. Here we show an example with feedstock KA-13 in Ludwigshafen. The estimated result is reasonable, but not as good as expected, which means that lots of work are needed to be done in the future, such as more accurate measurements, adjustment of the model parameters and so on. Using the same population balance equation as that used in the pore shrinkage model, we introduce the grain growth model, which only has different velocity model from that of pore shrinkage. Since during the intermediate stage of sintering, the kinetics of grain growth depends on the rate of pore shrinkage, we can further model the grain growth rate coupled with pore shrinkage through porosity or relative density, which depends on the solution of the pore shrinkage model. Here we solve the PDEs using finite element method with COMSOL Multiphysics 4.3a (which is a software based on finite element method), and compare the results with analytical solution, solution generated using finite different method in Matlab. Initial values and parameters in the model are discussed as well. In the end we give an simple example with temperature cycle in the real system.","sintering; alumina; pore shrinkage; grain growth; relative density","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","Risk","",""
"uuid:c36a0418-894d-45e4-b16e-b374ee6477e6","http://resolver.tudelft.nl/uuid:c36a0418-894d-45e4-b16e-b374ee6477e6","Floating Area in the Maashaven: Research of legal and administrative aspects in order to design and realize a floating area in the Rotterdam Maashaven","Fang, M.G.M.","Thissen, W.A.H. (mentor); Enserink, B. (mentor); Kruyt, R.L. (mentor); Ruijtenbeek, R.R. (mentor)","2013","Stadshavens Rotterdam [CityPorts Rotterdam] is a bounded area between the Beneluxtunnel and the Erasmusbrug. This area will undergo a transformation within the next 20 to 40 years. The total area of Stadshavens [CityPorts] encompasses 1,600 hectares and consists of four areas: 1. Rijnhaven-Maashaven; 2. Merwehaven-Vierhavens; 3. Eemhaven-Waalhaven; 4. RDM-terrein and Heijplaat. The Rijnhaven-Maashaven area is selected to experiment with floating buildings. This means that these type of buildings will be implemented in a buitendijks gebied [outside the dike area] and is therefore not protected by dikes. Floating buildings, which move along with water flows, can be a new delta solution. A successful exploitation can hopefully result in a new ‘export product’ for other areas and cities. Potentially, floating buildings can be introduced at many other locations due to the fact that many big cities in the world are located near water. A theoretical framework has been developed in order to define legal and administrative aspects. This framework is applied to empirical results to evaluate current experiences with floating buildings. Subsequently, this framework is elaborated for the Maashaven and Rijnhaven with corresponding realisation strategies.","administrative aspects; floating buildings; Rotterdam Maashaven; legal aspects; realisation strategies; Rotterdam CityPorts","en","master thesis","","","","","","","Campus only","2013-08-27","Technology, Policy and Management","Policy Analysis","","Systems Engineering, Policy Analysis and Management","",""
"uuid:04c9c3e0-8e98-4c16-95eb-ea914747036c","http://resolver.tudelft.nl/uuid:04c9c3e0-8e98-4c16-95eb-ea914747036c","Technology Assessment of sustainable options for the Dutch gas sector: A refined methodology combining Multi-Criteria-Decision Making with Pathway Analysis","Budelmann, L.T.","Quist, J. (mentor); Cunningham, S. (mentor); Mulder, K. (mentor)","2013","","technology assessment; sustainability; Dutch gas sector","en","master thesis","","","","","","","","","Technology, Policy and Management","Technology Dynamics and Sustainable Development","","Management of Technology","",""
"uuid:69274f6e-7996-488a-af28-02f39dc337d4","http://resolver.tudelft.nl/uuid:69274f6e-7996-488a-af28-02f39dc337d4","4D Trajectory De-Confliction For Future ATM By Applying Constraints","Baboeram Panday, R.A.S.","","2013","In the present ATC system conflicts between aircraft are detected and resolved in a stated-based approach. To meet traffic demand predictions, the global air traffic management (ATM) system needs revolutionary changes. Several visions on future ATM operations exist (e.g. NextGen, SESAR). A common function between the different visions is 4D Trajectory management. This function enables trajectory-based operation as opposed to the state-based approach of the present system. Instead of monitoring the current traffic situation and resolving short term conflicts by vectoring, the 4D trajectory management function de-conflicts all trajectories prior to execution. A key function of 4D trajectory management is the resolution of 4D trajectories. Conflict resolution of 4D trajectories is applied to conflict scenarios using constraints. A characteristic of a constraint is that it does not limit the aircraft to a particular solution but provides the aircraft the room to generate a trajectory within the actual solution space. Conflicting trajectories are resolved using constraints where the constraints provides an approximation of the solution space. This concept of trajectory de-confliction through the use of constraints is the topic of this thesis work.","","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Telecommunications","","","",""
"uuid:3e016968-2891-4efd-9360-1c779ea8d4a1","http://resolver.tudelft.nl/uuid:3e016968-2891-4efd-9360-1c779ea8d4a1","Development of Biofuel Technology in Indonesia","Panjaitan, N.","Kamp, L. (mentor)","2013","Indonesia has appeared to be an oil dependent society in the last four decades. However, Indonesia experienced a status change from oil net exporter to net importer in 2004. These factors created awareness in Indonesia to develop renewable energy sources. Biofuel is one of the most potential renewable resources in the country. The development of biofuel technology in Indonesia has experienced dynamics in a relatively short period of time. The acknowledgement of biofuel technology in the country started in the year 2006, the technology was developed and had its peak on the year 2008, and has slowed down since 2009. Many companies closed down their production activities, leaving the production of biofuel technology in Indonesia to half of the installed capacity. The main objective of this research is to analyse the development of biofuel technology in Indonesia. The defined research question is: What are the factors that hamper and boost the biofuel technology development in Indonesia? The Multilevel Perspective and the Functions of Innovation System approach were chosen to be the theoretical frameworks. The framework Multilevel Perspective (MLP) is utilised to analyse the level of entrenchment of the technology in regards to its development in the technical and social context. The Functions of Innovation System (FIS) is utilised to capture and analyse the dynamics that occur in the process of technology development. The FIS functions that are utilised are: Creating adaptive capacity, Knowledge diffusion through networks and Knowledge development, Guidance of the search, Creation of legitimacy, Resource mobilisation, Market formation, and Entrepreneurial activity. Furthermore, the two frameworks are combined. The purpose of this combined framework is to analyse how the dynamics of the technology development process influence the interaction between the embedded technology and the surrounding and to analyse the dynamics within the technology and its environment influence the development of the technology. There are three different stages of development can be defined for biofuel technology: commercial production, agriculture development, and research and development stages. Biodiesel from palm oil is the type of biofuel technology that exists at a commercial stage in Indonesia. Biodiesel from Jatropha as well as first generation bioethanol are currently in the agriculture development stages. Lastly, the second generation of bioethanol and biodiesel are still in the research and development stages. Government, research institutes, NGOs and companies are involved in the development of biofuel technology. The Ministry of Energy and Mineral Resources through the Directorate General of New Energy, Renewable Energy, and Energy Conservation is the main governmental actor to define and impose policies and regulations regarding biofuel technology in Indonesia. The utilisation of MLP framework in the analysis reveals that biofuel technology is still in the niche level of development. However, depending on the level of development, some types or generations of biofuel technology have to interact with actors from the agriculture and the energy regime. Biodiesel from palm oil, however, has reached the agriculture regime and furthermore the development of the technology has required interactions from the energy regime. Biodiesel from Jatropha as well as the first generation of bioethanol has developed to the stage where interaction with agriculture regime is necessary. Furthermore, the second generation bioethanol and biodiesel is currently in the niches, where the technology is being developed in protected spaces created mainly by researchers and scientists. The FIS analysis suggests that all FIS functions are available in Indonesia, with different levels of fulfilment. The existence of all functions contributes to the development of biofuel technology in Indonesia. The only significant flaw from the performed functions is the Resource Mobilisation that fails to mobilise the feedstock from agriculture sector to the biofuel producers. Furthermore, interactions between the FIS function are not well developed. Because of these weak interactions, the issue of sustainability in general and of biofuels in particular is not constantly on the political agenda, which causes inconsistencies in policies and the rise of negative views on the technology. These negative views, which are related to function Creation of Legitimacy, and the policy inconsistencies, which is related to function Market Formation hamper the technology development. The application of combined framework indicates that regarding biofuel technology development in Indonesia the FIS functions Knowledge Diffusion through Networks and Knowledge Development, Creation of Legitimacy, and Guidance of the Search are performed mainly only in the niches. The FIS functions Creating Adaptive Capacity and Resource Mobilisation are mainly related to the agriculture regime. The FIS functions Market Formation and Entrepreneurial Activity are mainly related to the energy regime. Lastly, the main recommendation for companies and governments is to ensure that all aspects related to biofuel are assessed and taken into account in all functions they performed. This would help the connection between one function and another to become more aligned. If the interactions between the functions are strong, the system can develop a stronger virtuous cycle that would enable a greater technology development.","biofuel; innovation system; multi-level perspective; functions of innovation system; Indonesia; technology development","en","master thesis","","","","","","","","","Technology, Policy and Management","Management of Technology","","Technology Dynamics & Sustainable Development","",""
"uuid:25d72452-9dde-4180-83cd-20644dff10cb","http://resolver.tudelft.nl/uuid:25d72452-9dde-4180-83cd-20644dff10cb","IT Driven Business Service Innovation: IT organizational contributions in large digitized companies to effective business service innovation","Kleiberg, E.H.","Van Beers, P.C. (mentor); Den Hartigh, E. (mentor); De Reuver, G.A. (mentor); Kramer, M. (mentor)","2013","Services play a key role in today’s leading global economies. Companies are facing fierce competition, shortening development cycles of new technologies, and more demanding customer expectations. Innovation is a key driver for economic growth and competitive advantage. New technology is one of the largest sources for innovation, but IT is identified as the largest barrier to effective service development. Studies indicate that IT organizations are is ranked last as the source of new ideas and the CIOs are least involved in the screening decisions of ideas. The growing importance of service innovation and IT has created opportunities for IT organizations to contribute to more effective service introductions. IT organizations can provide their technical knowledge and contribute to selection of ideas on both technical feasibility and compliance with existing capabilities. Nonetheless, IT organizations are often pressured to remain facilitators or technology enablers as conceptual understanding and appropriate innovation mechanisms are missing. The objective of this research is to further develop the understanding of the mechanisms for IT organizational contributions to effective generation, selection and commercial evaluation of business service innovation projects. Understanding is supported with two conceptual frameworks on IT innovation capabilities and by comparing them to large Dutch companies in financial, communica- tion, media and high-technology industries in an electronic survey and two case study examples.","IT organization; service innovation; NSD; capability; service process performance","en","master thesis","","","","","","","","2013-08-26","Technology, Policy and Management","Technology, Strategy and Entrepreneurship","","Management of Technology","",""
"uuid:48c0a762-fddc-4d61-aa8d-6e1583155bfa","http://resolver.tudelft.nl/uuid:48c0a762-fddc-4d61-aa8d-6e1583155bfa","Theoretical and numerical approach of ultimate capacity of transversely prestressed concrete deck","Petropoulou, G.D.","Hordijk, D.A. (mentor); Van der Veen, C. (mentor); Hendriks, M.A.N. (mentor)","2013","Introduction Many researchers have been discovered that bridge deck slabs which were designed to fail in bending, mostly fail under punching shear mode at a higher load than the expected for bending, because of the effect of in-plane compressive membrane forces, induced by the lateral restrained boundary conditions. Punching and bending failure modes are going to be analysed taken into account the enhancement due to compressive membrane action in the transverse prestressed concrete slab. Problem definition The objective of this thesis is to investigate the effect of compressive membrane action (CMA) in combination with the transversely prestress under a static point load applied at the midspan of the bridge’s slab. Research The aim of this thesis is to investigate the effect of the compressive membrane action and transversely prestress of the ultimate punching and bending capacity of a concrete deck slab. To develop the analysis of this scientific topic, research questions have been posed giving an orientation into the research and indicating the guiding components of the investigation. 1. Develop an analytical model to predict the ultimate capacity of a transversely prestressed slab accounting for the CMA and TPL. 2. To what extent can the CMA and the TPL contribute to the punching shear and bending capacity of the slab? 3. Comparative Study: Theoretical approach versus Experimental results Results – Conclusions Simulating the transverse prestress as an imposed strain, the punching capacity is hardly affected by the different prestress levels (1% deviation) and the compressive membrane force slightly changes, leading to the conclusion that the theoretical approach underestimates the prestress. In flexural mode the bending capacity is higher than the punching shear leading to the conclusion that the slab will fail in punching shear. The ultimate capacity of the interior panel is higher than the exterior but the displacement is smaller because the higher stiffness of the interior makes it stiffer and less ductile. Recommendations 1. Prestress should be simulated as a progressing action until the failure stage, not as a constant effect. 2. Effective stiffness in punching shear has to account for the boundary conditions. 3. Compressive membrane action should be defined separately from the ultimate punching shear capacity.","pucnhihg shear capacity; compressive membrane action","en","master thesis","","","","","","","","2013-09-09","Civil Engineering and Geosciences","Structural Engineering","","Concrete track","",""
"uuid:8276c89d-97ce-4d6f-a149-cdb04b71078c","http://resolver.tudelft.nl/uuid:8276c89d-97ce-4d6f-a149-cdb04b71078c","Simulation Studies of Foam for Enhanced Oil Recovery","Dharma, A.S.","Rossen, W.R. (mentor); Boeije, C.S. (mentor); Vincent-Bonnieu, S. (mentor); Baviskar, S.M. (mentor)","2013","In gas-injection enhanced oil recovery (EOR), foam is a promising method to improve sweep. We studied foam for EOR through analytical modeling and simulations in two cases: the ability of foam to prevent gravity override over large distances and the effect of oil on foam processes. Shan and Rossen (2004) present a simple model for SAG (surfactant-alternating-gas) foam process with vertical permeability kv equal to horizontal permeability kh, but they did not extend the numerical calculations to large distances. Robert de Velde Harsenhorst (2012) extended the model to the case for kv < kh, which gives the surprising prediction that gravity override is worse as kv decreases. With large kv, foam pushes gas downward in response to the pressure difference across the titled foam front. In the first part of this thesis, we extend the numerical calculations of de Velde Harsenhorst for the case 0 < kv < kh. Then, we use an example from a North Sea field to test the simple model in simulation. The simulation result confirms that segregation would be insignificant over the large distances between wells, 6 km, as predicted by the simple model. Then, we compare sweep efficiency in the North Sea example with continuous foam injection. Complete segregation over a relatively short distance with continuous foam injection is confirmed with simulation. The segregation length in the simulation is similar to that in analytical model derived by Van der Bol (2007). We also test the simple model with simulation under more demanding cases with more severe gravity segregation, using three sets of foam parameters: the North Sea example, model parameters fit to data of Persoff et al. (1991) and a foam model designed specifically to fit the assumptions of the simple model. Gravity segregation with SAG is worse as kv decreases in simulations in the latter two cases, which conforms to predictions of the simple model. The effect of oil on foam is complex and not fully understood. In the second part of this thesis, we study the effect of oil on foam from 1D computer simulations of continuous foam injection with oil present. We attempt to relate and compare plots of gas mobility-reduction factor with foam, plotted on a ternary composition diagram, with the composition paths of displacements simulated using the same model parameters. We also use fractional-flow theory, which provides key insights into foam EOR displacements, to verify the foam simulation results where the simulation composition paths travel along the binary sides of the ternary phase diagram. In the preliminary results, the injection point is always within the region of strong foam, but the initial condition is either inside or outside this region. In all cases, regardless of the initial condition, oil was displaced ahead of the foam. These results, which need further study, suggest possible usefulness of drawing composition paths on a plot of gas mobility-reduction factor on the 3-phase diagram. However, a check of the process by which foam is first created near the inlet in these simulations suggests numerical artifacts may have affected the results. This possibility needs further research.","foam; enhanced oil recovery; gravity override; SAG; effect of oil; porous media","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Petroleum Engineering","",""
"uuid:a48d7c63-7467-4434-8b38-3af273e72fca","http://resolver.tudelft.nl/uuid:a48d7c63-7467-4434-8b38-3af273e72fca","Window into the Future: The tablet app of Strategic Product Design that shows what is really out there","Moerenhout, L.","Buijs, J.A. (mentor)","2013","Strategic Product Design (SPD) is a master study of Delft University of Technology. SPD alumni have difficulties in presenting themselves to potential employers. Therefore, it unnecessarily is more difficult for them to compete with their competition on the job market. Currently, there is no information available that supports students in preparing themselves for practice. As SPD has connections with practice, it is a suitable collector and provider of this information. The tablet app SPD’s Window into the Future contributes to the solution. The app provides students with information about SPD professions, companies they could be working for, and how SPD is integrated in these companies. It is a broad range of useful information, derived from real experiences of SPD professionals, and presented in a visual way. The app supports second semester master students who are verifying their image of practice and orienting on their future professional options.","comic; SPD; practice; tablet app; visual communication; professions","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product Innovation Management","","Master of Science Strategic Product Design","",""
"uuid:38d4fa0e-8a3a-4216-9044-e8507a60ed66","http://resolver.tudelft.nl/uuid:38d4fa0e-8a3a-4216-9044-e8507a60ed66","The legal position and societal effects of security breach notification laws","Nieuwesteeg, B.F.H.","Steenhuisen, B.M. (mentor); De Vries, S.A. (mentor); Van Eeten, M.J.G. (mentor); Van den Berg, J. (mentor)","2013","This thesis scrutinizes the proportionality and describes the subsidiarity of proposals for security breach notification laws (hereafter: SBNLs) in the European Union. An SBNL obliges that a security breach within a company or government must be notified to affected customers and a supervisory authority. A law stands the proportionality test if the requirements of effectiveness and necessity are met. Effectiveness means that there is a causal relationship between the measure and the aim pursued. Necessity means that no less restrictive policy options are available that achieve the same aims. The closely linked subsidiarity test assesses the necessity of the European Union approach: the question whether the aims of the SBNL and cybersecurity cannot be achieved sufficiently by the Member States individually. Subsidiarity is to a great extent a political question and consequently described more limitedly. Why these tests? Proportionality and subsidiarity are fundamental principles of EU law. They demand the European legislature not to go beyond what is necessary to attain the objectives in the Treaties and to only adopt measures if a European Union approach has added value. The European Court of Justice scrutinizes whether European legislation is in accordance with these principles. The laws that have been assessed are Article 31 of the proposed Data Protection Regulation (hereafter: PDPR) and Article 14 of the proposed Cybersecurity Directive (hereafter: PCD). Article 31 PDPR concerns a single uniform personal data breach notification obligation. A personal data breach entails the unauthorized access to and/or theft of personal data. Article 14 PCD concerns the harmonization of national (significant) loss of integrity breach notification obligations. A loss of integrity concerns the loss of control over computer systems. A personal data breach always entails a loss of integrity, but a loss of integrity can also occur without the loss of personal data. The aim of the SBNL in the PDPR is “to ensure that individuals are in control of their personal data and trust the digital environment” in order to “increase the effectiveness of the fundamental right to data protection”. The aim of the SBNL in the PCD is: “to create a culture of risk management and improve the sharing of information between the private and public sectors.” The subsidiarity question covers cybersecurity in general and SBNLs in particular. The Commission argues that a European cybersecurity approach is necessary because of the cross border aspect of the Internet, the necessity of a uniform secure Internet for the Single Market and the protection of fundamental rights. Indeed, there is European cybersecurity legislation and a European cybersecurity policy framework. Regarding the PDPR and the PCD in particular, the Commission argues that there is a need to harmonize national initiatives in order to create a level playing field, legal certainty and lower administrative burdens for companies to notify. A literature review in this thesis shows that the United States aims to replace a state level SBNLs by a federal SBNL. The obligation to comply simultaneously with multiple SBNLs caused significant administrative burdens for companies. This strengthens the conception that SBNLs can better be achieved at a European level, although this remains a political consideration. From an apolitical point of view, this thesis did not find a convincing argument about the inappropriateness of a European approach regarding cybersecurity and SBNLs. The proportionality test contains two elements. The first element of the proportionality test, the effectiveness test, is performed more extensively in this thesis than the Commission did in its impact assessment of both the PDPR and the PCD. Legal scholars and the European legislator, usually assess the first aspect of proportionality limitedly. In the PDPR and PCD, the Commission did not mention in what way the SBNL is suitable to achieve the aim “to ensure that individuals are in control of their personal data and thrust in the digital environment” and “to create a culture of risk management and improvement of information sharing between private and public parties”. This is a deficiency in the analysis of legislation. This thesis challenges the aforementioned assumption that determination of causality is straightforward. This is done by a more substantive assessment of the proportionality test. This thesis contributes an empirical study from a security economics perspective, in order to substantively review (the complexity of) effects of SBNLs. Do the (expected) effects of SBNLs match the aims it should attain according to the European proposals? And are these effects desirable? Legal impact assessments can benefit from this perspective, because knowledge about the effectiveness of the law will be enhanced. To structure the empirical study, a first and second order effect of SBNLs have been distinguished. The first order effect is the effect of (characteristics of) SBNLs on the amount of breach notifications. Generating notifications is not one of the final aims of the proposed legislation, but a means to achieve the second order effect. The second order effect includes the positive and negative effects of the law on society. A literature review is conducted to provide an overview of what is already known concerning those two effects. The quantitative analysis systematically assesses the first order effect of American SBNLs by a longitudinal dataset containing security breach notifications. The subsequent qualitative analysis reviews the perception of Dutch security experts and managers regarding the first and second order effect and outcomes of the quantitative analysis. The results can substantiate the first element of the Commissions’ proportionality test of European SBNLs: This study proves the first order effect empirically by means of analyzing American data. The laws have an effect on the amount of breach notifications. The effect is relatively large: a notification increase of at least 50% can be attributed to the law, by a fixed effects regression analyzing differences in breach notification before and after the introduction of the law. The database is partly constructed by underlying sources that only register officially notified breaches, which can explain this high relative increase. From an absolute perspective, the effect is minor: less than 0.05% of the companies notified a security breach in America in the eight-year period that was researched. To compare: a recent study in the United Kingdom published that 88% of the companies surveyed had experienced data theft in 2009. The low absolute number of breaches could be explained by the incompleteness of the dataset, high compliance costs for a company due to reputation damage and unawareness of breaches. The introduction of the law thus has a structural first order effect, at least in the database of known security breaches. It is however ambiguous which aspects of the law cause this effect. Literature review and qualitative analysis showed that enforced sanctions generate compliance with the law and that reputation damage is a major driver for non-compliance. Confidential treatment of the notification and benefits from information sharing about security breaches are perceived as minor incentives for compliance. The quantitative analysis only confirmed that some American laws qualified as strict by American Attorneys cause an increase in notifications, but it is ambiguous what exactly makes these laws strict. The literature review and the qualitative study demonstrated several positive second order effects perceived in literature and by security managers and experts, such as increased investments in security, fostered cooperation between companies (literature only), increased awareness of consumers of security breaches and faster risk mitigation. The first two effects match with the aim of the PCD to 1.) create a culture of risk management and 2.) enhance information exchange between the private and public sectors respectively. The last two effects correspond with the aim of the PDPR to enhance personal data control of individuals. However, the positive effects can be nuanced. The security managers interviewed already shared security information with competitors, and did not see an incentive for cooperation with the government following from a security breach notification, because they did not value the government as a center of expertise. Moreover, a security expert challenged the effect of increased investments in security because the law provides an incentive to notify, not to improve security practices. Accepting the ‘risk’ of a notification might be less expensive than improving security practices in order to avoid notifications. This is however not confirmed in literature review or by other qualitative analysis, which implicates that the risk of not providing incentives to improve security practices at all must be perceived as low. Lastly, an increased number of security breach notifications might result in an overload of information that could also result in disinterest and a notification fatigue instead of enhanced awareness and risk mitigation. This overload is not a big treat given the current low amount of notified security breaches. For instance, in America, about 600 million records were breached in the eight-year period observed. This would entail that, on average, an American citizen would be notified twice in eight year. Hence, the second order effects in literature and qualitative analysis, although they are perceptions that can be nuanced, do match the objectives pursued in legislation. But, the objectives are vaguely defined and while their attainment could constitute effectiveness in the legal sense, the question remains what makes an SBNL effective and when an SBNL is effective. Moreover, there are also additional negative effects associated with SBNL in literature and qualitative analysis, such as reputational costs and maintenance costs. The second element of the proportionality test concerns the question whether there are less restrictive equally effective measures available. The SBNL can restrict companies, because it infringes the fundamental freedom to conduct a business by imposing administrative, compliance- and reputational costs. This study offers two observations concerning this infringement. First, the freedom to conduct business is more infringed than the Commission states. The cost assessment of the Commission only included the costs of making a notification, which are estimated between 125 euro and 20000 euro per notification. But, literature and qualitative analysis showed that there are costs that the Commission did not take into account, such as the reputation damage incurred (estimations up to 2% of a company’s turnover) and the costs of processing and enforcement of breach notifications. The cost estimation of the Commission thus is undervalued compared with the total societal costs of an SBNL. Second, the coexistence of the PDPR and the PCD unnecessarily infringes the freedom to provide a business as it imposes unnecessary costs for companies. In many cases, a breach thus should be notified twice to both the European supervisory authority and to the competent national authority, because the scope of personal data loss and loss of integrity overlap. Second, the proposals are regulated by a different legal instrument and emit different signals. The confidential treatment in the PCD will not function properly if simultaneously companies are forced to publicly disclose the same information in the PDPR. To conclude, the fuzziness of the aims and the complexity of measuring effects hamper the determination of a reasonable expectation of causality between the measure and the aims pursued. The Commission sets aims that are fuzzy and hard to measure, and does not specify how these goals will be achieved through the adoptions of SBNLs. Likewise, the empirical measurement of effects in part ? showed that it is complex to pinpoint effects of SBNLs. Moreover, the Commission undervalued societal costs and adverse effects. In my view, in the current situation, a reasonable expectation of effectiveness is not demonstrated sufficiently. In the theoretically desired situation, the goals are clear and measurable. The law is effective because the measurable aims are achieved by the measure. But, still, effectiveness is not simply attaining aims. Even if the causal relation between the measure and its aims can be proved in a narrow sense, the question remains whether the achievement of these aims is effective. From a security economics perspective, it can be argued that the law is effective if the revenues of positive effects are higher than the societal costs of negative effects. This requires an accurate empirical measurement of these effects, initiated in part ?, and a quantification of these effects. Unfortunately, this approach towards effectiveness does not cover non-economic, non-measurable aims such as the protection of fundamental rights. The protection of fundamental rights is not always ‘efficient’ and can certainly not always be quantified, but European legislation must remain within the boundaries of fundamental rights. Moreover, the complexity of the legal interferences in the field of cybersecurity makes it impossible to provide an exhaustive balance sheet of all (expected) effects. A security economics perspective would not be the perfect means to define effectiveness, because some aims are not measurable and expected effects are complex. Both a legal and an economic approach do not provide an optimal outcome for the definition of ‘effectiveness’. There is no uniformity of what makes a law effective. Thus, still the effectiveness question remains. What is needed to determine the effectiveness of SBNLs? Who may decide when a law is effective? In a democracy, we all should decide. More concrete: the European Commission, Parliament and Council state ex ante in the ordinary legislative procedure the aims of the law. The European Court of Justice decides ex post whether the law is effective. Thus, effectiveness in redefined, as legal and economic approaches towards effectiveness are troublesome. This definition must be regarded as a starting point for further research on interpreting effectiveness of the law. ""Effectiveness is the causality between a legislation and its aims defined by a democratic decision making process where as much information as possible about (potential) positive and negative effects is provided."" Hence, taking this definition into account, improving information about potential positive and negative effects is the key tool to enhance effectiveness of the law and correctly assess its necessity. The executed empirical analysis in this thesis has provided knowledge about the effects of SBNLs that can be used by the Commission. Increased availability of information about societal impact (expectations) enhances decision making of the legislature ex ante and the scrutiny of the Court ex post that determine the proportionality of cybersecurity laws. The Commission, which has the power of initiative, should invest to provide this information. To conclude, additional information about effects of legislation on society will improve the quality of draft legislation and the judicial decision about proportionality. For example, information about the adverse reputation damage on companies, demonstrated in this thesis, will play a vital role when judging about the infringement on the freedom to conduct business. Additional information about effects will not be decisive in a judicial decision, since also non measurable effects need to be balanced and (expected) effects have a certain margin of error. The proportionality test as such must be seen in relation to these inherent flaws within measuring effectiveness of the law on society. Often, causality between the measure and the aim can and will not be ‘proven’ scientifically by the legislature and the Court. Nevertheless, the proportionality principle has been a corner stone of European Law to analyze the effectiveness and necessity of legislation. Further enhancement of the execution of this principle by improving information about societal effects increases the democratic legitimacy of European Union law. Therefore, this thesis recommends the European Commission to enhance information about effects. This can be done to improve the measurement of (the expectation of) effects before and after the adoption of the law. These recommendations can be used for improving European laws in general and the PDPR and PCD in particular. Before the adoption of the law, a reasonable expectation of effectiveness should be provided by the Commission. This entails the operationalization of measurable aims, the separation of non-measurable aims and a substantiated expectation of causality between the law and the aims. This thesis recommends to operationalize aims that are in essence measurable. For instance, the perception of personal data control by European citizens can be measured. Another option is to use a proxy. The amount of personal data security breaches serves as a proxy for the aim of personal data control. Fundamental rights that are associated with the aims of the legislation, such as the freedom of speech and the freedom of expression, have an intrinsic value, which cannot be operationalized. These important non measurable aims should be included separately as informative input for a democratic legislative decision making process. An effective consideration of the democratic decision making process necessitates an extensive overview of potential negative effects as well. To provide a reasonable expectation of effectiveness, an extensive study of the expected effects is recommended by means of academic literature, secondary available comparative (quantitative) analysis and expert interviews. This threefold approach, adhered in this thesis, has enhanced the knowledge about expected effects and requires further development and a wider application. As a result, a conceptual framework clarifies the effects to enhance the decision maker’s information. Before the introduction of the law, the increased information about expected positive and negative effects and non-measurable aims allows for a more enhanced discussion about the desirability of the legislation. Ideally, the expected effects of the measurable part of the legislation will be quantified in order to clarify and structure the discussion about the desirability of the law. Consequently, the discussion solely concerns normative choices about the balance between non quantifiable effects with the sum of the measurable positive effects and negative effects. After the introduction of the law, the central registration of breach notifications, surveys about the perception of the effectiveness of the law and the registration of relevant proxies are key tools to empirically measure effectiveness.","","en","master thesis","","","","","","","","","Technology, Policy and Management","Policy, Organization, Law and Gaming","","","",""
"uuid:7a7feef2-a8f6-41ac-9e24-88451f612ec3","http://resolver.tudelft.nl/uuid:7a7feef2-a8f6-41ac-9e24-88451f612ec3","Design of a Force Measurement Table, providing objective force feedback during arthroscopic training on cadaver specimen","Wulms, P.H.L.M.","Dankelman, J. (mentor); Tuijthof, G.J.M. (mentor)","2013","To improve arthroscopic skills, orthopaedic residents train on medical simulators and cadaveric training courses. Some medical simulators provide feedback while cadaveric specimen offer the most realistic training environments. Providing objective feedback while training on cadaveric specimen will be an major improvement to the cadaveric training courses. The goal of this project is to develop a system that allows for objective force feedback during arthroscopic skills training on cadaveric specimen. To accomplish this we follow three basic steps: an analysis of the procedure is made, a theoretical model is developed, and from multiple concepts a 6DOF force sensor method is chosen. We developed a 6DOF force platform Force Measurement Table (FMT), which measures forces and torques in the range of 0-750N, with an accuracy of ±0.32N. The FMT was calibrated, and has proven to be able to distinguish between two statically provided independent forces. A pilot study with two intermediates showed a significant difference between the average forces exerted by the arthroscope (2.4 ±1.2N) and by the instrument with arthroscope (4.5 ±2.4N). This difference in force deviations indicates that the highest loads are mostly exerted by the probing instrument. The technology of the FMT shows high potential for the use of force measurements during cadaveric training courses. For exact dynamical measurements, an accurate tracking system can be to be added to the FMT.","arthroscopy; froce; cadaveric specimen","en","master thesis","","","","","","","","2013-09-11","Mechanical, Maritime and Materials Engineering","BioMechanical Engineering","","BMD","",""
"uuid:70564add-7afa-49fb-ae70-bf60137c6553","http://resolver.tudelft.nl/uuid:70564add-7afa-49fb-ae70-bf60137c6553","Kim's Cookies: Finding brand relevance in the cookie market","Goedegebuure, K.D.","Sääksjärvi, M.C. (mentor); Dehli, S.R. (mentor)","2013","Brand relevance theory by David Aaker (2011) was used to set up a cookie brand called Kim’s Cookies. The main objective for this cookie brand is to challenge the rigid market that is dominated by the big brands, by starting a new category. According to Aaker (2011), brands can reach relevance by following 4 steps: (1) create a new category, (2) market analysis to find competitors, (3) create differentiation for preference, (4) evaluation­. These steps were visualized in Figure 1, on page 10. A step 0 was added to the process, since the theory requires a brand and market that had not yet been created. In step 0, a setup for the Kim’s Cookies brand was made, including a logo, brand description and a kind of cookie. The brand was focused on the values ‘homemade’ and ‘happiness’ and on a young female target group. The first setup of the brand was assessed in four different tests, resulting in useful recommendations for the redesign of the cookies, logo and the brand. This information was used to optimize the brand story and the logo in step 3. Another part of this step was the creating of an extended brand relevance model based on theory of brand relevance. This model includes 8 criteria used to evaluate the final concept: visibility, time, emotion, people, risky, original, value and winner. The criteria from the extended relevance model were also used in a creative way in step 1, where the model provided input for generating 13 possible new categories for creating brand relevance. In the second step, the list of criteria was finalized by the addition of criteria set by the vision and the market analysis. In the vision, the most important aspects found were a passion for baking, homemade, personal, sharing and stories. One of the most important aspects of the market analysis was that brand relevance is not reached by selling cookies that are good for environment, people and/or animals. It is still important to sell products that have those qualities, but not as a main point of relevance. Another important conclusion from the market analysis was that the big supermarket brands have a very strong position and do not allow any competitors to enter the shelves. Other cookie brands are trying to grow using different channels in order to be able to compete. In the third step, the final category for relevance is chosen to be sharing homemade happiness. This category is strong, because no other cookies in the market are truly homemade, nor provide actual happiness by connecting people. Sharing homemade happiness is realized by the concept of Kim’s Cookies Kitchen: a place where people can come to bake together in workshops and real homemade cookies are sold. The brand was redesigned to communicate 5 important elements: happy baking by sharing smiles, perfect by imperfections, fresh = better recipes, the power of the personal touch and unique stories. The logo of Kim’s Cookies was changed to match the homemade look, within the boundaries provided by the research in step 0. In the last step, the concept and category were evaluated based on a business plan and a last research study. The business plan indicates a positive NPV after 5 years of business. The main problem is finding a way to get start up money to start the business, since it takes a large investment to get started. The brand, logo and concept were found to communicate the right associations and to focus on the right target group. Future descriptions of the concept should always contain the measures taken by Kim’s Cookies to guarantee the hygiene and quality of the cookies. The only change made to the concept based on the test was an increase of the price of the cookies and a slight decrease of the workshop price. Based on this project, it is recommended to look into the business plans of the other concepts to find whether they lead to similarly high investments, or might be easier to start with. Also, the possibilities of the brand relevance model could be explored, since it was so useful in this project. In order for Kim’s Cookies Kitchen to provide the full experience to its customers, the packaging, store and service design should be designed to enhance the values from the category and brand. Several recommendations are provided for each of these elements.","brand relevance; cookie; food; brand design; kitchen","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product Innovation Management","","","",""
"uuid:97e73e35-b65a-4b2c-ac7b-55b97dd15c8d","http://resolver.tudelft.nl/uuid:97e73e35-b65a-4b2c-ac7b-55b97dd15c8d","WOWK: Design of a product to provide better control for Chinese stir-frying","Zhang, Y.","Van Boeijen, A.G.C. (mentor); Henze, L.A.R. (mentor); Hoonhout, H.C.M. (mentor)","2013","This report described the process and results of an Integrated Product Design graduation project that was carried out in the Human Interaction & Experience department of Philips Research Eindhoven. The design process has resulted in a product concept that provides homemade stir-frying by applying induction heating technology. The target market is the G&S group in China. This project started with applying heating technology in a proper way. The core idea is keeping heat speed with using high temperature, but without burning the food. At the beginning, there were two design directions which were proposed to realize this idea: stir-frying and food re-heating. An external analysis has been made, followed by a qualitative user research. The design direction stir-frying has been chosen to develop further. Stir-frying provides a clearer and structured usage context and it is an essential part in Chinese cooking. People were experiencing several practical problems in stir-frying cooking, like oil splashing, smoke generating, hard to control the temperature, etc. The design vision has been identified according to this part of the study, which was summarized as ‘bring chef feeling into home cooking, by providing better control to deliver good quality food’. As stated in the design vision, chef, control and quality became the three key words. Based on the previous analysis, five key design issues have been identified to generate ideas: environment, smoke and oil splashing, oil temperature, heating elements and interaction and communication. In order to integrate related solutions into one product, a function analysis has been made to summarize the main functions and sub-functions of this product. Considering social-cultural, technology and usability aspects, three concepts have been proposed. A quantitative questionnaire research has been conducted to evaluate these three concepts with users. The concept which contains a round bottom wok has been selected. The indication of wok temperature and anti-splashing lid these two add-on functions have also been included in the design. By combining the suggestions from the questionnaire research and designer’s own knowledge, the preliminary design WOWK has been proposed. The design was evaluated in a domestic kitchen by means of a 1:1 scale prototype. Ten participants were invited to simulate the cooking process of a recipe and gave their opinion of the product based on the product. Generally, the design got positive feedbacks; especially the appearance was quite attractive. The results suggested making some improvements on the control panel to promote the usability of the product. However, other concerns about market positioning for this product has also been mentioned. This needs a longitudinal study in future.","stir-frying; user experience; kitchen appliance; Chinese market","en","master thesis","","","","","","","Campus only","2014-08-23","Industrial Design Engineering","Industrial Design","","","",""
"uuid:8ce66c05-0176-42be-94e6-65648baf1e39","http://resolver.tudelft.nl/uuid:8ce66c05-0176-42be-94e6-65648baf1e39","A Brand & Product Development for High Performance Bodyboarding, on the harsh Atlantic Coast of Ireland","Smith, A.","Sonneveld, M. (mentor); De Lille, C. (mentor)","2013","The project is centered around the creation of a brand whose identity represents the unique character of the Irish Atlantic explorers. This group is not bound by a style or a fashion, but by a deep and honest connection to the raw and wind battered beauty of nature on the Irish Atlantic Coast. They are the tussock lead pioneers of empty, freezing barrels. They are bodyboarders of extreme powerful waves. The product development is a luggage solution for these bodyboarders, that takes into consideration their travel habits on airlines, on surf missions, and on the hikes and treks to the undiscovered harsh miracles of Atlantic waves.","bodyboard; travel; branding; prototyping","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Integrated Product Design","",""
"uuid:cd2f0f79-8d81-4c09-9e98-6fafde951b5b","http://resolver.tudelft.nl/uuid:cd2f0f79-8d81-4c09-9e98-6fafde951b5b","ARTEP: A 3D model that uses augmented reality technology to help resident surgeons in training inguinal hernioplasty following the totally extraperitoneal approach","Van Vliet, R.W.","Goossens, R.H.M. (mentor); Kleinrensink, G.J. (mentor); Hajian, M. (mentor)","2013","This thesis describes the process and results of the development of an inguinal hernia training model given the name ARTEP. ARTEP is a physical model that represents the human anatomy of the groin region in an abstract way. Prospective doctors, or residents, can use this model to specifically train a proven to be difficult minimal invasive inguinal hernia repair procedure: laparoscopic hernioplasty, following the Totally ExtraPeritoneal approach, referred to as TEP. TEP is currently one of the most frequently applied techniques for minimal invasive inguinal hernia repair, preferred over conventional open repair because of improved recovery time for the patient. Residents currently have the opportunity to practice this procedure on training models, simulators and human cadavers however their availability is limited and the costs involved are high. Most residents therefore perform their first actual practice on a living patient, while having limited knowledge of procedure and with limited experience in the use of laparoscopic instruments. ARTEP provides the user with a physically correct representation of the human anatomy which enables residents to train the most important aspects of the TEP learning procedure: recognition of the structures and landmarks, movement of laparoscopic instruments and manipulation of structures in the preperitoneal space, training the hand-eye coordination of 2D feedback provided by the display while doing a 3D manipulation of the laparoscopic instruments and placement of the hernioplasty mesh. Additionally, ARTEP uses augmented reality to teach the user important aspects regarding the structures which are part of the anatomy of the groin region. This is done with the help of the currently available Aurasma application which can downloaded on most smartphones and tablets. During training the Aurasma application provides a realistic representation of the structures. Additional learning features are available for residents to learn the names of these structures and possible risks involved in wrongly manipulating these structures. Doing so, preparing their knowledge for surgery on living patients. To develop ARTEP information was gathered on the theory of development of surgical knowledge and skills and existing methods for training residents, known as tactile kinesthetic learning. The development of ARTEP from idea to working prototype is fully described in the thesis, finalizing with a proposition for market introduction as well as recommendations for further development.","ARTEP; augmented reality; hernioplasty; inguinal hernia; TEP","en","master thesis","","","","","","","Campus only","2014-08-23","Industrial Design Engineering","Applied Ergonomics and Design","","Medisign","",""
"uuid:6b5825b0-76b2-4a08-b84a-807060a9556f","http://resolver.tudelft.nl/uuid:6b5825b0-76b2-4a08-b84a-807060a9556f","High resolution reservoir characterisation in the Troll West Gas Province","Ogg, W.","Petersen, S.A. (mentor); Luthi, S.M. (mentor); Weltje, G.J. (mentor); Donserlaar, M.E. (mentor)","2013","Just like many other shallow marine fields, the Troll field is steadily increasing its recovery factor by performing an extensive infill drilling procedure. Well planning requires an ever increasing knowledge of the geological and sedimentary characteristics of the field, as higher drilling precision demands a more detailed reservoir model. The most important reservoir units of the Troll field consist of a stacking of shallow marine sand- and siltstones that were deposited in an asymmetric coastal spit system. The spit system consists of progradational surfaces including clinoform structures that contain heterogeneous and complex sediment accumulations which are difficult to map in the subsurface. A thorough literature investigation into the characteristics of asymmetric delta spit systems, clinoform deposition and the Troll geological history forms the basis of a new method to model the heterogeneous sediments in the field. Seismic interpretation and well log correlation between the many multilateral wells are used as input for the model. The model itself is built in the Compound Earth Simulator, a software package developed by Statoil’s research department. Using the Compound Earth Simulator, the sediments (logs and seismics) are brought back to their time of deposition with a backward time engine. The undeformed nature of the sediments at time of deposition makes it possible to find better correlation between the different wells, resulting in the construction of a high resolution sediment distribution. A forward time engine then brings the sediments forwards through time to their present day situation, in which all complexity of deformation is present again, but the high resolution sediment characteristics are still visible as well. The construction of synthetic seismics and virtual well logs show a quality check of the modelling procedure. The Compound Earth Simulator and the presented method offer a fast and easy routine to improve the modelling detail of a field by introducing a high resolution reservoir characterisation in problem areas. The results of the procedure show that the clinoform progradation direction in the Troll field is more heterogeneous than described in earlier work. For multiple parasequence in the specific area of interest within the field, the main progradation happens towards northwest or north, which is contradicting the earlier described west to southwest build-out direction that corresponds to the longshore current direction. Multiple possible explanations for this observation are presented. The concluded heterogeneities may be taken into account during future geomodel updates. The high resolution reservoir characterisation can moreover be used for well planning and drilling purposes. As the most important result, the method that is developed in this thesis may be used to create a high resolution reservoir characterisation in other parts of the Troll field or other fields as well.","reservoir characterisation; clinoform progradation; well logs; Compound Earth Simulator","en","master thesis","","","","","","","","2015-08-23","Civil Engineering and Geosciences","Geoscience & Engineering","","Applied Geology; Reservoir Geology","",""
"uuid:b893cf1a-df8f-4574-8565-aca686ab2aaf","http://resolver.tudelft.nl/uuid:b893cf1a-df8f-4574-8565-aca686ab2aaf","Using surface-related multiple reflections in illumination studies: A case study based on ray tracing","Scharpf, B.J.","Van Borselen, R.G. (mentor); Baardman, R. (mentor); Wapenaar, C.P.A. (mentor)","2013","Throughout the history of exploration for hydrocarbons, illumination and imaging in structurally complex geology with high-velocity contrasts has been a challenge. Recently introduced technological innovations such as dual-sensor streamers towed behind seismic vessels, provide new means to tackle these problems. Separating wavefields into upgoing and downgoing constituents triggered new, unconvential ways in imaging such as Seperated Wavefield imaging (SWIM). Given the new possibilities, phenomena like surface-related multiple reflections, which have alway been treated as noise in conventional processing, emerge interest treated as useful signal. Within this transition, however, their contribution to subsurface illumination is yet unclear. Using survey design and ray tracing softwares, forward modelling of acoustic wave propagation is carried out in a complex geologic model incorporating varying velocities of the sedimentary overburden and a salt pillow. Distinct surface-related multiple reflections from 1st to 3rd order are defined to investigate their contribution in illumination of a subsalt target which is compared to the illumination of primary reflections. Different seismic vessels were defined being part of the classical NATS versus a modern WATS acquisition geometry. After an enhanced illumination study, the ray tracing results suggest that incorporating the defined 1st to 3rd order surface-related multiple reflections illuminating the subsalt target partially fill illumination gaps left by primary reflections, can replace a dual azimuth NATS survey which considers primaries only, greatly infill subsalt illumination gaps using WATS and can replace a WATS survey using primaries only, if they are treated as signal in a NATS survey.","ray tracing; illumination study; surface-related multiple reflection; wavefield separation; dual-sensor streamers; NATS; WATS; salt; nucleus+; Norsar3D; primaries vs. multiples","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","IDEA League Joint Master in Applied Geophysics","",""
"uuid:8b0be8ed-93ac-4be0-8433-856d6e03179a","http://resolver.tudelft.nl/uuid:8b0be8ed-93ac-4be0-8433-856d6e03179a","ARTEP: A 3D model that uses augmented reality technology to help resident surgeons in training inguinal hernioplasty following the totally extraperitoneal approach","Van Vliet, R.W.","Goossens, R.H.M. (mentor); Kleinrensink, G.J. (mentor); Hajian, M. (mentor)","2013","This thesis describes the process and results of the development of an inguinal hernia training model given the name ARTEP. ARTEP is a physical model that represents the human anatomy of the groin region in an abstract way. Prospective doctors, or residents, can use this model to specifically train a proven to be difficult minimal invasive inguinal hernia repair procedure: laparoscopic hernioplasty, following the Totally ExtraPeritoneal approach, referred to as TEP. TEP is currently one of the most frequently applied techniques for minimal invasive inguinal hernia repair, preferred over conventional open repair because of improved recovery time for the patient. Residents currently have the opportunity to practice this procedure on training models, simulators and human cadavers however their availability is limited and the costs involved are high. Most residents therefore perform their first actual practice on a living patient, while having limited knowledge of procedure and with limited experience in the use of laparoscopic instruments. ARTEP provides the user with a physically correct representation of the human anatomy which enables residents to train the most important aspects of the TEP learning procedure: recognition of the structures and landmarks, movement of laparoscopic instruments and manipulation of structures in the preperitoneal space, training the hand-eye coordination of 2D feedback provided by the display while doing a 3D manipulation of the laparoscopic instruments and placement of the hernioplasty mesh. Additionally, ARTEP uses augmented reality to teach the user important aspects regarding the structures which are part of the anatomy of the groin region. This is done with the help of the currently available Aurasma application which can downloaded on most smartphones and tablets. During training the Aurasma application provides a realistic representation of the structures. Additional learning features are available for residents to learn the names of these structures and possible risks involved in wrongly manipulating these structures. Doing so, preparing their knowledge for surgery on living patients. To develop ARTEP information was gathered on the theory of development of surgical knowledge and skills and existing methods for training residents, known as tactile kinesthetic learning. The development of ARTEP from idea to working prototype is fully described in the thesis, finalizing with a proposition for market introduction as well as recommendations for further development.","ARTEP; augmented reality; hernioplasty; inguinal hernia; TEP","en","master thesis","","","","","","","Campus only","2014-08-23","Industrial Design Engineering","Applied Ergonomics and Design","","Master specialisation Medisign","",""
"uuid:7fdba46a-70e7-49f4-94a3-986f53c934e2","http://resolver.tudelft.nl/uuid:7fdba46a-70e7-49f4-94a3-986f53c934e2","Instituitions and Venture Capital: A cross country analysis on OECD countries","Singh, K.","Kleinknecht, A. (mentor); Storm, S. (mentor); Enserink, B. (mentor)","2013","Small and Medium Enterprises (SMEs) form the backbone of any economy. However, access to finance remains a key contraint to SME development and thus economic development. The Venture Capital industry has proved to be a good alternative source of financing in some countries to promote innovation and entrepreneurship. Having originated in the USA (a market based economy), it is catching up in Europe particularly in Scandinavian countries through numerous policy initiatives taken by the national governments. However, most continental European economies are traditionally bank-based and the venture capital industry has not been as successful (atleast in the last two decades) compared to USA. Past research in the field attributes this difference in performance to numerous factors but none that provides a detailed and in-depth institutional basis to it. This thesis attempts to find if the venture capital industry is more successful in a particular institutional environment or more specifically a particular kind of economic system.","Institutions; Innovation; Venture Capital; Financial Structure; Small and Medium Enterprises","en","master thesis","","","","","","","","2013-08-09","Technology, Policy and Management","Economics of Innovation","","Engineering and Policy Analysis","",""
"uuid:8857dc28-64a0-4b83-b4cd-e7d8274302a1","http://resolver.tudelft.nl/uuid:8857dc28-64a0-4b83-b4cd-e7d8274302a1","Assessing existing structures: Assessment protocol for the identification of structural possibilities developed for multi-story industrial heritage constructed with reinforced concrete between 1910 and 1950 in the Netherlands","Florisson, S.","Nijsse, R. (mentor); Pasterkamp, S. (mentor); Braam, R.C. (mentor); Van der Horst, A.Q.C. (mentor); Morri?n, J.J. (mentor)","2013","The focus of this thesis research was on developing an assessment protocol which assists the structural engineer in visualizing the structural possibilities for multi-story industrial heritage constructed between 1910 and 1950. The protocol distinguishes seven assessment steps which can be used to (1) indicate the material and structural quality (2) visualize the structural design possibilities and (3) assess the structural safety. The systematic approach introduced by the protocol stimulates a faster and more efficient determination of the comprehensive capabilities of the concrete load bearing frame. The protocol is developed from the context of integrated designing, giving the structural engineer an independent role in the redevelopment process. The individual assessment steps [the historic assessment, the visual assessment, the technical assessment, evaluation, the preliminary assessment, the [refined] structural safety assessment and the strenghtening assessment] are provided with current knowledge and trends available for the assessment of existing reinforced concrete structures. These steps are subjected to constant change and development. The structural engineer is therefore encouraged to supplement the protocol with experience gained during projects, and with future developments. The engineer is recommended to follow the assessment steps as proposed by the protocol. In cases where this is not possible the engineer should use the protocol to formulate a targeted assessment strategy, which minimizes the influences of the obstructed process. The protocol will provide the information, but requires the motivation and capabilities of the engineer to come to the desired results. QUALITY The first four assessment steps are designed to assist the visualization of the structural and material quality. The steps are focussed in gathering a sufficient amount of information to prevent unexpected situations in the construction or execution phase. The engineer should be aware that in the design of new buildings the information produced on paper will be realized, whereas in the situation of redesigning existing buildings what is realized should be put on paper. The information that is needed to estimate the remaining life span and to perform the structural safety assessment can only be found insitu. In some situations also design information can be found in the original document, but the engineer should be aware that his information always brings a certain level of inaccuracy and uncertainty. The first assessment step is the historic assessment which helps the engineer to collect a sufficient amount of original documentation [architectural design, structural design, reinforcement design, foundation etc.] to visualize the quality and characteristics of the load bearing system. The assessment step is substantiated by a historic database which informs the modern structural engineer about the material and structural characteristics of historic concrete. This concept is introduced to bridge the knowledge gap between past and present and eliminate possible risks occurring from this gap by visualizing the differences in material durability, and provide structural information to clarify the original documentation or when no original information is available to substantiate the making of assessment assumptions. The quality assessment of materials and structures is time consuming, expensive and difficult when performed into detail. The structural engineer is therefore challenged to formulate a targeted and efficient approach without compromising the desired information. To stimulate this process the protocol introduces at the end of the historic assessment a general strategy which helps to formulate the desired and required input and output regarding the visual and technical assessment. The visual assessment stimulates the engineer to visualize the structural and material quality in-situ, by proposing a visual inspection towards deterioration and the optical verification of the original drawings. The assessment V step also provides a description of the non-destructive measuring techniques which can either be used to verify certain forms of deterioration or to verify the test results found with the technical assessment. At the end of the visual assessment the engineer is granted the possibility to take concrete and steel samples for additional research to be performed in the laboratory to indicate, the mechanical properties, the cause of deterioration or to estimate future deterioration. The protocol provides an estimate of the required research pool, and the considerations which have to be taken into account when estimating the sample location. The technical assessment step provides the structural engineer with a general introduction on the different laboratory tests, and their specifications. The quality assessment is completed by introducing the evaluation step, which provides the structural engineer with the general methodology for reinforced concrete repair and protection. This methodology points out the importance for conservation, and a durable and compatible approach. The assessment step also provides a list with the general methods that can be used for repair and protection. DESIGN POSSIBILITIES The identification of the quality and the visualization of the structural design is the basic input of the preliminary assessment stage. This stage is focussed on generating structural redevelopment concepts based on a pragmatic approach, and from the context of integrated designing. This process stimulates the designer’s creativity in visualizing the structural possibilities with respect to functional change. The success of redevelopment seen from a structural perspective depends on the aspects of structural flexibility, the structural adaptability, the relation between building and user, and the standard redevelopment criteria [climate, day light entrance, emergency routing etc.]. To stimulate the successful integration of these design aspects into the redevelopment, the engineer is advised to use a morphological overview. Such an overview gathers the different structural aspects and combines them with possible structural redevelopment alternatives. The overview facilitates the making of combinations, generating redevelopment concepts and to rerun the design steps in a later stadium of the process. As a last note, the preliminary assessment recommends the engineer to generate the structural concepts from the concept of durable and sustainable design. The sustainable perspective requires the engineer to design with an eye on the future, whereas a durable design minimizes the need for functional change in the future. STRUCTURAL SAFETY The safety assessment of existing structures is different than the safety assessment for new structures. The differences can be found in the required aspects of the limit state design, and the considerations towards the structural reliability, the fire safety and the capacity estimation. The [refined] structural safety assessment visualizes the options regarding these different subjects, and clarifies their influences. The assessment stage also gives a general introduction on the methodology influencing the in depth detailing of the calculations and their reflection onto the desired results. In some situations the functional requirements exceed the bearing capacity of the load bearing structure. In such a case strengthening could be an option to improve the chances on redevelopment. Therefore, as last assessments stage the strengthening assessment is introduced. This assessment step visualizes the methodology towards estimating the required strengthening in respect to the ultimate and serviceability limit state design, and gives a general introduction on the strengthening methods available on today’s market.","","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Structural Design","",""
"uuid:47957f9e-8ee2-4c00-9cb8-9bbd49b7c7f9","http://resolver.tudelft.nl/uuid:47957f9e-8ee2-4c00-9cb8-9bbd49b7c7f9","Kinetics of Wüstite Formation and Reduction of Manganese alloyed Steel","Xu, J.","Sloof, W.G. (mentor)","2013","The oxidation and reduction kinetics of a 1.7 wt.% Mn steel alloy with 0.1 wt.% C was studied in different ?CO?_2/CO mixtures and at different temperatures. The external iron oxide growth, the internal alloying element oxide formation and the reduction of iron oxides were observed with thermogravimetry (TG). The oxidation at 750 ? follows a logarithmic growth rate law, which suggests that transport of electrons from the metal through the oxide determines the kinetics. However, the oxidation rate of a linear growth at 950 ? obeys a linear growth rate law, which suggests that the dissociation of ?CO?_2 into CO and adsorbed oxygen atoms or ions determines the kinetics. The kinetics of the reduction of external iron oxide by hydrogen follows a First-Order model. A Wüstite scale with internal Manganese oxide was formed during the thermal oxidation in different ?CO?_2/CO mixtures. After reduction with H_2at 950 ?, an iron layer with internal Manganese oxide was obtained at the surface of the steel. The depth of the internal Manganese oxide zone increased during the reduction.","manganese alloyed steel; oxidation; reduction; kinetics","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Materials Science & Engineering","","","",""
"uuid:f4895b17-bfe4-4bfa-9f7d-b6cb27c3ed35","http://resolver.tudelft.nl/uuid:f4895b17-bfe4-4bfa-9f7d-b6cb27c3ed35","Strategic advice for Gotcha’s design of new pantograph monitoring modules","Palazzo, F.","Santema, S.C. (mentor); Kester, L. (mentor)","2013","This project was commissioned to investigate and assess the market potential of Gotcha’s new modules for pantograph monitoring and to deliver strategic advice on how to turn them into commercially successful products. The problem was tackled by carrying out an analysis of the internal and external environments and by conducting an in-depth interview study to define what the modules’ strengths and weaknesses are in relation to the customers’ point of view. Since the modules have been pushed from the inside, the main objective of the research was to evaluate the alignment between the company’s offer and the demand of the customer. The results of the environmental analysis and qualitative study draw attention to the fact that the two modules differ from each other in terms of product launch readiness. The Uplift module is not ready for launch. This is because it suffers from three main aspects that collide with the customers’ needs: high installation efforts, high maintenance costs and unconvincing measurement technique. These three aspects go against the interests of the module, making it appear problematic to the eyes of the customers. The Strip wear module, instead, is ready for roll-out. Its design and technological edge allow this module to enter the pantograph monitoring market, take advantage of being an early mover and capitalise on the fact that the monitoring of pantograph is a new, big and growing market. Accordingly, the report provides Gotcha with an alternative design proposal for uplift measurements to overcome the pitfalls implied by the current solution. The proposal is based on high-speed camera technology that allows the system to work and be maintainable without interfering with the traffic operations. Differently from the current solution, the new system is entirely placed wayside. This characteristic makes the new system more suitable for sales and gives it a significant advantage over direct competition. The report also provides Gotcha with a market introduction plan for the Strip wear module. The newness of the product category and the early stages of the product life-cycle call for growth, market penetration and targeting of existing customers. Further product development, low price, increased customer awareness and product exposure gain are further elements of this plan. The major changes regarding the future of pantograph monitoring concern integration. Heading towards measurements and systems integration is therefore recommended.","strategy; design; marketing; consulting; transportation; rail industry","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Product Innovation Management","","Master of Science Strategic Product Design","",""
"uuid:65126b21-0c01-4ac5-987c-0fe5cb7dc63f","http://resolver.tudelft.nl/uuid:65126b21-0c01-4ac5-987c-0fe5cb7dc63f","Helix, a new outdoor sports toy","Van Wijk, B.C.","Van Heur, R.J.H.G. (mentor); Christiaans, H.H.C.M. (mentor)","2013","Helix is a new outdoor sports toy designed to get children moving again. Digital devices such as tablets and phones have a lot of attraction on kids, but during the summer they still like to play games like badminton and beachball. Badminton and beachball each have their drawbacks however. While badminton is easy to learn and play, if there is a bit of wind this will affect the game. On the other hand, beachball does not share this drawback but is significantly harder to play. Children are often only able to pass the ball back and forth a few times. The new game, called Helix, offers a middle ground between these games. It is based on a traditional Chinese game and uses two wooden paddles to hit a shuttle with three feathers. This game has been redesigned so that it suits launch in a western market and can be mass-produced. A new shuttle, paddle and brand identity were designed for the game. Helix is easier to play because the shuttle slows down after flying a while through the air. This ensures the shuttle is easier to hit because its horizontal speed reduces as it nears the other player. And like a badminton shuttle, it always aligns with the head forward. The product has a specially designed foot to hold the three blades at an angle. The angle creates a force that causes the projectile to spin, this further stabilizes the shuttle’s flight. The blades can be changed according to difficulty, proficiency or amount of wind. They can be swapped by the user to match the circumstances.","outdoor; sports; toy; shuttle; paddle; brand","en","master thesis","","","","","","","Campus only","2014-08-23","Industrial Design Engineering","Industrial Design","","Master of Science Integrated Product Design","",""
"uuid:e1f92542-2c1a-4bd9-81ce-0ad3279a7958","http://resolver.tudelft.nl/uuid:e1f92542-2c1a-4bd9-81ce-0ad3279a7958","A showcase of impact: The social innovation story of Kennisland","Muryani, M.","Stappers, P.J. (mentor); Manschot, M. (mentor); Sleeswijk Visser, F. (mentor)","2013","Social innovation is a term used describe the process of designing and developing creative solutions to address the pressing unmet social needs. Kennisland is among a few organizations who does social innovation in its scope of work. Kennisland needs to showcase the results of their social innovation to tell the public about the benefits of social innovation and the value of Kennisland, but the results are abstract and invisible because the problems are big and complex. However, Kennisland results are not that invisible. The results are already there, materialized in the personal stories of Kennisland's partners, funders, or users. Thus a tool is created to capture these personal stories. Kennisland and its partners/ funders/ users can use the tool to co-write, co-visualize, co-review, and publish the stories together. The story is written with a storytelling approach, using elements such as: setting/ context, characters (who are involved), problems (what problem is it trying to address), the beginning (how the project starts), the turning point (what kind of innovation is done), and the end (what have been changed, or what have been learned by both parties). Besides showing the benefits and values of social innovation and of Kennisland, these stories also serve as the evaluation and reflection tool for the parties involved to evaluate and reflect on the innovation process.","social innovation; sociale innovatie; kennisland; co-creation; storytelling; participatory design","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Design for Interaction","",""
"uuid:bfea58b0-f410-4eef-a94d-7eca89bbd059","http://resolver.tudelft.nl/uuid:bfea58b0-f410-4eef-a94d-7eca89bbd059","Turbulence Modeling for Heat Transfer to Supercritical Pipe Flows","Patel, A.","Pecnik, R. (mentor); Nemati, H. (mentor)","2013","In the present work, a comprehensive review on different mechanisms affecting heat transfer characteristics of supercritical flows is carried out. The physical mechanism of heat transfer is then further investigated using inhouse DNS data. In addition, RANS simulations of a heated vertical pipe with supercritical CO2 are carried out using conventional low-Reynolds number eddy viscosity turbulence models. The turbulence models are implemented in an inhouse FORTRAN code and validated using canonical cases available in the literature. The performance of the turbulence models is assessed by comparison with the inhouse DNS data. Furthermore, a theoretical framework has been established to take into account the large thermophysical property variations close to pseudo-critical point in the RANS averaged governing equations.","turbulence; turbulence modeling; RANS; supercritical; heat transfer; DNS","en","master thesis","","","","","","","","2014-08-01","Mechanical, Maritime and Materials Engineering","Process and Energy","","Energy Technology","",""
"uuid:9d56fdfb-5f5d-49ec-a35b-578c63e13fed","http://resolver.tudelft.nl/uuid:9d56fdfb-5f5d-49ec-a35b-578c63e13fed","Development of a smart mobile belt conveyor maintenance inspection tool","Kompeer, P.J.J.","Pang, Y. (mentor)","2013","Traditionally companies operating belt conveyor systems carry out their own maintenance inspections. Due to the lack of domain knowledge of the inspectors, maintenance decisions depend on unreliable communications to receive delayed advice. Automation of the visual inspection data acquisition and maintenance decision making should overcome these problems. This study aims to build an automated smart mobile inspection tool. This mobile inspection tool guides the inspector through visual inspection, and makes intelligent maintenance decisions. Developing a smart mobile inspection tool is achieved by integrating ICT-technology, wireless communication technology, artificial intelligence and fuzzy logic. Based on the primary process model of the visual inspection and decision making, a functional division is made in the logical architecture. The resulting three logical sections: data acquisition, data manipulation and data storage are assigned specific functional requirements. Together these logical sections and their data-flows are translated to a physical agent architecture. The physical architecture accommodates the online mobile inspection tool and the intelligent distributed decision making. To achieve intelligent multi-level decision making the process is divided in into sub-tasks. Overlapping the sub-tasks with the physical division of the BCS’s elements ensures appropriate domain knowledge matching to the agents. The smart decision making is achieved by the serializing the sub-tasks over the hierarchical dependency path of the physical BCS parts. Following this path takes the whole BCS maintenance status into account when making the maintenance decision. Developing the smart online inspection tool and its supporting infrastructure, integration of several ICT-technologies is needed. Selecting these technologies is done based on functional requirements and other criteria. The criteria used are specifically defined for the purpose of implementation in this study, to satisfy the objectives of this research. The implementation of mobile inspection tool is illustrated by supporting three uses-cases. Together these use-cases cover all functional requirements necessary to solve common problems in visual inspection. The smart mobile inspection tool is found able to handle these use-cases. This indicates the feasibility and capability of a mobile inspection tool to solve common problems in visual inspection.","","en","master thesis","","","","","","","","2015-08-23","Mechanical, Maritime and Materials Engineering","Marine and Transport Technology","","Transport Engineering and Logistics","",""
"uuid:191c65eb-1516-4b80-9810-6754353ab66d","http://resolver.tudelft.nl/uuid:191c65eb-1516-4b80-9810-6754353ab66d","The application process of fusionbonded epoxy as field joint coating","Kap, G.J.","van den Bos, w (mentor); Heijnen, P.W. (mentor)","2013","Allseas is one of the leading offshore pipeline installation contractors in the business. For the installation of pipes, it uses the so called S-lay method, a method where pipe sections are assembled into a continuous pipeline at the _ring line, on- board the pipe lay vessel. Subsequent stations perform welding, non-destructive testing and coating tasks in this _ring line. Since the founding of the company in 1985, much of the equipment to perform these tasks was designed, developed and built in-house. A lot of effort was put into improving installation time. Allseas and its clients were mainly focused on the welding and NDT testing stations while the coating process drew relatively less attention. In recent years the attention is shifted to the coating stations. There were also signals that on some projects the process time of individual coating stations negatively affected the overall installation time. Although some effort was made in the past to improve the coating process the results were disappointing. The need for reducing overall process times while maintaining coating quality still remains. Therefore Allseas initiated this research, exploring possible changes to the coating process. A preliminary research showed that fusion-bonded epoxy is the most used coating type. Based on that the choice was made to focus the research on the application process of fusion bonded epoxy...","","en","master thesis","","","","","","","","2015-08-23","Mechanical, Maritime and Materials Engineering","Marine and Transport Technology","","Transport Engineering and Logistics","",""
"uuid:100a30f8-3758-42be-b6d4-d22b6a8d75eb","http://resolver.tudelft.nl/uuid:100a30f8-3758-42be-b6d4-d22b6a8d75eb","Creative Policy Generation in Integrated Water Resources Management: A Case Study in the Upper Citarum Basin","Meyer zu Schlochtern, A.N.H.","Van de Giesen, N.C. (mentor); Hoes, O.A.C. (mentor); Hadihardaja, I.K. (mentor); Verhaeghe, R.J. (mentor); Pramana, K.E.R. (mentor)","2013","In the Upper Citarum Basin in Java, Indonesia, the Creative Policy Generation Method was used to study the applicability of the integrated Business Model Canvas (Osterwalder, 2010) and the creation track (Gray, 2010), which is a creative, solution-focused thinking theory. The goal in the Upper Citarum Basin was to create better, safer and more sustainable living conditions for the residents in the basin. The combination of emerging physical issues (flood, erosion, sedimentation, pollution, water scarcity, uncontrolled urbanization and land subsidence), poor living conditions, poor policy execution by the government and generally inflexible, government-reliant communities have caused a degradation of the basin and thus the living conditions. This research focuses on testing the Creative Policy Generation Method for Integrated Water Resources Management in Indonesia. The method incorporates three phases in order to devise alternative policy concepts to solve complex problems in multi-stakeholder settings. The three phases are:  Assessment: Assessing the strengths, weaknesses, opportunities and threats to the physical, institutional and social economic aspects.  Generation: Creating ideas for new policy concepts. These ideas will ultimately be presented in a Business Model Canvas.  Evaluation: Evaluate the policies regarding their strategic value, risks and economical value. During workshops in the generation phase, the issues mentioned above were discussed and alternative policy concepts were generated. This resulted in seven concept policies, which focus on creating solutions in an informal and un-structured manner. By integrating educational and social economic characteristics, the policy concepts require a lower investment and can be tested on a smaller scale. This provides the opportunity to obtain data, learn from this information, alter the concept policies and make them more effective. From the perspective of this study, the Creative Policy Generation Method achieved positive results. It has been proven that business models and creation tracks are applicable in the field of Integrated Water Resources Management, but it has also been found that iterations are needed in the future to optimize this method.","Creative Policy Generation; Integrated Water Resources Management; Citarum","en","master thesis","","","","","","","","2013-08-28","Civil Engineering and Geosciences","Water Management","","Water Resources","",""
"uuid:f43d489f-c53c-4392-824b-e1a8eaebb827","http://resolver.tudelft.nl/uuid:f43d489f-c53c-4392-824b-e1a8eaebb827","An Exploratory Study on Authorship Verification Models for Forensic Purpose","Li, Z.","Van den Berg, J. (mentor); Franssen, M. (mentor); Veenman, C. (mentor)","2013","Authorship verification is one subfield of authorship analysis. However, the majority of the research in the field of authorship analysis is on the authorship identification problem. The authorship verification problem has received less attention than the authorship identification problem. Thus, there is a demand for a study on the authorship verification problem. The authorship verification problem of digital documents is becoming increasingly important as the criminals or terrorist organizations take advantage of the anonymity of the cyberspace to avoid being punished. Thus, it is critical for forensic linguistic experts to come up with effective methods to verify a short text written by a suspect. This master thesis project provides an exploratory study on the authorship verification models to solve the authorship verification problem. The research problem is as follows: Given a few texts (around 1000 words each) of one author, determine whether the text in dispute is written by the same author. The primary objective of this research is to design several innovative authorship verification models to solve the problem described above. A second goal of this research is to participate in the PAN Contest 2013 in the task of authorship verification. This thesis project explores extensively the possibilities of using compression features to solve the authorship verification. Both one-class classification models and two-class classification models are designed in this project. In a one-class classification model, there is only target class, and the decision is based on a predefined rule. In a two-class classification model, there are both target class and outlier class, and the threshold is decided by learning the boundary between the two classes. In total five models have been designed and evaluated, four of which use compression features. Character N-Gram Model is designed in this research to make a comparison of character-grams and compression features. The initial task of this project is the data collection. In order to participate in the PAN Contest, similar data (engineering textbooks from bookboon.com) were collected. In total 72 books written by 51 authors are in the collected corpus. The Book Collection Corpus was derived from the collected book and was used to develop the models. Additionally, an Enron Email Corpus was used to test the performance of one authorship verification model. As a result, the models designed received desirable performances and have shown potential to solve other similar problems.","authorship verification; compression features; machine learning; one-class classification; two-class classification","en","master thesis","","","","","","","","2013-08-31","Technology, Policy and Management","ICT","","Management of Technology","",""
"uuid:83ba6378-0d60-47d3-9fdc-b2ea8c58d9da","http://resolver.tudelft.nl/uuid:83ba6378-0d60-47d3-9fdc-b2ea8c58d9da","Surface Wave Tomography at Exploration Scale","Da Col, F.","Socco, L.V. (mentor); Slob, E. (mentor); Bergamo, P. (mentor)","2013","In this work we present the application of a direct tomographic inversion method, similar to that historically used in global seismology, to exploration scale. We will start with an excursus on the physical background necessary to understand how surface waves propagate and the charachteristics which make these waves suitable for inversion. In the following section the optimal acquisition methods will be described. These are not very different from those for the datasets used for industry-standard reflection seismology imaging; however a few remarks have to be made. For instance, the length of the line, the spacing between receivers and the dominant wavelength are essential parameters to take into account when acquiring a dataset for surface wave analysis. The following section, regarding the processing, will present the most used methods for inversion of surface waves at exploration scale, those at regional (seismological) scale and the method used to perform the inversion. These can be classified into tomographic and non tomographic approaches. In both cases, the aim is to extract phase velocity dispersion curves from the data and invert them to get 1D models. The key difference lies in how the dispersion curves are extracted and the ""meaning"" we give to them. When performing a non tomographic inversion it is possible to extract the curves in many ways, e.g. by computing a Fourier transform in space and time (f-k domain) and pick the curve as energy maxima, as surface waves are the most energetic event in a seismogram. Most commonly, the f-k spectrum is an average one over a certain number of stations. Each of these curves will be inverted to get a 1D model and each of these models can be connected to the others via constraints (regularisation). On the other hand, when one wants to perform tomographic inversion, the dispersion curves are extracted by computing the average slowness of surface waves travelling along a path from one receiver to another, illuminated by the same source. Therefore, since more paths can cross the same model point, more dispersion curves have to fit the model parameters at each model point. Seismologists, at this point, generally compute phase velocity maps from which they extract further dispersion curves to be inverted. What's new in the method used for this work is the fact that we invert dispersion curves, without computing phase velocity maps. This is why it's called ""direct inversion"". This has several positive aspects, e.g. the computational efficiency. Another advantage, common to all tomographic approaches is the fact that it uses only two stations and therefore does not need a dataset with a large number of channels. On the other hand, it has some limitations both on the acquisition parameters (especially offset and distance between the two receivers) as well as the fact that it only inverts for the fundamental mode dispersion curve. Two datasets have been analysed: one shot in New Zealand by ETH Zurich, one shot in the area of Torino by the Italian National Centre for Research (CNR). The first constitutes of five 2D seismic lines, one of which at ultra-high resolution (1m receiver spacing and 2 m source spacing). This dataset has already been inverted using the estabilished multichannel analysis of surface waves method. Therefore, it was a good dataset to start with as results could be compared with those from this previous inversion. The CNR dataset is a small 3D dataset, above an artificially made tank filled with loose sand. The fact that the map of the subsurface was already known made it a good dataset to test the validity of the method also in 3D. In the appendix, we show tests performed on a large 3D seismic survey, acquired in Oman for oil exploration purposes. This dataset is known in the geophysical community (e.g. Gouédard et al., 2012) for having a low signal to noise ratio. Furthermore, the subsurface to be mapped shows strong lateral variations. For this reason, preliminary tests were performed in order to find a method to increase the signal to noise ratio and therefore assess the feasibility of a direct tomographic inversion. A good solution could be to stack the traces from two different sources aligned with the same couple of receivers.","SurfaceWaves","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Applied Geophysics and Petrophysics","",""
"uuid:6efe8629-8482-4cca-9010-d87ff0f19be0","http://resolver.tudelft.nl/uuid:6efe8629-8482-4cca-9010-d87ff0f19be0","Seismic Attribute Analysis of the Upper Cretaceous below the Tambaredjo oil field, Suriname","Roepnarain, R.","Luthi, S.M. (mentor)","2013","The Tambaredjo field is the largest oil field in Suriname. Since 1982 the state oil company, Staatsolie Maatschappij Suriname N.V., has been extracting oil from the Palaeocene reservoir sands. More recently there has been a growing interest in the Cretaceous interval below the reservoir sands. However, not much data is available from this interval. With this study an attempt is made to utilize seismic attributes from a 3-D seismic survey for identifying geological features of interest and predicting lithofacies and their distribution within the Upper Cretaceous below a part of the Tambaredjo oilfield. The approach of this attribute analysis was deterministic. Before extraction of the attributes a literature study was conducted in order to find and select appropriate seismic attributes. These attributes were the calculated in an interval marked by two seismic horizons, the Top of the Cretaceous and second horizon lying 60 ms (two-way-travel time) below the Top of the Cretaceous. Within this interval, flattened (expected) chronostratigraphic slices were created using a Horizon Cube and the Wheeler transform. The calculated attributes were then displayed and analysed along these flattened slices. The analysis of the attributes resulted in the identification of interesting geological features such as channels, which may contain potential reservoir sands. Furthermore using a selection of attributes, a segmentation analysis based on neural networks has been applied. This resulted in clustered areas of comparable seismic responses, which could indicate the distribution of different lithofacies or lithologies.","seismic attribute; Tambaredjo; Cretaceous","en","master thesis","","","","","","","","2015-08-22","Civil Engineering and Geosciences","Geoscience & Engineering","","Applied Geophysics","",""
"uuid:86031a8e-17e4-4f11-93f8-cf9261c82f4c","http://resolver.tudelft.nl/uuid:86031a8e-17e4-4f11-93f8-cf9261c82f4c","Robot-learning using a Tree-based Policy Representation","Zeestraten, M.J.A.","Jonker, P.P. (mentor)","2013","Learning is an important aspect in creating versatile robots. Pre-programming a robot to acquire a wide variety of skills in an ever changing environment is unfeasible. Robot learning provides a promising alternative. Two well-established learning techniques are Programming by Demonstration (PbD) and Learning from Exploration (LfE). PbD and LfE are often combined to strengthen each other. PbD is used because it allows fast learning: with only a few demonstrations, robots are able to reproduce tasks with reasonable performance. After these demonstrations, LfE is used to improve the robot's task performance or to adjust this skills to changing environments. Robots often use continuous mappings between states and actions to represent a skill. Such mappings are called policies and are represented by function approximators. The shape of the policy is determined by the parameters. During learning the robot tries to find optimal parameters for the policy. As the complexity of the skill increases, the number of parameters required to accurately describe the policy for this skill also increases. As the number of parameters increases, the complexity of the solution space increases as well. It is most likely that the LfE algorithm requires more trials to converge for these complex search spaces than simpler search spaces, thus the LfE performance decreases as the complexity of the search space increases. In this thesis a novel multi-resolution policy representation is investigated. The method, called Tree-based policy representation, creates a multi-resolution model based on demonstration data. After this initialization, LfE can use the structure of the Multi-resolution policy to increase learning performance. The method is tested in multiple experimental scenarios. The Tree-based policy representation achieves better learning performance compared to conventional `flat' policy representations, when learning motions that clearly have a multi-resolution aspect. In other cases, the Tree-based movement representation performs equally well or worse compared to standard `flat' policy representations.","","en","master thesis","","","","","","","","2013-09-19","Mechanical, Maritime and Materials Engineering","BioMechanical Engineering","","BMD","",""
"uuid:e8b93961-d531-4eda-b22f-26c1971be72e","http://resolver.tudelft.nl/uuid:e8b93961-d531-4eda-b22f-26c1971be72e","IOCoP Participation: Factors Influencing e-Health Entrepreneurs","Tahvildari, D.","Bouwman, H. (mentor); De Reuver, M. (mentor); Verburg, R. (mentor)","2013","Purpose- The purpose of this study is to Identify the motivational factors that in?uence entrepreneurs to participate in an Inter-Organizational Community of Practice (IOCoP). Design/methodology/approach- An inductive qualitative research design was conducted. Data Collection was based on an in-depth interviews within a sample which is consist of eight e-health start-ups; ?ve Dutch, two Italian, and one Finnish entrepreneurs. Unstructured interviews were designed among entrepreneurs who develop and exploit IT-based health solutions such as assisstive devices, Mobile health, and communication platforms. Through the parallel coding and data collection new concepts emerged that demonstrate the expectations of entrepreneurs from a community participation. The author used the two-stage inductive method in order to develop propositions. In the ?rst stage, through the primary literature review the main research question was created, the primary focus was shaped (using TPB and IOCoP), and accordingly, the interview sample was selected. In the second stage, through the open coding process, and having the research focus in mind, core themes and categories emerged. further more in the second stage the extensive literature review on the emerged concept was conducted in order to compare the categories with existing literature on the concepts. Finally the relationships between categories were de?ned, using the analysis results and the literature. Through out the process new propositions were created for future investigations.","IOCoP; e-Health; Entreprenerus' intention","en","master thesis","","","","","","","Campus only","2013-08-22","Technology, Policy and Management","Information and Communitcation Technolgoy","","","",""
"uuid:8d1551cf-52e0-4f68-ab14-397825b9d3d9","http://resolver.tudelft.nl/uuid:8d1551cf-52e0-4f68-ab14-397825b9d3d9","Surface-wave retrieval using Seismic Interferometry by multi-dimensional deconvolution","De Waard, V.M.","Van Dalen, K.N. (mentor); Ruigrok, E.N. (mentor)","2013","In this thesis, seismic interferometry by multi dimensional deconvolution is used to retrieve the surface-wave response from a virtual source to a receiver by using the observations due to, often passive, noise sources located elsewhere. The virtual source response is used to retrieve the phase velocity, a property used for shallow subsurface velocity models.","MDD; seismic interferometry; surface-wave retrieval","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Applied Geophysics and Petrophysics","",""
"uuid:39b82223-85a9-4308-a9e4-b57dda582191","http://resolver.tudelft.nl/uuid:39b82223-85a9-4308-a9e4-b57dda582191","The construction of a large hydropower project in Costa Rica: A transaction cost approach","Labarca Pérez, P.","Hertogh, M.J.C.M. (mentor); Schoenmaker, R. (mentor); Correljé, A.F. (mentor)","2013","","","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Construction Management and Engineering","",""
"uuid:612b43e4-5574-4c5c-a4e1-6a6d338edb72","http://resolver.tudelft.nl/uuid:612b43e4-5574-4c5c-a4e1-6a6d338edb72","Ceiling of the future","Van Ool, S.G.M.","Mooij, S. (mentor); Valencia, A. (mentor)","2013","The main goal of the project was to come up with a strategic design advice for the ceiling of the future that could extend the success of the EKAT-range of Rockfon Group in 5-10 years from now. The report guides you amongst other things through the company, competition and trends and developments in the building industry. Design directions are the result of these investigations. The report ends with a strategic design advice on how to extend the success of Rockfon Group in the future. The most important data out of this research is that the ceiling of the future is not a product, rather a process in which is accompanied by products. There is no single ceiling of the future product. Society is changing continuously, along with trends and developments. In order to keep up with and meet the needs of the market and their customers, the ceiling of the future is an infinite process characterized by continuous innovation in product development and a new philosophy of involving (young) architects in designing the ceiling of the future. The final advice given in this report is twofold. On the one hand Rockfon Group is offered a series of ideas that form a continuous process which is called the ceiling(s) of the future. On the other hand there is the involvement of architects of the future, which is a long term investment that should be reflected throughout the entire organisation. It is believed that the strategic advice can help Rockfon Group to create a competitive advantage and extend the success of the EKAT-range in 5-10 years from now.","ceiling industry; design strategy; product development; architects of the future; trends and developments","en","master thesis","","","","","","","Campus only","2014-08-22","Industrial Design Engineering","Strategic Product Design","","","",""
"uuid:e98b4e14-4453-4103-9ef1-03f3176ac0c7","http://resolver.tudelft.nl/uuid:e98b4e14-4453-4103-9ef1-03f3176ac0c7","An Energy-Efficient Reconfigurable Interface for Resonant Sensors Based On Ring-Down Measurement","Yan, Y.","Pertijs, M.A.P. (mentor)","2013","This thesis discusses the theory, architecture design, circuit design and measurements of an ultra-low-energy reconfigurable interface circuit for resonant gas sensors. This interface circuit employs a transient measurement method. The resonant sensor is driven at a frequency close to its resonance frequency by an excitation source that is intermittently disconnected, causing the sensor to oscillate at its resonance frequency with an exponentially-decaying amplitude. From the associated ring-down signal, the frequency of the freely-oscillating sensor and its quality factor are obtained by means of a counting technique. A prototype readout circuit that senses the ring-down signal and performs the required level-crossing detection has been fabricated in a standard 0.35-?m CMOS technology. The experimental results obtained using this prototype in combination with samples of micro-machined clamped-clamped beam resonators show good consistency with the resonance frequency and quality factor obtained using conventional impedance analysis. Compared to prior implementations, the realized prototype is less sensitive to leakage currents, enabling a shorter measurement time, and provides a reconfigurable front-end circuit that allows it to be connected to resonators with different parameters. The circuit consumes an energy of 207.9nJ per measurement.","energy-efficiency; sensor interfacing; resonant sensors; reconfigurability","en","master thesis","","","","","","","","2014-09-01","Electrical Engineering, Mathematics and Computer Science","Microelectronics & Computer Engineering","","Microelectronics","",""
"uuid:e07dca5a-da5f-4e97-8a3b-e2a8379836ed","http://resolver.tudelft.nl/uuid:e07dca5a-da5f-4e97-8a3b-e2a8379836ed","Evolving yield curves of sovereign debt issuers for computing haircuts on bond valuations","Budimir, T.","Oosterlee, C.W. (mentor)","2013","Sovereign debt is often used as collateral in derivative trading and repo lending. For risk management purposes the value of the bond is not the market valuation, but rather the market valuation minus a haircut percentage, or simply termed: haircut. The haircut captures the potential risk of the change in value of the bond over a short period of time, usually set at 1,2 or 4 weeks, as it may happen until trading stops or collateral is replaced. In this thesis, we consider examples of the Netherlands and Italy to examine historical valuations of existing bonds to determine the yield curves for these countries. To reduce dimensionality, we interpolate the data using B-splines and project the yield curve onto a three dimensional functional space of so-called Nelson-Siegel curves. The use of Nelson-Siegel curves is wide-spread in central bank yield curve modeling, but to the best of our knowledge the combination of interpolation and projection to Nelson-Siegel curves is original and we compare it to the method of fitting Nelson-Siegel curves directly. For forecasting, the Nelson-Siegel coefficients, representing the level, slope and curvature of the forward curve, need to be modeled which we do with three AR(1) processes. However, the coefficients are correlated and in order to capture this correlation, we model the residuals using the Dynamic Conditional Correlation (DCC) model. For the calibration of the DCC and AR(1) models, we use an iterative procedure which we believe to be novel and has not been reported in literature. Finally, we reprice the government bonds in each forecast scenario. The 95th percentile of value changes within the scenarios is used to determine the haircut for the government bonds. We compare our haircut estimates to those put forward by the Bank of International Settlements.","forward curve; yield curve; haircut; DCC; government bond; Nelson-Siegel; orthonormal projection; B-splines","en","master thesis","","","","","","","","2013-08-22","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","Numerical analysis","",""
"uuid:02336af2-6a7c-4600-b8d4-ec410eceabac","http://resolver.tudelft.nl/uuid:02336af2-6a7c-4600-b8d4-ec410eceabac","Signalized Turbo Roundabouts: A Study into the Applicability of Traffic Signals on Turbo Roundabouts","Hoek, R.M.","Hoogendoorn, S.P. (mentor)","2013","Since the 1980s, the modern single-lane roundabout has been applied in the Dutch road network. The roundabout offered major safety benefits compared to the conventional signalized intersection, however, it also required more space. Influenced by society’s growing mobility, the capacity requirements to intersections increased. This quest for capacity gave rise to the concentric multi-lane roundabout: a roundabout with two or more circulatory lanes and one or more lanes on the entrance and exit legs. The concentric multi-lane roundabout offered a higher capacity, but compromised the safety benefits of the single-lane roundabout. As an answer to the safety problems on the multilane concentric roundabout, Fortuijn developed the turbo roundabout in 1996. The turbo roundabout offers the same safety level as the single-lane roundabout and a higher capacity. Nowadays, the quest for a higher capacity continues unabated. This graduation project aims to contribute to the quest by investigating the combination of turbo roundabouts and traffic lights. The central question is whether traffic signals enhance the capacity of the turbo roundabout. The two largest turbo roundabout types have been investigated: the rotor roundabout (four-leg) and the star roundabout (three-leg). Three models (the MSRV, an analytical approach and VISSIM) have been applied to evaluate the capacity of the rotor and star roundabout (signalized and un-signalized). In addition, this project states proposals for future research into other performance indicators than the capacity; namely space requirement, delay time, robustness, traffic safety and environmental issues. This research shows that the signalized turbo roundabout only allows for a leg-by-leg control. However, the lane configuration on the rotor and star roundabout can be adjusted such, that the turbo roundabout is suitable for the more efficient two-phase control, which is currently being applied to the turbo circle. The results are the partial turbo circle (adjusted rotor roundabout) and the three-leg turbo circle (adjusted star roundabout). The latter intersection types require more space than the rotor and star roundabouts. The capacity evaluation shows that the partial turbo circle has no applicability range, because the capacity for left-turning traffic streams is very limited. The three-leg turbo circle has potential, because it offers a higher capacity than the star roundabout. The geometrical design of the signalized turbo roundabout allows for phase overlap within the leg-by-leg control. Thanks to the phase overlap, two subsequent legs can obtain green simultaneously for a period in the order of 1 to 8 seconds. Consequentially, the aggregated green time within one hour can be extended compared to the leg-by-leg control without any phase overlap, enhancing the capacity of the turbo roundabout. The capacity of the signalized turbo roundabout has been evaluated analytically by means of the analytical approach, which was developed by Fortuijn simultaneously with the development of the turbo roundabout. The analytical approach calculates the capacity by multiplying the green time per hour with the saturation flow. The capacity of the signalized rotor roundabout ranges from 2800 pcu/h to 3700 pcu/h; the capacity of the signalized star roundabout ranges from 4400 pcu/h to 5200 pcu/h, depending on the demand pattern. Using the green phase overlap, the rotor roundabout may offer 5% to 6% more capacity; the star roundabout may offer 7% to 9% more capacity. Moreover, the microscopic simulation tool VISSIM has been applied to evaluate the capacity of and delay time on the signalized turbo roundabout and the (partial and three-leg) turbo circle. The capacity results of the analytical approach and VISSIM do not differ much, except for the results for the star roundabout with an inscribed radius of 20 m. No explanation has been found. In order to compare the capacities of the signalized and the un-signalized turbo roundabouts, the capacity of the un-signalized turbo roundabout has been evaluated by means of the Meerstrooksrotondeverkenner (Multilane roundabout explorer). The un-signalized rotor roundabout offers a capacity ranging from 2900 pcu/h to 4500 pcu/h. The signalized rotor roundabout offers a lower capacity; this intersection type is not recommendatory for application. The same conclusion holds for the partial turbo circle, however, the partial turbo circle offers a higher capacity in situations with low left-turning intensities (in the range of 20% of the straight-ahead intensities). The turbo circle offers a much higher capacity than the (un-)signalized rotor roundabout (ranging from 4700 pcu/h to 9300 pcu/h, depending on diameter and demand pattern), but requires more space. With regard to the three-leg intersections: the capacity of the signalized star roundabout (ranging from 4400 pcu/h to 5200 pcu/h) is larger than the capacity of the un-signalized star roundabout (ranging from 3700 to 5100 pcu/h). However, the signalized star roundabout induces longer delay times (nearly twice as long), and probably less traffic safety and higher environmental burdens. The three-leg turbo circle offers an even higher capacity than the signalized star roundabout (ranging from 5400 pcu/h to 7100 pcu/h), but requires more space. From this study, it can be recommended to pay further attention to the signalized star roundabout and the smaller three-leg turbo roundabouts (both in scientific research as well as in practical engineering), because the signalized star roundabout has a larger capacity than the un-signalized star roundabout. The signalized rotor roundabout and the partial turbo circle are not recommendatory for further research, because the un-signalized rotor roundabout offers a higher capacity.","turbo roundabout; rotor roundabout; star roundabout; turbo circle; traffic signal; capacity; analytical model; simulation model VISSIM","en","master thesis","","","","","","","","2013-08-26","Civil Engineering and Geosciences","Transport & Planning","","Traffic Flow Theory","",""
"uuid:6ce1ce35-079d-4147-8d68-9e13df2e4fa2","http://resolver.tudelft.nl/uuid:6ce1ce35-079d-4147-8d68-9e13df2e4fa2","The urban water cycle: A case study of the Prinseneiland, Amsterdam","Rutten, P.J.P.","Van de Giesen, N.C. (mentor); Van de Ven, F.H.M. (mentor); Hoogvliet, M.C. (mentor); Ten Veldhuis, J.A.E. (mentor); Coenders, A.M.J. (mentor)","2013","Introduction The field of urban water management focusses on managing the (temporary) storages and flows of drinking, waste-, ground- , surface and storm water in urban environments. Adequate water management forms a prerequisite for pleasant living conditions . A difficulty urban water managers face is the limited or complete lack of control over some of the processes in urban areas, such as precipitation, evaporation, etc. Furthermore, the characteristics of an area in which the water needs to be managed forms a semi-fixed condition for the fluxes, as they cannot be manipulated to suit short term water management needs. Structural measures that can be taken in an area to improve the are relatively expensive and are therefore only possible once every (few) decade(s).This means that proposed changes to an area should result in similar or -preferably- improved living conditions for a long period of time. Next to the limited control, two other potential challenges to satisfactory management of water in urban areas are droughts and climate change.In order to be able to predict the merit of proposed measures during current and changed climatic conditions and droughts, more information is required on the possible consequences for the water cycle. Goal The goal of this research is therefore to investigate the relations between processes in the water cycle and their interdependencies. This thesis is also aimed at finding an indication of the possible effects of droughts and climate change on the urban water cycle. Approach For this study the water cycle of the Prinseneiland was used as a case study. The characteristics of the area were determined during a field survey. Further measurements on groundwater levels and sewer discharges were performed. Data on precipitation and potential evaporation were obtained from nearby measuring locations. A lumped, conceptual model was made for simulating the water cycle of the area. The model results were validated on the measured groundwater levels and sewer discharges. The model was used to simulate the effects of drought and climate change scenarios on the water cycle of the Prinseneiland. Conclusions Due to less precipitation in a dry year the interception evaporation, infiltration and surface runoff fluxes also decrease. Transpiration increases slightly due to higher potential evaporation. Groundwater recharge is decreases due to less infiltration and more transpiration. This causes the groundwater levels to drop more relative to normal situations. These effects are more or less proportional to the severity of the drought. Transpiration, however, is restricted by available soil moisture, which causes transpiration to remain relatively constant compared to the other fluxes. The effects of climate change mainly depend on whether the prevailing wind patterns change or not. In the latter case precipitation and potential evaporation increase, resulting in larger fluxes compared to the normal situation. When the wind patterns do change (as in the KNMI’06 ‘W+’ scenario) precipitation is concentrated in winter. During the summer months precipitation decreases and potential evaporation increases compared to the current situation. The interception evaporation, infiltration and surface runoff fluxes decrease. Transpiration increases due to higher potential evaporation. Groundwater levels are higher during winter due to higher winter precipitation and thus infiltration. In the summer groundwater levels decrease further compared to the normal situation.","urban water cycle; Prinseneiland","en","master thesis","","","","","","","","2013-08-21","Civil Engineering and Geosciences","Water Management","","Water Resources","",""
"uuid:9f47698c-360c-4ee2-ad0f-db22029ae0f0","http://resolver.tudelft.nl/uuid:9f47698c-360c-4ee2-ad0f-db22029ae0f0","Economic Capital for the Trading Book","Chenailller, A.","Oosterlee, C.W. (mentor); Van Buren, M. (mentor)","2013","Economic Capital consists of an internally defined amount of capital that is necessary to over- come adverse market conditions. It plays an important role in risk management and business decisions. This thesis focuses on the Economic Capital of the trading book of an international bank Several types of risks need to be modelled and, in this thesis, two risks are investigated, namely market risk and credit risk. For market risk, a model is explained and two risk mea- sures are analysed: Value at Risk and Expected Shortfall. The properties of the estimators of these risk measures are explained and a method to compute the one-year market risk compo- nent based on scaling a risk measure of a 10-day Profit and Loss distribution is derived. This method shows that Expected Shortfall is more appropriate than Value at Risk for modelling tail risk. The second part of this thesis focuses on the migration matrix employed in the model in order to capture the credit risk present in the trading book. Several methods are employed and compared, and a specific method is analysed to assess the probabilities of default in order to be consistent with other probabilities employed by the bank. Furthermore, several characteristics of a rating process are analysed, such as the Markovity and time-(in)homogeneity.","risk management; finance; VaR; ES; financial engineering; economic capital; trading book","en","master thesis","","","","","","","","2016-08-10","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","","",""
"uuid:200c99c6-a89d-4719-99da-9acab0625741","http://resolver.tudelft.nl/uuid:200c99c6-a89d-4719-99da-9acab0625741","SaaS Adoption Factors among SMEs in Indonesian Manufacturing Industry","Erisman, R.M.","Van Beers, C.P. (mentor); Van Geenhuizen, M.S. (mentor); Enserink, B. (mentor)","2013","Benefits of cloud computing to Small Medium-sized Enterprises (SMEs) seem obvious: financial savings (e.g. infrastructure savings, maintenance savings, etc.) and resource management advantage (e.g. skilled IT labor and equipment, resource flexibility, etc.). Software as a Service (SaaS) is one of cloud service model that has been acknowledged as the most plausible cloud service for SMEs. With regard to SMEs, Indonesia has enormous market size consisting of around 650.000 units. Despite its market size, according to Indonesian Cloud Forum (ICF), SMEs adoption to cloud computing including SaaS is only 3%. Yet, little is known about why the adoption of such technology is very low for SMEs in Indonesia. A requirement to SaaS adoption is the ICT adoption, notably the availability of basic IT infrastructure such as Internet and computer, which can also be seen as the basic requirement for SaaS adoption. However it is also unclear how many SMEs have adopted this basic IT infrastructure. Various factors may facilitate or inhibit SaaS adoption, yet very little is known about these factors. In this regard, this study seeks to investigate the factors that influence SMEs in Indonesia to adopt SaaS by focusing on manufacturing industry. Ordinal logistic regression and rough set analysis were applied to test the hypotheses in investigating the ICT and SaaS adoption factors. The study found a low level of ICT adoption among the SMEs. Moreover, the findings of the study suggest that firm size, education of middle to top management, and industry sector positively influence the ICT adoption among SMEs. In addition, the findings concerning SaaS adoption indicate that relative advantage, complexity, and compatibility as the strongest factors that tend to influence SaaS adoption level. These findings provide a better understanding on how SaaS is adopted by SMEs in Indonesia. It is still long way to go for SaaS to be adopted widely by SMEs; much effort is needed to boost such adoption. The low level of ICT adoption among SMEs should be addressed prior to or in parallel with SaaS adoption. Other factors from this study that expected to influence the ICT adoption are necessary to be investigated in this issue. Further, this study contributes to the knowledge on the adoption factors of information technology among SMEs in general. In terms of practical relevance, it gives recommendations to the national government as well as SaaS providers in formulating strategies for a better penetration of SaaS in the SMEs market.","adoption factor; ICT; SaaS; cloud computing; Indonesia; small medium enterprise","en","master thesis","","","","","","","","","Technology, Policy and Management","Innovation Systems","","Economic of Innovation","",""
"uuid:eaf3000c-13dd-4c97-aa2c-3cf0a016a3c1","http://resolver.tudelft.nl/uuid:eaf3000c-13dd-4c97-aa2c-3cf0a016a3c1","Differences in steering behaviour between experts, experienced and novice drivers: A driving simulator study","Negi, N.S.","Holweg, E.G.M. (mentor); Happee, R. (mentor); Van Leeuwen, P. (mentor)","2013","Through the years of automotive development driving safety has been one of the primary areas of concern. Inappropriate driver behaviour and insufficient driving skill are considered the primary causes of road accidents. Advanced driver assist systems are becoming increasingly important in their role of increasing driver safety. However, these technological advancements are not driver specific and often benchmark the average driver performance. A solution is to gain knowledge of the differences in driver skill and their relation to driver performance. In this thesis the steering behaviour of novice, experienced and expert drivers is investigated. Three experiments were analysed to research the differences between these drivers on a demanding racetrack, a double lane change and in a high and low friction cornering manoeuvre. In the first experiment expert drivers showed increased steering activity and differences in path strategy compared to normal drivers to achieve their better performance (faster lap-times and higher average lateral acceleration). Participants with more driving experience achieved better performance in the double lane change task (number of cones hit and deviation from the mid-path) and also in the cornering manoeuvre (faster lap-times and higher average lateral acceleration). Significant differences were found in driver control actions, showing higher steering activity in terms of steering rate, steering jerk and steering reversals for the expert and experienced drivers for the cornering tasks. Furthermore, differences were found in the path strategy and path consistency between the experts and normal drivers. In the double lane change test, novices show incorrect timing of the control action and hence provide late initial steering input and try to over compensate in a later stage, resulting in poor performance in terms of deviation from the mid-path and the number of cones hit. These results confirm previous findings in literature that increased control activity can lead to better performance and may lead to a future classification system of drivers based on their steering behaviour.","steering behavior; driver simulator","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Precision and Microsystems Engineering","","Automotive","",""
"uuid:04ea65ee-1f36-4fd3-89d4-3ada1f8e08dc","http://resolver.tudelft.nl/uuid:04ea65ee-1f36-4fd3-89d4-3ada1f8e08dc","Priva Lighting Control System: Providing a strategy for Priva to realise high performance buildings more completely - the development of a lighting control system concept","Ding, J.","Creusen, M.E.H. (mentor); Pont, S.C. (mentor)","2013","In the building management sector, Priva is a leader in the Dutch market. In order to become a global leader, the company aims to have a more complete product portfolio to provide better solutions for high performance buildings. Lighting control system is one part of the building management system, which is incomplete in Priva’s current portfolio. What is more, lighting has close connection to people’s performance, which consequently influences the business in the building. Priva sees this opportunity to develop a lighting control system for the non-residential building based on people’s performance. However, at this moment, Priva does not have any roadmap for the development of such lighting control products. This graduation project provides a strategy for the company to take the first step in the development process of this lighting control system. Analyses and research were conducted during the project to explore a direction for the new product by making use of the company’s strengths and market opportunities. A product strategy and a concept that shows the possible solution for the lighting control system were provided, together with an accompanying marketing strategy.","lighting control system; High Performance Building","en","master thesis","","","","","","","Campus only","2014-08-20","Industrial Design Engineering","Product Innovation Management","","Strategic product design","",""
"uuid:ae4e0a64-579d-40c4-bed0-d51614ddea9c","http://resolver.tudelft.nl/uuid:ae4e0a64-579d-40c4-bed0-d51614ddea9c","A comparison of open data policies in different countries: Lessons learned for an open data policy in Indonesia","Nugroho, R.","Tan, Y.H. (mentor); Janssen, M.F.W.H.A. (mentor); De Jong, W.M. (mentor); Zuiderwijk-van Eijk, A. (mentor)","2013","Many countries around the world have joined the open data movement. Data is being published for a various number of reasons which include for the public to reuse, to create a more efficient government, and to increase transparency. Recent development in this field is that the data published is expected to be in machine readable format. In general, there is a lack in guidelines to regulate and help the process of opening data. Many countries are in different stages in developing these guidelines. Indonesia is an example of a country just beginning to join the open data movement. A field of study that is lacking is about how countries can learn from each other in developing the necessary guidelines. Being in the early stages of development, Indonesia can especially benefit from research in this area. A complex comparison of open data policies is conducted in this research to provide a basis for drawing conclusions and recommendations for the open data policy in Indonesia. For this study, five different countries that are in different stages of development in their open data initiatives are explored which results in an extensive list of findings. These countries include the United States, United Kingdom, Netherlands, Kenya and Indonesia. For the design of the framework, literature and case studies are conducted. The case studies are in the form of interviews with eight respondents involved in open data in each country. First, it is identified what aspects influence the uneven development of open data. Second, lessons that are relevant for Indonesia based on the many similarities and differences are identified. As the scientific contribution of the research, this framework and comparison is given because there is currently lacking research in this area. It was concluded that Indonesia can synthesize a number of lessons from the comparison that comprises a combination of elements that were presented as findings from each of the countries. The lessons that were developed include suggestions for a more robust legal framework, the creation of an ecosystem between data publishers and data users, the development of stronger IT and organizational support for open data, and the launch of initiatives that use open data at the district government levels. Interestingly, from the study, it suggests that the focus of the policies for countries in the developing stages are more related to the release of data from the publishers and less on the technical processes that are involved with opening the data. Other interesting results that were founded from the study suggest that the difference between the countries are influenced by specific forces and counter forces in the area of open government and also from the existence of individuals that highly advocate for the development of open data in that country. So, the practical contribution of this research is the lessons that each of the countries can derive from the comparison and also the specific lessons that are designed for Indonesia’s open data policy both to reap the identified benefits of opening data. Further to this research, there is a possibility to conduct research on further comparisons for a more robust and comprehensive learning process. Comparisons can be conducted on different countries about open data policies or about different aspects of open data itself. Another possibility is to create lessons for all countries involved in this current study.","open government data; comparison framework; open data framework; open data policy; policy analysis; e-government","en","master thesis","","","","","","","","","Technology, Policy and Management","Information and Communication Technology","","","",""
"uuid:1e24b455-728d-42c0-82c5-e55f64956161","http://resolver.tudelft.nl/uuid:1e24b455-728d-42c0-82c5-e55f64956161","Designing Procedurally Generated Levels","Van der Linden, R.A.M.","Lopes, R. (mentor); Bidarra, R. (mentor)","2013","We aim to improve on the design of procedurally generated game levels. We propose a method which empowers game designers to author and control level generators, by expressing gameplay-related design constraints. Following a survey conducted on recent procedural level generation methods, we argue that gameplay-based control is currently the most natural control mechanism available for generative methods. Our method uses graph grammars, the result of the designer-expressed constraints, to generate sequences of desired player actions. These action graphs are used as the basis for the spatial structure and content of game levels; they guide the layout process and indicate the required content related to such actions. We showcase our approach with a case study on a 3D dungeon crawler game. Results allow us to conclude that our control mechanisms are both expressive and powerful, effectively supporting designers to procedurally generate game levels.","Procedural Content Generation","en","master thesis","","","","","","","","2013-08-20","Electrical Engineering, Mathematics and Computer Science","Intelligent Systems","","Computer Science - Media and Knowledge Engineering","",""
"uuid:5442b888-ad89-4117-b2fc-423e6b2107dd","http://resolver.tudelft.nl/uuid:5442b888-ad89-4117-b2fc-423e6b2107dd","An exploration of the use of open government data by private organisations: Contributing to the improvement of governmental policies by examining the current use of open government data by private organisations in the Netherlands","Kaasenbrood, M.D.J.","Zuiderwijk-van Eijk, A. (mentor); Janssen, M.F.W.H.A. (mentor); De Jong, W.M. (mentor)","2013","This is an explorative research into the, successful, usage of open government data. Based on this research recommendations are made to contribute to the improvement of governmental open data policies. Questions discussed are: How are private organisations using open government data? Under which socio-technical conditions do (the selected) private organisations see the gains of using open government data? How are the organisations using open government data? What are the similarities and differences between these organisations with regard to their open government data use?","open government data; OGD; policy; private organisation","en","master thesis","","","","","","","","","Technology, Policy and Management","ICT","","EPA","",""
"uuid:7867b8d1-28df-49fe-b002-7e6b8367bda4","http://resolver.tudelft.nl/uuid:7867b8d1-28df-49fe-b002-7e6b8367bda4","A predictive sourcing model for multi Export Credit Agency financed large industrial projects","Jansen, P.R.","Cunningham, S.W. (mentor); Storm, S.T.H. (mentor); Thissen, W.A.H. (mentor)","2013","CB&I is experiencing an issue in a new project to be executed in Russia, named NKNK. Despite the rich experience CB&I has with projects, there is a continuous struggle with the sourcing process in projects which it involves financing by multiple export credit agencies. The issue at stake is, CB&I does not know beforehand in which countries it is most likely to source its equipment to achieve to lowest possible sourcing costs. However, budgets available in countries will be set in an inception phase of a project. A preliminary estimation method is needed to determine the amount of budget needed in multiple countries, in order to increase the probability of minimizing total sourcing costs. In order to accomplish this, a new cost estimation methodology is needed. This combines strategic sourcing theory, descriptive statistics on suppliers, cost differentials among countries of manufacturing, macroeconomic theory, the role of export credit agencies in trade finance, conventional cost estimation methods, linear optimization, and Monte Carlo simulations. The importance of strategic sourcing is underpinned in this thesis. Theoretical optimal sourcing strategies are suggested on the basis of the level of perceived competition. The perceived level of competition within different industries is acquired through questionnaires with industry experts. The suggested sourcing strategies are tested on their practical applicability in large industrial projects. It turns out that there are serious limitations in applying multiple sourcing strategies, due to the nature of the highly customized equipment needed in these projects. Predominantly, single sourcing strategies are used, in which a number of suppliers is inquired for a bid. It is shown, through a linear regression analysis, there is a significant positive correlation between the perceived level of competition and the number of suppliers inquired for a bid. Descriptive statistics on suppliers involve per equipment type (more formally known as purchase order category), the number of suppliers selected and their most likely country of manufacturing. It is discussed that there are multiple restrictions in selecting potential suppliers for a project. Firstly, suppliers can only be selected and inquired for a bid, if they are stated in an ‘Approved Vendor List’. Secondly, ECA involved financing limits the budget available in each country to a certain extent. Therefore, selecting suppliers in a country where probably no budget is available, is a waste of effort. Thirdly, the increasing administrative burden in selecting larger numbers of suppliers poses limitations. Through a comparison on descriptive statistics on suppliers in two very similar projects, but with different project contexts, the effects of these limitations are determined. It is hypothesized there are sourcing cost differences among countries for particular purchase order categories. Through a literature review, macroeconomic factors that could explain these cost differentials are determined. These are categorized in economic-, infrastructural-, labor, supply based, and political factors. For each macroeconomic category indicators are selected to represent these. A total of twelve indicators per country are reduced to two factor scores per country, through a dimension reduction technique (principal component analysis). Based on quotations submitted by suppliers for a completed project in the near past, significant cost differentials among countries are determined using categorical variables in a linear regression. A statistical refinement has been done to place countries in a cost category. Factor scores per country and descriptive statistics on suppliers are used to substantiate these cost rankings. Combining cost differentials, macroeconomic indicators, and descriptive statistics proved to be a valuable tool to determine in which country one is most likely to receive the least expensive quotations. The role of export credit agencies (ECAs) in project finance is explored through a literature review. ECAs cover political and commercial risks for exporters and credit providing entities. ECAs are heterogeneous and there is no definitive model for ECAs. For terms associated with project finance (medium- to long-term), the most widely used mechanism by ECAs is buyer credit. ECAs are involved by issuing insurance, for defaults, directly to the exporter’s bank. ECAs are also involved in buyer credit by offering a precompletion risk facility. A recourse agreement is included, meaning defaults caused by the exporter can be reclaimed from the exporter and disbursed to the lending bank. To quantitatively compare differences in terms and conditions of ECAs, a new methodology is developed in this thesis. This methodology involves a discounted ‘Interest Rate Coefficient’, which incorporates ECA premiums rolled over into the loan in the financing period, and terms and conditions involved in the repayment period. Through a questionnaire terms and conditions applicable to the NKNK project are acquired, which are mainly budgetary constraints, insurance premiums, and interest rates. Combining the results of the questionnaire and the interest rate coefficient, necessary inputs are obtained for linear optimization and Monte Carlo simulations. The basis of the newly developed preliminary sourcing cost estimation methodology is a ‘sourcing allocation table’, which can be used as a direct input in a linear optimization model developed in line with this thesis. The methodology starts with listing all purchase orders for a project in the sourcing allocation table. Next, it is evaluated which data is readily available, with respect to suppliers, supplier countries, quotation values, and purchase order value estimates. Data which is not readily available on suppliers and supplier countries are estimated per purchase order category, based on the descriptive statistics on number of potential suppliers and their distribution among countries. For purchase orders of which no quotations or estimates are available, conventional estimation techniques are used. The order of magnitude method is used on a reference project, which is indexed to accommodate the inflationary impact of time. Dummy quotations are generated to fill in the missing data on suppliers, their countries, and quotation values. These dummy quotations take significant cost differentials among countries per purchase order category into account. In these quotations, values are randomly generated according to the average spread of quotation values, using a uniform distribution. Trade finance estimates are also included in the sourcing allocation table. Now the sourcing allocation tables contains, based on live data and dummy quotations, for each purchase order a number of suppliers, their country in manufacturing, and quotation values. As there are numerous randomly generated parameters, there is no definitive optimized value. Rather there is a range of possible outcomes, determined by doing a Monte Carlo simulation with the linear optimization model. The output of these simulations are, a probability distribution of the total optimized value, a probability distribution of the expenditures within each country, and an average distribution of ECA budgetary flows towards sourcing countries. The new methodology for preliminary estimation of sourcing costs is seen by CB&I as a valuable tool to determine in an early phase of the project where budgets are most likely needed. This allows to set ECA budgets properly, to increase the probability of minimizing sourcing costs. The first results are already presented to the client, which was impressed with the result. It gives a clear graphical representation of the estimated total costs, budgets needed in which countries, and where the budgets are spent. Evenly important, it shows the uncertainty in all these estimates, through probability distribution. In addition, this tool allows easy identification of the cost impact of different scenarios, such as exploring the cost effect of excluding budget from a certain ECA country.","optimization; Export Credit Agency; sourcing strategy; sourcing cost","en","master thesis","","","","","","","","2013-08-13","Technology, Policy and Management","Policy Analysis","","Management of Technology","",""
"uuid:8d660bfd-6e2e-4fdb-a098-d15457955340","http://resolver.tudelft.nl/uuid:8d660bfd-6e2e-4fdb-a098-d15457955340","Towards High Fidelity Aeroelastic analysis of Wind Turbines: Coupling and Verification","Van den Broek, S.F.","Van Keulen, A. (mentor)","2013","The design of wind turbines is a multidisciplinary process. Most of the codes currently used in industry and academia use low fidelity models, which are not suitable for detailed design. This thesis describes the development of an aerostructural model for wind turbines with a higg fidelity structural solver. This is done by coupling an existing high fidelity structural solver with an aerodynamic solver. Coupling is done by interfacing the components in Python. The aeroelastic solution is computed using the non-linear block Gauss-Seidel method. The code makes it possible to do steady-state analysis of a wind turbine blade. A high-fidelity model is created based on a Sandia National Labs model detailing the design of a 5MW turbine. Results from a comparative study between a low fidelity model and the developed model of this work show that the structural torsion has a significant effect on the performance of large wind turbines. Torsional degrees of freedom are not included in most low fidelity models. This is a clear indication that current aeroelastic codes have severe limitations when used to design flexible blades. The developed model makes it possible to model bend-twist coupling due to composite layups as well as geometry. Future work will focus on time-domain simulation of the aeroelastic response and high-fidelity optimization.","wind energy; aeroelasticity; coupling; high-reliability","en","master thesis","","","","","","","","2013-08-22","Mechanical, Maritime and Materials Engineering","Precision and Microsystems Engineering","","","",""
"uuid:cbc2c620-8b50-49d5-82ea-04af0240d343","http://resolver.tudelft.nl/uuid:cbc2c620-8b50-49d5-82ea-04af0240d343","Freeform Surface Interfaces Created Using Additive Manufacturing","Van Bennekom, S.M.","Doubrovski, E.L. (mentor)","2013","The assignment for this thesis was to develop a new visual product feature that is uniquely producable by additive manufacturing (AM) methods. In the first phase of the project the field of additive manufacturing was explored and the visual properties of products were studied. The most important finding here was that some AM technologies are gaining the capability of creating optical product features such as lenses and waveguides. Insight that waveguides could be used to create display features with complex shapes led to the formulation of a vision that describes the emergence of devices with interactive product surface features labeled ‘Freeform Surface Interfaces’ (FSI). It is found that such interfaces would have profound impact for the way products are used and manufactured. Using experimental prototypes the possibility of creating FSI’s using LED matrices and printed lightguide matrices. An important step in this was the realization that LEDs can be simultaneously used for both display functionality and sense functionality. The experiments find that such displays are possible, but that crucial steps eed to be taken in order for such interfaces can become sufficiently reliable. An attempt is then made to link process variables of the printing process used to the observed attenuation in printed lightguides, but this proves unfeasible within the scope of this project, and signifies the need for additional research. Lastly, a proof-of-concept prototype is made to demonstrate both current and expected future capabilities of printed lightguide FSI’s. This prototype and the vision supporting it finds strong validation with professional industrial designers.","additive manufacturing; displays; freeform; LEDs; product design","en","master thesis","","","","","","","Campus only","2014-08-19","Industrial Design Engineering","Design Engineering","","","",""
"uuid:7640df1c-2313-478e-a096-cbdeea4fef16","http://resolver.tudelft.nl/uuid:7640df1c-2313-478e-a096-cbdeea4fef16","Compliance Checking In Supply Chain Management: An approach to check regulatory compliance of business processes","Wang, S.","Janssen, J. (mentor); Aldewereld, H. (mentor); Oey, M. (mentor); Jiang, J. (mentor)","2013","Companies in the business world have to make their business processes compliant with the governmental regulations, otherwise, they may suffer from the law issues and economic losses. Due to globalization, checking for the conflicts between governmental regulations and the business processes in various countries is necessary, yet quite difficult. One of the problems is that if articles of regulation are interrelated, verifying the compliance cannot be achieved by just checking the compliance of each article separately as done traditionally. For this reason, we introduce Norm Nets, which is a regulation model that taking into consideration of the effect of interrelation among regulations. By using the model of Norm Nets, we proposed an approach to check the regulatory compliance. In this thesis, we first made a meta model of Norm Nets. Then we designed an automatic transformation tool from Norm Nets to Colored Petri Nets (the analysis tool used in this thesis) in order to improve the efficiency of the compliance checking approach. In the end, we verify the compliance checking approach through a case study.","Regulatory Compliance; Norm Nets; Colored Petri Net","en","master thesis","","","","","","","","2013-08-31","Technology, Policy and Management","ICT","","","",""
"uuid:f1f7fb43-4a1c-486e-9d68-6eb6d64eda42","http://resolver.tudelft.nl/uuid:f1f7fb43-4a1c-486e-9d68-6eb6d64eda42","Static Reservoir Model of Crevasse Splays in the Colorado River System, Salar of Uyuni, Bolivia","Torres Carranza, Y.A.","Donselaar, M.E. (mentor); Weltje, G.J. (mentor)","2013","The Altiplano Basin (Bolivia) exhibits one of the best examples of dryland river systems with a low gradient, where it is possible to obtain field data to build 3D high-resolution geological models of different sediment bodies. This study presents the development and understanding of a 3D geological model for crevasse splays deposited in this kind of basin. The data used consists of sediments in-situ and remote sensing data (satellite images). The integration of field and remote sensing data shows that the grain size has a better correlation with the channels location than the RGBD information from the satellites images. Likewise, with the grain size model, it is possible to visualize that porosity is not highly affected by the clay content, and due to the small grains, the initial predicted porosity is around 49 to 56%, which can be reduced to values below 7% because of overburden. According to grain size and porosity, permeability is around 350 to 600 mD, due to grain size distribution at surface conditions. These petrophysical properties are appropriated for gas storage and they can accumulate up to 3 MSCM of gas reserves in one single crevasse splay. As observed in the field, crevasse splays are vertically stacked resulting in a high net to gross ratio, and increasing gas reserves up to 300 MSCM of gas in-situ, making these reservoirs an attractive target for exploration in fluvial systems.","crevasse; modelling; sedimentology","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Petroleum Engineering","",""
"uuid:9150efb0-53ff-421b-b5ea-10adde87fc18","http://resolver.tudelft.nl/uuid:9150efb0-53ff-421b-b5ea-10adde87fc18","Verbeteren kwaliteit productie UMS Pastoe","Schilder, W.M.","Veeke, H.P.M. (mentor)","2013","UMS Pastoe produceert diverse productgroepen meubelstukken. De uiteenlopende specificaties van klanten maken dat iedere order als uniek wordt beschouwd. Verschuiving in de volumes tussen de productgroepen heeft geleid tot de vraag of het productie proces hierop moet worden worden aangepast. Het management van UMS Pastoe heeft gebrek aan inzicht in het productie proces, waardoor deze vraag in eerste instantie lastig te beantwoorden is. Bij aanvang van het onderzoek is het probleem vaag geformuleerd. Wel staat vast dat verbetering van het financiële resultaat door proces verbetering wenselijk is. De Soft Systems Methodology (Checkland, 1981) is toegepast, omdat met deze methode vaag geformuleerde problemen kunnen worden benaderd. Met Soft Systems Methodology wordt de probleem situatie onderzocht, zodat het juiste probleem kan worden vastgesteld. Onderdeel van de Soft Systems Methodology is het systeemdenken over de werkelijke wereld. Hiervoor wordt gebruik gemaakt van de Delft Systems Approach (in ‘t Veld, 1975) (Veeke, Ottjes, & Lodewijks, 2008). De Delft Systems Approach reikt conceptuele modellen aan waarmee het functioneren van processen kan worden onderzocht en aangepast. Verkennen van verschillende bedrijfsonderdelen, om vertrouwd te raken met operationele activiteiten, heeft aanknopingspunten voor verbeteringen opgeleverd. Naast verbeteringen op afdelingsniveau, zijn er overkoepelende problemen die de prestaties van het gehele productie proces beïnvloeden. Analyse van de gerealiseerde doorlooptijden toont aan dat 63% van de orders later dan de gestelde norm van 40 werkdagen gereed komt. Op basis van de gewerkte uren, orders en doorlooptijd is bepaald dat een gemiddelde order slechts 3,8% van de orderdoorlooptijd in bewerking is. Een mogelijke verkorting van de doorlooptijd is aannemelijk. De oplossingen om de doorlooptijd te beheersen en verkorten is het herzien van de productie aansturing. Verkleinen van de batch grootte heeft een kortere doorlooptijd tot gevolg. Proces aanpassingen om de doorlooptijd te verkorten leveren tevens een kostenbesparing, waarmee de winst met 98% stijgt. Een betere sevices door kortere doorlooptijden en verhoogde leverbetrouwbaarheid heeft bovendien een positieve stimulans op de omzet.","","nl","master thesis","","","","","","","","2015-08-19","Mechanical, Maritime and Materials Engineering","Marine and Transport Technology","","Transport Engineering and Logistics","",""
"uuid:06fb4a21-b4f7-4f83-8fed-0d83fa995613","http://resolver.tudelft.nl/uuid:06fb4a21-b4f7-4f83-8fed-0d83fa995613","The optimization of a Lower Deck Mobile Crew Rest, providing flight-crewmembers with an optimal resting-place during long-range flights","Pas, R.H.","Van Heur, R.J.H.G. (mentor); Minnoye, A.L.M. (mentor); Schreuder, T. (mentor)","2013","1. Introduction In commercial airline industry, flight- attendants have the right to rest during the flight when their flying duty period is exceeding a certain amount of hours. However, not every aircraft is equipped with the required rest facilities, the so called ‘crew-rests’. As a consequence, the airlines may offer their employees a business class seat to meet the requirements for resting. Evidently, those seats cannot be sold for commercial purposes. Zodiac Galleys Europe provides an alternative by means of their Lower Deck Mobile Crew Rest (LDMCR). Basically, the LDMCR is an aircraft cargo container furnished as a crew rest, placed in the lower deck of an aircraft and can be reached via a stair house on the upper deck. Currently the LDMCR provides rest facilities for six to eight flight attendants. Zodiac Galleys Europe has reasons to believe that there is a growing need for a LDMCR which provides rest facilities for eight flight attendants. Furthermore, in order to improve the ability to rest, Zodiac wants to redesign their current LDMCR with today’s knowledge and technology. In order to meet those wishes, a graduation assignment has been set up to explore the possibilities and to generate new and improved concepts. 2.1 LDMCR ‘LDMCR’ is the abbreviation for Lower Deck Mobile Crew Rest and it consists of a standard aircraft cargo container which is converted to a crew rest area, especially meant for flight attendants working on long range (intercontinental) flights. The LDMCR is produced by Zodiac Galleys Europe and only used in the Airbus A330 and A340. The LDMCR can be entered via a stair house on the upper deck of the aircraft and provides rest facilities for 6 - 8 flight attendants. 2.2 Design Brief The design of a new LDMCR concept that provide eight crew members with the rest and privacy they need in order to perform in optima forma. The focus for redesign shall be on space optimization 2.3 Process Summary In order to generate new and improved concept ideas for the Lower Deck Mobile Crew Rest, insights were gained by the analysis of the current product and its context. Within the context of the product the following topics were studied; the life-cycle of the product, the design approach of the company, the end-user (flight attendants), regulations on rest & sleep, and literature on rest & sleep. All insights gained led to the conclusion that a radical change in the design approach as well as in the design itself should be beneficial for all stakeholders (Zodiac, Airbus the airlines and the flight attendants). In the automotive industry, concept cars are made to gauge the stakeholders wishes, needs and interests towards innovative styling and technologies. Similarly, for this graduation project a ‘concept car’ has been developed by means of a showcase. 2.4 Concept Proposition The development of the concept proposition started with ‘relax & recharge’ as keywords. From here, an environment was created where flight attendants are encouraged to become in a relaxed (relax) state of mind, after which they will do a power nap for no more than 30 minutes (recharge). Striking elements in the design are the introduction of fold out beds and the redesign of the stairs. Both elements contribute to a great extend for space optimization. 2.5 Concept Evaluation A concept evaluation with the help of a flight attendant and a former flight attendant suggested that recharging by means of a power nap might not work in all situations. Yet, the design and the features of the concept are appreciated above the current LDMCR 2.6 Future Opportunities Due to the introduction of fold out beds, an environment can be easily created in which future opportunities come to mind. When not used as a crew rest, the environment can be used, for example, as theatre or business/meeting room for passengers. An extra for which airlines can charge money. 2.7 Recommendations It is recommended that Zodiac will use the concept presented in this report as a ‘concept car’ or showcase. Subsequent, it is recommended that Zodiac communicates the concept to all stakeholders (Airbus, airlines and flight attendants) to gauge reactions and to decide on elements for implementation for future crew rests. Additionally, it is recommended that Zodiac continues on the development of showcases in order to accelerate the process of innovating in crew rests.","crew rest; commercial aerospace; rest; sleep; relax; recharge","en","master thesis","","","","","","","Campus only","2014-08-16","Industrial Design Engineering","Industrial Design","","Master of Science Integrated Product Design","",""
"uuid:3232af97-a958-4b0f-a3fc-6d1514a31673","http://resolver.tudelft.nl/uuid:3232af97-a958-4b0f-a3fc-6d1514a31673","Working fluid design for organic rankine cycle systems (ORC)","Hattiangadi, A.","Colonna, P. (mentor); Mathijssen, T. (mentor)","2013","The Organic Rankine Cycle is an energy conversion cycle similar to the conventional Rankine cycle which runs on a working fluid other than water. The selection of a working fluid is a critical part of designing an Organic Rankine Cycle (ORC) system. The number of fluid types actually used in commercial ORC power plants do not justify the number of fluid selection studies present in scientific literature. Hence the objective of this work is to develop a tool which simultaneously optimizes the energy conversion process and selects the optimum working fluid for a given heat source. It is based on a framework that uses a continuous-molecular targeting approach which allows for an integrated working fluid and system design. The process is modeled in Cycle Tempo, a modern graphical tool for thermodynamic analysis and optimization of systems for the production of electricity, heat and refrigeration. The system is simultaneously optimized with the pure component parameters of PCP-SAFT equation of state using a state-of-the-art optimization suite. The working fluid is selected by comparison of the pure component parameters of the PCP-SAFT equation of state with real fluids. A preliminary turbine model implemented directs the tool to generate suitable fluids for practically realistic systems. The tool has been tested for a waste heat recovery system for heavy-duty truck engines based on an ORC turbogenerator. The choice of working fluid is restricted to only the siloxane class which not only adheres to the technical, environmental, and toxicological requirements typical of the automotive sector but also allows for the implementation of a preliminary radial turbine model, whose shaft can be lubricated by the working fluid itself. The turbine has been modeled by applying the methodology of using non-dimensional parameters. Future work will be devoted to implement detailed component models and extending the scope of fluid selection to other organic fluid classes.","ORC; Rankine Cycle","en","master thesis","","","","","","","","","Mechanical, Maritime and Materials Engineering","Process & Energy","","Energy Technology","",""
"uuid:1c1007d3-e5b2-472e-9715-4f68135516cf","http://resolver.tudelft.nl/uuid:1c1007d3-e5b2-472e-9715-4f68135516cf","Tijdsafhankelijke vervormingen in betonnen hoogbouw: Metselwerkgevels op Nederlandse hoogbouw: een gelukkige combinatie?","Poot, M.W.","Nijsse, R. (mentor); Braam, C.R. (mentor); Pasterkamp, S. (mentor); Falger, M. (mentor)","2013","The application of reinforced concrete in the load bearing structures of high-rise buildings requires awareness of the time-dependent behavior of the material. During the first few years after pouring of the concrete the elements will shorten, caused by shrinkage and creep. This may result in problems concerning non-load-bearing elements, which are connected to the load-bearing structure, such as cracks in masonry façades. The aim of the research is to identify the influence of the structural system on the time-dependent behavior of façade columns. Next the calculations will be used to check how much free scope is needed in a horizontal dilatation joint, in order to be able to cope with deformations of load-bearing structure and masonry outer leaf. To investigate the influence of the structural system on time-dependent behavior, a comparison has been made between core-systems and tube-systems. Those systems theoretically have the largest difference in compressive stresses in façade columns under permanent loads. Weight calculations have been made and the load bearing capacity of the façade columns have been determined. Next the time-dependent deformations during and following the construction phase have been calculated, based on EC2 calculations of shrinkage and creepfactors. The Age-adjusted Effective Modulus Method (AEMM) has been applied, which takes into account elastic and creepstrains, as well als shrinkage. The restraining influence of reinforcement on the deformations has been taken into account by reducing the found deformation by a separately determined reinforcement factor. Calculation of bearing capacities and the loads carried by the façade columns revealed that the theoretical distinction between ‘core’ and ‘tube’ systems is not to be consistently observed in the compressive stresses. Calculations of the time-dependent deformations show deformations (at t=2000 days) varying between 2,2 and 5,7 mm. Also a calculation method is proposed, which enables designers to make an approximation of the deformations that have already taken place at any given time during the construction phase. The choice for a specific structural system looks not decisive for the value of the concrete compressive stresses, which is an important factor in creep deformations. The advice of the KNB for horizontal joints with a free scope of 10 mm. seems enough for Dutch towers, if applied at every story.","creep; shrinkage; time-dependent behavior; concrete; high-rise; masonry facade; Age-adjusted Effective Modulus Method","nl","master thesis","","","","","","","","","Civil Engineering and Geosciences","Structural Engineering","","Structural Design","",""
"uuid:ff04cbf1-e0a3-4cd3-b10d-b8a74fd383b7","http://resolver.tudelft.nl/uuid:ff04cbf1-e0a3-4cd3-b10d-b8a74fd383b7","TiPi smartphone application: Designing with InterPersonal Informatics to support elderly rehabilitating from Total Hip Replacement","Kroon, D.J.","Jimenez Garcia, J.C. (mentor)","2013","Designing a smartphone application for elderly rehabilitating from total hip replacement. The theoretical background of this project lies in the fields of Personal Informatics, InterPersonal Informatics, Persuasive Technology and Social Sciences. The product context, the ADL of elderly rehabilitating at home, has been researched with sensitizing materials and interviews. This is followed by iterative design cycles and concept development leading to a final design. The final chapters contain the prototype testing, conclusions and recommendations.","InterPersonal Informatics; Persuasive Technology; Total Hip Replacement; rehabilitation; smartphone application","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Design Conceptualization and Communication","",""
"uuid:492ce6c0-ab22-42d0-ba00-3cf3702eb873","http://resolver.tudelft.nl/uuid:492ce6c0-ab22-42d0-ba00-3cf3702eb873","Working Fluid Design for Organic Rankine Cycle (ORC) Systems","Hattiangadi, A.","Colonna, P. (mentor); Mathijssen, T. (mentor)","2013","The Organic Rankine Cycle is an energy conversion cycle similar to the conventional Rankine cycle which runs on a working fluid other than water. The selection of a working fluid is a critical part of designing an Organic Rankine Cycle (ORC) system. The number of fluid types actually used in commercial ORC power plants do not justify the number of fluid selection studies present in scientific literature. Hence the objective of this work is to develop a tool which simultaneously optimizes the energy conversion process and selects the optimum working fluid for a given heat source. It is based on a framework that uses a continuous-molecular targeting approach which allows for an integrated working fluid and system design. The process is modeled in Cycle Tempo, a modern graphical tool for thermodynamic analysis and optimization of systems for the production of electricity, heat and refrigeration. The system is simultaneously optimized with the pure component parameters of PCP-SAFT equation of state using a state-of-the-art optimization suite. The working fluid is selected by comparison of the pure component parameters of the PCP-SAFT equation of state with real fluids. A preliminary turbine model implemented directs the tool to generate suitable fluids for practically realistic systems. The tool has been tested for a waste heat recovery system for heavy-duty truck engines based on an ORC turbogenerator. The choice of working fluid is restricted to only the siloxane class which not only adheres to the technical, environmental, and toxicological requirements typical of the automotive sector but also allows for the implementation of a preliminary radial turbine model, whose shaft can be lubricated by the working fluid itself. The turbine has been modeled by applying the methodology of using non-dimensional parameters. Future work will be devoted to implement detailed component models and extending the scope of fluid selection to other organic fluid classes.","Organic Rankine Cycle; Automotive Heat Recovery; Radial Turbine; Pinch Point; PCP-SAFT; Continuous molecular targeting approach to CAMD","en","master thesis","","","","","","","","2013-08-16","Mechanical, Maritime and Materials Engineering","Process and Energy","","Energy Technology","",""
"uuid:e06abee4-e41a-44f7-b603-779d1dbe9f9d","http://resolver.tudelft.nl/uuid:e06abee4-e41a-44f7-b603-779d1dbe9f9d","Imaging of Cracks and Weak Spots in Steel and Aluminium Plate Rolls","Van Gemert, J.H.F.","Remis, R.F. (mentor)","2013","Because of several - sometimes extreme - complications caused by cracks and weak spots in a metal industry roll, it is of great importance to detect these defects in time. Measurements on rolls with artificial- and natural defects have been performed. An imaging operator is introduced, which uses the measurement data to depict the correct locations of the scatterers in the roll. Even when almost 95% of the original measurement data is discarded, the defects in the roll can still be detected. This thesis shows how these imperfections cause deviations in the eddy current measurement setup and presents how the deviations can be used to locate these defects in the steel. The roll is modeled as a conductive half space after which the inhomogeneous Helmholtz equation will be solved to find the electromagnetic fields inside the steel. Defects are modeled as small spheroids with respect to the wavelength, which makes it possible to find the fields inside these scatterers. Furthermore, an equation is found which relates deviations in receiver signals to the electric- and magnetic fields and contrasts in the roll. The quasi-static approach is used to simplify this equation, after which results are shown for different defects and antenna configurations. Similar outcomes are obtained when the measurement data is compared to the theory.","cracks; imaging; electromagnetic; helmholtz; roll","en","master thesis","","","","","","","","2013-08-11","Electrical Engineering, Mathematics and Computer Science","Telecommunications","","Circuits and Systems","",""
"uuid:8b7a3a88-1cd9-44de-96ff-6daafd4dc91a","http://resolver.tudelft.nl/uuid:8b7a3a88-1cd9-44de-96ff-6daafd4dc91a","Improving productivity of driving processes for special baggage handling at KLM Royal Dutch Airlines","Bolijn, R.","Lodewijks, G. (mentor); Duinkerken, M.B. (mentor)","2013","Each day 120.000 to 160.000 pieces of baggage are handled at Schiphol Airport. Roughly 95.000 pieces of baggage (both KLM and other partners) are handled by KLM. The current baggage transport processes are based on outdated methods and IT support. The project BS Mobiel accomplishes improved driving process by digitalization of the work-order issuance process. The scope of this project is momentarily focused on the transport of incoming baggage. However, introduction of BS Mobiel might also be an opportunity to improve the special baggage transport processes, such as odd-size, animals, lost- and crew-baggage, etc. There might furthermore be an opportunity in improving special driving processes with the current resources. As such the following research question is formulated: “How can special baggage processes be improved with logistic strategies and additional IT-infrastructure?”...","","en","master thesis","","","","","","","","2018-08-16","Mechanical, Maritime and Materials Engineering","Marine and Transport Technology","","Transport Engineering and Logistics","",""
"uuid:b4a0c6a3-316f-42a3-97f7-2ab681257030","http://resolver.tudelft.nl/uuid:b4a0c6a3-316f-42a3-97f7-2ab681257030","Magnet.me IT Infrastructure Reorganization","Langerak, T.; Walterbos, A.T.","Bozzon, A. (mentor)","2013","The Bachelor Project assignment of internet startup Magnet.me, fulfilled by Tiddo Langerak and Alex Walterbos, consisted of the replacement of the IT infrastructure in the company. Before designing the new system, the old system was analyzed. Based on this analysis, a list of requirements was formed. The system has been designed so that it fulfills a significant amount of the requirements per definition: Using modern techniques like the Node.js platform, the AngularJS framework, Redis caching and an Nginx webserver, a high performance RESTful IT infrastructure was built. This design includes a server side service for business logic calculation and a Content Management System for internal usage. Using this system, Magnet.me hopes to grow substantially without being held back by technology. (Performance) tests have shown a significant improvement over the old system. The system is set up to be flexible, maintainable and reliable. Its performance is of a grade that, according to early estimations, should even be able to support international traffic. The Magnet.me management has already expressed their satisfaction with the systems performance, even before the system has been implemented completely.","Magnet.me; REST; web development","en","bachelor thesis","","","","","","","","2013-08-23","Electrical Engineering, Mathematics and Computer Science","Web Information Systems","","Computer Science","",""
"uuid:63a61f7d-663d-41a1-bd7f-92eaa2154e44","http://resolver.tudelft.nl/uuid:63a61f7d-663d-41a1-bd7f-92eaa2154e44","Design of an Eye-Screening Device to Detect Retinopathy of Prematurity in India","Horstink, W.B.","Mink, A. (mentor); Goossens, R.H.M. (mentor)","2013","This report presents the process and results of the graduation project of Wouter Horstink at the faculty of Industrial Design Engineering, Delft University of Technology. The project is titled: “Design of a handheld screening device to detect Retinopathy of Prematurity in India.” Retinopathy of Prematurity (RoP) is an eye ailment that can cause premature infants to get blind. Since the disease is only detectable after an eye examination, most of the premature infants need to be screened by taking images of their retina. Since there is only one doctor per 80.000 infants in India, finding these patients is a big challenge and a telemedicine system would apply. Currently, an expensive product called RETCAM (Clarity Medical Systems) is used in a few telemedicine programs to find patients that need treatment. The company Forus Health in Bangalore (India) is addressing this issue and has the ambition to develop an affordable device that is suited for the Indian context. The student (author) is asked to reside in Bangalore for a period of four months and develop an industrial design proposal with the focus on ergonomics and usability. The application of methods from the IDEO Human Centered Design Toolkit leads to requirements for product design regarding: Indian healthcare context, user preferences, available technology, user ergonomics and infant safety. After developing principles (chapter 9) and concepts (chapter 10) that involved several user evaluation sessions, conclusions were stated as follows: “There is a need for a handheld precision camera that is able to contact the eye and is operated with integrated controls.” A design proposal is presented in chapter 11 that has characteristics for precision screening including: The use of an ergonomic support that ensures stable operation of the device, even while operating the integrated controls. An ergonomic product casing design that allows for an ergonomic precision grip by its small diameter. A volume arrangement that is suitable for the proposed technology components provided by Forus Health. The product (presented in chapter 11) was evaluated by novice users and experts in a qualitative way with the use of detailed prototypes (chapter 12). Conclusions and recommendations that are presented include the expected success of the design proposal with regards to safety and usability. A list of recommendations is presented to advise about further development of the product. User research had a significant impact on the design process and this method was evaluated (chapter 14) to be successful in the way it helped in solving complex usability issues. The use of prototypes as main tool for generating ideas (IDEO Toolkit) was evaluated to be extremely useful in solving non-standard ergonomic problems.","Retinopathy of Prematurity; R.o.P.; India; Medical; Telemedicine","en","master thesis","","","","","","","Campus only","2014-08-15","Industrial Design Engineering","Industrial Design","","Integrated Product Design","",""
"uuid:2073e825-9078-4304-b050-54ba171622e2","http://resolver.tudelft.nl/uuid:2073e825-9078-4304-b050-54ba171622e2","Near-surface property extraction from vibrator impedance","Wallimann, B.W.","Baeten, G.B. (mentor); Ernst, F.E. (mentor); Drijkonigen, G.G.D. (mentor)","2013","In this thesis a numerical two-layer model for vibrator impedance has been evaluated with respect to its accuracy and sensitivity and an initial inversion approach based on this model has been deduced. This has been tested on synthetic and real data. The numerical two-layer model was introduced by [Baeten et al., 2008].","Geophysics; Select Civil Engineering and Geosciences; vibrator; impedance; near surface","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","","",""
"uuid:c3ec6202-c510-4d39-bd0f-6ded654a8fc0","http://resolver.tudelft.nl/uuid:c3ec6202-c510-4d39-bd0f-6ded654a8fc0","Designing a user-friendly gasification-stove for the rural population in Vietnam","Maymi Clariana, J.","Crul, M.R.M. (mentor); Tassoul, M. (mentor); Long, N. (mentor)","2013","The Master Thesis presents the design of a cook stove that uses biomass such as rice husk to cook. This cook stoves called gasifiers are an alternative to fossil fuel cook stoves in rural areas since the smoke generated by fossil fuels stove comprises a variety of health-damaging pollutants. The gasifier presented in this report was designed under the principles of human-centred design to adapt the technology to the users and enhance a better usability of this product and cooking experience.","gasification; human-centred design; cook stove; gasifier; Vietnam; biomass; user-friendly","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Integrated Product Design","",""
"uuid:68f91b3f-bc5d-4b1c-a927-d14d262bb4b4","http://resolver.tudelft.nl/uuid:68f91b3f-bc5d-4b1c-a927-d14d262bb4b4","LudoGraph: A Sampling Capable Cloud-Based System for Large-Scale Graph Processing: Based on the Pregel programming model","Biczak, M.","Iosup, A. (mentor)","2013","","","en","master thesis","","","","","","","","2013-08-14","Electrical Engineering, Mathematics and Computer Science","Software and Computer Technology","","Computer Science","",""
"uuid:9b6bd4b0-1001-4d9b-a6eb-7761bc3b2309","http://resolver.tudelft.nl/uuid:9b6bd4b0-1001-4d9b-a6eb-7761bc3b2309","Facies and permeability prediction based on analysis of core images","Wieling, I.S.","Weltje, G.J. (mentor); Bloemsma, M.R. (mentor)","2013","The present standards for core interpretation do not contain the acquisition of high resolution images from core slabs; images are taken on a very low resolution under a poor light source for administrative purposes only. The advantages of taking high resolution images and subsequent analysis of these images could be substantial and are investigated in this project. Besides the possible advantages image analysis could have, these images provide a safe way to store core information, as they are not prone to deterioration over time, which cores themselves are. Obtaining a high resolution description of facies and permeability by means of image analysis is a promising new technique, which could ease the operation of core analysis. This technique is relatively new because of the trend of increasing resolution of digital cameras and increasing processing power of computers, which make it possible to obtain high resolution images and process them without losing detail. In this project a routine is developed to analyze the images and the routines accuracy is compared to the present day standards of core interpretation. The proposed routine in this project first segments the core on a centimeter scale parallel to bedding, which is performed by a correlation scheme. The segments are subsequently subjected to an image analysis algorithm. Image analysis was based on RGBD color data and its auto-covariance properties, to enable the mapping of color and texture of the core. The results of this image analysis are used to classify the core based on lithology and grain size and produce a permeability model of the core. To enhance separation between facies in terms of the RGBD color data and Auto-Covariance properties, the data undergoes a Centered Log Ratio Transformation resulting in a continuous data space. The data subsequently undergoes a Principal Component Analysis to detect the properties that are potentially informative about the facies and permeability. Initially classification between sandstone and other lithologies was performed on the log-transformed RGBD color data, by means of a quadratic decision boundary. Subsequently analysis of the Auto-Covariance properties was performed to extract a permeability model of sandstone, which was calibrated with plug data. The resulting classification of lithology showed to be accurate for 84 % of the segments, where the largest misinterpretation occurred between very fine sandstone, siltstone and mudstone. All but the finest sandstones grain size classes showed an accuracy of classification above 95 %. Grain size was classified into the correct class or a similar class in terms of permeability for 55 % of the fine to medium grained sandstone. For mudstone, siltstone and coarse sandstone this percentage ranged between 93 % and 100%. The root mean squared error of the permeability model was an order of magnitude. This error is 30 % larger than the root mean squared error of the null model, which is a model that averages permeability over the facies as interpreted by the geologist. These results imply that image analysis could potentially be a good source of information and especially when combined with other reliable methods. The areas where image analysis is prone to misclassification could be classified by other reliable methods; Misclassification between mudstone and sandstone could easily be extracted with a gamma ray log, for example. The resulting map of grain size, lithology and permeability could aid the geologist during his core analysis. The initial estimation of the core’s characteristics is digitalized by the image analysis routine, reducing the job of the geologist to verifying the results and adjusting them where necessary.","petroleum engineering; core analysis; image analysis; permeability; facies; automated interpretation","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","","",""
"uuid:8ee5c6ed-63dd-49dc-b62e-e6c9b5c2b876","http://resolver.tudelft.nl/uuid:8ee5c6ed-63dd-49dc-b62e-e6c9b5c2b876","Batch Scheduling for Energy-Efficient Sensing in Smartphones","Tsitsikas, K.","Durmus, Y. (mentor)","2013","Sensing in smartphones consumes a significant amount of energy and leads to quick depletion of the battery. Most of the existing solutions to overcome the short battery lifetime caused by periodic sensing are personalized. They tend to learn and predict the user activities. Thus, fewer samples are required to recognize user state and sensing intervals can be extended. However, such methods require a training phase and any change in the user pattern causes a need for a new training phase. Therefore, in addition to personalized learning methods, we also need user-agnostic techniques that guarantee instant energy savings independently of the context to be recognized. In this thesis a user-agnostic method that seeks to provide energy efficiency in sensing is proposed. Our approach is based on the observation that an energy overhead occurs every time the CPU is woken up to perform a sensor sampling task. Hence, our goal is to decrease the number of CPU wake-ups incurred due to periodic sampling by combining multiple sensing actions into one joint activity. Our contribution is a mechanism that batches the execution of periodic tasks. BASS (BAtch Scheduler for Sensing) uses the greatest common divisor of the time intervals defined for the sensor sampling tasks. It also introduces a flexibility factor that implies the time delay tolerance regarding the execution of a task. Moreover, our tool implements a detection method for CPU wake-ups caused by any other application or the user. Based on the above, BASS applies batch scheduling to execute the sensor sampling tasks in batches and result in fewer CPU wake-ups. We evaluated our mechanism using a sensing application for monitoring patients that suffer from Rheumatic Arthritis. We conducted a number of experiments on an HTC Sensation phone, which showed that the efficient exploit of CPU wake-ups cuts down the energy consumption in mobile sensing. The BASS tool achieved an average power reduction of up to 44% and 18% in laboratory and real-world experiments respectively, in our application scenario, without compromising sensing time accuracy.","smartphone; batching; energy efficiency; scheduler","en","master thesis","","","","","","","","2013-08-02","Electrical Engineering, Mathematics and Computer Science","Software and Computer Technology","","Embedded Systems","",""
"uuid:6d1a5460-0235-4d8e-85a4-9343dcfa0709","http://resolver.tudelft.nl/uuid:6d1a5460-0235-4d8e-85a4-9343dcfa0709","Redesign Concept for Logistics of Volkswagen Commercial Vehicles in Hannover","Nyhuis, O.","Veeke, H.P.M. (mentor)","2013","Since 1956 the Volkswagen Commercial Vehicles plant in Hannover produces Transporters. Over time the plant grew increasingly complex, and today roughly 13,000 employees produce 600 T5, 120 Amarok, and 40 Porsche Panamera bodies per day. It is the Volkswagen Group’s declared goal to become the world’s leading automotive manufacturer, which also sets goals for the brand of Volkswagen Commercial Vehicles. This thesis focused on the order-to-delivery (OTD) process and its sub-processes of sales, planning, supply, production, and distribution. Its goal was to investigate the just-insequence production (JISP) concept and to provide a concept proposal to create more stable and robust logistics processes and to harvest the economic potential of JISP and just-in-sequence supply of components. Within the OTD process there are a number of issues that were investigated using the Delft Systems Approach to find their causes. These issues are the large stocks of JIS components at the third level logistics provider (3PL), the large inventories of finished vehicles in distribution, and the rather low internal delivery reliability. As root cause for the large stocks at the 3PL, the analysis identified the inaccurate information of JIS suppliers and a lack of knowledge of JIS suppliers about the supply process at Volkswagen. The large inventories in distribution are caused by a lack of information of the distribution department and the corresponding inability to plan. Moreover, the low internal delivery reliability is caused by process disturbances and negligence of differences in throughput times for certain characteristics of orders. These characteristics include non-standard roofs, double-layer paint, and painting of the vehicle on painting line 1. Together these root causes lead to the research question of how to improve the logistics processes and process communication without interfering with the current production process to improve efficiency and effectiveness in logistics. For mitigation of the identified problems, three approaches were investigated: transfer of additional data and coaching for JIS suppliers, transfer of additional data for the distribution department, and the integration of scheduling and sequencing with sequence-shifting.","","en","master thesis","","","","","","","","2018-08-14","Mechanical, Maritime and Materials Engineering","Marine and Transport Technology","","Transport Engineering and Logistics","",""
"uuid:fb95f69d-333a-43f7-964d-3475fa18aa38","http://resolver.tudelft.nl/uuid:fb95f69d-333a-43f7-964d-3475fa18aa38","Discover in the forest: An integrated visitor experience in the Awarehouse","Wang, Y.","Wormgoor, R. (mentor); Jepma, E.J. (mentor)","2013","This report is meant to document a graduation project aiming to design an integrated (interactive and educational) visitor experience in the Awarehouse where serves as the brand experience center of Interface Company, which is an international company that produces the environmentally responsible modular floor coverings. A fully developed proposal for six zones of Awarehouse and an interactive showroom were presented at the end of project, which mainly focuses on the brand essence of the Interface company: Design, Innovation and Sustainability. VIP approach was applied throughout the whole project, which built up a frame of future context and interaction in the Awarehouse. The framework of ‘Deconstruction’ was taken as an analytical tool to analyze the current situation (context and interaction) within the Awarehouse including the presented products or installments. On the purpose of getting insights for the future context and interaction, a further research on samples of museums or showrooms and inspiring trends (social, ecological and technical) was conducted. Based on these previous results, design vision was formulated that described as a metaphor: Discover in the forest, which provided a guideline for the ‘Construction’ of future context and interaction. The concepts of each zone and involving service were developed under the sub-metaphors that originated from the engaging activities in the forest. These concepts were eventually demonstrated by a scale model (1:50) while a special showroom from one zone was build into 1:1 scale prototype for user test. On the basis of test results, a developed proposal of the showroom was ultimately presented at the end of project. The manager of Awarehouse intended to implement the interactive showroom in the future project and partially adopt the proposals of six zones.","exhibition; showroom","en","master thesis","","","","","","","Campus only","","Industrial Design Engineering","Industrial Design","","Master of Science Integrated Product Design","",""
"uuid:d78723a9-7b4f-4d3a-a568-c0d7d14a1632","http://resolver.tudelft.nl/uuid:d78723a9-7b4f-4d3a-a568-c0d7d14a1632","Do we really need A Priori Link Quality Estimation?","Vasilopoulos, V.","Zúñiga Zamalloa, M.A. (mentor)","2013","Traditionally, link quality estimation (LQE) has been viewed as an a priori step in sensor network routing protocols because it filters out unreliable links before data transmission. Recent results, however, show that protocols can perform well without a priori LQE. Because getting rid of LQE seems rather counter-intuitive, the aim of this work is to look deeper into the behavior of LQE-free protocols. Our results, based on one of the state-of-the-art LQE-free protocols, show two interesting insights. First, LQE-free protocols manage to choose links that are slightly better than the ones obtained with a priori LQE methods. Second, in traditional protocols, the effort needed to identify good links accounts for 40% to 60% of the energy consumption of nodes. By eliminating this overhead, LQE-free protocols can save a significant amount of energy compared to standard approaches. On the other hand, clear downsides of LQE-free operation are the longer paths and the worse load balance. The latter poses a higher transmission burden on some nodes.","Link Quality Estimation; Data Collection; Routing; Collection Tree Protocol; Broadcast-Free Collection Protocol; Wireless Sensor Networks","en","master thesis","","","","","","","","2013-08-31","Electrical Engineering, Mathematics and Computer Science","Software and Computer Technology","","Embedded Systems","",""
"uuid:1ef9216e-d6f3-4687-88c5-d5fb9ce6b614","http://resolver.tudelft.nl/uuid:1ef9216e-d6f3-4687-88c5-d5fb9ce6b614","Verification of Cascading Events in Interconnected Stochastic Systems: Using Adaptive Parametric Importance Sampling Methods","Cox, P.B.","Abate, A. (mentor); Tkachev, I. (mentor); Blom, H.A.P. (mentor); Stano, P.M. (mentor)","2013","Verification of rare cascading events in interconnected Markov processes are of high interest in energy grids, computer networks, and banking systems. Small defaults may lead to a global cascade of failures in the network. In this work, the rare events of contagious bankruptcies of the interconnected banking system are verified by three adaptive parametric importance sampling methods, belonging to Monte Carlo simulation based approaches. All three methods show comparable results in terms of the accuracy and the convergence speed on the medium sized benchmark example. Additionally, we claim that the adaptive parametric importance sampling methods scale linearly in time with respect to the sample size. The sensitivities of large or small size banks are clearly different; the larger, well connected banks have a significantly higher probability to trigger cascading; whereas for small, well connected banks this increase in probability is not found. The probability of triggering cascading is comparable between the larger sized, low connected banks and all small sized banks disregard its degree of connectivity. The results are in line with literature, which makes the adaptive parametric importance sampling methods suitable for verification of the network sensitivity.","Verification; Cascading Events; Stochastic Hybrid Systems; Importance Sampling","en","master thesis","","","","","","","","2018-08-13","Mechanical, Maritime and Materials Engineering","Delft Center for Systems and Control","","Systems and Control Engineering","",""
"uuid:a1207c6a-36d9-4149-8279-ceffb2117273","http://resolver.tudelft.nl/uuid:a1207c6a-36d9-4149-8279-ceffb2117273","Pile Foundation and Soil Response to Deep Excavation","Haryono, I.S.","Van Tol, A.F. (mentor); Korff, M. (mentor); Bakker, K.J. (mentor); Brinkgreve, R.B.J. (mentor); Vervoorn, R.R.E. (mentor)","2013","Construction of deep excavation in densely populated area is not a trivial thing. The execution could induce disturbance to the soil and adjacent buildings. Many researches have analysed building responses to deep excavation or tunnelling projects. But the studies were mostly limited to buildings with shallow foundations. The importance of understanding the behaviour of piled buildings is significant, especially in the analysis of buildings displacement. It is commonly found that deep excavation pits are situated close to piled buildings, especially in densely populated cities with soft subsurface. Even the buildings are founded on piles, there are no guarantees that the buildings are not affected by deep excavation activities. Currently, a metro extension project in Amsterdam is being built. It passes the historic centre of the city and the buildings are founded on pile foundations. The project involved numerous amounts of measurements. Based on the measurement results, it has been found that due to the project, the buildings settle more than the foundation layer, but less than the surface settlement. It is suspected that the settlement of the buildings is influenced by the behaviour of the pile foundation. This research is conducted to investigate and explain pile behaviour during the execution of deep excavation project. The focus of the study is at Ceintuurbaan station. The construction stages are modelled in 3-dimensional finite element analysis, in order to include the diaphragm wall installation phases. Before analysing the pile behaviour, back analysis of soil displacement is performed. After reasonable agreement in the soil displacement has been achieved, the pile behaviour has been analysed in more detail. It is found that a reasonable agreement between measurement and simulation results can be obtained. Based on the analysis results, it is evident that the settlement of the building is influenced by several factors, including stress changes in the soil, neutral plane position, and the settlement of the soil adjacent to the pile. These factors are related interactively during each construction stage. The load on the pile also plays important role. Pile with higher load will experience larger settlement compared to pile with smaller load. Based on the monitoring data and the 3D simulation results, the importance of each construction stage is demonstrated. Based on the analysis of monitoring data at Ceintuurbaan Station, it is shown that preliminary works could induce 31-59% of soil and building settlement. In the analysis of soil-structure interaction, it is important to take into account each construction stages and it should not only focus on the excavation stages.","geotechnical engineering; foundation engineering; pile foundation; negative skin friction; deep excavation; finite element analysis","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Geo-engineering","",""
"uuid:cbdcf43c-d285-4e96-a053-88f2eca39f3c","http://resolver.tudelft.nl/uuid:cbdcf43c-d285-4e96-a053-88f2eca39f3c","Wake Dynamics Study of an H-type Vertical Axis Wind Turbine","He, C.","van Bussel, G.J.W. (mentor); Simao Ferreira, C.J. (mentor)","2013","Recent developments in wind energy have identified vertical axis wind turbines as a favored candidate for megawatt-scale offshore systems. Compared with the direct horizontal axis competitors they poss higher potentials for scalability and mechanical simplicity. The wake dynamics of an H-type vertical axis wind turbine is investigated using Particle Image Velocimetry (PIV). The experiments are conducted in an open jet wind tunnel with a turbine model of 1 m diameter constituted of 2 straight blades generated from a NACA0018. The turbine model is operated at a tip speed ratio of 4.5 and at a maximum chord Reynolds of 210,000. Two-component planar PIV measurements at the mid-span plane focus on vorticity shedding and horizontal wake expansion. Stereoscopic PIV measurements at 7 cross-stream vertical planes are performed to study tip vortex dynamics and evolution of 3D wake structures. Measurement at the turbine mid-span plane shows that the roll-up of shed vortex is triggered by wake interactions. Vorticity decay is asymmetrical with the faster decay rate at the leeward side. The faster windward wake expansion is attributed to the windward deflection of the tower wake. Wake recovery has not been observed in the horizontal measurement plane up to 4R downstream of the rotor. Experimental results on the vertical planes show that the tip vortex is stronger than the shed vortex in the horizontal plane. The strongest tip vortex is produced near the turbine axial plane (y/R = 0), and the in-rotor vorticity decay accounts for 60% - 90% of the overall decay. Near y/R = 0, tip vortices move inboard behind the rotor, whereas the turbine tower and the horizontal struts obstruct the inboard motion within the rotor swept volume. The rate of inboard motion is proportional to the vorticity strength. Due to weak vortex strength and strong blade blockage, tip vortices move outboard at two sides of the rotor primarily towards the windward side. Roll-over of vortex pairs contributes to the breakdown of vortical structure behind the rotor. Vertical wake recovery begins 4R downstream of the rotor, and the fastest recovery is observed near y/R = 0.","Windenergy","en","master thesis","","","","","","","","","Aerospace Engineering","Aerodynamics & Wind Energy","","","",""
"uuid:5a6113f5-04ca-4da3-b147-d32af7b58852","http://resolver.tudelft.nl/uuid:5a6113f5-04ca-4da3-b147-d32af7b58852","Statistical analysis of 2D trace-line maps of fracture networks in carbonate rocks of the Jandeíra Formation in Brazil","Paulides, C.A.M.","Bertotti, G. (mentor)","2013","The fracture network of the Jandeíra Formation in the northeastern part of Brazil is controlled by two main (paleo-) stress fields. The first stress field, characterized by a NS-oriented compression, occurred from the Campanian to the Miocene. The second occurred from the Miocene to the Quaternary as an EW-oriented compression. In the western and central part of the Potiguar Basin it shifts to a NW-SE-oriented compression and a NE-SW-oriented extension. Both stress fields resulted in a heterogeneous fracture network throughout the whole basin. This system has been analyzed with imagery from around 50 meters above the ground with a resolution of 1.5 cm/pixel. Three main fracture sets are found in the studied outcrop, though in the outcrop itself the sets are highly heterogeneous spread; which supports the conventional outcrop studies. The length distribution of EW fractures are strongly influenced by abutment i.e. earlier fractures have restricted the propagation of succeeding fractures. This study shows that fracture length distributions and spatial distribution are exponentially distributed. Although this study is limited by its resolution, it gives a good first impression of fracture behavior in the Jandeíra Formation, but composite analysis of different scale ranges would improve the value of this study considerably.","fracture network analysis; carbonate rocks; ArcGIS; georeferenced imagery","en","bachelor thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Applied Geology","",""
"uuid:8d73dc99-e8c4-4ff2-83b9-a16ba2ece4a5","http://resolver.tudelft.nl/uuid:8d73dc99-e8c4-4ff2-83b9-a16ba2ece4a5","Photoacoustic Imaging by Means of Sparsity Regularization","Stoev, V.V.","Remis, R.F. (mentor)","2013","The intertwine of the optical and acoustic domains by the photoacoustic effect has given rise to the novel technique of photoacoustic imaging. As a relatively new field it faces many challenges from different character on the way to clinical applications. One of these challenges, which deteriorates image quality and sharpness, is noise. The usual answer to this undesired effect is averaging over multiple measurements. This has its cost however, prompting the search for other noise reduction methods. In this thesis, we assume our imaging domain to be sparse and apply sparsity regularization accordingly. By this, we attempt to reduce the noise artefacts and improve the overall signal-to-noise ratio. To accomplish this task, we first solve the photoacoustic wave equation in linear form and discretize the result to acquire a data model. Then, we construct an imaging procedure based on the adjoint operator. Finally, we apply the sparsity regularization procedure to both synthetic and experimental data. We report on improved signal-to-noise ratio and several interesting finds among which are the dependence of the regularization parameter on the noise power and a different optimality criterion for the parameter choice in photoacoustic imaging.","photoacoustic; imaging; sparsity; regularization","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Telecommunications","","Circuits and Systems","",""
"uuid:2aa12ef6-b789-4c29-a8bd-774be37a17e2","http://resolver.tudelft.nl/uuid:2aa12ef6-b789-4c29-a8bd-774be37a17e2","Design proposal for using a new incubator technique for BabyBloom Healthcare","Ceulemans, D.S.","Geer, S.G. (mentor); Goossens, R.H.M. (mentor)","2013","This thesis is the result of the master graduation project of Danielle Ceulemans titled: Design proposal for using a new incubator technique for BabyBloom Healthcare. The design proposal describes a new incubator technique to prevent extreme premature infants from cold stress during a medical procedure while having optimal access to the infant. Introduction Current closed incubators lack in the protection for environmental stimuli, such as light and noise, bonding with the parents and they do not provide an ergonomic working position for the medical staff. This was the motivation for BabyBloom Healthcare to develop the world´s first child-, parent- and nurse friendly incubator. BabyBloom Healthcare´s current focus is on closed incubators and not on radiant warmers or Hybrid Incubators, which is a combination of a closed incubator and radiant warmer in one. Project goal BabyBloom Healthcare wishes for a better understanding of the actual use of Hybrid Incubators in hospitals, in order to improve or extend their current product portfolio. The project goal is to evaluate the Hybrid Incubator and ultimately give BabyBloom Healthcare a design proposal for the possible implementation of the Hybrid Incubator technique. Analysis Qualitative user research at the neonatal intensive care unit revealed that the Hybrid Incubator is convenient for the medical staff during medical procedures due to the optimal access that is increased by the raised canopy and lowered side panels. However, the research showed that extreme premature infants tend to decrease in temperature during the medical procedure and the radiant warmer cannot maintain the infant´s body temperature. Premature infants have a hard time controlling their body temperature due to their immature physical state and their primitive metabolic responses. Extreme premature infants have little to no brown fat, high skin permeability, large surface area to body mass ratio, poor muscle tone and an immature central nervous system, which increases evaporation. Evaporation is the major cause of heat loss of the extreme premature infant. Cold stress can be prevented with the use of an incubator that provides a humid environment around the infant to decrease evaporation. This humid environment disappears when the canopy is raised and the side panels are lowered. The protective environment for the extreme premature infant will be lost. The effects of cold stress on the short term are respiratory distress, a low glucose level, acid-base derangements and if the infant’s compensatory mechanisms fail, even death. Long term effects of cold stress may result into a reduced cognitive and motor development, however this is difficult to determine due several other environmental influences such as physical contact, light and noise. The conclusion can be drawn that the Hybrid Incubator is not able to maintain the body temperature of the extreme premature infant during a medical procedure, which may result into a decreased health for the infant. However, users often prefer the Hybrid Incubator over a closed incubator due to the optimal access above the infant after raising the canopy. The priority of the doctors is to focus on the treatment rather than maintaining the infant’s body temperature. This results into a conflicting concern whereby the doctor wants optimal access and the infant needs a protective humid environment. The mission was to find a balanced compromised solution between the conflicting concerns: accessibility and protective environment. Conclusion The proposed design provides optimal access to the infant after removing the side panels and the canopy from the baby compartment, while protecting the infant against cold stress during a medical procedure due to the warm and humid environment. Flow simulations prove that it is possible to create a warm and humid environment. Though, a solution has to be found for the small temperature differences of the protected environment as for the increased outlet temperature, to meet the requirements. The design has been evaluated by integrating the medical staff to simulate the interaction. This resulted in a small temperature decrease and optimisation is required to increase the strength to provide a better warm and humid environment. The Airena makes use of a new incubator technique that has never been used before and looks promising based on the flow simulations. Optimisation is necessary to improve the design to maintain its protective environment. The Airena is already an improvement in comparison with the current incubators due to the increased warm and humid environment in combination with the optimal accessibility to the infant. My advise to BabyBloom Healthcare is to improve the Airena in cooperation with aerodynamic experts. A feasibility study must reveal if BabyBloom Healthcare can improve or extend their current product portfolio with the Airena.","incubators; premature infants","en","master thesis","","","","","","","Campus only","2014-08-12","Industrial Design Engineering","Design for Interaction","","","",""
"uuid:c878e4b8-31c6-4192-84a4-be1576500eab","http://resolver.tudelft.nl/uuid:c878e4b8-31c6-4192-84a4-be1576500eab","Accelerating Wind Energy: A physical approach to monitor tower base fatigue loads using standard signals","Koopman, F.J.","","2013","Keeping track of the experience loads can be of great value for wind energy. If for instance lower loads are found than expected, the lifetime of a wind turbine could be extended beyond its design life. This will lead to a reduction in the cost of energy. Another advantage of so-called load monitoring is that design loads can be evaluated. This could lead to the conclusion that site conditions are different than expected, which means that either the turbine’s operation needs to be altered or the design can be changed for future turbines. Furthermore load monitoring gives insight into turbine behaviour.","Windenergy","en","master thesis","","","","","","","","","Aerospace Engineering","","","","",""
"uuid:a9db50d5-7b8f-42db-8896-175ac997316d","http://resolver.tudelft.nl/uuid:a9db50d5-7b8f-42db-8896-175ac997316d","Test Sequence Validation and Generation using Classification Trees","Schooljan, H.","Gross, H.G. (mentor)","2013","It has become very tedious to specify test cases for software artifacts in a consistent way, due to high complexity of the system under test. In order to help testers design these test cases more efficiently, tool support has been created in the form of CTE XL Professional to make people able to specify, validate and also generate test cases in a user-friendly way through the use of classification trees. This thesis project explores techniques for generating and validating sequences of dependent test steps using classification trees, which can only be done manually in the current support tools. We also describe the development process of a prototype plugin for CTE XL Professional for Berner & Mattner Systemtechnik GmbH, which is used to evaluate the test sequence generation process in a practical environment and as a contribution toward inclusion into a future CTE XL release. We find that exhaustive test sequence generation through the construction of a complete tree of possible test paths is only feasible for very small systems because of time complexity problems, and is only usable for achieving high transition coverage. Simple pseudorandom heuristic test sequence generation methods provide more diverse test sequence sets, however to achieve high test coverage more research is needed on more advanced heuristic algorithms.","classification tree; test sequence validation; test sequence generation; cte xl","en","master thesis","","","","","","","","2013-12-31","Electrical Engineering, Mathematics and Computer Science","Software Technology","","","",""
"uuid:d07d08de-e775-402d-ba4b-a6ade1152d67","http://resolver.tudelft.nl/uuid:d07d08de-e775-402d-ba4b-a6ade1152d67","Performance of reliability methods in geomechanical applications","Vásconez, P.A.","Hicks, M.A. (mentor); Van Gelder, P. (mentor); Van Den Bogert, P.A.J. (mentor); Vardon, P.J. (mentor); Nuttall, J.D. (mentor)","2013","Reliability-based design is an approach currently gaining more popularity for geotechnical engineering. Neverthless, its implementation poses several challenges, one being the additional time (usually significant) in order to perform it. An important portion of this additional time comes from the need to perform many scenarios to compute the probability of failure: a Monte Carlo analysis (the most widespread procedure) can easily take more than tens of thousands of realisations to converge. Moreover, there is a tendency to use complex models in practice (e.g. finite element analysis), producing more often prohibitive computation time. This thesis attempts to find alternative reliability methods to Monte Carlo capable of reducing the computation time for geomechanical problems in the oil and gas industry. The methodology is to evaluate several different methods (named workflows) for specific examples. The terms of the evaluations are in accuracy (defined as the closeness to the exact result obtained by a Monte Carlo analysis) and efficiency (measured in the number of geomechanical model realisations). Among the proposed workflows (i.e. methods), there is one which is capable of computing accurately and efficiently the probability of failure for all the analysis made, and others which have a potential to do so, if some improvements are performed. The worklow currently capable is First-Order Reliability Method (FORM), requiring around 30 to 100 realisations for cases with 6 and 11 random variables, respectively. The workflows with potential to be accurate and efficient are FORM and Monte Carlo applied on a response surface that updates (instead of directly using the actual complex model), which required between 10 to 30 realisations. Both represent a strong reduction versus a Monte Carlo analysis, which at took approximately 20,000 to 60,000 realisations in this study. However, for the latter workflows the accuracy on the probability of failure depends on the degree of non-linearity of the response and the target probability of failure. When the non-linearity is high and/or the target low, the updates of the response surface stops before it can accurately represent the actual response in the most probable failure region, subsequently obtaining low accuracies on the probability of failure. A connection between the updates and the prediction of the actual response surface is thought to be able to improve this workflows in order to achieve good accuracies for all the examples analysed in the study. Therefore, it is feasible with the methods proposed to compute accurately and efficiently the reliability in geotechnical engineering, but this conclusion is restricted to for the specific examples evaluated in this study. If a new type of problem is desired to be addressed, it is recommended to validate them first (by comparing their results to Monte Carlo analysis), before using them confidently in practice.","reliability; geotechnical; geomechanics; response surface; FORM; Monte Carlo","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Geo-engineering","",""
"uuid:c22e0ae7-49d9-44db-881a-55d7910d2684","http://resolver.tudelft.nl/uuid:c22e0ae7-49d9-44db-881a-55d7910d2684","Comparing Ochiai and Relief for Spectrum-based Fault Localization","Omoro, B.O.","Gross, H.G. (mentor)","2013","Fault localization is one of the activities of system diagnosis and its goal is to pinpoint the precise locations of faults in systems. This process is recognized as one of the most tedious, time-consuming and expensive undertakings of fault diagnosis. Consequently research in this domain have lead to the birth of numerous approaches to automate the process in order to minimize failures and produce reliable systems. Among the proposed fault localization approaches are the statistical-based Spectrum-based Fault Localization (SFL) and machine learning based Feature Selection Relief. In SFL, the assumed faultiness of a system component is computed using a similarity coefficient and the most commonly used coefficients are Ochiai, Tarantula and Jaccard. Currently, Ochiai clearly outperforms most of the known similarity coefficients in SFL. The Feature Selection based Relief, in short known as Relief, is an alternative technique that has been recently proposed for fault localization. The Relief technique works by assigning relevance weights to components and the components that are likely to be faulty receive the highest relevance weights. In this document, we describe the study performed to compare the performance of Ochiai and Relief for SFL in various systems using the SFL-Simulator which is a Ruby-based tool used for research in SFL. Results from the study indicate that the diagnostic performance of both fault localization methods largely depends on the configuration of the system under investigation, i.e. the number of faults, the health states of the faulty components, the constituent components and the links between them and the number of transactions or test runs used. Furthermore, the study has shown that Ochiai has a computational complexity that is superior to Relief.","Fault Localization; System Diagnosis; Spectrum-based Fault Localization (SFL); Ochiai; Feature Selection; Relief Algorithm; SFL-Simulator; Fault Diagnosis; Dynamic Testing","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Software and Computer Technology","","Software Engineering","",""
"uuid:37b78c00-b987-415e-b07a-8171827e743f","http://resolver.tudelft.nl/uuid:37b78c00-b987-415e-b07a-8171827e743f","Identifying Anomalies in a Continuous Running Software System through Log Data Extraction","Siadis, J.","Gross, H.G. (mentor)","2013","Checking the execution behaviour of continuous running software systems is a critical task, to validate if the system is behaving as expected. In order to facilitate this process, many companies from the industry utilize log mechanisms to record events of interest and analyze the data in a post-mortem fashion. However, employing logging facilities in continuous software systems conforms to the data stream model, where the rate of log line generation is high. As a consequence, storing log lines results in enormous log files, which makes manual inspection for troubleshooting and diagnosis purposes a herculean task. Additional factors such as lack of context, noise, verbosity and multi-dimensional data further increases the difficulty to efficiently use log lines as the user has intended. As such, the challenge is to extract anomaly related information from raw log lines and raise alarms when a specified threshold value is repeatedly exceeded. This thesis takes on the challenge by proposing a solution in the form of a data extraction application and an anomaly detection application, which operate on sets of log lines sharing the same identifier and take advantage of the limited variation of log lines.","log lines; anomaly detection; request traces","en","master thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Computer Science","","Software Engineering","",""
"uuid:bdab6529-0fa9-4425-916b-e218336f6c3d","http://resolver.tudelft.nl/uuid:bdab6529-0fa9-4425-916b-e218336f6c3d","Embedded Boundary Method: For Aerospace Problems","Pisaroni, Michele (TU Delft Aerospace Engineering)","Bijl, Hester (mentor); van Zuijlen, Alexander (mentor); Lahaye, Domenico (mentor); De Breuker, Roeland (mentor); Delft University of Technology (degree granting institution)","2013","The application of Computational Fluid Dynamics to model and simulate flows around flexible and moving objects has grown in the last decades fueled by new technological challenges in particular in the aerospace engineering field because of the introduction of highly deformable materials and complex moving systems. Existing body-fitted mesh methods such as the Arbitrary Lagrangian Eulerian (ALE) approach have been proposed to simulate the flow around moving and deforming structures but their applicability is limited because of the issues arising in deforming the computational grid constrained to the moving/deforming structure. This thesis focuses on the verification, and validation of an Embedded Boundary method (developed at Stanford University by Prof. Farhat research group) for the solution of fluidstructure interaction problems involving large and complex structural motions and deformations. The Embedded Boundary method works on non-body fitted grids, by using a tracking algorithm is able to impose the effects of an ’immersed’ moving and deforming surface mesh on the fixed Eulerian fluid mesh. For this reason this method is gaining popularity because it simplify a number of issues ranging from codes coupling (fluid-structure solvers) to formulating and implementing algorithms for applications that involve very large and complex motions-deformations and for which ALE algorithms are unfeasible.","","en","master thesis","","","","","","","","","","","","Aerospace Engineering | Aerodynamics and Wind Energy","",""
"uuid:abe4bb0c-2171-43cf-a0ac-5608bc07e66b","http://resolver.tudelft.nl/uuid:abe4bb0c-2171-43cf-a0ac-5608bc07e66b","Time-dependent flow through a junction of pipes","Van der Boor, B.F.","Romate, J. (mentor)","2013","","","en","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","","",""
"uuid:3555f705-cab3-4c3c-9efd-01fa662d46f6","http://resolver.tudelft.nl/uuid:3555f705-cab3-4c3c-9efd-01fa662d46f6","Discrete Fracture Networks in carbonate anticlines: An example from the Berda Anticline in Southern Tunisia","Bekkers, R.W.G.","Bertotti, G. (mentor); Hardebol, N.J. (mentor); Rossen, W.R. (mentor); Bisdom, K. (mentor)","2013","Fractures can have a big impact on fluid production from subsurface reservoirs, but direct evidence of their presence is often lacking or ignored until the later stages of reservoir development. Outcrop analogue studies help in understanding and extrapolating fracture data outside the radius of a well. This paper presents the analysis of the carbonate Berda Anticline in the Gafsa Basin of Southern Tunisia. Non-stratabound bed-perpendicular fractures of Late Miocene age were found to be created due to Layer Parallel Shortening (LPS). Normalized fracture densities are homogenous throughout the anticline, and no areal property trends were observed. The fracture size distribution is represented by a power-law distribution, which is in turn almost self-similar. The fractures are modelled as local Discrete Fracture Networks (DFN’s), and these local models are combined into a structure-wide DFN. Both the conditioning of the local DFN’s to the field data, as the conditioning of the structure-wide DFN were successful. An analysis on the influence of fracture aperture on network connectivity showed that this influence is high. No aperture-data is available, so the overburden pressure is used to estimate this property, corrected for the presence of tectonic stresses. A grid model was constructed to facilitate a limited field development. Due to the Monte Carlo method of simulating the fractures, areal permeability and porosity trends are absent. About 85% of the fracture network volume is connected to a vertical production well, with an increase of 1-2% when using either a deviated well or multiple wells. This is caused by the relative orientation of the fracture sets, and the high fracture density. A P50 development scenario resulted in a recovery of 268.000 barrels of oil.","fracture; folds; Tunisia; carbonates; reservoir model; fracture model","en","master thesis","","","","","","","","","Civil Engineering and Geosciences","Geoscience & Engineering","","Petroleum Engineering & Geosciences","",""
"uuid:7a4cef16-7cc6-4bc2-942a-73719358d7c7","http://resolver.tudelft.nl/uuid:7a4cef16-7cc6-4bc2-942a-73719358d7c7","Conceptual Design Analysis of an 8,000mt Crane for HMC’s NSCV",", Kamp, J.","van den Bos, W. (mentor)","2013","","","en","master thesis","","","","","","","","2018-08-08","Mechanical, Maritime and Materials Engineering","Marine and Transport Technology","","Transport Engineering and Logistics","",""
"uuid:0ab38f88-0588-499a-b99e-62ee941d4fda","http://resolver.tudelft.nl/uuid:0ab38f88-0588-499a-b99e-62ee941d4fda","Scansistant","Ypeij, T.M.; Hensen, D.K.L.","Clavel, C.L. (mentor); Nelson, A.T. (mentor); Bertels, K.L.M. (mentor)","2013","Nowadays a lot of students have smart-phones that can be put to use for mobile learning. The TU Delft Library has come up with an idea for this which also incorporates the use of a modern technology called Near Field Communication. It is already available on the market but immature so experience has to be gained in combination with mobile learning to see if it is worth to pursue further developments on this area. The TU Delft Library has the idea of using a mobile application to scan machinery on the campus as a way to get instructional videos and information to perform a feasibility study and to gain experience on the aforementioned area of interest. From the wishes of the client and our own acquired computer science skills the requirements came forth and as a start of the software development. For the requirements of the final delivered prototype application we carefully looked if the features could help to perform the feasibility study and are able to answer the questions for the this study. From these requirements we conclude that more than a simple Android application has to be built: a central server to house all video and data was also required and a way to provide communication between this server and android client application. For this we designed an API so that many clients can get information from the server. The software subsystems consist of a back-end, front-end and client application. They are developed in Java, building upon the Android SDK and in PHP, building upon the Zend Framework 2. For the NFC technology libraries are available so that tags could be successfully scanned after which the machine data could be downloaded. For development of all subsystems we used Eclipse and associated plugins to enable for Android and ZF2 development. The design of the subsystems was done in parallel and on-demand so that features required by the android application that needed an API method that was not yet there was immediately implemented when needed. It started with a global database design after which we could both focus individually on the platform specific details. The user interface design was important because that is the level at which the feasibility study will be performed when the end-user gets to use the application. The design focus was on smart-phones, but because tablets are widely used also we made it compatible making use of its bigger screen. Because of an agile and feature driven development methodology we use exploratory testing for the largest part of the project. After we had a stable system we started writing tests because we now had gained enough knowledge of the development platform to efficiently write tests. At the end we managed to have tested the Android application by unit testing the models and the API was tested by a controller testcase to test the responses of critical API methods. For the scope of our project we did not need to perform the feasibility study ourselves, but we did ran some user evaluation trials to get a first reaction on the application before delivering a final prototype. The feedback that we got from these user evaluations allowed us to increase the chances at success because the first issues we got from users could solved before delivering a prototype. The final prototype meets all requirements we planned to have and executes its task to scan a machine and show an instructional video very well. The application works on Android phones with the 4.0 version or higher and we think is a good platform to further develop. The Software Improvement Group evaluated our code and rated it at 4 out of 5 stars on their maintainability model, which means the maintainability of our total software system is above average.","NFC; scan; assistant; Scansistant; lab; machine; Android; Zend Framework 2","en","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Computer Science","","Technische Informatica","",""
"uuid:60938242-835c-4b17-9850-85b881c90e1a","http://resolver.tudelft.nl/uuid:60938242-835c-4b17-9850-85b881c90e1a","DC Microgrids in the Netherlands","Wattel, M.J.","Lukszo, Z. (mentor); Herder, P.M. (mentor); Warnier, M.E. (mentor); Schaacke, R. (mentor)","2013","The Dutch electricity system is changing and subject to multiple developments. Important developments are the increasing share of distributed energy resources (DER?s) such as solar panels and the increasing use of electronics like computers and televisions. While DER?s produce DC (Direct Current) power, electronics consume DC power. Nevertheless, the main electricity grid is based on AC (Alternate Current) power, which has been the standard since the 1890?s. This requires the electricity generated from DER?s to be inverted to AC power first before it can be delivered to the main grid. Subsequently, electronics need to convert the AC power back to DC power again before it can be used. This reduces the efficiency of the electricity system. DC microgrids are local small scale electricity grids, usually powered by DER?s. DC power from DER?s can directly be fed into this grid, while DC consuming devices can directly consume this electricity, resulting in a higher efficiency than the conventional electricity system based on AC. Applying DC microgrids has more advantages. It can reduce cost of raw materials while batteries and Electronic Vehicles (EV?s) can be integrated easily. Additionally, this type of electricity supply is more reliable. However, integrating DC microgrids in the Dutch electricity system is not easy since the standard for electricity transport and distribution has been AC for more than a century. This causes path dependence: the phenomenon of having a limited choice of decisions as a consequence of decisions made in the past. This leads to the following research question, investigated in this research: “What is the feasibility of integrating DC microgrids in the Dutch electricity system?” To examine this research question, a feasibility framework has been designed. This framework is based on the multi-level perspective, complemented by other theories and serves to analyze dynamics of transitions in socio-technical systems. The electricity supply system is an example of a socio-technical system (STS); an integration of technical artifacts, coordinated by human agencies that serve societal functions such as electricity supply. By using the framework, the main drivers and barriers that influence the transition are identified, including the way they influence the electricity system. The main drivers of DC microgrids are a reduction of costs, an increase of the reliability of the electricity supply and a better facilitation of developments in the electricity system. The main barriers to this system include the absence of developed standards and codes needed for DC appliances, engineers that think? in AC power, power electronics that have not yet been fully developed and the chicken-and-egg?-problem: first DC appliances or DC households. To examine the influence of these forces, the problem window and the solution window have been defined, and together lead to a window of opportunity for a transition. It is concluded that the solution window is opened: the advantages of DC microgrids are significant, and the developments are promising. Important actors in the electricity system consider DC microgrids as a serious alternative technology. However, for a transition and a window of opportunity, a problem window needs to be opened as well, which is not the case at this moment. A problem window opens when important actors and policy makers in the electricity system have a sense of urgency to solve certain problems to which DC microgrids could form a solution. Creating a sense of urgency among these actors could enhance the transition to DC microgrids. Other means that could enhance the transition to DC microgrids are described in a roadmap including: stimulating the dissemination of knowledge about DC microgrids, to execute pilot projects and to develop standards and norms for DC applications and systems.","DC microgrids; Dutch electricity system; multi-level perspective; socio-technical systems; transitions","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Energy","","SEPAM","",""
"uuid:7843855d-17cd-4937-a0e9-5fb3c85e952a","http://resolver.tudelft.nl/uuid:7843855d-17cd-4937-a0e9-5fb3c85e952a","The dynamics of electricity demand and supply in the low voltage distribution grid: A model study","Van Zoest, P.L.A.","Herder, P.M. (mentor); Lukszo, Z. (mentor); Künneke, R.W. (mentor); Veldman, E. (mentor)","2013","In this thesis a simulation study is executed that analyses how new developments of household electricity demand and decentralised electricity generation affect the low voltage distribution grid, and what the possibilities of distribution system operators are to deal with these changes. A simulation model is used to analyse how the electricity load on the low voltage distribution grid develops in the coming decades. Based on this load it is determined when different transformers and cables have to be replaced because of capacity constraints. In addition to this it is analysed how the implementation of demand side management, smart charging of electric vehicles and smart storage of electricity in the low voltage distribution grid affects the required number of investments in cables and transformers and the investment costs for distribution system operators. Based on these model outputs it has been determined that smart charging of electric vehicles is expected to have the largest impact on the required investments, and in combination with demand side management the required investments can be further decreased. The implementation of smart storage only has a limited impact on the required investments in low voltage distribution grids.","electricity distribution grid; load management; investment costs; smart storage; demand side management; smart charging","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Energy & Industry","","MSc Systems Engineering, Policy Analysis, and Management","",""
"uuid:f61f53fe-86bd-426d-8843-1e67d1141bdd","http://resolver.tudelft.nl/uuid:f61f53fe-86bd-426d-8843-1e67d1141bdd","“What do they say about us on Twitter?”: Hybrid sentiment retrieval for organisations","Visser, P.","Houben, G.J.P.M. (mentor); Bidarra, A.R. (mentor); Van Nuland, K.J. (mentor)","2013","We conclude this report with a system design and proof-of-concept to show how an adaptable hybrid sentiment classification system is able to improve sentiment analysis for organisations. GreenOnline, a service company in the field of customer services, wants to be able to quantify sentiment for organisations precisely, to create new services for organisations. To start with, this sentiment analysis will be based on Twitter messages. The main challenge during this research was that Tweets, short WOM (Word-Of-Mouth) messages that contain only little words, are highly abbreviated and sentiment is expressed in subtle ways with irony, sarcasm, slang and other linguistic shades of grey [9]. Therefore, the focus of this thesis project was to design a system that is able to combine different sentiment analysis techniques to find sentiment. Also, not only existing algorithms were combined, but also information from the message (message attributes) are regarded as a way to determine the sentiment or which algorithm will classify the sentiment of that message best. Overall, it was regarded that all these different elements leave room for optimisation, for what algorithms and attributes to use and for what messages to select from Twitter for an organisation. To support a process of optimisation for a campaign or organisation another goal was to embrace the ability of system optimisation by (GreenOnline) customer service experts. The result is a design and proof-of-concept implementation of a hybrid and adaptable sentiment analysis system design, which is using implementations of three sub classifier algorithms and message properties, that are combined by a hybrid sentiment classifier in a sentiment value of negative, positive or neutral. This proof-of-concept implementation showed a performance of 71,2% which is a great improvement with respect to the single sub classifications of which the best performance was only 58,2%. By improvement of customer service experts this performance can even grow further.","sentiment analysis; hybrid classification","en","master thesis","","","","","","","","2014-08-02","Electrical Engineering, Mathematics and Computer Science","Software and Computer Technology","","Web Information Systems","",""
"uuid:82e3eed5-b39b-48b5-b95a-3a8049b76d23","http://resolver.tudelft.nl/uuid:82e3eed5-b39b-48b5-b95a-3a8049b76d23","Integration or specialization? Impacts of current trends on the Dutch oil downstream industry","Van Huijstee, J.T.E.","Scholten, D. (mentor); Stikkelman, R. (mentor); Kunneke, R. (mentor); Fidder, J. (mentor); Holleman, R. (mentor)","2013","Due to the changing market structure of the downstream oil industry it is important for oil companies to gain more insight in how the oil downstream value chain works and how current trends affects them and their competitors. This article facilitates the need for insight by giving a clear picture of the oil downstream value chain and the different business models in the value chain and showing how these business models are affected by the changing market dynamics, global competition and other trends in the Netherlands. Based on the vertical integration theory and a case study into the Dutch downstream oil industry current trends were assessed. The main findings of the research are that due to the effects of the trends business models will polarize in their vertical integration strategy, focusing either on their core network through fully vertically integrating over the downstream value chain. Whilst the other found strategy focuses more on the core activities of the business model through vertical specialization over one or two industry sectors. This polarization in the market landscape in 2020 is driven by the underlining vertical integration motivations that are either based on the Economies of Vertical Integration approach or Transaction Cost Economies approach. Article: Polarization in the downstream industry: Impacts of the current trends on the Dutch oil downstream industry","vertical integration; downstream oil industry; trend analysis; business models; critical success factors","en","master thesis","","","","","","","Campus only","","Technology, Policy and Management","Economics of Infrastructures","","SEPAM","",""
"uuid:b1c86da0-3786-4fd7-b2c6-1cf0d3da8865","http://resolver.tudelft.nl/uuid:b1c86da0-3786-4fd7-b2c6-1cf0d3da8865","Enhanced digestion and alginate-like-exopolysaccharides extraction from Nereda sludge","Hogendoorn, A.A.","Van Lier, J.B. (mentor); Van Loosdrecht, M.C.M. (mentor); De Kreuk, M.K. (mentor); Koornneef, E. (mentor)","2013","Aerobic granular sludge/Nereda technology has proven to be more beneficial compared to activated sludge systems. Until now not much research has been spend on treatment of Nereda excess sludge (NES). In this study the biodegradability of NES is investigated, combined with thermal pressure hydrolysis (TPH) as pre-treatment method and the application of an up-flow digester concept. The maximal biodegradability is estimated at 50% volatile solids (VS) (VS content of raw sludge is 80%). In a conventional CSTR digester 42% VS is converted, whereas TPH increased this to 48% (HRT=20 days). The up-flow digester performed slightly better than the conventional system: 43% VS is converted. Modelling of the CSTR systems showed to yield well fitting results; modelling of up-flow digesters yielded results which deviated a lot from the measured values. Besides anaerobic digestion, the extraction procedure of alginate-like-exopolysaccharides (ALE) is optimized and the mutual influence of digestion and ALE extraction is researched. Extraction of ALE can be done with a lower amount of chemicals as the initial procedure. ALE seems to be slowly biodegraded during anaerobic digestion, although the amount of ALE recovered from digested sludge did not differ from undigested sludge. ALE extraction applied prior to digestion could be a synergistic hybrid, as the extraction procedure can act as a pre-treatment method to reduce sludge volume and increase biodegradability rate. The optimal combination is however not yet found. Finally the influence of ALE-extraction method and protein content is investigated. ALE seems to contain a significant fraction of protein (20-40%), although large differences were observed between protein detection methods and ALE extraction methods.","Nereda; Schwarting; digestion; alginate; alginate-like-exopolysaccharides; aerobic granular sludge; thermal pressure hydrolysis","en","master thesis","","","","","","","","2013-08-02","Civil Engineering and Geosciences","Water Management","","Sanitary engineering","",""
"uuid:d4eedec7-c14d-4c5b-b117-eb680ed35dfd","http://resolver.tudelft.nl/uuid:d4eedec7-c14d-4c5b-b117-eb680ed35dfd","Pricing of Asian options on baskets of futures","Borovykh, A.I.","Oosterlee, C.W. (mentor); Grzelak, L.A. (mentor)","2013","","","en","bachelor thesis","","","","","","","","","Electrical Engineering, Mathematics and Computer Science","Delft Institute of Applied Mathematics","","Applied Mathematics","",""
"uuid:289b1806-caf9-4e9e-8c9e-25c8acb5b591","http://resolver.tudelft.nl/uuid:289b1806-caf9-4e9e-8c9e-25c8acb5b591","Level Set Methode voor Tumorgroei in relatie tot Angiogenese","Schols, E.","Vermolen, F.J. (mentor)","2013","In dit project is het proces van tumorgroei gemodelleerd, met als belangrijkste wiskundige methoden de Level Set Methode en de Eindige Volume Methode. Hiervoor zijn partiële differentiaalvergelijkingen opgesteld voor de chemokinen- en zuurstofconcentratie. Aan de hand van deze concentraties wordt de groeisnelheid van de tumor bepaald. Aangezien dit model niet analytisch oplosbaar is, zijn hiervoor na discretisatie de genoemde wiskundige methoden gebruikt. Na het toepassen van de Eindige Volume Methode zijn de vergelijkingen door middel van de tijdsintegratiemethode Euler Voorwaarts opgelost. Dit model is in Matlab geïmplementeerd; vervolgens is in de simulatie specifiek gekeken naar de invloed van drie parameters uit het model.","angiogenese; level set methode","nl","bachelor thesis","","","","","","","","2013-08-11","Electrical Engineering, Mathematics and Computer Science","Applied mathematics","","","",""
